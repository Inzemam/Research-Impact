{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.core.display import display, HTML\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal='jmis'\n",
    "alt_detail='https://www.altmetric.com/details/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('altmetrics/'+journal+'_alt.json') as json_data:\n",
    "    d = json.loads(json_data.read())\n",
    "    json_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('policy/'+journal+'.txt', 'a') as out:\n",
    "    out.write('doi \\t article_title \\t policy_source \\t policy_date \\t policy_doc_title \\t policy_doc_link \\n')\n",
    "\n",
    "for doi in alt:\n",
    "    keys=alt[doi].keys()\n",
    "    if 'cited_by_policies_count' in keys:\n",
    "        alt_policy=alt_detail+str(alt[doi]['altmetric_id'])+'/policy-documents'\n",
    "        HTML(\"<a href=\"+alt_policy+\" target='_blank'>link</a>\")\n",
    "        r = requests.get(alt_policy)\n",
    "        soup = BeautifulSoup(r.text,\"html5lib\")\n",
    "        for item in soup.find_all('div',{'class':\"content with_image\"}):\n",
    "            with io.open('policy/'+journal+'.txt', 'a',encoding=\"utf-8\") as out:\n",
    "                article_title=alt[doi]['title']\n",
    "                policy_source=item.find('h4').text.split(' on ')[0].split('Cited by ')[1]\n",
    "                policy_date=item.find('h4').text.split(' on ')[1][-4:]\n",
    "                policy_doc_link=item.find().attrs['href']\n",
    "                policy_doc_title=item.find('h3').text\n",
    "                line=doi+'\\t'+article_title+'\\t'+policy_source+'\\t'+policy_date+'\\t'+policy_doc_title+'\\t'+policy_doc_link\n",
    "                line=line.replace('\\n','')\n",
    "                out.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('articles/'+journal+'.txt', 'a') as out:\n",
    "    out.write('doi\\t Authors\\t Year\\t Title\\t Journal\\n')\n",
    "\n",
    "for doi in alt:\n",
    "    keys=alt[doi].keys()\n",
    "    if 'cited_by_policies_count' in keys:\n",
    "        crossref_api='http://api.crossref.org/works/'+doi\n",
    "        r = requests.get(crossref_api)\n",
    "        soup = BeautifulSoup(r.text,\"html5lib\")\n",
    "        message=json.loads(soup.text)['message']\n",
    "        title=message['title'][0]\n",
    "        year_online=year_print=9999\n",
    "        if 'published-online' in message:\n",
    "            year_online=message['published-online']['date-parts'][0][0]\n",
    "        if 'published-print' in message:\n",
    "            year_print=message['published-print']['date-parts'][0][0]\n",
    "        year=min(year_online,year_print)\n",
    "        if 'author' in message:\n",
    "            authors=message['author']\n",
    "            author_string=authors[0]['family']\n",
    "            if len(authors)==2:\n",
    "                author_string=author_string+' & ' + authors[1]['family']\n",
    "            if len(authors)>3:\n",
    "                author_string=author_string+' et al.'\n",
    "        else: \n",
    "            author_string='MISSING'\n",
    "        journal_title=message['container-title'][0]\n",
    "        with io.open('articles/'+journal+'.txt', 'a',encoding=\"utf-8\") as out:\n",
    "            line=doi+'\\t'+author_string+'\\t'+str(year)+'\\t'+title+'\\t'+journal_title\n",
    "            out.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import glob\n",
    "\n",
    "file_list = glob.glob(\"policy/*.txt\")\n",
    "\n",
    "with open('policy_all.txt', 'w') as file:\n",
    "    input_lines = fileinput.input(file_list)\n",
    "    file.writelines(input_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import glob\n",
    "\n",
    "file_list = glob.glob(\"articles/*.txt\")\n",
    "\n",
    "with open('articles_all.txt', 'w') as file:\n",
    "    input_lines = fileinput.input(file_list)\n",
    "    file.writelines(input_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
