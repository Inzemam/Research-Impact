DETAILSDistribution, posting, or copying of this PDF is strictly prohibited without written permission of the National Academies Press.  (Request Permission) Unless otherwise indicated, all materials in this PDF are copyrighted by the National Academy of Sciences.Copyright © National Academy of Sciences. All rights reserved.THE NATIONAL ACADEMIES PRESSVisit the National Academies Press at NAP.edu and login or register to get:Œ  
Œ  10% off the price of print titles
Œ  Special offers and discountsGET THIS BOOKFIND RELATED TITLESThis PDF is available at SHARECONTRIBUTORS
http://nap.edu/12651Technology, Policy, Law, and Ethics Regarding U.S.Acquisition and Use of Cyberattack Capabilities390 pages | 6 x 9 | PAPERBACKISBN 978-0-309-13850-5 | DOI 10.17226/12651William A. Owens, Kenneth W. Dam, and Herbert S. Lin, Editors; Committee onOffensive Information Warfare; Computer Science and Telecommunications Board;Division on Engineering and Physical Sciences; National Research CouncilTechnology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.William A. Owens, Kenneth W. Dam, and Herbert S. Lin, 
Editors
Committee on Offensive Information Warfare
Computer Science and Telecommunications Board
Division on Engineering and Physical Sciences
Technology, Policy, Law, and Ethics 
Regarding U.S. Acquisition and Use of 
CYB
ERATTAC
K C
APA
BI
LITIES
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.THE NATIONAL ACADEMIES PRESS
 500 Fifth Street, N.W.
 Washington, DC 20001
NOTICE: The project that is the subject of this report was approved by the Gov
-erning Board of the National Research Council, whose members are drawn from 
the councils of the National Academy of Sciences, the National Academy of Engi
-neering, and the Institute of Medicine. The members of the committee responsible 

for the report were chosen for their special competences and with regard for 

appropriate balance.
Support for this project was provided by the MacArthur Foundation under award 
number 04-80965-000-GSS, the Microsoft Corporation under an unnumbered 

award, and the NRC Presidents™ Committee under an unnumbered award.
Any opinions, ˜ndings, conclusions, or recommendations expressed in this pub
-lication are those of the authors and do not necessarily re˚ect the views of the 
organizations that provided support for the project.
International Standard Book Number-13: 978-0-309-13850-5
International Standard Book Number-10: 0-309-13850-7
Library of Congress Control Number: 2009930416
Additional copies of this report are available from:
The National Academies Press
500 Fifth Street, N.W., Lockbox 285

Washington, DC 20055

(800) 624-6242
(202) 334-3313 (in the Washington metropolitan area)
Internet: http://www.nap.edu
Copyright 2009 by the National Academy of Sciences. All rights reserved.
Printed in the United States of America
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.The 
National Academy of Sciences
 is a private, nonpro˜t, self-perpetuating 
society of distinguished scholars engaged in scienti˜c and engineering research, 
dedicated to the furtherance of science and technology and to their use for the 
general welfare. Upon the authority of the charter granted to it by the Congress 
in 1863, the Academy has a mandate that requires it to advise the federal govern
-ment on scienti˜c and technical matters. Dr. Ralph J. Cicerone is president of the 

National Academy of Sciences.
The 
National Academy of Engineering
 was established in 1964, under the char
-ter of the National Academy of Sciences, as a parallel organization of outstand
-ing engineers. It is autonomous in its administration and in the selection of its 
members, sharing with the National Academy of Sciences the responsibility for 
advising the federal government. The National Academy of Engineering also 
sponsors engineering programs aimed at meeting national needs, encourages 

education and research, and recognizes the superior achievements of engineers. 

Dr. Charles M. Vest is president of the National Academy of Engineering.
The 
Institute of Medicine
 was established in 1970 by the National Academy of 
Sciences to secure the services of eminent members of appropriate professions 
in the examination of policy matters pertaining to the health of the public. The 

Institute acts under the responsibility given to the National Academy of Sciences 
by its congressional charter to be an adviser to the federal government and, upon 
its own initiative, to identify issues of medical care, research, and education. 

Dr. Harvey V. Fineberg is president of the Institute of Medicine.
The 
National Research Council
 was organized by the National Academy of 
Sciences in 1916 to associate the broad community of science and technology 
with the Academy™s purposes of furthering knowledge and advising the federal 

government. Functioning in accordance with general policies determined by the 

Academy, the Council has become the principal operating agency of both the 
National Academy of Sciences and the National Academy of Engineering in pro
-viding services to the government, the public, and the scienti˜c and engineering 
communities. The Council is administered jointly by both Academies and the 

Institute of Medicine. Dr. Ralph J. Cicerone and Dr. Charles M. Vest are chair and 
vice chair, respectively, of the National Research Council.
www.national-academies.org
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.vCOMMITTEE
 ON
 OFFENSIVE INFORMATION WARFARE 
WILLIAM A. OWENS, AEA Holdings, Inc., 
Co-chair
KENNETH W. DAM, University of Chicago, 
Co-chair
THOMAS A. BERSON, Anagram Laboratories
GERHARD CASPER, Stanford University 

DAVID D. CLARK, Massachusetts Institute of Technology

RICHARD L. GARWIN, IBM Fellow Emeritus

JACK L. GOLDSMITH III, Harvard Law School

CARL G. O™BERRY, The Boeing Company

JEROME H. SALTZER, Massachusetts Institute of Technology (retired)

MARK SEIDEN, MSB Associates

SARAH SEWALL, Harvard University

WALTER B. SLOCOMBE, Caplin & Drysdale

WILLIAM O. STUDEMAN, U.S. Navy (retired)

MICHAEL A. VATIS, Steptoe & Johnson LLP
Staff
HERBERT S. LIN, Study Director
KRISTEN BATCH, Associate Staff Of˜cer (through August 2008)

TED SCHMITT, Consultant

JANICE SABUDA, Senior Project Assistant (through March 2008)

ERIC WHITAKER, Senior Project Assistant
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.viCOMPUTER SCIENCE AND TELECOMMUNICATIONS BOARD
JOSEPH F. TRAUB, Columbia University, 
Chair
PRITHVIRAJ BANERJEE
, Hewlett Packard Company
FREDERICK R. CHANG, University of Texas, Austin
WILLIAM DALLY, Stanford University

MARK E. DEAN, IBM Almaden Research Center

DEBORAH L. ESTRIN, University of California, Los Angeles

KEVIN C. KAHN, Intel Corporation

JAMES KAJIYA, Microsoft Corporation

RANDY H. KATZ, University of California, Berkeley

JOHN E. KELLY III, IBM Research

SARA KIESLER, Carnegie Mellon University

JON KLEINBERG, Cornell University

PETER LEE, Carnegie Mellon University

TERESA H. MENG, Stanford University

WILLIAM H. PRESS, University of Texas, Austin

PRABHAKAR RAGHAVAN, Yahoo! Research

DAVID E. SHAW, D.E. Shaw Research

ALFRED Z. SPECTOR, Google, Inc.

ROBERT F. SPROULL, Sun Microsystems, Inc.

PETER SZOLOVITS, Massachusetts Institute of Technology

ANDREW J. VITERBI, Viterbi Group, LLC

PETER WEINBERGER, Google, Inc.
JON EISENBERG, Director
RENEE HAWKINS, Financial and Administrative Manager

HERBERT S. LIN, Chief Scientist, CSTB

LYNETTE I. MILLETT, Senior Program Of˜cer

NANCY GILLIS, Program Of˜cer
ENITA
 A. 
WILLIAMS
, Associate Program Of˜cer
MORGAN R. MOTTO, Program Associate
SHENAE
 B
RADLEY
, Senior Program Assistant
ERIC WHITAKER, Senior Program Assistant
For more information on CSTB, see its website at http://www.cstb.org, 
write to CSTB, National Research Council, 500 Fifth Street, N.W., Wash
-ington, DC 20001, call (202) 334-2605, or e
-mail CSTB at cstb@nas.edu.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.vii
Preface
Given the reality of a densely interconnected information society, 
much has been written about the possibility that adversaries of the United 
States such as terrorists or hostile nations might conduct very damag
-ing cyberattacks against critical sectors of the U.S. economy and critical 

national infrastructure that depend on reliably functioning, secure com
-puter systems and networks. For some years, the topic of cybersecurity 

has been an important part of the report portfolio of the National Research 

Council,
1 and a great deal of national attention has been given, in public, 
to the problem of how to protect U.S. information technology systems and 

networks against such attacksŠthat is, how to defend these systems and 

networks in both military and non-military contexts.
2 But, perhaps re˚ect
-ing the common wisdom of the time, these efforts have focused almost 

exclusively on the cyberdefense side of the equation. 
The possibility that the United States might choose to engage in 
cyberattacks to serve its own national interestsŠin cyberdefense as well 
1 An old but still quite relevant report on this topic is CSTB/National Research Council, 
Computers at Risk,
 National Academy Press, Washington, D.C., 1991; other relevant NRC 
reports include CSTB/NRC, 
Trust in Cyberspace,
 National Academy Press, Washington, D.C., 
1999, and NRC, 
Toward a Safer and More Secure Cyberspace,
 The National Academies Press, 
Washington, D.C., 2007.
2 See, for example, National Research Council, 
Information Technology for Counter
-terrorism,
 The National Academies Press, Washington, D.C., 2003; NRC, 
Cybersecurity Today 
and
 Tomorrow: Pay Now or Pay Later,
 The National Academies Press, Washington, D.C., 2002; 
and CSTB/NRC, 
Realizing the Potential of C4I: Fundamental Challenges,
 National Academy 
Press, Washington, D.C., 1998.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.viii
 PREFACE
as in other areasŠis rarely discussed in public. One recent public hint 
of U.S. government interest in the topic can be found in the still-classi
-˜ed Comprehensive National Cybersecurity Initiative (CNCI), which was 
adopted as national policy in January 2008 as part of National Security 

Presidential Directive 54/Homeland Security Presidential Directive 23 

(NSPD-54/HSPD-23). According to the director of national intelligence 

in February 2009, ﬁThe CNCI addresses current cybersecurity threats, 

anticipates future threats and technologies, and develops a framework 

for creating in partnership with the private sector an environment that no 

longer favors cyber intruders over defenders. The CNCI includes defen
-sive, 
offensi
ve [emphasis added], education, research and development, 
and counterintelligence elements.ﬂ
3 Press reports indicated that the CNCI 
involves 12 components designed to protect computer networks and 

systems and to improve information technology processes and policies.
4 These components included a program to reduce the number of connec
-tions from federal agencies to external computer networks to 100 or fewer. 

The other 11 programs address intrusion detection; intrusion prevention; 

research and development; situational awareness (involving the coordina
-tion of information from all agencies to help secure cyber networks and 

systems); cyber counterintelligence; classi˜ed network security; cyber 

education and training; implementation of information security technolo
-gies; 
deterrence strategies
 [emphasis added]; global supply chain security; 
and public/private collaboration.
There is some public writing on the subject of cyberattack. Starting in 
the mid-1990s, the ˜rst papers on the topic emerged, many of them focus
-ing on the legal issues involved in military uses of cyberattack.
5 One of 
3 Dennis Blair, Director of National Intelligence, Annual Threat Assessment of the 
Intelligence Community for the Senate Select Committee on Intelligence, February 12, 2009, 
available at http://intelligence.senate.gov/090212/blair.pdf.
4 See Jill R. Aitoro, ﬁNational Cyber Security Initiative Will Have a Dozen Parts,ﬂ 
Go
vernment Executi
ve, August 1, 2008, available at 
http://www.nextgov.com/nextgov/
ng_20080801_9053
.ph
p.5 See, for example, Lawrence T. Greenberg, Seymour E. Goodman, and Kevin J. Soo 
Hoo, Information Warfare and International Law
, National Defense University Press, 1998; 
Michael Schmitt, ﬁComputer Network Attack and the Use of Force in International Law: 
Thoughts on a Normative Framework,ﬂ 
Columbia Journal of Transnational Law
 37:885-937, 
1999;
 Christopher C. Joyner and Catherine Lotrionte, ﬁInformation Warfare as International 
Coercion: Elements of a Legal Framework,ﬂ 
European Journal of International Law
 12(5):825-865, 
2001; Jason Barkham, ﬁInformation Warfare and International Law on the Use of Force,ﬂ 
New 
York Uni
versity International Law and Politics
 34:57-113, 2001; Davis Brown, ﬁA Proposal for an 
International Convention to Regulate the Use of Information Systems in Armed Con˚ict,ﬂ 
Har
vard International Law Journal
 47(1):179-221, Winter 2006; Duncan B. Hollis, ﬁNew Tools, 
New Rules: International Law and Information Operations,ﬂ pp. 59-72 in 
Ideas as Weapons: 
In˜uence and Perception in Modern Warfare,
 G. David and T. McKeldin, eds., Potomac Books 
Inc., 2009.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PREFACE
 ix
the ˜rst studies to address the strategic implications of cyberattack was 
published by the RAND Corporation in 1996 (
Strategic Information Warfare: 
A New Face of War
).
6 A later study covering the same topic in much more 
detail was published as 
Strategic Warfare in Cyberspace
.7 A ˚urry of writing 
began to appear in the professional military literature in the late 1990s and 
early 2000s, but little or nothing can be found in this body of literature 

since around 2002 or 2003. 
THIS STUDYŠFOCUS, APPROACH, AND PURPOSE
Most of the writing to date has not brought together information tech
-nology experts who are knowledgeable in detail about what can and can
-not be done from a technical standpoint with senior individuals who have 
policy experience, nor has it addressed the topic in an
 interdisciplinary 
manner that integrates expertise from the disciplines and ˜elds that are 

relevant to the subject. The National Research Council undertook the 

present study (Box P.1) believing in the value of an integrated treatment 

that would help shed much-needed light on various important dimen
-sions of cyberattack (and secondarily on the topic of cyberexploitation, a 

term that refers to the penetration of adversary computers and networks 

to obtain information for intelligence purposes). Such a treatment would 

provide a point of departure for others so that a broad variety of indepen
-dent intellectual perspectives can be brought to bear on it.
The Committee on Offensive Information Warfare ˜rst met in July 
2006 and ˜ve times subsequently. Its earlier meetings were devoted pri
-marily to brie˜ngs on a variety of topics related to cyberattack, and later 

meetings were devoted primarily to committee deliberations.
The authoring committee did not receive classi˜ed information in the 
course of this study. What is sensitive about cyberattack is generally the 

fact of U.S. interest in a speci˜c technology for cyberattack (rather than the 

nature of that technology itself); fragile and sensitive operational details 

that are not speci˜c to the technologies themselves (e.g., the existence of a 

covert operative in a speci˜c foreign country or a particular vulnerability); 

or capabilities and intentions of speci˜c adversaries. None of these spe
-ci˜c areas are particularly relevant to a study that focuses on the articula
-tion of an intellectual framework for thinking about cyberattack. 
It is important to delineate the scope of what this report does and 
6 Roger C. Molander, Andrew S. Riddile, and Peter A. Wilson, 
Strategic Information 
Warfare: A New Face of War,
 National Defense Research Institute, RAND, Washington, D.C., 
1996, available at http://www.rand.org/pubs/monograph_reports/2005/MR661.pdf.
7 Gregory J. Rattray, 
Strategic Warfare in Cyberspace
, MIT Press, Cambridge, Mass., 
2001.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.x PREFACE
does not do. This report does not provide a detailed explication of U.S. 
policy and practice regarding cyberattack or cyberexploitation, nor does 
it describe cyberattack/cyberexploitation capabilities available to the U.S. 

government. Instead, it provides a framework for understanding cyberat
-tack that describes the basic technologies of cyberattack and cyberexploi
-tation, articulates basic principles of what cyberattack and cyberexploita
-tion might do, and discusses some of the policy goals that these actions 

might serve. It addresses some of the legal and ethical considerations that 

such uses might entail, and it suggests some analytical tools that might 

be useful for thinking about cyberattack from a policy perspective. It 

includes a number of ˜ndings and recommendations.
Just as other areas of national security have bene˜ted from a vigorous 
public airing of issues, the authoring committee hopes that this report 

will stimulate debate and discussion on cyberattack as an instrument of 

national policy at the nexus of technology, policy, law, ethics, and national 

security both inside and outside government and thus bring to bear on 

these knotty issues the best intellectual thought and consideration. 
A historical analogy might be drawn to the study of nuclear issues. 
In many ways, today™s state of affairs regarding public discourse on 
BOX P.1 Statement of Task
The National Research Council will appoint an ad hoc committee to examine 
policy dimensions and legal/ethical implications of offensive information warfare, 
informed by expert perspectives on and knowledge of the underlying technologies. 

These policy dimensions include but are not limited to factors that differentiate 

between cyberattack as a law enforcement matter versus cyberattack as a national 

security matter, the extent to which the U.S. Department of Defense is constrained 

from acting in response to cyberattack of uncertain origin, appropriate de˜nitions 

of concepts such as ﬁforceﬂ or ﬁarmed attackﬂ as they apply to different forms of 

offensive information warfare, the standards of proof required to establish the ori
-gin of a cyberattack, the nature and extent of actions that the United States may 

take unilaterally against a foreign cyberattacker, the possible utility of offensive 

information warfare as a mode of attack that is different from kinetic or physical 

attack, the nature and extent to which offensive information warfare may be a part 

of conventional military operations, and the extent to which a nation undertaking 

offensive information warfare may increase the likelihood that it would be attacked 

in response, either similarly or dissimilarly. Project products will be directed at 

policy makers and researchers, the former so that decision making can occur in 

a more informed manner and the latter so that other independent researchers will 

have a ˜rm base on which to ground their own work.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PREFACE
 xi
cyberattack is analogous to the nuclear debate of 50 years ago. At that 
time, nuclear policy issues were veiled in secrecy, and there was little 
public debate about them. Herman Kahn™s books (
On Thermonuclear War
, Thinking the Unthinkable
) were the ˜rst that addressed in the open litera
-ture what it might mean to ˜ght a nuclear war. These seminal pieces did 

much to raise the public pro˜le of these issues and stimulated an enor
-mous amount of subsequent work outside government that has had a real 

impact on nuclear policy.
From our perspective as the co-chairs of this study, the topic of cyber
-attack is so important across a multitude of national interestsŠnot just 

defense or even just national securityŠthat it deserves robust and open 

discussion and debate, both among thoughtful professionals in the policy, 

military, intelligence, law enforcement, and legal ˜elds and among secu
-rity practitioners in the private sector. But for such discussion and debate 

to be productive, they must be based on some common foundation of 

information about the topic at hand. Thus, the report™s role in providing 

education and background is in our view its most important function. 
It is because of the potential relevance of cyberattack across a broad 
spectrum of national interests that it was necessary to constitute a study 

committee whose members had very diverse backgrounds and many 

different perspectives on various aspects of cyberattack. The committee 

assembled for this project included individuals with expertise in network
-ing, computer security, large-scale computer systems and architecture, 

national security and defense policy, intelligence and military operations, 

international law governing war and con˚ict, human rights, international 

relations and diplomacy, constitutional law and civil liberties, and domes
-tic law enforcement as it relates to cybersecurity. Nonetheless, no one 

person had all of the necessary expertise across all relevant areas, and the 

committee expended considerable effort to bring all of its members to a 

common (if basic) level of understanding in these areas. The committee 

was by design highly heterogeneous and interdisciplinary, a characteristic 

intended to promote discussion and synergy among its members. As for 

the two co-chairs, one of us (Owens) has extensive military experience 

and the other (Dam) has extensive experience in foreign affairsŠand both 

of us have served in the private sector.
We hope that a second function of this report is to help establish the 
awareness needed in the elected government (executive and legislative) 

for making good decisions and providing proper oversight of capabili
-ties for cyberattack. As the report points out, the U.S. government does 

not appear to be well organized to manage these capabilities, either in an 

employment sense (when and under what circumstances a particular kind 

of cyberattack should be used) or in an acquisition sense (how to obtain 

capabilities for cyberattack). Many of the report™s ˜ndings and recom
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.xii
 PREFACE
mendations focus on taking some ˜rst steps for better organization of the 
government in this regard.
How will the presentation and analysis in this report endure over time? 
The question is natural given the inevitability of changes in the techno
-logical and global environment. Based on historical experience, it is highly 
likely that in a decade the technological substrate underlying information 

technology applications will be very different by one, two, or three orders of 

magnitude in a number of dimensionsŠprocessor power, cost, bandwidth, 

storage, and so on. Deployments of information technology will be more 

pervasive. Connectivity among individuals, embedded computers, and 

organizations is likely to increase dramatically, and myriad applications 

that are entirely unimagined now will be commonplace. The importance of 

the Internet (or its follow-on) to society will be greater as well. 
The global environment is also likely to be substantially different, 
although 
how
 it will be different cannot be predicted in the same way 
that Moore™s law predicts circuit densities. Many analysts of international 

affairs predict a rise in the signi˜cance of actors not tied or only loosely 

tied to nation-states, or of adversaries that do not share U.S. or Western 

values or legal traditions with respect to the conduct of con˚ict.
Few portions of the report are tied explicitly to current technolo
-gies, although a genuine breakthrough in technologies to support non-
cooperative high-precision attribution of attacks to bad actors in cyber
-space would have signi˜cant implications for several ˜ndings in this 

report. A rise in the non-state actor cyberthreat would be signi˜cant as 

wellŠand although the committee has attempted to grapple with that 

issue in its analysis, it would be the ˜rst to admit that a great deal more 

work is needed in that area. Thus, it is the committee™s hope that the 

framework established in this report for understanding cyberattack will 

endure for some time to come.
As this report goes into ˜nal publication in July 2009, a number of 
signi˜cant events have occurred.  For example, on May 29, 2009, the 

Obama White House released its 60-day review of cybersecurity policy 

(Cyberspace Policy Re
view: Assuring a Trusted and Resilient Information and 
Communications Infrastructure
8), a document that is essentially silent on the 
offensive dimension of cybersecurity.  On June 23, Secretary of Defense 

Robert Gates directed the establishment of the U.S. Cyber Command, 

a sub-uni˜ed command subordinate to U.S. Strategic Command and 

responsible for military cyberspace operations.
98 See http://www.whitehouse.gov/assets/documents/Cyberspace_Policy_Review_˜nal.
pdf.
9 Siobhan Gorman and Yochi Dreazen, ﬁMilitary Command Is Created for Cyber 
 Security,ﬂ 
Wall Street Journal,
 June 24, 2009, available at http://online.wsj.com/article/
SB124579956278644449.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PREFACE
 xiii
ACKNOWLEDGMENTS
This study could not have been undertaken without the ˜nancial sup
-port of the MacArthur Foundation and the Microsoft Corporation, both 
of which recognized the potential legal, policy, and ethical signi˜cance of 

new technologies for cyberattack. The National Research Council itself 
also provided some funding for this project. 
The complexity of the issues explored in this report meant that the 
committee had much to learn from its briefers. The committee is grateful 
to many individuals:
Ł For brie˜ngs on cyberattack technologies, Steven Bellovin of 
Columbia University and William Howard, independent consultant;
Ł For brie˜ngs on operational dimensions of cyberattack, Patrick 
D. Allen of General Dynamics Advanced Information Systems, Lt. Gen.

Bill Donahue, U.S. Air Force (retired), and Sam Gardiner, U.S. Air Force 

(retired); 
Ł For brie˜ngs on the various legal dimensions of cyberattack and 
cyberexploitation, Thomas Wing˜eld of the Potomac Institute, LTC Eric 

Jensen of the Of˜ce of the Judge Advocate General, U.S. Army, Joe Dhillon 

of the McGeorge School of Law at the University of the Paci˜c, Jeff Smith 

(former CIA General Counsel), Jim Dempsey of the Center for Democracy 

and Technology, Richard Salgado of Yahoo!, Eugene Volokh of the UCLA 

School of Law, and Robert Weisberg and Helen Stacy of the Stanford Uni
-versity Law School;
Ł For brie˜ngs on the ethics of cyberattack, Jeff McMahan of Rutgers 
University and Father J. Bryan Hehir of Harvard University;
Ł For brie˜ngs on current DOD perspectives on cyberattack, Admiral 
Elizabeth Hight of the JTFGNO, LTC Forrest Hare of the U.S. Air Force, 

and Dr. Linton Wells of the Department of Defense;
Ł For brie˜ngs on policy issues regarding non-lethal weapons, David 
Koplow of Georgetown University;
Ł For brie˜ngs on private sector perspectives, Rod Wallace of Nortel, 
Milo Medin of M2Z Networks, Jeffrey I. Schiller of MIT, and Naveen Jain 

of Intelius; 
Ł For a brie˜ng on deterrence theory as it might be applied to cyber
-attack, Thomas Schelling of the University of Maryland; and
Ł For a variety of independent perspectives on the subject of cyber
-attack, Stephen Cambone (former Undersecretary of Defense for Intelli
-gence), James N. Miller, Jr. (former Deputy Assistant Secretary of Defense 

for Requirements, Plans, and Counterproliferation), Dan Kuehl of the 

National Defense University, Stuart Starr of the Center for Technology 

and National Security Policy at the National Defense University, K.A. 
Taipale of the Center for Advanced Studies in Science and Technology 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.xi
v PREFACE
Policy, Neal Pollard of Georgetown University and the National Coun
-terterrorism Center, and Dorothy E. Denning of the Naval Postgraduate 
School.
Throughout the study, the committee™s complex and challenging tech
-nical and political discussions encompassed a wide range of thought and 

perspectives offered by those who appeared before the committee, the 

committee itself, and participants in the review process. In addition, from 

the CSTB staff, we thank Ted Schmitt, Kristen Batch, and David Padgham 

for substantial research assistance, and Janice Sabuda and Eric Whitaker 

for administrative support. Lastly, this report would not have been pos
-sible without the leadership and stamina of Herb Lin, whose organiza
-tional skills, leadership of the staff, and thoughtful, complete agendas for 

committee discussion exceeded the excellent standards established by the 

National Academies. Both of us are indebted to Herb for his counsel, his 

policy and technical knowledge, his ability to ˜nd ﬁjust the right word
-ingﬂ for contentious areas, and for the character and chemistry he has 

shown us in our personal dealings. The National Research Council is for
-tunate to have leaders of Herb Lin™s quality. This study and we co-chairs 

have bene˜ted greatly from his deep involvement. 
Kenneth W. Dam and William A. Owens, 
Co-chairs
Committee on Offensive Information Warfare
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.xvAcknowledgment of Reviewers
This report has been reviewed in draft form by individuals chosen 
for their diverse perspectives and technical expertise, in accordance with 
procedures approved by the National Research Council™s Report Review 

Committee. The purpose of this independent review is to provide candid 

and critical comments that will assist the institution in making its pub
-lished report as sound as possible and to ensure that the report meets 

institutional standards for objectivity, evidence, and responsiveness to 

the study charge. The review comments and draft manuscript remain 

con˜dential to protect the integrity of the deliberative process. We wish 

to thank the following individuals for their review of this report:
Matt Blaze, University of Pennsylvania,

W. Earl Boebert, Sandia National Laboratories (retired),

Lewis M. Branscomb, Independent Consultant, La Jolla, California,

Jogindar (Joe) Dhillon, State of California,

Stephen Dycus, Vermont Law School,

Michael Froomkin, University of Miami School of Law,

Dan Geer, Geer Risk Services,

Ronald Lee, Arnold and Porter,

Martin Libicki, RAND Corporation,

James McCarthy, USAF Academy,

John McLaughlin, Johns Hopkins University,

Richard Mies, SAIC,

Gregory Rattray, Independent Consultant, San Antonio, Texas,
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.xvi ACKNOWLEDGMENT OF REVIEWERS
Abe Sofaer, Stanford University, 
Eugene Spafford, Purdue University,

Phil Venables, Goldman Sachs & Co.,

Peter Weinberger, Google, Inc., and

Marc J. Zwillinger, Sonnenschein Nath & Rosenthal.
Although the reviewers listed above have provided many construc
-tive comments and suggestions, they were not asked to endorse the con
-clusions or recommendations, nor did they see the ˜nal draft of the report 
before its release. The review of this report was overseen by William H. 

Press, University of Texas at Austin, and Eugene Volokh, University of 

California at Los Angeles. Appointed by the National Research Council, 

they were responsible for making certain that an independent examina
-tion of this report was carried out in accordance with institutional proce
-dures and that all review comments were carefully considered. Responsi
-bility for the ˜nal content of this report rests entirely with the authoring 

committee and the institution.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.xvii
Contents
SYNOPSIS
   
11 OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 9 1.1
 What Is Cyberattack and Why Is It Important?, 9
 1.2
 Focus of and Motivation for This Report, 12
 1.3
  
Cyberattack in the Context of an Information Strategy for the 
United States, 17
 1.4
  
Important Characteristics of Cyberattack and 
Cyberexploitation, 19
 1.5
 Illustrative Applications of Cyberattack, 21
 1.6
 The Legal Framework Governing Cyberattack, 21
 1.7
 The Dynamics of Cybercon˚ict, 22
 1.8
 Findings, 24
   
1.8.1
 Technologies as Instruments of U.S. National Policy, 24
   
1.8.2
 Overarching Findings, 25
   
1.8.3
 Legal and Ethical Findings, 31
   
1.8.4
 Policy Findings, 39
   
1.8.5
 Technical and Operational Findings, 43
   
1.8.6
 Organizational Findings, 53
 1.9
 Recommendations, 56
   
1.9.1
 Fostering a National Debate on Cyberattack, 57
   
1.9.2
  
Organizing the Decision-Making Apparatus of 
 the U.S. Government for Cyberattack, 62
   
1.9.3
 Supporting Cyberattack Capabilities and Policy, 66
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.xviii
 CONTENTS
   
1.9.4
  
Developing New Knowledge and Insight into a New 
Domain of Con˚ict, 73
 1.10
 Conclusion, 75
PART I
 FRAMING
 AND
 B
ASIC
 T
ECHNOLOGY
2  
TECHNICAL AND OPERATIONAL CONSIDERATIONS IN 
CYBERATTACK AND CYBEREXPLOITATION
 79
 2.1
  
Important Characteristics of Cyberattack and 
Cyberexploitation, 80
 2.2
 The Basic Technology of Cyberattack, 82
   
2.2.1
 Information Technology and Infrastructure, 82
   
2.2.2
 Vulnerability, Access, and Payload, 83
   
2.2.3
 Scale and Precision, 89
   
2.2.4
 Critical Periods of Cyberattack, 89
   
2.2.5
 Approaches for Cyberattack, 91
   
2.2.6
 Propagating a Large-Scale Cyber Offensive Action, 106
   
2.2.7
 Economics, 108
 2.3
 Operational Considerations, 110
   
2.3.1
 The Effects of Cyberattack, 110
   
2.3.2
 Possible Objectives of Cyberattack, 114
   
2.3.3
 Target Identi˜cation, 116
   
2.3.4
 Intelligence Requirements and Preparation, 118
   
2.3.5
 Effects Prediction and Damage Assessment, 121
   
2.3.6
  
Complexity, Information Requirements, and 
Uncertainty, 126
   
2.3.7
 Rules of Engagement, 128
   
2.3.8
 Command and Control, 129
   
2.3.9
  
Coordination of Cyberattack Activities with Other 
Institutional Entities, 132
   
2.3.10
  
A Rapidly Changing and Changeable Technology and 
Operational Environment for Cyberattack, 133
 2.4
 Characterizing an Incoming Cyberattack, 134
   
2.4.1
 Tactical Warning and Attack Assessment, 135
   
2.4.2
 Attribution, 138
   
2.4.3
 Intent, 141
 2.5
  
Active Defense for Neutralization as a Partially Worked 
Example, 142
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.CONTENTS
 xix
  2.6
  
Technical and Operational Considerations for 
Cyberexploitation, 149
   
2.6.1
  
Technical Similarities in and Differences Between 
Cyberattack and Cyberexploitation, 149
   
2.6.2
 Possible Objectives of Cyberexploitation, 150
   
2.6.3
 Approaches for Cyberexploitation, 152
   
2.6.4
  
Some Operational Considerations for 
 Cyberexploitation, 153 
 2.7
 Historical Precedents and Lessons, 156
PART II
 MISSION
 AND
 I
NSTITUTIONAL
 P
ERSPECTIVES
3 A MILITARY PERSPECTIVE ON CYBERATTACK
 161
 3.1
 U.S. Military Doctrine and Cyberattack, 161
 3.2
 Department of Defense Organization for Cyberattack, 165
 3.3
 Rules of Engagement, 167
 3.4
 Some Historical Perspective, 171
 3.5
  
Cyberattack in Support of Military OperationsŠSome 
Hypothetical Examples, 177
   
3.5.1
  
Cyberattack in Support of Defense, Exploitation, and 
Other Information Operations, 177
   
3.5.2
  
Cyberattack in Support of Traditional Military 
Operations, 179
   
3.5.3
 Cyberattack in Support of Other Operations, 180
 3.6
 Operational Planning, 182
 3.7
 Human Capital and Resources, 184
 3.8
 Weapons Systems Acquisition, 186
4  
AN INTELLIGENCE COMMUNITY PERSPECTIVE ON 
CYBERATTACK AND CYBEREXPLOITATION
 188
 4.1
 Intelligence Collection and Analysis, 188
   
4.1.1
 Governing Principles, 188
   
4.1.2
  
How Cyberexploitation Might Be Used to Support 
Intelligence Collection, 190
 4.2
 Covert Action, 193
   
4.2.1
 Governing Principles, 193
   
4.2.2
 How Cyberattack Might Be Used in Covert Action, 195
 4.3
  
Possible Intelligence Community Interest in Cyberattack and 
Cyberexploitation, 198
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.xx
 CONTENTS
5  
PERSPECTIVES
 ON
 C
YBERATTACK
 O
UTSIDE
 N
ATIONAL
 SECURITY
  
200
 5.1
 Cyberattack and Domestic Law Enforcement, 200
 5.2
 Threat Neutralization in the Private Sector, 202
   
5.2.1
  
Possible Response Options for Private Parties Targeted 
by Cyberattack, 202
   
5.2.2
 Self-defense by Private Parties, 204
   
5.2.3
 Regulating Self-defense by Private Parties, 208
   
5.2.4
  
Negative Rami˜cations of Self-defense by Private 
Parties, 210
 5.3
 Cyberexploitation in the Private Sector, 212
 5.4
  
Threat Neutralization on Behalf of Non-military Government 
Agencies, 213
6 DECISION
 M
AKING
 AND
 O
VERSIGHT
 214
 6.1
 Executive Branch, 214
   
6.1.1
 Declaratory Policy, 215
   
6.1.2
 Acquisition Policy, 220
   
6.1.3
 Employment Policy, 223
   
6.1.4
 Operational Oversight, 229
 6.2
 Legislative Branch, 232
   
6.2.1
 Warmaking Powers, 232
   
6.2.2
 Budget, 234
   
6.2.3
 Oversight (and Noti˜cation), 235
PART III
 INTELLECTUAL
 T
OOLS
 FOR
 U
NDERSTANDING
 AND
 THINKING
 A
BOUT
 C
YBERATTACK
7 LEGAL
 AND
 E
THICAL
 P
ERSPECTIVES
 ON
 C
YBERATTACK
 239
 7.1
 The Basic Framework, 239
 7.2
 International Law, 241
   
7.2.1
 The Law of Armed Con˚ict, 241
   
7.2.2
  
Applying the Law of Armed Con˚ict to 
 Cyberattack, 250
   
7.2.3
 International Law and Non-state Actors, 273
   
7.2.4
 The Convention on Cybercrime, 277
   
7.2.5
 Human Rights Law, 281
   
7.2.6
 Reciprocity, 282
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.CONTENTS
 xxi
 7.3
 Domestic Law, 282
   
7.3.1
 Covert Action and Military Activity, 283
   
7.3.2
  
Title III and the Foreign Intelligence Surveillance 
 Act, 286
   
7.3.3
 Posse Comitatus, 288
   
7.3.4
  
The Computer Fraud and Abuse Act and Other Federal 
Law, 288
   
7.3.5
 The War Powers Resolution, 290
   
7.3.6
  
Executive Order 12333 (United States Intelligence 
Activities), 290
 7.4
 Foreign Domestic Law, 292
8 INSIGHTS
 FROM
 R
ELATED
 A
REAS
  293
 8.1
 Nuclear Weapons and Nuclear War, 293
 8.2
 Space, 296
 8.3
 Biological Weapons, 297
 8.4
 Non-lethal Weapons, 299
9 SPECULATIONS
 ON
 THE
 D
YNAMICS
 OF
 C
YBERCONFLICT
 302
 9.1
 Deterrence and Cybercon˚ict, 302
 9.2
  
Escalatory Dynamics of Cybercon˚ict Between 
 Nation-States, 306
   
9.2.1
 Crisis Stability, 306
   
9.2.2
 Escalation Control and Management, 308
   
9.2.3
 Complications Introduced by Patriotic Hackers, 310
   
9.2.4
 Incentives for Self-restraint in Escalation, 311
   
9.2.5
 Termination of Cybercon˚ict, 311
   
9.2.6
 The Role of Transparency, 312
   
9.2.7
 Catalytic Cybercon˚ict, 312
 9.3
  
Cybercon˚ict Between the United States and Non-state 
 Actors, 313
 9.4
 The Political Side of Escalation, 315
10
 ALTERNATIVE
 F
UTURES
 318
 10.1
 Regulatory RegimesŠBasic Principles, 318
 10.2
 Regulatory Regimes for Cyberattack, 321
   
10.2.1
  
Direct Approaches Based on Traditional Arms 
 Control, 321
   
10.2.2
  
Indirect Approaches Based on Regulation of 
Non-military Domains, 326
 10.3
 Foreign Perspectives on Cyberattack, 328
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.xxii
 CONTENTS
APPENDIXES
A  
Biographies of Committee Members and Staff
 337
B  
Meeting Participants and Other Contributors
 348
C  
Illustrative Criminal Cyberattacks
 350
D  
Views on the Use of Force in Cyberspace
 356
E   
Technical Vulnerabilities Targeted by Cyber Offensive 
 Actions
  
360
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Synopsis
This synopsis is intended to provide the reader with a sense of what 
the report contains. However, it is necessarily incomplete, and it omits 
any mention of many signi˜cant topics contained in the main body of 

the report.
UNDERSTANDING CYBERATTACK
What Is Cyberattack?
Cyberattack refers to deliberate actions to alter, disrupt, deceive, 
degrade, or destroy computer systems or networks or the information 

and/or programs resident in or transiting these systems or networks. The 

U.S. armed forces are actively preparing to engage in cyberattacks, per
-haps in concert with other information warfare means and/or with kinetic 

attacks, and may have done so in the past. Domestic law enforcement 

agencies also engage in cyberattack when they jam cell phone networks 

in order to prevent the detonation of improvised explosive devices.
Such matters pose some very important issues that relate to technol
-ogy, policy, law, and ethics. This report provides an intellectual framework 

for thinking about cyberattack and understanding these issues.
A ˜rst point is that cyberattack must be clearly distinguished from 
cyberexploitation, which is an intelligence-gathering activity rather than 

a destructive activity. Although much of the technology underlying 
cyberexploitation is similar to that of cyberattack, cyberattack and cyber
-1Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.2 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
exploitation are conducted for entirely different purposes. (This contrast 
is relevant to much of the public debate using the term ﬁcyberattack,ﬂ 
which in common usage often lumps both attack and exploitation under 

the ﬁattackﬂ label.)
Second, weapons for cyberattack have a number of characteristics that 
differentiate them from traditional kinetic weapons. Compared to kinetic 

weapons, many weapons for cyberattack: 

Are easy to use with high degrees of anonymity and with plausible 
deniability, making them well suited for covert operations and for insti
-gating con˚ict between other parties; 

Are more uncertain in the outcomes they produce, making it dif
-˜cult to estimate deliberate and collateral damage; and

Involve a much larger range of options and possible outcomes, and 
may operate on time scales ranging from tenths of a second to years, and 

at spatial scales anywhere from ﬁconcentrated in a facility next doorﬂ to 

globally dispersed.
Third, cyberattack as a mode of con˚ict raises many operational 
issues. For example, given that any large nation experiences cyberattacks 

continuously, how will the United States know it is the subject of a cyber
-attack deliberately launched by an adversary government? There is also a 

further tension between a policy need for rapid response and the techni
-cal reality that attribution is a time-consuming task. Shortening the time 

for investigation may well increase the likelihood of errors being made 

in a response (e.g., responding against the wrong machine or launching a 

response that has large unintended effects).
Illustrative Applications of Cyberattack
Cyberattack can support military operations. For example, a cyberat
-tack could disrupt adversary command, control, and communications; 

suppress air defenses; degrade smart munitions and platforms; or attack 

war˜ghting or warmaking infrastructure (the defense industrial base). 

Cyberattack might be used to augment or to enable some other kinetic 

attack to succeed, or to defend a friendly computer system or network by 

neutralizing the source of a cyberattack conducted against it.
Cyberattack can also support covert action, which is designed to 
in˚uence governments, events, organizations, or persons in support of 

foreign policy in a manner that is not necessarily attributable to the U.S. 

government. The range of possible cyberattack options is very large, 

and so cyberattack-based covert action might be used, for example, to 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SYNOPSIS
 3in˚uence an election, instigate con˚ict between political factions, harass 
disfavored leaders or entities, or divert money.
Illustrative Applications of Cyberexploitation
For intelligence gathering, cyberexploitation of an adversary™s com
-puter systems might yield valuable information. For example, U.S. intel
-ligence agencies might learn useful information about an adversary™s 
intentions and capabilities from a penetration of its classi˜ed government 

networks. Alternatively, they might obtain useful economic information 

from penetrating the computer systems of a competing nation™s major 

industrial ˜rms.
The Legal Framework Governing Cyberattack
In the committee™s view, the essential framework for the legal analy
-sis of cyberattack is based on the principle that notions related to ﬁuse 

of forceﬂ and ﬁarmed attackﬂ (terms of special relevance to the Charter 

of the United Nations) should be judged primarily by the effects of an 

action rather than its modality. That is, the fact that an attack is carried 

out through the use of cyberweapons rather than kinetic weapons is far 

less signi˜cant than the effects that result from such use, where ﬁeffectsﬂ 

are understood to include both direct and indirect effects.
Furthermore, the committee believes that the principles of the law of 
armed con˚ict (LOAC) and the Charter of the United NationsŠincluding 

both law governing the legality of going to war (
jus ad bellum
) and law 
governing behavior during war (
jus in bello
)Šdo apply to cyberattack, 
although new analytical work may be needed to understand how these 

principles do or should apply to cyberweapons. That is, some types of 

cyberattack are dif˜cult to analyze within the traditional LOAC structure. 

Among the more problematic cases are the following:

The presumption of nation-to-nation con˚ict between national 
military forces, 

The exception for espionage, and

The emphasis on notions of territorial integrity. 
The Dynamics of Cybercon˜ict
The escalatory dynamics of armed con˚ict are thought to be under
-stood as the result of many years of thinking about the subject, but the 

dynamics of cybercon˚ict are poorly understood. This report speculates on 

some of the factors that might in˚uence the evolution of a cybercon˚ict. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
For major nation-states with signi˜cant capabilities for kinetic attack 
and cyberattack at their disposal, among the important issues regarding 
the dynamics of cybercon˚ict are the following:

Crisis stability (preventing a serious cybercon˚ict from breaking 
out),

Preventing a cybercon˚ict from escalating to physical space, and

Knowing when a cybercon˚ict has been terminated.
Matters can be further complicated by the presence of non-state 
actors, such as cyberterrorists, patriotic hackers, and criminal groups. 

Perhaps the most important complication relates to identi˜cation of the 

appropriate party against which action might be taken and the related 

availability of cyber and/or kinetic targets whose destruction might cause 

pain or meaningful damage to the terrorist or criminal group. 
FINDINGS
Cyberattack is an important capability for the United States to main
-tain, but at the same time the acquisition and use of such capabilities raise 

many questions and issues, as described below.
Overarching Findings
 1.
 The policy and organizational issues raised by U.S. acquisition 
and use of cyberattack are signi˜cant across a broad range of con˚ict 

scenarios, from small skirmishes with minor actors on the international 

stage to all-out con˚icts with adversaries capable of employing weapons 

of mass destruction.
 2.
 The availability of cyberattack technologies for national purposes 
greatly expands the range of options available to U.S. policy makers as 

well as to policy makers of other nations.
 3.
 Today™s policy and legal framework for guiding and regulat
-ing the U.S. use of cyberattack is ill-formed, undeveloped, and highly 

uncertain.
 4.
 Secrecy has impeded widespread understanding and debate 
about the nature and implications of U.S. cyberattack.
 5.
 The consequences of a cyberattack may be both direct and indi
-rect, and in some cases of interest, the indirect consequences of a cyberat
-tack can far outweigh the direct consequences.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SYNOPSIS
 5Legal and Ethical Findings
 6.
 The conceptual framework that underpins the UN Charter on the 
use of force and armed attack and today™s law of armed con˚ict provides 
a reasonable starting point for an international legal regime to govern 

cyberattack. However, those legal constructs fail to account for non-state 

actors and for the technical characteristics of some cyberattacks.
 7.
 In today™s security environment, private parties have few useful 
alternatives for responding to a severe cyberattack that arrives over a 

network such as the Internet.
 8.
 Cyberattack poses challenges to existing ethical and human rights 
regimes.
Policy Findings
 9.
 Enduring unilateral dominance in cyberspace is neither realistic 
nor achievable by the United States.
10.
 The United States has much to lose from unrestrained cyberattack 
capabilities that are proliferated worldwide.
11.
 Deterrence of cyberattacks by the threat of in-kind response has 
limited applicability.
12.
 Options for responding to cyberattacks on the United States 
span a broad range and include a mix of dynamic changes in defensive 

postures, law enforcement actions, diplomacy, cyberattacks, and kinetic 

attacks.
Technical and Operational Findings
13.
 For many kinds of information technology infrastructure targets, 
the ease of cyberattack is increasing rather than decreasing.
14.
 Although the actual cyberattack capabilities of the United States 
are highly classi˜ed, they are at least as powerful as those demonstrated 

by the most sophisticated cyberattacks perpetrated by cybercriminals and 

are likely more powerful.
15.
 As is true for air, sea, land, and space operations, the defensive or 
offensive intent motivating cyber operations in any given instance may be 

dif˜cult to infer.
16.
 Certain cyberattacks undertaken by the United States are likely to 
have signi˜cant operational implications for the U.S. private sector. 
17.
 If and when the United States decides to launch a cyberattack, 
signi˜cant coordination among allied nations and a wide range of public 

and private entities may be necessary, depending on the scope and nature 

of the cyberattack in question.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.6 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
18.
 The outcomes of many kinds of cyberattack are likely to be more 
uncertain than outcomes for other kinds of attack.
19.
 Early use of cyberattack may be easy to contemplate in a pre-con
-˚ict situation, and so a greater degree of operational oversight for cyberat
-tack may be needed compared to that for the use of other options.
 20.
 Developing appropriate rules of engagement for the use of cyber
-weapons is very dif˜cult.
Organizational Findings
21.
 Both the decision-making apparatus for cyberattack and the over
-sight mechanisms for that apparatus are inadequate today.
22.
 The U.S. Congress has a substantial role to play in authorizing the 
use of military force, but the contours of that authority and the circum
-stances under which authorization is necessary are at least as uncertain 
for cyberattack as for the use of other weapons.
RECOMMENDATIONS
Fostering a National Debate on Cyberattack
 1.
 The United States should establish a public national policy regard
-ing cyberattack for all sectors of government, including but not necessar
-ily limited to the Departments of Defense, State, Homeland Security, 

Treasury, and Commerce; the intelligence community; and law enforce
-ment. The senior leadership of these organizations should be involved in 

formulating this national policy.
 2.
 The U.S. government should conduct a broad, unclassi˜ed 
national debate and discussion about cyberattack policy, ensuring that 

all partiesŠparticularly Congress, the professional military, and the intel
-ligence agenciesŠare involved in discussions and are familiar with the 

issues.
 3.
 The U.S. government should work to ˜nd common ground 
with other nations regarding cyberattack. Such common ground should 

include better mutual understanding regarding various national views of 

cyberattack, as well as measures to promote transparency and con˜dence 

building.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SYNOPSIS
 7Organizing the Decision-Making Apparatus of the 
 U.S. Government for Cyberattack
 4.
 The U.S. government should have a clear, transparent, and inclu
-sive decision-making structure in place to decide how, when, and why a 
cyberattack will be conducted.
 5.
 The U.S. government should provide a periodic accounting of 
cyberattacks undertaken by the U.S. armed forces, federal law enforce
-ment agencies, intelligence agencies, and any other agencies with authori
-ties to conduct such attacks in suf˜cient detail to provide decision makers 

with a more comprehensive understanding of these activities. Such a peri
-odic accounting should be made available both to senior decision makers 

in the executive branch and to the appropriate congressional leaders and 

committees.
 Supporting Cyberattack Capabilities and Policy
 6.
 U.S. policy makers should judge the policy, legal, and ethical sig
-ni˜cance of launching a cyberattack largely on the basis of both its likely 

direct effects and its indirect effects.  
 7.
 U.S. policy makers should apply the moral and ethical principles 
underlying the law of armed con˚ict to cyberattack even in situations that 

fall short of actual armed con˚ict.
 8.
 The United States should maintain and acquire effective cyberat
-tack capabilities. Advances in capabilities should be continually factored 

into policy development, and a comprehensive budget accounting for 

research, development, testing, and evaluation relevant to cyberattack 

should be available to appropriate decision makers in the executive and 

legislative branches.
 9.
 The U.S. government should ensure that there are suf˜cient levels 
of personnel trained in all dimensions of cyberattack, and that the senior 

leaders of government have more than a nodding acquaintance with such 

issues.
10.
 The U.S. government should consider the establishment of a 
 government-based institutional structure through which selected pri
-vate sector entities can seek immediate relief if they are the victims of 
cyberattack. 
Developing New Knowledge and Insight into a 
 New Domain of Con˜ict
11.
 The U.S. government should conduct high-level wargaming 
exercises to understand the dynamics and potential consequences of 

cybercon˚ict.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.8 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
12.
  Foundations and government research funders should support 
academic and think-tank inquiry into cybercon˚ict, just as they have sup
-ported similar work on issues related to nuclear, biological, and chemical 
weapons.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.1Overview, Findings, and 
Recommendations
1.1
 WHAT
 I
S C
YBERATTACK
 AND
 W
HY
 I
S I
T I
MPORTANT
?It is now broadly accepted that nations are becoming ever more 
dependent on information and information technology. Companies and 
organizations rely on computers for diverse business processes ranging 

from payroll and accounting, to the tracking of inventory and sales, to 

support for research and development (R&D). Food, water, and energy 

distribution rely on computers and networks at every stage, as do trans
-portation, health care, and ˜nancial services.
The same dependence also increasingly applies to the military. Mod
-ern military forces use weapons that are computer-controlled. Even more 

importantly, the movements and actions of military forces are increasingly 

coordinated through computer-based networks that allow information 

and common pictures of the battle˜eld to be shared. Logistics are entirely 

dependent on computer-based scheduling and optimization. 
Even terrorists rely on information technology. Although the weapons 
of terrorists are generally low-tech, their use of the Internet and informa
-tion technology for recruitment, training, and communications is often 

highly sophisticated.
Given the importance of information technology to many societal 
functions, it is not surprising that there has been much public debate 

about cybersecurity (i.e., protection of information technology systems 

and networks and the programs and information within them from hos
-tile actions) and about how the United States might improve its cyberse
-curity posture in the face of hostile actions perpetrated by an adversary, 
9Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.10 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
such as a terrorist group, criminals, or another nation. Although in many 
other domains, security has always had both defensive and attack com
-ponents, cybersecurity has been somewhat anomalous, in the sense that 
its purely defensive side has been the primary focus of attention over the 

years. But, in fact, it is possible to imagine that cyberattacks might be used 

to support cyber defensive objectives. It is further possible to imagine that 

cyberattack would naturally be part of a robust U.S. military posture. 
The possibility that the United States might choose to engage in 
cyberattacks to serve its own national interests is, however, rarely dis
-cussed in public. For the record, the U.S. government has acknowledged 

that it has an interest in such capabilities as a possible instrument of 

national policy,
1 but this is virtually all that it acknowledges publicly. 
At least one press report has indicated the existence of a still-classi˜ed 

National Security Presidential Directive, NSPD 16, issued in July 2002, 

that reportedly ordered the U.S. government to develop national-level 

guidance for determining when and how the United States would launch 

cyberattacks against enemy computer networks.
2 The 
National Strategy to 
Secure Cyberspace
, published in February 2003, is entirely silent about an 
offensive component to U.S. cybersecurity efforts.
3 In practice, hostile actions against a computer system or network can 
take two forms. One form is destructive in natureŠthe action is taken to 

harm the system or network and render it less functional or useful than 

before the action was taken. An example of such a hostile action is era
-sure by a computer virus of the hard disk of any computer that it infects. 

The second form is non-destructiveŠthe action is taken to extract from 

a system or network information that would otherwise be kept con˜
-dential. Actions of this second form are usually clandestine, conducted 

with the smallest possible interventions that still allow extraction of the 

information sought. Such an action is exempli˜ed by a computer virus 

that searches the hard disk of any infected computer and e-mails to the 

hostile party all ˜les containing a credit card number.
Collectively, both forms of hostile action are termed ﬁcyber offensive 
operations,ﬂ or simply, ﬁcyber offense.ﬂ In this report, because the distinc
-tion between them is often important, the two forms of hostile action are 

given individual designators and somewhat expanded de˜nitions:

Cyberattack
 refers to the use of deliberate actionsŠperhaps over an 
extended period of timeŠto alter, disrupt, deceive, degrade, or destroy 
1 An Assessment of International Legal Issues in Information Operations
, 2nd edition, De
-partment of Defense, Of˜ce of General Counsel, November 1999. 
2 Bradley Graham, ﬁBush Orders Guidelines for Cyber-Warfare,ﬂ 
Washington Post
, February 7, 2003, p. A01. 
3 See http://www.dhs.gov/xlibrary/assets/National_Cyberspace_Strategy.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 11
adversary computer systems or networks or the information and/or pro
-grams resident in or transiting these systems or networks.
4 Such effects on 
adversary systems and networks may also have indirect effects on enti
-ties coupled to or reliant on them. A cyberattack seeks to cause adversary 
computer systems and networks to be unavailable or untrustworthy and 

therefore less useful to the adversary. Furthermore, because so many dif
-ferent kinds of cyberattack are possible, the term ﬁcyberattackﬂ should 

be understood as a statement about a methodology for actionŠand that 

aloneŠrather than as a statement about the scale of the action™s effect. 

Cyberexploitation
 refers to the use of cyber offensive actionsŠper
-haps over an extended period of timeŠto support the goals and mis
-sions of the party conducting the exploitation, usually for the purpose of 

obtaining information resident on or transiting through an adversary™s 

computer systems or networks. Cyberexploitations do not seek to disturb 

the normal functioning of a computer system or network from the user™s 

point of viewŠindeed, the best cyberexploitation is one that such a user 

never notices.
Box 1.1 summarizes important distinctions between cyberattacks and 
cyberexploitations. The committee recognizes that analysts and commen
-tators have used a variety of different terms that are closely related to 

what this report calls cyberattack (Box 1.2).
For purposes of this report, cyberattacks do not include kinetic actions 
taken against computers or networks using cruise missiles, sledgeham
-mers, or satchel charges. But in practice, the destruction of or damage 

to an adversary computer or network could be accomplished by kinetic 

as well as cyber actions. Thus, as acknowledged by the Department of 

Defense,
5 a planner contemplating the destruction of an adversary com
-puter or network should think about both cyberattack and kinetic attack 

options. This report also does not consider the use of electromagnetic 

pulse (EMP) attacks. EMP attacks typically refer to non-selective attacks 

on electronics and electrical components on a large scale, although a tac
-tical EMP weapon intended to selectively target such components on a 

small scale is possible to imagine.
64 An adversary computer or network may not necessarily be owned and operated by 
the adversaryŠit may simply support or be used by the adversary.
5 ﬁDoD will conduct kinetic missions to preserve freedom of action and strategic 
advantage in cyberspace. Kinetic actions can be either offensive or defensive and used in 
conjunction with other mission areas to achieve optimal military effects.ﬂ See Department 

of Defense, 
National Military Strategy for Cyberspace Operations,
 2006, available at www.dod.
mil/pubs/foi/ojcs/07-F-2105doc1.pdf.
6 For a comprehensive description of the threat from EMP attacks, see 
Report of the Com
-mission to Assess the Threat to the United States from Electromagnetic Pulse (EMP) Attack
, avail
-able at http://www.globalsecurity.org/wmd/library/congress/2004_r/04-07-22emp.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.12
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
1.2
 FOCUS
 OF
 AND
 M
OTIVATION
 FOR
 T
HIS
 R
EPORT
This report of the Committee on Offensive Information Warfare focuses 
primarily on the policy consequences and legal and ethical implications of 
U.S. acquisition and use of cyberattack, and secondarily (and only when 

necessary) on cyberexploitation. There are two reasons that a report on 

cyberattack necessarily touches on cyberexploitation. First, cyberattack 

and cyberexploitation are closely related from a technical point of view. 
BOX 1.1
 Cyberattack Versus Cyberexploitation
  Cyberexploitation,intelligence,
Cyberexploitation, intelligence, 
 Cyberattack, attack, 
 exploitation,computernetwork
exploitation, computer network
Terms
1 computer network attack
 exploitation
exploitation
Approach and 
 Degrade, disrupt, deny, 
 Conduct smallest intervention
intent destroy attacked 
 consistent with desired
 infrastructure and 
 operations
 systems/networks
Primary relevant 
 U.S. Code Title 10
 U.S. Code Title 50 authorities
domestic law
 authorities and 
 and restrictions
 restrictions
2    Operational agency
 U.S. Strategic 
 National Security Agency
 Command, Joint 
 Functional Combatant 
 Command for Network 
 Warfare 
 Main advocate 
 U.S. Air Force
 Director of National
in the U.S. 
  
Intelligencegovernment to 
 date  Interactions with 
 Based on explicit
 Based on intelligence reporting
tactical military 
 inclusion in battle plans
operations
   Characterization 
 War˜ghters
 Intelligence community
of personnel
1 Discussion of these terms and concepts can be found in Chapters 2, 3, and 4.
2 Covert action involving cyberattack would fall under Title 50 authorities.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 13
Second, because of such similarities a nation that is the target of a cyberex
-ploitation might misinterpret it as being a cyberattackŠa possibility that 
U.S. policy makers must take into account in deciding whether to conduct 

a cyberexploitation. Nevertheless, the policy and operational dimensions 

of cyberattack and cyberexploitation are quite different, and this report 

distinguishes between these two.
Cyberattack has a variety of military applications (discussed in 
Chapter 3) and may be useful for covert action (discussed in Chapter 4). In 

addition, cyberattack is conceivably a tool that law enforcement agencies 

or even the private sector might wish to use under some circumstances 

(discussed in Chapter 5). 
As suggested in the previous section, cyberattack sometimes arises 
in the context of defending U.S. computer systems and networks. Passive 

defensive measures such as hardening systems against attack, facilitat
-ing recovery in the event of a successful attack, making security more 

usable and ubiquitous, and educating users to behave properly in a threat 

environment are important elements of a strong defensive posture.
7 Nev
-ertheless, for the defense to be successful, these measures must succeed 

every time the adversary attacks. The adversary™s attack need succeed 

only once, and an adversary that pays no penalty for failed attacks can 

continue attacking until he or she succeeds or chooses to stop. This places 

a heavy and asymmetric burden on a defensive posture that employs only 

passive defense.
If passive defense is insuf˜cient to ensure security, what other 
approaches might help to strengthen one™s defensive posture? One possi
-bility is to eliminate or degrade an adversary™s ability to successfully pros
-ecute an attack. In that case, the attack is ultimately less successful than it 

might otherwise have been because the defender has been able to neutral
-ize the attack in progress (or perhaps even before it was launched). 
A second possibility is to impose other costs on the adversary, and 
such a strategy is based on two premises. First, the imposition of these 

costs on an attacker reduces the attacker™s willingness and/or ability 

to initiate or to continue an attack. Second, knowledge that an attack is 
7 The broad topic of steps that might be taken to improve passive cyberdefenses and 
to enhance resilience of U.S. computer systems and networks is not part of this report. 
There are many important technology and policy issues in the domain of cyberdefense, 

but many other works have addressed these issues. For a sampling of relevant National 

Research Council reports on this topic, see Footnotes 1 and 2 in the Preface to this report. 

Other important reports include President™s Information Technology Advisory Committee, 

Cyber Security: A Crisis of Prioritization
, National Coordination Of˜ce for Information Tech
-nology Research and Development, Washington, D.C., February 2005; and Commission on 
Cybe
rsecurity for the 44th Presidency, 
Securing Cyberspace for the 44th Presidency
, Center for 
Strategic and International Studies, Washington, D.C., 2008.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.14 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 1.2
 Terminology Related to Cyberattack
1A wide variety of terms in the literature have de˜nitions that overlap with the 
de˜nitions used in this report. (It is perhaps emblematic of the state of discussion 
today that there is no standard and widely accepted term that denotes attacks on 

computer systems and networks.) For example:
The term ﬁinformation operationsﬂ was used by the Joint Chiefs of Staff 
in 1998 to denote ﬁactions taken to affect adversary information and information 

systems while defending one™s own information and information systems.ﬂ Infor
-
mation operations were characterized as offensive or defensive, where ﬁoffensive 

information operationsﬂ were conducted to affect adversary decision makers and 

achieve or promote speci˜c objectives. The JCS used the term ﬁinformation war
-
fareﬂ to refer to information operations conducted during time of crisis or con˚ict 

(including war) to achieve or promote speci˜c objectives over a speci˜c adversary 

or adversaries.
2 The term ﬁnetwork attackﬂ is used by the U.S. Air Force Materiel Com
-mand™s Electronic Systems Center to refer to ﬁthe employment of network based 

capabilities to destroy, disrupt, corrupt, or usurp information resident in or transiting 

through networks.ﬂ
3The term ﬁoffensive information warfareﬂ was used by Dorothy Denning 
to describe an operation that ﬁtargets or exploits a particular information resource 

with the objective of increasing its value to the offensive player and decreasing its 

value to the defensive player.ﬂ
4The term ﬁinformation warfareﬂ has been used often, but with a variety of 
meanings.
5 For example, the term is used by the Center for Strategic and Inter
-national Studies to denote data attack, such as propaganda, disinformation, data 

overload, and spam; software attack using computer viruses, Trojan horses, or 

trapdoors; hacking, i.e., penetration, unauthorized use, and/or snooping in other 

computer systems; and physical kinetic or directed energy attacks against informa
-tion systems.
6 By contrast, Ryan and Ryan de˜ne information warfare as ﬁthe appli
-cation of destructive force
 on a large scale against information assets and systems, 
against computers and networks which support the air traf˜c control systems, stock 

transactions, ˜nancial records, currency exchanges, Internet communications, 

telephone switching, credit record, credit card transactions, the space program, 

the railroad system, the hospital systems that monitor patients and dispense drugs, 

manufacturing process control systems, newspaper and publishing, the insurance 

industry, power distribution and utilities, all of which rely heavily on computers.ﬂ
7 Ryan and Ryan also note that ﬁInformation warfare is, ˜rst and foremost, warfare. 
It is not information terrorism, computer crime, hacking or commercial or state 
sponsored espionage using networks for access to desirable information.ﬂ
The term ﬁinformation attackﬂ is used by Davis Brown, a former deputy 
judge advocate for the U.S. Defense Information Systems Agency, to focus on 
information or information systems as the object, means, or medium of attack.
8The terms ﬁoffensive cyber operationsﬂ and ﬁoffensive cyberspace opera
-tionsﬂ are sometimes heard in discussions with military of˜cials and are appar
-
ently used to denote one or more actions, perhaps taken over a period of time, to 

disrupt, deny, degrade, or destroy information resident in computers and computer 

networks, or the computers and networks themselves.
9 Offensive cyber or cyber
-space operations apparently extend beyond computer network attack (for example, 

they include computer network exploitation) and recognize the possibility that an 

extended offensive campaign might be waged in cyberspace involving multiple 

cyberattacks.
The term ﬁcomputer network attackﬂ was adopted by the Joint Chiefs of 
Staff in 2006 to refer to ﬁactions taken through the use of computer networks to 

disrupt, deny, degrade, or destroy information resident in computers and computer 

networks, or the computers and networks themselves.ﬂ
10 In 2006, the Joint Chiefs 
of Staff also eliminated the term ﬁinformation warfareﬂ and the distinction between 

ﬁoffensiveﬂ and ﬁdefensiveﬂ information operations.
After considering the plethora of terms used in this domain, the committee 
settled on ﬁcyberattackﬂ as the term best describing the primary focus of this 

report.
1 This description of the various terms is derived in part from Davis Brown, ﬁA Proposal for 
an International Convention to Regulate the Use of Information Systems in Armed Con˚ict,ﬂ 
Harvard International Law Journal
, 47(1):179-221, Winter 2006.
2 Joint Chiefs of Staff, Joint Publication No. 3-13, Joint Doctrine for Information Operations, 
Oct. 9, 1998.
3 See Broad Agency Announcement (BAA ESC 07-0001) on 
Network Warfare Operations 
Capabilities (NWOC): Technology Concept Demonstrations
, May 31, 2007.
4 Dorothy E. Denning, 
Information Warfare and Security
, Addison-Wesley Longman Ltd., 
Essex, UK, 1999.
5 For a review of such de˜nitions, see Chapter 1 of Gregory Rattray, 
Strategic Warfare in 
Cyberspace, 
MIT Press, Cambridge, Mass., 2001.
6 Cybercrime Cyberterrorism Cyberwarfare: Averting an Electronic Waterloo
, Center for 
Strategic and International Studies, 1998.
7 Daniel and Julie Ryan, ﬁProtecting the NII against Infowar,ﬂ in Winn Schwartau, 
Information 
Warfare, 
Thunder™s Mouth Press
, 1996.8 Davis Brown, ﬁA Proposal for an International Convention to Regulate the Use of Informa
-tion Systems in Armed Con˚ict,ﬂ 
Harvard International Law Journal
 47(1):179-221, Winter 
2006.9 For example, the U.S. Air Force Cyber Command writes that ﬁCyberspace favors offensive 
operations. These operations will deny, degrade, disrupt, destroy, or deceive an adversary. 

Cyberspace offensive operations ensure friendly freedom of action in cyberspace while deny
-ing that same freedom to our adversaries. . . .  As an adversary becomes more dependent on 

cyberspace, cyberspace offensive operations have the potential to produce greater effects.ﬂ 
See Air Force Cyber Command Strategic Vision, undated document (probably 3 March 2008), 
available at http://www.afcyber.af.mil/shared/media/document/AFD-080303-054.pdf.
10 Joint Chiefs of Staff, Joint Publication No. 3-13, Joint Doctrine for Information Operations, 
February 13, 2006.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 15
BOX 1.2
 Terminology Related to Cyberattack
1A wide variety of terms in the literature have de˜nitions that overlap with the 
de˜nitions used in this report. (It is perhaps emblematic of the state of discussion 
today that there is no standard and widely accepted term that denotes attacks on 

computer systems and networks.) For example:
The term ﬁinformation operationsﬂ was used by the Joint Chiefs of Staff 
in 1998 to denote ﬁactions taken to affect adversary information and information 

systems while defending one™s own information and information systems.ﬂ Infor
-
mation operations were characterized as offensive or defensive, where ﬁoffensive 

information operationsﬂ were conducted to affect adversary decision makers and 

achieve or promote speci˜c objectives. The JCS used the term ﬁinformation war
-
fareﬂ to refer to information operations conducted during time of crisis or con˚ict 

(including war) to achieve or promote speci˜c objectives over a speci˜c adversary 

or adversaries.
2 The term ﬁnetwork attackﬂ is used by the U.S. Air Force Materiel Com
-mand™s Electronic Systems Center to refer to ﬁthe employment of network based 

capabilities to destroy, disrupt, corrupt, or usurp information resident in or transiting 

through networks.ﬂ
3The term ﬁoffensive information warfareﬂ was used by Dorothy Denning 
to describe an operation that ﬁtargets or exploits a particular information resource 

with the objective of increasing its value to the offensive player and decreasing its 

value to the defensive player.ﬂ
4The term ﬁinformation warfareﬂ has been used often, but with a variety of 
meanings.
5 For example, the term is used by the Center for Strategic and Inter
-national Studies to denote data attack, such as propaganda, disinformation, data 

overload, and spam; software attack using computer viruses, Trojan horses, or 

trapdoors; hacking, i.e., penetration, unauthorized use, and/or snooping in other 

computer systems; and physical kinetic or directed energy attacks against informa
-tion systems.
6 By contrast, Ryan and Ryan de˜ne information warfare as ﬁthe appli
-cation of destructive force
 on a large scale against information assets and systems, 
against computers and networks which support the air traf˜c control systems, stock 

transactions, ˜nancial records, currency exchanges, Internet communications, 

telephone switching, credit record, credit card transactions, the space program, 

the railroad system, the hospital systems that monitor patients and dispense drugs, 

manufacturing process control systems, newspaper and publishing, the insurance 

industry, power distribution and utilities, all of which rely heavily on computers.ﬂ
7 Ryan and Ryan also note that ﬁInformation warfare is, ˜rst and foremost, warfare. 
It is not information terrorism, computer crime, hacking or commercial or state 
sponsored espionage using networks for access to desirable information.ﬂ
The term ﬁinformation attackﬂ is used by Davis Brown, a former deputy 
judge advocate for the U.S. Defense Information Systems Agency, to focus on 
information or information systems as the object, means, or medium of attack.
8The terms ﬁoffensive cyber operationsﬂ and ﬁoffensive cyberspace opera
-tionsﬂ are sometimes heard in discussions with military of˜cials and are appar
-
ently used to denote one or more actions, perhaps taken over a period of time, to 

disrupt, deny, degrade, or destroy information resident in computers and computer 

networks, or the computers and networks themselves.
9 Offensive cyber or cyber
-space operations apparently extend beyond computer network attack (for example, 

they include computer network exploitation) and recognize the possibility that an 

extended offensive campaign might be waged in cyberspace involving multiple 

cyberattacks.
The term ﬁcomputer network attackﬂ was adopted by the Joint Chiefs of 
Staff in 2006 to refer to ﬁactions taken through the use of computer networks to 

disrupt, deny, degrade, or destroy information resident in computers and computer 

networks, or the computers and networks themselves.ﬂ
10 In 2006, the Joint Chiefs 
of Staff also eliminated the term ﬁinformation warfareﬂ and the distinction between 

ﬁoffensiveﬂ and ﬁdefensiveﬂ information operations.
After considering the plethora of terms used in this domain, the committee 
settled on ﬁcyberattackﬂ as the term best describing the primary focus of this 

report.
1 This description of the various terms is derived in part from Davis Brown, ﬁA Proposal for 
an International Convention to Regulate the Use of Information Systems in Armed Con˚ict,ﬂ 
Harvard International Law Journal
, 47(1):179-221, Winter 2006.
2 Joint Chiefs of Staff, Joint Publication No. 3-13, Joint Doctrine for Information Operations, 
Oct. 9, 1998.
3 See Broad Agency Announcement (BAA ESC 07-0001) on 
Network Warfare Operations 
Capabilities (NWOC): Technology Concept Demonstrations
, May 31, 2007.
4 Dorothy E. Denning, 
Information Warfare and Security
, Addison-Wesley Longman Ltd., 
Essex, UK, 1999.
5 For a review of such de˜nitions, see Chapter 1 of Gregory Rattray, 
Strategic Warfare in 
Cyberspace, 
MIT Press, Cambridge, Mass., 2001.
6 Cybercrime Cyberterrorism Cyberwarfare: Averting an Electronic Waterloo
, Center for 
Strategic and International Studies, 1998.
7 Daniel and Julie Ryan, ﬁProtecting the NII against Infowar,ﬂ in Winn Schwartau, 
Information 
Warfare, 
Thunder™s Mouth Press
, 1996.8 Davis Brown, ﬁA Proposal for an International Convention to Regulate the Use of Informa
-tion Systems in Armed Con˚ict,ﬂ 
Harvard International Law Journal
 47(1):179-221, Winter 
2006.9 For example, the U.S. Air Force Cyber Command writes that ﬁCyberspace favors offensive 
operations. These operations will deny, degrade, disrupt, destroy, or deceive an adversary. 

Cyberspace offensive operations ensure friendly freedom of action in cyberspace while deny
-ing that same freedom to our adversaries. . . .  As an adversary becomes more dependent on 

cyberspace, cyberspace offensive operations have the potential to produce greater effects.ﬂ 
See Air Force Cyber Command Strategic Vision, undated document (probably 3 March 2008), 
available at http://www.afcyber.af.mil/shared/media/document/AFD-080303-054.pdf.
10 Joint Chiefs of Staff, Joint Publication No. 3-13, Joint Doctrine for Information Operations, 
February 13, 2006.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.16
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
costly to an attacker deters other parties from attempting to attackŠand 
advance knowledge of such a possibility may deter the original adversary 
from attacking in the ˜rst place. There are in general many options for 

imposing costs on an adversary, including economic penalties such as 

sanctions, diplomatic penalties such as breaking of diplomatic relations, 

and even kinetic military actions such as cruise missile strikes. In-kind 

military actionŠa counter-cyberattackŠis also a possibility.
Both of these possible actionsŠneutralization of an attacker™s ability 
to attack and the imposition of costs on the attacker for the attackŠare 

often captured under the rubric of active defense. But actions taken in the 

name of active defense might well be seen as offensive acts. 
Consider the act of Zendia
8 probing a computer system or network 
belonging to Ruritania to gather information about it (what ports are 

open, what services are protected or available for use, the IP addresses 

of various machines on it, what operating systems are in use, and so 

on). If Zendia has 
already
 been the target of a cyberattack launched from 
Ruritania, Zendia may plausibly regard its probes of computer systems 

in Ruritania as part of a 
defensi
ve reaction to the attackŠgathering infor
-mation about the systems involved in an attack may be important for 

characterizing its scale and intent. But Ruritania may regard such a probe 

as a hostile action by Zendia against it, because such probes can be used 

to develop information useful in a cyberattack. 
The inadequacy of passive defense suggests that the national debate 
over cybersecurity necessarily includes a consideration of attack options 

for defensive purposes. Furthermore, once an attack capability is required 

to conduct active cyberdefense, and once a nation has the capability for 

active defense, it is also possible for that nation to use an attack capability 

for other, non-defensive purposes. Attack capabilities may under some 

circumstances also contribute to deterrenceŠa relationship that is expli
-cated in more detail in Chapter 9.
Given the possibility that cyberattack capabilities might be useful to 
the U.S. government for many purposes (including active defense), a host 

of policy issues arise that do not arise if passive defense is the only defen
-sive option under consideration. Box 1.3 provides an analogy to describe 

how policy issues inevitably emerge from any government consideration 

of offensive options.
8 Note to the reader: When the name of a nation is needed in this report, the names 
ﬁZendiaﬂ and ﬁRuritaniaﬂ are used as stand-ins. Depending on context, these nations may 
be a near-peer nation-state with military and economic stature and power comparable to 

that of the United States; a small, relatively undeveloped nation; or something in between. 

Generally in this report, Zendia is an adversary of the United States.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 17
BOX 1.3
 Policy Issues That Flow from 
 Government Use of Guns
In order for society to defend itself against armed criminals, one policy choice 
would be to focus on passive defense against gunsŠbulletproof vests might be 
distributed to the populace. Criminals might then invest in more powerful guns that 

could shoot through bulletproof vests. In response, the government might then sup
-port research into techniques for developing stronger, more dif˜cult-to-penetrate 

armor or initiate programs to provide bulletproof vests to more citizens more quickly 

and educate them about how to use bulletproof vests properly.
Such policy responses are much simpler than those arising from a situation 
in which police are themselves armed. Governments that arm police of˜cers must 

be concerned about:
Training
. Police of˜cers must have a level of training and expertise in the 
use of ˜rearms adequate for most situations they will encounter in their day-to-day 

work.
Rules of engagement
. Police of˜cers must follow pre-established rules 
of engagement that provide guidance on when the use of ˜rearms is and is not 

appropriate. 
Command and control
. Police of˜cers are subject to a chain of command 
that can grant or withhold permission to discharge ˜rearms. 
Identi˜cation friend-or-foe
 (IFF), the process by which police of˜cers de
-termine who or what counts as a legitimate target for their weapons. Because 

undercover police and criminals often choose to look like ordinary citizens (as a 

rule, they do not wear distinguishing uniforms), police must exercise great care in 

determining their targets. 
Liability
. Police (individual of˜cers and the department itself) may be 
found liable for civil damages or even subject to criminal penalties if a shooting 

takes place improperly, and especially if someone is injured or killed by such a 

shooting. 
Note that the fact of police of˜cers carrying guns serves a defensive pur
-poseŠprotecting the citizenryŠeven though guns themselves are arguably an 

offensive weapons technology, i.e., a weapons technology that is designed to in˚ict 

harm or damage to a target. The committee makes this gun-related analogy not 

to address any particular policy issue related to private or criminal or even police 

usage of guns, but to point out that policy and legal issues inevitably ˚ow from the 

use of offensive weapons by ﬁgood guys.ﬂ
1.3
 CYBERATTACK
 IN
 THE
 C
ONTEXT
 OF
 AN
 I
NFORMATION
 STRATEGY
 FOR
 THE
 U
NITED
 S
TATES
U.S. military forces have made great progress in developing and 
implementing plans for joint integrated operations in the conventional 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.18
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
military sphere, but in the information domain, U.S. doctrine and 
approaches have left many niches and gaps for adversaries to exploit. 
The lack of an integrated approach to the information domain has meant 

that the United States lacks timeliness and synergy in its planning and 

operations. An integrated approach would spread information and ideas 

that support U.S. interests and would degrade and disrupt information 

and ideas abroad that are adverse to U.S. interests (e.g., websites for ter
-rorist recruiting).
Cyberattack is only one dimension of information operations. In prac
-tice, many cyberattacks are likely to take place within a large, diverse, and 

organically interconnected domain in which deception, espionage, covert 

in˚uence, diversion, interception and disruption of communications, and 

other information operations will also take place (as discussed in Box 3.3 

in Chapter 3). All of these operations can be used in an intertwined and 

integrated fashion. Espionage can be a precursor to a denial-of-service 

attack, while denial of service can be used to facilitate espionage by forc
-ing one™s adversary to use an insecure mode of communication. And 

information operations are themselves only one aspect of what might be 

called an information strategy for pursuing U.S. strategic and security 

interests. 
Advocates of such an information strategy argue that the nature of 
warfare and con˚ict is changing, and that information will be central to 

national security affairs in the future. This argument is based in part on the 

idea that adversariesŠunable to compete with the United States in tradi
-tional military domainsŠwill seek to exploit U.S. weaknesses asymmetri
-cally, and that the information domain is one of the most important. 
Information is central for two reasons. First, modern societies are 
based largely on the effective use of large amounts of informationŠa fact 

re˚ected in the increasing ubiquity of and dependence on information 

technology throughout these societies. Second, the ﬁhearts and mindsﬂ 

of much of the world™s population will be won or lost through the in˚u
-ence gained by appropriately targeted ideas and information. The ˜rst 

point suggests that the information assets (and supporting technologies) 

of modern societies are a possible point of leverage for adversaries that 

are less dependent on information. The second point suggests that a pre
-dominantly military approach to national security is too narrow, and that 

the United States would be well served by a much broader strategy that 

puts hearts, minds, and ideas at its center.
In this view, the United States must integrate strategic/tactical in˚u
-ence and messaging and perception management with a broad spectrum 

of capabilities for information attack and defense. At the highest level of 

strategic perspective, the goal of information attack is to get into the mind 

of the adversary and in˚uence its decision making at critical times and 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 19
at all levels. This would include making adversaries question their plans, 
direction, capabilities, actions, likelihood of success, control, and whether 
generally they trust their information and knowledge base. At the tacti
-cal and operational level, information attack entails destroying, denying, 

degrading, disrupting, in˚uencing, and corrupting an adversary™s ability 

to see, know, understand, decide, and take action. The goal of informa
-tion defense is to protect our ability to see, know, understand, decide, and 

take action. 
A coordinated information strategy would integrate a variety of dis
-ciplines and specialties, most of which are not integrated today. These 

include strategic communications, in˚uence, and messaging; pub
-lic diplomacy; perception management; computer network operations 

(attack, defense, and exploitation); space control; electronic reconnais
-sance/warfare; psychological operations; strategic and departmental 

deception; propaganda, information assurance and infrastructure protec
-tion, and counter denial and deception; public affairs; counterintelligence; 

HUMINT (human intelligence) and OSINT (open source intelligence) 

activities; imagery and mapping operations; data and information min
-ing; and special operations forces. 
1.4
 IMPORTANT
 C
HARACTERISTICS
 OF
  CYBERATTACK
 AND
 C
YBEREXPLOITATION
As noted above, cyberattack refers to actionsŠperhaps taken over an 
extended period of timeŠto alter, disrupt, deceive, degrade, or destroy 

adversary computer systems or networks or the information and/or pro
-grams resident in or transiting these systems or networks. Several char
-acteristics of weapons for cyberattack are worthy of note.

The indirect effects of weapons for cyberattack are almost always more 
consequential than the direct effects of the attack.
 (Direct or immediate effects 
are effects on the computer system or network attacked. Indirect or fol
-low-on effectsŠwhich may be the primary purpose of a cyberattackŠare 

effects on the systems and/or devices that the attacked computer system 

or network controls or interacts with, or on the people who use or rely 

on the attacked computer system or network.) That is, the computer or 

network attacked is much less relevant than the systems controlled by the 

targeted computer or network (e.g., a cyberattack that affects a computer 

controlling an electric power generator will also, and more importantly, 

affect the generator itself) or the decision making that depends on the 

information contained in or processed by the targeted computer or net
-work, and indeed the indirect effect is often the primary purpose of the 

attack. Thus, the scale of damage of any given cyberattack can range from 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.20 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
the trivial to the enormous, depending on the systems and/or information 
connected to or associated with the target.

The outcomes of a cyberattack are often highly uncertain.
 Minute details 
of con˜guration can affect the outcome of a cyberattack, and cascading 
effects often cannot be reliably predicted. One consequence can be that 

collateral damage and damage assessment of a cyberattack may be very 

dif˜cult to estimate.

Cyberattacks are often 
very complex to plan and execute.
 Cyberattacks 
can involve a much larger range of options than most traditional military 

operations, and because they are fundamentally about an attack™s sec
-ondary and tertiary effects, there are many more possible outcome paths 

whose analysis often requires highly specialized knowledge. The time 

scales on which cyberattacks operate can range from tenths of a second 

to years, and the spatial scales may be anywhere from ﬁconcentrated in a 

facility next doorﬂ to globally dispersed.

Compared to traditional military operations, cyberattacks are relati
vely 
inexpensi
ve. 
The underlying technology for carrying out many types of 
cyberattacks is widely available, inexpensive, and easy to obtain. An 

attacker can compromise computers belonging to otherwise uninvolved 

parties to take part in an attack activity; use automation to increase the 

amount of damage that can be done per person attacking, increase the 

speed at which the damage is done, and decrease the required knowledge 

and skill level of the operator of the system; and even steal the ˜nancial 

assets of an adversary to use for its own ends. On the other hand, some 

cyberattack weapons are usable only once or a few times.

The identity of the originating party behind a signi˚cant cyberattack can 
be concealed with relati
ve ease, compared to that of a signi˚cant kinetic attack.
 Cyberattacks are very dif˜cult to attribute to any particular actor and are 

thus easy to conduct with plausible deniabilityŠindeed, most cyberat
-tacks are inherently deniable. Cyberattacks are thus also well suited for 

being instruments of catalytic con˚ictŠinstigating con˚ict between two 

other parties. 
Many of the operational considerations for cyberexploitation are simi
-lar to those for cyberattack. Like cyberattack, a successful cyberexploita
-tion requires a vulnerability, access to that vulnerability, and a payload 

to be executedŠthe only difference is in the payload to be executed. 

These similarities often mean that a targeted party may not be able to 

distinguish easily between a cyberexploitation and a cyberattackŠa fact 

that may result in that party™s making incorrect or misinformed deci
-sions. The primary technical requirement of a cyberexploitation is that 

the delivery and execution of its payload be accomplished quietly and 

undetectably. Secrecy is often far less important when cyberattack is the 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 21
mission, because in many cases the effects of the attack will be immedi
-ately apparent to the target.
1.5
 ILLUSTRATIVE
 A
PPLICATIONS
 OF
 C
YBERATTACK
Cyberattack can be used to support many traditional military opera
-tions, such as the disruption of adversary command, control, and commu
-nications; suppression of adversary air defenses; degradation of adversary 
smart munitions and platforms; and attack of adversary war˜ghting or 

warmaking infrastructure (the adversary defense industrial base). Cyber
-attack might be used to augment a kinetic attack or to enable it to succeed, 

or to defend a friendly computer system or network by neutralizing the 

source of a cyberattack conducted against it. Cyberattack could also be 

used to achieve military deception. For example, by assuming control of 

a computer used by a senior intelligence analyst, a cyberattack could send 

bogus e-mail traf˜c to that analyst™s clients. The contents of these e-mails 

could easily provide misinformation regarding the military capabilities, 

intentions, locations, and operations of friendly forces. 
From a strictly technical perspective, cyberattack has several attri
-butes that are well suited for the shadowy world of intelligence. For 

example, as noted above, attribution of a cyberattack is usually quite 

dif˜cult. The effects of a cyberattack may not become visible to the vic
-tim for long periods of time, if ever. And the range of possible options is 

very large, so that cyberattack-based operations might be set in motion to 

in˚uence an election, instigate con˚ict between political factions, harass 

disfavored leaders or entities, or divert money. Such operations can fall 

into the category of covert action, which by law is de˜ned as political, 

economic, propaganda, or paramilitary activities and is usually designed 

to in˚uence governments, events, organizations, or persons in support of 

foreign policy in a manner that is not necessarily attributable to the U.S. 

government. 
1.6
 THE
 L
EGAL
 F
RAMEWORK
 G
OVERNING
 C
YBERATTACK
 The committee™s view of the basic framework for the legal analysis 
of cyberattack is based on the principle that notions related to ﬁuse of 

forceﬂ and ﬁarmed attackﬂ (terms of special relevance to the Charter 

of the United Nations) should be judged primarily by the effects of an 

action rather than its modality. That is, the fact that an attack is carried 

out through the use of cyberweapons rather than kinetic weapons is far 

less signi˜cant than the effects that result from such use, where ﬁeffectsﬂ 

are understood to include both direct and indirect effects.
Accordingly, cyberattack should be judged according to the principles 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.22
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
of the law of armed con˚ict (LOAC) and the UN Charter, encompassing 
both 
jus ad bellum
 (law governing the legality of going to war) and 
jus in 
bello 
(law governing behavior during war) with the understanding that 
new analytical work is needed to understand how these principles do or 
should apply to cyberweapons. For example, some of the more problem
-atic cases involving cyberattack include the following:

Con˜icts that do not fall under the presumption of nation-to-nation con
-˜ict between national military forces.
 When the law of armed con˚ict was 
˜rst articulated, only nation-states had the ability to wage war. Because 

cyberattack weapons are inexpensive and easily available, non-state actors 

(e.g., terrorist groups, organized crime) are capable of engaging in armed 

con˚ict through the use of cyberweapons, as are individuals acting on 

their own with putatively ﬁpatrioticﬂ motivations or with criminal inten
-tions. Even in non-government hands, these weapons include some that 

are as capable of doing great harm as those available to governments. 

Thus, the lines between state, non-state, and individual attackers are 

unclear in a legal regime that distinguishes between LOAC on the one 

hand and national criminal laws on the other. 

The exception for espionage.
 The LOAC presumes that a clear distinc
-tion can be drawn between the use of force and espionage, where espio
-nage is avowedly not a use of force. However, the distinction between 

cyberattack and cyberexploitation may be very hard to draw from a tech
-nical standpoint, and may lie primarily in the intent of the user. 

The emphasis on notions of territorial integrity.
 A target in cyberspace 
may be known only through an electronic identi˜er, such as an IP address 

or a MAC address. (A component™s Media Access Control addressŠgen
-erally known as a MAC addressŠis a quasi-unique identi˜er assigned to 

most network adapters or network interface cards (NICs) by their manu
-facturer for identi˜cation.) To what extent should the physical location of 

a computer matter in determining whether it is a legitimate military target 

that may be subject to cyberattack? Also, the effects of attacking a given 

computer may not be felt at all in the immediate geographic vicinity of 

the computer, thus raising the question of which geographic location is 

relevant to the determination of legitimacy for attack.
1.7
 THE
 D
YNAMICS
 OF
 C
YBERCONFLICT
The escalatory dynamics of armed con˚ict are thought to be under
-stood as the result of many years of thinking about the subject. The 

dynamics of cyberwarfare are less well understood. This report spec
-ulates on some of the factors that might in˚uence the evolution of a 

cybercon˚ict. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 23
For major nation-states with signi˜cant kinetic and cyber capabilities 
at their disposal, some of the important questions to be addressed include 
the following:

Crisis stability
. What is the analog of crisis stability in cybercon˚ict? 
What are the incentives for preemptive cyberattack? Crisis stability refers 

to the condition in which even in a crisis, neither side has an incentive to 

escalate the con˚ict.

Resol
ving the tension between a policy need for rapid response and the 
technical reality that attribution of a cyber action is a time-consuming task
. Shortening the time for investigation may well increase the likelihood 

of errors being made in a response (e.g., responding against the wrong 

machine, launching a response that has large unintended effects).

Pre
venting cybercon˜ict from escalating to physical space
. Given that 
cyberattacks are likely to occur in the early stages of a con˚ict, how can 

cybercon˚ict between nations be limited to con˚ict in cyberspace? How 

should cyberattack be scoped and targeted so that it does not lead an 

adversary to escalate a con˚ict into kinetic con˚ict? How can a modestly 

scoped cyberattack conducted by a government be differentiated from the 

background cyberattacks that are going on all of the time? 

The complicating presence of non-state actors
. How can ﬁfreelanceﬂ 
activities on the part of ﬁpatriotic hackersﬂ be minimized or curtailed? 

Termination of cybercon˜ict
. How would two nations engaged in 
cybercon˚ict indicate that they have ceased cyberattacks against each 

other? 

The role of transparency
. What is the role of transparency in promot
-ing crisis stability and con˚ict limitation in cyberspace? 

Catalytic cybercon˜ict
. How can catalytic cybercon˚ict be avoided? 
(Catalytic con˚ict refers to the instigation of con˚ict between two parties 

at the behest or initiative of a third party.)
For non-state actors such as terrorist or criminal groups, two pri
-mary issues relate to identi˜cation of the appropriate party against which 

to retaliate, and the availability of cyber and/or kinetic targets whose 

destruction might cause pain or meaningful damage to the terrorist or 

criminal group. At the same time, nations hosting such groups might have 

plausible targets, and the assistance of those nations in acting against such 

groups might be obtained.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.24 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
1.8
 FINDINGS
This section presents the committee™s ˜ndings and recommendations, 
along with supporting arguments that summarize material contained in 
later chapters.
1.8.1
 Technologies as Instruments of U.S. National Policy 
Once a need has been established, a sound stance regarding the use 
of most technologies as an instrument of U.S. national policy rests on four 

pillars:

Capabilities to use the technology in a 
variety of situations and contexts.
 That is, the technology must be suf˜ciently well developed and robust to 

be usable in ways that advance U.S. national interests. When new tech
-nologies are in their infancy, unproven extravagant claims are often made 

about their putative effectivenessŠbut in some cases, such claims do turn 

out to be valid.

Policy guidance for when and how such capabilities should be exercised.
 Policy guidance can be expressed in many forms, including statutory 

and/or common law, regulations and directives, ethical standards, acqui
-sition decisions, military doctrine, and so on. As a general rule, these 

different expressions of national policy should reinforce, or at least be 

consistent with, each other. But since the U.S. government, like all gov
-ernments, has multiple loci for policy formation, such consistency is not 

always found in national policy.

Decision-making mechanisms for implementing policy guidance in an 
operational sense regarding the actual use of the capabilities a
vailable. For exam
-ple, when a crisis occurs, a well-organized government will have clear 

and transparent mechanisms in place for directing that various actions be 

taken in response. One central element of such mechanisms is necessar
-ily focused on reconciling competing interests and equities that may be 

present among the various stakeholders represented in the government 

and/or in the private sector.

Oversight to ensure consistency between actual use and policy guidance.
 In large bureaucracies, maintaining consistency between policy and actual 

practice or use is often dif˜cult, and oversight is necessary to ensure such 

consistency. In practice, oversight closes the feedback loop between out
-comes and policy, and provides indicators of whether a policy is working 

to advance national interests.
The ˜rst of these elements is inherent in the technology. But the 
remaining three elements emerge only from the organizations and people 

who must determine how any given technology is to be usedŠand such 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 25
emergence almost always trails the development of technological capa
-bilities. Furthermore, a rapid pace of change in technologies relevant 
to warfare almost always changes the nature of warfare itself, and thus 

military doctrine and concepts of use must also adjust to the realities of 

new technologies.
Regarding cyberattack, consider that the World Wide Web was 
invented in the early 1990s
9 and personal computers went mainstream 
for the general public less than 30 years ago with the introduction of the 

IBM PC in 1981. Over a billion people use cell phones today,
10
 and wire
-less services are growing exponentially. Accurate location and velocity 

information for vehicles is more available than ever before through GPS 

and similar systems. Taking into account the speed at which organizations 

such as national governments change, it is not surprising that policy guid
-ance, decision-making mechanisms for operational use, and oversight 

mechanisms for cyberattack have not been fully developed. These ele
-ments are the primary focus of the ˜ndings and recommendations that 

follow.
As for today™s policy context, policy and guidance are evolving rap
-idly at the time of this writing (early 2009). A number of reports have 

been recently issued speaking to the importance of cybersecurity to the 

nation. These reports have either obliquely or explicitly referred to the 

importance of integrating defensive activities with offensive activities in 

cyberspace. The outgoing administration launched the $40 billion Com
-prehensive National Cybersecurity Initiative (CNCI), which reportedly 

takes seriously this notion of integration. The organization of the Depart
-ment of Defense for cyber operations is in ˚ux as well, as different agen
-cies and services make their cases for signi˜cant roles regarding the attack 

mission.
1.8.2
 Overarching Findings
Finding 
1:
 The policy and organizational issues raised by U.S. 
acquisition and use of cyberattack are signi˜cant across a broad 

range of con˚ict scenarios, from small skirmishes with minor 

actors on the international stage to all-out con˚icts with adversar
-ies capable of employing weapons of mass destruction. 
9 See http://groups.google.com/group/alt.hypertext/msg/395f282a67a1916c.
10
 More precisely, the number of mobile telephone subscriptions globally reached 
3.3 billion in November 2007. See Reuters, ﬁGlobal Cellphone Penetration Reaches 50 Pct,ﬂ 
November 29, 2007, available at http://investing.reuters.co.uk/news/articleinvesting.

aspx?type=media&storyID=nL29172095.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.26
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
The statement above represents the primary ˜nding of the commit
-tee. All of the ˜ndings in this section are elaborations of this primary 
˜nding. 
While the immediate effects of cyberattack are unlikely to be compa
-rable to the effects of weapons of mass destruction (for example, nuclear, 

chemical, or biological weapons), a large-scale cyberattack could mas
-sively affect the functioning of a society and lead to many indirect casual
-ties. Conversely, it is possible to imagine that certain cyberattacks might 

be executed on a smaller scale and with a lower degree of lethality than 

might be expected if kinetic weapons were used for equivalent military 

purposes. Thus the policy implications of cyberattack have certain com
-monalities across the range from non-lethal engagements to wars involv
-ing the use of weapons of mass destruction. 
To the extent that new technologies afford new capabilities, they 
imply new policy challenges about how to develop, acquire, and use 

them; about who should use them and who should decide about using 

them; and indeed about how to think about them. But the policy issues 

associated with cyberattack are of particular urgency today, because the 

amount and degree of conceptualization and understanding in the policy-

making community about these issues relative to their potential signi˜
-cance is much lower than is the case with almost any other weapon in 

the U.S. arsenal. In other words, the state of policy formation regarding 

cyberattack is still in its infancy compared to policy regarding most other 

weapons, even though the availability and proliferation of cyberattack 

technologies is a technological watershed. And it is the committee™s belief 

that the issues surrounding cyberattack extend far beyond the traditional 

responsibilities of the Department of Defense and the intelligence commu
-nity and touch national interests such as diplomacy and foreign relations, 

law enforcement, and commerce and trade. 
Finally, the committee notes that the goals of a cyberattack (i.e., the 
alteration, disruption, deception, degradation, or destruction of a com
-puter system or network) may sometimes be accomplished by more tra
-ditional kinetic means. Any planner contemplating the destruction of an 

adversary computer or network would have to think about both cyber
-attack and kinetic attack options. But there is a well-developed body of 

doctrine and guidance regarding kinetic options, and so the committee 

has not speci˜cally examined or presented the kinetic perspective in any 

systematic way in this report.
Finding
 2: 
The availability of cyberattack technologies for 
national purposes greatly expands the range of options avail
-able to U.S. policy makers as well as to policy makers of other 

nations.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 27
Cyberattack technologies can have a broad range of effects and impacts 
(Chapter 2). They are thus quite ˚exible, and for example can sometimes 
be operated reversibly or irreversibly and in a lethal/destructive or non-

lethal/non-destructive manner depending on the speci˜c technology 

involved. In addition, cyberattack technologies have a largely clandestine 

character and are relatively inexpensive. These characteristicsŠ˚exibility, 

clandestine nature, and low costŠcan be helpful in many applications by 

the military, intelligence, and law enforcement communities.
An important consequence of the broad range of possible effects and 
impacts is that cyberattack as an instrument of national policy has both 

offensive and defensive implications (as noted in Section 1.2 and Chapter 

2), and both tactical and strategic implications as well (Chapter 9). Fur
-thermore, much of the supporting technology for characterizing ongoing 

cyberattacks (e.g., detection, warning, attack assessment) is relevant to 

both offense and defense, and to tactical and strategic planning and deci
-sion making. Such dualities can be found for kinetic technologies as well, 

but they are front and center in thinking about cybercon˚ict.
The fact that cyberattack technologies can have a broad range of 
effects and impacts also means that their use may sometimes result in 

unanticipated, unforeseen, or unintended consequences. Concerns about 

these unanticipated consequences may (and perhaps should) inhibit the 

use of cyberattack under some circumstances. Finding 18 notes the uncer
-tainties associated with the effects of many kinds of cyberattack.
In addition, the nature of cyberattack technologies is that they are 
available to other nations and non-state actors as well as to the United 

StatesŠa fact that results in the plentitude of vulnerabilities to the 

U.S. critical infrastructure and U.S. military documented in so many 

reports.
11
Finding
 3:
 Today™s policy and legal framework for guiding and 
regulating the U.S. use of cyberattack is ill-formed, undeveloped, 

and highly uncertain.
To date, national policy regarding cybercon˚ict has focused mostly on 
the defense of friendly computer systems and networks against cyberat
-tack, although by most accounts the information technology infrastructure 
of the United States is still quite vulnerable and policy for cyberdefense 
11
 See, for example, President™s Information Technology Advisory Committee, 
Cyber 
Security: A Crisis of Prioritization
, National Coordination Of˜ce for Information Technology 
Research and Development, Washington, D.C., February 2005.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.28
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
is still uncertain.
12
 But the United States has no comprehensive publicly 
stated strategic national policy apart from a criminal framework concern
-ing how it will regard cyberattacks conducted against the United States 
or how it might use cyberattack in support of U.S. interests. The most 

relevant international legal frameworkŠthe law of armed con˚ict com
-bined with the Charter of the United NationsŠwas formulated in an era 

that long predates the information age and cyberattack, and although the 

principles of the LOAC framework still apply (Finding 6), the speci˜cs of 

applying the principles to cyberattack are sometimes uncertain.
These points illustrate the lack of a shared conceptual understanding 
about the full spectrum of issues regarding cyberattack among all of the 

stakeholdersŠmilitary, intelligence, law enforcement authorities, and the 

private sector. Such a shared understanding is a prerequisite for respon
-sible decision making about this topic.
The undeveloped and uncertain nature of this legal and policy frame
-work poses a number of dangers for the United States, not the least of 

which is that policy and law developed in a time of (or in response to) 

crisis are oftenŠsome might argue usuallyŠhastily formulated and thus 

incompletely considered. Crisis may also bias the policy consideration in 

undesirable ways. For example, arguments in favor of a particular course 

of action can be arti˜cially bolstered by crisis, and arguments against 

that course of action arti˜cially suppressed, thus bypassing the weighing 

of tradeoffs that characterizes non-crisis decision making. And unsound 

policy formulated and implemented during crisis may prove dif˜cult to 

change or reverse when the crisis has passed.
Finding 4:
 Secrecy has impeded widespread understanding and 
debate about the nature and implications of U.S. cyberattack. 
The relatively recent emergence of cyberattack technologies and the 
resulting dearth of associated policy, law, and ethics raise some very 
important issues for all sectors of society. Nevertheless, a full public 

discussion of these issues has yet to coalesce, and classi˜cation of such 

topics as being at secret or higher levels has left U.S. government think
-ing on these issues highly opaque. Such opacity has many undesirable 

consequences: 

Neither the potential importance and usefulness of cyberattack as 
12 
See, for example, National Research Council, 
Information Technology for Counterterror
-ism: Immediate Actions and Future Possibilities
, The National Academies Press, Washington, 
D.C., 2003, and National Research Council, 
Toward a Safer and More Secure Cyberspace
, The 
National Academies Press, Washington D.C., 2007.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 29
an instrument of national policy nor the potential perils and pitfalls of 
using cyberattack are well understood outside niches in the defense and 
intelligence communities. Secrecy about policy relevant to cyberattack 

inhibits public scrutiny and thus increases the likelihood that policy will 

be formulated with narrow parochial or short-term interests foremost in 

mind. 

Programs to develop cyberattack capabilities are classi˜ed and 
dispersed throughout many program elements within the Department of 

Defense, with the result that overall capabilities may not be widely known 

even among those with the necessary clearances. Effective congressional 

oversight that goes beyond a few individuals on the relevant committees 

is also inhibited.

Unclassi˜ed programs to develop stronger or more effective defen
-sive capabilities do not bene˜t from the insights derived from knowledge 

of cyberattack. Yet it is well known that many intellectual and program
-matic synergies are possible when experts in defense and attack can 

collaborate.

Independent research and investigation about the topic is inhibited, 
in particular for two groups: non-military/non-government researchers 

and DOD/intelligence community personnel (both uniformed and non
-uniformed) who do not now but may in the future need to know about 

this area. 

For the ˜rst group, the loss of independent non-governmental 
analysis increases the likelihood that the full array of national and interna
-tional intellectual capital will not be brought to bear on the issue, thereby 

depriving policy makers of its potential contributions to understanding 

the issue. (In this regard, the committee notes a 50-year history of inde
-pendent non-government analysis that has made important contributions 

to the formulation of U.S. policy regarding nuclear, chemical, and biologi
-cal weapons.) 

For the second group, it is not reasonable to expect individuals 
placed into responsible positions to get up to speed quickly if they do not 

have the basic and fundamental background knowledge needed. Yet this 

is precisely what is implied by the current regime of secrecy surrounding 

cyberattackŠDOD/intelligence community personnel in other assign
-ments have no reasonable opportunity to be exposed to the basic policy 

issues involved in cyberattack (because they have no ﬁneed to knowﬂ in 

their current duty assignments), and they are expected to be in a position 

to make sound policy judgments when they ˜ll their cyberattack billets. 

Moreover, personnel in non-cyberattack assignments need to comprehend 

the basic policy issues involved in cyberattack so that they are able to 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.30 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
understand and assess what these policy issues for cyberattack mean for 
the responsibilities of their current positions.

Dissemination even of unclassi˜ed information is inhibited by the 
broad classi˜cation of the cyberattack topic. Guidelines for the protection 
of classi˜ed information force individuals with clearances and access to 

such information to be certain that information they discuss publicly is 

indeed unclassi˜edŠotherwise, they are obligated to treat any material 

received in classi˜ed settings as classi˜ed even if the material in question 

is in fact unclassi˜ed. The result is that such individuals are reluctant to 

talk publicly about such issues at all.

Professional military education cannot explore the cyberattack 
topic in any meaningful sense. Nevertheless, professional military educa
-tion is one of the most important venues in which those military person
-nel unfamiliar with critical topics can learn about them.

Secrecy has also inhibited discussion of issues related to cyberat
-tack outside the defense context. For secrecy as well as other reasons, 

discussion about the pros and cons of cyberattack as a component of a 

comprehensive defense has been inhibited and delegitimized. Greater 

public discussion of cyberattack in a military context is likely to spur 

greater discussion of related issues in non-military contexts.
Finding
 5:
 The consequences of a cyberattack may be both 
direct and indirect, and in some cases of interest, the indi
-rect consequences of a cyberattack can far outweigh the direct 

consequences.
To the extent that there has been any public discussion about cyberat
-tack, the full range of possible effects and consequences of cyberattack is 
often not addressed. In fact, cyberattacks can have a very broad range of 

consequence, from barely noticeable by careful observers to immediately 

signi˜cant on a global scale. For this reason, any discussion of cyberat
-tack in use must address its effects. Furthermore, since the information 

available to attackers may well be limited, there will also be some range 

of uncertainty about the extent and nature of a cyberattack™s effects.
A full consideration of a cyberattack™s effects necessarily includes both 
direct (immediate) and indirect (follow-on) effects (Section 1.4). Direct or 

immediate effects are effects on the computer system or network attacked. 

Indirect or follow-on effects are effects on the systems and/or devices that 

the attacked computer system or network controls or interacts with, or on 

the people that use or rely on the attacked computer system or network. 
Another dimension of the effects issue relates to the time scale on 
which the effects of a cyberattack will be manifest. Some cyberattacks 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 31
target data or software, and such attacks are usually more easily and more 
rapidly reversed, at least in part, than are kinetic attacks on objects that 
are energetically disassembled (blown up). For example, if backup media 

are easily accessible, it may be possible to restore corrupted data and 

software to their pre-attack states relatively quickly and with only mini
-mal losses. An attacker might have the ability to restore data as well (e.g., 

some cyberattacks call for the in-place encryption of data and decrypting 

it only after hostilities terminate). But the indirect or follow-on effects are 

generally not as easily reversible in much the same way that the direct 

effects of kinetic attacks are generally not easily reversible. A cyberat
-tack on the computer controlling a generator or a dam that was in fact 

intended to disable the generator or the dam could cause the generator to 

burn itself out or the dam to release its ˚oodgates too soon. Such effects 

are kinetic in nature, and thus are only as reversible as their underlying 

physical structures are replaceable or repairable. (Even in the case where a 

cyberattack is intended to confuse the enemy (e.g., by altering data) rather 

than to cause a kinetic or physical effect, the ultimate results of that confu
-sion are likely to be dif˜cult to reverse.) Depending on the nature of the 

cyberattack, the extent of reversibility may be an additional (and possibly 

signi˜cant) factor in undertaking any analysis of its effects.
One important consequence of Finding 5 is that policy makers and 
operational commanders cannot assume that cyberattacks are non-lethal 

simply because they target computers or networksŠa fact that provides 

further support for Finding 1. The full scope of effects, both direct and 

indirect, must be taken into account in a determination of the lethality and 

other consequences of any given cyberattackŠand this is true for attacks 

launched by the United States as well as for attacks directed against the 

United States.
A second consequence is that not all cyberattacks constitute ﬁcyber
-warfare.ﬂ As a form of warfare, cyberwarfare automatically brings in all 

of the associated legal and ethical constructs associated with the term, and 

they may not apply in all cases of cyberattack. Furthermore, cyberattacks 

should not be con˚ated with cyberexploitations, as they often are in the 

popular press and in lay discussions of the topic (Box 1.4).
1.8.3
 Legal and Ethical Findings 
Much of today™s current thinking about how to engage in armed con
-˚ict originated a century ago, and thus it is not surprising that today™s 

international lawŠand especially the law of armed con˚ictŠmay not be 

entirely adequate to handle all of the implications of cyberattack technolo
-gies that have emerged only in the last few decades. The same is true of 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.32
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 1.4
 Conflation of Cyberattack and CyberexploitationŠ
Negative Consequences
Cyberattack and cyberexploitation are often con˚ated in public discourse, 
and in particular cyberexploitations are reported and discussed using the term 
ﬁcyberattack.ﬂ For example: 
Congress.
 Representative Frank Wolf (R-VA) stated on the House ˚oor in 
June 2008 that ﬁIn August 2006, four of the computers in my personal of˜ce were 

compromised by an outside source. On these computers was information about all 

of the work I have done on behalf of political dissidents and human rights activists 

around the world. . . . The FBI revealed that the outside sources responsible for 

this attack
 [emphasis added] came from within the People™s Republic of China.ﬂ
1 News organizations.
 A 
Time magazine article of 2005 stated that ﬁCar
-penter had never seen hackers work so quickly, with such a sense of purpose. 

They would commandeer a hidden section of a hard drive, zip up as many ˜les as 

possible and immediately transmit the data to way stations in South Korea, Hong 

Kong or Taiwan before sending them to mainland China. They always made a silent 

escape, wiping their electronic ˜ngerprints clean and leaving behind an almost 

undetectable beacon allowing them to re-enter the machine at will. An entire 
attack
 [emphasis added] took 10 to 30 minutes.ﬂ
2National laboratories
. In December 2007, the Oak Ridge National Labora
-tory posted a notice labeled 
Potential Identity Theft
 stating that ﬁOak Ridge National 
Laboratory (ORNL) recently experienced a sophisticated 
cyber attack
 [emphasis 
added] that appears to be part of a coordinated attempt to gain access to com
-puter networks at numerous laboratories and other institutions across the country. 

A hacker illegally gained access to ORNL computers by sending staff e-mails that 

appeared to be of˜cial legitimate communications. When the employees opened 

the attachment or accessed an embedded link, the hacker planted a program on 

the employees™ computers that enabled the hacker to copy and retrieve information. 

The original e-mail and ˜rst potential corruption occurred on October 29, 2007. We 

have reason to believe that data was stolen from a database used for visitors to 

the Laboratory.ﬂ
3The committee believes that con˚ating these terms does not contribute to an 
informed public discussion of cyberattack or the broader discussion of cybersecu
-rity. Indeed, such con˚ation has a number of negative consequences:
It overstates the actual threat, thus in˚aming public passion and beating 
the drums of war unnecessarily. It is certainly true that cyberexploitations are not 

friendly acts, but they are not armed attacks either. Most nations engage in es
-pionage even against allies and neutral nations without it leading to war or even 

armed con˚ict, and cyberexploitation is in essence a form of espionage.
Calling a cyberexploitation an attack may imply in the public mind an im
-mediate right to counterattackŠperhaps through cyber means or perhaps through 

kinetic meansŠeven though the action in question would not properly be regarded 

as a military attack. Thus, if policy makers lump together cyberexploitations and 

real cyberattacks as ﬁcyberattack,ﬂ they may well be impelled to counterattack with 

more force than is appropriate under the circumstances.
Calling cyberexploitation a cyberattack could prejudge U.S. positions and 
interests in future cyber arms control talks. With an overly broad de˜nition, the 

United States might ˜nd itself unwilling to ratify a treaty in order to preserve certain 

capabilities that fall short of actual attack, and thus end up outside international 

norms even when it might not object to limiting certain attack capabilities.
1 See http://wolf.house.gov/?sectionid=211&sectiontree=7,211&itemid=1213. The Congres
-sional Record transcript can be found at http://www.fas.org/irp/congress/2008_cr/wolf061108.
html.2 By Elaine Shannon, ﬁThe Invasion of the Chinese Cyberspies (and the Man Who Tried 
to Stop Them),ﬂ 
Time
, August 29, 2005, available at http://www.time.com/time/magazine
/article/0,9171,1098961,00.html.
3 See http://www.ornl.gov/identifytheft/.
domestic lawŠthis too has lagged behind the times in coming to terms 
with the implications of new cyberattack technologies.
Finding
 6:
 The conceptual framework that underpins the UN 
Charter on the use of force and armed attack and today™s law of 

armed con˚ict provides a reasonable starting point for an inter
-national legal regime to govern cyberattack. However, those legal 

constructs fail to account for non-state actors and for the technical 

characteristics of some cyberattacks.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 33
BOX 1.4
 Conflation of Cyberattack and CyberexploitationŠ
Negative Consequences
Cyberattack and cyberexploitation are often con˚ated in public discourse, 
and in particular cyberexploitations are reported and discussed using the term 
ﬁcyberattack.ﬂ For example: 
Congress.
 Representative Frank Wolf (R-VA) stated on the House ˚oor in 
June 2008 that ﬁIn August 2006, four of the computers in my personal of˜ce were 

compromised by an outside source. On these computers was information about all 

of the work I have done on behalf of political dissidents and human rights activists 

around the world. . . . The FBI revealed that the outside sources responsible for 

this attack
 [emphasis added] came from within the People™s Republic of China.ﬂ
1 News organizations.
 A 
Time magazine article of 2005 stated that ﬁCar
-penter had never seen hackers work so quickly, with such a sense of purpose. 

They would commandeer a hidden section of a hard drive, zip up as many ˜les as 

possible and immediately transmit the data to way stations in South Korea, Hong 

Kong or Taiwan before sending them to mainland China. They always made a silent 

escape, wiping their electronic ˜ngerprints clean and leaving behind an almost 

undetectable beacon allowing them to re-enter the machine at will. An entire 
attack
 [emphasis added] took 10 to 30 minutes.ﬂ
2National laboratories
. In December 2007, the Oak Ridge National Labora
-tory posted a notice labeled 
Potential Identity Theft
 stating that ﬁOak Ridge National 
Laboratory (ORNL) recently experienced a sophisticated 
cyber attack
 [emphasis 
added] that appears to be part of a coordinated attempt to gain access to com
-puter networks at numerous laboratories and other institutions across the country. 

A hacker illegally gained access to ORNL computers by sending staff e-mails that 

appeared to be of˜cial legitimate communications. When the employees opened 

the attachment or accessed an embedded link, the hacker planted a program on 

the employees™ computers that enabled the hacker to copy and retrieve information. 

The original e-mail and ˜rst potential corruption occurred on October 29, 2007. We 

have reason to believe that data was stolen from a database used for visitors to 

the Laboratory.ﬂ
3The committee believes that con˚ating these terms does not contribute to an 
informed public discussion of cyberattack or the broader discussion of cybersecu
-rity. Indeed, such con˚ation has a number of negative consequences:
It overstates the actual threat, thus in˚aming public passion and beating 
the drums of war unnecessarily. It is certainly true that cyberexploitations are not 

friendly acts, but they are not armed attacks either. Most nations engage in es
-pionage even against allies and neutral nations without it leading to war or even 

armed con˚ict, and cyberexploitation is in essence a form of espionage.
Calling a cyberexploitation an attack may imply in the public mind an im
-mediate right to counterattackŠperhaps through cyber means or perhaps through 

kinetic meansŠeven though the action in question would not properly be regarded 

as a military attack. Thus, if policy makers lump together cyberexploitations and 

real cyberattacks as ﬁcyberattack,ﬂ they may well be impelled to counterattack with 

more force than is appropriate under the circumstances.
Calling cyberexploitation a cyberattack could prejudge U.S. positions and 
interests in future cyber arms control talks. With an overly broad de˜nition, the 

United States might ˜nd itself unwilling to ratify a treaty in order to preserve certain 

capabilities that fall short of actual attack, and thus end up outside international 

norms even when it might not object to limiting certain attack capabilities.
1 See http://wolf.house.gov/?sectionid=211&sectiontree=7,211&itemid=1213. The Congres
-sional Record transcript can be found at http://www.fas.org/irp/congress/2008_cr/wolf061108.
html.2 By Elaine Shannon, ﬁThe Invasion of the Chinese Cyberspies (and the Man Who Tried 
to Stop Them),ﬂ 
Time
, August 29, 2005, available at http://www.time.com/time/magazine
/article/0,9171,1098961,00.html.
3 See http://www.ornl.gov/identifytheft/.
The committee believes that the conceptual framework that under
-pins the UN Charter and today™s law of armed con˚ict regarding the use 
of force and armed attack is generally consistent with the notion that the 

effects of an action rather than the modality of that action are the primary 

measure in judging its legality under the UN Charter or LOAC. 
Prior to an acknowledged armed con˚ict, the legal status of any mili
-tary activity is judged by its effects (regardless of the means) according 

to the criteria of the UN Charter and 
jus ad bellum
. Therefore, if the effects 
(including both direct and indirect effects) to be produced by a cyberat
-tack would, if produced by other means, constitute an armed attack in the 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.34 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
sense of Article 51 of the UN Charter, it should be treated as an armed 
attack. Similarly, if a cyberattack would have the same effects as certain 
governmentally initiated coercive/harmful actions that are traditionally 

and generally not treated as the ﬁuse of forceﬂ (e.g., economic sanctions, 

espionage, or certain covert actions), such a cyberattack should also not 

be regarded as a use of force. 
Article 51 acknowledges the conditional right of a nation to engage in 
the use of armed force for self-defense, including the situation in which 

the nation is the target of an armed attack, even without Security Council 

authorization. Thus, the response to a cyberattack by acts constituting use 

of force is legal, permitted, and proper only if and whenŠbut de˜nitely if 

and whenŠthe effect of the initial action is equivalent to the effect of an 

armed attack. If the initial provocation does not rise to the level of being 

an armed attack, it is not legal to respond with any act that constitutes the 

use of force, whether cyberattack or otherwise.
The committee also concurs in the judgment of the U.S. armed forces 
that during acknowledged armed con˚ict (notably when kinetic and other 

means are also being used against the same target nation), military use 

of cyberattack is governed by all the standard LOAC criteria of 
jus in 
bello
Šmilitary necessity (and seeking the destruction only of legitimate 
targets that make a direct contribution to the enemy™s war effort), pro
-portionality (and thus pursuing offensive action only when the military 

advantage to be gained by the attack outweighs the collateral damage that 

would ensue), and distinction (restricting combatants and non-combat
-ants to their legitimate roles in return for the different legal protections 

afforded to them). 
At the same time, the framework underpinning existing law is poorly 
suited to deal with certain aspects of cyberattack. One major complicating 

factor in the analysis of cyberattacks is that although the law of armed 

con˚ict continues to govern the use of cyberattacks by the U.S. armed 

forces (and in principle, by other nations as well), LOAC is based on 

a state-to-state framework and thus largely assumes interstate con˚ict. 

But today, and especially in cyberspace, non-state actors (e.g., terror
-ist groups, organized crime) are entirely capable of engaging in armed 

con˚ict, as are individuals acting on their own with putatively ﬁpatri
-oticﬂ motivationsŠand the lines between state, non-state, and individual 

attackers are unclear in a legal regime that focuses primarily on LOAC on 

the one hand and national criminal laws on the other. International agree
-ments, such as the Convention on Cybercrime (Section 7.2.4), will help to 

increase the effectiveness of criminal law in dealing with cyberattacks, 

but it is likely that some gray area will always exist between LOAC and 

criminal law when certain kinds of cyberattack occur.
Of course, the notion that a threat might emanate from a non-state 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 35
actor is not unique to the domain of cyberattack. Terrorists seeking to 
in˚ict kinetic damage often operate from a neutral nation™s territoryŠand 
indeed, using cyberattack as an instrument against non-state actors brings 

into play many of the issues that arise in ˜ghting terrorists. For example, 

self-defense against attacking parties in neutral territory (discussed in 

Section 7.2.2.2.4) can easily become relevant to a decision to launch a 

counter-cyberattack against a cyberattack apparently emerging from a 

neutral nationŠand the structure of the process used in deciding this 

case would be very similar to the decision-making process used in decid
-ing whether to launch a kinetic attack against terrorists operating from a 

failed state.
A second complicating factor is related to various technical charac
-teristics of cyberattacks that may be carried over the Internet. Today, the 

United States is undertaking major efforts to monitor Internet activity for 

indications of hostile intent. For example, the DOD, under the auspices 

of the U.S. Strategic Command, monitors attacks on DOD systems. A 

variety of computer emergency response teams and commercial anti-

virus/worm-detection ˜rms also continually monitor Internet network 

operations for indications of threat warning. These monitoring efforts are 

likely to provide some degree of ﬁearly warningﬂ for impending cyberat
-tacks conducted over the Internet, although that time may be measured 

in seconds. As such an attack unfolds, its scope and effects may become 

clearer as well.
However, these efforts at Internet surveillance will not necessarily 
reveal planning and preparation of the attack, nor intent or even origin. 

Neither does surveillance reveal aspects of the attack that take place at 

protocol levels below the monitoring sensors, or above them if concealed. 

(For example, a cyberattack may be deliberately designed to hide the 

extent and nature of the damage it causes. In addition, an adversary™s 

battle˜eld preparation for a cyberattack (e.g., installing easy-to-use back 

doors) may be done surreptitiously, thus making it dif˜cult for the victim 

to know the scope and nature of the preparation.) Because LOAC and the 

UN Charter presume not only nation-states in con˚ict but also that the 

speci˜c nation-states involved are known to all, the dif˜culty of attribut
-ing a cyberattack in its early stages to a particular actor, which may be a 

state or a non-state actor, remains a major challenge to the current legal 

regime. Thus, the United States may know that it has suffered an ﬁarmed 

attackﬂ or been the target of a ﬁuse of force,ﬂ but it may take a long time 

to determine the party or parties responsible.
Finally, because so much of LOAC and the UN Charter is based on the 
idea that civilian and military assets can be separated, the intermingling 

and interconnection of military and civilian information technology assets 

and the importance of a nation™s critical infrastructure to both military and 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.36
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
civilian activities will present challenges to today™s LOAC/UN Charter 
regime. Even with the intent to comply with LOAC and the UN Charter, 
policy makers will face many dif˜culties in arriving at sound judgments 

regarding events involving cyberattack, whether the United States is the 

victim or the launcher of a cyberattack.
Finding
 7:
 In today™s security environment, private parties have 
few useful alternatives for responding to a severe cyberattack that 

arrives over a network such as the Internet.
When a private party is the target of a cyberattack that arrives over a 
network such as the Internet, it has four options for responding. First, it 
can implement passive measures to strengthen its defensive posture. For 

example, it can drop functionality on its own systems that the attacker is 

trying to exploit, reject traf˜c, and close ports on its ˜rewall. Second, it 

can report the event to law enforcement authorities, and law enforcement 

authorities can take appropriate action to try to shut down the cyberattack 

(e.g., by ˜nding the perpetrator and arresting him, but not by launching 

a cyber counterattack). Third, it can take self-help measures to further 

investigate and characterize the source of the cyberattack and then report 

the information to appropriate law enforcement authorities. Fourth, it can 

take actions to actively neutralize the incoming cyberattack.
The ˜rst two options are generally legal under U.S. domestic law. 
But the ˜rst option may cause the victim to lose the bene˜t of essential 

computer and network services and connections. With respect to the 

second option, law enforcement authorities may not be able to respond 

effectively on a time scale that will prevent signi˜cant immediate harm 

to the victim, although arrest and prosecution might provide a possible 

venue for restitution. That is, there appears to be no government agency 

that has the legal authorization to perform a ﬁharm cessationﬂ function 

apart from the arrest-and-prosecute mode.
Furthermore, the appropriate and relevant law enforcement authori
-ties are not always easily identi˜ed. If a U.S. ˜rm with of˜ces in Japan is 

cyberattacked in Japan by the Russian mob, are the cognizant law enforce
-ment authorities American (because the ˜rm is a U.S. ˜rm), Japanese 

(because that was the place where the consequences were manifested), or 

Russian (because Russia was the national home of the bad attackers)?
If the ˜rst two options are not suf˜cient to keep losses to an accept
-able level, the victim might understandably consider the third and fourth 

options. That is, if the victim is unable to strengthen its defenses without 

losing essential functionality, and law enforcement authorities cannot 

prevent further harm, self-help options gain in attractiveness.
However, regarding option three, it may well be illegal under both 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 37
the Computer Fraud and Abuse Act (CFAA) and the Electronic Commu
-nications Protection Act for the victim to investigate and characterize the 
attack and attacker by initiating probes of its own, even if such informa
-tion would be useful for law enforcement authorities in conducting their 

own investigation. 
Option four likely violates the CFAA, which forbids private individu
-als and organizations to intentionally cause damage in excess of $5,000, 

without authorization, to any computer ﬁused in interstate or foreign 

commerce or communication, including a computer located outside the 

United States that is used in a manner that affects interstate or foreign 

commerce or communication of the United States.ﬂ Still, limited rights 

regarding the defense of property intended to prevent continuing harm 

have traditionally been afforded to victims of attack under some circum
-stances even in the absence of explicit legislative authority for actions 

taken in the defense of property. In short, even a private party under 

continuing cyberattack may itself have some rights to use a cyberattack 

of its own to stop the incoming cyberattack. 
To the best of the committee™s knowledge, defense of property has 
never been invoked in a defense against charges of violating the CFAA, 

and so the legal justi˜ability of such actions is subject to some doubt. 
At the same time and regardless of the legality of such actions, exer
-cise of such rights may well be problematic both for the attacked party 

and for the nation at large from a policy perspective:

The particular conditions necessary to invoke rights to defense 
of property are not clearly speci˜ed anywhere, and thus some degree of 

legal uncertainty necessarily attaches to such actions.

Because many kinds of cyberattack can be transmitted across large 
distances, cyber actions taken to respond to a cyberattack will almost 

inevitably invade the premises of the attacker.

Actions taken by the attacked party may be attributed to the gov
-ernment with responsible authority over it, especially if government stan
-dards governing the invocation of such rights are established.

Given the dif˜culties of technical attribution of a cyberattacker, a 
victim undertaking a responsive cyberattack has a non-negligible chance 

of striking innocent third parties, making defense of property in this con
-text far more problematic than the defense engaged in by a homeowner 

shooting at a home intruder.
Finding
 8:
 Cyberattack poses challenges to existing ethical and 
human rights regimes.
As noted in Chapter 7, the laws of armed con˚ict are based on two 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.38
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
central ethical principlesŠthat the use of force or violence against another 
state must be justi˜ed by ﬁgoodﬂ reasons for doing so, and that even if 
violent con˚ict between nations is inevitable from time to time, unneces
-sary human suffering should be minimized. To the extent that the laws 

of armed con˚ict govern the use of cyberattack, cyberattack is not a 
sui 
generis
 phenomenon that is incompatible with these ethical principles. 
On the other hand, cyberattack can complicate the application of these 
ethical principles. For example, the argumentation for Finding 6 noted 

the complications introduced into today™s legal regime by the dual-use 

nature of today™s information technology infrastructure. This dual-use 

nature also complicates ethical judgments that have traditionally been 

based on the notion of separating civilian and military assets, and the 

need for making such judgment may well be relevant in situations short 

of acknowledged armed con˚ict in which LOAC is held to apply.
The possibility of extended cyberattacks on a society™s information 
technology infrastructure also raises the question of whether the IT-

dependent features of modern society are in any sense essential to life as 

the citizens of that society know it. For example, the citizens of a large 

nation often use credit cards to conduct retail transactions. If a cyberattack 

on the ˜nancial infrastructure disrupted the ability of citizens to conduct 

electronic transactions for an extended period of time without causing 

large-scale death or destruction of property, what, if any, is the ethical 

responsibility of the nation launching the attack? Estonia, for example, 

has gone so far as to declare that Internet access is a fundamental right 

of its citizenry.
13
 An extended cyberattack campaign against a modern 
nation that deprived citizens only of such features of modern life (and 

did not cause large-scale death or destruction of property) might still be 

reasonably considered a use of force by the attacked nation and the world 

community and/or a human rights violation of the citizens of the attacked 

nation by the attacker.
The International Covenant on Civil and Political Rights articulates 
one current international understanding of human rights. But although a 

number of its provisions can be argued to be relevant to the cyber domain, 

it is reasonably clear that the framers of that convention did not take 

explicit account of the possibility that cyberattacks might affect human 

rights. The United States has argued that the convention does not apply 

extraterritorially, and hence it would not regulate U.S. behavior regarding 

other countriesŠhowever, as a practical matter, the role of human rights 

law during con˚ict is contested internationally, and there is no reason to 

expect that cybercon˚ict will be exempt from this debate.
13
 Colin Woodward, ﬁEstonia, Where Being Wired Is a Human Right,ﬂ 
Christian Science 
 Monitor,
 July 1, 2003, available at http://www.csmonitor.com/2003/0701/p07s01-woeu.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 39
Finally, if cyberattack capabilities are seen as providing policy makers 
with an alternative short of using traditional kinetic armed force in the 
conduct of their international relations (Section 8.4), they may increase the 

likelihood that national leaders will choose to intervene when they might 
otherwise have refrained from intervention.
  Such an outcome may raise 
ethical and moral issues as well.
1.8.4
 Policy Findings 
Finding
 9:
 Enduring unilateral dominance in cyberspace is nei
-ther realistic nor achievable by the United States. 
In the event that con˚ict does occur, U.S. military doctrine seeks dom
-inance in the relevant domains of con˚ictŠthat is, U.S. freedom of action 
in any domain of con˚ict (including cybercon˚ict) coupled with denying 

U.S. adversaries the same freedom of action.
14
 Dominance requires supe
-riority in both offensive and defensive capabilities. 

Many cyberattack technologies are inexpensive and easily avail
-able to non-state actors, including individuals, and these technologies 

include some that are as capable of doing great harm as those available to 

governments. Much of the expertise needed to wield cyberattack weap
-ons effectively is widespread. These points, discussed further in Chapter 

2, suggest that the United States cannot maintain overall dominance in 

cyberattack capabilities for any extended period of time.

With respect to cyberdefense, current trends in information tech
-nology development and deployment suggest that exploitable vulner
-abilities will continue to be present in both civilian and military computer 

systems and networks of the United States. Thus, the U.S. information 

technology infrastructure is likely to remain vulnerable to cyberattack for 

the foreseeable future.
15
Thus, cybercon˚ict is quite unlike the land, air, and maritime domains 
in which U.S. armed forces operate, and enduring unilateral dominance 
14
 According to the Joint Chiefs of Staff, joint force commanders are called upon to ﬁseek 
superiority early in air, land, maritime, and space domains and the information environment 
to prepare the operational area and information environment and to accomplish the mission 

as rapidly as possible.ﬂ Joint Publication 3-0, 
Joint Operations,
 February 13, 2008, available at 
http://www.dtic.mil/doctrine/jel/new_pubs/jp3_0.pdf.
15
 In addition, another nation may impose by decree cybersecurity measures on all 
information technology used by that nation or it may impose and enforce a strong separa
-tion between the information and information technology infrastructures for military and 

civilian use. Such a nation would likely have advantages in a cybercon˚ict with the United 

States, which does not do either of these things.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.40
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
with respect to cybercon˚ict is not realistically achievable by the United 
States. This does not mean that the United States should refrain from 
developing cyberattack capabilitiesŠonly that it should not expect endur
-ing advantage from such development.
Finding
 10:
 The United States has much to lose from unrestrained 
cyberattack capabilities that are proliferated worldwide.
The United States is highly dependent on the capabilities afforded 
by ubiquitous information technology in every sector, both military and 
civilian. Consequently, the United States has much to lose from unre
-strained cyberattack capabilities that are proliferated worldwide. (Some 

analysts also make the further argument that the United States would 

have the 
most
 to lose compared to any other nationŠan assessment that 
is plausible but that depends on relative judgments about the dependence 

on information technology of various nations. The committee would not 

dispute that conclusion if it were accompanied by a defensible analysis, 

but it was not willing to make that assessment itself.)
In addition, comparing the as-yet-unproven utility of U.S. cyberattack 
against its adversaries to the demonstrated growing dependence of the 

United States on information technology, it is generally more important 

for the United States to be able to use information technology freely in 

pursuit of its national interests than for it to be able to deny adversaries 

the use of their own systems and networks. However, this conclusion 

does not rule out the possibility that cyberattacks by the United States will 

be an appropriate and useful action under some circumstances, although 

it does emphasize the importance of protecting the U.S. information tech
-nology infrastructure.
Finding 11: 
Deterrence of cyberattacks by the threat of in-kind 
response has limited applicability.
In general, deterrence of adversaries is the cornerstone of U.S. mili
-tary strategy. Deterrence seeks to promote stability by persuading an 
adversary to refrain from taking aggressive actions against U.S. interests. 

Deterrence is based on two elementsŠpunishment and denial. Deterrence 

by punishment threatens to in˚ict unacceptable costs on an adversary that 

takes aggressive actions. If he knows he will suffer such costs should he 

take such actions, he will refrain from taking them. Deterrence by denial 

seeks to deny the adversary success from his aggressive actions. If he 

knows his aggressive actions will not result in success, he will refrain 

from taking them. 
As applied to cybercon˚ict, deterrence is complex. For the most 
part, defensive capabilities contribute to deterrence by denial, and attack 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 41capabilities contribute to deterrence by punishment. Actions taken to 
strengthen important U.S. computer systems and networks promote 
deterrence by denial, but for a host of reasons described in Chapter 2 and 

in other reports,
16
 the gap between defensive capabilities and the adver
-sarial cyberattack threat is large and growing today. 
Deterrence by punishment is more likely to be an effective strategy 
against nations that are highly dependent on information technology, 

because such nations have a much larger number of potential targets that 

can be attacked. Nevertheless, even nations with a less technologically 
sophisticated national infrastructure are probably vulnerable to cyber
-attack in selected niches. 
A cyber aggressor also knows the time of his cyberattack, and can take 
action to mitigate the punishment that will follow his attack. The aggres
-sor can take steps to invalidate the intelligence information on cyber 

targets that the defender has already collected on him, and thus can force 

the defender into either a non-selective retaliation or a retaliation delayed 

until new intelligence information can be collected. In the ˜rst case, the 

defender may not be willing to risk the large-scale escalation that might 

accompany a non-selective retaliatory cyberattack, and in the second case, 

the aggressor may have already achieved its objectives by the time a new 

retaliatory strike can be planned.
Perhaps most importantly, deterrence by punishment requires knowl
-edge of an adversary™s identityŠanonymous adversaries cannot be pun
-ished. As noted in Chapter 2, today™s information technology makes it 

easy for evildoers to act anonymouslyŠand even in the event that new 

information technologies are developed with stronger authentication 

capabilities, there is always the risk that an authenticated computer could 

be improperly compromised to conduct aggressive action. On the other 

hand, an actionable degree of attribution might be possible by making use 

of non-technical information. Policy makers seeking absolute and unam
-biguous technical proof that a speci˜c party is responsible for a cyberat
-tack will almost certainly be disappointed in any real-life incident, and 

may ultimately be forced to rely on non-technical information more than 

they would prefer. The bottom line is that it is too strong a statement to 

say that plausible attribution of an adversary™s cyberattack is impossible, 

but it is also too strong to say that de˜nitive and certain attribution of an 

adversary™s cyberattack will always be possible.
Assuming that the adversary™s identity can be known, there is no 
reason that a retaliatory cyberattack would necessarily be favored over 

a retaliatory kinetic attack. A variety of considerations might apply to 

choosing the retaliatory mode. For example, a ﬁtit-for-tatﬂ retaliatory 
16
 See, for example, National Research Council, 
Toward a Safer and More Secure Cyber
-space
, The National Academies Press, Washington, D.C., 2007. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.42 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
response against an adversary might call for a cyberattack of compa
-rable scale against a comparable target. However, a threat to do so might 
not be credible if the United States has a great deal to lose from such 

an action, thus throwing doubt on the viability of an ﬁin-kindﬂ deter
-rence strategy. On the other hand, a near-peer competitor might well be 

deterred from launching a large-scale cyberattack by the knowledge that 

it too would have much to lose if the United States launched an in-kind 

counterattack.
If an access path is available to the adversary, it may be reasonable 
to use attack capabilities to neutralize an incoming cyberattack even if 

the identity of the adversary is not known. By developing capabilities to 

deny the adversary a successful cyberattack, the United States might be 

able to deter adversaries from launching at least certain kinds of cyberat
-tack against the United States. Yet neutralization is likely to be dif˜cultŠ

destroying or degrading the source of a cyberattack may simply lead the 

adversary to launch the attack from a different source. Deterrence also 

relies on the adversary™s belief that the United States is indeed capable of 

neutralizing its attackŠand such capabilities may well have to be dem
-onstrated in order to induce that belief. But a demonstration may provide 

an adversary with ways of defending against those capabilities, and so 

the fragility of cyberweapons, noted in Chapter 2, may itself provide dis
-incentives for the United States to provide such demonstrations. These 

disincentives may 
raise
 the thresholds at which the United States is willing 
to use those particular weapons. Thus, neutralization may be an appropri
-ate response strategy, but whether a threat to neutralize an adversary™s 

attack is a reasonable basis for a strategy of deterrence through denial 

remains to be seen.
As for the tailored deterrence discussed in Chapter 9, that concept is 
premised on an understanding and a knowledge of speci˜c adversaries. 

Indeed, it presumes that such knowledge is available 
in ad
vance
 as the 
basis for tailoring a deterrence strategy against that particular adversary. 

But by de˜nition, deterrence cannot be tailored to an adversary about 

whom nothing is known.
Against non-state parties, deterrence by punishment may be par
-ticularly ineffective, as noted in Section 9.3. First, a non-state group may 

be particularly dif˜cult to identify. Second, it is likely to have few if any 

information technology assets that can be targeted. Third, some groups 

(such as organized hacker groups) regard counterattacks as a challenge 

to be welcomed rather than something to be feared. Fourth, a non-state 

group such as a terrorist or insurgent group might seek to provoke cyber 

retaliation in order to galvanize public support for it or to antagonize the 

public against the United States.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 43Finding 12: 
Options for responding to cyberattacks on the United 
States span a broad range and include a mix of dynamic changes 
in defensive postures, law enforcement actions, diplomacy, cyber
-attacks, and kinetic attacks.
Today, important information systems in the United States are subject 
to innumerable hostile actions on a daily basis from a variety of actors 
ranging from teenagers acting on their own to major nation-states.
17
 An 
important question for policy makers to address is thus, How should the 

United States respond to such attacks? And if or when the nature of cyber
-attacks changes in the future, how should it respond to those attacks?
Such questions cannot be addressed in the absence of speci˜c facts. 
But it is important to understand that the United States has a multitude 

of options for responding to any given cyberattack, depending on its 

scope and character; these options include a mix of dynamic changes in 

defensive postures, law enforcement actions, diplomacy, cyberattacks, 

and kinetic attacks. Put differently, the United States is in no way obli
-gated to employ an in-kind response to a cyberattack, even if an in-kind 

response may super˜cially seem most obvious or natural.
Some of the potential responses are less escalatory (e.g., changes 
in defensive postures), others more so (e.g., retaliatory cyberattacks or 

kinetic attacks). Implementing less escalatory responses would seem to 

require lower levels of authority than would more escalatory responses, 

and thus would be more easily undertaken.
1.8.5
 Technical and Operational Findings
Cyberattack technologies are a relatively new addition to the tech
-nologies of warfare. 
Finding 13: 
For many kinds of information technology infra
-structure targets, the ease of cyberattack is increasing rather than 

decreasing. 
Many recent reports have noted that the increasing use of informa
-tion technology in existing and new infrastructure in the United States is 
increasing the vulnerability of that infrastructure. For example, 
Toward a 
Safer and More Secure Cyberspace
 notes that an increasing dependence on 
information technology applications in all walks of life has resulted in 
17
 See, for example, Dennis Blair, Director of National Intelligence, 
Annual Threat As
-sessment of the Intelligence Community for the Senate Select Committee on Intelligence
, February 
12, 2009, available at http://intelligence.senate.gov/090212/blair.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.44
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
vulnerabilities being created faster than they can be found and ˜xed.
18
 Because the culture of information technology development in the United 
States does not promote security, new technologies, new architectures, and 

new applications result in new opportunities for attack. Old technologies 

and legacy systems also exhibit signi˜cant vulnerabilities because retro˜t
-ted security is often much less effective than security that is ﬁdesigned inﬂ 

from the start. The times required for defenders to repair security holes 

are long compared to the times required for attackers to develop new 

attacks. Many individuals and institutions do not know how to defend 

themselves because it is hard to do, and this is especially true of end users 

and small organizations.
These comments are also likely to be true for many other parties as 
wellŠto the extent that other nations are becoming dependent on infor
-mation technology, there is no reason to suppose that they do not suffer 

from the same kinds of vulnerabilities. This is not to say that cyberattack 

on certain speci˜c targets will not be very dif˜cult, or that all cyberat
-tacks can be assured of success with high probability. But on average and 

as argued in many reports,
19
 the gap between the attacker™s capability to 
attack many vulnerable targets and the defender™s inability to defend all 

of them is growing rather than diminishing. 
Finding 14: 
Although the actual cyberattack capabilities of the 
United States are highly classi˜ed, they are at least as powerful 

as those demonstrated by the most sophisticated cyberattacks 

perpetrated by cybercriminals and are likely more powerful.
The cyberattack capability of a major nation-state (such as the United 
States) is almost certainly greater than that of the individual hacker or 
even the most talented cybercriminals. Such greater capability arises pri
-marily from the resources available to nation-states rather than from 

fundamental differences in the base technologies available. A nation-state 

can draw on the services of its intelligence services and the funds in its 

national treasury, has enormous in˚uence with the private sector compa
-nies over which it has jurisdiction, and is more than willing to bribe or 

extort to compromise a trusted insider if that is a cost-effective route to its 

objectives. In addition, it is entirely possible that certain technical prob
-lems have solutions that are today classi˜ed and thus not available to the 
18
 National Research Council, 
Toward a Safer and More Secure Cyberspace
, The National 
Academies Press, Washington D.C., 2007. 
19
 See, for example, National Research Council, 
Information Technology for Counterterror
-ism: Immediate Actions and Future Possibilities
, The National Academies Press, Washington, 
D.C., 2003; and National Research Council, 
Toward a Safer and More Secure Cyberspace
, The 
National Academies Press, Washington, D.C., 2007.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 45world at large. In the domain of cryptography, it is known that the British 
Government Communications Headquarters (GCHQ; the UK equivalent 
of the National Security Agency) knew of public key encryption and in 

particular of the RSA algorithm for public key encryption several years 

before they were announced in the open literature.
20
 Thus, one might rea
-sonably presume that there may well be technical approaches to various 

forms of cyberattack that are known, at present, only on the ﬁinside.ﬂ
The open literature documents a variety of sophisticated cyberattacks 
and cyberexploitations that have been used by criminals, and tools for 

these activities available to them. It is thus reasonable to posit that some 

of the tools available to nation-states are more sophisticated versions of 

criminal tools, that the associated procedures and practices are also more 

sophisticated versions of social engineering, and that the intelligence ser
-vices of nation-states have greater capabilities with respect to cyberattacks 

that depend on some kind of close access. Put differently, the cyberat
-tack capabilities of a major nation-state are at least as capable as those of 

sophisticated cybercriminals from a technical standpoint, and the attacks 

undertaken by such parties have been sophisticated indeed.
The comments above notwithstanding, non-state actors have certain 
advantages over nation-states. Non-state actors are known for their ability 

to act and react more nimbly. Neither terrorists nor criminals are subject 

to the often-ponderous processes of governmental oversight, which sug
-gests that they may be able to move faster to take advantage of emergent 

opportunities for cyberattack (e.g., the approvals needed to conduct a 

cyberattack are likely to be fewer than in the U.S. government). Nor are 

they likely to adhere to either the letter or spirit of the laws of armed 

con˚ict in conducting their cyberattacks, which suggests that their plan
-ning is likely to be simpler and face fewer constraints (e.g., they can avoid 

the need to minimize collateral damage). And in a search for technical 

expertise and talent, they can often offer ˜nancial compensation that 

far exceeds anything that the U.S. government can legitimately offer its 

employees or troops. Whether such advantages offset the nation-state™s 

superiority of resources and access regarding actual operations and the 

best use of available capabilities is not clear.
Finding 15: 
As is true for air, sea, land, and space operations, the 
defensive or offensive intent motivating cyber operations in any 

given instance may be dif˜cult to infer. 
20
 Peter Wayner, ﬁBritish Document Outlines Early Encryption Discovery,ﬂ 
New York 
Times
, December 24, 1997, available at http://www.nytimes.com/library/cyber/week/
122497encrypt.html#1.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.46 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
This report distinguishes between different kinds of cyber actions 
(that is, cyber actions with different effects) and different intents (whether 
an action is carried out with offensive or defensive intent). A useful anal
-ogy is military mines. From a technological standpoint, a mine is an 

explosive device designed to explode (for example) on contact with a 

vehicle or a vessel. But it can be used for both defensive and offensive 

purposes. U.S. mines in the Korean demilitarized zone are intended to 

slow a North Korean attack, and their deployment is thus defensive in 

intent. U.S. mines in Nicaraguan ports were intended to contribute to the 

economic isolation of Nicaragua, and thus their deployment was offensive 

in intent.
Similarly, a U.S. cyberattack against a speci˜c Zendian computer sys
-tem may be conducted in order to stop an attack on U.S. systems emanat
-ing from that Zendian system (a defensive use), or it may be conducted 

in order to cripple a military computer system in anticipation of a U.S. 

kinetic attack on Zendia (an offensive use). Such issues affect perception 

across national boundaries as wellŠwhat the United States regards as a 

defensive action another nation may regard as an offensive action. And 

both perceptions would have some factual basis. 
Furthermore, and as noted in Section 9.2.2, it may be more dif˜cult 
to discern or assess intent when cyberattack is involved than when tradi
-tional military forces are involved. From a policy perspective, this point 

regarding the dif˜culty of inferring intent is signi˜cant when the United 

States is the target of cyberattacks as well as when it conducts cyberat
-tacks. The strategic signi˜cance and societal effect of a cyberattack on the 

United States originating with an overly curious teenaged hacker in San 

Diego or in Mexico City is not the same as one originating from Zendia™s 

342nd Information Operations regiment, although in the initial stages of 

a cyberattack on the United States, it may not be entirely clear which of 

these parties is behind it. At the same time, if an adversary is uncertain 

about the intent behind a cyberattack emanating from the United States, 

its reaction may well be may be hard to predict.
Finding 16: 
Certain cyberattacks undertaken by the United States 
are likely to have signi˜cant operational implications for the U.S. 

private sector. 
The private sector owns and operates much of the infrastructure 
through which certain cyberattacks might be transmitted and also has 
a signi˜cant stake in the continuing operation of that infrastructure, in 

particular the Internet. Thus, cyberattacks launched through the Inter
-net may well have implications for and impacts on other non-military 

national interests. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 47It is not new that military decision makers must consider the impact 
of such decisions on other parties; for example, military decision makers 
have long known that reducing the availability of GPS satellites could 

have a major impact on non-military transportation, and efforts to jam 

adversary radars might impact non-military communications. However, 

in many such instances, the impacts could be spatially localized, e.g., by 

reducing the availability of GPS satellites only in the theater of con˚ict. 

Furthermore, because the adversary has been assumed to be con˜ned to a 

particular geographic theater, adversary reactions to U.S. offensive opera
-tions have been con˜ned as wellŠthus allowing non-military national 

activities outside the theater to be pursued under more or less normal 

conditions. 
However, the Internet portion of cyberspace is entirely shared between 
military and civilian uses and between the United States and adversaries. 

Thus, the U.S. private sector must be prepared to deal with the conse
-quences should the United States take actions that provoke in-kind coun
-terattack by an adversary. In addition, the United States must consider the 

possibility that a cyberattack of its own, carried over the Internet, might 

be detected by U.S. Internet service providers carrying that traf˜cŠand 

then shut down in the (mistaken) belief that it was an attack being carried 

out by hackers or another nation.
Lastly, U.S. cyberattacks that are directed against globally shared 
infrastructure supporting the private sector might have deleterious ﬁblow
-backﬂ effects on U.S. private sector entities. Such effects might be direct, in 

the sense that a U.S. cyberattack might propagate to harm a U.S. ˜rm. Or 

they might affect the supply chain of a U.S. ˜rmŠa node in Zendia might 

support communications between a key U.S. ˜rm and a supplier ˜rm in 

Ruritania as well as military communications in Zendia, and a disabling 

cyberattack on that node might leave the U.S. ˜rm without the ability to 

order goods from the Ruritanian ˜rm.
Finding 17: 
If and when the United States decides to launch 
a cyberattack, signi˜cant coordination among allied nations 

and a wide range of public and private entities may be neces
-sary, depending on the scope and nature of the cyberattack in 

question.
Signi˜cant amounts of coordination with multiple parties may be 
required if and when the U.S. government contemplates the use of cyber
-attack. Although cyberattacks that are narrowly focused on highly spe
-ci˜c objectives may not have much potential for interfering with other 
ongoing cyber operations initiated by other parties, a suf˜ciently broad 

cyberattack might indeed interfere. In such cases, it may be necessary to 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.48 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
coordinate among a number of parties, including various U.S. govern
-ment agencies and allied nations. All of these parties may have various 
cyber operations underway that might interfere with a U.S. cyberattack on 

an adversary. In addition, these agencies and nations would likely bene˜t 

from the strengthening of their defensive postures that could occur with 

advance notice of a possible in-kind response. The same considerations 

apply to private sector operators of information infrastructure that would 

be likely targets of an adversary™s in-kind response to a U.S. cyberat
-tack and for which advance notice of cyberattack would be helpful in 

strengthening their defensive posture, although selective noti˜cation for 

operators of U.S. information technology infrastructure may raise issues 

of discrimination comparable to those that led to the State Department™s 

adoption (after the Pan Am 103 bombing) of a policy of not warning gov
-ernment employees of a terrorist threat without making a general public 

announcement of the threat. Certain kinds of cyberattack may require 

the cooperation of various vendorsŠe.g., virus attacks that depend on 

disabling antivirus protection supplied by U.S. or foreign vendors or 

denial-of-service attacks requiring increased bandwidth supplied by U.S. 

or foreign Internet service providers.
Finally, the United States is likely to have in its midst ﬁpatriotic 
hackersﬂŠU.S. citizens and others who are strongly motivated to take 

direct action in putative support of an overt U.S. confrontation with 

another nation. These individualsŠprivate citizens with some skills in 

the use of cyberattack weaponsŠmight well launch cyberattacks on an 

adversary nation on their own initiative, that is, without the blessing and 

not under the direction or control of the U.S. government. Such actions 

might interfere tactically with operations planned by the U.S. govern
-ment, and strategically they might be misinterpreted by the party being 

attacked as intentional U.S. actions and thus complicate the conduct of 

diplomatic action. 
Thus, the U.S. government would have to be prepared to discour
-age their actions using all legal means at U.S. disposal (e.g., through 

law enforcement authorities seeking to enforce the Computer Fraud and 

Abuse Act against these patriotic hackers) and would have to anticipate 

in its planning the actions that were not discouraged. Such means are not 

limited to prosecution (which would almost surely require a time scale 

much longer than that of a U.S. cyberattack); other legal means are often 

available to shut down the operational capability of a patriotic hacker, 

including arrest, seizure of the computer involved, disconnection from 

the Internet service provider that the hacker uses, and so on. 
In extreme cases, the agency conducting the cyberattack might also 
˜nd it necessary to conduct a cyberattack to neutralize the civilian sys
-tem involved in this unhelpful hacker activity. Clear standards, thresh
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 49olds, and approval requirements would be necessary if such action were 
contemplated, and higher authority would have to consider a variety of 
questions. What sort of ﬁinterferenceﬂ with a U.S. cyberattack is enough 

to justify an attack on a civilian U.S. system? What sort of circumstances 

would warrant such an attack? Need legal methods be attempted ˜rst? 

What level of certainty must exist about the involvement of the site before 

it can be attacked? Who must give the approval? 
Finding 18: 
The outcomes of many kinds of cyberattack are likely 
to be more uncertain than outcomes for other kinds of attack.
Although planners for any kind of attack, kinetic or cyber, must take 
into account many uncertainties about the characteristics of the target 
and the environment around it, the intelligence information needed for 

a successful cyberattack (e.g., details of cabling between two systems) is 

often dif˜cult to obtain through traditional methods such as remote photo 

reconnaissance. Such uncertainties can increase signi˜cantly the likelihood 

of unintended and/or unanticipated consequences. By contrast, many of 

the uncertainties in kinetic targeting can be calculated and bounded, and 

most of the remaining uncertainties relate to matters such as target selec
-tion and collocation of other entities with the intended target.
These comments should not be taken to imply that the mere pres
-ence of uncertainty renders cyberweapons inherently unusable. In some 

cases, operational or policy goals may require ﬁtaking a chanceﬂ even if 

the uncertainty of a given cyberattack™s effects is large. In other cases, the 

uncertainty inherent in a given cyberattack may not be signi˜cant from 

an operational or policy perspective. Moreover, the uncertainty associated 

with any and all cyberattacks is not necessarily large. A cyberattack might 

be designed to affect only a speci˜c computer with a speci˜c known serial 

numberŠsuch an attack would have few ill effects on any other computer 

system. A close-access cyberattack on a computer without electronic con
-nections with the outside world is very unlikely to have effects in the 

outside world, as long as it remains isolated. A cyberattack using soft
-ware agents exploiting vulnerabilities in Linux cannot necessarily exploit 

similar vulnerabilities on computers running Windows or Macintosh-OS 

systems. But greater intelligence efforts to resolve uncertainties are likely 

to be necessary to achieve levels of con˜dence equivalent to those that 

generally characterize kinetic attacksŠand such efforts may in some cases 

take long enough to render the use of cyberattack moot.
Finding 19: 
Early use of cyberattack may be easy to contemplate 
in a pre-con˚ict situation, and so a greater degree of operational 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.50 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
oversight for cyberattack may be needed compared to that for the 
use of other options.
It is easy to see how policy makers might regard cyberattack as a 
desirable option when coercive measures are needed. Cyberattack can 
be portrayed as an instrument that is easy, simple, temporary, reversible, 

non-lethal, and non-risky for the United States to use. But although it is 

possible to imagine that such attributes might characterize some cyberat
-tacks, the committee believes that such claims should generally engender 

a certain degree of skepticism among policy makers.
For example, a cyberattack might be regarded as a minor step. 
Although it is not new that ﬁsmallﬂ activities in a precon˚ict situation 

may have large consequences,
21
 the operational footprint left by cyberat
-tack activities is small, a fact that tends to render activities related to this 

area less visible to senior decision makers. Given the fact that cyberattack 

may have strategic signi˜cance (perhaps inadvertently),
22
 senior military 
commanders (for example) will need to take special care to maintain situ
-ational awareness and af˜rmative control of their own forces under these 

circumstances and will need to exercise a greater degree of oversight than 

might be necessary if only conventional military forces are involved. (Of 

course, they also need to maintain awareness of adversary forces.)
Similar considerations apply to those responsible for making deci
-sions about covert action. From a technical standpoint, cyberattack is an 
 instrument that is well suited to covert action because of the inherent 
deniability of a cyberattack and the ability to conduct such an attack 
without ﬁboots on the groundﬂ (and thus without placing U.S. or other 

friendly lives at risk). This point is 
not
 intended to comment on the desir
-ability of covert action as an option for U.S. decision makersŠonly that 

should covert action be determined to be desirable and in the national 

interest, policy makers are likely to be drawn to cyberattack as a preferred 

methodology for implementing such action. Accordingly, all of those 

responsible for exercising oversight over covert actions up the entire 
21
 For example, during the Cuban Missile Crisis, a U-2 reconnaissance aircraft on 
a ﬁroutine air sampling missionﬂ over Alaska went off course and ˚ew into Soviet air
-space. The Soviet Union scrambled ˜ghters to intercept the airplane, and the United States 
scrambled ˜ghters to provide cover for the U-2. These U.S. ˜ghters had been armed with 
nuclear air-to-air missiles. Upon hearing this news, Secretary of Defense Robert McNamara 

expressed grave concerns that the U-2 ˚ight could have been interpreted as the prelude to a 

U.S. nuclear strike on the Soviet Union. See Max Frankel, 
High Noon in the Cold War: Kennedy, 
Khrushche
v, and the Cuban Missile Crisis
, Random House, New York, 2005.
22
 Consider the possibility that a nuclear-armed nation might respond with the use 
of nuclear weapons to a major cyberattack (i.e., one with major societal consequences), as 

discussed in Section 10.3. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 51
chain of command must be cognizant and aware of the risks, bene˜ts, and 
uncertainties that they entail, whether they involve the use of cyberattack 
or other instruments. The possibility of using cyberattack as a means of 

covert action may also tempt decision makers to think that they might 

conduct a covert action with very little chance of detectionŠand there
-fore might lead to an inclination to intervene simply because the risks of 

detection are seen as lower.
Finding 20: 
Developing appropriate rules of engagement for the 
use of cyberweapons is very dif˜cult.
Rules of engagement (ROEs) specify for military personnel the cir
-cumstances under which they can use their weapons and the author
-ity required for doing so. Most importantly, ROEs are supposed to be 
developed 
prior to
 the need for use of their weapons, so that operators 
have proper guidance under operational circumstances. This fact means 

that various contingencies must be anticipated in advance, and of course 

it is dif˜cult to imagine all possible contingencies before any of them 

happen.
Although ROEs normally are not speci˜c to individual weapons sys
-tems, the presence of weapons or tools for cyberattack may be problem
-atic. When cyberattack may be used, ROEs must be developed to cope 

with the fact that several dimensions of cyberattack span a wide range. A 

cyberattack may be non-lethal, or it may be destructive on a society-wide 

scale. The impact of a cyberattack can be easily predicted in some cases 

and highly uncertain in other cases. The set of potential targets that may 

be adversely affected by a cyberattack is quite large, and likely larger than 

the corresponding set of potential targets for other weapons. A cyberat
-tack conducted for offensive purposes may well require authorization 

from higher levels of command than would a technically similar cyberat
-tack conducted for defensive purposes. The adversary might not react at 

all to a cyberattack, or it might react with nuclear weapons. The adversary 

might be a solo hacker or a well-funded nation-state. It is thus unrealistic 

to try to craft a single ROE that attempts to cover all uses of cyberattack. 

Rather, it will be necessary to tailor an array of ROEs that are applicable 

to speci˜c kinds of cyberattack and for likely speci˜c circumstances. And 

it will be at least as dif˜cult to craft ROEs for missions involving cyberat
-tack as for missions involving other kinds of weapons.
As an illustration of the complexity of developing ROEs in a speci˜c 
situation involving cyberattack, consider some of the issues in developing, 

in advance, military ROEs for active threat neutralizationŠunder what 
circumstances governed by what authority might a counter
-cyberattack 
be launched to neutralize an immediate or ongoing threat? 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.52
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES

Who should ha
ve in˜uence on the de
velopment of ROEs for acti
ve threat 
neutralization?
 It is obvious that the agency conducting a counterattack 
should have input (likely the DOD or the intelligence community). But 
other agencies (notably the Departments of Homeland Security, State, 

Justice, and Commerce) may have equities at stake as well. And although 

it makes little sense for Congress to be involved in approving rules of 

engagement in detail, Congress should have mechanisms for being kept 

informed of the general circumstances under which the U.S. government 

does undertake active threat neutralization.

How, if at all, are the intent and the identity of a cyberattacker rele
vant?
 If the cyberattacker is determined to be a nation-state, does it increase or 

decrease the appropriateness of a neutralization effort? (If it depends on 

other factors, what other factors?) And if intent is relevant, how is the 

intent of the cyberattacker to be ascertained? Suppose that the proximate 

nodes involved in an attack can be identi˜ed but they are likely innocent 

parties who have been compromisedŠis it appropriate to neutralize the 

threat emanating from their systems?

How does the proportionality principle apply to acti
ve threat neutraliza
-tion? 
Proportionality requires that the value of neutralizing the threat be 
outweighed by the likely collateral damage of the counterattack. How 

is the likely collateral damage to be estimated, especially if the response 

is automated and launched without human analysis or intervention? Or 

does a proper proportionality analysis 
require
 human intervention before 
such a response is launched?

How far down the chain of command should delegation of authority 
to launch an acti
ve threat neutralization be carried?
 For example, although 
the commander of the U.S. Strategic Command has the authority under 

standing rules of engagement to conduct a response action, it is unlikely 

(though possible) that he must himself approve the action. It is more likely 

that the authority to do so is further delegated to other parties down the 

chain of command. But since a response action is a serious thing, there 

must be limits (not known to the committee) to how far this authority is 

delegated. (An automated response, as proposed by the U.S. Air Force™s 

Concept of Operations for its Cyber Control System, would represent the 

ultimate in delegation of authority.)

What le
vel of impact (among other factors) must an incoming cyberattack 
threat achie
ve in order to justify an acti
ve threat neutralization?
 The standard 
used by the U.S. Strategic Command is that an incoming cyberattack must 

have a material impact on the DOD™s ability to perform a mission or to 

carry out an operation, and that cyberattacks that merely cause inconve
-nience or that are directed only at intelligence gathering do not rise to the 

threshold of warranting such a response. For example, a cyberattack on 

the command and control system for Navy ballistic missile submarines 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 53
might warrant an active threat neutralization, but a cyberattack on the 
administrative computers of the U.S. Strategic Command might not.

How should the scope, duration, and intensity of a neutralization action 
be calibrated?
 The intent of neutralization is to stop an incoming attack. But 
the scope, duration, and intensity of a response may relate to one™s con
-˜dence in actually achieving an effective neutralization, as well as to the 
collateral damage that may be incurred. In addition, political reality may 

dictate that only a commensurate response (i.e., a response that in˚icts 

a similar amount of harm on an adversary) is possibleŠhow might this 

requirement square with effectiveness in stopping the attack?
A further level of complication in developing rules of engagement is 
that the factors above cannot be assessed independently. For example, the 

authority needed to launch an active threat neutralization may depend on 

the identity of the attackerŠperhaps local authority would be needed if 

the attacker were a teenager in Zendia, but perhaps the personal author
-ity of the commander of U.S. Strategic Command would be needed if the 

attacker were the 418th Zendian Information Operations Brigade. Perhaps 

higher-level authority would be needed if more collateral damage were 

possible.
The dif˜culties in formulating appropriate rules of engagement, and 
of different human beings interpreting these rules in a manner consis
-tent with the intent in formulating them, suggest that there may well be 

differences between what is intended and what is actually doneŠand 

furthermore that these differences re˚ect an enduring reality of the way 

such processes operate.
1.8.6
 Organizational Findings
Finding 21: 
Both the decision-making apparatus for cyberattack 
and the oversight mechanisms for that apparatus are inadequate 

today.
Adequate policy decision making and oversight require a suf˜cient 
base of technical knowledge relevant to the activities in question, an 
organizational structure that enables decision making and oversight to 

take place, and information about activities that are actually undertaken 

under the rubric of policy.
Cyberattack is a relatively new addition to the menu of options that 
policy makers may exercise, and there are few precedents and little his
-tory to guide them today. The infrastructure and resources needed to 

conduct such activities, and the activities themselves, are by their nature 

less visible than those associated with more traditional military, intel
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.54 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
ligence, or law enforcement activities. They do not ˜t into standard cat
-egoriesŠthe weapons involved initially act in a non-lethal manner, even 
though they may have subsequent effects that are lethal or destructive; 

the activities for which they are suited go far beyond just surveillance or 

just covert action; and they are shrouded in secrecy. In many cases, bud
-gets to acquire cyberattack capabilities are likely small compared to the 

budgets for major weapons acquisition programs. The technical knowl
-edge needed to conduct informed oversight is not widespread, and the 

importance of cyberattack as a possible option for policy makers is not 

widely appreciated. Procedures for informing potentially relevant policy 

makers in both the executive and the legislative branches appear to be 

minimal or non-existent.
To illustrate the committee™s concerns, consider the delegation of 
authority to the commander of the U.S. Strategic Command for conduct
-ing an active threat neutralization (a limited and speci˜c form of active 

defense) to protect military computer systems and networks whose mis
-sion performance has been compromised by a cyberattack. The implica
-tions of such an action conducted against computer systems or networks 

outside U.S. borders may range beyond strictly military ones, especially 

if the potential for unintended consequences is taken into account. This is 

not to say that all active responses have such potential, or that any active 

response will necessarily have unintended consequences. But absent 

mechanisms for factoring in diplomatic or political considerations, the 

committee is concerned about a decision to conduct an active threat neu
-tralization that takes into account only military or local tactical consider
-ations of protecting the mission capability of U.S. military networks.
With such factors in play, an adequate organizational structure for 
making decisions and exercising oversight has not emerged, and much 

of the information relevant to conducting oversight is unavailable. As a 

result, government and society at large are neither organized nor pre
-pared to think about the implications of cyberattack as an instrument of 

national policy, let alone to make informed decisions about them.
Finding 22: 
The U.S. Congress has a substantial role to play in 
authorizing the use of military force, but the contours of that 

authority and the circumstances under which authorization is 

necessary are at least as uncertain for cyberattack as for the use 

of other weapons.
One important missing elementŠconspicuous in its absenceŠin the 
decision-making apparatus of the U.S. government is the role that the 
Congress does or should play in decisions related to cyberattack. As noted 

in Chapter 6, Congress has an important authorization role regarding 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 55
the use of military force under many circumstances, although the limits 
of that authority are the subject of much dispute between the executive 
and legislative branches. If the necessity of congressional authorization 

for the use of traditional U.S. military forces is disputed as it has been 

in recent U.S. history, consider the conundrums that could accompany 

the use of weapons that are for all practical purposes covert and whose 

ﬁdeploymentsﬂ would be entirely invisible to the public or even to most 

uniformed military personnel.
In general terms, the use of cyberattack raises the same sorts of 
issues as other instruments of warfare such as frigates and cruise mis
-siles. When does the President have inherent authority to act regardless 

of what Congress says or does? When must the President obtain congres
-sional approval before acting? When can Congress de˜ne the standards 

and procedures that limit what would otherwise be plenary presidential 

authority? Nevertheless, cyberweapons raise particularly dif˜cult issues 

in this context (as do certain kinds of non-cyberweapons), because of the 

need for speed in using such weapons (e.g., because of a target™s tran
-sience), the risk of unintended and unknown consequences, and the lack 

of visibility of their use.
The committee refrains from making a ˜nding on the boundaries 
between presidential and congressional authorities in this area, but notes 

the existence of certain limiting cases on both sides of this debate. In one 

limiting case, the committee believes it would be broadly accepted that 

presidential views of executive branch powers notwithstanding, congres
-sional authorization is required for the United States to launch a large-

scale cyberattack against another nation with the intent of shutting down 

the essential civil services of that nationŠtransportation, electric power, 

˜nancial services, and so onŠif the attack were contemplated as a ˜rst 

use of coercive or aggressive action against that nation.
In another limiting case on the other side, the committee believes that 
there are certainly some circumstances under which some kind of cyberat
-tack might be launched without explicit congressional authorization, just 

as certain kinds of military force can be used under some circumstances 

without such authorization. The canonical example of the latter is the 

use of force in self-defenseŠif U.S. military units are attacked, standing 

rules of engagement generally permit the use of lethal force against the 

attacking party.
However, in the vast area of possible circumstances in between these 
two limiting cases in which the United States might contemplate a cyber
-attack, the lines are most unclear, and the committee is explicitly silent 

on those lines. 
A variety of factors may in˚uence whether a given situation falls 
above the line requiring congressional authorization or below the line. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.56
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Possibly relevant factors include the scale of the cyberattack contem
-plated, the target of the cyberattack, and the circumstances that de˜ne 
ﬁ˜rst use.ﬂ One particularly problematic issue is the possibility of escala
-tion and unanticipated effects, in which cyberattacks that do not require 

congressional authorization might evolve into cyberattacks that do. 

(Unanticipated effects are, by de˜nition, unintentional, although they 

might well not be perceived by the attacked party as unintentional.) The 

escalation issue is also present in a non-cyber context, and is indeed what 

the War Powers Resolution was intended to prevent, but as discussed in 

Section 6.2.1, the cyber dimension of the issue signi˜cantly increases the 

complexity of the problem. 
Finally, the committee calls special attention to the fact that congres
-sional concerns about asserting authority over the use of military forces are 

generally at their maximum when U.S. military forces are placed directly 

in harm™s wayŠthat is, when U.S. casualties may be the result of direct 

combat. Cyberattacks launched by the United States are highly unlikely 

to place U.S. forces at direct risk, and indeed would in general be easy to 

undertake with minimal public visibility. Thus, explicit mechanisms to 

provide relevant information to the appropriate congressional parties are 

essential if Congress is to know if and when it should be involved.
1.9
 RECOMMENDATIONS
U.S. acquisition and use of cyberattack capabilities raise many issues 
in need of broad understanding and deserving of extensive and wide
-spread national conversation and debate. One set of committee recom
-mendations focuses on fostering that debate. A second set of recommen
-dations focuses on operational needs.
A caution to the reader: For the most part, the recommendations 
below are formulated as advising that ﬁthe U.S. government should do 

X or 
Y.ﬂ This formulation violates a basic canon of making recommenda
-tions to policy makers, namely that the party viewed by the committee 

as responsible for taking action on a recommendation should always 

be made as speci˜c as possible. However, consistent with Finding 21, 

the committee could not identify an appropriate entity within the U.S. 

government to take action, and indeed as this report is being written, the 

U.S. government is trying to decide how best to organize itself internally 

to deal with the implications of cyberattack as an instrument of national 

policy.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 57
1.9.1
 Fostering a National Debate on Cyberattack
Recommendation 1:
 The United States should establish a public 
national policy regarding cyberattack for all sectors of govern
-ment, including but not necessarily limited to the Departments of 
Defense, State, Homeland Security, Treasury, and Commerce; the 

intelligence community; and law enforcement. The senior leader
-ship of these organizations should be involved in formulating this 

national policy.
As noted in Chapter 6, the DOD Information Operations Roadmap 
of 2003 recommended that the U.S. government should have a declara
-tory policy on the use of cyberspace for offensive cyber operations. As 
the committee has been unable to ˜nd any such statement of declaratory 

policy, it concurs with and reiterates this call. At a minimum, such a policy 

would involve the DOD, the intelligence community, and law enforce
-ment agencies, and would address the following questions:

For what purposes does the United States maintain a capability for 
cyberattack?

Do cyberattack capabilities exist to ˜ght wars and to engage in 
covert intelligence or military activity if necessary, or do they exist pri
-marily to deter others (nation-states, terrorist groups) from launching 

cyberattacks on the United States? 

If they exist to ˜ght wars, are they to be used in a limited fash
-ion? Under what circumstances would what kinds of cyberattack be 

launched?

What legal regimes are relevant to different levels of cybercon˚ict?

How and when is cybercon˚ict to be stopped?

To the extent that cyberattack is part of the U.S. deterrent posture, 
how can its use be established as a credible threat?

What, if any, role do cyberattack capabilities have in law enforce
-ment efforts directed against transnational criminal groups?
A clear statement of policy in this area would enable various gov
-ernment actors, and the private sector as well, to understand the con
-straints and limitations on using cyberattack for various purposes and 

to establish appropriate standards of behavior in this domain. Appro
-priate policy would provide important guidance for U.S. armed forces, 

intelligence agencies, and others in a domain in which international and 

national law may be inadequate to manage the full rami˜cations of using 

cyberattack. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.58
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
For example, the United States could declare its commitment to abid
-ing by the laws of armed con˚ict with respect to cyberattack. Such a 
posture could well affect the willingness of other nations to make simi
-lar declarations. Another related example concerns the national military 

strategy of the United States. As noted in Section 6.1.1, the 
National Mili
-tary Strategy of the United States
, published in 2004, indicated that the 
United States could respond using nuclear weapons to certain kinds of 

large-scale cyberattacks. Does this presumably authoritative statement of 

2004 continue to re˚ect U.S. policy? If not, how does current policy differ? 

If so, is this an appropriate policy?
The new administration could undertake a review of cyberattack 
policy comparable to the nuclear policy review that new administrations 

often perform. Congressional hearings on this topic would also be useful 

in shedding light on government thinking about this topic.
The promulgation of a comprehensive declaratory policy would be a 
good ˜rst step for the government in becoming more forthcoming about 

its own thinking in this area and providing a benchmark for public discus
-sion. But although the committee endorses the 2003 DOD recommenda
-tion regarding establishment of declaratory policy with respect to military 

equities, the committee goes further still. As noted in Finding 1, the com
-mittee believes that U.S. acquisition and use of cyberattack raises many 

important policy issues that go far beyond the Department of Defense. 

Such issues deserve an extensive and widespread national conversa
-tion and debate about how cyberattack might affect a broad spectrum of 

national interests. 
The Departments of State, Homeland Security, and Treasury, and 
law enforcement agencies are thus included in Recommendation 1, even 

though they are not traditionally regarded as agencies with interests in 

cyberattack. The State Department is included because cyberattack has 

many international dimensions. The DHS and law enforcement agencies 

are included because tracing the ultimate source of an incoming cyber
-attack often requires the investigator to penetrate intermediate nodes, 

capture the relevant traf˜c, and then analyze it to determine the next 

node in the chain. Law enforcement authorities are also responsible for 

aspects of preventing or prosecuting cybercrime. The Department of the 

Treasury has responsibility for enforcing sanctions, and cyberattack may 

be relevant to the performance of this mission. In addition, implementa
-tion of Recommendation 10 may call for the establishment of an agency or 

a body with certain law-enforcement-like responsibilities that would also 

˜nd some utility in conducting certain kinds of cyberattack.
Recommendation 2:
 The U.S. government should conduct a 
broad, unclassi˜ed national debate and discussion about cyber
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 59
attack policy, ensuring that all partiesŠparticularly Congress, the 
professional military, and the intelligence agenciesŠare involved 
in discussions and are familiar with the issues.
As noted in the Preface, the topic of cyberattack is highly classi˜ed 
within the U.S. government. Some aspects of the topic are classi˜ed with 
good reasonŠthese include the fact of U.S. interest in a speci˜c cyberat
-tack technology (rather than the nature of that technology itself); fragile 

and sensitive operational details that are not speci˜c to the technologies 

themselves (e.g., the existence of a covert operative in a speci˜c foreign 

country or a particular vulnerability); or capabilities and intentions of spe
-ci˜c adversaries. But the details of these areas are not particularly relevant 

to answering questions about declaratory policy, and thus secrecy even 

about broad policy issues serves mostly to inhibit necessary discussion 

about them.
Although implementation of Recommendation 2 would bene˜t both 
the private and public sectors of the nation as a whole, two stakeholder 

groups have particular signi˜cance. Both the U.S. Congress and the profes
-sional military/intelligence agencies need at least a basic understanding of 

the policy issues and their relationship to the basic technologies involved, 

but the broad classi˜cation of virtually all issues related to cyberattack is 

a signi˜cant barrier to the discharge of their responsibilities.
Recommendation 3:
 The U.S. government should work to ˜nd 
common ground with other nations regarding cyberattack. Such 

common ground should include better mutual understanding 

regarding various national views of cyberattack, as well as mea
-sures to promote transparency and con˜dence building.
The committee believes that most other nations are no farther along 
in their understanding of the key issues than is the United States. It is 
therefore important for the United States to begin to ˜nd common ground 

on this topic with allies, neutrals, and potential adversaries. In this con
-text, ﬁcommon groundﬂ is not a euphemism for treaties or arms control 

agreements regarding cyberattack. It is rather a term that denotes a com
-mon understanding of its signi˜cance for policyŠand common ground 

is important for allies and adversaries alike if misunderstandings are to 

be avoided.
Consultations with allies of the United States (such as the NATO 
countries) are likely to be the easiest to undertake. Such consultations 

should take two tracksŠbetween the governmental entities that would 

be responsible for executing cyberattacks in these nations and between 

the cognizant policy decision makers. At the very least, those with opera
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.60 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
tional responsibility for attack execution need to develop mechanisms for 
coordinating cyberattacks so that they do not interfere with each other. 
And policy makers must be able to discuss issues related to cyberattack 

in an informed manner, without having to learn about them in the middle 

of a cyber crisis.
As an example of such consultation, NATO established in March 2008 
the Cyber Defence Management Authority, which will manage cyberde
-fense across all NATO™s communication and information systems and 

could support individual allies in defending against cyberattacks upon 

request.
23
 One press report indicates that ﬁthe Authority will also develop 
and propose standards and procedures for national and NATO cyberde
-fence organisations to prevent, detect, and deter attacks,ﬂ but will focus on 

defense ﬁwhether an attack comes from state, criminal or other sources.ﬂ
24
 Similar efforts to reach common understandings regarding cyberattack 

(and on the relationship of cyberattack to cyberdefense) would be help
-ful as well.
Consultations with potential near-peer adversaries, or with the United 
Nations, are more politically fraught, especially with the Russian Federa
-tion seeking to delegitimize cyberattack entirely as a method of warfare. 

But Russian proposals on this topic are based on a Russian view of the 

topic, and it is worth understanding in some detail the sources of Russian 

concerns, even if the ultimate result is an agreement to disagree about 

basic premises and concepts. More generally, it would be helpful for all of 

the world™s nations to understand the scope and nature of their interests 

where cyberattack is involved, and the only way to begin the process of 

developing understanding is to start consultations.
There are, of course, multiple forums in which to initiate consulta
-tions. Treaty negotiations are one possible forum, although U.S. policy 

makers may feel that such a forum grants too much legitimacy to an idea 

deemed by many in the U.S. government to be inconsistent with U.S. 

national interests. The UN Security Council itself could be another forum 

for discussions. NATO or G-7 ministerial discussions could be used to 

start consultations among allies.
The committee believes that greater mutual understanding and com
-mon ground should be sought on the following topics:

The scope and nature of cyberattacks, especially including those that 
would constitute a ﬁuse of forceﬂ and an ﬁarmed attack.ﬂ
 Given the overall lack 
23
 NATO, ﬁDefending Against Cyber Attacks: What Does This Mean in Practice?,ﬂ 
March 31, 2008, available at http://www.nato.int/issues/cyber_defence/practice.html.
24
 See http://www.computerweekly.com/Articles/2008/04/04/230143/nato-sets-up-
cyber-defence-management-authority-in-brussels.htm/.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 61
of experience and history with cyberattack, such discussions would serve 
to provide common vocabularies and conceptual frameworks for address
-ing the issue in the future. What activities constitute a cyberattack? How 
might damage or harm from a cyberattack be assessed? What activities 

might constitute evidence of hostile intent? How should cyberexploitation 

and intelligence gathering be differentiated from cyberattacks? How, if 

at all, should exploitations for economic purposes be differentiated from 

exploitations for national security purposes? During discussions of these 

issues, no nation would have to acknowledge undertaking any of these 

activities since the intent would be the development of common concep
-tual frameworks.

Measures to promote transparency and to build con˚dence in the lack 
of aggressi
ve intent
. By analogy to con˜dence-building measures in other 
domains (Chapter 10), the United States and other nations should seek to 

establish lines of communication between responsible and authoritative 

parties within their respective governments that would be able to account 

for or to deny suspicious cyber operations that might appear to be occur
-ring at government direction. To make such communications meaningful, 

it would also be helpful for the nation involved to agree to cooperate 

in the investigation of such operations and/or to allow the victimized 

party to engage in self-help activities. Explicit agreement could be sought 

on what is required in order to ﬁcooperateﬂ on any investigation. For 

example, cooperation might require the nation hosting a network node 

involved in a cyberattack to provide forensic analysis of information on 

that node.

Building of informal relationships among key participants in both the 
public and the pri
vate sector
. One of the primary lessons of the Estonian 
incident of 2007 was the enormous value of relationships of trust among 

certain individuals in the Estonian government and top technical people 

from the various Internet service providers for Estonia and around the 

world. By exploiting these relationships, it was possible to take action to 

dampen the effect of the cyberattack against Estonia in a much shorter 

time than would have been possible if only formally sanctioned relation
-ships between governments were available. Support and encouragement 

to develop such relationships should be provided by the governments 

involved.

Separation or identi˚cation of the computer systems and networks of 
military forces, the ci
vilian population, and speci˚cally protected entities (e.g., 
hospitals)
. Much of the dif˜culty of adhering to the framework of the law 
of armed con˚ict in the context of cyberattack arises from the dif˜culty of 

distinguishing between valid military targets and other entities that are 

specially protected or are possible victims of collateral damage. It may 

be possible to develop mutually agreed methods or cooperative technical 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.62
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
means for cyberattackers to distinguish between these different catego
-ries to minimize inadvertent damage to non-military targets and ways to 
verify that these declared distinctions were being properly applied.

The signi˚cance of non-state parties that might launch cyberattacks, 
and how nations should respond to such attacks
. Today, the Convention on 
Cybercrime is the only international agreement on how nations should 

respond to cyberattacks, and is in essence an agreement to harmonize 

criminal law in this area and to facilitate law enforcement cooperation 

among the signatories. But as noted in the argumentation for Finding 
7, the law enforcement framework operates in many cases on a time scale 

that is far too long to protect victims of cyberattack from harm.
1.9.2
 Organizing the Decision-Making Apparatus of the 
 U.S. Government for Cyberattack
Recommendation 4:
 The U.S. government should have a clear, 
transparent, and inclusive decision-making structure in place to 

decide how, when, and why a cyberattack will be conducted. 
As noted earlier, the use of cyberattack in pre-con˚ict situations is 
likely to be tempting to policy makers. But because cyberattack can have 
far-reaching implications (at least in part because the actual scope of a 

cyberattack somehow gone awry may be much greater than that intended), 

senior policy makers should have a mechanism for ensuring that consulta
-tions take place with all stakeholders with equities that might be affected 

by a U.S. cyberattack in pre-con˚ict situations. At a minimum, it would 

appear that the Departments of Defense, State, and Homeland Security, 

and the law enforcement and intelligence communities would have to be 

involved in coming to terms with issues, such as advance coordination of 

a U.S. cyberattack that might lead to a cyberattack on the United States 

or to a determination that exploitation of adversary computers should (or 

should not) have priority over disabling or damaging them.
As an example of a question for which the U.S. government as a 
whole needs to establish an authoritative decision-making structure, con
-sider cyberattack in the context of the dividing line between covert action 

and military activity. The U.S. Code de˜nes covert action as ﬁan activity 

or activities of the United States Government to in˚uence political, eco
-nomic, or military conditions abroad, where it is intended that the role 

of the United States Government will not be apparent or acknowledged 

publiclyﬂ (50 USC 413b(e)). At the same time, the U.S. code also de˜nes 

any activity executed under control of the DOD chain of command as 

falling under the de˜nition of a traditional military activity associated 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 63
with anticipated or ongoing hostilities, and such activity thus is not covert 
action subject to the ˜ndings and congressional reporting process.
The question of the boundaries between covert action and traditional 
military activities has been the subject of much discussion over the past 
several years (since the U.S. invasions of Afghanistan and Iraq). The ˜nd
-ings and reporting process is often disliked by incumbent administrations, 

because it constrains an administration™s ability to act freely and quickly 

and runs the risk of leaks that may reveal the existence of a covert action. 

On the other hand, many informed advocates of the process believe that 

the existence of such a process forces the executive branch to coordinate 

internal stakeholders and their equities, and also provides for necessary 

external review of actions that may be ill-advised from a broader public 

policy perspective.
The committee was not constituted to address this tension in its broad
-est formulation. But the stealthy operation and the dif˜culty of attribution 

associated with cyberattack weapons inherently makes them instruments 

of deniable action and may change the cost-bene˜t calculation in deciding 

whether a given covert action should be undertaken. Thus, the committee 

anticipates that this tension will increasingly manifest itself in a cyberat
-tack context, and may push the boundaries of settled law and policy into 

uncharted territory. Accordingly, the committee believes that the issue 

is suf˜ciently important to warrant high-level attention from both the 

Administration and the Congress.
A second example of the need for an inclusive decision-making struc
-ture regarding cyberattack relates to active defense. As noted in Chapter 

3, STRATCOM has the authority to neutralize a cyberthreat that compro
-mises DOD mission effectiveness. Such authority is consistent with the 

traditional DOD standing rules of engagement that provide for force pro
-tection. Depending on the nature of the response action taken, however, a 

response may have strategic implications that go beyond force protection, 

even if the response action is limited in scope, effect, and duration. For 

example, if a cyberthreat is emanating from the military forces of a near-

peer adversary, a response action may lead to escalationŠespecially if the 

response is not as controlled in execution as it was in planning or if the 

incident occurs during times of tension.
For such reasons, the committee believes that the decision to take 
such actions should be made at levels of authority high enough to weigh 

the various equities (military, diplomatic, and so on) appropriately. For 

example, the committee believes that the stakes of a neutralization cyber
-attack must be high enough (i.e., the damage being caused to computer 

systems and networks important and serious enough) and success likely 

enough to justify the political risks of launching a counterattack, such as 

the possibility that world opinion might not see U.S. cyberattacks under
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.64 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
taken under the rubric of active defense as innocent acts of self-defense, 
even if they are. Such an assessment can be made only at the highest levels 
of government. 
These points should not be taken to imply that the authority to con
-duct a neutralization response should not be delegated (though they do 

suggest that delegation should not go too far down the chain of com
-mand). Delegation with clear rules of engagement may be the only way to 

reconcile high-level decision making with the need for prompt response. 

Such rules would clearly establish the threshold at which a military mis
-sion is compromised and the constraints on the scope and nature of a 

neutralization response. For instance, one constraint might be conducting 

a neutralization response only when other methods
25
 for responding to 
a cyberattack have proven (or will prove) ineffective. Another constraint 

might require that a neutralization response be limited in scope and as 

focused as possible on eliminating the threat in order to minimize the pos
-sibility of inadvertent escalation.
26
 (Both of these constraints appear to be 
consistent with the rules of engagement described in Section 3.3 concern
-ing possible DOD response actions for computer network defense.)
But because of the potential for erroneous response (Chapter 2 dis
-cusses the dif˜culties of attribution and attack assessment) and for inad
-vertent escalation (as described in Chapter 9), the committee is highly 

skeptical of the idea that delegation should include automated neutraliza
-tion responses, a capability of interest to the U.S. Air Force (as noted in 

Box 3.5). Indeed, the authority for conducting a neutralization response 

should ˚ow explicitly from higher authority, only after higher authority 

has considered all of the various equities in an integrated manner, and 

only after higher authority has reviewed and if necessary modi˜ed stand
-ing rules of engagement during times of crisis. Whether this description 

of the ˚ow of authority in fact characterizes current rules of engagement 

for STRATCOM™s authority to conduct response actions is not known to 

the committee. 
A third example of the need for an inclusive decision-making struc
-25
 These other methods may include dropping connections, closing ports, asking Inter
-net service providers to shut down nodes identi˜ed as being sources of the attack, diverting 
attack traf˜c to other locations, changing IP addresses, and so on.
26
 For example, consider two possible neutralization responses to a given botnet threat, 
wherein the botnet is controlled by a machine to which an access path has been established. 

One approach might be to launch a denial-of-service attack against the controller in order 

to prevent it from communicating with the bots it controls. Another approach might be to 

break into the controller to assume control of the botnet, and then issue orders to shut off 

the attack. Although the ˜rst method might be faster, it presumes that the attacked machine 

is dedicated to the controlling function, whereas in fact the machine in question might have 

other non-hostile functions whose termination might constitute an escalation. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 65
ture can be seen in the fact that during active hostilities, a cyberattack 
conducted for tactical purposes might lead to opportunities whose exploi
-tation would have strategic signi˜cance. For example, consider a cyberat
-tack on the command and control network in the nationwide Zendian air 
defense system. In the process of exploring the network, corrupting data, 

and issuing confusing or damaging commands, U.S. operators might 

stumble onto a communications link with the Zendian national command 

authority (NCA). Exploitation of that link might enable the United States 

to penetrate the command and control network of the Zendian NCAŠbut 

a decision to do so should not be made by operators and commanders 

on the ground but rather by higher U.S. authorities. Thus, mechanisms 

must be established to provide such information up the chain of com
-mand when necessary, and other mechanisms established to act on such 

information should it be made available.
Recommendation 5:
 The U.S. government should provide a peri
-odic accounting of cyberattacks undertaken by the U.S. armed 

forces, federal law enforcement agencies, intelligence agencies, 

and any other agencies with authorities to conduct such attacks 

in suf˜cient detail to provide decision makers with a more com
-prehensive understanding of these activities. Such an accounting 

should be made available both to senior decision makers in the 

executive branch and to the appropriate congressional leaders 

and committees.
Whether or not cyberattack falls into the category of covert action, 
it appears that even within the executive branch, knowledge of the 
actual cyberattack activities of the United States is highly fragmented. 

An authoritative source, updated periodically, that documents the extent 

and nature of such activities and provides analyses of their impact and/

or signi˜cance would help senior decision makers within the executive 

branch and Congress in carrying out their authorization and oversight 

responsibilities.
The committee expects that such a compendium would be highly 
classi˜ed, as it would likely reveal many sensitive details regarding actual 

U.S. capabilities and actions. For understanding policy and for exercising 

oversight, such an accounting would describe the purposes served by 

any given cyberattack, the intended target(s), the outcome, the dif˜culties 

encountered in conducting the attack, the rules of engagement relevant 

to that cyberattack, and both the anticipated and the actual value of the 

attack in serving U.S. national interests. If necessary, exemptions to such 

reporting for extremely sensitive operations might be modeled on those 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.66
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
in the statute on covert action providing for more limited ﬁGang-of-Eightﬂ 
reporting.
27
One approach to collecting the information would be for cyberattacks 
to be reported more or less contemporaneously to the National Security 
Council, which would compile and analyze the information and then 

distribute it when required to do so. This approach also has the advan
-tage of informing senior executive branch decision makers of potentially 

signi˜cant events that might affect their activities and decisions in other 

domains (e.g., if undertaken in the middle of a crisis, an inappropriately 

timed cyberattack might have diplomatic repercussions).
28
Also, consistent with Finding 22, the committee recommends the 
establishment of mechanisms to promptly inform the appropriate parties 

in Congress before the United States launches signi˜cant U.S. cyberat
-tacks against other powers or entities or promptly thereafter. ﬁPromptlyﬂ 

should be understood to refer to a time scale shorter than or comparable 

to those required by the War Powers Resolution for introducing U.S. 

armed forces into hostilities. 
Finally, the committee recognizes that many de˜nitional issues remain 
to be worked out. It is the committee™s recommendation that a reportable 

cyberattack be de˜ned as one that was initiated with the intent of alter
-ing, disrupting, deceiving, degrading, or destroying adversary computer 

systems or networks or the information and/or programs resident in or 

transiting these systems or networks immediately or in the future. For 

example, reasonable people might disagree over whether cyberexploita
-tions should also be included, but the goal is for responsible senior deci
-sion makers to have a reasonably comprehensive view of the cyberattack-

related activities of the U.S. government.
1.9.3
 Supporting Cyberattack Capabilities and Policy
Recommendation 6:
 U.S. policy makers should judge the policy, 
legal, and ethical signi˜cance of launching a cyberattack largely on 

the basis of both its likely direct effects and its indirect effects. 
27
 ﬁGang-of-Eightﬂ reporting refers to the requirement to report only to the chair and 
ranking minority member of the House and Senate Select Committees on Intelligence, the 
Senate majority and minority leaders, and the Speaker of the House and the House Minor
-ity Leader. Reporting to the ﬁGang of Eightﬂ meets the legal requirement for presidential 

brie˜ng to Congress for certain selected intelligence activities.
28
 In this regard, executive branch noti˜cation might be regarded as being analogous 
to notifying the secretary of defense about all missile test launches. The intent of this long-

standing rule was not that the secretary had to approve such launches but rather that the 

secretary should know if a launch was going to occur in the middle of other events or dur
-ing a crisis.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 67
As noted in Finding 
5, the consequences of a cyberattack may be both 
direct and indirectŠand both must be taken into account in determining 
appropriate courses of action. Cyberattacks cannot be assumed to be of 

lesser consequence simply because they are primarily non-kinetic attacks 

on computer systems or networks. 
This point is especially relevant in considering responses to a crisis or 
an incident in which a forceful U.S. response is desired. Because a cyber
-attack may appear to be an action short of a ﬁrealﬂ military deployment 

or response if only direct effects are considered, and in any event would 

be unlikely to place U.S. forces directly in harm™s way, policy makers 

may be unduly tempted to take such an action unless they consider the 

cyberattack™s indirect effects as well.
More generally, the dif˜cult legal and ethical policy issues regard
-ing the appropriateness of using cyberattack seem to arise mostly in a 

prekinetic situation, where traditional armed con˚ict has not yet arisen 

(and may never arise). In this context, decision makers must determine 

whether a cyberattack would be equivalent to ﬁthe use of forceﬂ or ﬁan 

armed attack.ﬂ Effects-based analysis provides one criterion for such a 

determinationŠequivalence would be determined by comparing the scale 

of death and/or destruction that would result from a cyberattack (taking 

into account both direct and indirect effects) to that which would result 

from a use of kinetic force. 
As for the situation in which a ﬁkineticﬂ con˚ict has already broken 
out, cyberattack is just one more tactical military option to be evaluated 

along with other such optionsŠthat is, when U.S. military forces are 

engaged in traditional tactical armed con˚ict and except in extraordinary 

circumstances, there is no reason that any non-LOAC restrictions should 

be placed on the use of cyberattack vis-à-vis any other tactical military 

option. Thus, if a given tactical operation calls for attacking a certain 

target, LOAC questions about necessity, proportionality, and distinction 

must be asked about the use of cyberattack, the use of special operations 

troops, and the use of a cruise missileŠand attacks that do not satisfy 

LOAC constraints may not be used. (Needless to say, both direct and 

indirect effects must be considered in this analysis, and uncertainties in 

the answers to these questions must be taken into account as well.)
The extraordinary circumstances mentioned above relate to instances 
in which U.S. military forces might be contemplating actions with stra
-tegic signi˜cance. For example, a cyberattack on an adversary satellite 

might have tactical bene˜ts, but the use of a cyberattack for this purpose 

should be considered just as carefully as the use of a direct-ascent mis
-sile or a ground-based laser. The latter decision today would not be the 

sole province of the commander in the ˜eld, but would likely involve the 

National Command Authority directly, and so should the former. Com
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.68
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
manders in the ˜eld should not be tempted by the seeming ease or low 
pro˜le of cyberattack to use such an option when other options would 
not be used.
Finally, Recommendation 6 should not be taken to mean that only 
effects are relevant to a policy, legal, or ethical analysis of any given cyber
-attack. The committee recognizes, for example, that the intent with which 

a cyberattack is carried out may well be relevant to such analysis, though 

the attacker™s intent may be largely irrelevant to its effects. Indeed, the 

DOD standing rules of engagement (mentioned in Section 3.3) obligate 

military commanders to ﬁdefend that commander™s unit and other U.S. 

forces in the vicinity from a hostile act or 
demonstration of hostile intent
.ﬂ 
The party responsible for the attack is also a relevant factorŠit matters 

whether the responsible party is a nation-state, terrorist group, criminal 

organization, hacker, or a careless graduate student. Thus, a cyberattack 

launched by a terrorist group affecting a small number of important 

national security computer systems may well be regarded as a more 

hostile act than a cyberattack launched by a careless graduate student 

affecting millions of systems around the world (including some national 

security computer systems)Šand a national response should account for 

such differences.
Recommendation 7:
 U.S. policy makers should apply the moral 
and ethical principles underlying the law of armed con˚ict to 

cyberattack even in situations that fall short of actual armed 

con˚ict.
As noted in Chapter 7, the law of armed con˚ictŠspeci˜cally 
jus in 
bello
Šdoes not pertain to the behavior of military forces in situations 
that fall short of actual armed con˚ict, and the relevant international law 
under such circumstances is poorly developed at best. Nevertheless, the 

committee believes that U.S. policy makers should apply the moral and 

ethical principles underlying the law of armed con˚ict 
jus in bello
 (pro
-portionality, necessity, distinction, and so on) to cyberattack even if the 

use of cyberattack is contemplated for situations that fall short of actual 

armed con˚ict. 
The application of these principles would be particularly relevant in 
two situations:

Co
vert actions in
vol
ving cyberattack.
 (As noted in Chapter 4, tradi
-tional U.S. interpretations of the laws of armed con˚ict require covert 

action, whether or not it involves violent activities, to be conducted con
-sistent with LOAC™s requirements.)

Periods of heightened tension,
 during which combatant commanders 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 69
may undertake some cyberattack activities for shaping the operational 
environment to facilitate later employment of other activities (as noted 
in Chapter 3). 
Recommendation 8:
 The United States should maintain and 
acquire effective cyberattack capabilities. Advances in capabili
-ties should be continually factored into policy development, and 

a comprehensive budget accounting for research, development, 

testing, and evaluation relevant to cyberattack should be avail
-able to appropriate decision makers in the executive and legisla
-tive branches.
The committee believes that it would be unwise policy to eschew 
cyberattack under all circumstances. For those instances in which the 
use of cyberattack is warranted, the United States should have at its 

disposal the most effective and ˚exible cyberattack technologies and sup
-porting infrastructure possibleŠsystems that can operate on the time 

scales required, with the necessary command and control (including self-

destruct when necessary and appropriate), guided by the best possible 

intelligence information, with a high probability of mission success and a 

low risk of collateral damage.
Accordingly, in addition to a robust and signi˜cant effort for research, 
development, testing, and evaluation to strengthen U.S. cyber defensive 

capabilities, the committee believes that the United States should continue 

to invest in the development and acquisition of effective and highly ˚ex
-ible cyberattack capabilities. In addition to providing operational utility, 

such capabilities may strengthen deterrence against cyber adversaries. 

Lastly, increased knowledge of cyberattack technologies will contribute 

to the knowledge base supporting development of improved defensive 

capabilities, assuming that mechanisms can be found to promote cross-

fertilization among the researchers in the relevant areas. 
If and when new policy emerges that calls for a deemphasis of cyber
-attack capabilities, the U.S. investment can be scaled back at that time. 

The committee recognizes precedents from history in which the momen
-tum built up by a large-scale development and procurement plan made 

changes in policy more dif˜cult to accomplish. Nevertheless, it believes 

that acquiring many kinds of cyberattack weaponry is relatively inexpen
-sive compared to traditional large-scale weapons acquisition efforts, and 

thus policy changes would be easier to effect.
In addition, even if international agreements are made to restrict the 
use of cyberattack, nations must prepare for the possibility that non-sig
-natories (e.g., non-state actors, or recalcitrant states) or ﬁcheatingﬂ states 

will not abide by the provisions of any such agreementŠand for the 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.70 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
United States to not be prepared to compete successfully in such a world 
is unacceptable.
Finally, it is important for the United States to have a comprehen
-sive view of the effort among all of the relevant stakeholders to develop 
and acquire cyberattack capabilities. Some responsible party within the 

executive branch, perhaps an of˜ce within the Of˜ce of Management 

and Budget, should have a cross-agency view into overall amounts being 

spent on acquisition of cyberattack capabilities and the details of how 

individual agency budgets are being spent. Overall levels of spending and 

the relevant detail should be available, on a classi˜ed basis as necessary, 

to appropriate congressional decision makers. (Recommendation 8 is not 

a plea for centralized direction of the acquisition effort, but rather one for 

information to help policy makers understand the overall effort.) 
Recommendation 9:
 The U.S. government should ensure that 
there are suf˜cient levels of personnel trained in all dimensions of 

cyberattack, and that the senior leaders of government have more 

than a nodding acquaintance with such issues.
The issues related to cybercon˚ict are quite complex. Conducting 
cyberattacks requires specialized expertise in operations, intelligence, and 
communications, as well as law and technology. Understanding policy 

related to cyberattack requires expertise in defense, intelligence, law 

enforcement, and homeland security, and in diplomacy, foreign relations, 

and international law. In short, the prospect of cybercon˚ict requires that 

considerable attention be given to professionalization of the involved 

workforce. 
These needs contrast with the history of how today™s thinking about 
cyberattack has evolved over the last few decades. The personal comput
-ers ˜rst introduced in the 1980s and then later the World Wide Web in 

the mid-1990s are the most visible signs of the information technology 

revolution that increasingly has affected all sectors of society, including 

the military. The possibility of information and information technology as 

the driver for a revolution in military affairs began to gain in˚uence dur
-ing this time, along with the notion of attacking an adversary™s comput
-ers as an instrument of warfare. However, for the most part, that notion 

was con˜ned to the grass roots of the military, and only recently has the 

thinking of senior military leadership begun to embrace such possibilities 

seriously.
Against this backdrop, the paucity of educational opportunities in 
this domain for senior leadership, the professional military, the diplo
-matic corps, intelligence analysts, law enforcement of˜cials, and others is 

striking. As importantly, because cybercon˚ict is interdisciplinary, career 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 71
paths and opportunities for specialists in this area are few in number. 
Accordingly, the committee believes that the U.S. government should 
make signi˜cant efforts to develop human capital with expertise in the 

issues related to cyberattack.
Recommendation 10:
 The U.S. government should consider 
the establishment of a government-based institutional structure 

through which selected private sector entities can seek immediate 

relief if they are the victims of cyberattack.
As suggested in Finding 
7, the United States lacks mechanisms for 
responding effectively to prevent further harm if a private sector entity is 
subjected to a cyberattack. 
Given the numerous cyberattacks endured by U.S. private sector enti
-ties, it would not be surprising if one or more of these entities have taken 

self-help action in the past. And it is further likely that in the absence 

of meaningful and effective mechanisms to prevent further damage in 

the wake of a cyberattack, some such parties will seriously contemplate 

taking such action in the future if they feel that the costs of such action 

are less than the bene˜ts from neutralizing the incoming attack, even if 

such actions constitute a violation of the Computer Fraud and Abuse Act 

(Section 5.2). 
The argumentation for Finding 
7 noted some of the undesirable 
aspects of taking self-help action. But the committee does not believe 

that a simple prohibition on such action, or even raising the penalties 

for such action, are alone suf˜cient to prevent all self-help actions in the 

future. For this reason, it may be desirable to consider the establishment 

of a government-regulated institutional structure through which private 

sector entities that are the targets of sustained and ongoing cyberattack 

can seek immediate relief.
A boundary condition in determining the appropriate structure is 
the impact of similar developments in other nations. That is, the U.S. 

government should consider the impact on the United States if other 

nations were to develop similar institutional structures to protect their 

own private sector entities.
In the absence of further study, the committee makes no endorsement 
of speci˜c elements that should be included in the structure proposed in 

Recommendation 10. The following elements are listed for illustrative 

purposes only, and it should be noted that committee members disagreed 

among themselves about the desirability of some of these as elements of a 

structure for helping private sector victims of a cyberattack.

Impro
vements in capabilities for threat warning and attack assessment to 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.72
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
support better forensics. 
Such improvements are a necessary precondition if 
active threat neutralization is to be a viable policy option.

International agreements that bind signatories to respond quickly with 
law enforcement actions to suppress cyberattacks emanating from their territory,
 with failure to do so entitling the target of the cyberattack to seek threat 
neutralization in response if it is located in a signatory nation.

An explicit clari˚cation of the limits to defense of property for 
violating 
the Computer Fraud and Abuse Act,
 which could explicitly allow or prohibit 
cyberattacks for this purpose.

An explicit clari˚cation of whether the 
victim of a cyberattack is permitted 
to non-destructi
vely gather intelligence on the attacker in a non-cooperati
ve man
-ner.
 If allowed, such activities would have to be documented meticulously 

to demonstrate the lack of hostile intent. 

A capability for gathering the information needed to effect threat neu
-tralization, accompanied by explicit rules and regulation, perhaps established by 

statute, to specify:
The selected private sector entities that are entitled to call on the 
government to exercise this capability for threat neutralization and 

the standards of security practice required of such entities;
29
The circumstances under which threat neutralization is to be 
performed;
The criteria needed to identify the attacking party with suf˜
-ciently high con˜dence; and
The evidence needed to make the determination that any given 
cyberattack posed a threat suf˜ciently severe to warrant neutralization.
Again, to be clear, the committee does not recommend that any spe
-ci˜c element in the list above be included or excluded in the institutional 
structure proposed for consideration in Recommendation 10. For exam
-ple, some committee members believe that a government capability for 

threat neutralization is a necessary element of a robust deterrence posture 

against cyberattack on private sector entities, and they argue that entities 

under attack should themselves be allowed to effect threat neutralization 

subject to appropriate government regulation. Others believe it would 

be a serious mistake to erode the government™s legal monopoly on cyber 

violence, and that such a capability, even if invoked promptly, would have 
29
 The term ﬁselectedﬂ is used in recognition of the fact that not all such entities neces
-sarily warrant access to the institutional structure considered in Recommendation 10, and 
thus some mechanism will be necessary for selecting those entities that are deemed eligible. 

ﬁStandards of security practiceﬂ refers to the fact that these entities should be required to 

adhere to good security practices as a necessary prior condition before calling for outside 

assistance.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 73
at best a minimal impact in providing relief to the private sector entities 
under attack. Despite such disagreements, the committee does believe 
that it is important for the U.S. government to consider what can be done 

to help private sector entities cope with the undeniable inadequacies of 

passive defense as things currently stand.
1.9.4
 Developing New Knowledge and Insight into a 
 New Domain of Con˜ict
Recommendation 11:
 The U.S. government should conduct high-

level wargaming exercises to understand the dynamics and poten
-tial consequences of cybercon˚ict.
As noted in Chapter 9, the dynamics of cybercon˚ict are not well 
understood, and many of the most interesting questions about cybercon
-˚ict concern matters related to deterrence, compulsion, and escalation. 
What are the elements that contribute to stability when cybercon˚ict 

is possible? What causes cyber adversaries to be deterred from taking 

hostile action? How might cyberwarfare escalate? Signi˜cant insight into 

crisis stability, deterrence, escalation, and other issues related to cyber
-con˚ict might be gained by conducting serious high-level wargaming 

exercises involving individuals with policy backgrounds and others with 

operational experience in cyberattack. The participation of active-duty 

and in-of˜ce individuals would also help to familiarize them with some of 

the issues. As importantly, a ﬁgamemasterﬂ with detailed technical knowl
-edge of cyberdefenses and what is and is not possible through cyberattack 

would be essential for such exercises to produce useful knowledge. The 

insight and knowledge gained would be useful to senior decision makers 

(who would become more familiar with the issues involved), to analysts 

(who would gain insight into how decision makers think about such 

issues), and to operational personnelŠthe war˜ghtersŠwho would gain 

experience in the same way that regular exercises help traditional forces 

develop expertise.
Recommendation 12:
 Foundations and government research 
funders should support academic and think-tank inquiry into 

cybercon˚ict, just as they have supported similar work on issues 

related to nuclear, biological, and chemical weapons.
The committee believes that cybercon˚ict and cyberattack are topics 
that are both important and understudied. Much of the serious thought 
about such subjects to date has originated in the Department of Defense, 

and much of that work has been classi˜ed. Whether or not the commit
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.74 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
tee™s recommendation is adopted regarding declassi˜cation of the policy-
related discussion of cyberattack, the nation can only be better served 
by more open debate, discourse, and scholarship across the intellectual 

spectrum. 
As noted in the Preface to this report, a greater interest in and more 
open intellectual activity regarding the subject of cyberattack would con
-stitute an important mark of success for this committee™s efforts.
Some important technical issues worth investigation include the 
following:

Attribution of cyberattacks.
 Arguably the most salient technical issue 
in cybercon˚ict, other reports have underscored both the importance and 

the dif˜culty of solving the attribution problem.
30
 This report emphati
-cally reiterates those conclusions. 

Attack identi˚cation.
 Knowing that a nation or even a particular 
facility is under serious cyberattack is highly problematic given the back
-ground noise of ongoing cyberattacks all the time. 

Geolocation of a computer that might be remotely attacked.
 Given that 
computers are physical objects, any computer that might be attacked is 

in some physical location. Knowledge of that location may be important 

in understanding the political impact of any given cyberattack. 

Techniques for limiting the scope of a cyberattack.
 Associated with a 
kinetic munition is the notion of a lethal radius outside of which a given 

type of target is likely to be relatively unharmed. Lethal radius is a key 

construct for minimizing collateral damage when such munitions are 

used. In a world of interconnected computers, what might be a plausible 

analog for a ﬁlethal radiusﬂ for cyberweapons?
There are also a host of non-technical issues raised by some of the 
discussion in this report. For example:

How might cyberattack best be used to undermine the con˜dence 
of users in their information technology systems? What are the character
-istics of the minimum attack needed to achieve this goal?

What might be the impact on con˚ict escalation of inhibiting cyber 
offensive actions early in a tense international situation?

How might cyberattack be used to support information operations 
such as propaganda?

What are the relative advantages and disadvantages of different 
declaratory policies regarding cyberattack? 
30
 National Research Council, 
Toward a Safer and More Secure Cyberspace
, The National 
Academies Press, Washington D.C., 2007. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.OVERVIEW, FINDINGS, AND RECOMMENDATIONS
 75

What are the relative advantages and disadvantages of different 
policies regarding self-help actions by private sector entities that come 
under cyberattack themselves? 

What are the dynamics of known instances of cyberattack and 
cybercon˚ict? How did the parties learn they were under attack? How did 

they decide to respond? What were the rami˜cations of responding?
1.10
 CONCLUSION
Cyberattack technologies bring to the forefront of policy a wide range 
of possibilities in many dimensions: They raise many new policy issues, 

they provide many more options for operational commanders, and they 

complicate existing legal regimes to a considerable extent. But the ˜nd
-ings of this report illustrate that thinking about U.S. acquisition and use 

of cyberattack capabilities need not start from scratch. Although a number 

of important nuances and subtleties can signi˜cantly complicate policy 

making regarding cyberattack, cyberattack should not be regarded as 

a 
sui generis
 form of warfare, and there is much to be said for drawing 
analogies to existing procedures, practices, and intellectual paradigms. 

At the same time, developing new knowledge is likely to be essential for 

genuinely informed policy making regarding cyberattack.
The thinking of the U.S. government on the topic of cyberattack is 
changing rapidly even as this report is being written. Because most of this 

ferment takes place behind the shields of classi˜cation, it is impossible to 

provide in an unclassi˜ed study a de˜nitive report on what is going on 

today within the U.S. government, and it is entirely possible that some of 

the ˜ndings articulated and discussed above are already re˚ected in parts 

of the U.S. government and that some of the recommendations are already 

being implemented. If so, the committee applauds such actions. But for 

those ˜ndings and recommendations that have not been incorporated 

into government processes and thinking, the committee hopes that they 

will be seriously considered and that they will stimulate a government 

reexamination of its thinking in the relevant areas.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Part I
Framing and Basic Technology
Part I contains one chapterŠChapter 2Šwhich provides an introduc
-tion to the technological and operational dimensions of cyberattack. The 
technological dimensions refer to what cyberattacks are and how they 

might be conducted. As the chapter makes clear, there are many differ
-ent kinds of cyberattack with many different kinds of objectives, and the 

term ﬁcyberattackﬂ without further quali˜cation should be seen more as a 

statement about the use of a particular attack methodology than about its 

targets or purpose. The operational dimensions refer to the support that a 

successful cyberattack requires, such as intelligence information about its 

targets and ways to start, stop, and calibrate a cyberattack. Cyberexploita
-tion is addressed separately and in contrast to cyberattack. 
Note to the reader: 
When the name of a nation is needed in this report, 
the names ﬁZendiaﬂ and ﬁRuritaniaﬂ are used as stand-ins. Depending on 

context, these nations may be a near-peer nation-state with military and 

economic stature and power comparable to that of the United States; a 

small, relatively undeveloped nation; or something in between. Generally 

in this report, Zendia is an adversary of the United States.
77
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.2Technical and Operational 
Considerations in Cyberattack and 
Cyberexploitation
This chapter focuses on technical and operational dimensions of 
cyberattack and cyberexploitation. Section 2.1 provides the essential 
points of the entire chapter, with the remainder of the chapter provid
-ing analytical backup. Section 2.2 addresses the basic technology of 
cybe
rattack. Section 2.3 addresses various operational considerations 
associated with ﬁweaponizingﬂ the basic technology of cyberattack. 

These sections are relevant both to the attacker, who uses cyberattack as 

a tool of his own choosing, and to the defender, who must cope with and 

respond to incoming cyberattacks launched by an attacker. Section 2.4 

focuses on the centrally important issue of characterizing an incoming 

cyberattack. Cyberattack and cyberdefense are sometimes intimately 

related through the practice of active defense (Section 2.5), which may 

call for the defender to launch a cyberattack itself in response to an 

incoming cyberattack on it. Section 2.6 addresses cyberexploitation and 

how its technical and operational dimensions differ from cyberattack. 

Section 2.7 provides some lessons that can be learned from examining 

criminal use of cyberattack and cyberexploitation.
For perspective on tools used for cyberattack, Table 2.1 provides a 
comparison of tools for kinetic attack and tools for cyberattack.
Note:
 The committee has no speci˜c information on actual U.S. cyber
-attack or cyberexploitation capabilities, and all references in this chapter 

to U.S. cyberattack or cyberexploitation capabilities are entirely hypotheti
-cal, provided for illustrative purposes only. 
79
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.80 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
2.1
 IMPORTANT
 C
HARACTERISTICS
 OF
  CYBERATTACK
 AND
 C
YBEREXPLOITATION
For purposes of this report, cyberattack refers to the use of deliber
-ate actionsŠperhaps over an extended period of timeŠto alter, disrupt, 
deceive, degrade, or destroy adversary computer systems or networks 

or the information and/or programs resident in or transiting these sys
-tems or networks. Several characteristics of weapons for cyberattack are 
 worthy of note: 
Ł The indirect effects of such weapons are almost always more con
-sequential than the direct effects of the attack. (Direct or immediate effects 
are effects on the computer system or network attacked. Indirect or fol
-low-on effects are effects on the systems and/or devices that the attacked 

computer system or network controls or interacts with, or on the people 

that use or rely on the attacked computer system or network.) That is, 

the computer or network attacked is much less relevant than the systems 

controlled by the targeted computer or network or the decision making 

that depends on the information contained in or processed by the targeted 

computer or network, and indeed the indirect effect is often the primary 

purpose of the attack. Furthermore, the scale of damage of a cyberattack 

can span an enormous range. 
TABLE 2.1
 A Comparison of Key Characteristics of Cyberattack 
Versus Kinetic Attack
Kinetic Attack
Cyberattack
Effects of significance
Direct effects usually 
more important than 
indirect effects
Indirect effects usually more 
important than direct 

effects
Reversibility of direct 
effects
Low, entails 
reconstruction or 

rebuilding that may 

be time-consuming
Often highly reversible on a 
short time scale
Acquisition cost for 
weapons
Largely in procurement
Largely in research and 
development
Availability of base 
technologies
Restricted in many 
cases
Widespread in most cases
Intelligence 
requirements for 

successful use
Usually smaller than 
those required for 

cyberattack
Usually high compared to 
kinetic weapons
Uncertainties in 
planning
Usually smaller than 
those involved in 

cyberattack
Usually high compared to 
kinetic weapons
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 81
Ł The outcomes of a cyberattack are often highly uncertain. Minute 
details of con˜guration can affect the outcome of a cyberattack, and cas
-cading effects often cannot be reliably predicted. One consequence can be 
that collateral damage and damage assessment of a cyberattack may be 

very dif˜cult to estimate.
Ł Cyberattacks are often very complex to plan and execute. They 
can involve a much larger range of options than most traditional military 

operations, and because they are fundamentally about an attack™s sec
-ondary and tertiary effects, there are many more possible outcome paths 

whose analysis often requires highly specialized knowledge. The time 

scales on which cyberattacks operate can range from tenths of a second 

to years, and the spatial scales may be anywhere from ﬁconcentrated in a 

facility next doorﬂ to globally dispersed.
Ł Compared to traditional military operations, cyberattacks are rela
-tively inexpensive. The underlying technology for carrying out cyberat
-tacks is widely available, inexpensive, and easy to obtain. An attacker 

can compromise computers belonging to otherwise uninvolved parties 

to take part in an attack activity; use automation to increase the amount 

of damage that can be done per person attacking, increase the speed at 

which the damage is done, and decrease the required knowledge and skill 

level of the operator of the system; and even steal the ˜nancial assets of an 

adversary to use for its own ends. On the other hand, some cyberattack 

weapons are usable only once or a few times.
Ł The identity of the originating party behind a signi˜cant cyberat
-tack can be concealed with relative ease, compared to that of a signi˜
-cant kinetic attack. Cyberattacks are thus easy to conduct with plausible 

deniabilityŠindeed, most cyberattacks are inherently deniable. Cyberat
-tacks are thus also well suited for being instruments of catalytic con˚ictŠ

instigating con˚ict between two other parties. 
Cyberexploitations are different from cyberattacks primarily in their 
objectives and in the legal constructs surrounding them. Yet, much of the 

technology underlying cyberexploitation is similar to that of cyberattack, 

and the same is true for some of the operational considerations as well. A 

successful cyberattack requires a vulnerability, access to that vulnerability, 

and a payload to be executed. A cyberexploitation requires the same three 

thingsŠand the only difference is in the payload to be executed. That is, 

what technically distinguishes a cyberexploitation from a cyberattack is 

the nature of the payload. These technical similarities often mean that a 

targeted party may not be able to distinguish easily between a cyberex
-ploitation and a cyberattackŠa fact that may result in that party™s making 

incorrect or misinformed decisions. On the other hand, the primary tech
-nical requirement of a cyberexploitation is that the delivery and execution 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.82
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
of its payload must be accomplished quietly and undetectablyŠsecrecy is 
often far less important when cyberattack is the mission.
2.2
 THE
 B
ASIC
 T
ECHNOLOGY
 OF
 C
YBERATTACK
1Perhaps the most important point about cyberattack from the stand
-point of a major nation-state, backed by large resources, national intelli
-gence capabilities, and political in˚uence is that its cyberattack capabili
-ties dwarf the kinds of cyberattacks that most citizens have experienced in 
everyday life or read about in the newspapers. To use a sports metaphor, 

the cyberattacks of the misguided teenagerŠeven sophisticated onesŠ

could be compared to the game that a good high school football team can 

play, whereas the cyberattacks that could be conducted by a major nation-

state would be more comparable to the game of a professional football 

team with a 14-2 win-loss record in the regular season.
2.2.1
 Information Technology and Infrastructure
Before considering the basic technology of cyberattack, it is helpful 
to review a few facts about information technology (IT) and today™s IT 

infrastructure.
Ł The technology substrate of today™s computers, networks, oper
-ating systems, and applications is not restricted to the U.S. military, or 

even just to the United States. Indeed, it is widely available around the 

world, to nations large and small, to subnational groups, and even to 

individuals.
Ł The essential operating parameters of this technology substrate 
are determined largely by commercial needs rather than military needs. 

Military IT draws heavily on commercial IT rather than the reverse.
Ł A great deal of the IT infrastructure is shared among nations and 
between civilian and military sectors, though the extent of such sharing 

varies by nation. Systems and networks used by many nations are built 

by the same IT vendors. Government and military users often use com
-mercial Internet service providers. Consequently, these nominally private 

entities exert considerable in˚uence over the environment in which any 

possible cybercon˚ict might take place.
1 A primer on cyberattack in a military context can be found in Gregory Rattray, 
Strate
-gic Warfare in Cyberspace, 
MIT Press, Cambridge, Mass., 2001. Rattray™s treatment covers 
some of the same ground covered in this chapter.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 83
2.2.2
 Vulnerability, Access, and Payload
A successful cyberattack requires a vulnerability, access to that vul
-nerability, and a payload to be executed.
2 In a non-cyber context, a vulner
-ability might be an easily pickable lock in the ˜le cabinet. Access would 
be an available path for reaching the ˜le cabinetŠand from an intruder™s 

perspective, access to a ˜le cabinet located on the International Space 

Station would pose a very different problem from that posed by the same 

cabinet being located in an of˜ce in Washington, D.C. The payload is 

the action taken by the intruder after the lock is picked. For example, he 

can destroy the papers inside, or he can alter some of the information on 

those papers.
2.2.2.1
 Vulnerabilities
For a computer or network, a vulnerability is an aspect of the system 
that can be used by the attacker to compromise one or more of the attri
-butes described in the previous section. Such weaknesses may be acci
-dentally introduced through a design or implementation ˚aw. They may 

also be introduced intentionally. An unintentionally introduced defect 

(ﬁbugﬂ) may open the door for opportunistic use of the vulnerability by 

an attacker who learns of its existence. Many vulnerabilities are widely 

publicized after they are discovered and may be used by anyone with 

moderate technical skills until a patch can be disseminated and installed.
3 Attackers with the time and resources may also discover unintentional 

defects that they protect as valuable secretsŠalso known as zero-day 

exploits.
4 As long as those defects go unaddressed, the vulnerabilities they 
create may be used by the attacker.
2 In the lexicon of cybersecurity, ﬁusingﬂ or ﬁtaking advantageﬂ of a vulnerability is 
often called ﬁexploiting a vulnerability.ﬂ Recall that Chapter 1 uses the term ﬁcyberexploita
-tionﬂ in an espionage contextŠa cyber offensive action conducted for the purpose of obtain
-ing information. The context of usage will usually make clear which of these meanings of 
ﬁexploitﬂ is intended. 
3 The lag time between dissemination of a security ˜x to the public and its installation 
on a speci˜c computer system may be considerable, and it is not always due to unawareness 

on the part of the system administrator. It sometimes happens that the installation of a ˜x 

will cause an application running on the system to cease working, and administrators may 

have to weigh the potential bene˜t of installing a security ˜x against the potential cost of 

rendering a critical application non-functional. Attackers take advantage of this lag time to 

exploit vulnerabilities.
4 A zero-day attack is a previously unseen attack on a previously unknown vulner
-ability. The term refers to the fact that the vulnerability has been known to the defender for 

zero days. (The attacker has usually known of the attack for a much longer time.) The most 

dangerous is a zero-day attack on a remotely accessible service that runs by default on all 

versions of a widely used operating system distribution. These types of remotely accessible 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.84 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Two additional factors have increased opportunities for the attacker. 
First, the use of software in society has grown rapidly in recent years, and 
the sheer amount of software in use continues to expand across societal 

functions. For instance, a study by the Center for Strategic and Interna
-tional Studies estimated that the amount of software used in Department of 

Defense systems has been increasing rapidly with no let-up for the foresee
-able future.
5 More software in use inevitably means more vulnerabilities.
Second, software has also grown in complexity. Users demand more 
and more from software, and thus the complexity of software to meet user 

requirements increases steadily. Complex software, in turn, is dif˜cult to 

understand, evaluate, and test.
6 In addition, software is generally devel
-oped to provide functionality for a wide range of users, and for any par
-ticular user only a limited set of functionality may actually be useful. But 

whether used or not, every available capability presents an opportunity 

for new vulnerabilities. Simply put, unneeded capability means unneces
-sary vulnerability.
7 Even custom systems often include non-essential but 
ﬁnice-to-haveﬂ features that from a security perspective represent added 

potential for risk, and the software acquisition process is often biased in 

favor of excess functionality (seen as added value) while failing to prop
-erly evaluate added risk.
Of course, vulnerabilities are of no use to an attacker unless the 
attacker knows they are present on the system or network being attacked. 

But an attacker may have some special way of ˜nding vulnerabilities, and 

nation-states in particular often have special advantages in doing so. For 

example, although proprietary software producers jealously protect their 

source code as intellectual property upon which their business is depen
-dent, some such producers are known to provide source-code access to 

governments under certain conditions.
8 zero-day attacks on services appear to be less frequently found as time goes on. In response, 
a shift in focus to the client side has occurred, resulting in many recent zero-day attacks on 

client-side applications. For data and analysis of zero-day attack trends, see pages 278-287 

in Daniel Geer, 
Measuring Security
, Cambridge, Mass., 2006, available at http://geer.tinho.
net/measuringsecurity.tutorialv2.pdf.
5 Center for Strategic and International Studies, ﬁAn Assessment of the National Se
-curity Software Industrial Base,ﬂ presented at the National Defense Industrial Association 

Defense Software Strategy Summit, October 19, 2006, available at http://www.diig-csis.

org/pdf/Chao_SoftwareIndustrialBase_NDIASoftware.pdf. 
6 Defense Science Board, ﬁReport of the Defense Science Board Task Force on Mission 
Impact of Foreign In˚uence on DoD Software,ﬂ U.S. Department of Defense, September 

2007, p. 19.
7 Defense Science Board, ﬁReport of the Defense Science Board Task Force on Mission 
Impact of Foreign In˚uence on DoD Software,ﬂ U.S. Department of Defense, September 

2007, p. 55.
8 See, for example, http://www.microsoft.com/industry/publicsector/government/
programs/GSP.mspx.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 85
Availability of source code for inspection increases the likelihood that 
the inspecting party (government) will be able to identify vulnerabilities 
not known to the general public. Furthermore, through covert and non-

public channels, nation-states may even be able to persuade vendors or 

willing employees of those vendors to insert vulnerabilitiesŠsecret ﬁback 

doorsﬂŠinto commercially available products (or require such insertion 

as a condition of export approval), by appealing to their patriotism or 

ideology, bribing or blackmailing or extorting them, or applying political 

pressure. 
In other situations, a nation-state may have the resources to obtain 
(steal, buy) an example of the system of interest (perhaps already embed
-ded in a weapons platform, for example). By whatever means the sys
-tem makes its way into the hands of the nation-state, the state has the 

resources to test it extensively to understand its operational strengths and 

weaknesses, and/or conduct reverse engineering on it to understand its 

various functions and at least some of its vulnerabilities.
Some of the vulnerabilities useful to cyberattackers include the 
following:
Ł Software.
 Application or system software may have accidentally or 
deliberately introduced ˚aws whose use can subvert the intended pur
-pose for which the software is designed.
Ł Hardware.
 Vulnerabilities can also be found in hardware, including 
microprocessors, microcontrollers, circuit boards, power supplies, periph
-erals such as printers or scanners, storage devices, and communications 

equipment such as network cards. Tampering with such components may 

secretly alter the intended functionality of the component, or provide 

opportunities to introduce hostile software.
Ł Seams between hardware and software.
 An example of such a seam 
might be the reprogrammable read-only memory of a computer (˜rm
-ware) that can be improperly and clandestinely reprogrammed.
Ł Communications channels.
 The communications channels between 
a system or network and the ﬁoutsideﬂ world can be used by an attacker 

in many ways. An attacker can pretend to be an ﬁauthorizedﬂ user of the 

channel, jam it and thus deny its use to the adversary, or eavesdrop on it 
to obtain information intended by the adversary to be con˜dential.
 Ł Con˚guration.
 Most systems provide a variety of con˜guration 
options that users can set, based on their own security versus convenience 

tradeoffs. Because convenience is often valued more than security, many 

systems areŠin practiceŠcon˜gured insecurely.
Ł Users and operators. 
Authorized users and operators of a system 
or network can be tricked or blackmailed into doing the bidding of an 

attacker.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.86
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Ł Ser
vice pro
viders.
 Many computer installations rely on outside par
-ties to provide computer-related services, such as maintenance or Internet 
service. An attacker may be able to persuade a service provider to take 

some special action on its behalf, such as installing attack software on a 

target computer.
Appendix E discusses these vulnerabilities in more detail.
2.2.2.2
 Access
In order to take advantage of a vulnerability, a cyberattacker must 
have access to it. Targets that are ﬁeasyﬂ to attack are those that involve 

relatively little preparation on the part of the attacker and where access 

to the target can be gained without much dif˜cultyŠsuch as a target that 

is known to be connected to the Internet. Public websites are a canonical 

example of such targets, as they usually run on generic server software 

and are connected to the Internet, and indeed website defacement is 

an example of a popular cyberattack that can be launched by relatively 

unskilled individuals.
At the other end of the spectrum, dif˜cult targets are those that require 
a great deal of preparation on the part of the attacker and where access 

to the target can be gained only at great effort or may even be impossible 

for all practical purposes. For example, the on-board avionics of an adver
-sary™s ˜ghter plane are not likely to be connected to the Internet for the 

foreseeable future, which means that launching a cyberattack against it 

will require some kind of close access to introduce a vulnerability that can 

be used later (close-access attacks are discussed in Section 2.2.5.2). Nor 

are these avionics likely to be running on a commercial operating system 

such as Windows, which means that information on the vulnerabilities 

of the avionics software will probably have to be found by obtaining a 

clandestine copy of it. In general, it would be expected that an adversary™s 

important and sensitive computer systems or networks would fall into the 

category of dif˜cult targets.
9Access paths to a target may be transient. For example, antiradiation 
missiles often home in on the emissions of adversary radar systems; once 
9 An important caveat is the fact that adversary computer systems and networks are 
subject to the same cost pressures as U.S. systems and networks, and there is no reason to 
suppose that adversaries are any better at avoiding dumb mistakes than the United States 

is. Thus, it would not be entirely surprising to see important and/or sensitive systems con
-nected to the Internet because the Internet provides a convenient communications medium, 

or for such systems to be built on commercial operating systems with known vulnerabilities 

because doing so would reduce the cost of development. However, the point is that no cy
-berattacker can 
count on
 such dumb mistakes for any particular target of interest.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 87
the radar shuts down, the missile aims at the last known position of the 
radar. Counterbattery systems locate adversary artillery by backtracing 
the trajectory of artillery shells, but moving the artillery piece quickly 

makes it relatively untargetable. Similar considerations sometimes apply 

to an adversary computer that makes itself known by transmitting (e.g., 

conducting an attack). Under such circumstances, a successful cyberat
-tack on the adversary computer may require speed to establish an access 

path and use a vulnerability before the computer goes dark and makes 

establishing a path dif˜cult or impossible.
Under some other circumstances, an access path may be intermittent. 
For example, a submarine™s onboard administrative local area network 

would necessarily be disconnected from the Internet while underwater 

at sea, but might be connected to the Internet while in port. If the admin
-istrative network is ever connected to the on-board operational network 

(controlling weapons and propulsion) at sea, an effective access path may 

be present for an attacker.
Access paths to a target can suggest a way of differentiating between 
two categories of cyberattack:
Ł Remote-access cyberattacks,
 in which an attack is launched at some 
distance from the adversary computer or network of interest. The canoni
-cal example of a remote access attack is that of an adversary computer 

attacked through the access path provided by the Internet, but other 

examples might include accessing an adversary computer through a dial-

up modem attached to it or through penetration of the wireless network 

to which it is connected and then proceeding to destroy data on it.
10
Ł Close-access cyberattacks,
 in which an attack on an adversary com
-puter or network takes place through the local installation of hardware 

or software functionality by friendly parties (e.g., covert agents, vendors) 

in close proximity to the computer or network of interest. Close access 

is a possibility anywhere in the supply chain of a system that will be 

deployed, and it may well be easier to gain access to the system before it 

is deployed.
These two categories of cyberattack may overlap to a certain extent. 
For example, a close-access cyberattack might result in the implantation 

of friendly code in online, Internet-propagated updates to a widely used 
10
 The Department of Defense (DOD) de˜nition of computer network attack (CNA)Š
ﬁactions taken through the use of computer networks to disrupt, deny, degrade, or destroy 
information resident in computers and computer networks, or the computers and networks 

themselvesﬂŠis similar in spirit to this report™s use of ﬁremote-accessﬂ cyberattack. See Joint 

Publication 3-13, 
Information Operations
, February 13, 2006.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.88
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
program. Such an attack would embody elements of the two categories. 
Also, communications channels (the channels through which IT systems 
and networks transfer information) can also be targeted through remote 

access (e.g., penetrating or jamming a wireless network) or through close 

access (e.g., tapping into a physical cable feeding a network). 
2.2.2.3
 Payload
Payload is the term used to describe the things that can be done once 
a vulnerability has been exploited. For example, once a software agent 

(such as a virus) has entered a given computer, it can be programmed to 

do many thingsŠreproducing and retransmitting itself, destroying ˜les 

on the system, or altering ˜les. 
Payloads can have multiple capabilities when inserted into an adver
-sary system or networkŠthat is, they can be programmed to do more than 

one thing. The timing of these actions can also be varied. And if a com
-munications channel to the attacker is available, payloads can be remotely 

updated. Indeed, in some cases, the initial delivered payload consists of 

nothing more than a mechanism for scanning the system to determine its 

technical characteristics and an update mechanism to retrieve from the 

attacker the best packages to further its attack.
A hostile payload may be a Trojan horseŠa program that appears to 
be innocuous but in fact has a hostile function that is triggered immedi
-ately or when some condition is met. It may also be a rootkitŠa program 

that is hidden from the operating system or virus checking software 

but that nonetheless has access to some or all of the computer™s func
-tions. Rootkits can be installed in the boot-up software of a computer, 

and even in the BIOS ROM hardware that initially controls the boot-up 

sequence. (Rootkits installed in this latter manner will remain even when 

the user erases the entire hard disk and reinstalls the operating system 

from scratch.)
Once introduced into a targeted system, the payload sits quietly and 
does nothing harmful most of the time. However, at the right moment, the 

program activates itself and proceeds to (for example) destroy or corrupt 

data, disable system defenses, or introduce false message traf˜c. The ﬁright 

momentﬂ can be triggered because a certain date and time are reached, 

because the payload receives an explicit instruction to activate through some 

covert channel, because the traf˜c it monitors signals the right moment, or 

because something speci˜c happens in its immediate environment. 
An example is a payload that searches for ﬁpackets of death.ﬂ This 
payload examines incoming data packets on a host for a special pattern 

embedded within it. For almost all packets, the payload does nothing. 

But when it sees a particular sequence of specially con˜gured packets, 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 89
it triggers some other hostile actionŠit crashes the system, deletes ˜les, 
corrupts subsequent data packets, and so on. (Note that the hostile action 
may be to do nothing when action should be takenŠan air-defense sys
-tem that ignores the signature of certain aircraft when it receives such a 

packet has clearly been compromised.)
Note that payloads for cyberattack may be selective or indiscriminate 
in their targeting. That is, some payloads for cyberattack can be con˜g
-ured to attack any computer to which access may be gained, and others 

can be con˜gured to attack quite selectively only certain computers.
2.2.3
 Scale and Precision 
A cyberattack can be conducted over a wide range of scales, depend
-ing on the needs of the attacker. An attack intended to degrade con˜dence 

in the IT infrastructure of a nation might be directed against every Inter
-net-connected desktop computer that uses a particular operating system. 

Attacks intended to ﬁzombifyﬂ computers for later use in a botnet need 

not succeed against any particular machine, but instead rely on the fact 

that a large fraction of the machines connected to the Internet will be 

vulnerable to being compromised.
Alternatively, a cyberattack might be directed to all available targets 
across one or more critical infrastructure sectors. A probe intended to test 

the feasibility of a large-scale cyberattack might be directed against just a 

few such computers selected at random. An attack might also be directed 

against a few selected key targets in order to have secondary effects (e.g., 

disruption of emergency call dispatch centers timed to coincide with 

physical attacks, thus amplifying the psychological effect of those physi
-cal attacks). 
A cyberattacker may also care about which computers or networks 
are targetedŠan issue of precision. Of greatest signi˜cance are the sce
-narios in which focused but small-scale attacks are directed against a 

speci˜c computer or user whose individual compromise would have 

enormous value (ﬁgoing after the crown jewelsﬂ)Šan adversary™s nuclear 

command and control system, for example. Or, a cyberattack may be 

directed against a particular electric power generation plant that powers 

a speci˜c building in which adversary command and control systems are 

known to operate, rather than all of the generation facilities in a nation™s 

entire electric grid. 
2.2.4
 Critical Periods of Cyberattack
How a cyberattack evolves over time is relevant, and there are sev
-eral time periods of interest. The ˜rst, T
intelligence collection
, is the period 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.90 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
available for collecting intelligence needed to launch the attack. A second 
relevant period, T
attack launch
, is the period over which the functionality 
required to carry out the attack on the targeted system(s) is installed or 
deployedŠthat is, during which the attack is launched. A third relevant 

period, T
compromise
, is the period over which the con˜dentiality, integrity, or 
availability attributes of the targeted system(s) are compromised. A fourth 

relevant period, T
effects apparent
, is the time period over which the victim 
actually suffers the ill effects of such compromises. During this time, the 

target can recover from the attack or reconstitute its function. Depending 

on the speci˜c nature of the cyberattack, these four periods mayŠor may 

notŠoverlap with each other. 
The distinctions between these various periods are important.
11
 For 
example, the fact that T
attack launch
 and T
compromise
 are different windows 
in time means that the period T
attack launch
 can be used to ﬁpre-positionﬂ 
vulnerabilities to facilitate later actions. This pre-positioning could be in 

the form of trapdoors left behind from previous virus infections, uninten
-tional design vulnerabilities,
12
 or vulnerable code left by a compromised 
staff member or by a break-in to the developer™s site.
13
Such pre-positioning is helpful for launching high-volume cyber
-attacksŠpossible targets include air-traf˜c control facilities, systems in 

manufacturing or shipping departments, logistics systems in rail trans
-port companies, energy production facilities, and so on, as well as a 

variety of military facilities. An attacker that has prepared his targets 

in this manner has avenues for instantaneous disruption or corruption 

of operational processes through a large-scale injection of forged com
-munications, destruction of data, or ˚ooding of services from inside nor
-mal perimeter defenses. When hosts inside a network begin to attack 

the internal network infrastructure or servers, they are often hard to 

identify rapidly because the very tools that are used by network opera
-tions staff to diagnose network problems may not be available. An attack 

spread widely enough can overwhelm the network operations and system 
11
 These concepts can also be found in epidemiologic models for the spread of malware. 
See, for example, http://geer.tinho.net/measuringsecurity.tutorialv2.pdf.
12
 An example is the recent episode during which Sony™s BMG Music Entertainment 
surreptitiously distributed software on audio compact disks (CD) that was automatically 
installed on any computers that played the CDs. This software was intended to block the 

copying of the CD, but it had the unintentional side effect of opening security vulnerabili
-ties that could be exploited by other malicious software such as worms or viruses. See Iain 

Thomson and Tom Sanders, ﬁVirus Writers Exploit Sony DRM,ﬂ November 10, 2005, avail
-able at http://www.vnunet.com/vnunet/news/2145874/virus-writers-exploit-sony-drm.
13
 P.A. Karger and R.R. Schell, 
Multics Security E
valuation: Vulnerability Analysis
, ESD-
TR-74-193, Vol. II, June 1974, HQ Electronic Systems Division, Hanscom Air Force Base, 

available at http://csrc.nist.gov/publications/history/karg74.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 91
administration staffs, increasing the time it takes to diagnose and mitigate 
the attack. 
More complex attacks can also be coordinated with other events to 
achieve a force-multiplier effect. For example, if an attack of this nature 
could successfully be made against an air defense network, the attacker 

could disrupt the network™s operation in concert with a hostile ˚ight 

operation, potentially blinding the defense system for a period of time. 
Still another relevant time scale is the duration of what might be 
called the entire operation, which itself might call for multiple cyberat
-tacks to be conducted over time. A denial-of-service attack is the canonical 

example of an operation that requires multiple cyberattacks over a period 

of timeŠwhen the attacks stop, the denial of service vanishes. Multiple 

cyberattacks conducted over time might also be needed to coordinate 

the entire cyber operation with other military activity taken against an 

adversary. Alternatively, and perhaps more prosaically, multiple cyberat
-tacks might be needed to ensure the continuing disruption of an adver
-sary computer system or network because the vulnerabilities that an 

attacker needs to target may not remain static. In an operation that calls 

for multiple cyberattacks over time, the targeted party may well respond 

to the ˜rst signs of the attack by closing or correcting some or all of the 

vulnerabilities enabling the attack. Other vulnerabilities would no doubt 

remain, but the attacker would have to have advance knowledge of them 

and adjust the attack accordingly. 
These different time scales also help to explain possible different per
-ceptions of the parties involved regarding what might ﬁcountﬂ as an attack. 

For example, the attacker might reasonably believe that a cyberattack has 

not been committed until a hostile agent planted on the adversary™s com
-puter has caused actual damage to it. The adversary might reasonably 

believe that a cyberattack has been committed when the agent was ˜rst 

planted on the computer, thus giving the agent™s controller the technical 

capability
 of causing actual damage to the adversary™s computer.
2.2.5
 Approaches for Cyberattack
What are the approaches that may be used for cyberattack? In general, 
a cyberattack depends on the attacker™s operational skill and knowledge 

of the adversary, and its success relies on taking advantage of a mix of the 

adversary™s technical and human vulnerabilities. Furthermore, although 

the military services and intelligence agencies rightly classify a variety 

of operational techniques and approaches to cyberattack, they too are 

governed by the same laws of physics as everyone else, and there are 

no magic technologies behind closed doors that enable, for example, an 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.92
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
attacker to beam a virus into a computer that lacks connections to the 
outside world. 
The discussion in this section is thus based on what is publicly known 
about tools and methods for conducting cyberattacks. This generic dis
-cussion is not intended to be complete or comprehensive, but it provides 
enough information for readers to gain a sense of what might be possible 

without providing a detailed road map for a would-be cyberattacker. This 

section is divided into three subsections: malware suitable for remote 

attacks, approaches for close-access attacks, and social engineering.
In many cases, these tools and methods are known because they have 
been used in criminal enterprises. Box 2.1 describes some of the advan
-tages that a nation-state has over others in conducting cyberattacks; these 

advantages can be used to re˜ne and weaponize these tools and methods 

so that they are more effective in carrying out operational missions. (The 

actions of nation-states are also constrained by applicable domestic laws, 

although in the United States, certain government agencies are explicitly 

exempted from complying with certain laws. See Section 7.3.4 for more 

discussion of this point.)
2.2.5.1
 Possible Approaches for Remote-Access Cyberattacks
Remote-access cyberattacks can be facilitated with a variety of tools, 
some of which are described below.
2.2.5.1.1 B
otnets
An attack technology of particular power and signi˜cance is the bot
-net. 
Botnets
 are arrays of compromised computers that are remotely con
-trolled by the attacker. A compromised computerŠan individual botŠis 

connected to the Internet, usually with an ﬁalways-onﬂ broadband con
-nection, and is running software clandestinely introduced by the attacker. 

The attack value of a botnet arises from the sheer number of computers 

that an attacker can controlŠoften tens or hundreds of thousands and 

perhaps as many as a million. (An individual unprotected computer may 

be part of multiple botnets as the result of multiple compromises.) Since 

all of these computers are under one party™s control, the botnet can act as 

a powerful ampli˜er of an attacker™s actions. 
An attacker usually builds a botnet by ˜nding a few individual com
-puters to compromise, perhaps using one of the tools described above. 

The ˜rst hostile action that these initial zombies take is to ˜nd other 

machines to compromiseŠa task that can be undertaken in an automatic 

manner, and so the size of the botnet can grow quite rapidly. It is widely 

reported that only minutes elapse between the instant that a computer 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 93
BOX 2.1 Cyberattack Advantages of Nation-States over
  Other Types of Actors
Nations have enormous resources to bring to bear on the problem of cyber
-attack. They are ˜nanced by national treasuries; they can take advantage of the 
talents of some of the smartest and most motivated individuals in their populations; 

they often have the luxury of time to plan and execute attacks; and they can draw 

on all of the other resources available to the national government, such as national 

intelligence, military, and law enforcement services. As a result, a government-

supported cyberattacker can be relatively pro˚igate in executing its attack and 

in particular can target vulnerabilities at any point in the information technology 

supply chain from hardware fabrication to user actions. 
The availability of such resources widens the possible target set of nation-
state attackers. Low- and mid-level attackers often bene˜t from the ability to gain 

a small pro˜t from each of many targets. Spammers and ﬁbotﬂ harvesters are the 

best examples of this phenomenonŠan individual user or computer is vulnerable 

in some way to a spammer or a bot harvester, but the spammer or bot harvester 

pro˜ts because many such users or computers are present on the Internet. How
-ever, because of the resources available to them, high-end attackers may also be 

able to target a speci˜c computer or user whose individual compromise would have 

enormous value (ﬁgoing after the crown jewelsﬂ). In the former case, an attacker 

confronted with an adequately defended system simply moves on to another sys
-tem that is not so well defended. In the latter case, the attacker has the resources 

to increase the scale and sophistication of the attack to a very high degree if the 

target is suf˜ciently valuable.
It is also the case that the resources available to a nation are not static. This 
means that for a suf˜ciently valuable target, a nation may well be able to deploy 

additional resources in its continuing attack if its initial attacks fail. In other words, 

capabilities that are infeasible for a nation today may become feasible tomorrow. 
A nation-state also has the resources that allow it to obtain detailed informa
-tion about the target system, such as knowledge gained by having access to the 

source code of the software running on the target or the schematics of the target 

device or through reverse engineering. (A proof of principle is illustrated in the 

short delay between the unauthorized public disclosure of portions of the source 

code for Microsoft Windows 2000 and Windows NT 4.0 in February 2004 and the 

reported appearance of exploits apparently derived from an examination of the 

source code.
1) Success in obtaining such information is not guaranteed, of course, 
but the likelihood of success is clearly an increasing function of the availability of 

resources. 
A nation-state cyberattacker does not care how it succeeds, as long as the 
path to success meets various constraints such as affordability and secrecy. In 

particular, the nation-state has the ability to compromise or blackmail a trusted 

insider to do its bidding or in˜ltrate a target organization with a trained agent rather 

than crack a security system if the former is easier to do than the latter. 
1 Statement from Microsoft Regarding Illegal Posting of Windows 2000 Source Code, http://
www.microsoft.com/presspass/press/2004/Feb04/02-12windowssource.mspx.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.94 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
attaches to the Internet and the time that it is probed for vulnerabilities 
and possibly compromised itself.
14
 A botnet attacker (controller) can communicate with its botnet (Box 
2.2) and still stay in the background, unidenti˜ed and far away from any 
action, while the individual botsŠwhich may belong mostly to innocent 

parties that may be located anywhere in the worldŠare the ones that are 

visible to the party under attack. The botnet controller has great ˚exibility 
14
 See, for example, 
Sur
vival Time
, available at http://isc.sans.org/survivaltime.html. 
Also, in a 2008 experiment conducted in Auckland, New Zealand, an unprotected computer 
was rendered unusable through online attacks. The computer was probed within 30 seconds 

of its going online, and the ˜rst attempt at intrusion occurred within the ˜rst 2 minutes. After 

100 minutes, the computer was unusable. (See ﬁExperiment Highlights Computer Risks,ﬂ 

December 2, 2008, available at http://www.stuff.co.nz/print/4778864a28.html.)
BOX 2.2
 Managing a Botnet 
Many botnets today make use of a two- or three-tier hierarchy, from attacker 
to a central controller (or handler), from handler to agents (ﬁbotsﬂ), and sometimes 

from agents (bots) to re˚ectors.
1 There are still limitations, however, on how many 
bots can be in a given channel at a given time, and attackers using large botnets 

know to move them around from server to server and channel to channel (known 

as herding) to avoid discovery or take-down of the botnets. 
A high-capacity attack network can make good use of another layer between 
the attacker and the handlers, which ideally is highly survivable and hardened 

so as to remain active in the face of defensive action. This layer is then used to 

control multiple independent botnets, or lower levels of distributed attack networks, 

in a manner similar to the regiment/battalion/company hierarchy used by conven
-tional military forces. By adding this additional layer, it is possible to coordinate 

much larger forces using independent teams, similar to what was done by the 

team of ﬁconsultantsﬂ in Operation Cyberslam,
2 but on an even larger scale. This 
additional layer will require a database to keep track of the various lower-level 
distributed attack networks and to assemble, reassemble, or reconstitute them as 

need be, in a manner very similar to maintaining force size through replacement 

of killed or wounded soldiers, and adjusting force strength through redeployment 

and reinforcement. 
Another approach to command and control involves two-way communications 
between controllers and bots. For example, rather than await orders, bots can 

send requests to controllers asking what to do next (ﬁpullingﬂ orders rather than 

ﬁpushingﬂ them). Successive requests from one bot go to different controllers. If a 

controller does not respond, after a while the bot tries another controller. If none 

of the controllers respond, the bot generates a series of random Domain Name 

System (DNS) names and tries those hosts, one at a time. The bot herders know 
the random number generation algorithm, and if they lose control of some group of 

bots (perhaps because some controllers have been discovered and disabled), they 

register one of the random DNS names just before the orphaned bots are about to 

try it, and when the bot checks in they update it to regain control. 
It is also possible to use out-of-band communications (e.g., telephone,
 radio, 
or face-to-face conversation) to relay targeting information and attack timing. 
 Especially in the case of long-running operations, there is no need for constant or 
immediate network connections between attacking networks. In fact, it would be 
less expensive and less risky from an operational security perspective to coordi
-nate a large number of distributed attack networks independently of each other. 

In this way, one or more groups could be responsible for recruiting (compromising 

and taking control over) new computers, which are then added to individual attack 

networks as requested when capacity drops below a certain level. If the attack 

tools are designed in a suf˜ciently modular wayŠand IRC botnets today already 

have these capabilities built inŠthis becomes an issue of human management 

rather than technology.
1 An example of a re˚ector attack would be to send DNS requests with a forged source 
address containing the intended target™s IP address to a large number of DNS servers, which 
would in turn send the replies back to what they believed to be the ﬁrequesterﬂ (the victim), 
which is then ˚ooded with traf˜c. If the DNS request packet contained 100 bytes of data, and 
the replies contained 700 bytes of data, a 7
 ampli
˜cation would result, in addition to re˚ection. 
There is no need for malicious software to be installed on the re˚ector; hence this makes a 
good indirect attack method that is very hard to trace back to the attacker.
2 Department of Justice, ﬁCriminal Complaint: United States of America v. Paul G. Ashley, 
Jonathan David Hall, Joshua James Schichtel, Richard Roby and Lee Graham Walker,ﬂ 2004, 
available at http://www.reverse.net/operationcyberslam.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 95
in the actions he may takeŠhe may direct all of the bots to take the same 
action, or each of them to take different actions. 
Botnets are ideally suited for conducting distributed denial-of-service 
(DDOS) attacks against computer systems, and there are few good ways 
to defend against such attacks. A denial-of-service attack ˚oods a speci˜c 

target with bogus requests for service, thereby exhausting the resources 

available to the target to handle legitimate requests for service and thus 

blocking others from using those resources. Such an attack is relatively 

easy to block if these bogus requests for service come from a single source, 

because the target can simply drop all service requests from that source. 

However, a distributed denial-of-service attack can ˚ood the target with 

multiple requests from many different machines, each of which might, in 

principle, be a legitimate requester of service. 
DDOS attacks are often conducted using unprotected machines in the 
BOX 2.2
 Managing a Botnet 
Many botnets today make use of a two- or three-tier hierarchy, from attacker 
to a central controller (or handler), from handler to agents (ﬁbotsﬂ), and sometimes 
from agents (bots) to re˚ectors.
1 There are still limitations, however, on how many 
bots can be in a given channel at a given time, and attackers using large botnets 

know to move them around from server to server and channel to channel (known 

as herding) to avoid discovery or take-down of the botnets. 
A high-capacity attack network can make good use of another layer between 
the attacker and the handlers, which ideally is highly survivable and hardened 

so as to remain active in the face of defensive action. This layer is then used to 

control multiple independent botnets, or lower levels of distributed attack networks, 

in a manner similar to the regiment/battalion/company hierarchy used by conven
-tional military forces. By adding this additional layer, it is possible to coordinate 

much larger forces using independent teams, similar to what was done by the 

team of ﬁconsultantsﬂ in Operation Cyberslam,
2 but on an even larger scale. This 
additional layer will require a database to keep track of the various lower-level 
distributed attack networks and to assemble, reassemble, or reconstitute them as 
need be, in a manner very similar to maintaining force size through replacement 
of killed or wounded soldiers, and adjusting force strength through redeployment 
and reinforcement. 
Another approach to command and control involves two-way communications 
between controllers and bots. For example, rather than await orders, bots can 
send requests to controllers asking what to do next (ﬁpullingﬂ orders rather than 
ﬁpushingﬂ them). Successive requests from one bot go to different controllers. If a 
controller does not respond, after a while the bot tries another controller. If none 
of the controllers respond, the bot generates a series of random Domain Name 
System (DNS) names and tries those hosts, one at a time. The bot herders know 
the random number generation algorithm, and if they lose control of some group of 

bots (perhaps because some controllers have been discovered and disabled), they 

register one of the random DNS names just before the orphaned bots are about to 

try it, and when the bot checks in they update it to regain control. 
It is also possible to use out-of-band communications (e.g., telephone,
 radio, 
or face-to-face conversation) to relay targeting information and attack timing. 
 Especially in the case of long-running operations, there is no need for constant or 
immediate network connections between attacking networks. In fact, it would be 
less expensive and less risky from an operational security perspective to coordi
-nate a large number of distributed attack networks independently of each other. 

In this way, one or more groups could be responsible for recruiting (compromising 

and taking control over) new computers, which are then added to individual attack 

networks as requested when capacity drops below a certain level. If the attack 

tools are designed in a suf˜ciently modular wayŠand IRC botnets today already 

have these capabilities built inŠthis becomes an issue of human management 

rather than technology.
1 An example of a re˚ector attack would be to send DNS requests with a forged source 
address containing the intended target™s IP address to a large number of DNS servers, which 
would in turn send the replies back to what they believed to be the ﬁrequesterﬂ (the victim), 
which is then ˚ooded with traf˜c. If the DNS request packet contained 100 bytes of data, and 
the replies contained 700 bytes of data, a 7
 ampli
˜cation would result, in addition to re˚ection. 
There is no need for malicious software to be installed on the re˚ector; hence this makes a 
good indirect attack method that is very hard to trace back to the attacker.
2 Department of Justice, ﬁCriminal Complaint: United States of America v. Paul G. Ashley, 
Jonathan David Hall, Joshua James Schichtel, Richard Roby and Lee Graham Walker,ﬂ 2004, 
available at http://www.reverse.net/operationcyberslam.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.96
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
open Internet environment. But there is no reason in principle that they 
could not be conducted in a more closed environment, such as a classi˜ed 
Zendian network for military communications or planning. Planting the 

initial botnet ﬁseedsﬂ would probably be more dif˜cult and time-consum
-ing than doing so on the open Internet, but once established, it is likely 

that the ﬁinsideﬂ botnet could grow rapidly because many sensitive net
-works are protected only by a hardened perimeter.
Individual bots can sense and probe their immediate environment. 
For example, a bot can examine clear-text data (e.g., sensitive informa
-tion such as user names and passwords) passing by or through its host 

computer, including keystrokes entered by users and traf˜c on the local 

area network to which that host computer is attached. It might examine 

data ˜les accessible to the host computer, such as any document stored on 

the computer. This information could be harvested and passed back to the 

botnet controller and mined for useful intelligence (a cyberexploitation). 
A bot could examine system ˜les on the system to ascertain the par
-ticular operating system and version being used, transmit this informa
-tion back to the controller, and receive in return an upgraded payload 

that is speci˜cally customized for that environment. This payload might 

be a destructive one, to be triggered at a certain time, or perhaps when 

the resident bot receives a subsequent communication from the controller. 

As a cyberexploitation, it could also ascertain the identity(ies) of the users 

and possibly their roles in an organization.
A bot could assume the identity of a legitimate user, and use its host 
as the originating site for e-mail. Whereas in the criminal world botnets 

often generate spam e-mail consisting of millions of identical messages, a 

military application might call for sending a personalized message from 

a compromised bot to another, uncompromised user that would mislead 

or confuse him.
Individual bots can also act as hosts for information ex˜ltration. Bot
-nets sharing data using encrypted peer-to-peer connections could be used 

as ﬁdistributed dead drops.ﬂ This would make it much more dif˜cult to 

prevent the information from being received and to discern the ultimate 

location of the botnet controllers.
Perhaps the most important point about botnets is the great ˚exibility 
they offer an attacker (or an exploiter). Although they are known to be 

well suited to DDOS attacks, it is safe to say that their full range of utility 

for cyberattack and cyberexploitation has not yet been examined.
2.2.5.1.2 
Other Tools and Approaches for Remote-Access Cyberattack 
Security Penetrations
 The owner or operator of an important system usu
-ally takes at least some measures to protect it against outside intruders. A 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 97
common security suite may involve requiring users to authenticate them
-selves and running security software that selectively blocks external access 
(˜rewalls) and checks for hostile malware that may be introduced.
However, password guessing is a common method for penetrating 
system security. Users have a tendency to choose easily remembered 

passwords that they change rarely if ever, suggesting certain patterns in 

password choice that are likely to be common. For example, passwords 

are often drawn from popular culture and sports, or are likely to be 

words from the user™s native language. Even when the system attempts 

to enforce password choices with variation (e.g., ﬁmust contain a digitﬂ), 

people subvert the intent in simple and easily predictable ways (e.g., 

they often choose PASSWORD1, PASSWORD2, and so on). Dictionaries 

are often used for guessing passwordsŠe.g., trying every word in the 

Zendian dictionary; such a technique can be effective if proper safeguards 

are not in place. Similar problems hold for any authenticator that remains 

constant.
An attacker may try to compromise security software to pave the 
way for the introduction of another attack agent. Some agents evade 

detection by varying the malicious payload or by checking constantly to 

ensure that a given virus is not identi˜ed by antivirus engines.
15
 Others 
are designed to disable antivirus programs, and may do so selectively so 

that only a speci˜c virus or worm written by the attacker sent later will 

be allowed through. These are simple automation steps that can use tech
-niques described openly within the computer security industry.
16
 Worms and Viruses
 Worms and viruses are techniques generally used 
for installing Trojan horses on many computers. A worm is self-replicat
-ingŠin addition to infecting the machine on which it is resident, it uses 

that machine to seek out other machines to infect. A virus replicates 

through user actionsŠfor example, an e-mail containing a virus may be 

sent to Alice. When Alice opens the e-mail, her computer is infected. The 

virus program may then send an e-mail (ostensibly from Alice) to every 

person in her contact list; when Bob receives the e-mail from Alice and 

opens it, Bob™s computer is infected and the cycle repeats itself. Because 

user action is required to propagate a virus, viruses tend to spread more 

slowly than do worms. 
Worms and viruses may be initially propagated in many ways, includ
-15
 As many as 30 percent of virus and other malware infections may be undetectable 
by today™s antivirus engines. See, for example, Niels Provos et al., ﬁAll Your iFRAMEs Point 
to Us,ﬂ 
Proceedings of the 
17
th Usenix Security Symposium 0
8, 2008, available at http://www.
usenix.org/events/sec08/tech/full_papers/provos/provos.pdf.
16
 Metasploit Anti-Forensics Project. Metasploit Anti-forensics homepage, available at 
http://www.metasploit.com/research/projects/antiforensics/.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.98
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
ing e-mails received by, web pages visited by, images displayed by, and 
software downloaded by the victim. Worms and viruses are often used 
as intermediate stepping stones to assume full control of an adversary 

system. For example, they can be used to establish reverse tunnels out 

through the ˜rewall (from inside to outside), which in turn grant someone 

outside the protected network full control of the host inside the network, 

or to control hosts in an enterprise in the supply chain of the primary 

target. 
Anonymizers
 Anonymizers are used to conceal the identity of an attack
-ing party. One particularly useful anonymizing technique is onion rout
-ing, a technology originally designed to disguise the source of electronic 
traf˜c.
17
 But since the technology cannot distinguish between different 
kinds of traf˜c, attackers can use onion routing to disguise the source of 

a remote cyberattack. 
Onion routing works by establishing a path through a maze of mul
-tiple onion routers, each of which accepts a packet from a previous router 

and forwards it on to another onion router. The originating partyŠin this 

case, the attackerŠencrypts the packet multiple times in such a way that 

each onion router can peel off a single layer of encryption; the ˜nal router 

peels off the last layer, is able to read the packet in the clear, and sends it 

to the appropriate destination. A variety of public-domain onion router 

networks exist, and some support specifying where the exit point should 

be. Thus, the attacker can specify ﬁExit from an onion router located in 

Zendiaﬂ and that is where a target would see an attack coming from. (On 

the other hand, a sophisticated target might notice that an attack was com
-ing from a public-domain onion router, and make probabilistic inferences, 

though not de˜nitive, about where the attack was really coming from.)
Penetrations of and Denial-of-Ser
vice Attacks on Wireless Networks
 Wireless 
networks to enable communications among computers and devices are 

increasingly common and provide clandestine methods for access and 

denial of service. An attacker may be able to insert his own broadcast/

reception node (on a WiFi network, he might insert his own wireless 

access point) to intercept and monitor traf˜c and perhaps be able to 

impersonate an authorized network user. 
An attacker may sometimes impersonate an authorized user with 
relative ease if access to the wireless network is not protected. For exam
-ple, satellites communicate with their ground stations through wireless 

communications, and the command link may not be encrypted or may 
17
 See, for example, the TOR router (and project) at http://www.torproject.org/.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 99
be otherwise insecure. If so, a Zendian satellite can be controlled by com
-mands sent from the United States just as easily as by commands sent 
from Zendia. With access to the command link, adversary satellites can 

be turned off, redirected, or even directed to self-destruct by operating in 

unsafe modes.
Alternatively, an attacker might choose to deny service on the net
-work by jamming it, ˚ooding the operating area with RF energy of the 

appropriate frequencies. WiFi wireless networks for computer commu
-nications are an obvious target, and given the increasing ubiquity of cell 

phones around the world, cell phone networks could be a particularly 

useful target of a jamming cyberattack should an attacker wish to disrupt 

a primary communications mechanism probably used by government and 

non-government personnel alike.
Router Compromises
 Router compromises often manipulate the logical 
map of a network (whether open, like the Internet, or closed, like that of 
a corporate network) in ways desired by the attacker. For example, modi
-˜cation of the software and data tables that underlie routing of informa
-tion, a speci˜c site could effectively be isolated so that it could not receive 

e-mail sent to it from elsewhere on the Internet or so that web pages 

hosted on it could never be found by anyone on the Internet. A different 

modi˜cation of the routing software and data might result in much more 

widespread chaos on the Internet for many sites rather than just one. 
Attacks on routers are feasible because the routers themselves are 
often Internet accessible and have software and hardware vulnerabilities 

just like any other computers, although even if they were not Internet 

accessible, compromising them would not be impossible. Moreover, code 

to support attacks on routers is often available in the public domain, mak
-ing attacks on routers easier than they would otherwise be. Under some 

circumstances, router ˚aws may enable an attacker to damage the rout
-ing hardware itself remotely, as might be possible if the boot ROM were 

compromised or if the attacker gained access to low-level functions that 

controlled power supplies or fan speeds. 
An example of a router compromise is the Border Gateway Protocol 
(BGP) attacks. The Internet is a network of networks. Each network acts 

as an autonomous system under a common administration and with com
-mon routing policies. Primarily used by Internet service providers (ISPs) 

and very large private networks such as those of multinational corpora
-tions, BGP is the Internet protocol used to characterize every network to 

each other, for example between ISPs. BGP does so by publishing tables 

containing information on how packets should be routed between any 

given network and other networks. However, if these tables are cor
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.100
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
rupted, traf˜c can be misdirected.
18
 One kind of BGP attack deliberately 
corrupts these tables to misdirect traf˜c away from its rightful destination 
and toward a network controlled by the attacker. 
Once the attacker has captured traf˜c intended for a given destination, 
the captured traf˜c can be discarded (thus isolating the destination net
-work) or copied for later examination and then forwarded to the correct 

destination (to reduce the likelihood of the attack becoming known). If the 

captured traf˜c contains information such as passwords, the attacker may 

be able to impersonate the sender at a later date. Another kind of attack 

hijacks a block of IP addresses in order to send undesirable or malicious 

traf˜c such as spam or denial-of-service attacks. Such an attack allows a 

sender to remain untraceable. The attacker uses the routing infrastructure 

to evade IP-based ˜ltering aimed at blacklisting malicious hosts. 
Protocol Compromises
 A network protocol is a standard that controls or 
enables communication between two computing devices. In practice, pro
-tocolsŠeven widely accepted and used protocolsŠare sometimes ˚awed. 

For example, a given protocol may be designed incorrectly or be incom
-pletely speci˜ed.
19
 A given implementation of a well-designed and well-
speci˜ed protocol may itself be incomplete and/or contain a bug. (An 

incomplete implementation may mean that the system can enter some 

unanticipated state, and thus that consequences that ensue are unpredict
-able.) An attacker may take advantage of such ˚aws. 
An example of a protocol attack is DNS cache poisoning. The Domain 
Name System (DNS) is a global system that maps domain names (e.g., 

www.nas.edu) into speci˜c numeric IP addresses (e.g., 144.171.1.22).
20
 However, in order to reduce the load on the primary name servers, tables 

containing the relevant information are stored (cached) on secondary 

DNS servers operated by Internet service providers. By taking advantage 
18
 See Xin Hu and Z. Morley Mao, ﬁAccurate Real-Time Identi˜cation of IP Pre˜x 
Hijacking,ﬂ 
Proceedings of IEEE Symposium on Security and Pri
vacy,
 May 2007, pp. 3-17; 
Anirudh Ramachandran and Nick Feamster, ﬁUnderstanding the Network-Level Behavior 
of Spammers,ﬂ 
Proceedings of the Association of Computing Machinery SIGCOMM 
200
6, pp. 
291-302, available at http://www.cc.gatech.edu/~avr/publications/p396-ramachandran-

sigcomm06.pdf.
19
 Incomplete speci˜cations or implementations are dangerous because of the possibil
-ity of inputs for which no response is speci˜ed or provided. That is, a protocol (or a given 
implementation of the protocol) may not unambiguously specify an action to be taken for all 

inputs. If one of these ﬁunde˜ned responseﬂ inputs is received, the receiving system will do 

something unanticipated. If enough is known about the receiving system and its particular 

implementation of the protocol being used, the subsequent action may be exploitable. 
20
 Every device connected to the Internet has a unique identifying number known 
as its IP address. An IP address may take the form 144.171.1.22 (for IP Version 4) or 2001:

db8:0:1234:0:567:1:1 (for IP Version 6). 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 101of vulnerabilities in DNS software, it is sometimes possible to alter these 
tables, so that a request to ﬁwww.nas.eduﬂ maps to 144.117.1.22, rather 
than the correct 144.171.1.22. The incorrect IP address 144.117.1.22 can be 

a phony host con˜gured to look like the real thing, and can be used to 

intercept information sent by the user and intended for the real site. Alter
-natively, corrupted tables could be used simply to misdirect messages 

being transmitted from point to point.
21
 (The corruption of a DNS server 
to redirect traf˜c is sometimes known as ﬁpharming.ﬂ) Cache poisoning 

is possible because the DNS protocol does not authenticate responses, 

which is widely regarded as a ˚aw in the security of that protocol. This 

˚aw means that an attacker can take advantage of the protocol by sending 

an inquiry to a server that causes it to make an inquiry to another server, 

and then sending a bogus reply to the ˜rst server before the second server 

has a chance to respond. 
Other examples of protocol attacks may involve partially opening 
many Transmission Control Protocol connections to tie up resources, or 
sending packets marked as the ˜rst and last fragments of a huge
 datagram 
in order to tie up buffer space.
2.2.5.2
 Possible Approaches for Close-Access Cyberattacks
To reduce the threat from tools that enable remote attacks, a poten
-tial target might choose to disconnect from easily accessible channels of 

communication. A computer that is ﬁair gappedﬂ from the Internet is not 

susceptible to an attack that arrives at the computer through Internet con
-nections. Thus, it is sometimes too dif˜cult or impossible for an attacker 

to obtain remote access to a computer of interest. In these instances, other 

methods of attack are necessary.
One approach to attacking a putatively isolated and ﬁstand-aloneﬂ 
computer is to consider whether that computer is in fact isolated. For 

example, a computer without an Internet connection may be accessible 

through a dial-up modem; if the attacker can discover the phone num
-ber associated with that modem, the computer may be vulnerable to a 

remote attack for the price of a long-distance telephone call. Or the com
-puter of interest may connect to the Internet only occasionally to receive 

updatesŠduring those moments of connection, the computer may be 

vulnerable. Or the computer might require the use of external media to 

provide dataŠalthough the data does not arrive through an Internet con
-nection, data is supplied through the insertion of the data-carrying media 

into an appropriate slot in the computer, and the placement of hostile data 
21
 National Research Council, 
Signposts in Cyberspace: The Domain Name System and 
Internet Na
vigation, 
The National Academies Press, Washington, D.C., 2005.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.102 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
on the CD-ROM can occur on a computer that 
is connected to the Internet. 
(Hostile data is data that, when processed, might cause the computer to 
fail or crash.)
If the computer or network of interest is indeed isolated, close-access 
attacks provide an alternative. Close-access attacks require a human to 

be physically present, which can increase the chances of being caught 

and/or identi˜ed. Sometimes, a close-access attack is used late in the 

supply chain, e.g., against a deployed computer in operation or one that 

is awaiting delivery on a loading dock. In these cases, the attacks are by 

their nature narrowly and speci˜cally targeted, and they are also not 

scalable, because the number of computers that can be compromised is 

proportional to the number of human assets available. In other cases, 

a close-access cyberattack may be used early in the supply chain (e.g., 

introducing a vulnerability during development), and high leverage 

might result from such an attack. For example, for many years the United 

States overtly restricted the cryptographic strength of encryption products 

allowed for export. If it had done so covertly, such an action might well 

have counted as a close-access cyberattack intended to make encryption 

products more vulnerable to compromise. 
By de˜nition, close-access attacks bypass network perimeter defenses. 
A successful close-access cyberattack makes an outsider appear, for all 

intents and purposes, to be an insider, especially if credentials have already 

been compromised and can be used without raising alarms. Sophisticated 

anomaly detection systems that operate from login audit logs, network 

˚ow logs, and other sources of network and computer usage would be 

necessary to be able to detect this type of activity. Standard antivirus 

software and intrusion detection or protection systems are signi˜cantly 

less effective.
Examples of close-access cyberattacks include the following:
Ł Attacks somewhere in the supply chain. Systems (and their com
-ponents) can be attacked in design, development, testing, production, 

distribution, installation, con˜guration, maintenance, and operation. (See 

Box 2.3 for a documented example.) Indeed, the supply chain is only as 

secure as its weakest link.
22
 In most cases, the supply chain is only loosely 
managed, which means that access control throughout the entire supply 

chain is dif˜cult. Examples of hypothetical supply-chain attacks include 

the following: 
22
 Defense Science Board, ﬁReport of the Defense Science Board Task Force on Mission 
Impact of Foreign In˚uence on DoD Software,ﬂ U.S. Department of Defense, September 
2007, p. 25.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 103 ŠA vendor with an employee loyal to an attacker introduces mali
-cious code as part of a system component for which it is a subcontractor 
in a critical system.
23
  ŠAn attacker intercepts a set of CD-ROMs ordered by the victim 
and substitutes a different doctored set for actual delivery to the victim. 

The doctored CD-ROMs contain attack software that the victim installs as 

he uses the CDs.
 ŠAn attacker bribes a shipping clerk to look the other way when 
the computer is on the loading dock for transport to the victim, opens the 

box, replaces the video card installed by the vendor with one modi˜ed by 

the attacker, and reseals the box.
Ł Compromises of third-party security software.
 Security software is 
intended to protect a computer from outside threats. In many cases, it 

does so by identifying and blocking speci˜c malicious software or activi
-ties based on some kind of ﬁsignatureﬂ associated with a given malicious 

action. But a government could induce the vendor of such security soft
-ware to ignore threats that might be associated with a virus or worm that 

the government might use to attack an adversary™s system. The govern
-ment could induce such cooperation in many ways. For example, it could 

persuade the CEO of the vendor™s company to take such action, prevent 

the company from selling its products if it failed to take such action, or 
23
 For a partial compendium of instances in which vendors have shipped to customers 
products ﬂpre-infectedﬂ with malware (e.g., virus or other security vulnerability or prob
-lem), see http://www.attrition.org/errata/cpo/.
BOX 2.3
 Project ﬁGunmanﬂ
On October 25, 1990, Congressman Henry Hyde revealed some of the tech
-nical highlights of a Soviet intelligence penetration of the U.S. embassy in Moscow 
that was still under construction at that time. Within the U.S. intelligence community, 

the Soviet operation was known by the code name ﬁGunman.ﬂ In 1984, the United 

States discovered that a number of IBM Selectric typewriters within the U.S. Em
-bassy had been secretly modi˜ed by the Soviets to transmit to a nearby listening 

post all keystrokes typed on those machines. Access to these typewriters to imple
-ment the modi˜cation was achieved during part of the logistics phase prior to their 

delivery to the embassy at a point when the typewriters were unsecured. 
SOURCE: U.S. House of Representatives, Rep. Henry J. Hyde, Introduction to ﬁEmbassy 
Moscow: Attitudes and Errors,ﬂ 
Congressional Record
, October 25, 1990, E3489.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.104
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
bribe some low-level programmer to ﬁforgetﬂ to include a particular sig
-nature in the virus checker™s database.
24
 Ł Compromises in the patch process.
 Patching software defects, espe
-cially those that ˜x known vulnerabilities, is an increasingly routine part 
of system maintenance. Yet patching introduces another opportunity 

for introducing new vulnerabilities or for sustaining old ones.
25
 Both 
automated (e.g., Windows updates) and manual patch processes present 

opportunities for close-access cyberattacks, though the tools and resources 

required may be quite different. The patch issued may be corrupted by 

the cyberattacker; alternatively, the distribution channel itself may be 

compromised and hostile software installed.
2.2.5.3
 Compromise of Operators, Users, and Service Providers 
Human beings who operate and use IT systems of interest constitute 
an important set of vulnerabilities for cyberattack.
  They can be compro
-mised through recruitment, bribery, blackmail, deception, or extortion.
  Spies working for the attacker may be unknowingly hired by the victim, 
and users can be deceived into actions that compromise security.
  
Misuse 
of authorized access, whether deliberate or accidental, can help an attacker 

to take advantage of any of the vulnerabilities previously describedŠand 

in particular can facilitate close-access cyberattacks. 
For example, the operation of a modern nationwide electric power 
grid involves many networked information systems and human operators 

of those systems; these operators work with their information systems to 
24 Some possible precedent for such actions can be found in the statement of Eric Chien, 
then chief researcher at the Symantec antivirus research lab, that Symantec would avoid up
-dating its antivirus tools to detect a keystroke logging tool that was used only by the FBI (see 
John Leyden, ﬁAV Vendors Split over FBI Trojan Snoops,ﬂ 
The Register
, November 27, 2001, 
available at http://www.theregister.co.uk/2001/11/27/av_vendors_split_over_fbi/). More 

discussion of this possibility can be found in Declan McCullagh and Anne Broache, ﬁWill 

Security Firms Detect Police Spyware?,ﬂ 
CNET News,
 July 17, 2007, available at http://news.
cnet.com/2100-7348-6197020.html. Other corporate cooperation with government authori
-ties was documented in the Church Committee hearings in 1976. For example, RCA Global 

and ITT World Communications ﬁprovided virtually all their international message traf˜c 

to NSAﬂ in the period between August 1945 and May 1975 (see Book III of Supplementary 

Detailed Staff Reports on Intelligence Activities and the Rights of Americans, 94th Congress, 

Report 94-755, p. 765). As for a government in˚uencing vendors to compromise security in 

their products, the canonical example is that for many years, the United States had imposed 

export controls on information technology vendors selling products with encryption capa
-bilitiesŠallowing more relaxed export controls only on those products capable of weak en
-cryption. Most export controls on strong encryption products were lifted in the late 1990s. 
25
 Defense Science Board, ﬁReport of the Defense Science Board Task Force on Mission 
Impact of Foreign In˚uence on DoD Software,ﬂ U.S. Department of Defense, September 

2007, p. 25.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 105keep the system in dynamic balance as loads and generators and trans
-mission facilities come on and off line. A cyberattack might be directed at 
the systems in a control center that provide situational awareness for the 

operatorsŠand so operators might not be aware of an emerging problem 

(perhaps a problem induced by a simultaneous and coordinated physical 

attack) until it is too late to recover from it.
In many instances involving the compromise of users or operators, 
the channels for compromise often involve e-mails, instant messages, 

and ˜les that are sent to the target at the initiative of the attacker, or other 

sources that are visited at the initiative of the target. Examples of the lat
-ter include appealing web pages and certain shareware programs, such 

as those for sharing music ˜les, or even playing a music CD with rootkit-

installation software.
An appealing web page might attract many viewers in a short period 
of time, and viewers could be compromised simply by viewing the page, 

while shareware programs might contain viruses or other malware. In an 

interesting experiment at West Point in 2004, an apparently legitimate e-

mail was sent to 500 cadets asking them to click on a link to verify grades. 

Despite their start-of-semester training (including discussions of viruses, 

worms, and other malicious code, or malware), over 80 percent of recipi
-ents clicked on the link in the message.
26
 Another example of social engineering in cyberattack involved a red 
team™s use of inexpensive universal serial bus (USB) ˚ash drives to pen
-etrate an organization™s security.
  These drives were scattered in parking 
lots, smoking areas, and other areas of high traf˜c.
  In addition to some 
innocuous images, each drive was preprogrammed with software that 

could have collected passwords, logins, and machine-speci˜c informa
-tion from the user™s computer, and then e-mail the ˜ndings to the red 
team.
  Because many systems support an ﬁauto-runﬂ feature for insertable 
media (i.e., when the medium is inserted, the system automatically runs 

a program named ﬁautorun.exeﬂ on the medium) and the feature is often 
turned on, the red team was noti˜ed as soon as the drive was inserted.
  The result: 75 percent of the USB drives distributed were inserted into a 

computer.
27
  
A ˜nal category of vulnerabilities and access emanates from the IT-
based service providers on which many organizations and individuals 

rely. Both individuals and organizations obtain Internet connectivity from 
26
 See Aaron J. Ferguson, ﬁFostering Email Security Awareness: The West Point 
 Carronade,ﬂ 
EDUCAUSE Quarterly
 28(1):54-57, 2005, available at http://net.educause.edu/
ir/library/pdf/EQM0517.pdf.
27
 Steve Stasiukonis, ﬁSocial Engineering, the USB Way,ﬂ 
Dark Reading
, June 7, 2006, avail
-able at 
http://www.darkreading.com/document.asp?doc_id=95556&WT.svl=column1_
1.Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.106 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Internet service providers. Many organizations also make use of external 
˜rms to arrange employee travel or to manage their IT security or repair 
needs. These service providers are potential additional security vulner
-abilities, and thus might well be targeted in a cyberattack directed at the 

original organization. 
Note:
 Close-access attacks and social engineering are activities in 
which national intelligence agencies specialize, and over the years these 

agencies have presumably developed considerable expertise in carrying 

out such activities. In practice, it is often cheaper and easier to compro
-mise a person than it is to break through ˜rewalls and decrypt passwords. 

Indeed, in many situations, human subversion and physical action are 

the two quickest, cheapest, and most effective methods of attacking a 

computer system or network.
2.2.6
 Propagating a Large-Scale Cyber Offensive Action
In order to take control of a large number of computers, an attacker 
needs to locate vulnerable computers and somehow install malicious soft
-ware on those computers. This can be done using direct attacks against 

exposed services (e.g., scan and attack behavior seen in worms like 
 Slammer and Blaster), or indirectly using social engineering techniques 
(e.g., e-mail with Trojan horse executables as ˜le attachments, instant 
messages with hypertext links, web pages containing malicious content, 

Trojan horse executables in modi˜ed ﬁfreeﬂ software download archives, 

or removable media devices dropped in parking lots). 
2.2.6.1
 Direct Propagation 
Direct attacks are the fastest means of compromising a large number 
of hosts. The most common method of direct propagation is either by scan
-ning for vulnerable hosts followed by direct remote attack, or by simply 
choosing random addresses and attempting to use
 vulnerabilities regard
-less of whether there is a host listening on that IP address, or even pos
-sessing the vulnerability at all. Malware artifacts (e.g., Agobot/Phatbot
28
) often look for opportunistic avenues for attack, including the back doors 

left by other malware that may have previously infected the host. This 

tactic does not require the use of a new zero-day exploit, as there may be 

plenty of other commonly known ways to take control of computers. The 

successful hit rate is lowest by scanning entirely randomly while attack
-ing, although there is an element of surprise using this method because 
28
 LURHQ, ﬁPhatbot Trojan Analysis,ﬂ June 2004, available at http://www.lurhq.com/
phatbot.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 107there is no opportunity for the target to see the reconnaissance scans. 
Either way, a direct attack increases the chances of detection through 
either signature (e.g., IDS/IPS or AV scanning) or anomalous ˚ow detec
-tion, possibly triggering a reaction by security operations personnel. Even 

if an attacker launches a new attack whose signature is not known to the 

defender, the defender may still be able to use traf˜c ˚ow analysis to 

detect the attack by observing and noting anomalous ˚ows. 
As mentioned above, worms to date have been quite noisy and in 
some cases spread so fast that they disrupt the network infrastructure 

devices themselves. In order to make direct attacks viable to recruit hosts 

for the kind of attack described here, a more slow and subtle attack (espe
-cially one involving a zero-day attack method whose existence is kept 

secret) over a much longer period of time would be needed. 
The methods just described are active in nature, but there are also 
opportunities for passive direct propagation. For example, hosts infected 

with the Blaster worm can still be observed actively attempting to propa
-gate, suggesting that attacking through more recently discovered vul
-nerabilities is likely to be feasible.
29
 By simply passively monitoring for 
signs of Blaster-infected hosts scanning randomly across the Internet, 

one can identify hosts that have a high probability of possessing one or 

more remotely usable vulnerabilities. Those hosts can then be compro
-mised and taken over, as was done by the Agobot/Phatbot malware in 

2003/2004.
30
 There is also a very good chance that attacks against these 
hosts, since they were already compromised and are actively scanning 

the Internet for more victims, would not be noticed by the owners of the 

computers or networks in which they reside. 
2.2.6.2
 Indirect Propagation 
Indirect methods of cyberattack are often slower, but less easy to 
detect by either network level IDS/IPS or AV/anti-spam systems. Some 

indirect methods of cyberattack include: 
Ł Compromising installation archives of freeware or shareware pro
-grams, either used generally or known to speci˜cally be used by tar
-get organizations. Examples include open source software development 

efforts, or software linked from sites that aggregate and categorize free
-29
 Michael Bailey, Evan Cooke, Farnam Jahanian, David Watson, and Jose Nazario, 
ﬁThe Blaster Worm: Then and Now,ﬂ 
IEEE Security and Pri
vacy
 3(4):26-31, 2005, available at 
http://ieeexplore.ieee.org/iel5/8013/32072/01492337.pdf?arnumber=1492337.
30
 Joe Stewart, ﬁPhatbot Trojan Analysis,ﬂ March 15, 2004, available at http://www.
secureworks.com/research/threats/phatbot/?threat=phatbot.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.108 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
ware and shareware programs.
31
 Unwitting users download these altered 
installation archives and install them without ˜rst verifying hashes or 
cryptographic signatures that attest to their integrity. (In general, use of 

cryptography for authentication of software is done poorly, or not at all, 

allowing these kinds of attacks to succeed in many cases.)
Ł Drive-by download attacks resulting from redirection of clients by 
corruption of DNS resolver con˜gurations, or man-in-the-middle attacks 

on DNS requests, for example in free WiFi networks. The attacker who 

wishes to redirect a software download request, or web page request, 

must simply answer an unauthenticated DNS request that is easily seen 

by the attacker in an open WiFi network. The client is then silently redi
-rected to a malicious site, where malicious software is downloaded and 

installed onto the system.
32
Ł Cross-site scripting attacks involve redirection of web browsers 
through embedded content in HTML or Javascript. The redirection is 

invisible to the user, and can result in portions of a web session being 

hijacked to install malicious content and/or to capture login credentials 

that can be used later to compromise the user™s account. As an example, 

some online auctioning sites have a signi˜cant problem with their users 

attacking each other using the site as a platform; the mechanism is that the 

site permits upload of HTML to its regular vendor™s own internal-to-site 

web pages and in that HTML are hidden various attack mechanisms. 
2.2.7
 Economics
The economics of cyberattack are quite different from those of kinetic 
attack.
Ł Producti
vity
. Certain kinds of cyberattacks can be undertaken 
with much more productivity than can kinetic attacks because the latter 

depend on human actions while the former depend on computer systems. 

Automation can increase the amount of damage that can be done per 
31
 An incident related to such compromises was reported in August 2008. The Red 
Hat Network, distributors for the Linux operating system, detected an intrusion on some 
of its computer systems. The intruder was able to sign a small number of OpenSSH pack
-ages (OpenBSD™s SSH (Secure SHell) protocol implementation), and these packages may 

have been improperly modi˜ed. See https://rhn.redhat.com/errata/RHSA-2008-0855.html. 

Some users relying on a Red Hat™s digital signature to ensure that they install only autho
-rized software are thus at some potential risk.
32
 This is mostly a risk to users who perform normal tasks like reading news on web
-sites from accounts on their computer that have elevated system administrator privileges. 

For this reason, it is typically recommended that users employ the concept of least-privileges 
and use accounts with administrator rights only when installing or con
˜guring software, 
not for general tasks.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 109attacker, increase the speed at which the damage is done, and decrease 
the required knowledge and skill level of the operator of the system. (A 
corollary is that the scale of effects of a cyberattack may be only weakly 

correlated with effort. As early as 1988, the Morris wormŠdeveloped 

with relatively little effortŠdemonstrated that a cyberattack could have 

effects on national and international scales. Indeed, the most dif˜cult part 
of some cyberattacks may well be to limit their effects to speci˜c com
-puters.) Automation can also simplify operational tasking by providing 

capabilities such as automated target acquisition, reducing effects to a set 

of alternatives in a pull-down menu, and turning rules of engagement 

into operational parameters that tie available actions to targets in the 

system™s menu. The result is a system that is easier to operate than a col
-lection of discrete attack tools and thus requires lower levels of training, 

knowledge, and speci˜c skills.
Ł Capital in
vestment.
 A cyberattack architecture functioning on a ser
-vice-oriented model can be replicated at very low cost if it relies on stolen 

services. For example, millions of compromised computers assembled in a 

botnet can be tasked to any C2 control center, allowing a larger number of 

individual attackers to operate independently. This distributes the opera
-tional and management loads, similar to the way a military battalion is 

composed of companies, cohesive units using similar weapons and tactics 

but capable of attacking different objective targets at different locations at 

the same time. Implementing a service-oriented model for a distributed 

architecture is simply a matter of programming and separation of duties 

(i.e., acquisition of newly compromised hosts to be controlled, and com
-mand and control of subsets of these hosts by individual operational 

warfare units). The more loosely coupled the functions of command and 

control versus effects on and from compromised end hosts, the more 

resistant the overall architecture is to detection and mitigation. 
On the other hand, highly specialized cyberweapons (e.g., those 
designed to attack very speci˜c targets) may well be costly. For example, 

the development of a particular cyberweapon may require intelligence 

collection that is dif˜cult and thus expensive to perform. Other cyber
-weapons may only be useful against adversary targets one or a few times 

(Section 2.3.10), making their use an expensive proposition.
Ł Funding
. Financial assets of an adversary can be used by an attacker. 
Rather than paying a defense contractor market rates to develop arms 

and munitions out of its own public coffers, a nation has the ability to 

steal money from an adversary for use in developing and advancing 

its cyberattack capabilities. For example, it could develop Version 1.0 

of an attack platform on its own and then use the proceeds from fraud 

perpetrated using Version 1.0 to fund development of a larger and more 

effective Version 2.0 platform, and so forth. Such an approach could be 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.11
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
particularly appealing to subnational groups, such as terrorist or criminal 
organizations, orŠin the absence of speci˜c legal prohibitions against 
such actionsŠto underfunded government agencies. 
Ł Availability
. The underlying technology for carrying out cyberat
-tacks is widely available, inexpensive, and easy to obtain. Software pack
-ages embedding some of the technology for carrying out cyberattacks are 

available on the Internet, complete with user manuals and point-and-click 

interfaces. The corollary is that government has no monopoly on cyber
-weapons or over expertise. Private businesses and private individuals can 

own or control major cyberweapons with signi˜cant capability, but the 

same tends to be less true of kinetic weapons, citizen-built truck bombs 

notwithstanding.
2.3
 OPERATIONAL
 C
ONSIDERATIONS
The previous section addresses the basic technologies of and 
approaches to cyberattack. This section considers the operational impli
-cations of using cyberattack. Both nation-states and hackers must grapple 

with these implications, but the scope of these implications is of course 

much broader for the nation-state than for the hacker.
2.3.1
 The Effects of Cyberattack
Although the ultimate objective of using any kind of weapon is to 
deny the adversary the use of some capability, it is helpful to separate the 

effects of using a weapon into its direct and its indirect effects (if any). The 

direct effects of using a weapon are experienced by its immediate target. 

For example, the user of a kinetic weapon seeks to harm, damage, destroy, 

or disable a physical entity. The indirect effects of using that weapon 

are associated with the follow-on consequences of harming, damaging, 

destroying, or disabling a physical entity, which may include harming, 

destroying, or disabling 
other
 physical entitiesŠa runway may be dam
-aged (the direct effect) so that aircraft cannot land or take off (the indirect 

effect). This distinction between direct and indirect effects is particularly 

important in a cyberattack context. 
2.3.1.1
 Direct Effects
33
By de˜nition, cyberattacks are directed against computers or net
-works. The range of possible direct targets for a cyberattack is quite broad 

and includes (but is not limited to) the following:
33 
Much of the discussion in this section is based on National Research Council, 
Toward 
a Safer and More Secure Cyberspace, 
The National Academies Press, Washington D.C., 2007.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 111
Ł Computer chips embedded in other de
vices,
 such as weapons systems, 
communications devices, generators, medical equipment, automobiles, 
elevators, and so on. In general, these microprocessors provide some kind 

of real-time capability (e.g., a supervisory control and data acquisition 

system will control the operation of a generator or a ˚oodgate, a chip in 

an automobile will control the ˚ow of fuel, a chip in an ATM will dispense 

money). 
Ł The computing systems controlling elements of the nation™s critical infra
-structure,
 for example, the electric power grid, the air traf˜c control sys
-tem, the transportation infrastructure, the ˜nancial system, water puri˜
-cation and delivery, or telephony. For example, cyberattacks against the 

systems and networks that control and manage elements of a nation's 

transportation infrastructure could introduce chaos and disruption on a 

large scale that could drastically reduce the capability for transporting 

people and/or freight (including food and fuel).
Ł Dedicated computing de
vices
 (e.g., desktop or mainframe co
mputers). 
Such devices might well not be just any desktop computer (e.g., any 
computer used in of˜ces around the country) but rather the desktop com
-puters in particular sensitive of˜ces, or in critical operational software 

used in corporate or government computer centers (e.g., a major bank 

or the unclassi˜ed systems of an adversary nation™s ministry of defense). 

Dedicated computer systems might also include the routers that control 

and direct traf˜c on the Internet or on any other network.
Cyberattacks generally target one of several attributes of these com
-ponents or devicesŠthey seek to cause a loss of integrity, a loss of authen
-ticity, or a loss of availability (which includes theft of services):
Ł Integrity
. A secure system produces the same results or information 
whether or not the system has been attacked. An attack on integrity seeks 

to alter information (a computer program, data, or both) so that under 

some circumstances of operation, the computer system does not provide 

the accurate results or information that one would normally expect even 

though the system may continue to operate. A computer whose integrity 

has been compromised might be directed to destroy itself, which it could 

do if it were instructed to turn off its cooling fan. A loss of integrity also 

includes suborning a computer for use in a botnet, discussed further in 

Section 2.2.5.1.1.
Ł Authenticity
. An authentic message is one that is known to have 
originated from the party claiming to have originated it. An attack on 

authenticity is one in which the source of a given piece of information is 

obscured or forged. A message whose authenticity has been compromised 

will fool a recipient into thinking it was properly sent by the asserted 

originator.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.112
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Ł Availability
. A secure system is available for normal use by its right
-ful owner even in the face of an attack. An attack on availability may 
mean that e-mail sent by the targeted user does not go through, or the 

target user™s computer simply freezes, or the response time for that com
-puter becomes intolerably long (possibly leading to catastrophe if a physi
-cal process is being controlled by the system). Some analysts also discuss 

theft of servicesŠan adversary may assume control of a computer to do 

his bidding. In such situations, the availability of the system has been 

increased
, but for the wrong party (namely, the adversary). 
These attributes may be targeted separately or together. For example, 
a given cyberattack may support the compromise of both integrity and 

availability, though not necessarily at the same time. In addition, the vic
-tim may not even be aware of compromises when they happenŠa victim 

may not know that an attacker has altered a crucial database, or that he or 

she does not have access to a particular seldom-used emergency system. 
In some situations, integrity is the key target, as it might well be 
for a tactical network. A commander who doubts the trustworthiness of 

the network used to transmit and receive information will have many 

opportunities for second-guessing himself, and the network may become 

unreliable for tactical purposes. In other situations, authenticity is the key 

targetŠa cyberattack may take the form of a forged message purportedly 

from a unit™s commanders to move from one location to another. And 

in still other situations, availability is the targetŠa cyberattack may be 

intended to turn off the sensors of a key observation asset for the few 

minutes that it takes for kinetic assets (e.g., airplanes) to ˚y past it.
The direct effects of some cyberattacks may be easily reversible. 
(Reversibility means that the target of the attack is restored to the operat
-ing condition that existed prior to the attack.) For example, turning off a 

denial-of-service attack provides instant reversibility with no effort on the 

part of the attacked computer or its operators. If backups are available, 

an attack on the integrity of the operating system may take just a few 

minutes of reloading the operating system. Many effects of kinetic attacks 

are not as easy to reverse.
34
A corollary to this point is that achieving enduring effects from a 
cyberattack may require repeated cyberstrikes, much as repeated bomb
-ing of an airstrip might be necessary to keep it inactive. If so, keeping a 
34
 For example, the time scales involved may be very different. Restoring the capability 
of an attacked computer that controls a power distribution system is likely to be less costly 
or time-consuming compared to rebuilding a power plant damaged by kinetic weapons. (A 

cyberattack on a computer controlling a power distribution system may even be intended 

to give the attacker physical control over the system but not to damage it, enabling him to 

control production and distribution as though he were authorized to do so.)
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 113
targeted system down is likely to be much more dif˜cult than bringing 
it down in the ˜rst place, not least because the administrators of the vic
-timized system will be guided by the nature of the ˜rst attack to close off 
possible attack paths. Thus, the attacker may have to ˜nd different ways 

to attack if the goal is to create continued effects. That is, depending on the 

nature of his goals, the attacker must have operational plans that antici
-pate possible defense actions and identify appropriate responses should 

those defense actions occur.
2.3.1.2
 Indirect (and Unintended) Effects
Although the direct effects of a cyberattack relate to computers, net
-works, or the information processed or transmitted therein, cyberattacks 

are often launched in order to obtain some other, indirect effectŠand in 

no sense should this indirect effect be regarded as secondary or unim
-portant. The adversary air defense radar controlled by a computer is of 

greater interest to the U.S. commander in the ˜eld than is the computer 

itself. The adversary™s generator controlled by a computer is of greater 

interest to the U.S. National Command Authority than is that computer 

itself.
35
 In such cases, the indirect effect is more important than the ˜rst-
order direct effect.
Computers are also integral parts of command and control networks. 
In this case, the indirect effect sought by compromising such a computer 

is to prevent or delay the transmission of important messages, or to alter 

the contents of such messages.
Indirect effectsŠwhich are often the primary goal of a cyberattackŠ
are generally not reversible. A cyberattack may disrupt a computer that 

controls a generator. The attack on the computer may be reversible (leav
-ing the computer as good as new). But the follow-on effectŠthe generator 

overheating and destroying itselfŠis not reversible.
Cyberattacks are particularly well suited for attacks on the psychol
-ogy of adversary decision makers who rely on the affected computers, and 

in this case such effects can be regarded as indirect effects. For example, 

a single database that is found to be deliberately corrupted, even when 

controls are in place to prevent such corruption, may call into question 

the integrity of all of the databases in a system. It is true that all produc
-tion databases have some errors in them, and indeed savvy users ought to 
35 
For example, a test staged by researchers at the Department of Energy™s Idaho Na
-tional Laboratories used a cyberattack to cause a generator to self-destruct. Known as Au
-rora, the cyberattack was used to change the operating cycle of the generator, sending it out 
of control. See CNN, ﬁStaged Cyber Attack Reveals Vulnerability in Power Grid,ﬂ September 

26, 2007, available at http://www.cnn.com/2007/US/09/26/power.at.risk/index.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.11
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
adjust for the possibility that their data may be incorrect. But in practice, 
they often do not. Being made conscious of the fact that a database may 
have been compromised has de˜nite psychological effects on a user. Thus, 

the victim may face a choice of working with data that mayŠor may 

notŠhave been corrupted and suffering all of the con˜dence-eroding con
-sequences of working in such an environment, or expending enormous 

amounts of effort to ensure that other databases have not been corrupted 

or compromised.
36
 A second example might be the clandestine alteration 
of critical data that causes decision makers to make poor or unfavorable 

decisions.
The unintended consequences of a cyberattack are almost always indi
-rect effects. For example, a cyberattack may be intended to shut down the 

computer regulating electric power generation for a Zendian air defense 

facility. The direct effect of the cyberattack could be the disabling of the 

computer. The intended indirect effect is that the air defense facility loses 

power and stops operating. However, ifŠunknown to the attackedŠa 

Zendian hospital is also connected to the same generation facility, the 

hospital™s loss of power and ensuing patient deaths are also indirect 

effects, and also an unintended consequence, of that cyberattack.
2.3.2
 Possible Objectives of Cyberattack
Whether a cyberattack is conducted remotely or through close access, 
what might it seek to accomplish? Some possible objectives include the 

following, in which an attacker might seek to:
Ł Destroy a network or a system connected to it.
 Destruction of a net
-work or of connected systems may be dif˜cult if ﬁdestructionﬂ means 

the physical destruction of the relevant hardware, but is much easier if 

ﬁdestructionﬂ simply means destroying the data stored within and/or 

eliminating the application or operating systems programs that run on 

that hardware. For example, an attacker might seek to delete and erase 

permanently all data ˜les or to reformat and wipe clean all hard disks 

that it can ˜nd. Moreover, destruction of a network also has negative 

consequences for anything connected to itŠpower-generation facilities 
36 
For example, in 1982, the United States was allegedly able to ﬁspikeﬂ technology that 
was subsequently stolen by the Soviet Union. Above and beyond the immediate effects of 
its catastrophic failure in a Soviet pipeline, Thomas Reed writes that ﬁin time the Soviets 

came to understand that they had been stealing bogus technology, but now what were they 

to do? By implication, every cell of the Soviet leviathan might be infected. They had no way 

of knowing which equipment was sound, which was bogus. All was suspect, which was the 

intended endgame for the entire operation.ﬂ See Thomas C. Reed, 
At the Abyss: An Insider™s 
History of the Cold War
, Ballantine Books, New York, 2004.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 115
controlled by a network are likely to be adversely affected by a disabled 
network, for example.
Ł Be an acti
ve member of a network and generate bogus traf˚c. 
For exam
-ple, an attacker might wish to masquerade as the adversary™s national 
command authority or as another senior of˜cial (or agency) and issue 

phony orders or pass faked intelligence information. Such impersonation 

(even under a made-up identity) might well be successful in a large orga
-nization in which people routinely communicate with others that they 

do not know personally. Alternatively, the attacker might pretend to be 

a non-existent agency within the adversary™s government and generate 

traf˜c to the outside world that looks authentic. An impersonation objec
-tive can be achieved by an attacker taking over the operation of a trusted 

machine belonging to the agency or entity of interest (e.g., the National 

Command Authority) or by obtaining the relevant keys that underlie their 

authentication and encryption mechanisms and setting up a new node on 

the network that appears to be legitimate because it exhibits knowledge 

of those keys.
Ł Clandestinely alter data in a database stored on the network.
 For exam
-ple, the logistics deployment plan for an adversary™s armed forces may 

be driven by a set of database entries that describe the appropriate arrival 

sequence of various items (food, fuel, vehicles, and so on). A planner 

relying on a corrupted database may well ˜nd that deployed forces have 

too much of certain items and not enough of others. The planner™s con˜
-dence in the integrity of the database may also be affected, as discussed 
in
 Section 2.3.1.2.
Ł Degrade or deny ser
vice on a network.
 An attacker might try to degrade 
the quality of service available to network users by ˚ooding communi
-cations channels with large amounts of bogus traf˜cŠspam attacks can 

render e-mail ineffective as a communications medium, for example. 

Denial-of-service attacks might be directed at key ˜nancial institutions, 

for example, and greatly degrade their ability to handle consumer ˜nan
-cial transactions. A denial-of-service attack on the wireless network (e.g., 

a jamming attack) used to control a factory™s operations might well shut it 

down. Taking over a telecommunications exchange might give an attacker 

the ability to overwhelm an adversary™s ministry of defense with bogus 

phone calls and make it impossible for its employees to use its telephones 

to do any work. A denial-of-service attack might be used to prevent an 

adversary from using a communications system, and thereby force him 
to use a less secure method for communications against which a cyber
-exploitation could be successful.
Ł Assume control of a network and/or modulate connecti
vity, pri
vileges, 
or 
ser
vice.
 An attacker might assume control of an Internet service provider 
in an adversary nation, and decide who would get what services and con
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.116
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
nectivity. For example, it might intentionally (and clandestinely) degrade 
bandwidth to key users served by that ISP, so that transmission of large 
˜les (e.g., images or video) would take much longer than expected. If the 

ISP was used by the Zendian Ministry of Defense to pass targeting infor
-mation for prompt action, delays in transmission might cause Zendian 

forces to miss important deadlines.
Finally, cyberattacks can be carried out in conjunction with kinetic 
attacks, and indeed the effect of a cyberattack may be maximized if used 

in such a manner. For example, a cyberattack alone might be used to cause 

confusion. But the ability to cause confusion in the midst of a kinetic 

attack might well have greater operational signi˜cance for the attacker.
2.3.3
 Target Identi˚cation
As with any other weapon, a cyberattack must be directed at speci˜c 
computers and networks. Even if a nation-state has been identi˜ed as 

being subject to cyberattack, how can the speci˜c computers or networks 

of interest be identi˜ed in a useful manner? (Note also that target identi
-˜cation is often related to attribution, but does not necessarily followŠa 

computer posing a threat may well be regarded as a target, even if the 

party controlling it is not known.)
In some instances, the target identi˜cation process is a manual, intel
-ligence-based effort. From a high-level description of the targets of inter
-est (e.g., the vice president™s laptop, the SCADA systems controlling the 

electric generation facility that powers the air defense radar complex 

10 miles north of the Zendian capital, the transaction processing systems 

of the Zendian national bank), a route to those speci˜c targets must be 

found. For example, a target system with an Internet presence may have 

an IP address. Knowledge of the system™s IP address provides an initial 

starting point for attempting to gain entry to the appropriate component 

of the target system. 
Sometimes a computer is connected to the Internet indirectly. For 
example, although it is common for SCADA systems to be putatively 

ﬁair gappedﬂ from the Internet, utility companies often connect SCADA 

systems to networks intended for administrative use so that their business 

units can have direct real-time access to the data provided by SCADA sys
-tems to improve ef˜ciency.
37
 Compromising a user of the administrative 
37
 For example, in January 2003, the Slammer worm downed one utility™s critical 
SCADA network after moving from a corporate network, through a remote computer to a 
VPN connection to the control center LAN. See North American Electric Reliability Council, 

ﬁSQL Slammer Worm Lessons Learned for Consideration by the Electricity Sector,ﬂ June 20, 

2003, available at http://www.esisac.com/publicdocs/SQL_Slammer_2003.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 117
network may enable an attacker to gain access to these SCADA systems, 
and thus intelligence collection efforts might focus on such users.
Target identi˜cation information can come from a mix of sources, 
including open source collection, automated probes that yield network 
topology, and manual exploration of possible targets. Manual target iden
-ti˜cation is slow, but is arguably more accurate than automated target 

identi˜cation.
Automated target selection is based on various methods of mapping 
and ˜ltering IP addresses and/or DNS names, for example through pro
-grammed pattern matching, network mapping, or querying databases 

(either public ones, or ones accessible through close-access attacks). The 

scope of automated attack identi˜cation can be limited by the use of 

network address ˜ltering. Say, for example, an attacker wishes to target 

a speci˜c military base, or to affect only hosts within a speci˜c corporate 

network. Various public records exist, such as WHOIS network registra
-tion information, BGP network routing information, DNS zone ˜les, and 

so on, that map Internet-accessible domain names to IP network address 

blocks. 
Automated target selection within an internal network is more com
-plicated. An internal network may have one gateway to the Internet, but 

within the perimeter of the internal network may be any arrangement 

of internal addresses. Once an attacker gains access to a host inside the 

network, the internal DNS zone tables can be accessed and decoded to 

identify appropriate targets. This will not always be possible, but in many 

cases even internal network ranges can be determined with minimal effort 

by the attacker. It is also possible to perform simple tests, such as attempt
-
ing to access controlled websites to test the ability to make outbound 

(i.e., through the ˜rewall) connections
38
 and thus to determine network 
membership through the resulting internal/external address mappings. 

If the attacker has suf˜cient lead time, a ﬁlow and slowﬂ network probe 

canŠwithout arousing suspicionŠgenerally yield connectivity informa
-tion that is adequate for many attack purposes.
 A cyberattacker may also be interested in selecting targets that fall 
under a number of administrative jurisdictions. As a rule of thumb, orga
-nizations under different jurisdictions are less willing to share informa
-tion among themselves than if only a single jurisdiction is affectedŠand 

thus a coordinated response to a cyberattack may be less effective than 

it might otherwise be. Furthermore, different administrative jurisdictions 

are likely to enforce a variety of security precautions, suggesting that 

some jurisdictions would be less resistant to an attack than others. 
38 
An illustration is the use of a query to the domain name system as a covert 
channel.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.118
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
2.3.4
 Intelligence Requirements and Preparation
Attacks on the con˜dentiality, integrity, authenticity, and availability 
attributes require taking advantage of some vulnerability in the targeted 
system. However, an attacker seeking to exploit a given vulnerability 

must knowŠin advance of the attackŠwhether the targeted system is 

in fact vulnerable to any particular attack method of choice. Indeed, the 

success of a cyberattack (to include both achieving the intended goal and 

minimizing collateral damage) often depends on many details about the 

actual con˜guration of the targeted computers and networks. 
As a general rule, a scarcity of intelligence information regarding pos
-sible targets means that any cyberattack launched against them can only 

be a ﬁbroad-spectrumﬂ and relatively indiscriminate or blunt attack. (Such 

an attack might be analogous to the Allied strategic bombing attacks of 

World War II that targeted national infrastructure on the grounds that the 

infrastructure supported the war effort of the Axis.) Substantial amounts 

of intelligence information about targets (and paths to those targets) are 

required if the attack is intended as a very precise one directed at a par
-ticular system and/or if the attack is to be a close-access attack.
39
 Con
-versely, a lack of such information will result in large uncertainties about 

the direct and indirect effects of a cyberattack, and make it dif˜cult for 

commanders to make good estimates of likely collateral damage.
Information collection for cyberattack planning differs from tradi
-tional collection for kinetic operations in that it may require greater lead 

time and may have expanded collection, production, and dissemination 

requirements, as speci˜c sources and methods may need to be positioned 

and employed over time to collect the necessary information and conduct 

necessary analyses.
40
 As illustrations (not intended to be exhaustive), 
intelligence information may be required on:
Ł The target™s platform, such as the speci˜c processor model;
Ł The platform™s operating system, down to the level of the speci˜c 
version and even the history of security patches applied to the operating 

system;
Ł The IP addresses of Internet-connected computers; 
Ł The speci˜c versions of systems administrator tools used;
39 
To some extent, similar considerations apply to the intelligence required to support 
precise kinetic weaponry. If a kinetic weapon is intended to be used, and capable of being 
used, in a precise manner, more information about the target and its environment will be 

necessary than if the weapon is blunt and imprecise in its effects.
40 
Joint Chiefs of Staff, 
Information Operations
, Joint Publication 3-13, U.S. Depart
-ment of Defense, Washington, D.C., February 2006, available at www.dtic.mil/doctrine/ 

jel/new_pubs/jp3_13.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 119
Ł The security con˜guration of the operating system, e.g., whether or 
not certain services are turned on or off, or what antivirus programs are 
running; 
Ł The physical con˜guration of the hardware involved, e.g., what 
peripherals or computers are physically attached;
Ł The speci˜c operators of the systems in question, and others who 
may have physical access to the rooms in which the systems are kept;
Ł The name of the shipping company that delivers computer compo
-nents to the facility; 
Ł The telephone numbers of the help desk for the system in question; 
and so on.
That is, the list of information items possibly relevant to cyberattacks 
in general is quite long indeed. Although not all such information will be 

necessary for any given attack, some of it will surely be needed depending 

on the precise nature of the cyberattack required.
In some cases, such information may be available from public sources, 
and these sources are often voluminous with a wealth of useful infor
-mation. In other cases, the required information may not be classi˜ed 

but may be available only through non-of˜cial sources, such as in the 

non-shredded of˜ce trash of the installation in question. In still other 

cases, the relevant information may be available through the traditional 

techniques of human agents in˜ltrating an organization or interviewing 

people familiar with the organization. Finally, automated means may be 

used to obtain necessary intelligence informationŠan example is the use 

of automated probes that seek to determine if a system has ports that are 

open, accessible, and available for use.
Intelligence preparation for a cyberattack is often a staged process. 
For example, stolen login credentials can be used to gain access to com
-promised accounts, followed by escalation of privileges to (a) locate and 

ex˜ltrate ˜les or (b) gain complete control over the host, allowing further 

keystroke logging or password extraction to compromise not only other 

accounts on the same system, but also accounts on other hosts. This in 

turn extends the attacker™s reach (as seen in the Stakkato case described 

in Appendix C) and enables the attacker to gather more information that 

might support an attack. Maximizing the ability to take advantage of 

these stolen credentials becomes a matter of database entry and process
-ing to automate the tasks. 
A cyberattacker will also bene˜t from knowledge about the adver
-sary™s ability to respond in a coordinated manner to a widespread attack. 

At the low end of this continuum (Table 2.2), the adversary is only mini
-mally capable of responding to attacks even on isolated or single systems, 

and has no capability at all to take coordinated action against attacks on 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.12
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
multiple systems. At the high end of this continuum, the adversary can 
integrate information relating to attacks on all of the systems under its 
jurisdiction, develop a relatively high degree of situational awareness, 

and respond in an active and coordinated manner.
41
 Ultimately, the operational commander must make an assessment 
about whether the information available is adequate to support the exe
-cution of a cyberattack. Such assessments are necessarily informed by 

judgments about riskŠwhich decreases as more information is available. 

Unfortunately, there is no objective, quantitative way to measure the 

adequacy of the information available, and also no way to quantitatively 

ascertain the increase in risk as the result of less information being avail
-able (the discussion in Section 2.3.6 elaborates on sources of uncertainty). 

In practice, the best way to adapt to a lack of detailed information may 

be to ensure the availability of skilled and adaptive personnel who can 

modify an attack as it unfolds in response to unanticipated conditions.
Lastly, the fact that considerable intelligence information may be 
required to conduct a speci˜c targeted attack points to a possible defen
-41 
Even when the capacity and resources exist to be able to operate at a high response 
level, there are many reasons why system owners may not respond in a cooperative man
-ner to a widespread computer attack. They may not be capable of immediately responding, 
may lack adequate resources, may be unable to physically attend to the compromised host, 

or may even speak a different language than the person reporting the incident. There may 

be active complicity within the organization, or a willful disregard of reports that allow the 

attacker to continue unabated.
TABLE 2.2
 Levels of Intrusion Response 
Level 
Victim Posture 
Characteristic Actions 
0 Unaware 
None: Passive reliance on inherent 

software capabilities 
1 Involved 
Uses and maintains antivirus software 

and personal firewalls 
2 Interactive 
Modifies software and hardware in 

response to detected threats 
3 Cooperative 
Implements joint traceback with other 

affected parties 
4 Non-cooperative 
 (active response) 
Implements invasive tracebacks, cease-

and-desist measures, and other actions 

up to retaliatory counterstrikes 
SOURCE: David Dittrich, 
On the De
velopment of Computer Network Attack Capabilities
, work 
performed for the National Research Council under agreement D-235-DEPS-2007-001, Feb
-ruary 3, 2008.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 121
sive strategyŠif one knows that a cyberattack is imminent, a defender 
may take steps to invalidate the intelligence information that the attacker 
may have collected. Such steps may be internally originated (e.g., chang
-ing one™s own system con˜guration and defensive posture) or externally 

originated (e.g., downloading a security update provided by a vendor). 

If these steps are successful (and it may well be possible to change defen
-sive postures rapidly), such action may force the attacker to postpone or 

abandon his attack or to conduct an attack that is much less precise and 

focused and/or much less certain in outcome than it would otherwise 

have been. (These points are far less relevant if the attacker is interested 

in a ﬁgeneralﬂ attack against broad swaths of an adversary™s computers 

and networksŠin such an attack, the targets of interest are, by de˜nition, 

the most weakly defended ones.)
2.3.5
 Effects Prediction and Damage Assessment
In the kinetic world, weapons (or, more precisely, munitions) are 
aimed against targets. Predicting the effect of a weapon on a given target 

is obviously important to operational planners, who must decide the most 

appropriate weapons-to-target matching. In general, characteristics of the 

weapon, such as explosive yield, fusing, likely miss distances (more pre
-cisely, Circular Error ProbableŠthe distance from the target within which 

the weapon has a 50 percent chance of striking), and so on are matched 

against characteristics of the target (such as target hardness, size, and 

shape), and its surrounding environment (e.g., terrain and weather).
Damage assessment for physical targets is conceptually straightforwardŠ
one can generally know the results of a strike by visual reconnaissance, 

although a task that is straightforward in principle may be complicated by 

on-the-ground details or adversary deception. For example, the weather 

may make it impossible to obtain visual imagery of the target site, or the 

adversary may be able to take advantage of the delay between weapons 

impact and damage assessment to create a false impression of the dam
-age caused. 
There are similar needs for understanding the effect of cyberweapons 
and assessing damage caused by cyberweapons. But munitions effects 

and damage assessment are complex and dif˜cult challenges, because 

the effectiveness of cyberweapons is a strong function of the intelligence 

available.
Munitions effects in the kinetic world can often be calculated on the 
basis of computational models that are based on physics-based algo
-rithms. That is, the fundamental physics of explosives technology and of 

most targets is well known, and so kinetic effects on a given target can be 

calculated with acceptable con˜dence. Thus, many of the uncertainties in 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.122
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
kinetic targeting can be theoretically calculated and empirically validated 
(e.g., at weapons effects test ranges), and the remaining uncertainties 
relate to matters such as target selection and collocation of other entities 

with the intended target. 
But there is no comparable formalism for understanding the effects of 
cyberweapons. The smallest change in the con˜guration and interconnec
-tions of an IT system can result in completely different system behavior, 

and the direct effects of a cyberattack on a given system may be driven by 

the behavior and actions of the human system operator and the speci˜c 

nature of that system as well as the intrinsic characteristics of the cyber
-weapon involved. Furthermore, these relatively small and/or obscure 

and/or hidden characteristics are often important in cyber targeting, and 

information about these things is dif˜cult to obtain through remote intel
-ligence collection methods such as photo reconnaissance, which means 

that substantial amounts of relevant information may not be available to 

the attacker. 
An example of an error causing unexpected behavior in a cyberattack 
is the Sapphire/Slammer worm of January 2003. Although the Sapphire 

worm was the fastest computer worm in history (infecting more than 90 

percent of vulnerable hosts within 10 minutes), a defective random num
-ber generator signi˜cantly reduced its rate of spread.
42
 (The worm tar
-geted IP addresses chosen at random, and the random number generator 

produced numbers that were improperly restricted in range.) In a military 

attack context, a cyberattack that manifested its effects more slowly than 

anticipated might be problematic.
An additional complication to the prediction problem is the possibil
-ity of cascading effects that go further than expected. For example, in ana
-lyzing the possible effects of a cyberattack, there may be no good analog 

to the notion of a lethal radius within which any target will be destroyed. 

When computer systems are interconnected, damage to a computer at 

the NATO Defense College in Italy can propagate to a computer at the 

U.S Air Force Rome Laboratory in New YorkŠand whether or not such a 

propagation occurs depends on a detail as small as the setting on a single 

switch, or the precise properties of every device connected at each end of 

the link, or the software characteristics of the link itself.
Engineers often turn to test ranges to better understand weapons 
effects, especially in those instances in which a good theoretical under
-standing is not available. A weapons test range provides a venue for test
-ing weapons empiricallyŠsending them against real or simulated targets 

and observing and measuring their effects. Such information, suitably 
42 
David Moore, ﬁThe Spread of the Sapphire/Slammer Worm,ﬂ undated publication, 
available at http://www.caida.org/publications/papers/2003/sapphire/sapphire.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 123
re˜ned, is then made available to users to assist them in the weapons 
selection process. 
A certain kind of cyberweapon may need to be tested against different 
versions of operating systems (and indeed, even against different builds 
of the same operating system), different con˜gurations of the same oper
-ating system, and even against different operators of that system. To test 

for cascading effects, multiple computers must be interconnected. Thus, 

realistic test ranges for cyberweapons are inevitably complex. It is also 

quite dif˜cult to con˜gure a cyber test range so that a simulation will 

provide high con˜dence that a given cyberattack will be successful.
Some analysts take from these comments that the effects of a cyber
-attack are impossible to predict. As a blanket statement, this claim is 

far overstated. It is true that the launch of a worm or virus may go on 

to infect millions of susceptible computers, and some of the infected 

machines might happen to control an electric power grid or a hospital 

information system. The media often report such events as if they were a 

surpriseŠand indeed it may well have been a surprise that these particu
-lar machines were infected. Nevertheless, after-the-fact analysis of such 

cyberattacks sometimes leads to the conclusion that the party launching 

the attack could have predicted the number of susceptible machines fairly 

accurately.
43
Indeed, more customized cyberattacks are quite possible, depend
-ing on the 
goal
 of the attacker. A software agent introduced into a target 
machine could, in principle, search its environment and remain resident 

only if that search found certain characteristics (e.g., if the machine had 

more than 10 ˜les containing the phrases ﬁnuclear weaponﬂ and ﬁWash
-ington D.C.ﬂ and had an IP address in a particular range, which might 

translate into the nation in which the machine was located). 
Nevertheless, high degrees of customization may require large 
amounts of information on machine-identi˜able characteristics of appro
-priate targets. Such information may be obtained through traditional 

intelligence collection methods. In some cases, a scouting agent under
-takes the initial penetration, explores the targeted machine or network 

to obtain the necessary information, and then retrieves the appropriate 

exploit from its controller to carry out the next step in the attack. 
To illustrate, the precise geographical location of a computer is often 
not available to a software agent running on it, and may indeed be impos
-43 
These comments presume that the attack software is written correctly as the at
-tacker intendedŠmistakes in the worm or virus may indeed lead to unintended effects. A 
classic example of a worm written with unintended consequences is the Morris worm. See 

Brendan P. Kehoe, ﬁZen and the Art of the Internet,ﬂ available at http://www.cs.indiana.

edu/docproject/zen/zen-1.0_10.html#SEC91.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.12
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
sible for the agent to discover. On the other hand, its topological relation
-ship to other systems may be the variable of signi˜cance, which may or 
may not be as good an indicator of function or importance, and topologi
-cal relationships are likely to be discoverable by an agent.
An issue for uncustomized cyberattacks is ﬁblowback,ﬂ which refers 
to a bad consequence returning to the instigator of a particular action. In 

the cyberattack context, blowback may refer to direct damage caused to 

one™s own computers and networks as the result of a cyberattack that one 

has launched. For example, if the United States launched a cyberattack 

against an adversary using a rapidly multiplying but uncustomized worm 

over the Internet, the worm might return to adversely affect U.S. comput
-ers and networks. It might also refer to indirect damageŠa large-scale 

U.S. cyberattack against a major trading partner™s economic infrastructure 

might have effects that could harm the U.S. economy as well.
Another class of weapons effects might be termed strategic. Tactical 
effects of using a weapon manifest themselves immediately and gener
-ally involve destruction, disabling, or damage of a targetŠtactical attacks 

seek an immediate effect on an adversary and its military forces. By con
-trast, strategic effects are less tangible and emerge over longer periods of 

timeŠstrategic attacks are directed at adversary targets with the intent or 

purpose of reducing an adversary™s warmaking capacity and/or will to 

make war against the United States or its allies, and are intended to have 

a long-range rather than an immediate effect on an adversary. Strategic 

targets include but are not limited to key manufacturing systems, sources 

of raw material, critical material, stockpiles, power systems, transporta
-tion systems, communication facilities, and other such systems.
44
 Most importantly, strategic effects are often less predictable than tacti
-cal effects. For instance, recall the history of the German bombing of Lon
-don in World War II. Originally believed by the Germans to be (among 

other things) a method of reducing civilian support for the British govern
-ment, it proved to have the opposite effect.
45
 As a new modality of offen
-sive action, the strategic impact of cyberattack on a population would be 

even harder to predict in the absence of empirical evidence.
As for assessing damage caused by a cyberattack, note ˜rst that the 
damage due to a cyberattack is usually invisible to the human eye. To 

ascertain the effects of a computer network attack over the Internet, an 
44
 See DOD de˜nitions for ﬁstrategic operationsﬂ and ﬁstrategic air warfare,ﬂ in Joint 
Chiefs of Staff, 
Dictionary of Military and Associated Terms
, Joint Publication 1-02, Department 
of Defense, Washington, D.C., April 12, 2001 (as amended through October 17, 2008), avail
-able at http://www.dtic.mil/doctrine/jel/new_pubs/jp1_02.pdf.
45 
See, for example, L. Morgan Banks and Larry James, ﬁWarfare, Terrorism, and Psy
-chology,ﬂ pp. 216-222 in 
Psychology of Terrorism
, Bruce Bongar et al., eds., Oxford University 
Press, 2007.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 125
attacker might be able to use Internet tools such as 
ping 
and 
traceroute
. These tools are commonly available, and they test the routing from the 
sending machine to the target machine. 
Ping 
is intended to measure the 
round-trip time for a packet to travel between the sending machine and 

the target machineŠand if the target machine is down, 
ping
 will return 
an error message saying it could not reach the target machine. 
Traceroute
 reports on the speci˜c path that a given packet took from the send
-ing machine to the target machineŠand if the target machine is down, 
 traceroute
 returns a similar error message. Thus, the receipt of such an 
error message by the attacker may indicate that an attack on the target has 

been successful. But it also may mean that the operators of the target 

machine have turned off the features that respond to 
ping
 and 
traceroute
, so as to lower their vulnerability to criminal hackers or to mislead the 

damage assessor about the effectiveness of an attack.
More generally, a cyberattack isŠby de˜nitionŠintended to impair 
the operation of a targeted computer or network. But from a distance, it 

can be very dif˜cult to distinguish between the successful outcome of a 

cyberattack and a faked outcome. For example, an attack may be intended 

to disrupt the operation of a speci˜c computer. But the attacker is faced 

with distinguishing between two very different scenarios. The ˜rst is 

that the attack was successful and thus that the targeted computer was 

disabled; the second is that the attack was unsuccessful and also was 

discovered, and that the adversary has turned off the computer deliber
-atelyŠand can turn it on again at a moment™s notice.
How might this problem be avoided? Where 
ping
 and 
traceroute
 as 
tools for damage assessment depend on the association of a damaged 

machine with a successful cyberattack, an alternative approach might call 

for the use of in-place sensors that can report on the effects of a cyberat
-tack. Prior to a cyberattack intended to damage a target machine, the 

attacker plants sensors of its own on the target machine. These sensors 

respond to inquiries from the attacker and are programmed to report back 

to the attacker periodically. These sensors could also be implanted at the 

same time as attack capabilities are installed on the target machine. Such 

sensors could report on the outcomes of certain kinds of cyberattacks, 

and thus in some situations could reduce the uncertainty of damage 

assessment. 
It may also be possible to use non-cyber means for damage assess
-ment of a cyberattack. For example, if a cyberattack is intended to cause 

a large-scale power outage in a city, its success or failure may be observ
-able by an individual in that city reporting back to the attackers via 

satellite phone or by an indigenous news network reporting on events 

within the country. But if the intent of the cyberattack is to turn off the 

power to a speci˜c radar installation in the nation™s air defense network 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.126
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
at a speci˜c time, it will be dif˜cult to distinguish between a successful 
attack and a smart and wily defender who has detected the attack and 
shut the power down himself but who is prepared to turn it back on at a 

moment™s notice.
The bottom line on damage assessment is that the state of the art in 
damage assessment techniques for cyberattacks is still primitive in com
-parison to similar techniques for kinetic attacks. Cyberattackers must 

therefore account for larger amounts of uncertainty in their operational 

planning than their physical-world counterpartsŠand thus may be inhib
-ited from relying solely or primarily on cyberattack for important mis
-sions.
 2.3.6
 Complexity, Information Requirements, and Uncertainty
From an analytical perspective, it is helpful to separate the uncer
-tainty of effects resulting from cyberattack into several components:
Ł Uncertainties that result from any military operation using any kind of 
weapon.
 All military operations are uncertain in outcome to some extent, 
and all run some risk of incurring collateral damage or having unintended 

consequences. The availability of intelligence information that is more 

accurate and more complete reduces the uncertainty inherent in an opera
-tion, and it is likely that the necessary intelligence for cyber targets will 

be less available than for most kinetic targets.
Ł Uncertainties that result from the lack of experience with a new weapon.
 Additional uncertainties arise when new weapons are used because their 

operational effects are not well known or well understood. For exam
-ple, the actual death tolls associated with the Hiroshima and Nagasaki 

bombings far exceeded the predicted tolls because only blast effects were 

taken into consideration. (Scientists understood that nuclear weapons 

had effects other than blast, but they did not know how to estimate their 

magnitude.) The same has been true for most of the history of U.S. plan
-ning for nuclear strikes.
46
Ł Uncertainties that result from unanticipated interactions between ci
vilian 
and military computing and communications systems.
 Because much of the IT 
infrastructure is shared for military and civilian purposes, disruptions to a 

military computer system or network may propagate to a civilian system 

or network. (In some cases, an adversary may 
deliberately
 intermingle mili
-tary and civilian assets in order to dissuade the attacker from attacking 
46 
Lynn Eden, 
Whole World on Fire: Organizations, Knowledge, and Nuclear Weapons De
vasta
-tion,
 Cornell University Press, Ithaca, N.Y., 2004.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 127
and thereby causing additional collateral damage.
47
) But without detailed 
knowledge of the interconnections between military and civilian systems, 
cascading effects may well occur.
As a rule, planning for cyberattack can involve a much larger range 
of choices and options than planning for most traditional military opera
-tions. For example, cyberattack planners must account for a wide range 

of time and space dimensions. The relevant time scales can range from 

tenths of a second (a cyberattack may interfere with the timing of a real-

time process control system) to years (a cyberattack may seek to implant 

ﬁsleeperﬂ capabilities in an adversary network that might be activated 

many years hence). And the systems targeted may be dispersed around 

the globe or concentrated in a facility next door. All of these factors 

increase the complexity of planning a cyberattack. 
One of the most dif˜cult-to-handle aspects of a cyberattack is that 
in contrast to a kinetic attack that is almost always intended to destroy 

a physical target, the desired effects of a cyberattack are almost always 

indirect, which means that what are normally secondary effects are in 

fact of central importance. In general, the planner must develop chains 

of causalityŠdo 
X, and 
Y happens, which causes 
Z to happen, which in 
turn causes 
A to happen. Also, many of the intervening events between 
initial cause and ultimate effect are human reactions (e.g., in response 

to an attack that does 
X, the network administrator will likely respond 
in way 
Y, which means that 
ZŠwhich may be preplannedŠmust take 
response 
Y into account). Moreover, the links in the causal chain may 
not all be of similar characterŠthey may involve computer actions and 

results, or human perceptions and decisions, all of which combine into 

some outcome.
Understanding secondary and tertiary effects often requires highly 
47 
The same is true in reverseŠa cyberattack on the civilian side may well result in 
negative effects on military computers. This point was illustrated by the ﬁI Love Youﬂ virus 
(also referred to as the ﬁLove Bugﬂ), released in May 2000. Press releases and articles from 

the Department of Defense indicate that some unclassi˜ed DOD systems, and even a few 

classi˜ed systems, were infected with this virus. See Jim Garamone, ﬁLove Bug Bites DoD, 

Others,ﬂ American Forces Press Service, May 4, 2000, available at http://www.defenselink.

mil/news/newsarticle.aspx?id=45220; ﬁStatement by Assistant Secretary of Defense (Public 

Affairs) Ken Bacon,ﬂ U.S. Department of Defense, May, 2000, available at http://˜ndarticles.

com/p/articles/mi_pden/is_200005/ai_2892634075. Testimony to a congressional subcom
-mittee from the Government Accounting Of˜ce shortly after the virus struck noted the 

impacts to DOD and many other federal agencies, in addition to the impacts on the private 

sector. See General Accounting Of˜ce, ﬁ‚ILOVEYOU™ Computer Virus Highlights Need for 

Improved Alert and Coordination CapabilitiesŠStatement of Jack L. Brock, Jr.,ﬂ Testimony 

Before the Subcommittee on Financial Institutions, Committee on Banking, Housing and 

Urban Affairs, U.S. Senate, GAO/T-AIMD-00-181, May 18, 2000.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.128
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
specialized knowledge. For example, an attack on an electric power grid 
will require detailed knowledge about the power generation plant of 
interestŠmodel numbers, engineering diagrams, and so on. Thus, plan
-ning a cyberattack may also entail enormous amounts of intellectual 

coordination among many different individuals (likely scattered through 

many organizations).
The result is often a complex execution plan, and complex execution 
plans have many ways to go wrongŠthe longer a causal chain, the more 

uncertain its ultimate outcomes and conclusions. This is not simply a mat
-ter of unintended consequences of a cyberattack, though that is certainly a 

concern. The point also relates to the implications of incomplete or over
-looked intelligence. For example, it may be that a cyberattack is entirely 

successful in disabling the computer controlling an air defense radar, but 

also, as it turns out, that there is a backup computer in place that was not 

mentioned in the intelligence reports used to plan the attack. Or a con
-nection between two systems that is usually in place is disconnected on 

the day of the attack because of a maintenance schedule that was changed 

last week, and thus was unknown to the attack plannersŠresulting in the 

inability of the attacker to destroy the backup computer.
One way of coping with uncertainty in this context is to obtain feed
-back on intermediate results achieved through monitoring the execution 

of the initial plan and then applying ﬁmid-course correctionsﬂ if and 

when necessary. The need to apply mid-course corrections means that 

contingency plans must be developed, often in advance if mid-course 

corrections need to be applied rapidly. The need to develop contingency 

plans in advance adds to the complexity of the planning process. 
In practice, execution monitoring may be dif˜cult to undertake. The 
attacker needs to know outcomes of various intermediate steps in the 

causal chain as well as what responses the victim has made at various 

stages of the attack, so that he may take appropriate compensating action. 

The dif˜culties of collecting such information are at least as hard as those 

of undertaking damage assessment for the ultimate outcome. 
2.3.7
 Rules of Engagement
Rules of engagement de˜ne the appropriate use of force by specifying 
the circumstances under which various offensive actions may be under
-taken and whose authority is needed to order such actions to be taken. In 

the physical world, the rules of engagement may specify, for example, that 

individuals with guns have the authority to ˜re them only when they are 

˜red upon ˜rst, and that they may never ˜re when the shooter is running 

away from them. Alternatively, rules of engagement may allow the target
-ing of tracked but not wheeled vehicles, or of vehicles but not personnel.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 129
Rules of engagement specify what tools may be used to conduct a 
cyberattack, what targets may be attacked, what effects may be sought, 
and who may conduct a cyberattack under what circumstances. Rules of 

engagement are formulated with different intent and for different pur
-poses depending on the interests at stake, and are discussed at greater 

length in Chapters 3-5 (on the military, the intelligence agencies, and law 

enforcement). 
2.3.8
 Command and Control 
2.3.8.1
 Command and ControlŠBasic Principles
According to the DOD,
48
 command and control (C2) refers to the 
exercise of authority and direction by a properly designated commander 

over assigned and attached forces in the accomplishment of the mission. 

Command and control functions are performed through an arrangement 

of personnel, equipment, communications, facilities, and procedures 

employed by a commander in planning, directing, coordinating, and 

controlling forces and operations in the accomplishment of the mission.
In principle, C2 involves passing to weapons operators information 
such as the targets to be attacked, the time (which may be upon receipt) 

that an attack is to be launched, the nature of the attack to be launched, and 

the time (which may be upon receipt) that an attack in progress must be 

stopped. (Note, however, that not all weapons are designed to implement 

such C2 capabilitiesŠsometimes, a weapon is designed to be used and 

then ﬁforgottenﬂ; that is, once launched or activated, it cannot be recalled 

and will do whatever damage it does without further intervention.)
C2 requires situational awarenessŠinformation about the location 
and status of the targets of interest and friendly or neutral entities that 

should not be attacked (Section 2.3.3) and their characteristics (Section 

2.3.4), decision making that results in an appropriate course of action, 

communication of the desired course of action to the weapons available 

(Section 2.3.8.2, below), and damage assessment that indicates to the deci
-sion maker the results of the actions taken (Section 2.3.5).
C2 becomes more complex when more weapons, more targets, or 
more friendly/neutral entities must be taken into account in decision 

making. For example, on a complex battle˜eld, issues of coordination 

often arise. A second strike on a given target may or may not be necessary, 

depending on the outcome of the ˜rst strike. Target A must be attacked 
48 
DOD JP1-02, 
Dictionary of Military and Associated Terms
, April 12, 2001 (as amended 
through September 30, 2008), available at http://www.dtic.mil/doctrine/jel/new_ pubs/
 jp1_02.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.13
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
and neutralized before Target B is attacked, because Target A provides 
defenses for Target B. A weapon launched to attack one target may inad
-vertently interfere with the proper operation of another weapon launched 
to attack that same targetŠavoiding this problem is known as decon˚ic
-tion. (When cyberattack is concerned, planners may well have to contend 

with cyberattacks launched by multiple agencies, multiple nations (e.g., 

allies), and even private citizens taking unauthorized actions.) All of these 

problems must be addressed by those planning an attack. (Section 3.6 

speculates on how the DOD might address these problems.) 
C2 and coordination issues are complex enough in the context of 
cyber activities alone. But they are multiplied enormously when cyberat
-tacks are conducted as part of an integrated campaign (i.e., a campaign 

that integrates all U.S. military capabilities, not only cyber capabilities) 

against an adversary.
Many analysts also include matters such as damage assessment, 
attack assessment, and tactical warning under the rubric of command 

and control; this report addresses these matters in Section 2.3.5 (damage 

assessment), Section 2.4.1 (tactical warning and attack assessment), and 

Section 2.4.2 (attribution).
2.3.8.2
 Illustrative Command and Control Technology for Cyberattack
A cyberattack often depends on a program running on the computer 
being attackedŠwhat might be called an attack agent. The C2 function is 

used to convey or transmit orders about what to do, when to do it, and 

when to stop doing it. C2 methods can include: 
Ł Direct (encrypted or clear text) connections to and from controller 
hosts or peers in peer-to-peer networks; 
Ł Covert channels using crafted packets that appear to be innocuous 
protocols, controlling speci˜c header ˜elds in packets, or using stegano
-graphic techniques that embed commands in ﬁnormalﬂ traf˜c on standard 

protocols (e.g., embedded characters in HTTP requests); and
Ł Embedded commands in ˜les retrieved from web servers, instant 
messages, or chat messages on Internet Relay Chat (IRC) servers. 
Direct C2 communication ˚ows can often be detected using standard 
intrusion detection signature methods. Encryption may obscure the con
-tent of the information ˚owing in C2 channels, but it is sometimes not 

very hard to identify a C2 channel by looking at ˚ow history to a host that 

was recently engaged in a DDOS attack or at outbound scanning activity. 

If a central C2 method is used, and it is easy to identify the C2 server, it 

can be possible to identify the attacker and to mitigate the attack. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 131
Recently, distributed attack tool authors have sought to employ 
stronger cryptography, including use of public key exchange algorithms 
to generate per-session encryption keys, as well as to use peer-to-peer 

mechanisms for communication to conceal the complete distributed 

attack network, or to use time-delayed command execution to tempo
-rally separate C2 traf˜c from hostile actions like DDOS attacks that trig
-ger alarms. Stepping stones, or relays, can further obscure the traceback 

from a targeted computer to the keyboards of attackers. Even as far back 

as 2001, the Leaves worm used both strong encryption and synchronized 

infected hosts™ clocks to support synchronized, time-delayed execution 

of commands.
49
 Even without centralized command and control, different attack 
agents can coordinate their actions. For example, an agent active on one 

adversary computer can delay its action until it receives a signal from a 

second agent on another computer that the second agent has completed 

its work. Or, for purposes of impeding an adversary™s attempts to detect 

an attack, multiple agents might be implanted on a target computer with 

a mix of functionalitiesŠcoordination among these agents could be as 

effective asŠor more so thanŠendowing a single agent with all of these 

functions.
Coordination among different attack agents may be particularly 
important if and when the same computers have been targeted by differ
-ent organizations. Without careful planning, it is possible that agents may 

be working at cross-purposes with each other. For example, one agent 

may be trying to jam a communications channel that is used clandestinely 

by another agent.
C2 channels can also be used to update the capabilities of attack 
software already in place. Indeed, as long as the channel is active, such 

software can be upgraded or even replaced entirelyŠwhich means that 

an attack plan can be easily re˜ned as more information is gained about 

the target. Defensive plans to prevent counterattack can also be changed 

in real time, so that (for example) a controller can itself be moved around 

(see Box 2.2).
Lastly, an attack agent will often need ways to transmit information 
to its controller for purposes such as damage assessment, report-back 

status checking, and specifying its operating environment so that a more 

customized attack can be put into place. For such purposes, an attacker 

may use outbound communications channels that are not usually blocked, 

such as port 80 (associated with the HTTP protocol) or DNS queries.
49
 CERT Coordination Center, ﬁCert Incident Note IN-2001-07 w32/leaves: Exploita
-tion of Previously Installed Subseven Trojan Horses, July 2001. See http://www.cert.org
/incident notes/IN-2001-07.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.132
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
2.3.8.3
 The Role of Human Expertise and Skill
In large part because the intelligence information on a cyber target is 
likely to be incomplete or inaccurate in some ways, the initial stages of 
a cyberattack may well be unsuccessful. Thus, for a cyberattack to suc
-ceed, the attack plan may need to be modi˜ed in real time as unexpected 

defenses and unanticipated problems are encountered. Some cyberattacks 

can be ﬁ˜re-and-forgetﬂŠespecially those attacks for which the target set 

is relatively large and individual successes or failures are not particularly 

relevant. But if a cyberattack is very speci˜cally targeted, adaptability and 

˚exibility on the part of the attacker may well be needed.
2.3.9
 Coordination of Cyberattack Activities with 
 Other Institutional Entities 
If a cyberattack is launched by the United States, coordination is likely 
to be necessary in three domainsŠwithin the U.S. government, with the 

private sector, and with allied nations.
Ł Coordination within the U.S. go
vernment.
 As noted in Chapters 3 and 
4, a number of U.S. government agencies have interests in cyberattack. 

It is easy to imagine that a lack of interagency coordination might lead 

to con˚icts between those wanting to exploit an adversary network and 

those wanting to shut it down. Policy con˚icts over such matters are not 

new with the advent of cyberattack, but technical decon˚iction issues 

arise as well, as different agencies might conduct cyber operations (either 

cyberattack and/or cyberexploitation) that might interfere with each 

other. In this connection, the committee has heard informally of potential 

struggles between the U.S. Air Force and the National Security Agency 

for institutional primacy in the cyberattack mission. In addition, under 

some circumstances, it may be necessary to consult with the congressional 

leadership and/or the relevant congressional committees, as discussed in 

Section 6.2.
Ł Coordination with the pri
vate sector.
 Because so much IT is designed, 
built, deployed, and operated by the private sector, some degree of coor
-dination with the private sector would not be surprising in the planning 

and execution of certain kinds of cyberattack. For example, a cyberattack 

may travel over the Internet to an adversary computer, and spillover 

effects (such as reductions in available bandwidth) may occur that affect 

systems in the private sector. Or a U.S. cyberattack may prompt an 

adversary counterattack against U.S. systems and networks in the private 

sector. Or a U.S. cyberattack against an adversary transmitted through 

a commercial Internet service provider might be detected (and perhaps 

suppressed) by that provider, believing it to be the cyberattack of a crimi
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 133
nal or acting on the protest of the targeted network. Such possibilities 
might suggest that the defensive posture of U.S. private sector systems 
and networks be strengthened in anticipation of a U.S. cyberattack (or at 

least that relevant commercial parties such as ISPs be noti˜ed), but this 

notion raises dif˜cult questions about maintaining operational security 

for the U.S. attack.
Ł Coordination with allied (or other) nations.
 Issues of agency coordina
-tion and coordination with the private sector arise with allied nations as 

well, since allied nations may also have government agencies with inter
-ests in cyberattack activities and private sector entities whose defensive 

postures might be strengthened. Another issue is the fact that a cyberat
-tack of the United States on Zendia might have to be transmitted over 

facilities controlled by third countries, and just as some nations would 

deny the United States military over˚ight rights, they may also seek to 

deny the United States the rights to transmit attack traf˜c through their 

facilities. Routing traf˜c to avoid certain countries is sometimes possible, 

but may require a signi˜cant amount of pre-planning and pre-positioning 

of assets depending on the nature of the attack to be launched.
2.3.10
 A Rapidly Changing and Changeable Technology and 
Operational Environment for Cyberattack 
The technological and operational environment in which cyberattacks 
may be conducted is both highly malleable and subject to very rapid 

change. Consider ˜rst the underlying technologies. Historical experi
-ence suggests that it takes only a decade for the technological substrate 

underlying IT applications to change by one, two, or three orders of 

magnitudeŠprocessor power, cost, bandwidth, storage, and so on. Then 

factor in trends of growing numbers of IT applications in both stand-alone 

and embedded systems and increasing connectivity among such applica
-tions. These points indicate that the overall IT environment changes on a 

time scale that is short compared to that of the physical world.
IT-based applications also evolve, but here the story is more mixed. 
Because such applications depend on knowledge and insight about how 

best to exploit technology, the march of progress is not nearly as consis
-tent as it has been with the underlying technologies, and many dif˜cult 

problem domains in IT have been dif˜cult for many years. Of particular 

relevance to cyberattack is the problem of technical attack attribution (Sec
-tion 2.4.2), which has bedeviled the cybersecurity community for many 

years.
50
 Many cyberattack capabilities are themselves afforded by various 
50 
For more discussion of this point, see National Research Council, 
Toward a Safer and 
More Secure Cyberspace
, The National Academies Press, Washington, D.C., 2007.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.13
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
IT-based applications, and mayŠor may notŠchange dramatically in 
the future, especially in relation to the defensive capabilities available to 
potential victims. That is, offensive capabilities are likely to grow for all 

of the reasons described in Section 2.2, but defensive capabilities are also 

likely to grow because IT vendors are placing more emphasis on security 

to meet the growing criminal threat. 
A second important point is that the security con˜guration of any 
given cyber target is also subject to very rapid change, and the vulner
-abilities on which cyberattacks depend are sometimes easily ˜xed by 

the defender. A system administrator can close down unused access 

points with a few keystrokes. A patch can repair a security ˚aw only a 

few seconds after it is installed. A new security scan can discover and 

eliminate a malicious software agent in a few minutes. Responding to a 

security warning, an administrator may choose to strengthen security 

by deliberately degrading system functionality (e.g., reducing backward 

compatibility of applications that may also be associated with greater 

vulnerability).
Even worse from the standpoint of the attacker, all such changes in 
security con˜guration can occur without notice. (Such changes are analo
-gous to randomly changing the schedule of a guard.) Thus, if a speci˜c 

computer system is to be targeted in a cyberattack, the attacker must 

hope that the access paths and vulnerabilities on which the cyberattack 

depends are still present at the time of the attack. If they are not, the 

cyberattack is likely to fail.
(These considerations are less signi˜cant for a cyberattack in which 
the precise computers or networks attacked or compromised are not 

important. For example, if the intent of the cyberattack is to disable a 

substantial number of the desktop computer systems in a large organiza
-tion, it is of little consequence that any given system is invulnerable to 

that attackŠwhat matters is whether most of the systems within that 

organization have applied the patches, closed down unneeded access 

points, and so on.)
Finally, if a cyberattack weapon exploits a vulnerability that is eas
-ily closed, a change in security con˜guration or posture can render the 

weapon ineffective for subsequent use. This point is signi˜cant because 

it means that an attacker may be able to use a given cyberattack weapon 

only once or a few times before it is no longer useful. That is, certain 

cyberweapons may well be fragile.
2.4
 CHARACTERI
ZING
 AN
 I
NCOMING
 C
YBERATTACK
As noted in Chapter 1, the de˜nition of active defense involves launch
-ing a cyberattack as a defensive response to an incoming cyberattack. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 135
However, before any such response occurs, the responding party must 
characterize the incoming attack accurately enough that its response is both 
appropriate and effective. Even if the victim of an incoming cyberattack 

does not plan to launch a cyberattack in response, it is important to char
-acterize the incoming attack for forensic and law enforcement purposes.
2.4.1
 Tactical Warning and Attack Assessment
Tactical warning and attack assessment (TW/AA) refer to the pro
-cesses through which the subject of an attack is alerted to the fact that an 

attack is in fact in progress and made aware of the scale, scope, and nature 

of an attack. In the strategic nuclear domain, early TW/AA, including, for 

example, information on the number of launches and their likely targets, 

would be provided for the United States by a network of satellites that 

detected adversary missiles just after launch. Moreover, the time scales of 

launch from Soviet territory to impact on U.S. soil (roughly 30 minutes in 

the case of ICBMs, 10-15 minutes in the case of submarine-launched bal
-listic missiles) were a primary determinant of a U.S. command and control 

system to assess an attack and determine the appropriate response. 
For a cyberattack, even knowing that an attack is in progress is highly 
problematic. 
Ł For individual sites, anomalous activity may be associated with 
the start of a cyberattack, and if a site detects such activity, it may receive 

early warning of an attack. But characterizing anomalous activity on a 

computer system or network that reliably indicates an attack is an enor
-mously dif˜cult task (legitimate users do all kinds of unusual things), and 

general solutions to this identi˜cation problem have eluded computer 

scientists for decades. 
Ł Attack assessment is even more dif˜cult, because the initial intru
-sions may simply be paving the way for hostile payloads that will be 

delivered later, or the damage done by a cyberattacker may not be visible 

for a long time after the attack has taken place (e.g., if rarely used but 

important data has been corrupted). (Clandestine or delayed-discovery 

attacks have obvious advantages when it is desirable to weaken an adver
-sary without its knowledge.) 
Ł A ﬁseriousﬂ attackŠthat is, one conducted by a nation-state or 
a terrorist adversary for seriously hostile purposesŠmust be somehow 

distinguished from the background attacks that are constantly ongoing 

for nearly all systems connected to the Internet. These background attacks 

include a variety of hacking activities, virus propagation, distributed 

denial-of-service attacks, and other activities conducted for illicit mon
-etary gain, sport, or pure maliciousness that are constantly being con
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.136
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
ducted, in addition to the ongoing activities presumably undertaken by 
various nation-states or other subnational entities for covert intelligence-
gathering purposes and/or to ﬁprepare the battle˜eldﬂ for possible future 

cyberattacks for offensive purposes.
For a dispersed entity (such as the Department of Defense, the U.S. 
government, or a large corporation), multiple sites may be attacked in a 

coordinated manner. If attacks were somehow known to be coordinated, 

such coordination might indicate a serious attack. On the other hand, 

detecting such coordination against the background noise of ongoing 

attacks also remains an enormous intellectual challenge, as useful infor
-mation from multiple sites must be made available on a timely basis. (And 

as detection capabilities improve, attackers will take steps to mask such 

signs of coordinated attacks.)
An attack assessment would seek to address many factors, including 
the scale of the attack (how many entities are under attack), the nature of 

the targets (which entities are under attack, e.g., the DOD Global Command 

and Control System, electric power generating facilities, Internet retailers), 

the success of the attack and the extent and nature of damage caused by 

the attack, the extent and nature of any foreign involvement derived from 

technical analysis of the attack and/or any available intelligence informa
-tion not speci˜cally derived from the attack itself, and attribution of the 

source of the attack (discussed at greater length in Section 2.4.2).
Information on these factors is likely to be quite scarce when the 
initial stages of an attack are ˜rst noticed. For example, because cyber
-weapons can act over many time scales, anonymously, and clandestinely, 

knowledge about the scope and character of a cyberattack will be hard to 

obtain quickly. Other non-technical factors may well play into an attack 

assessment, such as the state of political relations with other nations that 

are capable of launching such an attack.
From an organizational perspective, the response of the United States 
to a cyberattack by a non-state actor is often characterized as depending 

strongly on whether the attackŠas characterized by factors such as those 

described aboveŠis one that requires a law enforcement response 
or
 a 
national security response. This characterization is based on the idea that 

a national security response relaxes many of the constraints that would 

otherwise be imposed by a law enforcement response.
51
But the ﬁlaw enforcement versus national securityﬂ dichotomy is 
51
 For example, active defenseŠeither by active threat neutralization or by cyber 
 retaliationŠmay be more viable under a national security response paradigm, whereas a 
law enforcement paradigm might call for passive defense to mitigate the immediate threat 
and other activities to identify and prosecute the perpetrators.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 137
misleading. In practice, the ˜rst indications of a cyberattack are likely to 
be uncertain, and many factors relevant to a decision will be unknown. 
Once the possibility of a cyberattack is made known to national authori
-ties, information must be gathered to determine perpetrator and purpose, 

and must be gathered using the available legal authorities (described in 

Section 7.3). Some entity within the federal government integrates the rel
-evant information and then it or another higher entity (e.g., the National 

Security Council) renders a decision about next steps to be taken, and 

in particular whether a law enforcement or national security response is 

called for.
How might some of the factors described above be taken into account 
as a greater understanding of the event occurs? Law enforcement equities 

are likely to predominate in the decision-making calculus if the scale of 

the attack is small, if the assets targeted are not important military assets 

or elements of critical infrastructure, or if the attack has not created sub
-stantial damage. To the extent that any of these characteristics are not 

true, pressures may increase to regard the event as one that also includes 

national security equities.
The entity responsible for integrating the available information and 
recommending next steps to be taken has evolved over time. In the late 

1990s, the U.S. government established the National Infrastructure Protec
-tion Center (NIPC) as a joint government and private sector partnership 

that provided assessment, warning, vulnerability, and investigation and 

response for threats to national critical infrastructure. Consisting of per
-sonnel from the law enforcement, defense, and intelligence communities, 

each with reach-back into their respective agencies for support, along 

with representatives from the private sector and foreign security agencies, 

the NIPC was the place where information on the factors described was 

to be fused and the intelligence, national security, law enforcement, and 

private sector equities integrated regarding the signi˜cance of any given 

cyberattack.
Organizationally, the NIPC was part of the Department of Justice 
under the Federal Bureau of Investigation. In later years, the
 analysis and 
warning
 functions of the NIPC were
 dispersed throughout the Depart
-ment of Homeland Security (DHS) as the result of that department™s 

creation, while the principal investigative functions remained at the FBI 

(with some investigative functions performed by the U.S. Secret Service, 
an autonomous part of
 DHS).
52
 Initially, they were integrated into the 
Information Analysis and Infrastructure Protection Directorate, primarily 

the National Infrastructure Coordinating Center (NICC) under the Of˜ce 
52
 See Department of Homeland Security, ﬁHistory: Who Became Part of the Depart
-ment?,ﬂ 2007, available at http://www.dhs.gov/xabout/history/editorial_0133.shtm. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.138
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
of Operations Coordination and the United States Computer Emergency 
Readiness Team, the operational arm of the National Cyber Security Divi
-sion. The NICC provides operational assessment, monitoring, coordina
-tion and response activities, and information sharing with the private 
sector through information sharing and analysis centers. The United 

States Computer Emergency Readiness Team (US-CERT), the operational 

arm of the National Cyber Security Division, coordinates defense against 
cyberattacks.
  
Further reorganization at DHS moved the Of˜ce of Operations Coor
-dination to a freestanding component that runs NICC as part of the 

National Operations Center. The Of˜ce of Infrastructure Protection (OIP) 

became part of the National Protection and Programs (NPP) Director
-ate. A separate Of˜ce of Cybersecurity and Communications, also under 

NPP, includes the National Cyber Security Division, which still man
-ages US-CERT operations. Broadly, the NIPC functions that focused on 

risk reduction, warning, and vulnerability assessment are now part of 

NPP. Those NIPC functions that focused on operational assessment and 

coordination are today part of the NICC under the Of˜ce of Operations 

Coordination.
As this report is being written, the U.S. government apparatus respon
-sible for warning and attack assessment is likely to be reorganized again.
The government agencies responsible for threat warning and attack 
assessment can, in principle, draw on a wide range of information sources, 

both inside and outside the government. In addition to hearing from 

private sector entities that come under attack, cognizant government 

agencies can communicate with security IT vendors, such as Symantec 

and McAfee, that monitor the Internet for signs of cyberattack activity. 

Other public interest groups, such as the Open Net Initiative and the 

Information Warfare Monitor, seek to monitor cyberattacks launched on 

the Internet.
53
2.4.2
 Attribution
Attribution is the effort to identify the party responsible for a cyber
-attack. 
Technical attribution
 is the ability to associate an attack with a 
responsible party through technical means based on information made 

available by the fact of the cyberattack itselfŠthat is, technical attribution 
53
 See http://opennet.net/ and http://www.infowar-monitor.net for more infor
-mation on these groups. A useful press report on the activities of these groups can be 
found at Kim Hart, ﬁA New Breed of Hackers Tracks Online Acts of War,ﬂ 
Washington 
Post,
 August 27, 2008, available at http://www.washingtonpost.com/wp-dyn/content/ 
article/2008/08/26/AR2008082603128_pf.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 139
is based on the clues available at the scene (or scenes) of the attack. All-
source attribution is a process that integrates information from all sources, 
not just technical sources at the scene of the attack, in order to arrive at 

a judgment (rather than a de˜nitive and certain proof) concerning the 

identity of the attacker.
Two key issues in technical attribution are precision and accuracy:
Ł Precision.
 An attribution has associated with it some range of preci
-sion for the identity of the attacker. The attack might be associated with 

a speci˜c nation (Zendia), a speci˜c department within that nation (the 

ministry of defense), a speci˜c unit (the 409th Information Operations 

Brigade), a speci˜c set of IP addresses, a speci˜c individual, and so on. 
Ł Accuracy.
 A characteristic related to precision is accuracy, a measure 
of the quality of attribution, such as the probability that the attribution 

is correct. Accuracy is a key issue in legal standards for evidence and in 

the extent to which it is reasonable to develop linkages and inferences 

based on those attributes. Note that an attacker may seek to reduce the 

accuracy of attribution if he or she wishes to operate secretly by taking 

countermeasures to impersonate other parties.
The unfortunate reality is that technical attribution of a cyberattack is 
very dif˜cult to do (it is often said that ﬁelectrons don™t wear uniformsﬂ), 

and can be nearly impossible to do when an unwittingly compromised or 

duped user is involved. As the existence of botnets illustrates, a cyberat
-tacker has many incentives to compromise others into doing his or her 

dirty work, and untangling the nature of such a compromise is inevitably 

a time-consuming and laborious (if not futile) process.
To illustrate the point, consider a scenario in which computers of the 
U.S. government are under a computer network attack (e.g., as the result 

of a botnet attack). The owners/operators of the attacked computers in 

the United States would likely be able to ˜nd the proximate source(s) of 

any attack. They might discover, for example, that the attack traf˜c ema
-nated from computers located in Zendia. But there may well be no techni
-cal way to differentiate among a number of different scenarios consistent 

with this discovery. These scenarios include the following:
Ł The attack against the United States was launched by agents of the 
Zendian government with the approval of the Zendian national command 

authority.
Ł The attack against the United States was launched by low-level 
agents of the Zendian government without the approval or even the 

knowledge of the Zendian national command authority.
Ł The attack was launched through the efforts of computer-savvy 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.140
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
citizens of Zendia who believe that the United States oppresses Zendia in 
some way. Although the efforts of these citizens are not initiated by the 
Zendian government, the Zendian government takes no action to stop 

them. (Such individuals are often known as ﬁpatriotic hackersﬂ and are 

discussed in more detail in Section 7.2.3.3.)
Ł The Zendian computers used to conduct the attack against the 
United States have been compromised by parties outside Zendia (perhaps 

even from the United States, as happened in the Solar Sunrise incident 

in February 1998
54
), and Zendia is merely an innocent bystander on the 
international stage.
Ł The attack was launched at the behest of the Zendian government, 
but not carried out by agents of the Zendian government. For example, 

it may have been carried out by the Zendian section of an international 

criminal organization.
However, the limitations of technical attribution are not dispositive. 
All-source attribution takes into account whatever information is avail
-able from efforts at technical attribution, but also uses information from 

other sources to arrive at a judgment. Such sources might include:
Ł Intelligence sources.
 For example, a well-placed informant in the 
Zendian government might provide information indicating the responsi
-bility of that nation in initiating the attack, or routinely monitored mes
-sage traf˜c might indicate a point of responsibility within the Zendian 

government.
Ł Political sources.
 The Zendian government might publicly take 
credit for the attack. (Of course, a claim that ﬁWe were responsible for the 

attackﬂ would itself have to be veri˜ed.)
Ł Other technical information.
 The technical signature of the cyber
-attack might be similar to that of a previous attack, and the United States 

might have information on the originator of that previous attack. The 

scale or nature of the attack might be such that only a major nation-state 

could have mounted it, thus ruling out other parties. Or it might be pos
-sible to determine the time zone of the actual attacking machine.
55
Ł Temporal proximity to other coerci
ve or aggressi
ve actions that can be 
attributed
. For example, Zendia might choose to ﬁbundleﬂ a set of such 
actions together, such as cyberattack coupled with an embargo on selling 
54
 More information on the Solar Sunrise incident can be found at http://www.sans.
org/resources/idfaq/solar_sunrise.php.
55
 For example, it is sometimes possible to learn information about a target computer™s 
physical environment through the remote monitoring of time stamps. Local time stamps are 
governed by a computer™s clock, and the rate at which the clock runs is affected by the ambi
-ent temperature. Thus, time stamp information provides information on changes of ambient 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 141certain computer chips or strategic raw materials to the United States, a 
break in diplomatic relations, and refusal of ﬁsafe harborﬂ rights for U.S. 
naval vessels. 
Thus, although the process of all-source attribution might well take a 
long time to arrive at an actionable (if not de˜nitive) judgment, the case 

for attribution is not as hopeless as it is often portrayed.
Attribution of an attack should not be confused with establishing or 
identifying an access path to the source of the attack. Under a given set 

of circumstances, the victim may be able to establish both of these pieces 

of information, one of them, or none of them. For example, it may be 

impossible to establish an access path to the source of a cyberattack, but 

at the same time an all-source attribution effort might de˜nitively iden
-tify a given nation as being responsible for the attack. Alternatively, an 

access path to the source of a cyberattack might be established without 

providing any useful information at all regarding the party responsible 

(e.g., the launching point for a cyberattack against a corporation might be 

located inside that corporation and not be further traceable). The differ
-ence between attribution and having an access path is signi˜cant, because 

in the absence of an access path, neutralization of a cyberattack is not pos
-sible, though retaliation for it might be. The converse is true as wellŠin 

the absence of attribution, retaliation or reprisal is not possible, though 

neutralization of a cyberattack might be.
Finally, the problems that anonymity poses for a defensive actor can 
easily be seen as advantages for an attacker. The discussion above sug
-gests that with careful and appropriate planning, a cyberattack can often 

be conducted with a high degree of plausible deniability. Such a capability 

may be useful in certain intelligence operations when it is desirable that 

the role of the government sponsor of a cyberattack is not to be publicly 

acknowledged (as discussed in Section 4.2).
2.4.3
 Intent
In the realm of traditional military con˚ict, it is generally presumed 
that national governments control the weapons of warfareŠfrigates, 
temperature, which may be correlated with time-of-day physical location. Measur
ements of 
day length and time zone can provide information useful for estimating the physical loca
-tion of a computer. Local temperature changes caused by air-conditioning or movements 
of people can identify whether two machines are in the same location, or even are virtual 

machines on one server. See Steven J. Murdoch, ﬁHot or Not: Revealing Hidden Services by 

Their Clock Skew,ﬂ Proceedings of the 13th ACM Conference on Computer and Communi
-cations Security, CCS™06, October 30ŒNovember 3, 2006, Alexandria, Va., 2006, available at 

http://www.cl.cam.ac.uk/users/sjm217/.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.142 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
˜ghter jets, tanks, and so on. Thus, if any of these weapons are used, there 
is a presumption that actions involving them have been sanctioned by the 
controlling governmentŠand inferences can often be drawn regarding 

that government™s intent in ordering those actions.
But when other weapons are not controlled exclusively by govern
-ments, inferring intent from action is much more problematic. This is 

especially so if communication cannot be established with the control
-ling partyŠas will often be the case with cyberattack. Attribution of a 

cyberattack (discussed above) helps, but if the party identi˜ed as being 

responsible is not a national government or another party with declared 

intentions toward the United States, it will be virtually impossible to 

determine intent with high con˜dence.
Determinations of intent and attribution
 of
 the source are often com
-plicatedŠand inappropriately biasedŠby a lack of information.
  Ulti
-mately, such determinations are made by human beings, who seek to 
integrate all available information in order to render a judgment.
  (Such 
integration may be automated, but human beings program the rules for 
integration.)
  When inexperienced human beings with little hard infor
-mation are placed into unfamiliar situations in a general environment 
of tension, they will often make worst-case assessments.
  In the words 
of a former
 Justice Department of˜cial
 involved with critical infrastruc
-ture protection, ﬁI have seen too many situations where
 government
 of
-˜cials
 claimed a
 high degree of con˜dence
 as to
 the source, intent, and 
scope of an attack,
 and it turned out they were wrong on every aspect of 
it.
  That is, they were often wrong, but never in doubt.ﬂ
2.5
 ACTIVE
 D
EFENSE
 FOR
 N
EUTRALI
ZATION
 A
S A 
 PARTIALLY
 W
ORKED
 E
XAMPLE
To suggest how the elements above might ˜t together operationally, 
consider how a speci˜c active defense scenario might unfold. In this 

scenario, active defense means offensive actions (a cyber counterattack) 

taken to neutralize an immediate cyberthreatŠthat is, with an operational 

goalŠrather than retaliation with a strategic goal. The hostile cyberattack 

serves the offensive purposes of Zendia. The cyber counterattack in ques
-tion is for defensive purposes.
The scenario begins with a number of important U.S. computer systems 
coming under cyberattack. For de˚niteness, assume that these computer 

systems are SCADA and energy management systems controlling elements 

of the power grid, and that the attacker is using unauthorized connections 

between these systems and the Internet-connected business systems of a 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 143power generation facility to explore and manipulate the SCADA and energy 
management systems.
The ˚rst stepŠ
very dif˚cult in practiceŠis to recognize the act as an 
unambiguously hostile one rather than one undertaken by cyber pranksters 
with too much time on their hands. Further inspection re
veals that the 
unauthorized intruder has planted software agents that would respond to 
commands in the future by disabling some of the power generation and 

transmission hardware controlled by these systems, and furthermore that the 
apparent controllers of these agents are located around the world. Howe
ver, 
even the a
vailability of such information cannot determine the moti
vations 
of the responsible parties regarding why they are undertaking such a hostile 

act.
A second step is to recognize that these attacks are occurring on many 
different SCADA and energy management systems around the nation. Such 
recognition depends on the existence of mechanisms within the U.S. go
vern
-ment for fusing information from different sources into an o
verall picture 
indicating that any indi
vidual attack ˚ts into a larger ad
versarial picture, 
rather than being an isolated e
vent.
The third step is to identify the attackerŠthat is, the party installing 
the agents. The IP address of the proximate source of this party can be ascer
-tained with some degree of con˚dence, and a corresponding geographic loca
-tion may be a
vailableŠin this case, the geographic location of the proximate 
source is Zendia. 
But these facts do not re
veal whether the attack was:
Ł Sponsored by Zendia and launched with the appro
val of the highest 
le
vels of the Zendian National Command Authority;
Ł Launched by low-le
vel elements in the Zendian military without 
high-le
vel authorization or e
ven the knowledge of the Zendian NCA;
Ł Launched by computer-sa
vv
y Zendian citizens;
Ł Launched by terrorists from Zendian soil; or
Ł Launched by Ruritania transiting through Zendia, which may be 
entirely innocent.
Suppose further that additional information from non-technical sources 
is a
vailable that sheds additional light on the attacker™s identity. In this case, 
intelligence sources indicate with a moderate degree of con˚dence that the 

attack ultimately emanates from parties in Zendia.
The a
vailability of information about the attacker™s identity marks an 
important decision point about what to do next. One option is to approach 
the Zendian go
vernment and attempt to resol
ve the problem diplomatically 
and legally, where ﬁresolutionﬂ would call for Zendian go
vernment action 
that results in a cessation of the attackŠin this case, refraining from install
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.144
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
ing any more agents on U.S. SCADA and energy management systems. 
(Knowing that the attacks ha
ve actually ceased is yet another problem, 
especially against the background of myriad other hostile or ad
versarial 
actions being taken e
very day against U.S. systems of 
various sorts.) Such an 
approach also risks compromising U.S. intelligence sources, and thus U.S. 
decision makers may be wary of taking this route.
Continuing with this scenario, the United States disco
vers that the hos
-tile agent controllers are themsel
ves centrally controlled by an Internet-con
-nected system located in Zendia. Cognizant of the uncertainties in
vol
ved, the 
United States quietly probes the master controller to understand its 
vulner
-abilities, but decides to refrain from further action at this time. It also works 
on remo
ving the deployed agents from the SCADA and energy management 
systems in question, replacing them with harmless look-alike agents that can 
perform all of the rele
vant report-back functions to the controller. Howe
ver, 
cyber response teams from the United States realize that they are unlikely to 
˚nd e
very SCADA and energy management system so infested.
A few months later, tensions between the United States and Zendia rise 
because of a non-lethal incident between the Zendian air force and a U.S. 

reconnaissance plane. In order to put pressure on the United States, Zendia 
tries to acti
vate its SCADA/EMS agents. Zendia recei
ves many af˚rmati
ve reports from the ˚eld, some of which are in fact misleading and others 
valid. 
In order to stop the remaining agents, the United States launches a denial-
of-ser
vice attack against the Zendian controller, effecti
vely disconnecting it 
from the Internet while at the same time issuing a demarche to the Zendian 
go
vernment to cease its hostile actions and to pro
vide information on the 
SCADA/EMS systems penetrated that is suf˚cient to effect the remo
val of all 
hostile agents. Zendia responds to the U.S. demarche publicly, denouncing 
the U.S. denial-of-ser
vice attack on it as an unpro
voked and unwarranted 
escalation of the situation. 
This neutralization scenario raises many issues. Neutralization of 
cyberthreats requires an access path to the particular hardware unit from 
which the attack emanates (e.g., the attack controller). In addition, an 

indication of the physical location of that hardware may be necessary.
Ł Knowledge of the controller™s speci˜c hardware unit is important 
because the attacker may have taken a very circuitous route to reach the 

target. If the attacker has been clever, neutralization of any intermediate 

node along the way is unlikely to result in a long-term cessation of the 

attack, and only disruption of the controller will suf˜ce. If not, there may 

be a particular intermediate node whose destruction or degradation may 

be suf˜cient to stop the attack.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 145Ł Physical location is important because of the legal jurisdictional 
issueŠdepending on the physical (national) location of the hardware, 
different laws regarding the putative criminality of its behavior and the 

legality of damaging it may apply. This point is relevant especially if an 

attack has a foreign origin; however, knowledge of physical location is not 

required
 to neutralize the attack.
In practice, none of these conditions are easy to meet. Attackers have 
strong incentives to conceal their identity, and so are likely to use com
-promised computers as intermediate launching points for their attacks. 

Furthermore, because one compromised computer can be used to com
-promise another one, the chain leading to the actual attackerŠthe only 

one with malevolent intentŠcan be quite long, and thus quite dif˜cult 

(and time-consuming) to unravel. By the time an actual machine identity 

of the controller has been established, the attacker may no longer have a 

presence on the originating machine.
Yet another complicating factor is that the controller function can be 
executed on a variety of different systems. Thus, even if a victim is suc
-cessful in identifying the controller of the attack, and even if it successfully 

launches a counterattack that neutralizes that controller (a counterattack 

that may be electronic, kinetic, or even legal), the controller function may 

shift automatically to another systemŠif so, another laborious process 

may need to be started again. (An analogy could be drawn to the opera
-tion of a mobile missile launcher [Transporter-Erector-Launcher, TEL]. A 

TEL sets down in a speci˜c, usually pre-surveyed, location, launches its 

missile, and then immediately moves to minimize the effectiveness of a 

counterattack against it.) On the other hand, the controller of the attack 

may not shift, especially if the attacker is not well resourced or sophisti
-cated. Under such circumstances, a counter-cyberattack may well succeed 

in shutting down an attack, at least for a while.
A long chain of compromised machines is not the only obfuscation 
technique an attacker may use. An attacker may also plant false evidence 

implicating other parties on one or more of the intermediate links. Such 

evidence could lead the forensic investigator to mistakenly identify a par
-ticular intermediate node as the true source of an attack, and a neutraliza
-tion counterattack launched against that node would target an innocent 

party. In this case, the fact that the United States has only moderate con
-˜dence in the fact of Zendian responsibility is problematic.
An important aspect of any neutralization counterattack is the time 
it takes to determine the identity of the attacking party and to establish 

an access path and its geographic location. Perhaps the most plausible 

justi˜cation for a neutralization counterattack is that a counterattack is 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.146 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
needed to stop the immediate harm being done by an attack. If it takes 
so long for the defending party to obtain the necessary information for a 
counterattack that the attack has ceased by the time the counterattack can 

be launched, this justi˜cation may no longer be plausible.
56
Note that the policy requirement to quickly and properly identify the 
attacking party and the technical reality that attribution is a time-consum
-ing task work against each other. Shortening the time for investigation, 

perhaps by going so far as to automate the identi˜cation, assessment, and 

response process, may well increase the likelihood of errors being made 

in any response (e.g., responding against the wrong machine, launching 

a response that has large unintended effects). 
On the other hand, it is possible that a neutralization cyberattack 
would be used only after a number of hostile cyberattacks had occurred. 

Consider the ease of an unknown adversary launching cyberattacks against 

a particular U.S. defense facility. If forensic investigation is undertaken 

after each attack, after a while enough information might be obtained to 

determine the leading indicators of an attack by this adversary. At some 

point, the United States might well have enough information in hand so 

that it could respond quickly to the next cyberattack launched by this 

adversary, and might be willing to take the chance that it was responding 

erroneously with a neutralization cyberattack.
From a policy standpoint, the acceptability of an increase in the likeli
-hood of errors almost surely depends on the state of the world at the time. 

During times of normal political relations with other nations, such an 

increase may be entirely unacceptable. However, during times of political, 

diplomatic, or even military tension with other nations, the U.S. leader
-ship might well be willing to run the risk of a mistaken response in order 

to ensure that a response was not crippled by an adversary attack. (In this 

regard, the situation is almost exactly parallel to the issue of riding out a 

strategic attack on the United States or employing a strategy of launch
-ing a land-based strategic missile on warning or while under attackŠthe 

latter being regarded as much more likely during times of tension with a 

putative adversary.)
Under some circumstances, the United States might choose to launch 
a neutralization cyberattack fully expecting that the adversary would 

respond with an even larger hostile cyberattack. If it did so, it would be 

necessary for the United States to prepare for that eventuality. Such prepa
-ration might involve taking special measures to strengthen the cybersecu
-rity posture of key facilities and/or preparing for kinetic escalation.
56
 On the other hand, the cessation of an attack may simply indicate the end of one 
phase and the start of a lull before the next phase. A clever attacker would launch the next 
phase in such a way that the defender would have to unravel an entirely new chain.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 147These concerns do not automatically imply that neutralization coun
-terattacks are a bad idea under all circumstances. But they do raise several 
questions that must be answered before such a response is made.
Ł What defensive measures must be taken, if any, before launching a 
neutralization counterattack? Should a neutralization counterattack be a 

last resort, to be used when all other methods for responding to a cyberat
-tack have proven (or will prove) ineffective?
57
 Or should a neutralization 
counterattack be a measure of ˜rst resort, to be triggered automatically 

without human intervention in the ˜rst few seconds of an attack? Or 

somewhere in between?
Ł A counterattack requires only that an access path to the attacker 
be available. Under what circumstances must the identity of the attack
-ing party be known? If the attacker must be known, what degree of 

con˜dence and what evidentiary basis are needed? And how, if at all, 

should the attacker™s identity affect a decision to launch a counterattack? 

(For example, how might such a decision be affected by the fact that an 

attack is emanating from the information network of a U.S. hospital or an 

important laboratory?)
Ł How likely is it that the attacker will have anticipated a neutraliza
-tion counterattack and taken steps to mitigate or negate the effect of the 

counterattack? What are those steps likely to have been? How likely is it 

that a neutralization counterattack will indeed curb or halt the incoming 

attack? 
Ł How narrowly should a neutralization counterattack be focused? 
Should it be limited solely to eliminating or mitigating the threat (and not 

causing harm outside that effort)? Or is causing additional damage to the 

attacker a desirable outcome?
Ł At what threshold of actual or expected damage to U.S. systems 
and networks should a neutralization counterattack be launched? That is, 

how should the bene˜t of a counterattack be weighed against the politi
-cal risks of launching it? For example, what targets are worth protecting? 

(U.S. military installations? Installations associated with national critical 

infrastructure? Defense industrial base ˜rms? Fortune 500 companies?) 
Ł How should the threshold of damage be established? Should it be 
established unilaterally in real time by the original victim (e.g., the corpo
-ration or government entity attacked)? Or should it result from an orderly 

interagency and governmental process that operates well in advance of 

when policy guidance is needed?
57
 For example, one might argue that technical means such as target hardening and 
adversary deception and legal methods such as appeal to an ISP to disconnect an attacker 
from the Internet must be exhausted before active defense is considered.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.148 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Lastly, given the dif˜culties of knowing if a cyberattack is taking or 
has taken place; whether a given cyberattack is hostile, criminal, or mis
-chievous in intent; the identity of the responsible party; and the extent to 
which it poses a signi˜cant threat, the neutralization option must not be 

seen as the only way to respond to an attack. Box 2.4 describes a spectrum 

of possible responses to a cyberattackŠnote that the neutralization option 

corresponds to Action 6 or Action 7, and as such is a more aggressive form 

of response.
BOX 2.4
 A Possible Taxonomy of Active Responses 
There is a broad range of actions possible to respond to a cyberattack. One 
possible taxonomy of response actions was developed by Sergio Caltagirone.
1 This taxonomy identi˜es eight types of response in increasing order of activity 
required by the responder, potential impact on the attacker, and potential for col
-lateral and unintended consequences. 
1. No action
Ša conscious decision to take no action in response to an 
identi˜ed attack. Not taking any action is active insofar as it involves a thoughtful 
decision process that considers the bene˜ts and costs of potential options.
2. Internal noti˜cation
Šnotifying users, administrators, and management of 
the system attacked. Some subset of these may be noti˜ed depending on the type 

of attack, but the attack is not reported to anyone outside the organization of the 

affected system. 
3. Internal response
Štaking speci˜c action to protect the system from the 
attacker. The response likely depends on the type of attack, but might include 

blocking a range of IP addresses or speci˜c ports, segmenting or disconnecting 

parts of the system, and purposely dropping connections.
4. External cooperative response
Šcontacting external groups or agencies 
with responsibility for classifying, publicizing and analyzing attacks (e.g., CERT, 

DShield), taking law enforcement action (e.g., FBI, Secret Service), providing 

protection services (e.g., Symantec, MacAfee), and providing upstream support 

(e.g., Internet service providers).
There is a broad consensus that Actions 1-4 are legitimate actions under 
almost any set of circumstances. That is, an individual or organization is unambigu
-ously allowed to take any of these actions in response to a cyberattack. However, 

the same is not true for Actions 5-8 described below, which are listed in order of 

increasing controversy and increasing likelihood of running afoul of today™s legal 

regime should the target of a cyberattack take any of these actions.
5. Non-cooperative intelligence gathering
Šthe use of any tools to gather 
information about the attack and the attacker. Tools might include honeypots, 

honeynets, traceroutes, loose source and record routes, pings and ˜ngers. 
6. Non-cooperative ﬁcease and desistﬂ
Šthe use of tools to disable harmful 
services on the attacker™s system without affecting other system services.
7. Counterstrike
Šresponse taking two potential forms: direct action (active 
counterstrike) such as hacking the attacker™s systems (hack-back) and transmitting 

a worm targeted at the attacker™s system; passive counterstrike that redirects the 

attack back to the attacker, rather than directly opposing the attack. Examples of 

passive counterstrike are a footprinting strike-back that sends endless data, bad 

data, or bad SQL requests, and network reconnaissance strike-back using trace-
route packets (ICMP ﬁTTL expiredﬂ). 
8. Preemptive defense
Šconducting an attack on a system or network in 
anticipation of that system or network conducting an attack on your system.
Different actions may be taken based on the type of attack and an analysis 
of the bene˜ts and costs associated with each type of response. Multiple types of 
responses may be taken for any given attack. 
Actions 1-4 are generally non-controversial, in the sense that it would not 
be legally problematic for a private company to take any of these responses. 

Actions 6-8 are much more aggressive, fall into the general category of active 

defense (and more), and certainly raise many questions under the statutory pro
-hibitions against conducting cyberattack. In addition, system administrators often 

express concern about the legality of Action 5 in light of the various statutes gov
-erning electronic surveillance.
1 
S. Caltagirone and D. Frincke, 
Information Assurance Workshop, 2005, IAW ‚05, Pro
-ceedings from the Sixth Annual IEEE SMC
, June 15-17, 2005, pp. 258-265. See also David 
 Dittrich and Kenneth Einar Himma, ﬁActive Response to Computer Intrusions,ﬂ 
The Handbook 
of Information Security,
 Hossein Bidgoli, editor-in-chief, John Wiley & Sons, Inc., Hoboken, 
N.J., 2005.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 1492.6
 TECHNICAL
 AND
 O
PERATIONAL
  CONSIDERATIONS
 FOR
 C
YBEREXPLOITATION
2.6.1
 Technical Similarities in and Differences 
 Between Cyberattack and Cyberexploitation
The cyberexploitation mission is different from the cyberattack mis
-sion in its objectives (as noted in Chapter 1) and in the legal constructs 
surrounding it (as discussed in Chapter 7). Nevertheless, much of the 

technology underlying cyberexploitation is similar to that of cyberattack, 

and the same is true for some of the operational considerations as well.
BOX 2.4
 A Possible Taxonomy of Active Responses 
There is a broad range of actions possible to respond to a cyberattack. One 
possible taxonomy of response actions was developed by Sergio Caltagirone.
1 This taxonomy identi˜es eight types of response in increasing order of activity 
required by the responder, potential impact on the attacker, and potential for col
-lateral and unintended consequences. 
1. No action
Ša conscious decision to take no action in response to an 
identi˜ed attack. Not taking any action is active insofar as it involves a thoughtful 
decision process that considers the bene˜ts and costs of potential options.
2. Internal noti˜cation
Šnotifying users, administrators, and management of 
the system attacked. Some subset of these may be noti˜ed depending on the type 

of attack, but the attack is not reported to anyone outside the organization of the 

affected system. 
3. Internal response
Štaking speci˜c action to protect the system from the 
attacker. The response likely depends on the type of attack, but might include 

blocking a range of IP addresses or speci˜c ports, segmenting or disconnecting 

parts of the system, and purposely dropping connections.
4. External cooperative response
Šcontacting external groups or agencies 
with responsibility for classifying, publicizing and analyzing attacks (e.g., CERT, 

DShield), taking law enforcement action (e.g., FBI, Secret Service), providing 

protection services (e.g., Symantec, MacAfee), and providing upstream support 

(e.g., Internet service providers).
There is a broad consensus that Actions 1-4 are legitimate actions under 
almost any set of circumstances. That is, an individual or organization is unambigu
-ously allowed to take any of these actions in response to a cyberattack. However, 

the same is not true for Actions 5-8 described below, which are listed in order of 

increasing controversy and increasing likelihood of running afoul of today™s legal 

regime should the target of a cyberattack take any of these actions.
5. Non-cooperative intelligence gathering
Šthe use of any tools to gather 
information about the attack and the attacker. Tools might include honeypots, 

honeynets, traceroutes, loose source and record routes, pings and ˜ngers. 
6. Non-cooperative ﬁcease and desistﬂ
Šthe use of tools to disable harmful 
services on the attacker™s system without affecting other system services.
7. Counterstrike
Šresponse taking two potential forms: direct action (active 
counterstrike) such as hacking the attacker™s systems (hack-back) and transmitting 

a worm targeted at the attacker™s system; passive counterstrike that redirects the 

attack back to the attacker, rather than directly opposing the attack. Examples of 

passive counterstrike are a footprinting strike-back that sends endless data, bad 

data, or bad SQL requests, and network reconnaissance strike-back using trace-
route packets (ICMP ﬁTTL expiredﬂ). 
8. Preemptive defense
Šconducting an attack on a system or network in 
anticipation of that system or network conducting an attack on your system.
Different actions may be taken based on the type of attack and an analysis 
of the bene˜ts and costs associated with each type of response. Multiple types of 
responses may be taken for any given attack. 
Actions 1-4 are generally non-controversial, in the sense that it would not 
be legally problematic for a private company to take any of these responses. 

Actions 6-8 are much more aggressive, fall into the general category of active 

defense (and more), and certainly raise many questions under the statutory pro
-hibitions against conducting cyberattack. In addition, system administrators often 

express concern about the legality of Action 5 in light of the various statutes gov
-erning electronic surveillance.
1 
S. Caltagirone and D. Frincke, 
Information Assurance Workshop, 2005, IAW ‚05, Pro
-ceedings from the Sixth Annual IEEE SMC
, June 15-17, 2005, pp. 258-265. See also David 
 Dittrich and Kenneth Einar Himma, ﬁActive Response to Computer Intrusions,ﬂ 
The Handbook 
of Information Security,
 Hossein Bidgoli, editor-in-chief, John Wiley & Sons, Inc., Hoboken, 
N.J., 2005.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.15
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
As noted in Section 2.2.2, a successful cyberattack requires a vulner
-ability, access to that vulnerability, and a payload to be executed. A cyber
-exploitation requires the same three thingsŠand the only technological 
difference is in the payload to be executed. That is, what distinguishes a 

cyberexploitation from a cyberattack is the nature of the payload. 
Whereas the attacker might destroy the papers inside a locked ˜le 
cabinet once he gains access to it, the exploiter might copy them and take 

them away with him. In the cyber context, the cyberexploiter will seek 

to compromise the con˜dentiality of protected information afforded by a 

computer system or network. 
2.6.2
 Possible Objectives of Cyberexploitation
What might cyberexploitations seek to accomplish? Here are some 
hypothetical examples. The cyberexploiter might seek to:
Ł Exploit information a
vailable on a network.
 For example, an attacker 
might monitor passing traf˜c for keywords such as ﬁnuclearﬂ or ﬁpluto
-nium,ﬂ and copy and forward to the attacker™s intelligence services any 

messages containing such words for further analysis. A cyberexploita
-tion against a military network might seek to ex˜ltrate con˜dential data 

indicating orders of battle, operational plans, and so on. Alternatively, 

passwords are often sent in the clear through e-mail, and those passwords 

can be used to penetrate other systems. This objective is essentially the 

same as that for all signals intelligence activitiesŠto obtain intelligence 

information on an adversary™s intentions and capabilities.
Ł Be a passi
ve obser
ver of a network™s topology and traf˚c. 
As long as 
the attacker is a passive observer, the targeted adversary will experience 

little or no direct degradation in service or functionality offered by the 

network. Networks can be passively monitored to identify active hosts 

as well as to determine the operating system and/or service versions 

(through signatures in protocol headers, the way sequence numbers are 

generated, and so on).
58
 The attacker can map the network and make 
inferences about important and less important nodes on it simply by 

performing traf˜c analysis. (What is the organizational structure? Who 

holds positions of authority?) Such information can be used subsequently 

to disrupt the network™s operational functionality. If the attacker is able 

to read the contents of traf˜c (which is likely, if the adversary believes 

the network is secure and thus has not gone to the trouble of encrypting 
58
 Annie De Montigny-Leboeuf and Frederic Massicotte, ﬁPassive Network Di
scovery 
for Real Time Situation Awareness,ﬂ 2004, available at http://www.snort.org/docs
/industry/ADeMontigny NatoISTToulouse2004.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 151
 
traf˜c), he can gain much more information about matters of signi˜cance 
to the network™s operators. As importantly, a map of the network provides 
useful information for a cyberattacker, who can use this information to 

perform a more precise targeting of later attacks on hosts on the local 

network, which are typically behind ˜rewalls and intrusion detection/

prevention systems that might trigger alarms. 
Ł Obtain technical information from a company™s network in another 
country in order to bene˜t a domestic competitor of that company. For 

example, two former directors of the DGSE (the French intelligence ser
-vice) have publicly stated that one of the DGSE™s top priorities was to col
-lect economic intelligence. During a September 1991 NBC news program, 

Pierre Marion, former DGSE director, revealed that he had initiated an 

espionage program against U.S. businesses for the purpose of keeping 

France internationally competitive. Marion justi˜ed these actions on the 

grounds that the United States and France, although political and military 

allies, are economic and technological competitors. During an interview 

in March 1993, then-DGSE director Charles Silberzahn stated that politi
-cal espionage was no longer a real priority for France but that France was 

interested in economic intelligence, ﬁa ˜eld which is crucial to the world's 

evolution.ﬂ Silberzahn advised that the French have had some success in 

economic intelligence but stated that much work is still needed because 

of the growing global economy. Silberzahn advised during a subsequent 

interview that theft of classi˜ed information, as well as information about 

large corporations, was a long-term French government policy.
59
 The examples above suggest certain technical desiderata for cyberex
-ploitations. For instance, it is highly desirable for a cyberexploitation to 

have a signature that is dif˜cult for its target to detect, since the cyberex
-ploitation operation may involve many separate actions spread out over 

a long period of time in which only small things happen with each action. 

One reason is that if the targeted party does not know that its secret 

information has been revealed, it is less likely to take countermeasures to 

negate the compromise. A second reason is that the exploiter would like 

to use one penetration of an adversary™s computer or network to result 

in multiple ex˜ltrations of intelligence information over the course of 

the entire operation. That is, the intelligence collectors need to be able to 

maintain a clandestine presence on the adversary computer or network 

despite the fact that information ex˜ltrations provide the adversary with 

opportunities to discover that presence.
Also, an individual payload can have multiple functions simultane
-59
 See page 33, footnote 1, in National Research Council, 
Cryptography™s Role in Securing 
the Information Society
, National Academy Press, Washington, D.C., 1996.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.152
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
ouslyŠone for cyberattack and one for cyberexploitationŠand which 
function is activated at any given time will depend on the necessary 
command and control arrangements (see Section 2.3.8). For example, a 

payload delivered to an adversary command and control network may 

be designed to ex˜ltrate information during the initial stages of a con˚ict 

and then to degrade service on the network when it receives a command 

to do so.
In addition, the relationship between technologies for cyberexploita
-tion and cyberattack is strong enough that the cost of equipping a tool for 

the former with the capability for the latter is likely to be lowŠso low that 

in many cases acquisition managers could ˜nd it sensible as a matter of 

routine practice to equip a cyberexploitation tool with attack capabilities 

(or provide it with the ability to be modi˜ed on-the-˚y in actual use to 

have such capabilities).
60
 2.6.3
 Approaches for Cyberexploitation
As is true for cyberattack, cyberexploitation can be accomplished 
through both remote-access and close-access methodologies.
A hypothetical example of cyberexploitation based on remote access 
might involve ﬁpharmingﬂ against an unprotected DNS server, such as 

the one resident in wireless routers.
61
 Because wireless routers at home 
tend to be less well protected than institutional routers, they are easier to 

compromise. Successful pharming would mean that web traf˜c originat
-ing at the home of the targeted individual (who might be a senior of˜cial 

in an adversary™s political leadership) could be redirected to websites 

controlled by the exploiter. With access to the target™s home computer 

thus provided, vulnerabilities in that computer could be used to insert a 

payload that would ex˜ltrate the contents of the individual™s hard disk, 

possibly providing the exploiter with information useful for blackmailing 

the target. As a historical precedent, Symantec in January 2008 reported an 

incident directed against a Mexican bank in which the DNS settings on a 

customer™s home router were compromised.
62
 An e-mail was sent to the 
target, ostensibly from a legitimate card company. However, the e-mail 
60
 If these cyberexploitation tools were to be used against U.S. citizens (more precisely, 
U.S. persons as de˜ned in EO 12333 (Section 7.3.6)), legal and/or policy implications might 
arise if these tools were to have attack capabilities as well. Thus, the observation is most 

likely to be true for tools that are not intended for such use.
61
 ﬁPharmingﬂ is the term given to an attack that seeks to redirect the traf˜c to a par
-ticular website to another, bogus website. 
62
 Ellen Messmer, ﬁFirst Case of ‚Drive-by Pharming™ Identi˜ed in the Wild,ﬂ 
Network 
World
, January 22, 2008, available at http://www.networkworld.com/news/2008/012208-
drive-by-pharming.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 153
contained a request to the home router to tamper with its DNS settings. 
Thus, traf˜c intended for the bank was redirected to the criminal™s web
-site mimicking the bank site.
A hypothetical example of cyberexploitation based on close access 
might involve intercepting desktop computers in their original shipping 
cartons while they are awaiting delivery to the victim, and substitut
-ing for the original video card a modi˜ed one that performs all of the 

original functions and also monitors the data being displayed for subse
-quent transmission to the exploiter. There is historical precedent for such 

approaches. One episode is the 1984 U.S. discovery of Soviet listening 

devices in the Moscow embassy™s typewritersŠthese devices captured all 

keystrokes and transmitted them to a nearby listening post.
63
 A second 
reported episode involves cameras installed inside Xerox copiers in Soviet 

embassies in the 1960s.
64
 A third episode, still not fully understood, is the 
2004-2005 phone-tapping affair in Greece.
65
 2.6.4
 Some Operational Considerations for Cyberexploitation
2.6.4.1
  
The Fundamental Similarity Between Cyberattack and 
Cyberexploitation
Because the cyber offensive actions needed to carry out a cyber
-exploitation are so similar to those needed for cyberattack, cybe
rexploitations 
and cyberattacks may be dif˜cult to distinguish in an operational context. 

(The problem of distinguishing between them is compounded by the fact 

that an agent for exploitation can also contain functionality to be used at 

another time for attack purposes.) This fundamental ambiguityŠabsent 

with kinetic, nuclear, biological, and chemical weaponsŠhas several 

consequences:
63
 Jay Peterzell, ﬁThe Moscow Bug Hunt,ﬂ 
Time
, July 10, 1989, available at http://www.
time.com/time/magazine/article/0,9171,958127-4,00.html.
64
 Ron Laytner, ﬁXerox Helped Win The Cold War,ﬂ 
Edit International,
 2006, available at 
http://www.editinternational.com/read.php?id=47ddf19823b89.
65
 In this incident, a number of mobile phones belonging mostly to members of the 
Greek government and top-ranking civil servants were found to have been tapped for an ex
-tended period of time. These individuals were subscribers to Vodafone Greece, the country™s 
largest cellular service provider. The taps were implemented through a feature built into the 

company™s switching infrastructure originally designed to allow law enforcement agencies 

to tap telephone calls carried on that infrastructure. However, those responsible for the taps 

assumed control of this feature to serve their own purposes and were also able to conceal 

their activities for a long time. The sophistication of the programming required to undertake 

this compromise is considerable, and has led to speculation that the affair was the result 

of an inside job. See Vassilis Prevelakis and Diomidis Spinellis, ﬁThe Athens Affair,ﬂ 
IEEE 
Spectrum
, July 2007, available at http://www.spectrum.ieee.org/print/5280.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.15
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Ł The targeted party may not be able to distinguish between a cyber
-exploitation and a cyberattack, especially on short time scales, even if 
such differences are prominent in the minds of the party undertaking 

cyber offensive actions.
Ł Because the legal authorities to conduct cyberexploitations and 
cyberattacks are quite different, clarity in the minds of the operators about 

their roles in any given instance is essential. 
Ł From a training and personnel standpoint, developing expertise 
at cyberattack also develops most of the required skill set for conducting 

cyberexploitation, and vice versa.
 66
2.6.4.2
 Target Identi˚cation and Intelligence Preparation 
Although some intelligence operations may be characterized by a 
ﬁvacuum cleanerﬂ approach that seeks to obtain all available traf˜c for 

later analysis, a cyberexploiter may be very concerned about which com
-puters or networks are targetedŠan issue of precision. Very precise cyber
-exploitations would be characterized by small-scale operations against 

a speci˜c computer or user whose individual compromise would have 

enormous value (ﬁgoing after the crown jewelsﬂ)Šthe vice president™s 

laptop, for example. 
To the extent that speci˜c systems must be targeted, substantial intel
-ligence efforts may be required to identify both access paths and vulner
-abilities. For example, even if the vice president™s laptop is known to be 

a Macintosh running OS-X, there may well be special security software 

running on her laptop; ˜nding out even what software might be run
-ning, to say nothing of how to circumvent it, is likely to be very dif˜cult 

in the absence of close access to it. The same considerations are true of 

Internet-connected computer systems that provide critical functionality 

to important companies and organizationsŠthey may well be better pro
-66
 For example, Air Force Doctrine Document 2-5 (issued by the Secretary of the Air 
Force, January 11, 2005) explicitly notes that ﬁmilitary forces under a combatant commander 
derive authority to conduct NetA [network attack] from the laws contained in Title 10 of 

the U.S. Code (U.S.C.). However, the skills and target knowledge for effective NetA are best 

developed and honed during peacetime intelligence or network warfare support (NS) opera
-tions. Intelligence forces in the national intelligence community derive authority to conduct 

network exploitation and many NS [national security] operations from laws contained in 

U.S.C. Title 50. For this reason, ‚dual-purpose™ military forces are funded and controlled 

by organizations that derive authority under laws contained in both Title 10 and Title 50. 

The greatest bene˜t of these ‚dual-purpose™ forces is their authority to operate under laws 

contained in Title 50, and so produce actionable intelligence products while exercising the 

skills needed for NetA. These forces are the preferred means by which the Air Force can 

organize, train, and equip mission-ready NetA forces.ﬂ See http://www.herbb.hanscom.

af.mil/tbbs/R1528/AF_Doctrine_Doc_2_5_Jan_11__2005.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 155
tected than is the average system on the Internet. Nevertheless, as press 
reports in recent years make clear, such measures do not guarantee that 
their systems are immune to the hostile actions of outsiders.
67
 As for gathering the intelligence needed to penetrate an adversary 
computer or network for cyberexploitation, this process is essentially 

identical to that for cyberattack. The reason is that cyberexploitation and 

cyberattack make use of the same kinds of access paths to their targets, 

and take advantage of the same vulnerabilities to deliver their payloads. In 

the event that an adversary detects these intelligence-gathering attempts, 

there is no way at all to determine their ultimate intent.
2.6.4.3
 Rules of Engagement and Command and Control
Rules of engagement for cyberexploitation specify what adversary 
systems or networks may be probed or penetrated to obtain information. 

A particularly interesting question arises when a possible target of oppor
-
tunity becomes known in the course of an ongoing cyberexploitation. For 

example, in the course of exploring one adversary network (Network A), 

the exploiter may come across a gateway to another, previously unknown 

network (Network B). Depending on the nature of Network B, the rules 

of engagement speci˜ed for Network A may be entirely inadequate (as 

might be the case if Network A were a military command and control 

network and Network B were a network of the adversary™s national com
-mand authority). Rules of engagement for cyberexploitation must thus 

provide guidance in such situations.
In at least one way, command and control for cyberexploitation is 
more complex than for cyberattack because of the mandatory requirement 

of report-backŠa cyberexploitation that does not return information to 

its controller is useless. By contrast, it may be desirable for a cyberattack 

agent or weapon to report to its controller on the outcome of any given 

attack event, but its primary mission can still be accomplished even if it 

is unable to do so.
Report-back also introduces another opportunity for the adversary 
to discover the presence of an exploiting payload, and thus the exploiter 

must be very careful in how report-back is arranged.
67
 For example, the Slammer worm attack reportedly resulted in a severe degrada
-tion of the Bank of America™s ATM network in January 2003. See Aaron Davis, ﬁComputer 
Worm Snarls Web: Electronic Attack Also Affects Phone Service, BOFA™s ATM Network,ﬂ 
San Jose Mercury News
, January 26, 2003, available at http://www.bayarea.com/mld
/mercurynews/5034748.htm+atm+slammer+virus&hl=en.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.156
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
2.6.4.4
 Effectiveness Assessment
The cyberexploitation analog to damage assessment for cyberattack 
might be termed effectiveness assessment. If a cyberexploitation does not 
report back to its controller, it has failed. But even if it does report back, 

it may not have succeeded. For cyberexploitation, the danger is that it 
has been discovered and that somehow the adversary has provided false 
or misleading information that is then reported back. Alternatively, the 

adversary may have compromised the report-back channel itself and 

inserted its own message that is mistaken for an authentic report-back 

message. (In a worst-case scenario, the adversary may use the report-back 

channel as a vehicle for conducting its own cyberattack or cyberexploita
-tion against the controller.)
These scenarios for misdirection are not unique to cyberexploita
-tion, of courseŠthey are possible in ordinary espionage attempts as well. 

But because it is likely to be dif˜cult for an automated agent to distin
-guish between being present on a ﬁrealﬂ target versus being present on a 

ﬁdecoyﬂ target, concerns about misdirection in a cyberexploitation context 

are all too real.
2.6.4.5
 Tradeoffs Between Cyberattack and Cyberexploitation
In contemplating what to do about an adversary computer or net
-work, decision makers have essentially two optionsŠrender it unavail
-able for serving adversary purposes or exploit it to gather useful informa
-tion. In many cases, these two options are mutually exclusiveŠdestroying 

it makes it impossible to exploit it. In some cases, destroying it may also 

reveal to the adversary some vulnerability or access path previously 

unknown to him, and thus compromise friendly sources and methods.
These tradeoffs are no less present in cyberattack and cyberexploita
-tion. But in some ways, the tradeoffs may be easier to manage. For exam
-ple, because a given instrument for cyberexploitation can be designed 

with cyberattack capabilities, the transition between exploitation and 

attack may be operationally simpler. Also, a cyberattack may be designed 

to corrupt or degrade a system slowlyŠand exploitation is possible as 

long as the adversary does not notice the corruption. 
2.7
 HISTORICAL
 P
RECEDENTS
 AND
 L
ESSONS
To provide a sense of what might be possible through cyberattack and 
cyberexploitation, it is useful to consider some of the ways in which crimi
-nals have used them. A number of such cases are described in Appen
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.TECHNICAL AND OPERATIONAL CONSIDERATIONS
 157
dix C, and some of the lessons derived from considering these cases are 
provided below.
Ł Attacks can have multiple phases, as illustrated in several of the 
cases in Appendix C, that last over a relatively long period of time (over 
a year, in many cases.) This is especially true of DDOS attacks, where 

attackers must ˜rst take control of thousands and thousands of comput
-ers by installing their malicious software on them, causing them to join 

into mass command and control (e.g., join a botnet in IRC channels.) The 

same bots that are used for DDOS are also used for recruiting new bots 

through direct attack, sending copies of the malware to addressees in the 

victimized computer™s address book. The less visible or ﬁnoisyﬂ the activ
-ity, the longer the multiphase attack can last before being detected and 

mitigated.
Ł Attacks can also have multiple foci. In the Invita case (Appendix 
C), there was a primary focus on trying to locate credit card data to per
-petrate fraud, but the attackers also used extortion to obtain ˜nancial 

gain. In some of the botnet cases, the botnets would be used for extortion 

or click-fraud. The Stakkato case was multitarget, but this was primarily 

a by-product of following login trust relationships between systems and 

sites. 
Ł The same tactics used to compromise one host can be extended 
to compromise 1,000 hosts, given enough resources to repeat the same 

steps over and over, assuming the attacked systems are part of the same 

system monoculture all running the same targeted software (such as 

the same operating system). Automating these steps makes the job even 

easier, which can readily be done. (Anything that a user can do by typing 

at a keyboard can be turned into a scripted action. This is how the Invita 

attackers managed the creation and use of e-mail and online bidding 

accounts.) 
A corollary is the notion that an indirect attack can be as successful as 
a direct attack, given the resources necessary to work through the entire 

set of login relationships between systems. For example, one can attempt 

to get access to another person™s account by attacking that target™s lap
-top or desktop system. This may fail, because the target may secure its 

personal computers very well. But the target may depend on someone 

else for system administration of its mail spool and home directory on 

a shared server. The attacker can thus go after a colleague™s, a fellow 

employee™s, or the service provider™s computer and compromise it, and 

then use that access to go after an administrator™s password on the ˜le 

server holding the target™s account.
The best case (from an attacker™s standpoint) is when the same vul
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.158
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
nerability exists at all levels within large interconnected systems, where 
ﬁredundantﬂ resources can be compromised, resulting in cascading 
effects.
68
 This situation could allow an adversary to very quickly com
-mandeer a large and diverse population of systems, as has been witnessed 

in various worm outbreaks over the past few years. 
Ł The theft of credentials, either for login authentication or execut
-ing ˜nancial transactions, is a popular and successful avenue of attack. 

All that is necessary is either to direct a user to pass his or her keystrokes 

through a program under control of the attack (e.g., as in ﬁphishingﬂ 

attacks), or to get administrative control of either clients or servers and 

install software that logs keystrokes.
Ł Highly targeted attacks against speci˜c companies are possible, 
as was seen in the Israeli industrial espionage case, as well as a variant 

of the BugBear trojan in 2003 that speci˜cally targeted the domains of 

more than 1,000 speci˜c banks in several countries.
69
 Discovery and tak
-ing advantage of implicit business trust relationships between sites are 

also possible, as was seen in the Stakkato case. An attacker need only 

start with the most basic information that can obtained about a company 

through open sources (e.g., press releases, organizational descriptions, 

phone directories, and other data made public through websites and news 

stories). She then uses this information to perform social engineering 

attacks, a pretext designed to trick users into giving out their passwords 

so that she can gain access to computers inside an organization™s net
-work. Once in control of internal hosts, she effectively has insider access 

and can leverage that access to do more sensitive intelligence gathering 

on the target. She can learn business relationships, details about active 

projects and schedules, and anything necessary to fool anyone in the 

company into opening e-mail attachments or performing other acts that 

result in compromise of computer systems. (This is basic intelligence col
-lection and analysis.) Control of internal hosts can also be used to direct 

attacksŠbehind the ˜rewall and intrusion detection systems or intrusion 

prevention systemsŠagainst other internal hosts.
68
 See, for example, Daniel E. Geer, ﬁMeasuring Security,ﬂ 2006, pp. 170-178, available 
at http://geer.tinho.net/measuringsecurity.tutorialv2.pdf.
69
 F-Secure, ﬁF-Secure Virus Descriptions: Bugbear.B,ﬂ 2003, available at http://www.
f-secure.com/v-descs/bugbear_b.shtml.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Part II
Mission and Institutional Perspectives
Part II contains three different mission perspectives. Chapter 3 
addresses military perspectives on cyberattack, largely from the point 
of view of the Department of Defense. Chapter 4 addresses intelligence 

perspectives on cyberattack (for conducting covert action) and cyberex
-ploitation (for obtaining information). Chapter 5 addresses federal law 

enforcement perspectives on cyberattack and cyberexploitation and con
-siders how the private sector might view cyberattack as an element of 

its defensive posture. These chapters depict in outline form how various 

institutions both inside and outside government have conceptualized or 

may in the future conceptualize the use of cyberattack and cyberexploita
-tion technologies. 
Regrettably, the picture that emerges from these chapters is frag
-mented and incompleteŠlargely because national policy with respect to 

cyberattack is fragmented and incomplete. The secrecy that surrounds 

policy in this area has further worsened the coherence of the overall 

picture. On the other hand, it is often true that with a new and easily 

available technology (the technology of cyber offensive actions), interests 

among a variety of different institutional actors in using this technology 

have arisen from the bottom upŠfrom those with operational missions. 

In the early stages of technology adoption, some actors consider how 

the technology of cyber offensive actions might support or better enable 

the performance of their traditional missionsŠand others ignore it. The 

bottom-up nature of technology adoption in such cases inevitably leads 

to adoptions at different rates and for relatively parochial purposes, and 
159
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.16
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
so the fragmentation of policy and organization today is not entirely 
surprising.
Nevertheless, the committee believes there is value in setting forth 
a notional view of how these institutions might conceptualize the uses 

of cyberattack, the associated decision-making structures, and the infra
-structure needed to support the use of cyberattack as an instrument in 

their toolkits. If nothing else, the availability of a notional view provides 

a framework against which to react and within which to pose questions 

about what might be missing. These comments should be kept in mind 

as these chapters are read.
Part II also contains Chapter 6, a description of decision-making and 
oversight mechanisms in both the executive and the legislative branches 

that are relevant for cyberattack. Considering these mechanisms from a 

top-down perspective is intended to provide some points of reference that 

can help to identify what is missing from the picture painted by Chapters 

3, 4, and 5.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.3A Military Perspective on Cyberattack
3.1
 U.S. M
ILITARY
 D
OCTRINE
 AND
 C
YBERATTACK
The most current statement of U.S. military doctrine regarding cyber
-attack identi˜es computer network attack (an aspect of what this report 
calls cyberattack) as an element of computer network operations (CNO), 

the other two of which are computer network defense (CND) and related 

computer network exploitation (CNE) enabling operations. Computer 

network attack (CNA) refers to actions taken through the use of com
-puter networks to disrupt, deny, degrade, or destroy information resident 

in computers and computer networks, or the computers and networks 

themselves. CND refers to actions taken through the use of computer 

networks to protect, monitor, analyze, detect, and respond to unauthor
-ized activity against or within DOD information systems and computer 

networks. CNE (computer network exploitation, an aspect of what this 

report calls cyberexploitation) refers to operations conducted through 

the use of computer networks to gather data from target or adversary 

automated information systems or networks, and the term ﬁrelated CNE 

enabling operationsﬂ refers to operations undertaken to gather intelli
-gence information for carrying out CNO or CND operations.
Current doctrine (Joint Publication 3-13, 
Joint Doctrine on Information 
Operations
) notes that all of these capabilities can be used for both offen
-sive and defensive purposes. For example, under this rubric, a computer 

network attack might be used for a defensive purpose, such as the neu
-tralization of a cyberthreat to a DOD computer or network. 
At the date of this writing, an unclassi˜ed and authoritative state
-161
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.162
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
ment of current joint doctrine for the use of computer network attack is 
unavailable, and it is fair to say that current doctrine on this matter is still 
evolving. However, in testimony to the House Armed Services Commit
-tee on March 21, 2007, General James E. Cartwright, Commander of the 

United States Strategic Command, said that ﬁcyberspace has emerged as 

a war˜ghting domain not unlike land, sea, and air, and we are engaged 

in a less visible, but nonetheless critical battle against sophisticated cyber
-space attacks.ﬂ He pointed out the importance of deterring adversaries 

and assuring U.S. freedom of action in cyberspace, and argued that ﬁfun
-damental to this approach is the integration of cyberspace capabilities 

across the full range of military operations.ﬂ He then observed that ﬁto 

date, our time and resources have focused more on network defenses to 

include ˜rewalls, antivirus protection, and vulnerability scanning. [But] 

while generally effective against unsophisticated hackers, these measures 

are marginally effective against sophisticated adversaries.ﬂ 
Following this observation, he then stated: 
History teaches us that a purely defensive posture poses signi˜cant 
risks; the ﬁMaginot Lineﬂ model of terminal defense will ultimately fail 

without a more aggressive offshore strategy, one that more effectively 
layers and integrates our cyber capabilities. If we apply the principles of 
warfare to the cyber domain, as we do to sea, air, and land, we realize the 

defense of the nation is better served by capabilities enabling us to take 

the ˜ght to our adversaries, when necessary to deter actions detrimental 
to our interests.
A number of other DOD and service statements and publications have 
added texture to the perspective articulated by General Cartwright. The 
2006 
National Military Strategy for Cyberspace Operations
 (redacted copy 
available online
1) says that ﬁas a war-˜ghting domain . . . cyberspace 
favors the offense . . . an opportunity to gain and maintain the initiative.ﬂ 

It further de˜nes cyberspace as a domain ﬁcharacterized by the use of elec
-tronics and the electromagnetic spectrum to store, modify, and exchange 

data via networked systems and associated physical infrastructures.ﬂ 
Prevailing military doctrine calls for the U.S. dominance of domains 
of warfare, traditionally including land, sea, air, and space, and now 

including cyberspace. Dominance in a domain means that the U.S. mili
-tary should have freedom of access to and use of the domain, and should 

be able to deny access to and use of that domain to an adversaryŠand 

dominance requires that the United States play both offense and defense. 

Furthermore, if cyberspace is like any other war˜ghting domain, the fun
-damental concepts of warfare must apply to the cyberspace domain.
1 See http://www.dod.mil/pubs/foi/ojcs/07-F-2105doc1.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 163
An example of how such thinking regarding cyberspace-as-domain 
can play out was described to the committee in a brie˜ng from the Air 
Force Cyberspace Task Force. In the CTF view, the United States should 

be provided with ﬁoffensive capabilities and deliberate target sets.ﬂ In 

addition, the brie˜ng argued that ﬁcyber favors the offensiveﬂ and that 

under this rubric fell several different missions, including strategic attack 

directly at enemy centers of gravity, suppression of enemy cyberdefenses, 

offensive countercyber, defensive countercyber, and interdiction. Consis
-tent with Secretary of the Air Force Michael W. Wynne™s statement that 

ﬁall aspects of air war will have some equivalent role in cyber war,ﬂ
2 these 
missions have rather close analogs to traditional Air Force missionsŠ
 strategic bombing attack against enemy centers of gravity, suppression 
of enemy air defenses to facilitate airspace penetration of enemy borders, 
offensive counter-air (destroying enemy aircraft on the ground), defen
-sive counter-air (defending friendly territory from enemy aircraft in the 

air), and interdiction (attack of enemy assets far behind the battlefront).
3 (Whether this particular view of cyberspace as a domain of military con
-˚ict will ultimately be adopted throughout the Department of Defense is 

not clear at this time.) 
The doctrinal perspective that cyberspace is another war˜ghting 
domain has other implications as well. For example, operations in cyber
-space need to be synchronized and coordinated with other operations, 

just as land and air operations, for example, must be synchronized and 

coordinated. In other words, during overt or open military con˚ict, it is 

highly likely that information operationsŠincluding cyberattacks if mili
-tarily appropriateŠwill not be the only kind of military operations being 

executed. Examples of coordination issues are described in Box 3.1.
The doctrinal perspective further implies that cyberweapons should 
be regarded as no different from any other kind of weapon available to 

U.S forces. That is, their use should be initiated on the basis of their suit
-ability for conducting the attacks in question, and should not require any 

extraordinary analysis or authority to which the non-cyberspace military 

is not already accustomed. Thus, in determining the best way to attack 

a target, cyberweapons simply provide the operational planner with 

another option, in addition to the air-delivered laser-guided bomb and the 

Special Operations force with demolition charges.
Similar considerations apply from a legal perspective. For example, 
2 Michael W. Wynne, ﬁFlying and Fighting in Cyberspace,ﬂ 
Air & Space Power Journal,
  
Spring 2007, available at http://www.airpower.maxwell.af.mil/airchronicles/apj/apj07/
spr07/wynnespr07.html.
3 Indeed, Lt. Gen. Bill Donahue (USAF, ret.) argued in a brie˜ng to the committee that 
one could almost literally do a global search and replace that would replace ﬁAirﬂ with 

ﬁCyberspaceﬂ in Air Force war˜ghting doctrine.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.16
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 3.1
 Possible Coordination Issues for Cyberattack
Cross-domain coordination requires that the effects of a cyberattack on the 
physical world (both direct and consequential) and the timing of those effects 
should be known with enough certainty that their possible use can be taken into 

account in operational planning. Some issues include the following:
Coordination with other military operations.
 Planners might choose to at
-tack a given target using both a cyberweapon and a kinetic weapon. Redundancy 

in an attack, especially using different modes of attack that might exploit different 

vulnerabilities, is often desirable from a planning perspective. On the other hand, 

problems may result if the damage assessment from one operation is not avail
-able to those planning the other operation (e.g., as the result of stovepiping within 

executing agents).
Coordination between cyber operations for attack and for defense.
 A 
computer network attack launched by the U.S. military may stimulate a counter-

response from an adversary that could affect U.S. computers and networks, which 

mayŠor may notŠbe under military control. For example, a cyberattack that is 

conducted against a target in a given geographic command (e.g., PACOM) by the 

U.S. Strategic Command may stimulate action that has an impact on the regional 

networks used by that geographic command. A cyberattack launched by the United 

States may also stimulate adversary action that would have an impact on private 

sector network use and potentially disrupt important civilian activitiesŠsuggesting 

that cyberattacks by the U.S. military may have defensive implications.
Coordination between cyberattack and cyberexploitation.
 Unless attack 
and exploitation are coordinated, it is possible to imagine scenarios in which a 

cyberattack to plant false information in an adversary™s database results in the 

cyberexploitation extracting that false information and using it as though it were 

real and valid. And, of course, there is the classic con˚ict about whether it is more 

desirable to shut down an adversary™s communication channel (an attack opera
-tion) or to listen to it (an exploitation operation).
all military operations are subject to certain limitations mandated by the 
law of armed con˚ict regarding differentiation of targets, military neces
-sity, limiting collateral damage, and so on. Of course, targets in cyberspace 

are different from targets on the ground, so the facts relevant to any given 

operation may be different in the former case than in the latter, but the 

analytical process remains the same. Thus, if it was legitimate to attack 

a target with kinetic weapons, it remains legitimate under the laws of 

armed con˚ict to attack it with cyberweapons. These considerations are 

addressed at length in Chapter 7.
In short, according to this perspective, con˚ict in cyberspace should 
be treated like con˚ict in a physical domain, the same rules and policies 

should apply, and the only differences are operational.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 165
3.2
 DEPARTMENT OF DEFENSE O
RGANI
ZATION
  FOR
 C
YBERATTACK
The U.S. Strategic Command (STRATCOM) plays a key role in DOD 
cyber operations. STRATCOM is composed of eight functional compo
-nents, including ˜ve Joint Functional Component Commands (JFCCs).
4 Each JFCC is responsible for focusing on a speci˜c operational areaŠone 
of those operational areas involves offensive network warfare (NW) and 

defensive network operations (NetOps).
5Offensive network warfare is the responsibility of the Joint Functional 
Component Command for Network Warfare (JFCC-NW). The commander 

of the JFCC-NW is also the director of the National Security Agency (NSA) 

and is ﬁresponsible for deliberate planning of network warfare, which 

includes coordinated planning of offensive network attack.ﬂ
6 JFCC-NW 
was established in January 2005.
7 Network warfare as used in the context 
of JFCC-NW means ﬁthe employment of Computer Network Operations 

(CNO) with the intent of denying adversaries the effective use of their 

computers, information systems, and networks, while ensuring the effec
-tive use of our own computers, information systems, and networks.ﬂ
8 These operations include computer network attack (CNA), computer 

network exploitation (CNE), and Computer Network Defense (CND). 

The JFCC-NW also supports the network warfare needs of Combatant 

Commands/Commanders (COCOMs).
9 Defensive network operations are the responsibility of the Joint Task 
Force-Global Network Operations (JTF-GNO). The commander of JTF-

GNO is also the director of the Defense Information Systems Agency and 

is responsible for operating and defending the DOD information infra
-4 The eight components are JFCCŒGlobal Strike and Integration (JFCC-GSI), JFCCŒ
Integrated Missile Defense (JFCC-IMD), JFCCŒIntelligence, Surveillance and Reconnaissance 
(JFCC-ISR), JFCCŒSpace (JFCC-SPACE), Joint Information Operations Warfare Command 

(JIOWC), STRATCOM Center for Combating Weapons of Mass Destruction (SCC-WMD), 

and Joint Task ForceŒGlobal Network Operations (JTF-GNO). See http://www.stratcom.

mil/organization-fnc_comp.html. 
5 Lt. Gen. Keith B. Alexander, ﬁWar˜ghting in Cyberspace,ﬂ 
Joint Force Quarterly
 46(3):58-61, 2007. 
6 Clay Wilson, ﬁInformation Operations and Cyberwar: Capabilities and Related Policy 
Issues,ﬂ U.S. Congressional Research Service (RL31787), updated September 14, 2006, p. 8. 
7 JFCC-NW Implementation Directive, January 20, 2005. Cited in Keith B. Alexander, 
ﬁWar˜ghting in Cyberspace,ﬂ 
Joint Force Quarterly
, July 2007, available at http://www.
military.com/forums/0,15240,143898,00.html.
8 USSTRATCOM Command Video, available at http://www.stratcom.mil/Videos/
transcripts/Command%20Video.txt.
9 Joint Publication 3-13 (2006) states that STRATCOM has responsibility for ﬁidentify
-ing desired characteristics and capabilities of CNA, conducting CNA in support of assigned 

missions, and integrating CNA capabilities in support of other combatant commanders.ﬂ 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.166
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
structure known as the Global Information Grid (GIG). The Joint Informa
-tion Operations Warfare Command, responsible for assisting combatant 
commands with an integrated approach to information operations, coor
-dinates network operations and network warfare with the JTF-GNO and 

the JFCC-NW.
10
 As of November 2008, the JTF-GNO is for the ˜rst time 
placed under the operational control of the JFCC-NW.
11
The JFCC-NW engages in a substantial amount of coordination with 
other entities. It coordinates its offensive activities directly with the defen
-sive activities of the JTF-GNO. It ﬁfacilitates cooperative engagement with 

other national entities in computer network defense and network warfare 

as part of global information operations.ﬂ
12
 Because the commander of the 
JFCC-NW is dual-hatted as the director of the National Security Agency 

(Box 3.2), the JFCC-NW can easily work with the intelligence community 

to provide intelligence support for computer network operations. In addi
-tion, coordination between cyberattack (a Title 10 function) and cyberex
-ploitation (a Title 50 function) is more easily accomplished.
Lastly, Joint Publication 3-13 also notes that 
CDRUSSTRATCOM™s speci˜c authority and responsibility to coordinate 
IO [information operations, Box 3.3] across AOR and functional boundar
-ies does not diminish the imperative for the other combatant command
-ers to coordinate, integrate, plan, execute, and employ IO. These efforts 

may be directed at achieving national or military objectives incorporated 

in TSCPs [Theater Security Cooperation Programs], shaping the opera
-tional environment for potential employment during periods of height
-ened tensions, or in support of speci˜c military operations.
Two important points are embedded in this paragraph. First, STRAT
-COM is not necessarily the only command that can actually carry out 
information operations, including computer network attack. (In some 

cases, STRATCOM will be a supporting command that provides support 

to other regional or functional commands. In other cases, it will be the 

supported command, receiving support from other regional or functional 

commands.) Second, information operations, including computer net
-work attack, may be used both in support of speci˜c military operations 

and
 during periods of ﬁheightened tensions,ﬂ that is, early use 
before
 overt 
con˚ict occurs.
10
 Clay Wilson, ﬁInformation Operations and Cyberwar,ﬂ 2006.
11
 Memo of Robert Gates (Secretary of Defense) to DOD regarding Command and Con
-trol for Military Cyberspace Missions, November 12, 2008. Copy available from the NRC.
12
 U.S. Strategic Command website, http://www.stratcom.mil/about-ch.html. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 167
BOX 3.2
 The National Security Agency-Central Security Service
Often known simply as the National Security Agency, the organization is in 
fact a combat support agency of the DOD under the authority, direction, and con
-trol of the Secretary of Defense, and is responsible for centralized coordination, 
direction, and performance of highly specialized intelligence functions in support of 

U.S. government activities. It includes both the National Security Agency and the 

Central Security Service. The NSA carries out the responsibilities of the Secretary 

of Defense to serve as executive agency for U.S. government signals intelligence 

(SIGINT), communications security, computer security, and operations security 

training activities. The CSS is composed of the Service Cryptologic Elements of the 
four uniformed services that are responsible for conducting their Title 50 SIGINT 
mission, and provides the military Services a uni˜ed cryptologic organization within 

the DOD that assures proper control of the planning, programming, budgeting, and 

expenditure of resources for cryptologic activities. Service cryptologic elements 

also perform other missions in direct support of their respective Services related 

to information operations (including computer network operations), and in doing 

so, they operate under Title 10 authority. 
The director of the National Security Agency (DIRNSA) serves as the director 
of both the National Security Agency and the Central Security Service and has 

both Title 10 and Title 50 responsibilities. As national executive agent for SIGINT, 

DIRNSA has operated with Title 50 authority and thus would be responsible for 

conducting cyberexploitations, which by de˜nition are not supposed to damage, 

degrade, or disable adversary computer systems or networks. As the party re
-sponsible for DOD information assurance, DIRNSA has operated with Title 10 

authority. Finally, in January 2005, the Joint Functional Component Command for 

Network Warfare (JFCCŒNW) was established under the U.S. Strategic Command, 

and DIRNSA was designated as its commander. As such, DIRNSA operates with 

Title 10 authority for any offensive missions (including cyberattacks) undertaken 

by the JFCC-NW. 
As this report is being written, these arrangements are in ˚ux, as the DOD 
and the intelligence community are discussing the potential standup of a cyber 

combatant command.
3.3
 RULES
 OF
 E
NGAGEMENT
In general, the rules of engagement (ROEs) for military forces specify 
the circumstances under which they may take certain kinds of action. 
(The laws of armed con˚ict place additional constraints on the permis
-sible actions of military forces.) For example, many military installations 

contain areas in which ﬁthe use of deadly force is authorizedﬂ to stop 

individuals from trespassingŠguards of such areas are authorized (but 

not required) to use any means necessary to do so. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.168
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 3.3
 Information Operations and Related Capabilities
Computer network operations are themselves part of a larger complex des
-ignated as information operations (IO) by the Joint Chiefs of Staff. These other 
elements of information operations include:
Psychological operations (PSYOP),
 which include operations to convey 
selected truthful information and indicators to foreign audiences to in˚uence their 

emotions, motives, objective reasoning, and ultimately, the behavior of their gov
-ernments, organizations, groups, and individuals. The purpose of PSYOP is to 

induce or reinforce foreign attitudes and behavior favorable to the originator™s 

objectives.
Military deception,
 which includes actions taken with the purpose of delib
-erately misleading adversary decision makers as to friendly military capabilities, 

intentions, and operations, thereby causing the adversary to take speci˜c actions 

(or inactions) that will contribute to the accomplishment of the friendly forces™ 

mission. 
Operations security (OPSEC),
 which is a process of identifying critical 
information and subsequently analyzing friendly actions and other activities to 

identify what friendly information is necessary for the adversary to have suf˜
-ciently accurate knowledge of friendly forces and intentions; deny adversary deci
-sion makers critical information about friendly forces and intentions; and cause 

adversary decision makers to misjudge the relevance of known critical friendly 

information because other information about friendly forces and intentions remains 

secure. OPSEC seeks to deny real information to an adversary and prevent correct 

deduction of friendly plans. 
Electronic warfare (EW)
 refers to any military action involving the use of 
electromagnetic (EM) and directed energy to control the EM spectrum or to at
-tack the adversary. EW includes electronic attack (EM energy, directed energy, or 

antiradiation weapons to attack personnel, facilities, or equipment with the intent 

of degrading, neutralizing, or destroying adversary combat capability), electronic 

protection (which ensures the friendly use of the EM spectrum), and electronic war
-fare support (ES, which searches for, intercepts, identi˜es, and locates or localizes 

sources of intentional and unintentional radiated EM energy for the purpose of im
-mediate threat recognition, targeting, planning, and conduct of future operations). 

ES data can be used to produce SIGINT, provide targeting for electronic or other 

forms of attack, and produce measurement and signature intelligence (MASINT). 

SIGINT and MASINT can also provide battle damage assessment (BDA) and 

feedback on the effectiveness of the overall operational plan.
In addition, a number of other capabilities support information operations in 
the DOD context, such as information assurance (IA), physical security, physical 

attack, and counterintelligence. Capabilities related to IO include public affairs (PA), 

civil-military operations (CMO), and defense support to public diplomacy. The Joint 

Chiefs of Staff note that these capabilities can also make signi˜cant contributions 

to IO but that their primary purpose and the rules under which they operate must 

not be compromised by IO.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 169
Some of the issues relevant to formulating ROEs for cyberattack might 
include:

When to execute a cyberattackŠwhat are the circumstances under 
which a cyberattack might be authorized? 

Scope of a cyberattackŠwhat are the entities that may be targeted? 

Duration of the cyberattackŠhow long should a cyberattack last?

Noti˜cationsŠwho must be informed if a cyberattack is conducted?

Authority for exceptionsŠwhat level of authority is needed to 
grant an exception for standing ROEs?
To illustrate, consider the standing rules of engagement promul
-gated by the Joint Chiefs of Staff, which state that ﬁa [U.S.] commander 
has the authority and obligation to use all necessary means available 

and to take all appropriate [i.e., necessary and proportional] actions 

to defend that commander™s unit and other U.S. forces in the vicinity 

from a hostile act or 
demonstration of hostile intent
 [emphasis added]ﬂ
13
 where ﬁhostile intentﬂ is understood to mean that another party has 

taken some action that reasonably indicates a potential for more or less 

immediate attack. 
Applying this rule to the cyber domain raises the question of actions 
that constitute a demonstration of hostile intent. For example, do non-

destructive adversary probes of important military U.S. computer systems 

and networks (or even systems and networks associated with U.S. critical 

infrastructure) constitute demonstrations of hostile intent? If so, do such 

actions justify actions beyond the taking of additional passive defense 

measures? Would a commander be permitted to conduct probes on adver
-sary networks from which these probes were emanating? To conduct a 

responsive cyberattack to neutralize the probes? 
On this speci˜c topic, Rear Admiral Betsy Hight of the Joint Task 
Force on Global Network Operations testi˜ed to the committee that the 

commander of the U.S. Strategic Command has operational authority to 

conduct cyber operations that are defensive in purpose against systems 

outside the DOD networks. The action taken in the operation may have 

an offensive characterŠthat is, it may seek to damage or disrupt a system 

that is adversely affecting a DOD asset. Self-defense is generally limited in 

scope to addressing or mitigating the immediate hostile act, and is a last 

resort. The frequency with which the U.S. Strategic Command has actu
-ally acted under this asserted authority, if at all, is unknown.
13
 Joint Chiefs of Staff, Chairman of the Joint Chiefs of Staff Instruction, CJCSI 3121.01A, 
January 15, 2000, Standing Rules of Engagement for US Forces, available at http://www.fas.
org/man/dod-101/dod/docs/cjcs_sroe.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.17
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
CND response actions (RAs) are a speci˜c subset of self-defense and 
are likewise constrained to a measured response used as a last resort. 
CND RAs can be used only in response to a network event that creates 

a threshold impact. Additional limitations constrain the scope, duration, 

and impact of the CND RA. Moreover, CND RAs, like all self-defense, is 

a tactical activity, characterized as such because it is used in response to a 

speci˜c hostile action and is designed to address and mitigate that action, 

and only that action. Offensive actions are not so limited. Both offensive 

and defensive actions must follow the law of war limitations with regard 

to differentiation of targets, military necessity, and limiting collateral 

damage, but defensive actions tend to be more limited in scope.
Such self-defense operations would be designated as a CND response 
action, authority for which is described, constrained, and granted through 

standing rules of engagement established by the National Command 

Authority and ˚owing, through the secretary of defense, from the Pres
-ident™s authority as commander-in-chief. Standing rules of engagement 

generally describe the authority commanders have to defend their per
-sonnel and designated property. According to Admiral Hight™s testimony 

to the committee, the rules of engagement for CND response actions 

also specify that they are not authorized unless the hostile action has an 

impact on the ability of a combatant commander to carry out a mission 

or an ongoing military operation, and in particular that hostile actions 

that result only in inconvenience or that appear directed at intelligence 

gathering do not rise to this threshold.
An example of a legitimate target for a CND response action would 
be a botnet controller that is directing an attack on DOD assets in cyber
-space. Thus, if bots are active in DOD networks, and if through DOD mis
-sion partners the controller of those bots can be identi˜ed in cyberspace, 

and if the botnet attack is compromising the DOD network™s ability to 

carry out its mission operationally, a CND response actionŠinvolving 

cyberattackŠcan be directed against the controller under these standing 

rules of engagement.
As for geographic scope, a hostile cyber act may emanate from any
-where in cyberspace. Accordingly, the impact of CND response actions 

directed against that source could also occur anywhere in cyberspace. 

The ease with which actors can use and misuse U.S.-based cyber assets 

for malicious purposes increases the probability that future CND response 

actions might impact that space. For this reason, the JTF-GNO maintains 

relationships with law enforcement, other federal entities, and Internet 

service providers. This ensures that if some other national asset, or the 

commercial sector, can mitigate malicious cyber activity against the DOD, 

those assets are used before resorting to CND response actions. 
The ˜nal point about this particular example is that from the DOD 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 171
perspective, the cessation of a hostile action may be more important than 
the attribution of the action to a particular actor. Accordingly, under the 
stated policy, the DOD may be willing to take many steps to ensure that 

the hostile action ceases, even if those actions have rami˜cations beyond 

U.S. borders.
3.4
 SOME
 H
ISTORICAL
 P
ERSPECTIVE
Because the number of con˜rmed and unclassi˜ed instances of 
cyberattack launched by governments, friendly or hostile, is vanishingly 

small, it is hard to cite actual experience as a basis for understanding the 

effects of cyberattack. But a number of other incidents can provide some 

insight. Although the events described are not cyberattacks themselves, 

the affected entities involved are the kinds of targets that proponents of 

cyberattack weapons often discuss when advancing the case for the value 

of such weapons. The operational effects are the kinds of effects that 

cyberattacks might seek to cause.

In December 2006, a major ˜ber optic cable providing some 50 
percent of Iran™s digital communications and Internet connections was 

damaged in Iran™s territorial waters in the Persian Gulf. A month later, 80 

percent of the damaged capability had been restored.

In late December 2006, an earthquake off the shores of Taiwan dam
-aged or destroyed eight ˜ber optic lines that connected Taiwan to other 

nations in the Paci˜c. There was some disruption to Internet and phone 

for about 2 days, and Internet connections were slow in Taiwan, Hong 

Kong, Japan, China, Singapore, and South Korea. However, although the 

cables were not repaired for almost 3 weeks, workaround restored most 

services quickly.

In February 2007, Mexico™s largest cell phone company experi
-enced a ﬁcrashﬂ that left 40 million cell phone users without service for 

most of a day.

In May 1999, the United States targeted the Belgrade electric power 
system as part of the Kosovo con˚ict, using carbon ˜bers to short genera
-tors. In all, four strikes were conducted against the power system, but in 

each case, power generation was restored within a few days to a substan
-tial fraction of what it was prior to the strike.
Perhaps the most important feature of these incidents is the fact that 
their effects were relatively transitory, largely because the parties affected 

found workarounds that enabled them to compensate for the immedi
-ate loss of capability. If these incidents had been caused deliberately, it 

is likely that repeated attacks would have been necessary to ensure that 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.172
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
the reduction of capability persisted over time. Moreover, these incidents 
were, by themselves, of little strategic signi˜cance, though if they had 
been timed to coincide with some kinetic military operation, they might 

well have had a signi˜cant impact.
At the same time, these observations do not account for possible 
impact on the psychological state of mind of relevant decision makers. 

The same major outage of service may result from a natural disaster, by a 

deliberate overt action, or by a deliberate and well-concealed actionŠbut 

decision makers are likely to care about the speci˜c cause of such an 

event. An outage caused by deliberate action is fundamentally differ
-ent from the ﬁsameﬂ outage caused by natural disaster, because the ˜rst 

carries with it the implicit threat of happening again when an adversary 

wants it to happen again. A well-concealed action attributed to a speci˜c 

party could be argued to have an even greater impact on a decision maker, 

since he might well be hard-pressed to do anything about it. 
The 2007 cyberattack on Estonia yielded similar lessons (Box 3.4). The 
attack had a variety of short-term consequences for Estonia, including the 

inability of Estonians to access online banking services and government 

services, and for individuals outside Estonia to access the Estonian web 

for a while. Less measurable impacts such as confusion and miscom
-munication were also noted.
14
 Although these impacts led press reports 
to suggest that the con˚ict was variously the ˜rst war in cyberspace,
15 
Web War I,
16
 and ﬁthe ˜rst real example of nation-states ˚exing their 
cyber-warfare capabilities,ﬂ
17
 no critical infrastructure was targeted in 
the attacks, most sites were restored to service quickly, and the primary 

operational result of the attack was inconvenience.
This is not to say that the attack was inconsequential. The incident 
did serve as a ﬁwake-up callﬂ for many other nations to inquire how they 

should respond to similar situations that might arise in the future. Dur
-ing the attack, NATO provided experts in Internet warfare to assist in the 

investigation and defense.
18
 Furthermore, in the aftermath of the attacks, 
Estonia has proposed that NATO create a Cooperative Cyber Defense 

Center of Excellence to improve NATO members™ ability to cooperate 
14 Jaak Aaviksoo, Minister of Defense of Estonia, presentation to Centre of Strategic and 
International Studies, November 28, 2007, p. 3. of transcript, available at http://www.csis.
org/component/option,com_csis_press/task,view/id,3525/.
15
 Mark Landler and John Markoff, ﬁIn Estonia, What May Be the First War in Cyber
-space,ﬂ 
International Herald Tribune
, May 28, 2007.
16
 Joshua Davis, ﬁHackers Take Down the Most Wired Country in Europe,ﬂ 
Wired
, Issue 
15.09, August 21, 2007.
17
 MacAfee Corp., ﬁCybercrime: The Next Wave,ﬂ McAfee Virtual Criminology Report, 
2007, p. 9.
18
 Economist
, ﬁA Cyber-riot,ﬂ May 10, 2007.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 173
BOX 3.4
 The Cyberattacks on Estonia and Georgia
EstoniaOn April 27, 2007, a series of distributed denial of service (DDOS) attacks 
 
began on a range of Estonian government websites, media sites, and online bank
-ing services.
1 Attacks were largely conducted using botnets to create network traf˜c. 
The duration and intensity of attacks varied across the websites attacked. According 
to data collected by Arbor Networks, the attacks were primarily Internet Control 

Message Protocol (ICMP) ˚oods with most lasting from 1 minute to 1 hour and a 

few lasting up to 10 hours. Most attacks had an intensity of 30 Mbps or less, though 

some measured up to 95 Mbps.
2 Some Estonian websites were also
 defaced by 
people claiming to be Russian hackers, and tools in the form of scripts to conduct 

attacks were offered on Russian hacker sites and chat rooms.
3 Computers running 
those scripts became packet sources, also contributing to the attacks.
4 The attacks followed the removal the previous night of a statue memorial
-izing WWII Soviet war dead from the center of the Estonian capital of Tallinn. 

They continued off and on until mid-May after peaking on May 9th, the day Russia 

commemorates Victory in Europe.
5 The attacks were started and stopped deliber
-ately by the attackers rather than being shut down through defensive measures.
6 The Estonian government was quick to claim links between those conducting the 
 attacks and the Russian government.
7 The Estonian minister of defense stated that 
the attacks were ﬁunusually well-coordinated and required resources unavailable to 
common people.ﬂ
8 He claimed this indicated involvement beyond the capabilities of 
outraged citizens, though he did not make any explicit claims about involvement by 

state actors. One expert in cyberterrorism was quoted as saying that the attacks 

bore the hallmarks of a ﬁfalse ˚agﬂ operation, used to test out defenses.
9 Russian 
of˜cials denied any involvement.
10Evidence of Russian involvement was circumstantial with no ﬁsmoking gunﬂ 
found to indicate any connection between the Russian government and the con
-duct of the attacks.
11 Hillar Aarelaid, chief security of˜cer for Estonia™s version of 
the U.S. Computer Emergency Response Team, dismissed claims that a Russian 

government link could be proven.
12 The botnets were composed of compromised 
computers from the United States, Europe, Canada, Brazil, Vietnam, and other 

countries around the world. There was evidence of Russian nationalists promoting 

the attacks through blog posts with scripts and instructions for conducting DDOS 

attacks on Estonian websites.
13 One script used in the attacks which sent ping 
˚oods to Estonian websites was shared extensively on Russian language boards.
14
 Some attackers in the earliest attacks were identi˜ed by their IP addresses as 

coming from Russia, including some from Russian state institutions.
15 An Estonian 
news site stated that a member of Nashi, a Russian youth group tied to Russian 

President Putin, claimed that the group was behind the attacks, but there was no 

corroboration of this claim.
16Continued
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.17
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX
 3.4 Continued
Georgia 
In August 2008, a military con˚ict involving land, air, and sea forces of Geor
-gia and Russia occurred in South Ossettia and Abkhazia, provinces under the 
nominal control of Georgia. Russian military action in this con˚ict was immediately 

preceded by a number of cyberattacks against a variety of websites of the Geor
-gian government.
17 These attacks defaced these websites and also made it very 
dif˜cult for the Georgian government to put out its side of the story. Cyberattacks 

against certain Georgian government Web sites reportedly continued even after 

Russia declared a cease-˜re.
In broad outline, the cyberattacks against Georgia were very similar to those 
against Estonia. As in the Estonian case, these attacks were not conclusively 

traced to the Russian government, and the Russian government denied involve
-ment.18 Various analysts argue that they were controlled by the Russian Business 
Network,
19 a business organization alleged to have criminal ties, and even private 
Russian citizens.
20The primary signi˜cance of the cyberattacks on Georgia is in their appearing 
to be the ˜rst instance of simultaneous actions involving cyberattack and kinetic 

attack, rather than in any of the particulars of the cyberattacks themselves.
1 Economist, ﬁA Cyber-riot,ﬂ May 10, 2007; Jaak Aaviksoo, Minister of Defense of Estonia 
presentation to Centre of Strategic and International Studies, November 28, 2007.
2 The most detailed measurements on the attacks are from Arbor Networks; Jose
 Nazario, 
ﬁEstonian DDoS AttacksŠA Summary to Date,ﬂ May 17, 2007, available at http://asert
.arbornetworks.com/2007/05/estonian-ddos-attacks-a-summary-to-date/. Those measurements 
also show a small percentage of the TCP SYN attacks. 
3 Some examples are available from the F-Secure weblog at http://www.f-secure.com
/weblog/archives/archive-052007.html#00001188. See also Miska Rantanen,
 ﬁVirtual Harass
-ment, But for Real,ﬂ 
Helsingin Sanomat
, May 6, 2007, available at http://www.hs.˜/english
/ article/Virtual+harassment+but+for+real+/1135227099868. 
4 Heise Security
, ﬁEstonian DDoSŠA Final Analysis,ﬂ May 31, 2007, available at http://www.
heise-security.co.uk/news/90461. This article quotes Jose Nazario from Arbor Networks. See 
also the Arbor Networks measurements cited previously. 
5 Michael Lesk, ﬁThe New Front Line: Estonia under Cyberassault,ﬂ 
IEEE Security & Privacy
 5(4):76-79, 2007.
6 MacAfee Corporation, ﬁCybercrime: The Next Wave,ﬂ 
McAfee Virtual Criminology Report, 
2007, p. 11.
7 Maria Danilova, ﬁAnti-Estonia Protests Escalate in Moscow,ﬂ 
Washington Post
, May 2, 2007, available at
 http://www.washingtonpost.com/wp-dyn/content/article/2007/05/02/
AR2007050200671_2.html. The article quotes both the Estonian president and ambassador 
to Russia as claiming Kremlin involvement. 
8 Jaak Aaviksoo, minister of defense of Estonia, in a presentation at the Centre of Strategic 
and International Studies, November 28, 2007, p. 2 of transcript, available at http://www.csis.
org/component/option,com_csis_press/task,view/id,3525/. 
9 MacAfee Corp., op. cit., p. 9. The report quotes Yael Shahar, International Institute for 
Counter-Terrorism, Israel.
10 MacAfee Corp., op. cit., p. 7.
11 E-mail from Jose Nazario of Arbor Networks, July 5, 2007. See also 
Heise Security
, ﬁEstonian DDoSŠA Final Analysis,ﬂ May 31, 2007, available at http://www.heise-security.

co.uk/news/90461.
12
 Jeremy Kirk, ﬁEstonia Recovers from Massive DDoS Attack,ﬂ 
Computerworld Securi
-ty
, May 17, 2007, available at http://www.computerworld.com/action/article.do?command= 
viewArticleBasic&articleId=9019725.
13 Jeremy Kirk, ﬁRussian Gov™t Not Behind Estonia DDOS Attacks: Analysis Throws Doubt 
on Whether a Single Agency Alone Was Involved,ﬂ 
InfoWorld
, June 1, 2007, available at http://
www.infoworld.com/article/07/06/01/Russia-not-behind-Estonia-DDOS-attacks_1.html.
14 Heise Security
, op. cit. 
15 Ian Traynor, ﬁRussia Accused of Unleashing Cyberwar to Disable Estonia,ﬂ 
Guardian, May 
17, 2007, available at http://www.guardian.co.uk/russia/article/0,,2081438,00.html. 
16 Cory Doctorow in a June 2, 2007, blog entry on Boing Boing (http://www.boingboing.
net/2007/06/02/estonia-didnt-suffer.html) cited an Estonian news article from Postimees.ee 

posted on May 29, 2007, available at http://www.postimees.ee/290507/esileht/siseuudised/ 
263405.php. See Owen Matthews and Anna Nemtsova, ﬁPutin™s Powerful Youth Guard,ﬂ 
News
-week
, May 28, 2007, for a description of Nashi and its link to President Putin and the Russian 

government.
17 ﬁGeorgia Accuses Russia of Coordinated Cyberattack,ﬂ 
CNET News
, August 11, 2008, 
available at http://news.cnet.com/8301-1009_3-10014150-83.html.
18 John Markoff, ﬁBefore the Gun˜re, Cyberattacks,ﬂ 
New York Times
, August 13, 2008, avail
-able at http://www.nytimes.com/2008/08/13/technology/13cyber.html?fta=y. 
19 Gregg Keizer, ﬁCyberattacks Knock Out Georgia™s Internet Presence,ﬂ 
Computerworld
, August 11, 2008, available at http://www.computerworld.com/action/article.do?command= 
viewArticleBasic&articleId=9112201.
20
 Byron Acohido, ﬁSome Russian PCs Used to Cyberattack Georgia,ﬂ 
USA Today
, August 17, 2008, available at http://www.usatoday.com/tech/news/computersecurity/ 

hacking/2008-08-17-russia-georgia-war-hackers_N.htm.
in operational situations and to develop a doctrine for responding to 
cyberattacks.
19
 Data on and analysis of the attacks have been provided to 
NATO members to inform efforts aimed at better defending against such 
19 Jaak Aaviksoo, Minister of Defense of Estonia, presentation to Centre of Strategic and 
International Studies, November 28, 2007, p. 7. of transcript, available at http://www.csis.
org/component/option,com_csis_press/task,view/id,3525/.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 175
BOX
 3.4 Continued
Georgia 
In August 2008, a military con˚ict involving land, air, and sea forces of Geor
-gia and Russia occurred in South Ossettia and Abkhazia, provinces under the 
nominal control of Georgia. Russian military action in this con˚ict was immediately 

preceded by a number of cyberattacks against a variety of websites of the Geor
-gian government.
17 These attacks defaced these websites and also made it very 
dif˜cult for the Georgian government to put out its side of the story. Cyberattacks 

against certain Georgian government Web sites reportedly continued even after 

Russia declared a cease-˜re.
In broad outline, the cyberattacks against Georgia were very similar to those 
against Estonia. As in the Estonian case, these attacks were not conclusively 

traced to the Russian government, and the Russian government denied involve
-ment.18 Various analysts argue that they were controlled by the Russian Business 
Network,
19 a business organization alleged to have criminal ties, and even private 
Russian citizens.
20The primary signi˜cance of the cyberattacks on Georgia is in their appearing 
to be the ˜rst instance of simultaneous actions involving cyberattack and kinetic 

attack, rather than in any of the particulars of the cyberattacks themselves.
1 Economist, ﬁA Cyber-riot,ﬂ May 10, 2007; Jaak Aaviksoo, Minister of Defense of Estonia 
presentation to Centre of Strategic and International Studies, November 28, 2007.
2 The most detailed measurements on the attacks are from Arbor Networks; Jose
 Nazario, 
ﬁEstonian DDoS AttacksŠA Summary to Date,ﬂ May 17, 2007, available at http://asert
.arbornetworks.com/2007/05/estonian-ddos-attacks-a-summary-to-date/. Those measurements 
also show a small percentage of the TCP SYN attacks. 
3 Some examples are available from the F-Secure weblog at http://www.f-secure.com
/weblog/archives/archive-052007.html#00001188. See also Miska Rantanen,
 ﬁVirtual Harass
-ment, But for Real,ﬂ 
Helsingin Sanomat
, May 6, 2007, available at http://www.hs.˜/english
/ article/Virtual+harassment+but+for+real+/1135227099868. 
4 Heise Security
, ﬁEstonian DDoSŠA Final Analysis,ﬂ May 31, 2007, available at http://www.
heise-security.co.uk/news/90461. This article quotes Jose Nazario from Arbor Networks. See 
also the Arbor Networks measurements cited previously. 
5 Michael Lesk, ﬁThe New Front Line: Estonia under Cyberassault,ﬂ 
IEEE Security & Privacy
 5(4):76-79, 2007.
6 MacAfee Corporation, ﬁCybercrime: The Next Wave,ﬂ 
McAfee Virtual Criminology Report, 
2007, p. 11.
7 Maria Danilova, ﬁAnti-Estonia Protests Escalate in Moscow,ﬂ 
Washington Post
, May 2, 2007, available at
 http://www.washingtonpost.com/wp-dyn/content/article/2007/05/02/
AR2007050200671_2.html. The article quotes both the Estonian president and ambassador 
to Russia as claiming Kremlin involvement. 
8 Jaak Aaviksoo, minister of defense of Estonia, in a presentation at the Centre of Strategic 
and International Studies, November 28, 2007, p. 2 of transcript, available at http://www.csis.
org/component/option,com_csis_press/task,view/id,3525/. 
9 MacAfee Corp., op. cit., p. 9. The report quotes Yael Shahar, International Institute for 
Counter-Terrorism, Israel.
10 MacAfee Corp., op. cit., p. 7.
11 E-mail from Jose Nazario of Arbor Networks, July 5, 2007. See also 
Heise Security
, ﬁEstonian DDoSŠA Final Analysis,ﬂ May 31, 2007, available at http://www.heise-security.

co.uk/news/90461.
12
 Jeremy Kirk, ﬁEstonia Recovers from Massive DDoS Attack,ﬂ 
Computerworld Securi
-ty
, May 17, 2007, available at http://www.computerworld.com/action/article.do?command= 
viewArticleBasic&articleId=9019725.
13 Jeremy Kirk, ﬁRussian Gov™t Not Behind Estonia DDOS Attacks: Analysis Throws Doubt 
on Whether a Single Agency Alone Was Involved,ﬂ 
InfoWorld
, June 1, 2007, available at http://
www.infoworld.com/article/07/06/01/Russia-not-behind-Estonia-DDOS-attacks_1.html.
14 Heise Security
, op. cit. 
15 Ian Traynor, ﬁRussia Accused of Unleashing Cyberwar to Disable Estonia,ﬂ 
Guardian, May 
17, 2007, available at http://www.guardian.co.uk/russia/article/0,,2081438,00.html. 
16 Cory Doctorow in a June 2, 2007, blog entry on Boing Boing (http://www.boingboing.
net/2007/06/02/estonia-didnt-suffer.html) cited an Estonian news article from Postimees.ee 

posted on May 29, 2007, available at http://www.postimees.ee/290507/esileht/siseuudised/ 
263405.php. See Owen Matthews and Anna Nemtsova, ﬁPutin™s Powerful Youth Guard,ﬂ 
News
-week
, May 28, 2007, for a description of Nashi and its link to President Putin and the Russian 

government.
17 ﬁGeorgia Accuses Russia of Coordinated Cyberattack,ﬂ 
CNET News
, August 11, 2008, 
available at http://news.cnet.com/8301-1009_3-10014150-83.html.
18 John Markoff, ﬁBefore the Gun˜re, Cyberattacks,ﬂ 
New York Times
, August 13, 2008, avail
-able at http://www.nytimes.com/2008/08/13/technology/13cyber.html?fta=y. 
19 Gregg Keizer, ﬁCyberattacks Knock Out Georgia™s Internet Presence,ﬂ 
Computerworld
, August 11, 2008, available at http://www.computerworld.com/action/article.do?command= 
viewArticleBasic&articleId=9112201.
20
 Byron Acohido, ﬁSome Russian PCs Used to Cyberattack Georgia,ﬂ 
USA Today
, August 17, 2008, available at http://www.usatoday.com/tech/news/computersecurity/ 

hacking/2008-08-17-russia-georgia-war-hackers_N.htm.
attacks.
20
 From a legal and policy standpoint, the attack raised questions 
about whether such an attack constituted an armed attack in the sense 
intended by the UN Charter and whether cyberattacks against a member 

nation ought to be included in the provisions of Article V of the North 
20
 MacAfee Corporation, ﬁCybercrime: The Next Wave,ﬂ 
McAfee Virtual Criminology 
Report
, 2007, p. 11.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.176
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Atlantic Treaty which provides for collective self-defense if any member 
is attacked.
21
A second set of issues appears to have emerged from the U.S. experi
-ence more generally with information operations in the Kosovo con˚ict. 
Analysts and decision makers considered using information operations, 

including computer network attack, as part of an integrated campaign 

against certain targets in Kosovo. However, in practice, options such as 

computer network attack proved harder to use than expected, in part 

because of the dif˜culties in obtaining the necessary approvals and autho
-rizations to use them. In some cases, the approval process took so long 

that the utility of the operation had passed, at least in part because the 

execution of a particular option had many unknowns about likely effects. 

In other cases, it would have been relatively straightforward for the 

adversary to counter the use of such an option. The summary assessment 

of a senior military of˜cer regarding information operations in Operation 

Allied ForceŠﬁa big wind-up to an underhand throw.ﬂ
Of course, the past may not be the best predictor of the future, espe
-cially when Allied forces are just starting to explore the possibilities and 

limitations of information operations, and in particular where decision-

making processes have not yet fully accommodated the need to account 

for information operations. These observations are offered only to suggest 

that initial predictions of easy application are not likely to be realized.
The past decade has also seen a number of shifts in doctrinal perspec
-tive. For example, in 1998 the DOD publication JP3-13, 
Joint Doctrine for 
Information Operations, 
made reference to offensive and defensive infor
-mation operations, as well as to ﬁinformation warfare.ﬂ The 2006 revision 

of JP3-13, 
Information Operations, 
discontinued the terms ﬁoffensive IOﬂ 
and ﬁdefensive IOﬂ but retained the recognition that information opera
-tions can be applied to achieve both offensive and defensive objectives, 

and it eliminated the term ﬁinformation warfareﬂ from joint IO doctrine. 

Furthermore, it de˜ned ˜ve core capabilities for information operations 

(electronic warfare, computer network operations, psychological opera
-tions, operations security, and military deception) and their associated 

supporting and related capabilities. Lastly, it established the core IO capa
-bility of computer network operations, integrating computer network 

attack, computer network defense, and computer network exploitation 

under one umbrella.
21
 Ian Traynor, ﬁRussia Accused of Unleashing Cyberwar to Disable Estonia,ﬂ 
Guardian, 
May 17, 2007, available at http://www.guardian.co.uk/russia/article/0,,2081438,00.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 177
3.5
 CYBERATTACK
 IN
 S
UPPORT
 OF
 M
ILITARY
 O
PERATIONS
ŠSOME
 H
YPOTHETICAL
 E
XAMPLES
What are some of the applications of cyberattack? It is helpful to 
consider several broad categories separately. Cyberattack can support 
information operations within the information operations sphere and also 

other military operations. In addition, cyberattack can be applied to mis
-sions that are not traditionally within the military domain. 
3.5.1
 Cyberattack in Support of Defense, Exploitation, and 
 Other Information Operations
As noted above, cyberattack can be used defensively to eliminate a 
threat to DOD systems or networks (an application of computer network 

defense). For example, the DOD might use a botnet to launch a DDOS 

counterattack to disable the computers from which a threat to DOD sys
-tems originates.
22
 In support of CNE, a cyberattack could be used to dis
-able security software so that a cyberexploitation could insert monitoring 

software (e.g., key loggers) on adversary computers or networks.
Cyberattack can also be used to support other non-computer IOs. For 
example:

Psychological operations
. A cyberattack could be used to generate 
frequent e-mail messages or telephone calls to speci˜c adversary deci
-sion makers. The frequency of such e-mail messages or phone calls could 

disrupt their work environments, making it dif˜cult for them to work 

there. And the content of such e-mail messages could include threats such 

as ﬁyour building is going to be bombed in 30 minutes; it is a good idea 

if you leaveﬂ or ﬁwe know where your lover™s safe house is.ﬂ
23
 Another 
PSYOP application might call for the launching of a small but very visible 
22
 The notion that the United States would actually do soŠuse a botnet in such a 
 mannerŠis speculative, but such speculation has been seen from senior military lawyers, 
such as the staff judge advocate for the Air Force Intelligence, Surveillance and Reconnais
-sance Agency. See Charles W. Williamson III, ﬁCarpet Bombing in Cyberspace: Why America 
Needs a Military Botnet,ﬂ 
Armed Forces Journal International,
 May 2008, available at http://
www.armedforcesjournal.com/2008/05/3375884.
23
Air Force Doctrine Document 
2-5 (issued by the Secretary of the Air Force, January 11, 
2005) explicitly notes that ﬁpsychological operations can be performed using network attack 

[de˜ned as employment of network-based capabilities to destroy, disrupt, corrupt, or usurp 

information resident in or transiting through networks] to target and disseminate selected 

information to target audiences.ﬂ See http://www.herbb.hanscom.af.mil/tbbs/R1528/AF_

Doctrine_Doc_2_5_Jan_11_2005.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.178
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
cyberattack and then announcing it to an adversary in order to undermine 
the adversary™s con˜dence in its essential systems.
24

Operations security
. Cyberattacks could be used to target speci˜c 
adversary sensor systems that are intended to report on information 
related to the location of friendly forces. For example, an adversary may 

have compromised a computer system on a DOD network that has access 

to information related to troop movements. An attack on that computer 

could render it inoperative, but it might be more useful to feed it incor
-rect information about troop movements knowing that such information 

might be highly trusted by the adversary.

Military deception
.25
 Cyberattacks could be used to gain access to 
an adversary computer system in its command and control structure. 

By assuming control of a computer used by a senior intelligence analyst, 

for example, bogus e-mail traf˜c could be sent to that analyst™s custom
-ers. The contents of these e-mails could easily provide misinformation 

regarding the military capabilities, intentions, locations, and operations 

of friendly forces. Moreover, responding e-mails back to the analyst could 

be intercepted and appropriately modi˜ed before being displayed to the 

analyst.

Electronic warfare
. Cyberattacks could be used to disable an adver
-sary™s software-de˜ned radios, thus preventing enemy wireless battle˜eld 

communications (which is often a goal of EW). In addition, EW could sup
-port cyberattacks. For example, to the extent that adversary computer sys
-tems are connected through wireless links, EW might be used to jam those 

links in order to disrupt the wireless networkŠthat is, jamming would be 

a denial-of-service cyberattack against the network in question.
Cyberattack can also be used to support related missions, such as 
propaganda. Here is one possible example: 

Ruritania and Zendia are adversaries. Ruritania penetrates a 
Zendian GIS system focused on Armpitia, a Ruritarian ally, to alter maps 

and targeting databases. An Armpitian building containing a day-care 

center is marked as a munitions bunker, a historic cathedral as a troop 

barracks, and the embassy of a neutral nation as a branch of the ally™s 
24
 Defense Science Board, ﬁReport of the Defense Science Board Task Force on Mission 
Impact of Foreign In˚uence on DoD Software,ﬂ U.S. Department of Defense, September 
2007, p. 22.
25
 Air Force Doctrine Document 2-5 (issued by the secretary of the Air Force, Janu
-ary 11, 2005) explicitly notes that ﬁnetwork attack may support deception operations against 

an adversary by deleting or distorting information stored on, processed by, or transmitted 

by network devices.ﬂ Available at http://www.herbb.hanscom.af.mil/tbbs/R1528/AF_
 Doctrine_Doc_2_5_Jan_11_2005.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 179
ministry of defense. When Zendia launches an attack on Armpitia using 
cruise missiles, it destroys the embassy and the church, and kills dozens 
of children. CNN shows the evidence of the war crimes to the world. 

Public opinion swings against Zendia, war crime charges are ˜led at the 

Hague, and Zendian planners lose con˜dence in their standoff weapon 

systems.
Another example is the use of botnets to send spam e-mail carry
-ing propaganda messages to an entire population. One related instance 

occurred in 2000, when a virus was used to spread information regarding 

a speci˜c ethnically based incident or community in Sri Lanka.
26
 3.5.2
 Cyberattack in Support of Traditional Military Operations
Cyberattacks could also be used in connection with a variety of 
traditional military operations. Five illustrative examples are provided 

below:

Disruption of ad
versary command, control, and communications.
 Such 
disruption could involve denial of service (so that those links are unus
-able) or spoo˜ng or impersonation of legitimate authorities (so that infor
-mation received by one party is not the information sent by the originat
-ing party). Tactical C2 networks and/or links between the adversary 

national command authority and forces in the ˜eld could be disrupted. 

Adversary planning (e.g., for military actions against U.S. forces) could 

be disrupted or altered clandestinely.

Suppression of ad
versary air defenses.
 A networked air defense system 
that can pass data from forward-deployed sensors to air defense forces 

in the rear is much more effective than one without such coordination 

available. Disruption of such communications links can degrade the per
-formance of the overall system considerably. It is also possible to imagine 

that long before any attack took place, an air defense radar delivered to an 

adversary might be clandestinely programmed to ignore certain radar sig
-natures, namely those associated with airplanes friendly to the attacker, 

but only during certain times of day. From the adversary™s perspective, 

the radar would appear to be working properly, as it would detect most 

airplanes most of the time. But the attacker would know the proper win
-dow to attack so that its airplanes would be ignored.

Degradation of ad
versary smart munitions and platforms (example 
1).
 Platforms (e.g., airplanes) and munitions (e.g., missiles) are increasingly 
26
 Second Incident of Cyber-Terrorism in Sri Lanka, available at http://www.lankaweb.
com/news/items01/210501-2.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.18
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
controlled by microelectronics, and such platforms may be sold or made 
available to other parties (e.g., friendly nations or insurgent groups). But 
there may be no assurances that these items will not ever be used against 

U.S. forces. To guard against this possibility, the electronics of such sys
-tems could be programmed to self-destruct if a ﬁstay-aliveﬂ code were not 

entered after a ˜xed period of time, or if the hardware saw a particular 

bit stream on a communications bus or in memory. The ﬁself-destructﬂ bit 

stream could, in principle, be transmitted by U.S. forces confronted with 

these platforms or munitions.

Degradation of ad
versary smart munitions and platforms (example 
2).
 Zendia acquires smart weapons using GPS chips made in a factory in 

a country friendly to the United States. Unbeknownst to Zendia, the 

GPS chips have circuitry such that if they are given coordinates within 

the borders of the United States or its allies, they actually translate the 

coordinates in a random direction to 2 times the damage radius that the 

United States has calculated for the weapons in use. The weapons test ˜ne 

for Zendia on all ranges, and work ˜ne when they are used in a skirmish 

against a neighbor. However, in any engagement with an U.S. ally, the 

weapons consistently fail to hit targets, and there is no adjustment pos
-sible because of the random nature of the translation.

Attacking ad
versary war˚ghting or warmaking infrastructure
 (the 
adversary defense industrial base). A cyberattack might be used to gain 

access to a factory producing electric motors for military vehicles. (The 

factory in question is poorly managed and produces motors only for 

military use.) With a few commands, the factory is redirected to produce 

motors using materials that are badly suited for the demands of heavy 

military use. Such motors work for a short time, but by the time the prob
-lem is discovered, many such motors have been shipped and installed in 

the adversary™s military vehicles.
3.5.3
 Cyberattack in Support of Other Operations
Cyberattack can support a variety of other operations as well, though 
these are not in the category of what are traditionally undertaken by mili
-tary forces. Illustrative cyberattacks against terrorist groups or interna
-tional organized crime are described in Chapter 4, on the intelligence com
-munity; illustrative cyberattacks to support cyberexploitation on domestic 

criminals are described in Chapter 5, on domestic law enforcement.
However, an important point to note is that irrespective of whether 
the intelligence community or domestic law enforcement agencies ˜nd it 

useful and appropriate to conduct cyberattacks against some adversary, 

it may well be that the U.S. military is the only U.S. government agency 

with the technical capacity to launch appropriately focused cyberattacks 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 181
of signi˜cance. Thus, if U.S. military assets and personnel are needed for 
such purposes, appropriate interagency understandings would have to be 
reachedŠand necessary legal authorities obtainedŠto allow the DOD to 

execute cyberattacks on behalf of any of these other agencies.
For illustrative purposes only, the examples below describe how 
cyberattack might be used in support of non-military objectives:

The leader of an adversary nation controls signi˜cant military 
forces, presides over signi˜cant human rights violations in his coun
-try, and enriches himself at public expense. A cyberattack could be one 

approach to threatening the leader™s personal ˜nancial assets. The exis
-tence of such a personal threat might be useful in in˚uencing the leader 

to stand down his military forces when peacekeeping forces arrive.

Cyberattack might be an element of a strategic communications 
effort with the population of a nation. Just as radio has been used as a 

medium through which the United States has been able to provide infor
-mation un˜ltered by the governments of nations of interest (e.g., Radio 

Free Europe), the Internet is such a medium today and for the future. 

However, since nations have been known to seek to block information 

˚ows that they regard as unfriendly, U.S. cyberattacks might be used to 

help residents of these nations circumvent or avoid these various blocking 

mechanisms.

Cyberattack might be an element of a strategic communications 
effort against an adversary. For example, some terrorist groups are known 

to use the World Wide Web for recruiting purposes and the Internet for 

communications. Cyberattacks might be used to compromise recruiting 

websites or servers known to be used by terrorists. Another scenario 

relates to a kinetic attack on a nation that is accompanied by a cyberat
-tack against that nation™s government and media websites. Such an attack 

might be used to inhibit that nation™s ability to tell the world its side of the 

story,
27
 or perhaps even to assume control of those websites and provide 
the world (and its own citizens) with information more favorable to the 

attacker™s position.
It must be emphasized that the scenarios described above are not 
endorsed by the committee as being desirable applicationsŠonly that 
27
 According to press reports, a cyberattack on Georgian government websites was 
launched (perhaps by the Russian government, perhaps by private parties sympathetic to 
the Russian attack) to coincide with the August 2008 Russian attack on South Ossetia, which 

had the effect of limiting the Georgian government™s ability to spread its message online and 

to connect with sympathizers around the world during the ˜ghting with Russia. See John 

Markoff, ﬁBefore the Gun˜re, Cyberattacks,ﬂ 
New York Times
, August 13, 2008, available at 
http://www.nytimes.com/2008/08/13/technology/13cyber.html?_r=1&oref=slogin.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.182
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
they represent kinds of scenarios that arise naturally in discussions about 
cyberattack in pursuit of large-scale strategic interests. As an illustration 
of a potential problem with such scenarios, consider that manipulation 

of the information on the websites of an adversary nation™s government 

might affect the information received by U.S. citizens (e.g., through news 

media receiving altered or manipulated information from those sources 

and broadcasting that information in the United States). To the extent that 

the altered or manipulated information was untrue, the U.S. government 

might be explicitly responsible for misleading the publicŠan action that 

could negatively affect the free speech rights of U.S. citizens.
3.6
 OPERATIONAL
 P
LANNING
Operational planning processes for cyberattack are not known pub
-licly. But given the similarities of Air Force doctrine for air operations 

and the cyber missions laid out in Section 3.1, it is not unreasonable to 

suggest one notional planning process for cyberattack that is roughly par
-allel to the process for planning offensive air operationsŠspeci˜cally the 

development of the air tasking order (ATO) that speci˜es at a high level 

of detail the actions of air assets in a speci˜c con˚ict for a speci˜c period 

of time (usually, 24 hours). The development of a notional cyberattack 

tasking order (CTO) might entail the following steps.

The starting point is the explication of a commander™s objectives 
and guidance, and his vision of what constitutes military success. The 

intent of the operation is de˜ned, and priorities are set. The commander™s 

intent drives the development of targeting priorities and the appropriate 

rules of engagement. For example, the commander would determine if 

the intent of the cyberattack is to create widespread chaos or very speci˜c 

targeted damage. 

The next step is target development. Subject to requirements 
imposed by the law of armed con˚ict and the rules of engagement, targets 

are nominated to support the targeting objectives and priorities provided 

by the commander. Targets are selected from a variety of sources, includ
-ing requests from the ˜eld, reconnaissance, and intelligence recommenda
-tions. Target development often begins before hostilities begin, and the 

end product of target development is a prioritized list of targets. Legal 

issues enter here regarding whether a proposed target is indeed a valid 

and legitimate military target (the necessity requirement discussed in 

Chapter 7).

Then comes weaponeering assessment. In these phases, the target 
list is matched to the appropriate types of weapons in the inventory, 

taking into account the expected results of using weapons on these tar
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 183
gets. Knowledge of munition effectiveness is thus an essential aspect of 
weaponeering. Legal issues enter here regarding whether the military 
value of destroying the target outweighs the collateral damage that might 

occur during the attack (the proportionality requirement, discussed in 

Chapter 7).

Force execution refers to the actual execution of the various forces 
allocated to servicing the targets on the target list, and is the phase in 

which all elements of the operation are integrated to gain maximum 

effect. A cyberattack tasking order could support other combat operations 

and other combat operations could support cyber operations which could 

be their principal role. Decon˚iction (i.e., coordination of forces to ensure 

that they do not interfere with each other) is part of force execution. For 

a cyberattack, two phases of execution may be required. An initial phase 

may introduce a vulnerability that can be exploited later, though if an 

exploitable vulnerability already exists, this phase may not be necessary. 

A later phase (perhaps much later) involves the actual exploitation of the 

vulnerability to cause the damage desired.

Combat assessment evaluates the effectiveness of combat opera
-tions against the commander™s objectives. Combat assessment includes 

battle damage assessment and recommendations for reattack, and it pro
-vides the inputs for the next iteration of the cyberattack tasking order.
Another notional process for operational planning of cyberattack 
might be similar to that used to develop the Single Integrated Operating 

Plan (SIOP) for using nuclear weapons.
28
 It is publicly known that the 
SIOP contains a variety of options from which the President may select 

should he decide that nuclear weapons should be used. These options 

fall into categories such as ﬁMajor Attack Options,ﬂ ﬁSelected Attack 

Options,ﬂ ﬁLimited Attack Options,ﬂ ﬁDemonstration Use,ﬂ and so on. 

Any given option consists of a list of targets, a timetable on which the 

targets are to be attacked, and the nuclear weapons systems that are to be 

used in the attack on those targets.
Translated into the cyberattack domain, a cyber-SIOP could similarly 
include a list of targets, a timetable on which the targets are to be attacked, 

and the cyberweapons that are to be used in the attack on those targets. 

Large-scale attack options might involve large attacks intended to create 

far-reaching effects, while small-scale options might be narrowly tailored 

to address a particular target set. Depending on the rules of engagement 

and the authorizations needed to execute such a plan, either STRATCOM 
28
 The name of the strategic nuclear response plan was changed to OPLAN 8044 in early 
2003. The SIOP terminology is retained here because it is less cumbersome than OPLAN 
8044.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.18
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
or the geographic combatant command could carry out any one of these 
options, though it is likely that STRATCOM is largely responsible for 
planning regional attack options as well as attack options relevant to the 

entire globe.
A major difference between a cyber-SIOP and a nuclear response 
plan is the possibility of rapid changes in defensive postures for cyber 

targets. Many of the targets in any nuclear response plan would be ˜xed 

in location, with no defensive measures in place. To the extent that cyber 

targets might change their defensive postures in ways unknown to a 

cyberattacker, they are more analogous to targeting mobile assets in the 

nuclear response planŠand targeting of mobile assets is known to be an 

extraordinarily challenging task. The operational implication of a cyber-

SIOP is that a static planning process is unlikely to be effective, and both 

intelligence gathering and attack planning on possible targets in the vari
-ous attack options would have to be done on a frequent if not continuous 

basis.
3.7
 HUMAN
 C
APITAL
 AND
 R
ESOURCES
As the U.S. armed forces become more involved with offensive cyber 
operations, it becomes more important to have a professional military 

corps that is actively engaged in thinking about how best to use the new 

capabilities associated with cyberattack. 
From an operational perspective, the complexity and scope of cyber
-attack suggest that the mix of skills needed to operate successfully is quite 

broad. Moreover, the necessary skills are not limited to the traditional 

military specializations of operations, intelligence, and communicationsŠ

necessary specialized knowledge and information may be needed from 

the private sector or from other government agencies (e.g., the State 

Department or Department of Commerce or the Of˜ce of the U.S. Trade 

Representative). 
Thus, the operational planning process must include some ways of 
making such expertise available to military planners and decision mak
-ers. Note also that a distributed planning process is also more logistically 

cumbersome than one in which all the individuals with relevant expertise 

are available in one location (and are in the same time zone).
Another problem regarding the specialized expertise brought to bear 
in operational planning is the highly classi˜ed nature of cyberattack. 

With such classi˜cation practices in widespread use, it becomes dif˜cult 

to gain broad exposure to the techniques and the operational implications 

of employing those techniquesŠand thus the available expertise is more 

restricted than it would otherwise be.
Yet another issue is that, as noted in Chapter 2, the success of a cyber
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 185
attack may well depend on the availability of skilled operators who can 
think ﬁon the ˚yﬂ and adapt an attack in progress to circumvent unex
-pected defenses and unanticipated problems. This fact has many implica
-tions for training and suggests the importance of focusing on developing 
cyberattack skills to a very high level of pro˜ciency in a few individuals 

in addition to developing basic skills in a large number of individuals.
Today, cyberattack operators do not have their own specialization, 
and they are often typically drawn from those in the intelligence and 

communications career tracks. (In other cases, they are drawn from com
-bat specializations that do not nurture any particular expertise relevant 

to cyberattack at all.) In the long run, the increasing skill requirements 

described above for conducting successful cyberattacks suggest a need 

for specialization comparable to the more traditional combat specializa
-tions for personnel. Such specializationŠlikely in operations rather than 

intelligence or communicationsŠwould provide training and education 

that integrates the relevant skills from all of the relevant disciplines. It 

would also provide upward mobility and well-de˜ned career paths with 

opportunities for multiple promotions and senior leadership.
Lastly, the Department of Defense invests heavily in realistic training 
and exercises for personnel with traditional military specializations. Train
-ing and exercises go far beyond developing individual competence and 

expertise in combatŠthey are proving grounds for new tactical concepts 

and provide insight into how groups of people (i.e., units) can function 

effectively as a team. Today, traditional military exercises may include a 

cyber component, but often the cyber component is not prominent in the 

exercise and only a relatively small fraction of the exercise involves cyber 

activities.
The investment in training and exercises for cyberattack and cyber
-con˚ict is far below that which is allocated to training for combat in tra
-ditional domains. However, not enough is known to determine if the cur
-rent investment is adequate (that is, if it properly re˚ects the importance 

and scale of cyber operations in the future) or inadequate (as might be 

the case if institutional pressures and prejudices gave short shrift to this 

type of combat). As this report was going to press, Secretary of Defense 

Robert Gates announced that in order to improve cyberspace capabilities, 

the DOD will seek to increase the number of cyber experts that the depart
-ment can train from 80 students per year to 250 per year by FY 2011.
29
29
 ﬁGates Unveils Overhaul of Weapons Priorities,ﬂ 
Wall Street Journal, 
April 6, 2009, avail
-able at http://online.wsj.com/article/SB123904207376593845.html?mod=googlenews_wsj.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.186
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
3.8
 WEAPONS
 SYSTEMS
 AC
QUISITION
The acquisition of weapons is one of the prime responsibilities of the 
military services. To illustrate some service desires for cyberweaponry:

The Air Force is seeking to acquire a Cyber Control System (CCS) 
to provide command and control for the Air Force portion of the DOD 
Global Information Grid (GIG). The CCS is intended to enable active 

defense operations ﬁby providing GIG situational awareness along with 

both automated responses (based on pre-de˜ned Rules of Engagement) 

and recommended Courses of Action (COA) in response to network 

intrusions/attacks.ﬂ The CCS is also intended to enable network attack 

operations.
30

The Air Force is supporting the Dominant Cyber Offensive Engage
-ment problem, which is intended to develop capabilities for gaining access 

to any remotely located open or closed computer information systems; 

obtaining full control of a network for the purposes of information gath
-ering and effects-based operation; and maintaining an active stealthy but 

persistent presence within the adversaries™ information infrastructure.
31
 
The U.S. Air Force has noted a need for new technologies to sup
-port network attack (network-based capabilities to destroy, disrupt, cor
-rupt, or usurp information resident in or transiting through networks), 

network defense (network-based capabilities to defend friendly informa
-tion resident in or transiting through networks against adversary efforts 

to destroy, disrupt, corrupt, or usurp it), and network warfare support 

(actions tasked by or under direct control of an operational commander 

to search for, intercept, identify, and locate or localize sources of access 

and vulnerability for the purpose of immediate threat recognition, target
-ing, planning, and conduct of future operations such as network attack).
32
 Some of these speci˜c needs are described in Box 3.5.

The Army has issued a broad agency announcement seeking tech
-nologies for network disruption using ﬁsubtle, less obvious methodology 
30 
See http://www.fbo.gov/spg/USAF/AFMC/ESC/R1739/SynopsisP.html.
31
 FUNDING OPPORTUNITY NUMBER: BAA 08-04-RIKA, https://www.fbo.gov/
index?s=opportunity&mode=form&id=b34f1f48d3ed2ce781f85d28f700a870&tab=core&_
cview=0&cck=1&au=&ck=.
32
 Broad Agency Announcement (BAA ESC 07-0001), OL-AA 950 ELSG/KIS, Network 
Warfare Operations Capabilities (NWOC), Technology Concept Demonstrations, available at 

http://www.herbb.hanscom.af.mil/tbbs/R1528/Final_NWOC_BAA_Amend_5.doc.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.A MILITARY PERSPECTIVE ON CY
BERATTACK
 187
that disguises the technique used and protecting the ability whenever 
possible to permit future use.ﬂ
33
Acquisition policy in general terms is addressed in Chapter 6.
33
 Army Offensive Information Operations Technologies Broad Agency An
-nouncement, May 3, 2007, available at https://abop.monmouth.army.mil/baas.nsf/
Solicitation+By+Number/9BE5D8EAE22A6339852572D4004F0DD5/$File/BAA+Army+

Offensive+Information+Operations+Technologies.doc.
BOX 3.5
 Illustrative U.S. Air Force 
 Technology Needs for Cyberattack
A broad agency announcement from the U.S. Air Force calls for proposals 
to develop the following technologies for network attack, network defense, and 

network warfare support.
1 Some of the technologies sought include:
Mapping of networks (both data and voice);
Access to networks;
Denial of service on current and future operating systems and network 
devices;
Data manipulation;
Technologies/concepts for developing capabilities for IO modeling and 
simulation;
Situational awareness that gives the operator near real-time effectiveness 
feedback in a form that is readily observed by the operator;
Technologies/concepts for developing capabilities to assess and visualize 
non-kinetic effects;
Technologies/capabilities/concepts for generating and distributing dynam
-ic electronic target folders to include non-kinetic courses of action (COAs);
Processing of multi-level security information; and
Technologies/concepts for developing capabilities to support rapid imple
-mentation of effects-based capabilities.
1  
Broad Agency Announcement (BAA ESC 07-0001), OL-AA 950 ELSG/KIS, Network 
Warfare Operations Capabilities (NWOC), Technology Concept Demonstrations, available at 
http://www.herbb.hanscom.af.mil/tbbs/R1528/Final_NWOC_BAA_Amend_5.doc.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.4An Intelligence Community Perspective 
on Cyberattack and Cyberexploitation 
The intelligence community™s primary role relates to the process of 
generating ˜nished intelligence from raw information for policy makers 
to use in decision making and action regarding national security and 

foreign policy. In addition, as a matter of policy and in accordance with 

legislation and executive order, the Central Intelligence Agency has an 

operational role in undertaking covert action intended to in˚uence events 

abroad. 
The reader should keep in mind that this chapter is necessarily less 
complete than the discussion of Chapter 3 since much less is known pub
-licly about the intelligence community™s thinking about cyberattack and 

cyberexploitation. Furthermore, all of the scenarios described below are 

entirely hypothetical.
4.1
 INTELLIGENCE
 C
OLLECTION
 AND
 A
NALYSIS
4.1.1
 Governing Principles
In the domain of national security, intelligence is useful for both tacti
-cal and strategic purposes. Tactical intelligence is useful to the military 

services, because it provides advantages on the battle˜eld against adver
-sary forces through direct support to operational commanders in areas 

such as reconnaissance, mapping, and early warning of adversary force 

movements or other actions. Tactical intelligence is also necessary for 

counterterrorism efforts that seek to preempt or disrupt terrorist activi
-188
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.AN INTELLIGENCE COMMUNITY PERSPECTIVE
 189
ties before they occur. Intelligence for strategic purposes (national intel
-ligence) serves foreign policy, national security, and national economic 
objectives. National intelligence focuses on foreign political and economic 

events and trends; strategic military concerns such as plans, doctrine, 

and scienti˜c and technical resources; weapons system capabilities; and 

nuclear program development.
The intelligence-generation process, usually described as a cycle, has 
several steps. It begins with 
planning and direction
, which identi˜es deci
-sion-maker needs for information about a potential adversary (or perhaps 

even a friendly party). These needs constitute the basis for information 

collection
 requirements, which specify the scope and nature of the raw 
information that may be needed in analysis. As a rule, information can 

be collected from many sources, including open sources such as foreign 

broadcasts, newspapers, periodicals, books, and websites. Other sources 

of information are secret, and may include agents abroad, defectors 

from adversaries, or information clandestinely gleaned from telephone, 

radio, or Internet transmissions. Information 
processing
 converts the large 
amounts of raw information into forms usable by intelligence analysts, 

and may entail decryption, language translations, and data reduction. 

Analysis and production
 converts information into ˜nished intelligence and 
involves integrating, evaluating, and analyzing all available information 

from all sources. Such analysis may take place over the course of days or 

weeks or months (in the case of strategic intelligence) or over the course 

of hours or minutes (in the case of tactical intelligence). 
Dissemination
 distributes the ˜nished intelligence to the decision makers who requested 

the intelligence in the ˜rst place. (The cyclical nature of the intelligence 

process results from the fact that recipients of intelligence often develop 

new requirements and intelligence needs after they receive ˜nished intel
-ligence, and the cycle starts anew.)
The information collection step is the most relevant to this report. 
Traditionally, sources of information have included signals intelligence 

(SlGINTŠinformation derived from intercepted communications, radar, 

telemetry, and computer networks), imagery (IMINTŠoverhead and 

ground imagery), measurement and signature intelligence (MASINTŠ

technically derived intelligence data other than imagery and SIGINT, 

examples of which might be the distinctive radar signatures of speci˜c 

types of aircraft or the composition of air and water samples), human-

source intelligence (HUMINTŠincluding clandestine source acquisition 

of information; overt information collection by civilian and military per
-sonnel assigned to U.S. diplomatic and consular posts; debrie˜ng of for
-eign nationals and U.S. citizens who have traveled abroad or have access 

to foreign information; of˜cial contacts with foreign governments, includ
-ing liaison with their intelligence and security services), and open-source 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.19
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
information (OSINTŠpublicly available information appearing in print 
or electronic form).
In the context of this report, activities generally labeled as exploita
-tion are sources of raw information and support the information collec
-tion step of the intelligence cycle. As noted in Chapter 1, exploitation 
operations use adversary information systems and networks to support 

friendly goals and missions.
Computer-based or network-based exploitation operations can be 
used to support information collection, although they do not necessar
-ily ˜t neatly into any one of the several sources described above. For 

example, software agents can be introduced into a collection target™s 

computer system that can scan all accessible ˜les for certain keywords 

(e.g., ﬁnuclearﬂ in the appropriate local language) and e-mail those ˜les 

in encrypted form to an address controlled by U.S. intelligence services. 

Other types of agents can monitor all keystrokes made on a target™s 

computer keyboard. A hardware agent introduced during the design of a 

microprocessor might secretly render its encryption functions useless for 

practical purposes, thus making eavesdropping on encrypted messages 

from that computer relatively easy to perform.
1Finally and as noted in Chapters 2 and 3, cyberattack often requires 
substantial intelligence support to succeed, and often cyberexploitation 

techniques will be used to acquire such information for this purpose. 

Intelligence agencies of the U.S. government will play a signi˜cant role 

in collecting the intelligence information necessary for such operations by 

the U.S. armed forces.
4.1.2
 How Cyberexploitation Might Be Used to 
 Support Intelligence Collection 
Some tools for intelligence collection are based on the clandestine 
installation of a software or hardware agent into an adversary computer 

system or network. Once installed, the functionality of the agent for intel
-ligence collection depends only on its ability to route information back to 

its controller, however circuitous or opaque that route might be. 
The following hypothetical scenarios may be illustrative:
1 Famed cryptographer Adi Shamir noted that ﬁif some intelligence organization dis
-covers
 (or secretly plants)
 [emphasis added] even one pair of integers a and b whose product 
is computed incorrectly (even in a single low-order bit) by a popular microprocessor, then 
ANY key in ANY RSA-based security program running on ANY one of the millions of PCs 

that contain this microprocessor can be trivially broken with a single chosen message.ﬂ See 

Adi Shamir, ﬁResearch Announcement: Microprocessor Bugs Can Be Security Disasters,ﬂ 

November 2007, available at http://cryptome.info/bug-attack.htm.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.AN INTELLIGENCE COMMUNITY PERSPECTIVE
 191

The director of the Zendian intelligence service is known to be a 
strong supporter of the Zendian national soccer team. The soccer team 
maintains a website on which it provides team statistics, video highlights 

from recent games, and other content of interest to fans. An intelligence 

collection operation is launched to exploit a ˚aw in the operating sys
-tem of the server that handles the soccer team™s website, and installs a 

Trojan horse program as a modi˜cation of an existing videoclip. When 

the director views the clip, the clip is downloaded to his hard drive, and 

when his desktop search program indexes the ˜le, the Trojan horse is 

launched.
2 The collection payload then searches the local hard drive for 
evidence suggesting that the user is in fact the director. If none is found, 

the program erases itself. If the program ˜nds evidence that the user is 

the director of intelligence (or perhaps the minister of defense, also known 

to be a soccer fan), it retrieves all plaintext ˜les within reach and e-mails 

encrypted compressed versions of them to an e-mail address set up spe
-ci˜cally as a ﬁdead-dropﬂ location.

The Zendian Secret Internet Protocol Router Network (Z-SIPRNet) 
carries classi˜ed information and messages for the Zendian ministry of 

defense, and supports the Zendian command and control system for 

managing troop deployments, the Zendian defense message system, and 

many other classi˜ed war˜ghting and planning applications. Although 

no connections between Z-SIPRNet and the public Internet are allowed, it 

is known that Gorga, a system administrator, has connected his computer 

at work to a password-protected dial-up modem. Through a manipula
-tion of the telephone switching center, phone calls from Gorga™s home 

phone number to the modem are secretly redirected to a login simulator 

that captures his login name and password. Using Gorga™s administrator 

privileges, the intelligence collection operation installs a ﬁsnifferﬂ on the 

network that examines all passing traf˜c, and forwards interesting com
-munications to a ˜le that is saved in a temporary work area on Gorga™s 

computer. At night, while Gorga is asleep, the collection operation down
-loads the ˜le.

An intelligence collection operation scatters inexpensive uni
-versal serial bus (USB) ˚ash drives in parking lots, smoking areas, and 

other areas of high traf˜c near a building associated with the Zendian 
2 For example, a vulnerability in the way in which Windows operating systems handled 
Windows Meta˜le vector images was reported in late 2005Šthis vulnerability allowed arbi
-trary code to be executed on any computer affected without the knowledge or permission of 
its users upon viewing of certain image ˜les. See Swa Frantzen, 
WMF FAQ
, January 7, 2006, 
available at http://isc.sans.org/diary.html?storyid=994.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.192
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Ministry of Defense.
3 In addition to some innocuous images, each drive 
has already-loaded software that collects passwords, login names, and 
machine-speci˜c information from the user™s computer, and then e-mails 
the ˜ndings to the intelligence collectors.
  Because many systems sup
-port an ﬁauto-runﬂ feature for insertable media (i.e., when the medium is 

inserted, the system automatically runs a program named ﬁautorun.exeﬂ 

on the medium) and the feature is often turned on, the intelligence collec
-tors can receive their ˜ndings as noti˜ed as soon as the drive is inserted.
  The program also deletes itself and any trace of the e-mail after sending. 

The login information can then be used to compromise the security of 

existing accounts.

A Zendian ˜rm and a Ruritanian ˜rm are competitors for a 
 multibillion-dollar contract in a third country. Working closely with the 
Zendian ˜rm to understand what it would need to know to compete more 
effectively, the Zendian intelligence service conducts against the Rurita
-nian ˜rm a series of cyber offensive actions that install dual-purpose and 

well-hidden Trojan horses on the ˜rm™s network. At ˜rst, these Trojan 

horses are programmed to send back to Zendian intelligence con˜dential 

business information about the Ruritanian bid; this information is subse
-quently shared with the Zendian negotiating team. Later, as the deadline 

for each side™s best and ˜nal bid approaches, the second function of the 

Trojan horses is activated, and they proceed to subtly alter key data ˜les 

associated with the Ruritanian proposal that will disadvantage the ˜rm 

when the proposals are compared side by side.
4 (Note that these cyber 
offensive actions combine cyberexploitation with the installation of a 

capability for subsequent cyberattack.)
In each of these cases, the installed agent copies ˜les (or parts thereof) 
and then transmits them to the handler. But any access to copy a ˜le could 

almost as easily rewrite the ˜le with different data, and on many systems 

do so without evidence. Such an action would convert the intelligence 

collection agent into a destructive agent as well.
It should be noted that some of the activities in these scenarios would 
raise legal and policy questions for U.S. intelligence agencies if they were 

to engage in such activities. These agencies surely possess the technical 

capability to engage in such activities, but by policy, the United States 

does not target intelligence assets for the speci˜c purpose of enhancing 
3 This exploit is based on an actual experiment reported in 2006. In this experiment, 
over 75 percent of the drives distributed resulted in a system penetration. See Steve Stasiuko
-nis, ﬁSocial Engineering, the USB Way,ﬂ 
Dark Reading
, June 7, 2006, available at 
http://www.
darkreading.com/document.asp?doc_id=95556&WT.svl=column1_
1.4 The use of national intelligence agencies to aid private companies is not unprec
-edented, as noted in Section 2.6.2.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.AN INTELLIGENCE COMMUNITY PERSPECTIVE
 193
the competitive position of U.S. industries or speci˜c U.S. companies. If 
it did, U.S. companies might be able to obtain competitively useful and 
proprietary information about the future generations of foreign products, 

such as airplanes or automobiles, or about business operations and con
-tract negotiating positions of their competitors. 
A potential legal question arises in the action of the U.S. government 
in conducting a cyber offensive action against any viewer of a given 

website, which could include U.S. citizens. Section 7.3.4 addresses the 

legality of such actions taken by intelligence agencies against foreign or 

domestic computers, but additional uncertainties arise if such activities 

are regarded as infringing on the constitutional rights of U.S. citizens.
4.2
 COVERT
 A
CTION
4.2.1
 Governing Principles
By law (50 USC 413b(e)), covert action relates to activities of the 
U.S. government to in˚uence political, economic, or military conditions 

abroad, where it is intended that the role of the U.S. government will 

not be apparent or acknowledged publicly. Covert action must support 

identi˜able foreign policy objectives of the United States and be important 

to the national security of the United States, and must be authorized by 

˜ndings of the President. Covert action must not violate the Constitution 

or any statute of the United States, nor in˚uence United States political 

processes, public opinion, policies, or media, and must also be appropri
-ately reported to appropriate individuals in the U.S. Congress. (The legal 

basis for covert action is addressed in greater detail in Chapter 7.)
In general, covert action is not focused primarily on activities related 
to intelligence collection or analysis, although such collection may occur 

incidentally to covert action.  Executive Order 12333 stipulates that the 

Central Intelligence Agency has by default the lead role in covert action.
Classic examples of covert action include providing weapons or fund
-ing to a favored party in a con˚ict, supporting agents to in˚uence political 

affairs in another nation, engaging in psychological warfare, disseminat
-ing disinformation about a disfavored party, or deceiving a disfavored 

party. Speci˜c actions that could be undertaken under the rubric of covert 

action include:

Funding opposition journalists or newspapers that present nega
-tive images of a disfavored party in power;

Paying intelligence agents or party members to make public state
-ments favorable to U.S. interests; 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.19
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES

Providing ˜nancial support to opposition civil society groups and 
helping them set up international networks;

Advancing conditions for economic disruption by creating fuel 
shortages, promoting hoarding, making doomsday predictions, or closing 
key markets;

Providing military aid or training to favored parties;

Bolstering individual leaders favorable to the United States who 
could plausibly ˜ll a power vacuum once the party in power is ousted;

Funneling money to a favored party through legal or illegal 
means;

Supporting paramilitary action against a disfavored government 
of a foreign nation;

Instigating a ˜ght or discord between two adversarial, disfavored 
parties;

In˚uencing an election; and

Disseminating propaganda.
As a practical matter, the ˜ndings process of the covert action statute 
was established to provide safeguards in situations where the United 

States would be drawn further into some con˚ict or the lives of people 

on the ground were at risk. The ﬁfeel and characterﬂ of such situations are 

signi˜cantly different from actions such as remotely placing Trojan horse 

programs in the operating system of a foreign defense ministryŠand it 

would be less likely for decision makers to believe that ˜ndings would be 

necessary to authorize such actions. Nevertheless, covert actionŠwhether 

it involves computers or notŠ
is
 subject to the ˜ndings and noti˜cation 
process speci˜ed by law.
In addition, it is entirely conceivable that activities originally intended 
to be outside the statutory de˜nition of covert action will evolve over time 

into such action, at which time the ˜ndings mechanism is supposed to be 

invoked. Put differently, there is a certain threshold (an ill-de˜ned thresh
-old to be sure) that must be met in order to trigger the ˜ndings process, 

and to the extent that an activity remains below or outside that threshold, 

the safeguards described in the previous paragraph are not operative.
According to Jeff Smith, former general counsel to the Central Intel
-ligence Agency (1995-1996), traditional U.S. interpretations of the laws 

of armed con˚ict (LOAC; further described in Chapter 7) require covert 

action, whether or not it involves violent activities, to be conducted con
-sistent with LOAC™s requirements. (For example, the War Crimes Act 

(18 U.S.C. 2441) is applicable to all U.S. nationals.) Smith further noted 

that observance of the spirit and letter of LOAC is generally helpful in 

any operation in which it is desirable to win the hearts and minds of the 

people of the nation involved, and in any case increases the likelihood 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.AN INTELLIGENCE COMMUNITY PERSPECTIVE
 195
that other nations will support (or at least less strenuously oppose) U.S. 
actions.
This discussion of covert action should not be construed as support
-ing or opposing the notion of covert action in the ˜rst place, and a number 
of points must be kept in mind. First, covert action is predicated on the 

assumption that the policy goals being supported are indeed sound and 

appropriate. No covert action can turn bad policy into good policy, even 

when decision makers are tempted to use covert action to rescue failed 

policy. In the latter case, it is easy for covert action to 
become
 the policy, 
and for decision makers to forget or downplay the original policy goals. 

Second, covert action is undertaken on the assumption that its link to the 

U.S. government can be kept secret. Although experience demonstrates 

that covert action can indeed be kept secret under some circumstances, 

decision makers cannot assume that any given covert action will be kept 

secretŠand this holds as well for any covert action that might be based 

on cyberattack capabilities.
4.2.2
 How Cyberattack Might Be Used in Covert Action
One alleged U.S. activity involving cyberattack in a covert action 
occurred in 1982.
5 According to Thomas Reed, a former National Secu
-rity Council of˜cial, the United States doctored software that was sub
-sequently obtained by the Soviet Union in its efforts to obtain U.S. tech
-nology.
6  At the time, the United States was seeking to block Western 
Europe from importing Soviet natural gas. The intent of U.S. doctoring 

was ﬁto disrupt the Soviet gas supply, its hard currency earnings from the 

West, and the internal Russian economy,ﬂ and to support this goal, ﬁthe 

pipeline software that was to run the pumps, turbines, and valves was 

programmed to go haywire after a decent interval to reset pump speeds 

and valve settings to produce pressures far beyond those acceptable to 

pipeline joints and welds.ﬂ Soviet use of the doctored software allegedly 

caused a large explosion in a Siberian natural gas pipeline.
The following additional (and entirely hypothetical) examples of how 
cyberattack might be used in covert action are presented for discussion 

only and without comment on the merits of the underlying goals: 
5 However, since the U.S. statute de˜ning covert action was not signed into law until 
1991, it is unclear whether the 1982 action should be considered a covert action in the legal 
sense of the term.
6 Thomas C. Reed, 
At the Abyss: An Insider™s History of the Cold War
, Ballantine Books, 
New York, 2004.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.196
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES

An election is to be held in Zendia, and the predicted margin of 
victory between the favored and disfavored parties is relatively small. 
This election will be the ˜rst Zendian election to use electronic voting, and 

the Zendian election authorities have obtained electronic voting machines 

to administer this election from Ruritania. U.S. intelligence operatives 

intercept the CD-ROM containing a software update from the Ruritanian 

vendor en route to Zendia, and substitute a new CD-ROM in the package 

containing the original update plus additional functionality that will tilt 

the election toward the favored party.

A disfavored party is in power in Zendia, and the U.S. government 
wishes to weaken it. U.S intelligence operatives conduct a cyberattack 

against the Zendian Social Services Agency by compromising employ
-ees of the agency, using the USB ˚ash drive technique described above. 

Obtaining access to the Social Services Agency databases, the United 

States corrupts the pension records of many millions of people in the 

country. In the next election, the disfavored ruling party is voted out of 

of˜ce because of the scandal that resulted.
7 
Two traditionally adversarial nations are armed with nuclear 
weapons, and the United States has been conducting intelligence col
-lection operations against these nations for many years. Through a mix 

of human and technical means, it has been successful in learning about 

cyber vulnerabilities in the nuclear command and control networks of 

each nation. During a crisis between the two nations in which both sides 

have launched conventional kinetic attacks against the other side™s terri
-tory and armed forces, nuclear confrontation between them is imminent. 

The U.S. government makes a decision to corrupt the transmission of any 

nuclear launch orders transmitted through those networks in order to 

prevent their use.
8
Zendia is an authoritarian nation that recognizes the value of the 
Internet to its economy, but as an instrument of political control, it actively 

censors certain kinds of Internet content (e.g., negative stories about the 

Zendian government in the foreign press) for its population. Its censor
-7 This scenario is based on the Japanese election in 2007, in which the ruling party lost 
resoundingly. Many analysts attributed the loss to the fact that the Japanese Social Insur
-ance Agency was revealed to have lost pension records for 50 million people. Although no 
evidence suggests that cyberattacks played any role in this scandal, it is easy to see how in 

an age of increasingly automated records, such attacks might well have such a large-scale 

effect. See Pino Cazzaniga, ﬁElection Defeat Marks Abe™s Political Future,ﬂ 
AsiaNews.it
, July 
30, 2007, available at http://www.asianews.it/index.php?l=en&art=9962.
8 In 1996, a scenario with many similar elements involving India and Pakistan was 
proposed by John Sheehan, then-commander-in-chief of the U.S. Atlantic Command. See 

Bradley Graham, ﬁCyberwar: A New Weapon Awaits a Set of Rules,ﬂ 
Washington Post
, July 8, 
1998, p. A1.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.AN INTELLIGENCE COMMUNITY PERSPECTIVE
 197
ship mechanisms are largely automated and operate at one of a few 
Internet gateways to the country. During a time of tension with Zendia, 
the United States launches a cyberattack against the automated Zendian 

censors so that the population can obtain, at least temporarily, a broader 

range of information than it would otherwise be able to access.

A party favored by the United States is conducting an armed rebel
-lion against the Zendian government. No funds are currently available to 

help the favored party. However, the U.S. President wishes to ˜nd a way 

to help the rebels, and authorizes a cyberattack that diverts money from 

the Zendian national treasury to the rebels.

A Zendian cyberattack is launched against the military medical ser
-vices of Ruritania to obtain the medical records of all active personnel.  In 

the days before a planned armed attack by Zendia, postings and mailings 

from anonymous sources appear pointing out that Ruritanian Colonel X is 

being treated for bipolar disorder, that Captain Y was treated three times 

for a sexually transmitted disease in the last 2 years, and that Admiral Z is 

on tranquilizers. Copies of the medical recordsŠsometimes secretly and 

undetectably alteredŠwere released to back up the stories.  The results 

led to some family problems for Captain Y, Admiral Z was relieved of 

˜eld command, and Colonel X resigned his commission. Others were 

simply discom˜ted. The result was a drop in readiness by the command 

structure when Zendia struck, giving Zendia some advantage. Note that 

this particular covert action has an element of intelligence collection.

The Zendian nuclear weapons program relies on a social network of 
scientists and engineers. The United States launches cyberattacks against 

a dozen key scienti˜c leaders in this network to harass and discredit them. 

These cyberattacks plant false adverse information into their security 

dossiers, insert driving-under-the-in˚uence-of-drugs/alcohol incidents 

into their driving records, alter their credit records to show questionable 

˜nancial statuses, change records of bill payments to show accounts in 

arrears, and falsify telephone records to show patterns of contact with 

known Zendian criminals and subversives.
9 Discrediting these individu
-als throws the program into chaos. 

Scientists working on the Zendian biological weapons program use 
an in-house network to communicate with each other and manage their 

research and development program. U.S. intelligence agencies penetrate 

the network to install dual-purpose software agents to ex˜ltrate the traf
-˜c on the network to intelligence analysts. When analysis of the traf˜c 

indicates that the Zendian research efforts are reaching a critical stage, 
9 This scenario is based on one taken from the Global Organized Crime Project, 
Cyber
-crime, Cyberterrorism, Cyberwarfare: A
verting an Electronic Waterloo
, Center for Strategic and 
International Studies, Washington, D.C., 1998. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.198
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
the software agents begin to alter key data clandestinely so that critical 
experiments fail. Further, these software agents are so well hidden that 
they can maintain their presence over a period of years so that subsequent 

experiments fail at critical times as well.

The Zendian airplane industry and a major U.S. defense contractor 
are engaged in a competition to win a lucrative contract from Ruritania for 

producing ˜ghter aircraft. In order to support a key company in the U.S. 

defense industrial base, the U.S. government conducts a cyberattack to 

disrupt and delay the production of the Zendian ˜ghter plane and thereby 

provides an additional incentive for Ruritania to select the U.S.-produced 

plane.
10
4.3
 POSSIBLE
 I
NTELLIGENCE
 C
OMMUNITY
 I
NTEREST
 IN
 CYBERATTACK
 AND
 C
YBEREXPLOITATION
Because such information would fall into the category of sensitive 
ﬁsources and methods,ﬂ it is not publicly known whether the intelligence 

community has used or intends to use cyberexploitation. However, the 

use of cyberexploitation techniques for ex˜ltration of sensitive business 

and personal information is well known, and the U.S. government has 

indicated that DOD systems have been subjected to foreign cyberexploi
-tation for such purposes. Thus, it would be highly surprising if the U.S. 

intelligence community did not know about and make use of cyberexploi
-tation when appropriate or helpful. 
As for covert action, again the CIA™s interest in or use of cyberattack 
is not known publicly. But given the demonstrated dif˜culties in tracing 

the source of a destructive cyberattack to a speci˜c party, it would not be 

at all surprising for the CIA to be interested in cyberattack as at least a 

potential tool for covert action.
Hints of possible interest in the value of cyberattack for the intelli
-gence community can be found in the testimony of Director of National 

Intelligence J. Michael McConnell to the Senate Select Committee on 
10
 Although such actively destructive actions have not, to the committee™s knowledge, 
been taken to bene˜t U.S. companies, U.S. intelligence has been used to uncover unfair trade 
practices of other nations whose industries compete with U.S. businesses, and has helped 

the U.S. government to ensure the preservation of a level economic playing ˜eld. Accord
-ing to the National Security Agency, the economic bene˜ts of SIGINT contributions to U.S. 

industry taken as a whole have totaled tens of billions of dollars over the several-year period 

prior to 1996. See National Research Council, 
Cryptography™s Role in Securing the Information 
Society, 
National Academy Press, Washington, D.C., 1996, Chapter 3. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.AN INTELLIGENCE COMMUNITY PERSPECTIVE
 199
Intelligence in February 2008.
11
 McConnell noted a need for the United 
States ﬁto take proactive measures to detect and prevent intrusions from 
whatever source, as they happen, and before they can do signi˜cant dam
-age.ﬂ He also noted concern about ﬁhow best to optimize, coordinate and 

decon˚ict cyber activities.ﬂ The ˜rst statement points to the inadequacy 

of hardening and passive defense alone as defensive strategies, and the 

second statement about coordination and decon˚iction suggests the exis
-tence of (or the desire to conduct) cyber activities outside one™s own 

defensive perimeter that might contribute to defense.
Finally, as noted in Box 3.2, the National Security AgencyŠwhich 
is a member of the intelligence community and also a component of the 

Department of DefenseŠhas in its latter role certain responsibilities for 

cyberattack activities.
11
 J. Michael McConnell, ﬁ
Annual Threat Assessment of the Director of National Intel
-ligence for the Senate Select Committee on Intelligence
,ﬂ February 5, 2008, available at http:/
/intelligence.senate.gov/080205/mcconnell.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.5Perspectives on Cyberattack 
 Outside National Security
As noted in Chapters 3 and 4, the military and intelligence commu
-nities have missions to which cyberattack capabilities are relevant.  But 
cyberattack may be relevant to at least two other constituenciesŠthe 

domestic law enforcement community and the private sector.  This chap
-ter explores some of those possible connections.
5.1
 CYBERATTACK
 AND
 D
OMESTIC
 L
AW
 E
NFORCEMENT
For many years, the law enforcement community has had the author
-ity to undertake covert surveillance and monitoring of electronic com
-puter-based communications under legally authorized circumstances.  

(The legal authority for such activity is Title III of the Omnibus Crime 

Control and Safe Streets Act of 1968, as amended to include the Electronic 

Communications Privacy Act, and brie˚y described in Chapter 7.)  In 

addition, law enforcement authorities may conduct surreptitious searches 

of computers for documents when so authorized under a court-issued 

warrant.
From a technological standpoint, such activities are equivalent to the 
intelligence collection activities described in Chapter 4.  Law enforcement 

authorities can and do conduct cyberexploitation with the appropriate 

legal authorization, although the legal framework for providing authori
-zation is very different for the law enforcement community than for the 

intelligence community.  
By contrast, law enforcement authorities often eschew cyberattack.  
200
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PERSPECTIVES ON CY
BERATTACK OUTSIDE NATIONAL SECURITY
 201One possible reason is the prosecutorial focus of law enforcement authori
-ties, who are generally concerned with obtaining legally admissible evi
-dence in order to support successful prosecution.  Evidence collected 
from the computers of suspects has been subject to claims that computer 

records have been altered.
1  Absent speci˜c evidence that tampering has 
occurred, such claims have not prevailed to date.  But if an operation 

were speci˜cally 
designed
 to damage or destroy information resident on a 
target computer, it is hard to imagine that such claims would not be taken 

more seriously.  
A second reason may be that other tools are often available.  For 
example, a criminal website in the United States being used to defraud 

consumers, for example, can be taken down by legal rather than techni
-cal means.
On the other hand, public reports indicate that law enforcement 
authorities have in fact conducted denial-of-service attacks against wire
-less (cell phone) networks and other wireless devices such as garage door 

openers and remote control devices for toys in order to prevent their 

use to detonate remote-controlled bombs.
2 Jamming cell phone networks 
in a speci˜c geographic area could be used to help stop terrorists and 

criminals from coordinating their activities during a physical attack and 

prevent suspects from erasing evidence on wireless devices.  In prisons, 

jamming could interfere with the ability of prison inmates to use contra
-band cell phones, which are often used to intimidate witnesses, coordinate 

escapes, and conduct criminal enterprises.
Federal law enforcement of˜cials are permitted to use jamming tech
-nology with speci˜c legal authorization, and state and local law enforce
-ment agencies are not allowed to do so at all.  In particular, 47 USC 333 

states that ﬁno person shall willfully or maliciously interfere with or cause 

interference to any radio communications of any station licensed or autho
-rized by or under this chapter or operated by the United States Govern
-ment.ﬂ  However, Section 305 of the Communications Act of 1934 (today 

47 USC 305) stipulated government-owned radio stations need not adhere 

to rules and regulations designed to prevent interference with other radio 

stations.  The National Telecommunications and Information Adminis
-1 U.S. Department of Justice, 
Searching and Seizing Computers and Obtaining Electronic 
Evidence in Criminal In
vestigations
, Computer Crime and Intellectual Property Section, 
Criminal Division, July 2002, available at http://www.usdoj.gov/criminal/cybercrime/
s&smanual2002.htm#_VB1_.
2 Speci˜cally, the 
Washington Post
 reported that such jamming technology was 
used to protect President Obama™s inaugural motorcade on Pennsylvania Avenue.  See 
 Spencer S. Hsu, ﬁLocal Police Want Right to Jam Wireless Signals,ﬂ 
Washington Post
, Feb
-ruary 1, 2009, p. A02, available at http://www.washingtonpost.com/wp-dyn/content/ 
article/2009/01/31/AR2009013101548_pf.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.202 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
tration Organization Act of 1992, Public Law 102-538 and codi˜ed at 47 
USC 901-904, established the NTIA as the federal point of responsibility 
for managing U.S. domestic use of the spectrum.
3  Speci˜cally, the Of˜ce 
of Spectrum Management within the National Telecommunications and 

Information Administration of the Department of Commerce develops 

and implements policies and procedures for domestic issues regarding the 

use of the spectrum by the federal government in the United States.
The use of jamming technology is not the only way to thwart the use 
of cell phones for terrorist or criminal purposes.  Persuading cell phone 

providers to shut down service, either over a broad area or just in the 

vicinity of a few speci˜c cell towers, can also work effectivelyŠsuch an 

approach to a cell phone provider might well be regarded as the equiva
-lent of a close-access ﬁcyberattack.ﬂ
4 In February 2009, Senator Joseph I. Lieberman planned to introduce 
legislation that would give law enforcement agencies ﬁthe tools they need 

to selectively jamﬂ communications in the event of a terrorist attack.
5 Senator Kay Bailey Hutchison and Representative Kevin Brady also intro
-duced a bill that would allow the U.S. Bureau of Prisons and governors 

to seek the authority to jam cell phones in prisons.
65.2
 THREAT
 N
EUTRALI
ZATION
 I
N THE
 P
RIVATE
 S
ECTOR
5.2.1
 Possible Response Options for Private Parties 
 Targeted by Cyberattack
In general, a private party that is the target of a cyberattack has four 
options for responding.  First, it can implement passive measures to 

strengthen its defensive posture.  For example, it can drop functionality 

on its own systems that the attacker is trying to exploit, reject traf˜c, and 

close ports on its ˜rewall.  Second, it can report the event to law enforce
-ment authorities, and law enforcement authorities can take appropriate 

action to try to shut down the cyberattack (e.g., by ˜nding the perpetrator 
3 See http://www.ntia.doc.gov/osmhome/roosa8.html.
4 Indeed, the 
Washington Post
 story reported that the U.S. Department of Homeland 
Security reached an agreement in 2006 with cell phone companies to voluntarily shut down 
service under certain circumstances, which could disable signals for areas ranging from a 

tunnel to an entire metropolitan region.
5 See Spencer S. Hsu, ﬁLocal Police Want Right to Jam Wireless Signals,ﬂ 
Washington 
Post
, February 1, 2009, p. A02, available at http://www.washingtonpost.com/wp-dyn
/content/article/2009/01/31/AR2009013101548_pf.html.
6 Matthew Harwood, ﬁBill Would Allow Prisons to Jam Cell Phone Signals,ﬂ 
Security 
Management
, January 16, 2009, available at http://www.securitymanagement.com/news/
bill-would-allow-prisons-jam-cell-phone-signals-005082.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PERSPECTIVES ON CY
BERATTACK OUTSIDE NATIONAL SECURITY
 203and arresting him). (However, to the best of the committee™s knowledge, 
law enforcement authorities have never launched a counter-cyberattack.)  
Third, it can take self-help measures to further investigate and charac
-terize the source of the cyberattack and then report the information to 

appropriate law enforcement authorities.  Fourth, it can take actions to 

neutralize the incoming cyberattack.
The ˜rst optionŠstrengthening its defense posture passivelyŠentails 
a minimum of controversy as a matter of law and policy.  But although 

stronger passive defensive measures are unlikely to be effective over the 

long run, the other options do entail some degree of controversy.
Consider the long-standing thread of policy that law enforcement 
authorities have a key role to play in responding to a cyberattack against 

a private sector entity. The law enforcement paradigm is oriented primar
-ily toward investigation, prosecution, and conviction of those who violate 

existing criminal laws about causing damage or destruction to computer 

systems (described in more detail below).  Such processes take time to 

operate, often weeks or months, and are often constrained by the avail
-ability of law enforcement resources and expertise.  
In the meantime, the private sector entity subject to a hostile cyber
-attack can only hope that passive defense measures will mitigate the 

threatŠtoday, there are no legal mechanisms or institutional structures 

available to provide immediate relief under such circumstances.  Such a 

lacuna raises the possibility that some form of active defense for threat 

neutralization (active threat neutralization for short) may be a necessary 

component of a strong cybersecurity posture for the private sector.  
As noted in Chapter 3, the U.S. Strategic Command (STRATCOM) 
asserts the authority to conduct response actions, including threat neutral
-ization, on behalf of cyberattacks against DOD installations under certain 

circumstances.  The Department of Homeland Security has the responsi
-bility for seeing to the cyber protection of the defense industrial base and 

the providers of critical infrastructure.  But to the best of the committee™s 

knowledge, neither DHS nor any other part of government has been given 

the authority to conduct active threat neutralization on behalf of any part 

of the private sector (including the companies of the defense industrial 

base and the providers of critical infrastructure).  
This state of affairs is problematic for large multinational corporations 
that face major cybersecurity threats, and that are themselves concerned 

with how to manage the risk associated with the cyberattacks they face.  

For such entities, one element of any rational risk management strategy 

would involve managing the tradeoff between the legal liabilities associ
-ated with actions for the defense of property and the bene˜ts from taking 

such actions.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.204
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
5.2.2
 Self-defense by Private Parties
If passive defensive measures by themselves are insuf˜cient for an 
adequate cybersecurity posture (as might be inferred from the consider
-ation of active threat neutralization for DOD cybersecurity), the question 
arises as to whether critical parts of the private sector might be afforded 

a similar kind of protection.  Some elements of the private sector with 

services to offer do make just such an argument.
7  Without prejudging the 
pros or cons of such arrangements, the discussion below indicates some of 

the legal and policy issues that would need to be addressed before such 

practices could be adopted.
A ˜rst point is whether cyberattack expertise is available to the pri
-vate sector.  Although it is likely that the capabilities of the DOD far 

exceed those available to the private sector, many private sector compa
-nies use penetration testing and ﬁred-teamingﬂ as a way of testing their 

own cybersecurity postures.  Such testing involves hiring a ˜rm or an 

individual to penetrate one™s own information systemsŠtypically these 

˜rms and individuals advertise their services under the label of ﬁethical 

hackersﬂ or something similar.  The expertise needed to provide these ser
-vices is roughly the same as that needed to conduct cyberattacks against 

any other target, and so it is clear that some level of cyberattack expertise 

is available.
8  In addition, many private enterprises make use (in some 
cases, extensive use) of threat intelligence and surveillance capability 

provided by private companies.
As for the legal dimension, U.S. common law admits certain rights 
of self-defense and of defense of property in preventing the commis
-sion of a crime against an individual or a corporation.  (In legal usage, 

self-defense refers to the defense of one™s self (or others)Ša defense of a 

person.  Defense of property is more limited, in the sense that the range 

of allowable actions for the defense of property is more limited than for 
7 For example, in a paper entitled ﬁOffensive Operations in Cyberspaceﬂ (dated June 1, 
2007), the White Wolf Security corporation argued that corporate victims of cyberattack have 
limited rights to use offensive cyber operations in order to proactively protect their assets 

and workforce from attacks originating in the United States and in allied non-U.S. nations 

and that private military companies constitute an emerging base from which to conduct such 

operations on behalf of any party entitled to conduct them.  This paper is no longer online, 

but it is in the committee™s possession and available in this project™s public access ˜le.
8 An important area in which necessary cyberattack expertise may vary according to 
the kind of target is the expertise needed to conduct social engineering attacks, which by 

de˜nition involve exploitation of vulnerabilities that are embedded in the particular culture 

and operating procedures and practices of the target entity.  It is almost certainly harder for 

a U.S. ﬁethical hackerﬂ to conduct a social engineering attack in Zendia than in the United 

States, for reasons that might include a lack of knowledge of the Zendian language or of 

Zendian cultural norms.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PERSPECTIVES ON CY
BERATTACK OUTSIDE NATIONAL SECURITY
 205certain kinds of self-defense (in particular, for self-defense against lethal 
attack).  But the range of allowable actions for the defense of property 
is roughly comparable to the range for 
non-lethal
 self-defenseŠthe use 
of non-lethal force can be justi˜ed in order to defend one™s self against 

non-lethal attack and to defend one™s property.  For hostile cyberattacks, 

the relevant concept will almost always be defense of property, as cyber
-attacks against private parties have not usually had lethal intent.  Note 

that self-defense in this context has an entirely different meaning than 

self-defense in international law, a topic explored at length in Chapter 7.)  

While individuals are not permitted to engage in revenge or retaliation 

for a crime (that is, vigilantism is forbidden by law), they areŠunder 

some circumstancesŠentitled to take otherwise-prohibited actions for 

the purpose of preventing or averting an imminent crime or one that is in 

progress.  Moreover, these rights attach even if speci˜c statutes may not 

explicitly acknowledge their existence.
9  Thus, the widely held view that 
government has a literal monopoly on legitimate use of physical force is 

simply not true as a matter of common law.  
Today, the primary federal law addressing cyberattacks is the Com
-puter Fraud and Abuse Act (CFAA), codi˜ed as Title 18, Section 1030.  

Loosely speaking, this act criminalizes the intentional damaging of any 

computer connected to the Internet.
10
  (A number of state laws have similar 
provisions and would apply to individuals and corporations within their 

jurisdiction.
11
  The CFAA is discussed further in Section 7.3.4.)  Although 
the CFAA contains an explicit exception for law enforcement agencies that 

undertake the normally proscribed behavior with respect to cyberattack, 

there is no explicit exception for private parties.
On the other hand, the CFAA was never intended to apply and does 
9 The Model Penal Code does include exceptions for self-defense and defense of prop
-erty (
Model Penal Code,
 American Law Institute, Philadelphia, 1962, available at http://www.
ali.org/index.cfm?fuseaction=publications.ppage&node_id=92).  See also Paul H. Robinson, 
ﬁCriminal Law Defenses: A Systematic Analysis,ﬂ 
Columbia Law Re
view
 82:199-291, 1982, 
available at http://papers.ssrn.com/sol3/papers.cfm?abstract_id=662043.
10 
Section 1030 of the Computer Fraud and Abuse Act penalizes individuals who 
ﬂknowingly cause the transmission of a program, information, code, or command, and as a 

result of such conduct, intentionally causes damage [in excess of $5,000] without authoriza
-tion, to a protected computer.ﬂ ﬁProtected computersﬂ are de˜ned to include computers 

ﬁused in interstate or foreign commerce or communication, including a computer located 

outside the United States that is used in a manner that affects interstate or foreign commerce 

or communication of the United States.ﬂ  In short, virtually any computer connected to the 

Internet falls under the de˜nition of ﬁprotected computer.ﬂ
11 
For example, Section 815.06 of Title XLVI of the Florida Code (entitled ﬁOffenses 
Against Computer Usersﬂ) criminalizes the willful, knowing, and unauthorized access or 

destruction of a computer or network (among other things).  See http://www.leg.state.˚.us/

Statutes/index.cfm?App_mode=Display_Statute&Search_String=&URL=Ch0815/SEC06.

HTM&Title=-%3E2007-%3ECh0815-%3ESection%2006#0815.06.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.206 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
not apply to penetration testersŠprivate parties hired (authorized) by a 
company to test its own defenses.
12
  A number of such ˜rms provide such 
services so that a company can obtain a realistic assessment of its own 
security posture, and indeed penetration testing is often recommended 

as one of the best ways of doing so.
13
A more signi˜cant issue is that in light of common law traditions 
regarding self-defense and defense of property, it is at least possible that 

a court might ˜nd that certain cyberattack actions undertaken in defense 

of property might be allowable, although whether such actions can stand 

as an exculpatory rationale for conducting active threat neutralization has 

not been tested in the courts to date.  Even if not, actions taken in defense 

of property might be a starting point for legislative change if a policy deci
-sion is made that such actions involving cyberattack 
should
 be allowed in 
certain circumstances.
14
In the context of active threat neutralization of private, non-govern
-ment computer systems under attack, an interesting question thus arises.  

To what extent and under what circumstances is self-help a legitimate 

option for the target of a cyberattack to stop it?  Box 2.4 in Chapter 2 

describes a spectrum of possible responses to a cyberattack, some of 

which plausibly count as active defense for threat neutralization.
Security specialists in a private organization are often warned about 
undertaking efforts to gather information about the perpetrators of a 

cyberattack against the organization.  For example, they are warned 

against compromising an already compromised machine to insert track
-ing and collection software to gather such information.  Concerns some
-times arise over the possibility that the private organization and/or the 

security specialists themselves might be subject to civil or even criminal 

liability for their actions and that their efforts might contaminate evidence 

should a prosecution occur.
 As for more aggressive actions, actions taken in self-defense or for 
the defense of property are often justi˜ed as the only timely response 

available in exigent circumstances when law enforcement authorities are 

unavailable at the moment they are needed to prevent a crimeŠthat is, 

in seconds rather than in the minutes or hours that it often takes law 

enforcement of˜cials to arrive at the scene of a crime in progress.  In the 
12
 The CFAA criminalizes only intentional damage caused without authorization.
13
 National Research Council, 
Cybersecurity Today and Tomorrow: Pay Now or Pay Later
, The National Academies Press, Washington, D.C., 2002.
14
 As an example of a policy that would endorse cyberattack as a response to a threat 
to commercial interests, consider the controversial proposal of Senator Orrin Hatch to ﬁde
-stroyﬂ computers that have repeatedly been involved in the online trading of music and 
movie ˜les after ˜rst providing warnings to the user to refrain from such behavior.  See As
-sociated Press, ﬁHatch Wants to Fry Traders™ PCs,ﬂ June 18, 2003, available at http://www.

wired.com/entertainment/music/news/2003/06/59298. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PERSPECTIVES ON CY
BERATTACK OUTSIDE NATIONAL SECURITY
 207case of responding to hostile cyberattacks, the enormous number of sites 
subject to such cyberattacks suggests that suf˜cient government resources 
will indeed be unavailable to protect all of them, and law enforcement 

authorities are often hard-pressed to respond at all, let alone adequately, 

to cybercrimes in progress.
In the absence of suf˜cient law enforcement resources, two options 
are possibleŠprioritize so that government resources are used to con
-duct actions to defend people and property only against the most seri
-ous threats, and/or allow the attacked parties to conduct such actions 

themselves.  
In large part, a choice between these two options rests on one™s view 
about whether the conduct of offensive activities should be the exclusive 

purview of government.  Very few individuals would be sympathetic to 

the notion of privatizing the nuclear deterrent force or even battleships 

or jet ˜ghters.  Yet under some circumstances, private parties can and do 

act with lethal force in order to neutralize an immediate threat to life, 

and they can act with non-lethal force to neutralize an immediate threat 

to property.
It is not known how frequently victims of cyberattack take self-help 
actions. Likely because of concerns about violations of the CFAA, few 

of those who actually take such actions will report them openly.  Yet 

some anecdotal evidence and personal experience of committee members 

suggests that the frequency is not zero, and the committee is aware of 

instances in which attacked companies have indeed conducted denial-

of-service counterattacks against the attacking parties, even though such 

actions have never been acknowledged openly or done in ways that draw 

attention to them.
One data point on this issue is provided by the 
New York Times
,15
 which reported that a worm released in late 2008 known has Con˜cker 

has reignited a debate inside the computer security community over the 

possibility of eradicating the program before it is used, by launching a 

cyberattack to compromise the worm™s controller and direct it to send 

messages to users warning them of the infection.  One cybersecurity 

researcher working on a counter to the Con˜cker worm said of such a 

possibility, ﬁYes, we are working on it, as are many others.  Yes, it™s ille
-gal, but so was Rosa Parks sitting in the front of the bus.ﬂ  Others in the 

cybersecurity research community continue to oppose such an effort to 

stop the worm because of a concern that such efforts would create even 

more problems.
If a domestic policy decision is made to allow attacked private
-sector 
15 
John Markoff, ﬁWorm Infects Millions of Computers Worldwide,ﬂ 
New York Times
, January 22, 2009, available at http://www.nytimes.com/2009/01/23/technology/internet/
23worm.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.208 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
parties to conduct actions in defense of property,
16
 mechanisms can be 
put into place that depend on other parties whose job it is to defend the 
interests (life, property) of a possible victim.  That is, an individual or 

a company may hire armed guards to implement self-defense practices 

or procedures should they become necessary.  Regarding cyberattack, 

the analogous situation might be a company that provides active threat 

neutralization services that could be called into action when a customer 

reports being under attack (Box 5.1).
5.2.3
 Regulating Self-defense by Private Parties
Some cybersecurity analysts propose letters of marque and reprisal as 
a model for regulated private cyberattacks to support threat neutraliza
-tion.
17
  Letters of marque and reprisal were originally used by govern
-ments to give private parties the authority to take certain actions gener
-ally regarded as appropriate only for a nation™s military forcesŠnamely 

to operate and use armed ships to attack and capture enemy merchant 

ships in time of war.  These letters were crafted with a certain degree of 

speci˜city to ensure that the actions of the private party did not exceed 

the intent of the issuing government, and further were never intended to 

imply that such letters were needed for immediate self-defense.
Although the Paris Declaration Respecting Maritime Law of 16 April 
1856 was issued to abolish such private actions, and many nations rati˜ed 

this declaration, the United States did not and has never renounced the 

right to do so.  Indeed, Article 1, Section 8 of the United States Constitu
-tion includes the issuance of letters of marque and reprisal as one of the 

enumerated powers of Congress.  
In the context of privately conducted cyberattacks, letters or licensing 
could be used to specify the circumstances under which threat neutraliza
-tion may be performed for the defense of property, the criteria needed to 

identify the attacking party with suf˜ciently high con˜dence, the evidence 

needed to make the determination that any given cyberattack posed a 

threat suf˜ciently severe as to warrant neutralization, and the nature and 

extent of cyberattacks conducted to effect threat neutralization.
A key issue is the threshold at which it is appropriate to conduct an 
16
 Although the policy decision would be domestic, it might well have implications 
for international law as well.  In particular, it is not clear how an explicit decision to allow 
attacked private sector parties to conduct actions in self-defense or in defense of property 

would square with the international Convention on Cybercrime (discussed further in Sec
-tion 7.2.4).
17
 See, for example, Excalibur R&D, ﬁLetter of Marque and Reprisal for Fighting 
Terrorists,ﬂ August 20, 2008, available at http://excaliburrd.com/cs/blogs/excalibur
/Excalibur%20Letter%20of%20Marque%20paper%2015%20August%202008.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PERSPECTIVES ON CY
BERATTACK OUTSIDE NATIONAL SECURITY
 209active threat neutralization, and how that threshold is determined.  Who 
determines the threshold?  What level of actual damage, if any, must the 
victim sustain in order to demonstrate harm?  How are such levels to be 

measured?  Who should have the authority to make such a determina
-tion?  What alternatives to active threat neutralization must have been 

tried before active defense can be used?  How should their success (or 

lack thereof) be documented?
Although in a cyberattack context, these questions re˚ect largely 
unexplored legal territory, a few speculations can be made based on past 

precedents.  To be justi˜ed, lethal actions taken in self-defense must usu
-BOX 5.1
 A Security Operations Center
Nearly all large organizations face daily a deluge of security inputs from a 
variety of different systems, platforms, and applications.  Usually, these inputs 
are generated as the result of point solutions distributed over multiple locations 

and do not adhere to any standards of syntax (they come in different formats, for 

example) or semantics (they report on different things).  Growth in the number of 

attacks experienced every day, new technologies and rapid expansion, and new 

regulations and laws increase the burden on systems administrators.
In response, many organizations seek to centralize the management of their 
security functions in what are often known as security operations centers (SOCs).  

SOCs track and integrate the multiple security inputs, ascertain risk, determine 

the targets of an attack, contain the impact of an attack, and recommend and/or 

execute responses appropriate to any given attack.  In some cases, an organiza
-tion will establish a SOC for itself.  In other cases, SOC services are outsourced 

to a private company that specializes in providing such services.
A SOC is constrained today to provide only passive defensive services when 
a threat originates outside the perimeter of the organization it serves.  But active 

defense could be provided, legally, if undertaken within the organizational perim
-eter
1Šand it is a matter of policy and law rather than technology that would prevent 
a SOC from taking similar action against parties outside the organizational perim
-eter.  Of course, if policy and law were established to allow such action, a SOC™s 

actions would be subject to whatever standards and regulatory requirements were 

part of that policy and law.
1 As noted in Footnote 10 of this chapter, the Computer Fraud and Abuse Act criminalizes 
only attacks committed 
without authorization
.  If a SOC conducts active defense within an 
organization™s perimeter at the behest of that organization, it is acting with authorization.
SOURCE: Adapted from Computer Associates, ﬁBest Practices for Building a Security Opera
-tions Center,ﬂ August 2006, available at http://www.secguru.com/˜les/papers/best_practices_

snoc_white_paper.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.21
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
ally be carried out as a last resort,
18
 but the same is not true for non-lethal 
actions taken either in self-defense or in defense of property.  That is, in 
the case of protecting one™s self from lethal attack, the ostensible victim 

must have tried other less violent methods for mitigating the harm that 

an attack might cause, or at least have good cause to believe that those 

other methods would not work.  The same is not true for taking non
-lethal actions to combat a non-lethal threat.  In the case of cyberattack, 

even though such attacks are generally non-lethal, an argument might 

be made that the former analogy imposes a degree of prudence that is 

appropriateŠif so, the analogy would require that a victim has taken 

all available passive defense measures (e.g., ˜rewalls or system patches) 

before active threat neutralization is to be allowed as a permissible self-

help action.
A related point is that an action in defense of property might be mis
-directed and thus harm an innocent third party.  From a legal point of 

view, a party taking an action in defense of property resulting in such 

harm may have a plausible defense to the violation of criminal law if he 

has made reasonable efforts to identify the party responsible for the origi
-nal attack, even if the efforts were erroneous.  Civil liability may attach 

for such action (e.g., the party launching the action in defense of property 

may be responsible to the innocent victim for damages suffered), although 

the liability might be less if the innocent party was negligent in allowing 

his or her computer to be used for malevolent purposes.
19
5.2.4
 Negative Rami˚cations of Self-defense by Private Parties
The discussion above should not be construed as advocating a change 
from today™s legal regime that strongly discourages active threat neutral
-ization by private sector entities.  Indeed, allowing self-help actions for 

private parties also has a variety of broader and negative rami˜cations for 

the nation™s interests writ large.  
18
 In most states, it is legal to use deadly force against an attack that threatens death, 
serious bodily injury, rape, kidnapping, or in some states robbery or burglary, even if one 
could have safely avoided the injury by retreating.  And in all states, it is legal to use deadly 

force against such an attack even if one could have safely avoided the problem by turning 

over property that the attacker is demanding as a condition of not injuring the victim.
19
 Uncertainties abound in this area.  For example, it is theoretically possible that cy
-berattack conducted to neutralize an active threat might itself be characterized as an ﬁultra-
hazardous activity,ﬂ depending on its scope and nature.  If so, the courts could apply strict 

liability to all the harmful effects it caused.  Alternately, if the defense of property is found 

not to apply to an active threat neutralization, the defender could easily ˜nd his responsive 

acts characterized as wrongful.  Still other legal traditions forbid ﬁhot pursuitﬂ of an attacker 

after he no longer poses a threat, and the line between active threat neutralization and retali
-ation is not necessarily clear.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PERSPECTIVES ON CY
BERATTACK OUTSIDE NATIONAL SECURITY
 211
For example, active threat neutralization conducted by the private 
sector may have negative implications for the conduct of international 
relations.  A private party in the United States conducting an action 

that harms computers in Zendia is likely to be attributed to the U.S. 

government even if there is no such linkage, and Zendia may well seek 

to hold the United States government responsible.  A denial by the U.S. 

government may even be seen as evidence of government complicity in 

a plausibly deniable attack.  And if Zendia believes that the U.S. govern
-ment is responsible for an attack on it, itŠor computer-savvy citizens of 

ZendiaŠmay well see ˜t to attack the United States directly or its interests 

(e.g., private sector companies).  (Such complex escalation scenarios do 

not generally characterize the typical self-defense or defense-of-property 

scenarios of a company defending its building or a homeowner defend
-ing her home.)
In addition, active threat neutralization conducted by the private 
sector may also interfere with cyberattacks launched by the U.S. govern
-ment.  For example, it is easy to imagine a scenario in which major U.S. 

corporations come under cyberattack from a foreign power and the U.S. 

government chooses to respond in kind.  Cyberattacks launched by these 

corporations at the same time might well interfere with the conduct of 

the U.S. cyberattack, might work at cross-purposes with it, and would 

almost certainly be indistinguishable from cyberattack actions taken by 

the U.S. government.
These issues are further complicated if the U.S. government estab
-lishes standards, mandates licensing, or otherwise provides advice that 

could support actions taken in defense of property (e.g., that describe 

what conditions must be established for when such behavior should be 

considered a reasonable option, or what the limits on such actions should 

be).  
In the absence of mandatory standards for taking such action, actions 
by private parties would be governed by the party™s own view of its self-

interest, and in particular would be unlikely to take into account other 

broader societal or national needs.
20
  Thus, active threat neutralization 
may run a higher risk of having effects that work against those broader 

needs or objectives.  A private party™s threshold for action may also be 

lower (for example, it may be less tolerant of corporate espionage) than 

public policy might dictate.
20
 Precedent for this likely outcome can be found in the behavior of private companies 
today, which invest in cybersecurity to the extent, and only to the extent, that their business 
needs call for such protection.  The result has been a societal level of cyber protection that 

is, by most accounts, inadequate to meet the needs of the nation as a whole. See National 

Research Council, 
Toward a Safer and More Secure Cyberspace
, The National Academies Press, 
Washington, D.C., 2007.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.212
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
On the other hand, the explicit establishment of stated policy that 
allowed private parties to act in defense of property to a cyberattack could 
well be taken as government endorsement of such actions, even if such 

policy did not require them to do so.  Standards established ostensibly to 

regulate such behavior and prevent these actions from being taken arbi
-trarily or solely at the discretion of the victimized party could thus have 

a perversely negative effect on how the U.S. government is perceived. 
Self-help actions of multinational corporations have implications with 
respect to both international law and the domestic laws of all the nations 

in which the corporations have a physical presence (where, for example, 

personnel and assets may be placed at risk by actions taken elsewhere by 

the corporation).  Although such actions have not yet produced a visible 

reaction from other nations (perhaps because the scale of the problems 

involved has not reached the necessary level), how nations and the inter
-national community will react in the future remains to be seen.
Some of the negative rami˜cations described are also associated with 
today™s regime, in which victims sometimes take self-help actions on the 

basis of their own judgments and perceptions quietly and under the table 

without policy or legal guidance.  If and when such self-help actions reach 

a level where they interfere signi˜cantly with U.S. policy or its execution, 

policy makers may eventually consider a legal regime that is tighter with 

respect to self-help rather than looser than that of today.  A tighter regime 

might explicitly prohibit active threat neutralization by private parties 

even under the rubric of defense of property, prohibit active intelligence 

gathering by private parties in the wake of a cyberattack, make parties 

undertaking threat neutralization strictly liable for any harm they cause, 

and so on.
5.3
 CYBEREXPLOITATION
 IN
 THE
 P
RIVATE
 S
ECTOR
Given that the technical skills for cyberexploitation are similar to 
those required for cyberattack and in light of the discussion above, it is 

likely that some U.S. companies would have the technical capability to 

conduct cyberexploitation against their competitors.  However, the Eco
-nomic Espionage Act of 1996, 18 USC 1831-1839, criminalizes the theft 

of trade secrets related to or included in a product that is produced for 

or placed in interstate or international commerce.  (ﬁTrade secretsﬂ are 

de˜ned as ﬁall forms and types of ˜nancial, business, scienti˜c, technical, 

economic, or engineering information, including patterns, plans, compi
-lations, program devices, formulas, designs, prototypes, methods, tech
-niques, processes, procedures, programs, or codes.ﬂ) Whether individual 

U.S. ˜rms have engaged in this kind of industrial intelligence against 

competitors despite its illegality is unknown to the committee.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.PERSPECTIVES ON CY
BERATTACK OUTSIDE NATIONAL SECURITY
 213
5.4
 THREAT
 N
EUTRALI
ZATION
 ON
 B
EHALF
 OF
  NON
-MILITARY
 G
OVERNMENT
 A
GENCIES
Most of the discussion in the previous sections applies equally as 
well to active threat neutralization conducted on behalf of non-military 
government agencies.  The Department of Homeland Security has the 

responsibility for seeing to the cyber protection of non-military govern
-ment agencies, and to the best of the committee™s knowledge, neither DHS 

nor any other part of government has been given the authority to conduct 

active defense on behalf of these agencies.
The primary difference between protection for government agencies 
and for the private sector is the fact that the actions of government agen
-cies are subject to government control and direction within the limits of 

statutory law and constitutional restraint, whereas the U.S. government 

has exercised little in˚uence apart from the bully pulpit today to direct or 

even in˚uence the actions of much of the private sector regarding cyberse
-curity, a notable exception being private sector companies that are subject 

to strong government regulation, such as the ˜nancial sector or companies 

in the defense industrial base, or that provide key services to the federal 

government.  (Whether this ﬁhands-offﬂ stance of government toward the 

private sector will continue to be the case in the future is not clear.)
This difference is perhaps most important regarding issues related to 
the determination of the threshold at which an active defense is appro
-priate.  A private party setting the threshold is highly unlikely to take 

into account the overall national interest if it is given a free hand in 

determining that threshold, whereas a decision by government on the 

threshold is supposed to do so, at least in principle.  That is, an action by 

a government agency is, in principle, coordinated throughout the federal 

government and that interagency process is responsible for ensuring that 

the overall national interest is indeed served by that action.
A variety of pragmatic issues are also easier to resolve when govern
-ment agencies are at issue.  For example, through executive order the 

President can direct federal agencies to share data about the scope and 

nature of any cyberattacks they are experiencing.  Such information is 

necessary to determine the overall scope of any attack and thus to deter
-mine the nature of any active defense required.  But most private parties 

are currently under no such obligation to provide such information to the 

federal government.
21
21
 Certain private parties subject to government regulation may be required to provide 
information under some circumstancesŠ˜nancial institutions, for example, are required to 
notify their regulatory authorities if they experience signi˜cant cyber penetrations, although 

this requirement is not a real-time requirement.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.6Decision Making and Oversight
This chapter describes decision making about and oversight of 
cyberattack as an instrument of U.S. national policy, focusing on issues 
usually associated with the Department of Defense and intelligence 

communities.
6.1
 EXECUTIVE
 B
RANCH
 The discussion belowŠaddressing declaratory policy, acquisition pol
-icy, and employment policyŠdraws from discussions of nuclear history 

and policy,
1 not because cyberweapons and nuclear weapons are similar 
(they are not), but because such discussions have highlighted the impor
-tance of several issues discussed below. That is, the committee found 

that nuclear history and policy are useful points of departureŠframing 

notions and metaphorical checklistsŠfor understanding policy regarding 

cyberattack but not that the conclusions that emerge from nuclear policy 

and history are directly applicable. 
1 Robert S. Norris, ﬁThe Dif˜cult Discipline of Nuclear History: A Perspective,ﬂ a 
presentation at the Carnegie Conference on Non-Proliferation, November 7, 2005, avail
-able at http://www.carnegieendowment.org/static/npp/2005conference/presentations
/Norris_Nuclear_History_Slides.pdf, and David M. Kunsman and Douglas B. Lawson, 
A Primer on U.S. Strategic Nuclear Policy
, Sandia National Laboratories, Albuquerque, 
N.Mex., January 2001, available at http://www.nti.org/e_research/of˜cial_docs/labs/

prim_us_nuc_pol.pdf. 
21
4Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 215
6.1.1
 Declaratory Policy
6.1.1.1
 The Need for Declaratory Policy
Declaratory policy states, in very general terms, why a nation acquires 
certain kinds of weapons and how those weapons might be used. For 
example, the declaratory policy of the United States regarding nuclear 
weapons is stated in 
The
 National Military Strategy,
 last published in 
2004:
2Nuclear capabilities [of the United States] continue to play an impor
-tant role in deterrence by providing military options to deter a range of 
threats, including the use of WMD/E and large-scale conventional forces. 
Additionally, the extension of a credible nuclear deterrent to allies has 
been an important nonproliferation tool that has removed incentives for 

allies to develop and deploy nuclear forces.
By contrast, the declaratory policy of Israel regarding nuclear weap
-ons is that it will not be the ˜rst nation to introduce nuclear weapons in 
the Middle East. The declaratory policy of China regarding nuclear weap
-ons is that it will not be the ˜rst to use nuclear weapons under any cir
-cumstances. The Soviet Union once had a similar ﬁno ˜rst use of nuclear 

weaponsﬂ declaratory policy, but Russia has since explicitly revoked that 

policy. U.S. declaratory policy has also evolved since 1945Šﬁmassive 

retaliation,ﬂ ﬁ˚exible response,ﬂ and ﬁescalation dominanceﬂ are some 

of the terms that have characterized different versions of U.S declaratory 

policy regarding nuclear weapons in that period.
Declaratory policy is not necessarily linked only to the use of nuclear 
weapons. In 1969, the United States renounced ˜rst use of lethal or inca
-pacitating chemical agents and weapons and unconditionally renounced 

all methods of biological warfare.
3 In 1997, the United States rati˜ed the 
Chemical Weapons Convention, which prohibits the signatories from 

using lethal chemical weapons under any circumstances. 
Declaratory policy is directed toward adversaries as much as it is to 
the declaring nation itself. A declaratory policy is intended, in part, to sig
-nal to an adversary what the declaring nation™s responses might be under 

various circumstances. On the other hand, a declaratory policy may also 

be couched deliberately in somewhat ambiguous terms, leaving some
-what vague and uncertain the circumstances under which the declaring 

nation would use nuclear weapons. Such vagueness and uncertainty have 

historically been regarded by the United States as a strength rather than 
2 Joint Chiefs of Staff, 
The National Military Strategy of the United States of America, 
2004, 
available at http://www.strategicstudiesinstitute.army.mil/pdf˜les/nms2004.pdf.
3 See http://www.state.gov/t/ac/trt/4718.htm.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.216
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
a weakness of such policies, on the grounds that uncertainty about a U.S. 
response is an essential part of deterring other nations from taking hostile 
action against its interests. By contrast, a declaratory policy that is highly 

explicit may be perceived as limiting a nation™s options in a crisis and 

telegraphing its intent to some extent, thus simplifying an adversary™s 

planning process.
Yet another related issue is whether another nation should believe 
a nation™s declaratory policy. For example, the Soviet Union formally 

adopted an explicit ﬁno-˜rst-useﬂ policy regarding nuclear weapons in 

1982, but many military analysts gave little credence to that statement. 

On one hand, no immutable law mandates consistency between prior 

declaratory policy and subsequent action, and declaratory policy need 

not constrain actual practice. On the other hand, declaratory policy may 

in˚uence a nation™s armed forces™ training and doctrine. If, for example, 

the declaratory policy states that a nation will not use weapon 
X, and its 
armed forces do not train to use weapon 
X, and its military doctrine does 
not contemplate the use of weapon 
X, that nation may well be ill-prepared 
to use weapon 
X in practice even if its leaders decide to act in violation of 
the stated declaratory policy.
6.1.1.2
 Present Status
For the use of cyberweapons, the United States has no declaratory 
policy, although the DOD Information Operations Roadmap of 2003 stated 

that ﬁthe USG should have a declaratory policy on the use of cyberspace for 

offensive cyber operations.ﬂ The 2006 
National Military Strategy for Cyberspace 
Operations
 indicates that ﬁas a war-˜ghting domain . . . cyberspace favors 
the offense . . . an opportunity to gain and maintain the initiative.ﬂ
4 This 
statement is the beginning of a declaratory policy, but it is incomplete.
A declaratory policy would have to answer several questions. 

For what purposes does the United States maintain a capability for 
cyberattack?

Do cyberattack capabilities exist to ˜ght wars and to engage in 
covert intelligence or military activity if necessary, or do they exist primar
-ily to deter others from launching cyberattacks on the United States? 

If they exist to ˜ght wars, are they to be used in a limited fashion? 
On the basis of what is known publicly, it is possible to formulate 
what might be called an implied declaratory policy of the United States 
on cyberwarfare. (Of course, the notion of an implied declaratory policy 
4 See http://www.dod.mil/pubs/foi/ojcs/07-F-2105doc1.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 217
is itself an oxymoronŠa declaratory policy that is not explicitly stated is 
hardly declaratory. Rather, what follows below is an example of a declara
-tory policy that would be consistent with what is known publicly.)
The United States acquires cyberattack capabilities as part of its overall 
deterrent posture, which is based on full spectrum dominanceŠthe abil
-ity to control any situation or defeat any adversary across the range of 
military operations. Cyberattack capabilities provide the U.S. military 
and intelligence communities with additional options for action and 

use, and are thus intended for use just as any other weapons could be 

used in support of U.S. military or intelligence objectives. Cyberattack 
capabilities are to be fully integrated into U.S. military operations when 
appropriate, and distinctions between cyberattack and kinetic force are 

not meaningful except in an operational context. Cyberattack capabilities 

may be particularly useful to the United States in many con˚ict scenarios 

short of all-out war.
In addition, two other questions are often included under the rubric 
of declaratory policy:

How is cybercon˚ict to be stopped? 

To the extent that cyberattack is part of the U.S. deterrent posture, 
how can its use be established as a credible threat?
In the nuclear domain, concerns have always been raised about 
nuclear strikes against an adversary™s strategic command and control 
system. The issue has been that such strikes could seriously impair war 

termination efforts by disconnecting the political leadership of a nation 

from the nuclear-armed forces under its control, leaving the question of 

how nuclear hostilities might be terminated. 
The use of large-scale cyberattacks against the communications infra
-structure of an adversary might well lead to similar concerns. Such attacks 

could result in the effective disconnection of forces in the ˜eld from the 

adversary™s national command authority, or sow doubt and uncertainty in 

an adversary™s military forces about the reliability of instructions received 

over their communications infrastructure. Again, under such circum
-stances, termination of hostilities might prove problematic (and if the 

adversary were a nuclear-armed nation, sowing such doubt might seri
-ously run counter to U.S. interests).
Regarding the credibility of nuclear use, the United States does much 
through its declaratory (and acquisition) policy to encourage the percep
-tion that there are circumstances under which the United States 
might
 use 
nuclear weapons, and it conducts large-scale military exercises involv
-ing nuclear forces in part to demonstrate to the world that it is capable 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.218
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
of mustering nuclear forces that could be brought to bear in any given 
situation. 
The situation is entirely reversed with respect to cyberwarfare. U.S. 
policy regarding the use of cyberweapons is shrouded in secrecy, and the 
lack of public discussion regarding U.S. policy in this domain almost by 

de˜nition does not contribute to deterrence.
Finally, the 
National Military Strategy of the United States of America
 of 
2004 also states:
5The term WMD/E relates to a broad range of adversary capabilities 
that pose potentially devastating impacts. WMD/E includes chemical, 

biological, radiological, nuclear, and enhanced high explosive weapons 
as well as other, more asymmetrical ﬁweapons.ﬂ They may rely more on 
disruptive impact than destructive kinetic effects. For example, cyber 

attacks on US commercial information systems or attacks against trans
-portation networks may have a greater economic or psychological effect 
than a relatively small release of a lethal agent.
Coupled with the declaratory policy on nuclear weapons described 
earlier, this statement implies that the United States will regard certain 
kinds of cyberattacks against the United States as being in the same 

category as nuclear, biological, and chemical weapons, and thus that a 

nuclear response to certain kinds of cyberattack (namely, cyberattacks 

with devastating impacts) may be possible. It also sets the relevant scaleŠ

a cyberattack that has an impact larger than that associated with a rela
-tively small release of a lethal agent is regarded with the same or greater 

seriousness.
6.1.1.3
 Alternative Declaratory Policies
Simply as illustration (and not as endorsement), the following dis
-cussion incorporates and addresses hypothetical declaratory policies (or 

elements thereof) regarding cyberattack.
Ł  
No large-scale cyberattacks. 
Although weapons for cyberattack are 
valid and legitimate military weapons to be deployed and used 

in support of U.S. interests, the United States will unilaterally 

refrain from conducting against nations cyberattacks that would 

have the potential for causing widespread societal devastation and 

chaos. Accordingly, the United States will refrain from conducting 

cyberattacks against a nation™s electric power grids and ˜nancial 
5 Joint Chiefs of Staff, 
The National Military Strategy of the United States of America, 
2004, 
available at http://www.strategicstudiesinstitute.army.mil/pdf˜les/nms2004.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 219
systems if such attacks would have a signi˜cant potential for affect
-ing national economies.
Such a policy would seek to delegitimize the use of large-scale cyber
-attacks as an instrument of national policy by any nation in much the 
same way that the unilateral U.S. renunciation of biological weapons 

contributed to stigmatizing use of such weapons by any nation. The ben
-e˜t to the United States if such stigmatization occurred would be a lower 

likelihood that it would experience such an attack.
Ł  
No ˚rst use of large-scale cyberattacks. 
Although weapons for cyberat
-tack are valid and legitimate military weapons to be deployed and 

used in support of U.S. interests, the United States will not be the 

˜rst nation in a con˚ict to conduct against nations cyberattacks that 

would have the potential of causing widespread societal devasta
-tion and chaos. Nevertheless, the United States reserves the right 

to conduct such attacks should it be subject to such attacks itself.
Such a policy would seek to discourage the use of large-scale cyberat
-tacks as an instrument of national policy by any nation. However, the U.S. 

stance on the use of large-scale cyberattacks would be based primarily 

on threatening in-kind retaliation rather than setting an example. As in 

the previous case, the bene˜t to the United States if such stigmatization 

occurred would be a lower likelihood that it would experience such an 

attack.
Ł  
No ˚rst use of cyberattacks through the Internet and other public net
-works
. The U.S. government will refrain from using the Internet 
and other public networks to conduct damaging or destructive 

acts, and will seek to prevent individuals and organizations within 

its authority from doing so, as long as other nations do the same.
Such a policy would seek to discourage the use of cyberattacks 
through the Internet as an instrument of national policy by any nation, 

presumably based on a rationale that sees the Internet as a global public 

utility whose bene˜ts to the world™s nations are outweighed by any tem
-porary military advantage that might be gained through Internet-based 

cyberattacks. Again, the U.S. stance on the use of such cyberattacks would 

be based primarily on threatening in-kind retaliation rather than example-

setting. The bene˜t to the United States would be that it (and especially 

its civilian sector) would be more likely to continue to enjoy the bene˜ts 

of Internet connectivity.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.22
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Ł  
National responsibility for cyberattacks. 
Nations are responsible for 
cyberattacks that emanate from their soil, whether or not their 
national governments have initiated such actions. If they have not, 

national governments are responsible for taking actions that lead 

or help lead to the cessation of such actions. The United States 

reserves the right to take unilateral action if a nation fails to take 

action to respond to cyberattacks emanating from its soil.
Such a policy would codify for cyberattack a legal principle that is 
foundational to international law regarding neutrality, self-defense, and 

the laws of armed con˚ict (discussed further in Chapter 7)Šthat nations 

are responsible for military conduct emanating from their territories and 

affecting other nations. The bene˜t of such a policy would be to make 

explicit what is already U.S. policy regarding kinetic attacks.
6.1.1.4
  
The Relationship Between Declaratory Policy and 

International Agreements
Declaratory policy might also be replaced or complemented by bilat
-eral or multilateral agreements, much as nations have sometimes agreed 

to certain standards of behavior for their navies on the high seas when 

interacting with the navies of nations also party to those agreements. This 

point is addressed in more detail in Chapter 10.
6.1.2
 Acquisition Policy
The acquisition of capabilities is, in principle, driven by statements 
of needŠthat is, how the U.S. military (for instance) may effectively take 

advantage of a given capability. Much has been written about the drivers 

of military acquisition, and a key driver that emerges from these writ
-ings is the anticipation that an adversary has or will acquire a particular 

military capability to which the nation must respond quickly by itself 

acquiring a similar or countering capability.
6 Acquisition policy addresses issues such as how much should be 
spent on weapons of various kinds, how many of what kind should be 

acquired on what timetable, and what the characteristics of these weapons 

should be. A statement of acquisition policy regarding nuclear weapons 

might say something like ﬁthe United States must deploy in the next 

2 decades 500 land-based new ICBMs with 10 nuclear warheads apiece, 
6 See, for example, Stephen Rosen, Chapter 7, ﬁWhat Is the Enemy Building?ﬂ in 
Win
-ning the Next War: Inno
vation and the Modern Military
, Cornell University Press, Ithaca, N.Y., 
1991. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 221
each with a kill probability (P
k) of 90 percent against targets hardened to 
withstand overpressures of 2000 pounds per square inch.ﬂ For a standoff 
munition, a statement of acquisition policy might say something like ﬁthe 

United States must acquire, at a rate of 1000 per year, a standoff ‚˜re-and-

forget™ munition carrying a 250-pound explosive warhead capable of 

being launched from a range of 30 kilometers with a Circular Error Prob
-able of 1 meter against moving targets under all weather and battle˜eld 

conditions.ﬂ 
The acquisition process also requires that a weapon in acquisition be 
subject to an internal review prior to production to determine if use of 

the weapon would con˚ict with existing international obligations (e.g., 

arms control treaties or customary international standards of necessity, 

proportionality, and discrimination in the law of armed con˚ict). Not 

surprisingly, such review is undertaken using DOD interpretations of the 

law of armed con˚ict, which outside analysts sometimes criticize as being 

overly narrow. These reviews are generally not classi˜ed, but in general, 

they have not been made widely available.
Finally, the acquisition process requires that certain weapons undergo 
operational testing and evaluation before large-scale production. Opera
-tional testing and evaluation (OT/E) involves ˜eld testing under realis
-tic combat conditions for the purpose of determining the effectiveness 

and suitability of a weapon for use in combat by typical military users. 

However, only weapons procured through a major defense acquisition 

program are subject to this OT/E requirement, and in particular weapons 

procured through a highly sensitive classi˜ed program (as designated by 

the secretary of defense) are exempt from this requirement.
In principle, this process also applies to the acquisition of cyberweap
-ons, or more precisely, capabilities for cyberattack. (It would be rare that 

a ﬁcyberweaponﬂ takes the same form as a kinetic weapon, in the sense 

of a package that can be given to a military operator as a ri˚e or a ˜ghter 

jet can be given. Rather, operators who launch cyberattacks are likely to 

have a variety of tools at their disposal for conducting an attack.) But 

acquiring capabilities (tools) for cyberattack differs in important ways 

from acquiring ordinary weapons, raising a number of issues for the 

acquisition process. 
For example, the rapid pace of information technology change places 
great stress on acquisition processes for cyberattack capabilities (and for 

cyberdefense as well). A second important point is that the acquisition cost 

of software-based cyberattack tools is almost entirely borne in research 

and development, since they can be duplicated at near-zero incremental 

cost. By contrast, procurement is a major portion of the acquisition cost 

for kinetic weapons. Thus, a testing and evaluation (T/E) regime timed 

to occur after R&D is unlikely to apply to cyberweapons. The absolute 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.222
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
acquisition cost of cyberweapons is also likely to be signi˜cantly smaller 
than those of kinetic weapons, thus exempting cyberweapons from T/E 
regimes linked to acquisition cost.
7A third point is that the acquisition process presumes that it is the 
only way to procure weapons. But cyberattack capabilities are so inex
-pensive to acquire that they could be acquired through operations and 

maintenance (O/M) funds (and may be legal as well). For example, under 

the rubric of upgrading the cybersecurity posture of an installation, a sys
-tem administrator might well obtain tools designed to test its computer 

security (that is, to support a ﬁred teamﬂ penetration test) and acquire 

these tools through O/M funds. But these very same tools could provide 

capabilities that could be used against adversary computers.
A second way to acquire cyberattack capability is to purchase services 
that provide them. For example, botnets (discussed in Section 2.2.5.1.1) 

can be rented at relatively low costŠinformed estimates vary, but are 

reported to be on the order of a few thousand dollars for a botnet consist
-ing of tens of thousands of zombies for a few days. Renting a botnet may 

be a much more ef˜cient method for acquiring the afforded capabilities 

than developing a botnet on one™s own, and indeed the Estonian minister 

of defense has asserted that the cyberattack on Estonia was conducted by 

botnets that were rented for that purpose.
8Of course, the rental of botnets contributes to the furtherance of a 
criminal enterprise, as the botnet owner/operator has broken U.S. law in 

assembling the botnet (presuming the owner/operator is subject to U.S. 

jurisdiction). An important policy question is whether it is appropriate for 

the United States to work with known criminals to pursue foreign policy 

objectives. More generally, the United States could ﬁoutsourceﬂ certain 

kinds of cyberattack to criminal hackers, especially if it wanted to leave 

no trace of such work, and incentivize such work by allowing the hackers 

to keep some or all of the ˜nancial resources they might encounter. Such 

cooperation has some precedent in U.S. historyŠfor example, the Cen
-tral Intelligence Agency sought to recruit the Ma˜a in 1960 to kill Fidel 

Castro
9Šthough such instances have hardly been uncontroversial.
Related is the fact that the computers of third parties, such as innocent 
7 For example, a major defense acquisition program is de˜ned by statute as one esti
-mated to require an eventual total expenditure for research, development, testing, and evalu
-ation of more than $300 million (in FY 1990 constant dollars) or an eventual total expenditure 
for procurement of more than $1.8 billion (in FY 1990 constant dollars). Programs for acquir
-ing cyberattack capabilities and tools are likely to cost far less than these amounts.
8 William Jackson, ﬁCyberattacks in the Present Tense, Estonian Says,ﬂ 
Go
vern
-ment Computing News
, November 28, 2007, available at http://www.gcn.com/online/
vol1_no1/45476-1.html.
9 Glenn Kessler, ﬁTrying to Kill Fidel Castro,ﬂ 
Washington Post
, June 27, 2007, p. A06.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 223
civilians in a nation of choice, might also be compromised in order to 
support a cyberattack. These computers can be con˜gured as ﬁweapons 
for cyberattackﬂ at will by the real attacker at essentially zero cost, even 

though they increase his attack capabilities by orders of magnitude, and 

because such scenarios were never envisioned by the traditional acquisi
-tion process, it is only a matter of policy that might inhibit the United 

States from doing so.
Acquisition policy should also address the issue of the proper balance 
of resource allocation. The absolute budget sums involved in acquir
-ing cyberattack capabilities are relatively small, as noted in Chapter 2. 

But serious defensive efforts are very expensive, not least for reasons of 

scaleŠthe sheer volume of computer systems and networks that must be 

protected. Thus, acquisition policy necessarily affects the balance between 

conventional military assets and cyber military assets and procedures on 

the defensive side. Given the dependence of today™s military forces on 

information technologies, some analysts have argued that present-day 

acquisition policies do not pay suf˜cient attention to cybersecurity and 

defensive operations.
The above discussion of acquisition policy relates primarily to the 
defense community. But the intelligence community must also acquire 

various capabilities to support its intelligence collection and covert action 

missions. Of particular signi˜cance for acquisition policy is that a tool 

to collect intelligence information from an adversary computer system 

or network canŠat little additional costŠbe modi˜ed to include certain 

attack capabilities, as described in Section 2.6. Indeed, the cost of doing 

so is likely to be so low that in the most usual cases, acquisition managers 

would probably equip a collection tool with such capabilities (or provide 

it with the ability to be modi˜ed on-the-˚y in actual use to have such 

capabilities) as a matter of routine practice.
6.1.3
 Employment Policy
Employment policy speci˜es how weapons can be used, what goals 
would be served by such use, and who may give the orders to use them. 

Such policy has a major in˚uence on how forces train (e.g., by driving the 

development and use of appropriate training scenarios).
One key question of employment policy relates to the necessary com
-mand and control arrangements. For example, although U.S. doctrine 

once did not differentiate between nuclear and non-nuclear weapons,
10
 10
 In 1954, President Eisenhower was asked at a press conference (March 16, 1954) 
whether small atomic weapons would be used if war broke out in the Far East. He said, ﬁYes, 
of course they would be used. In any combat where these things can be used on strictly mili
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.22
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
this is most surely not the case today. Nuclear weapons are universally 
regarded as worthy of special attention, policies, and procedures, and 
their use is tightly controlled and highly centralizedŠmore so than any 

other weapon in the U.S. arsenal. Whether similar arrangements will be 

made for cyberweapons in the future remains to be seen, although the 

discussion in Chapter 3 suggests that the command and control arrange
-ments of today are not as centralized.
A second key question of employment policy is the targets of such 
weapons. Some targets are off-limits by virtue of the LOAC and other 

relevant international law. But the propriety of attacking other kinds of 

targets is often determined by doctrine and views of the adversary.
For example, in the nuclear strategy of the Cold War, considerable 
debate arose about the propriety of targeting adversary nuclear forces. 

Advocates of prompt hard-target kill capabilities (that would use a bal
-listic missile against a hardened adversary missile silo) argued that the 

adversary (generally the leaders of the Soviet Union) placed great value 

on their instruments of national power, such as their nuclear forces, and 

that placing such instruments at risk would help to deter actions that 

worked against the interests of the United States. Opponents of such 

targeting argued that threatening to destroy such targets only increased 

the likelihood that the adversary would launch its missiles on warning of 

attack, thus making accidental launch more likely.
Given that there are no cyber equivalents of hardened missile silos 
that constitute an adversary™s retaliatory forces, no credible threat of 

annihilation, and no equivalent of launch on warning for cyber forces, 

nuclear strategy does not provide guidance for cyber targeting. What 

targets might or might not be appropriate for cyberattack and under 

what circumstances would this be so? From what can be determined from 

public statements, the DOD believes that cyberattack has military utility, 

and thus the use of cyberattack is subject to constraints imposed by the 

law of armed con˚ict. 
At the same time and apart from the need to comply with the LOAC, 
good reasons may exist for eschewing certain kinds of cyberattack against 

certain kinds of target for reasons other than those related to operational 

ef˜cacy. For example, cyberwarfare provides tools that can be focused 

directly on messaging and in˚uencing the leadership of an adversary 
tary targets and for strictly military purposes, I see no reason why they shouldn™t be used 
just exactly as you would use a bullet or anything else.ﬂ (See Eisenhower National Historic 

Site, National Park Service, at http://www.nps.gov/archive/eise/quotes2.htm.) Indeed, in 

1953, the U.S. National Security Council noted that ﬁin the event of hostilities, the United 

States will consider nuclear weapons to be as available for use as other munitions.ﬂ (U.S. Na
-tional Security Council (NSC), ﬁBasic National Security Policy,ﬂ NSC Memorandum 162/2, 

October 30, 1953, available at http://www.fas.org/irp/offdocs/nsc-hst/nsc-162-2.pdf.) 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 225
state. Message-based in˚uence might help to persuade the leadership 
to make decisions helpful to U.S. national interests, such as terminating 
hostilities or refraining from using weapons of mass destruction. But at 

the same time, it may be undesirable to conduct destructive or disruptive 

attacks on the command and control systems that connect the adversary™s 

national command authority to forces in the ˜eld. 
Disconnecting an adversary™s forces from their leadership may result 
in serious dysfunction, uncoordinated action, and psychological impact 

on the adversary such as fear and poor morale. Such positive effects must 

be balanced against possible negative effects, such as the inability of the 

adversary™s leadership to direct its forces to surrender or to stand down. 

In addition, if forces in the ˜eld lose con˜dence in the authoritativeness of 

commands from their national command authority, they may resort to fol
-lowing standing orders issued before the con˚ict beganŠand such orders 

may well instruct these forces to act in more destructive ways than they 

otherwise would. These considerations are particularly important if the 

adversary has nuclear weapons and if the cyberattack cannot differentiate 

between command and control systems for the adversary™s conventional 

and nuclear forces.
Other possible targets to be avoided may include those that could 
have signi˜cantly damaging effects on large numbers of non-combat
-ants. Entirely apart from the moral and ethical issues raised by such 

attacks, conducting such attacks against a nation with a declared policy 

of responding to such attacks with nuclear weapons arguably increases 

the likelihood that such weapons would be used. Targets in this category 

might include national ˜nancial systems and electric power grids.
Cyberattacks may be a preferred method for targeting infrastruc
-ture under some circumstances. The United States may wish to conduct 

operations related to war recovery and stabilization in the aftermath of a 

con˚ict, and thus wish to preserve infrastructure as an important element 

in war recoveryŠthe U.S. intent in Operation Iraqi Freedom (the Second 

Gulf War) in 2003 was to occupy Baghdad for some period of time there
-after and to enable Iraq to function as a sovereign nation. In its targeting 

of Iraqi infrastructure, the United States had to consider the possibility 

that destroying parts of it (e.g., the electric power grid) might impede 

war recovery efforts after the con˚ict. If cyberattacks made it possible to 

attack infrastructure in such a way that it was rendered non-functional for 

the duration of a con˚ict but could be easily restored to normal operation 

after the con˚ict was terminated, attack planners would have consider
-able incentives to prefer such attacks over more destructive ones.
A second issue relates to options for strategic use. As with nuclear 
weapons, the availability of preplanned options for cyberattack varying 

in scale, scope, and timing would increase ˚exibility and the ability to 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.226
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
respond promptly to various strategic contingencies. A number of impor
-tant questions arise in this contextŠthe large amount of intelligence infor
-mation likely to be needed for such options, the timeliness of information 
collected to support preplanned options, and indeed the actual value of 

prompt cyber response under various circumstances.
A third important issue is ensuring that cyberattack activities are suf
-˜ciently visible to higher authorities, including the political leadership. It 

is an unfortunate reality that during times of crisis, military actions that 

would normally be regarded as routine or ﬁsmallﬂ can lead to mispercep
-tions of strategic signi˜cance. For example, routine air reconnaissance 

undertaken during times of crisis can be interpreted as a prelude to attack. 

In a cyberattack context, analogs could include the routine gathering of 

intelligence that is needed to support a cyberattack (e.g., port scans of 

Zendian systems) or the self-defense neutralization of an active cyber
-attack threat from a Zendian patriotic hacker under standing rules of 

engagement. The possibility is very real that Zendian authorities might 

perceive such activities as aggressive actions associated with a planned 

and deliberate cyberattack by the United States.
Keeping the political leadership informed of such activities is a prob
-lem even when considering traditional military operations. But because 

the resources and assets needed to conduct cyberattacks are small by 

comparison and the potential impact still large, it may be more dif˜
-cult for higher authorities to stay informed about activities related to 

cyberattack.
Finally, the United States has a long-standing policy not to use cyber
-attack or cyberexploitation to obtain economic advantage for private com
-panies (as noted in Section 4.1.2). However, the economic domain is one 

in which the operational policies of adversaries are markedly different 

from those of the United States. That is, adversaries of the United Staes 

are widely believed to conduct cyber-espionage for economic advan
-tageŠstealing trade secrets and other information that might help them 

to gain competitive advantage in the world marketplace and/or over U.S. 

˜rms. As noted in Section 2.6.2, the intelligence services of at least one 

major nation-state were explicitly tasked with gathering intelligence for 

its potential economic bene˜ts. This asymmetry between U.S. and foreign 

policies regarding cyberexploitation is notable.
The committee also observes that national policy makers frequently 
refer to a major and signi˜cant cyberthreat against the United States 

emanating from many actors, including major nation-states. The result 

in recent years has been an upsurge of concern about the disadvantaged 

position of the United States in the domain of cybercon˚ict, and is most 

recently re˚ected in the still largely classi˜ed Comprehensive National 

Cybersecurity Initiative resulting from the National Security Presiden
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 227
tial Directive 54/Homeland Security Presidential Directive 23 of January 
2008.
11
On the other hand, the committee™s work has underscored many of 
the uncertainties that underlie any serious attempt by the United States 
to use cyberattack as an instrument of national policy. Moreover, military 

planners often engage in worst-case planning, which assumes that more 

things will go right for an adversary than for oneself. Thus, attack plan
-ners emphasize the uncertainties of an attack and assume that the defense 

will be maximally prepared and lucky. Defensive planners emphasize the 

uncertainties of defense and assume that the attacker will be maximally 

prepared and lucky. 
In short, the committee sees a marked asymmetry in the U.S. percep
-tion of cyberattackŠﬁtheyﬂ (the adversary) are using cyberattack means 

effectively against us (the United States), but it would be dif˜cult (though 

not impossible) for us to use such means effectively against them. 
The question thus arises, What might be responsible for this percep
-tion? One factor is the con˚ation of cyberattack and cyberexploitation 

in the public discourse (see Box 1.4 in Chapter 1). As noted by General 

Kevin Chilton, commander of the U.S. Strategic Command, many of the 

incidents that are billed as cyberattacks are, more accurately, just old-fash
-ioned espionageŠpeople looking for information who don™t necessarily 

represent military threats.
12
 Thus, if the public discourse uses the term 
ﬁcyberattackﬂ (what this discussion calls cyberattack-AUIPD, for ﬁcyber
-attack as used in public discourse,ﬂ to distinguish usages) to include 

cyberexploitation, then the balance is between adversary cyberattacks-

AUIPD (which would include what this report terms ﬁcyberattackﬂ [note 

absence of a tag] and which are largely espionage conducted for economic 

bene˜t) and U.S. ﬁcyberattacks-AUIPDﬂ (which by policy do not involve 

either cyberattack or cyberexploitation conducted for economic bene˜t), 

and in such a balance, adversary cyberattacks-AUIPD will obviously 

seem to be much more effective than those of the United States.
A third important factor contributing to this perception is the fact 
11
 Public reports indicate that this initiative has 12 components intended to reduce to 100 
or fewer the number of connections from federal agencies to external computer networks, 
and to make other improvements in intrusion detection, intrusion prevention, research and 

development, situational awareness, cyber counterintelligence, classi˜ed network security, 

cyber education and training, implementation of information security technologies, deter
-rence strategies, global supply chain security, and public/private collaboration. The cost of 

this initiative has been estimated at $40 billion. See, for example, Jill R. Aitoro, ﬁNational 

Cyber Security Initiative Will Have a Dozen Parts,ﬂ 
Nextgo
v, August 1, 2008, available at 
http://www.nextgov.com/nextgov/ng_20080801_9053.php.
12
 Wyatt Kash, ﬁCyber Chief Argues for New Approaches,ﬂ 
Go
vernment Computer News,
 August 22, 2008, available at http://gcn.com/articles/2008/08/22/cyber-chief-argues-for-

new-approaches.aspx.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.228
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
that as noted in earlier chapters, the United States provides only limited 
assistance to the private sector when it comes under cyberattack and 
restricts the ability of the private sector to engage in self-help activities (as 

discussed in Section 5.2), and it refrains from sharing intelligence informa
-tion that would bene˜t individual private sector companies (as discussed 

in Section 4.1). Some other nations do not practice such restraint. The com
-mittee speculates that this asymmetry in policy may account for at least 

some of the perception of asymmetric advantage derived by others.
If these observations are accurate, whatŠif anythingŠcan be 
done
 about it?
Regarding the con˚ation of cyberattack and cyberexploitation in pub
-lic discourse, there is no remedy except to insist that a user of the term 

ﬁcyberattackﬂ make clear what is included under the rubric of the term 

he or she is using. If the many foreign cyberexploitation efforts were not 

described as ﬁcyberattack,ﬂ the level of tension over cyberattack would 

be knocked down to a considerable degree.
The case for the current U.S. policy regarding eschewing the use of 
U.S. intelligence agencies for the bene˜t of private ˜rms is largely based 

on the desire of the United States to uphold a robust legal regime for the 

protection of intellectual property and for a level playing ˜eld to enable 

competitors from different countries to make their best business cases 

on their merits. If this policy position is to be revised, it seems that two 

of the most prominent possibilities are that (1) intelligence gathering for 

economic purposes ceases for all nations, or (2) the United States uses 

its intelligence-gathering capabilities (including cyberexploitation) for 

economic purposes. Under traditional international law, espionageŠfor 

whatever purposeŠis not banned, and thus the ˜rst possibility suggests 

a need to revise the current international legal regime with respect to the 

propriety of state-sponsored economic espionage. The second possibility 

raises the prospect that current restraints on U.S. policy regarding intel
-ligence collection for the bene˜t of private ˜rms might be relaxed.
Both of these possibilities
 would be controversial, and the commit
-tee
 takes
 no stand on them, except to note some of the problems associated 
with each of them. The ˜rstŠa change in the international legal regime to 

prohibit espionageŠwould require a consensus among the major nations 

of the world, and such a consensus is not likely. The secondŠa unilateral 

change in U.S. policyŠdoes not require an international consensus, but 

has many other dif˜culties. For example, the U.S. government would 

have to decide which private ˜rms should bene˜t from the government™s 

activities, and even what entities should count as a ﬁU.S. ˜rm.ﬂ U.S. gov
-ernment at the state and local level might well ˜nd that the prospect of 

U.S. intelligence agencies being used to help private ˜rms would not sit 

well with foreign companies that they were trying to persuade to relocate 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 229
to the United States. And it might well undercut the basis on which the 
United States could object to other nations conducting such activities for 
the bene˜t of their own domestic industries and lead to a ﬁWild Westﬂ 

environment in which anything goes.
After all is said and done, it may turn out that the most desirable 
(least undesirable) option for the United States is to learn to live with the 

current asymmetry. But if that is indeed the case, it should re˚ect a delib
-erate and considered assessment of the pros and cons of various options 

that in the committee™s view has not yet been engaged.
6.1.4
 Operational Oversight
Operations translate employment policy into reality. In practice, the 
U.S. armed forces operate on a worldwide basis and have many ongoing 

operations at any given time. For example, they constantly gather intelli
-gence and reconnaissance information. Some of those operations are sensi
-tive, in that they might be seen as provocative or otherwise inappropriate.
Thus, the U.S. government has established a variety of mechanisms 
intended to ensure that such operations are properly overseen. For 

example, the U.S. government sometimes speci˜es criteria in advance 

that de˜ne certain sensitive military missions, and then requires that 

all such missions be brought to the attention of senior decision makers 

(e.g., the National Security Council staff). In rare cases, a mission must be 

approved individually; more typically, generic authority is granted for a 

set of missions that might be carried out over a period of many months 

(for example). The ˜ndings and noti˜cation process for covert action is 

another mechanism for keeping the executive and legislative branches 

properly informed. From time to time these mechanisms are unsuccessful 

in informing senior decision makers, and it is often because the individual 

ordering the execution of that mission did not believe that such an order 

required consultation with higher authority.
In a cyberattack context, oversight issues arise at two stagesŠat the 
actual launch of a cyberattack and in activities designed for intelligence 

preparation of the battle˜eld to support a cyberattack.
6.1.4.1
 Launching a Cyberattack
Another important operational issue involves delegation of authority 
to launch a cyberattack as part of an active defense of U.S. computer sys
-tems and networks. As noted in Chapter 3, the U.S. Strategic Command 

has authority to conduct such attacks for active defense under a limited 

set of circumstances. But it is not known how far down the chain of com
-mand such authority has been delegated. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.23
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
The most extreme form of delegation would call for an entirely auto
-mated active defenseŠand indeed the U.S. Air Force has issued a call for 
proposals to develop a ﬁcyber control systemﬂ that ﬁwill enable active 

defense operations [involving] automated responses (based on prede˜ned 

Rules of Engagement) . . . , in response to network intrusions/attacks.ﬂ
13
 Automated responses are regarded as being militarily necessary when 

there is insuf˜cient time for humans to make decisions about the nature of 

a response and any given situation may present insuf˜cient time because 

of the ˚eeting nature of the opportunity to strike back or because of the 

harm that rapidly accrues if the attack is not stopped (though consider
-ation of other factors such as appropriate rules of engagement may pre
-vent such weapons from being deployed in any given situation). Both of 

these factors could characterize certain kinds of cyberattacks on certain 

targets in the United States.
On the other hand, the risks of error or inadvertent escalation are gen
-erally regarded as greatest when humans are not in the decision-making 

loop. Despite periodic calls for the nuclear command and control system 

to be automated so as to ensure that retaliation would take place in the 

event of a Soviet nuclear attack, the United States has always relied on 

humans (the President and the National Command Authority) to make 

the ultimate decision to release U.S. strategic forces. (Even so, many have 

criticized these arrangements as pro forma, arguing that in practice they 

are not much better than an automated launch decision, because they give 

the NCA too little time to evaluate the information available about the 

alleged incoming attack.)
An assessment of the wisdom of an automated response to a cyberat
-tack depends on several factors, including the likelihood that adequate 

and correct information will be available in a short period of time to 

develop an access path back to the attacker, the likely consequences of a 

cyberattack response, and the possible consequences of a misdirected or 

inappropriately launched counterattack. In the case of nuclear command 

and control, these factorsŠprimarily the lastŠindicate that an automated 

response would be foolish and foolhardy.
6.1.4.2
  
Conducting Intelligence Preparation of the Battle˚eld to 
Support a Cyberattack
In principle, conducting intelligence preparation of the battle˜eld 
(IPB) to support a cyberattack is not different from conducting other 

non-destructive cyberexploitation missions. For example, U.S. electronic 
13
 United Press International, ﬁAir Force Seeks Automated Cyber-response,ﬂ Jan. 2, 
2008, at 4:55 p.m.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 231
reconnaissance airplanes often ˚y missions near the border of another 
nation in order to ﬁlight upﬂ that nation™s air defense radars. By moni
-toring those radar emissions, they collect information on the waveforms 
and positions of a potential adversary™s radar systems; such information 

could be useful in the event that an air strike might be launched against 

that nation.
On the other hand, that nation might well regard those reconnais
-sance ˚ights as provocative. The airplane it is monitoring just outside its 

airspace could be armed, and the plane™s presence there could indicate 

hostile intent. The essential problem is that the boundaries of its national 

airspace provide almost no time for its air defense forces to react should 

the airplane turn out to have immediate hostile intent. Even if it is known 

to be unarmed, it is most likely to be a reconnaissance airplane collect
-ing information that could be useful in the event that an air strike was 

launched against that nation. If these reconnaissance ˚ights were taking 

place during a period of peacetime tension with the United States, it is 

easy to see how they might further exacerbate those tensions.
Missions of this kind fall squarely into the category of those that must 
be reported to senior policy makers. The IPB mission for a destructive 

cyberattack falls into the same category. In order to gather the necessary 

intelligence, an adversary™s network must be mapped to establish topol
-ogy (which nodes are connected to which other nodes). Ports are ﬁpingedﬂ 

to determine what services are (perhaps inadvertently) left open to an 

outside intruder, physical access points are located and mapped, operat
-ing system and application vulnerabilities are identi˜ed, sympathizers 

with important access privileges are cultivated, and so on.
However, there are at least three important differences between IPB 
for cyberattack and other kinds of intelligence collection. First, a U.S. gov
-ernment effort to conduct IPB for many kinds of cyberattack will be taking 

place against a background of other activities (e.g., probes and pings) that 

are not being conducted by the U.S. government. Second, network con
-nectivity may be such that ﬁlimitedﬂ intelligence probes and other inves
-tigations of a potential adversary™s networks will inadvertently reach very 

sensitive areas. Third, the dividing line between a tool intended to collect 

information on an adversary™s systems and a weapon intended to destroy 

parts of those systems may be very unclear indeed. 
The ˜rst factor above may reduce the sensitivity of the nation being 
probedŠand indeed, the U.S. IPB effort is likely to be undertaken in 

a way that does not reveal its origin. But the second two factors may 

increase sensitivity, and possibly lead to entirely unanticipated reactions 

on the part of the adversary.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.232
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
6.2
 LEGISLATIVE
 B
RANCH
The legislative branch has two basic roles regarding government 
operationsŠbudget and oversight. In addition, the Constitution gives 
the legislative branch the sole authority to declare war.
6.2.1
 Warmaking Powers
Article I, Section 8 of the U.S. Constitution authorizes the Congress 
to ﬁdeclare warﬂ and gives Congress numerous powers over the military, 

including the powers to ﬁraise and support armies,ﬂ to ﬁprovide and 

maintain a navy,ﬂ and to ﬁmake rules for the government and regulation 

of the land and naval forces.ﬂ Article II, Section 2 gives the President the 

ﬁexecutive powerﬂ and provides that he ﬁshall be commander in chief of 

the Army and Navy of the United States.ﬂ 
 At the time the Constitution was written, the primary purpose 
of national armed forces was to ˜ght wars, and these provisions were 

intended to give Congress primary responsibility for the decision to ini
-tiate war, and to give the President the primary responsibility for the 

conduct of war.
14
 Over time, as the international powers and responsi
-bilities of the United States have grown, and as the standing U.S. armed 

forces have grown, the President has asserted more and more authority 

to initiate armed con˚icts in the absence of authorization from Congress. 

Moreover, it has been argued that the notion of declaring war as a prelude 

to armed combat is simply irrelevant in the modern world.
Self-defense is the least controversial basis for the president to direct 
the armed forces to engage in combat. Madison said at the Convention 

that the ﬁdeclare warﬂ clause left to the President the power to ﬁrepel sud
-den attacksﬂ without congressional authorization.
15
 The Supreme Court 
upheld Lincoln™s authority to act against the confederacy in the absence 

of congressional authorization.
16
 President Clinton invoked self-defense 
in justifying the 1993 cruise missile strikes on Iraq in response to the 

attempted assassination of President George H.W. Bush.
17
  For some of the instances not involving self-defense in which U.S. 
armed forces have been deployed and used, presidents have sought and 
14
 See, e.g., Abraham D. Sofaer, 
War, Foreign Affairs and Constitutional Power: The Origins
, Ballinger Publishing, Cambridge, Mass.,
 1976. 
15
 The Records of the Federal Convention of 1787, at 318 (1911), Max Farrand, ed., rev. 
edition, 1966.
16
 See Prize Cases, 67 U.S. 635 (1863) (ﬁIf a war be made by invasion of a foreign nation, 
the President is not only authorized but bound to resist force by forceﬂ).
17
 See ﬁLetter to Congressional Leaders on the Strike on Iraqi Intelligence Headquar
-ters,ﬂ Pub. Papers of William J. Clinton 940, 1993.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 233
received explicit congressional authorization, although they have always 
claimed that their authority as commanders-in-chief was suf˜cient to 
take such actions and that in essence seeking congressional authorization 

was a courtesy extended to the legislative body. But matters are more 

complicated and controversial when the President acts without invoking 

self-defense and also without congressional authorization. 
The President has acted in such a manner in many circumstances 
in U.S. history, most notably in Korea and Kosovo, but also in dozens 

of other smaller-scale con˚icts. Presidents have asserted this authority, 

Congress often complains and opposes it, and the Supreme Court has not 

squarely addressed it.
To address such cases, Congress passed the War Powers Resolution 
(WPR) in 1973 (PL 93-148). Passed over then-President Nixon™s veto, the 

WPR requires the President to report to Congress in 48 hours ﬁin any case 

in which United States Armed Forces are introduced (1) into hostilities or 

into situations where imminent involvement in hostilities is clearly indi
-cated by the circumstances; (2) into the territory, airspace or waters of a 

foreign nation, while equipped for combat, except for deployments which 

relate solely to supply, replacement, repair, or training of such forces; or 

(3) in numbers which substantially enlarge United States Armed Forces 

equipped for combat [who are] already located in a foreign nation,ﬂ and 

requires the President to ﬁterminate any such use of armed forcesﬂ within 

60 days (subject to a one-time 30-day extension). 
The tensions between the executive and legislative branches of gov
-ernment over war-making authority are palpable. Many analysts believe 

that the intent of the Founding Fathers was to grant the Congress a sub
-stantial decision-making role in the use of U.S. armed forces, and if mod
-ern con˚ict has rendered obsolete the notion of a ﬁdeclaration of war,ﬂ 

mechanisms must still be found to ensure that Congress continues to play 

a meaningful role in this regard. Others acknowledge the obsolete nature 

of declarations of war, but conclude that executive branch authority can 

and should ˜ll the resulting lacunae.
This report does not seek to resolve this controversy, but observes that 
notions of cybercon˚ict and cyberattack will inevitably cause more confu
-sion and result in less clarity. Consider, for example, the meaning of the 

term ﬁhostilitiesﬂ in the War Powers Resolution. At the time the resolution 

was crafted, cyberattack was not a concept that had entered the vocabu
-lary of most military analysts. In the context of the resolution, hostilities 

refer to U.S. land, air, and naval units engaging in combat. The resolution 

also refers to the foreign deployments of combat-equipped U.S. forces. 
To the extent that the War Powers Resolution was intended to be a 
reassertion of congressional authority in warmaking, it is very poorly 

suited to U.S. forces that engage in cyber combat or launch cyberattacks. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.23
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
What conditions would de˜ne ﬁhostilitiesﬂ when military cyberattacks 
can be launched against adversary computers or networks? What counts 
as ﬁdeploymentsﬂ of forces capable of cyberattack into foreign territory? 

It is thus an open question whether a cyberattack launched by the United 

States would constitute the introduction of armed forces in another coun
-try within the meaning of the resolution.
When it comes to sorting out normative and practical issues con
-cerning congressional and presidential prerogatives, cyberwarfare poses 
issues
 even more dif˜cult for interpreting the War Powers Resolution than 
the already-dif˜cult issues associated with traditional kinetic con˚ict.
6.2.2
 Budget
In the preceding section, the relative invisibility of cyberattack activi
-ties is mentioned as a problem for higher authority. Cyberattack capa
-bilities are also not particularly visible to the legislative branch. In part, 

the veil of secrecy around cyberattack makes it more invisible than if 

the subject were not classi˜ed. But just as important is the fact that the 

funding for the development and deployment of cyberattack capabili
-ties is both minuscule and deliberately obscured in unclassi˜ed budget 

justi˜cations. 
For example, in the FY 2008 DOD budget request, one request for 
the ﬁdemonstration of offensive cyber operations technologies allowing 

attack and exploitation of adversary information systemsﬂ by the Air 

Force is contained in a program element component of $8.012 million; the 

program element is entitled ﬁAdvanced Technology Development,ﬂ and 

the component ﬁBattlespace Information Exchange.ﬂ
18
 A second request 
for developing cyber operations technologies is contained in a program 

element of $11.85 million for FY 2008; this program element is entitled 

ﬁApplied Research on Command, Control, and Communications.ﬂ
19
 A reasonable observation is that development and demonstration of 
cyberattack capabilities are distributed over multiple program elements, 
18
 See http://www.dtic.mil/descriptivesum/Y2008/AirForce/0603789F.pdf.
19
 In FY 2008, one component of this program element (ﬁcommunications technologyﬂ) 
called for activities to ﬁinitiate development of access techniques allowing ﬁcyber pathsﬂ to 
protected adversary information systems through a multiplicity of attack vectors; initiate 

development of stealth and persistence technologies enabling continued operation within 

the adversary information network; initiate programs to provide the capability to ex˜ltrate 

any and all types of information from compromised information systems enabling cyber 

intelligence gathering to achieve cyber awareness and understanding; initiate technology 

programs to deliver D5 (deny, degrade, destroy, disrupt, and deceive) effects to the adver
-sary information systems enabling integrated and synchronized cyber and traditional kinetic 

operations.ﬂ See http://www.dtic.mil/descriptivesum/Y2008/AirForce/0602702F.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.DECISION MAKING AND OVERSIGHT
 235
each of which is relatively small in ˜nancial terms. Budget oversight is 
thus dif˜cult to execute, even though it is intimately related to acquisition 
policy. In addition, the ability to increase certain attack capabilities ﬁfor 

freeﬂ (e.g., through the use of botnets and automated production func
-tions) negates to a considerable extent the ability of the legislative branch 

to use budget totals for restraining or limiting U.S. military capabilities.
A low budget pro˜le supports low visibility. Proponents of a given 
capability would prefer low visibility for programs supporting that capa
-bility, especially if the capability were controversial in nature. (Low vis
-ibility can also be achieved in other ways, such as by designating a pro
-gram as ﬁspecial access.ﬂ)
6.2.3
 Oversight (and Noti˚cation)
In addition to budgetary oversight, the legislative branch also pro
-vides operational oversight of government programs. For example, the 

executive branch is required by law (50 U.S.C. 413(a)(1)) to keep the 

congressional intelligence committees ﬁfully and currently informedﬂ 

of all U.S. intelligence activities, including any ﬁsigni˜cant anticipated 

intelligence activity.ﬂ
20
 Both intelligence gathering and covert action are 
included under this rubric, and thus cyberexploitation and covert action 

cyberattacks would have to be reported to these committees. These report
-ing requirements are subject to a number of exceptions pertaining to sen
-sitivity and possible compromise of intelligence sources and methods, or 

to the execution of an operation under extraordinary circumstances.
Certain DOD operations have also been subject to a noti˜cation 
requirement. Section 1208 of the FY 2005 Defense Authorization Act gave 

the secretary of defense the authority to expend up to $25 million in any 

˜scal year to ﬁprovide support to foreign forces, irregular forces, groups, 

or individuals engaged in supporting or facilitating ongoing military 

operations by United States special operations forces to combat terror
-ism.ﬂ In the event that these funds were used, the secretary of defense was 

required to notify the congressional defense committees expeditiously 

and in writing, and in any event in not less than 48 hours, of the use of 

such authority with respect to that operation. 
Yet another precedent for noti˜cation in support of oversight is the 
requirement for the attorney general to report annually to Congress and 

the Administrative Of˜ce of the United States Courts indicating the total 
20
 A discussion of this requirement can be found in Alfred Cumming, 
Statutory Pro
-cedures Under Which Congress Is to 
Be Informed of U.S. Intelligence Acti
vities, Including Co
vert 
Actions
, Congressional Research Service memo, January 18, 2006, available at http://www.
fas.org/sgp/crs/intel/m011806.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.236
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
number of applications made for orders and extensions of orders approv
-ing electronic surveillance under the Foreign Intelligence Surveillance 
Act, and the total number of such orders and extensions either granted, 

modi˜ed, or denied. 
To the best of the committee™s knowledge, no information on the 
scope, nature, or frequency of cyberattacks conducted by the United States 

has been made regularly or systematically available to the U.S. Congress 

on either a classi˜ed or an unclassi˜ed basis.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Part III
Intellectual Tools for Understanding 
and Thinking About Cyberattack
Cyberattack is a complex topic that is often oversimpli˜ed and/or 
demonized in popular accounts. Part III is intended to provide the reader 
with a variety of intellectual tools useful for thinking about cyberattack 

in its many forms and permutations.
Chapter 7 provides a primer on legal issues relevant to cyberattack, 
mostly related to international law. These issues arise because of the U.S. 

commitment to act in compliance with the international law of armed 

con˚ict and its treaty obligations (including that of the Charter of the 

United Nations) and because cyberattack presents various challenges in 

interpreting laws written and established to govern traditional kinetic 

warfare between nation-states. 
Chapter 8 examines a number of previously studied areas for pos
-sible lessons relevant to cyberattack. These include nuclear weapons and 

warfare, space as a domain of con˚ict, biological weapons, and non-lethal 

weapons. Chapter 8 will demonstrate that all of these areas have within 

them some relevant study or precedent, but that none of them carry over 

fully to cyberattack.
Chapter 9 presents some speculations on the dynamics of cybercon
-˚ict as it might involve the United States as a major player. Not much 

is known today about how such cybercon˚ict might start, and even less 

about how it would evolve over time. The best that can be done is to 

reason from analogy in a largely preliminary fashion, and that is the role 

of Chapter 9.
237
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.238
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Chapter 10 describes a variety of alternative futures. The current 
stance of the United States toward cyberattack is one that puts no con
-straints on its use apart from those imposed by the law of armed con˚ict 
and related customary international law. But other stances are possible, 

and from time to time proposals emerge that, if adopted, would constrain 

activities related to cyberattack undertaken by all nations, including the 

United States. Chapter 10 explores some of these proposals in notional 

form but does not take a stand one way or another on their inherent 

desirability.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.7Legal and Ethical Perspectives on 
Cyberattack
7.1
 THE
 B
ASIC
 F
RAMEWORK
  In the context of this chapter, international law refers to treaties (writ
-ten agreements among states governed by international law) and custom
-ary international law (general and consistent practices of states followed 
from a sense of legal obligation). Domestic law refers to the Constitution 

of the United States, federal statutes, and self-executing treaties
1 and can 
constrain the actions of government and of private individuals. 
This chapter focuses on the implications of existing international and 
domestic law as well as relevant ethical regimes for the use of cyberat
-tack by the United States.
 (It is thus not intended to address legal issues 
that arise mostly in the context of the United States defending against 
cyberattack.)
  Compared to kinetic weapons, weapons for cyberattack 
are a relatively recent addition to the arsenals that nations and other par
-ties can command as they engage in con˚ict with one another.
  Thus, the 
availability of cyberattack weapons for use by national governments natu
-rally raises questions about the extent to which existing legal and ethical 

perspectives on war and con˚ict and international relationsŠwhich affect 
1 In 2008, the Supreme Court explained that a self-executing treaty is one that ﬁoper
-ates of itself without the aid of any legislative provision,ﬂ and added that a treaty is ﬁnot 
domestic law unless Congress has either enacted implementing statutes or the treaty itself 

conveys an intention that it be ‚self-executing™ and is rati˜ed on these terms.ﬂ See 
Medellin 
v. Texas,
 128 S.Ct. 1346, 1356 (2008) (citations and internal quotations omitted).
239
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.240
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
considerations of how and when such weapons might be usedŠcould 
require reinterpretation or revision.
  Some analysts have responded to these questions in the negative, 
arguing that cyberweapons are no different than any other weapons and 
thus that no new legal or ethical analysis is needed to understand their 

proper use.
2  Others have taken the opposite view, arguing that cyber
-weapons are so different from kinetic weapons that new legal regimes are 

needed to govern their use.
3 Further, some argue that it is much easier to 
place substantive constraints
 on new military technologies before they 
have been integrated into the doctrine and structure of a nation™s armed 

forces. And still others have taken the view that although cyberweap
-ons do raise some new issues, the basic principles underlying existing 

legal and ethical regimes continue to be valid even though analytical 

work is needed to understand how these principles do/should apply to 

cyberweapons.
As is indicated below in this chapter, the committee™s perspective is 
most similar to the last one articulated above.
  Furthermore, the commit
-tee observes that in no small measure, the range of opinions and conclu
-sions about the need for new regimes comes from the fact that as indicated 

in Chapter 2, the notion of cyberattack spans an enormous range of scale, 

impact, and complexity. Some speci˜cation of a cyberattack™s range, scope, 

and purpose must be presented if analytical clarity is to be achieved.
This chapter does not attempt to provide a comprehensive norma
-tive analysis.
  Instead, it reviews the current international and domestic 
legal regimes, and suggests where existing regimes may be inadequate or 
ambiguous when the use of cyberweapons is contemplated.
  In addition, 
it explores issues that cyberattack may raise outside the realm of the rel
-evant legal regimes.
  In all instances, the emphasis is on raising questions, 
exploring ambiguities, and stimulating thought.
Although this report takes a Western perspective on ethics and human 
rights, the committee acknowledges that these views are not universal. 

That is, other religious and ethnic cultures have other ethical and human 

rights traditions and practices that overlap only partially with those of the 

United States or the West, and their ethical and human rights traditions 

may lead nations associated with these cultures to take a different per
-spective on ethical, human rights, and legal issues regarding cyberattack. 

Perhaps most importantly, other nations may take a more expansive or a 
2 This point of view was expressed in presentations to the committee by the USAF 
Cyberspace Task Force (brie˜ng of LTC Forrest Hare, January 27, 2007).
3 See, for example, Christopher C. Joyner and Catherine Lotrionte, ﬁInformation War
-fare as International Coercion: Elements of a Legal Framework,ﬂ 
European Journal of Interna
-tional Law
 12(5):825-865, 2001.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 241more restricted view of how the law of armed con˚ict constrains activities 
related to cyberattack.
Finally, it should be noted that legal considerations are only one set 
of factors that decision makers must take into account in deciding how 
to proceed in any given instance. There will no doubt be many circum
-stances in which the United States (or any other nation) would have a 
legal
 right to undertake a certain action, but might choose not to do so because 

that action would not be politically supportable or would be regarded as 

unproductive, unethical, or even harmful. 
7.2
 INTERNATIONAL
 LAW
 International obligations ˚ow from two sources: treaties (in this con
-text, the Charter of the United Nations, the Hague and Geneva Conven
-tions with their associated protocols, and the Cybercrime Convention) 

and customary international law. De˜ned as the customary practices of 

nations that are followed from a sense of legal obligation, customary inter
-national law has the same force under international law as a treaty.
Provisions of international law are sometimes enacted into national 
laws that are enforceable by domestic institutions (such as the President 

and courts). For example, Title 18, Section 2441 of the U.S. Code criminal
-izes the commission of war crimes and de˜nes war crimes as acts that 

constitute grave breaches of the Geneva or Hague Conventions. Such 

laws impose penalties on individuals who violate the relevant provisions 

of international law. 
When nations violate international law, the recourse mechanisms 
available are far less robust than in domestic law. For example, the Inter
-national Court of Justice has held speci˜c nations in violation of inter
-national law from time to time, but it lacks a coercive mechanism to 

penalize nations for such violations. In principle, the UN Security Council 

can call for coercive military action that forces a violator to comply with 

its resolutions, but the viability of such options in practice is subject to 

considerable debate.
7.2.1
 The Law of Armed Con˜ict
To understand the legal context surrounding cyberattack as an instru
-ment that one nation might deploy and use against another, it is helpful 

to start with existing lawŠthat is, the international law of armed con˚ict 

(LOAC). 
Today™s international law of armed con˚ict generally re˚ects two 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.242 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
central
 ethical principles.
4  First, a state that uses force or violence against 
another state must have ﬁgoodﬂ reasons for doing so, and indeed, through
-out most of history, states that have initiated violence against other states 
have sought to justify their behavior.
  Second, even if violent con˚ict 
between nations is inevitable from time to time, unnecessary human suf
-fering should be minimized.
LOAC addresses two separate questions. First, when is it legal for 
a nation to use force against another nation? This body of law is known 
as 
jus ad bellum
. Second, what are the rules that govern the behavior of 
combatants who are engaged in armed con˚ict? Known as 
jus in bello
, this 
body of law is separate and distinct from 
jus ad bellum
.7.2.1.1
 Jus ad Bellum
 Jus ad bellum
 is governed by the UN Charter, interpretations of the 
UN Charter, and some customary international law that has developed 

in connection with and sometimes prior to the UN Charter. 
 Article 2(4) of the UN Charter prohibits every nation from using 
ﬁthe threat or use of force against the territorial integrity or political 

independence of any state, or in any other manner inconsistent with the 

Purposes of the United Nations.ﬂ Nations appear to agree that a vari
-ety of unfriendly actions, including unfavorable trade decisions, space-

based surveillance, boycotts, severance of diplomatic relations, denial 

of communications, espionage, economic competition or sanctions, and 

economic and political coercion, do not rise to the threshold of a ﬁuse of 

force,ﬂ regardless of the scale of their effects. As for the ﬁthreats of forceﬂ 

prohibited by Article 2(4), Professor Thomas Wing˜eld of the U.S. Army 

Command and General Staff College testi˜ed to the committee that such 

threats might plausibly include verbal threats, initial troop movements, 

initial movement of ballistic missiles, massing of troops on a border, use 

of ˜re control radars, and interference with early warning or command 

and control systems. 
 The UN Charter also contains two exceptions to this prohibition on 
the use of force. First, Articles 39 and 42 permit the Security Council to 

authorize uses of force in response to ﬁany threat to the peace, breach of 

the peace, or act of aggressionﬂ in order ﬁto maintain or restore interna
-tional peace and security.ﬂ
4 The law of armed con˚ict is also sometimes known as international humanitarian 
law. A number of legal scholars, though not all by any means, view international humanitar
-ian law as including human rights law, and thus argue that the law of armed con˚ict also 
includes human rights law. For purposes of this chapter and this report, the law of armed 

con˚ict does not include human rights law.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 243Second, Article 51 provides as follows: ﬁNothing in the present Char
-ter shall impair the inherent right of individual or collective self-defense if 
an armed attack occurs against a Member of the United Nations, until the 

Security Council has taken measures necessary to maintain international 

peace and security.ﬂ The self-defense contemplated by Article 51 does not 

require Security Council authorization. Professor Wing˜eld argued that 

armed attack would include declared war, de facto hostilities, occupation 

of territory, a blockade, the destruction of electronic warfare or command 

and control systems, or the use of armed force against territory, military 

forces, or civilians abroad. In addition, there is debate over whether the 

right of self-defense is limited by Article 51, or whether Article 51 simply 

recognizes a continuation of the preexisting (ﬁinherentﬂ) right of self-

defense. Box 7.1 elaborates on notions of self-defense and self-help.
An important aspect of the interpretation of Article 51 involves the 
question of imminent attack. It is widely accepted that a nation facing 

unambiguous imminent attack is also entitled to invoke its inherent right 

of self-defense without having to wait for the blow to fall. (Self-defense 

undertaken under threat of imminent attack is generally called ﬁantici
-patory self-defense.ﬂ) For example, 
Oppenheim™s International Law: Ninth 
Edition
 states that:
5 The development of the law, particularly in the light of more recent state 
practice, . . . suggests that action, even if it involves the use of armed 

force and the violation of another state™s territory, can be justi˜ed as self-
defence under international law where:
a)
  
an armed attack is launched, or is immediately threatened, against a 
state™s territory or forces (and probably its nationals); 
b)
  
there is an urgent necessity for defensive action against that attack; 
c)
  
there is no practicable alternative to action in self-defence, and in 
particular another state or other authority which has the legal powers to 
stop or prevent the infringement does not, or cannot, use them to that 

effect; 
d)
  
the action taken by way of self-defense is limited to what is necessary 
to stop or prevent the infringement, i.e., to the needs of defence.
When are these conditions met? The facts and circumstances in any 
given situation may not lead to clear determinationsŠindeed, the threat
-ened party is likely to have a rather different perception of such facts and 
circumstances than the threatening state. 
The mere fact that Zendia possesses destructive capabilities that could 
be used against Ruritania cannot be suf˜cient to indicate imminent attackŠ
5 Oppenheim™s International Law: Ninth Edition
, 1991, p. 412.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.244
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 7.1
 Self-defense and Self-help
Article 51 acknowledges the right of a nation to engage in the use of armed 
force for self-defense, including the situation in which the nation is the target of an 
armed attack, even without Security Council authorization. (The issue of whether 

a nation may respond militarily without Security Council authorization if it is the 

target of a use of force short of an armed attack is less clear, with evidence to 

support both sides of this position.
1) Although the term ﬁself-defenseﬂ is unde˜ned 
in the UN Charter, it is convenient to consider three different types of actions, all 

of which involve the use of force in response to an attack.
A Type 1 action is a use of force taken to halt or curb an attack in prog
-ress or to mitigate its effects. Type 1 actions do not apply after the attack ceases, 
because all of the harm that the attack can cause has already been caused at that 

point.A Type 2 action is a use of force in which a nation is the ˜rst to use force 
because it has good reason to conclude that it is about to be attacked and that 

there is no other alternative that will forestall such an action. Type 2 actions are 

sometimes called actions of anticipatory self-defense.
2A Type 3 action is a use of force aimed at reducing the likelihood that the 
original attacker will continue its attacks in the future. Type 3 actions are predicated 

on the assumption that the original attacker has in mind a set of attacks, only one 

of which has occurred, and can be regarded as a kind of anticipatory self-defense 

against these likely future attacks. An example of a Type 3 action is the 1986 El 

Dorado Canyon bombing on Libya, which was justi˜ed as an act of self-defense 

against a continuing Libyan-sponsored terrorist threat against U.S. citizens.
3 (Note 
that under domestic law as it applies to private persons, Type 3 actions are gener
-
ally not legal, though Type 1 actions taken in self-defense are sometimes justi˜ed 

under common law, as indicated in Section 5.2.)
Many nations, including the United States, have asserted rights under the UN 
Charter to all three types of action under the rubric of self-defense. At the same 

time, other nations (especially including the target of such action) have claimed 

that a Type 3 action is really an illegal reprisalŠthat is, an act of punishment or 

revenge.
In the context of cyberattack and active defense, a Type 1 action corresponds 
to active threat neutralizationŠa cyberattack launched in response to an incoming 

cyberattack that is intended to neutralize the threat and to stop further damage 

from occurring. A Type 3 action corresponds to a cyberattack that is intended to 

dissuade the attacker from launching further attacks in the future. 
The difference between Type 1 and Type 3 actions is signi˜cant because a 
Type 3 action is technically easier to conduct than a Type 1 action under some 

circumstances. For example, it may easily come to pass that an incoming cyberat
-tack can be identi˜ed as emanating from Zendia and that the Zendian national 
authorities should be held responsible for it. A Type 3 action could then take the 

form of any kind of attack, cyber or kinetic, against ZendiaŠwithout the enormous 

dif˜culty of identifying a speci˜c access path to the controllers behind the attack 

(necessary for a Type 1 action). In addition and depending on the circumstances, 

a Type 1 action could be followed by a Type 3 action. That is, a policy decision 

might be made to take a Type 3 action to ensure that no more hostile actions were 

taken in the future.
Self-defense actions are clearly permissible when a nation or its forces have 
experienced an armed attack. Under standing rules of engagement, a missile ˜red 

on a U.S. ˜ghter plane or a ˜re-control radar locked on the airplane would count 

as an armed attack, and self-defense actions (e.g., bombing the missile site or 

the radar) would be allowable. In a similar vein, cyberattacks that compromise the 

ability of units of the DOD to perform the DOD™s mission might well be regarded as 

an armed attack, and indeed STRATCOM has the authority to conduct response 

actions to neutralize such threats (Chapter 3).
If a nation has been the target of a use of force (a cyberattack) that does not 
rise to the threshold of an armed attack, responses made by the victimized nation 

fall into the category of self-help. What self-help actions are permissible under the 

UN Charter?
Certainly any action that does not amount to a use of force is legal under 
the UN Charter as long as it does not violate some existing treaty obligation. An 

example of such an action might well be non-cooperative but non-destructive in
-telligence gathering about the attacking system. In addition, a small-scale Type 1 

action to neutralize an incoming cyberattack aimed at a single system is likely to 

be permissible. (An analogy from physical space might be the small-scale use of 

force to shoot armed border crossers.)
1 Department of Defense, Of˜ce of General Counsel, 
An Assessment of International Legal 
Issues in Information Operations, Second Edition, 
November 1999.
2 See, for example, 
Oppenheim™s International Law: Ninth Edition
, 1991, p. 412.
3 The raid was the culmination of increasing tensions between the United States and Libya. 
Since 1973, Muammar Qadha˜ asserted Libyan control over the Gulf of Sidra, a claim not 
recognized under international law (which recognizes only a 12-mile-from-shore claim for 
national waters). In 1981, the United States conducted naval exercises in the area claimed 
by Libya, with the result that two Libyan ˜ghter-bombers sent to challenge the United States 
presence were shot down. Tensions continued to increase, and in March 1986, Libya launched 
six SA-5 missiles against the U.S. Sixth Fleet, then operating nearby in the Mediterranean. In 
subsequent action, the United States destroyed two Libyan vessels. In early April 1986, a bomb 

exploded in a Berlin discotheque, killing a U.S. soldier and injuring 63 U.S. soldiers, among 
others. The United States asserted that it had communications intercepts proving Libyan 
sponsorship of the bombing, and Operation El Dorado Canyon occurred shortly thereafter, as 
the United States had at the time no reason to expect such attacks to cease. In May 2001, 
Qadha˜ acknowledged to a German newspaper that Libya had been behind the discotheque 
bombing 15 years earlier, which was carried out apparently in retaliation for the U.S. sinking 
of the two vessels in March 1986.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 245BOX 7.1
 Self-defense and Self-help
Article 51 acknowledges the right of a nation to engage in the use of armed 
force for self-defense, including the situation in which the nation is the target of an 
armed attack, even without Security Council authorization. (The issue of whether 

a nation may respond militarily without Security Council authorization if it is the 

target of a use of force short of an armed attack is less clear, with evidence to 

support both sides of this position.
1) Although the term ﬁself-defenseﬂ is unde˜ned 
in the UN Charter, it is convenient to consider three different types of actions, all 

of which involve the use of force in response to an attack.
A Type 1 action is a use of force taken to halt or curb an attack in prog
-ress or to mitigate its effects. Type 1 actions do not apply after the attack ceases, 

because all of the harm that the attack can cause has already been caused at that 

point.A Type 2 action is a use of force in which a nation is the ˜rst to use force 
because it has good reason to conclude that it is about to be attacked and that 

there is no other alternative that will forestall such an action. Type 2 actions are 

sometimes called actions of anticipatory self-defense.
2A Type 3 action is a use of force aimed at reducing the likelihood that the 
original attacker will continue its attacks in the future. Type 3 actions are predicated 

on the assumption that the original attacker has in mind a set of attacks, only one 

of which has occurred, and can be regarded as a kind of anticipatory self-defense 

against these likely future attacks. An example of a Type 3 action is the 1986 El 

Dorado Canyon bombing on Libya, which was justi˜ed as an act of self-defense 

against a continuing Libyan-sponsored terrorist threat against U.S. citizens.
3 (Note 
that under domestic law as it applies to private persons, Type 3 actions are gener
-
ally not legal, though Type 1 actions taken in self-defense are sometimes justi˜ed 

under common law, as indicated in Section 5.2.)
Many nations, including the United States, have asserted rights under the UN 
Charter to all three types of action under the rubric of self-defense. At the same 

time, other nations (especially including the target of such action) have claimed 

that a Type 3 action is really an illegal reprisalŠthat is, an act of punishment or 

revenge.
In the context of cyberattack and active defense, a Type 1 action corresponds 
to active threat neutralizationŠa cyberattack launched in response to an incoming 

cyberattack that is intended to neutralize the threat and to stop further damage 

from occurring. A Type 3 action corresponds to a cyberattack that is intended to 

dissuade the attacker from launching further attacks in the future. 
The difference between Type 1 and Type 3 actions is signi˜cant because a 
Type 3 action is technically easier to conduct than a Type 1 action under some 

circumstances. For example, it may easily come to pass that an incoming cyberat
-tack can be identi˜ed as emanating from Zendia and that the Zendian national 
authorities should be held responsible for it. A Type 3 action could then take the 

form of any kind of attack, cyber or kinetic, against ZendiaŠwithout the enormous 

dif˜culty of identifying a speci˜c access path to the controllers behind the attack 

(necessary for a Type 1 action). In addition and depending on the circumstances, 

a Type 1 action could be followed by a Type 3 action. That is, a policy decision 

might be made to take a Type 3 action to ensure that no more hostile actions were 

taken in the future.
Self-defense actions are clearly permissible when a nation or its forces have 
experienced an armed attack. Under standing rules of engagement, a missile ˜red 

on a U.S. ˜ghter plane or a ˜re-control radar locked on the airplane would count 

as an armed attack, and self-defense actions (e.g., bombing the missile site or 

the radar) would be allowable. In a similar vein, cyberattacks that compromise the 

ability of units of the DOD to perform the DOD™s mission might well be regarded as 

an armed attack, and indeed STRATCOM has the authority to conduct response 

actions to neutralize such threats (Chapter 3).
If a nation has been the target of a use of force (a cyberattack) that does not 
rise to the threshold of an armed attack, responses made by the victimized nation 

fall into the category of self-help. What self-help actions are permissible under the 

UN Charter?
Certainly any action that does not amount to a use of force is legal under 
the UN Charter as long as it does not violate some existing treaty obligation. An 

example of such an action might well be non-cooperative but non-destructive in
-telligence gathering about the attacking system. In addition, a small-scale Type 1 

action to neutralize an incoming cyberattack aimed at a single system is likely to 

be permissible. (An analogy from physical space might be the small-scale use of 

force to shoot armed border crossers.)
1 Department of Defense, Of˜ce of General Counsel, 
An Assessment of International Legal 
Issues in Information Operations, Second Edition, 
November 1999.
2 See, for example, 
Oppenheim™s International Law: Ninth Edition
, 1991, p. 412.
3 The raid was the culmination of increasing tensions between the United States and Libya. 
Since 1973, Muammar Qadha˜ asserted Libyan control over the Gulf of Sidra, a claim not 
recognized under international law (which recognizes only a 12-mile-from-shore claim for 
national waters). In 1981, the United States conducted naval exercises in the area claimed 
by Libya, with the result that two Libyan ˜ghter-bombers sent to challenge the United States 
presence were shot down. Tensions continued to increase, and in March 1986, Libya launched 
six SA-5 missiles against the U.S. Sixth Fleet, then operating nearby in the Mediterranean. In 
subsequent action, the United States destroyed two Libyan vessels. In early April 1986, a bomb 

exploded in a Berlin discotheque, killing a U.S. soldier and injuring 63 U.S. soldiers, among 
others. The United States asserted that it had communications intercepts proving Libyan 
sponsorship of the bombing, and Operation El Dorado Canyon occurred shortly thereafter, as 
the United States had at the time no reason to expect such attacks to cease. In May 2001, 
Qadha˜ acknowledged to a German newspaper that Libya had been behind the discotheque 
bombing 15 years earlier, which was carried out apparently in retaliation for the U.S. sinking 
of the two vessels in March 1986.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.246 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
otherwise, the mere existence of armed forces of an adversary would be 
suf˜cient justi˜cation. But if Zendia can use these capabilities effectively 
against Ruritania and with serious consequences without warning, and 

Zendia has indicated hostile intent toward Ruritania in other (perhaps 

non-military) ways, outside observers may indeed be more likely to judge 

that the conditions for anticipatory self-defense have been met.
7.2.1.2
 Jus in Bello
Once armed con˚ict has begun, the conduct of a nation™s armed forces 
is subject to a variety of constraints. 
Jus in bello
 is governed largely by 
the Hague Conferences of 1899 and 1907, the Geneva Conventions, and 

customary international law.

Military necessity.
 Valid targets are limited to those that make a 
direct contribution to the enemy™s war effort, or those whose damage or 

destruction would produce a military advantage because of their nature, 

location, purpose, or use. Thus, enemy military forces (and their equip
-ment and stores) may be attacked at will, as is also true for civilians and 

civilian property that make a direct contribution to the war effort. Assets 

that do not contribute to the war effort or whose destruction would pro
-vide no signi˜cant military advantage may not be deliberately targeted 

by cyber or kinetic means. LOAC also provides for a category of specially 

and (in theory) universally protected facilities such as hospitals and reli
-gious facilities.

Proportionality.
 It is understood that attacks on valid military tar
-gets may result in collateral injury and damage to civilian assets or people. 

Some degree of collateral damage is allowable, but not if the foreseeable 

collateral damage is disproportionate compared to the military advantage 

likely to be gained from the attack. In the event that military and nonmili
-tary assets are circumstantially commingled (e.g., the use of a common 

electric grid to power both military and civilian facilities), the attacker 

must make a proportionality judgment. But in instances when the enemy 

has deliberately intermingled military and non-military assets or people, 

the enemy must then assume some responsibility for the collateral dam
-age that may result. 
Put differently, LOAC always obligates a would-be attacker to make 
reasonable proportionality judgments. What is less clear, and may depend 

on circumstances, are the conditions under which the enemy has a legal 

responsibility to refrain from deliberately commingling military assets 

with non-military assets or more generally to separate such assets. For 
example, the enemy may
 have deliberately placed ﬁhuman shieldsﬂ 
around military targets.
  
In such a case, the enemy is
 clearly in violation 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 247of LOAC and bears the responsibility for any injury to the hostages if the 
target is attacked.
  However, in an extreme case
 where the likely deaths 
and injuries among the hostages are disproportionate to the military 
advantage
 to the attacker,
 the attacker is
 obligated to take into account 
the presence and likely deaths of those human shields in making a pro
-portionality judgment about a possible attack.
A common misperception about proportionality as a rule of 
jus in 
bello
 is that it requires the victim of an attack to respond only in ways that 
cause the original attacker approximately the same amount or degree of 
pain that the victim experienced. This kind of response is generally char
-acterized as a commensurate response, and although commensuration 

and commensurate response are often used by policy makers as guide
-posts in formulating responses to external attack, they are not required 

by LOAC.

Per˚dy.
 Acts of per˜dy seek to deceive an enemy into believing 
that he is obligated under the law of armed con˚ict to extend special 

protection to a friendly asset when such is not the case. For example, by 

convention and customary law, certain persons and property may not be 

legitimately attacked, including prisoners of war and prisoners-of-war 

camps, the wounded and sick, and medical personnel, vehicles, aircraft, 

and vessels. Persons and property in this category must be identi˜ed with 

visual and electronic symbols, and misuse of these symbols to prevent a 

legitimate military target from being attacked constitutes the war crime of 

per˜dy. In addition, it is unlawful to feign surrender, illness, or death to 

gain an advantage in combat, or to broadcast a false report that both sides 

had agreed to a cease-˜re or armistice. At the same time, ruses of war are 

explicitly permissible. A ruse of war is intended to mislead an adversary or 

to induce him to act recklessly but its use infringes no rule of international 

law applicable in armed con˚ict and does not mislead the adversary into 

believing that he is entitled to special protection. Camou˚age, decoys, 

mock operations, and misinformation are all permitted ruses. 

Distinction.
 Distinction requires armed forces to make reasonable 
efforts to distinguish between military and civilian assets and between 

military personnel and civilians, and to refrain from deliberately attack
-ing civilians or civilian assets. However, there are two important classes 

of civilians or civilian assetsŠthose that have been compromised and 

used (illegally) to shield the actions of a party to the con˚ict and those 

that suffer inadvertent or accidental consequences (ﬁcollateral damageﬂ) 

of an attack. Responsibility for harm is apportioned differently depending 

on the class to which a given civilian or civilian asset belongs (Box 7.2).

Neutrality.
 A nation may declare itself to be neutral, and is entitled 
to immunity from attack by either side at war, as long as the neutral 

nation does not assist either side militarily and acts to prevent its territory 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.248 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 7.2
 Avoiding Harm to Innocent Parties
The principle of distinction requires military forces to minimize harm to inno
-cent partiesŠthat is, non-combatants that are not actively engaged in helping to 
prosecute the war. But three categories of ﬁinnocent partiesﬂ must be distinguished, 

especially in the cyber context. 
Category AŠ
An innocent party that is compromised by an adversary and 
then used to shield the adversary™s actions. For example, an adversary (Zendia) 

that uses human civilians as shields to protect its antiaircraft sites is using this kind 

of innocent party. Zendia would also be doing so if it launched a cyberattack against 

Ruritania through the use of a compromised and innocent third-party computer 

(e.g., one belonging to civilians).
Category BŠ
An innocent party that is caught up in some effect that was 
unpredicted or could not have been expected. For example, a Zendian civilian 

truck in the desert is struck inadvertently by the empty drop tanks of a Ruritanian 

˜ghter-bomber en route to its target, and all those inside the truck are killed. Or, a 

Ruritanian cyberattack strikes a Zendian generator powering the Zendian ministry 

of defense, leading to a cascading power failure that disables hospitals in which 

Zendian patients then die.

Category CŠ
An innocent party that is granted special protection under the 
Geneva Convention, such as a hospital, and is then used as a facility from which to 

launch attacks. For example, the Zendian adversary that places mortars on the roof 

of a hospital is using Category C innocent parties. Or, Zendia launches a cyberattack 

on Ruritania using the servers and Internet connections of a Zendian hospital.
Distinguishing between these kinds of innocent parties is important because 
the categories of parties harmed have different implications for responsibility. If 
 Category A innocent parties are harmed, some responsibility attaches to Zendia 
for placing innocent parties in harm™s way. Some degree of responsibility may 
 
attach to Ruritania if the attack did not meet the requirements of
 proportionalityŠ
that is, if the military value of the target shielded was small by comparison to the 
loss of Zendian civilian life. If Category B innocent parties are harmed, the respon
-sibility does not fall on Zendia, and if Ruritania took reasonable care in route plan
-ning, no responsibility attaches to Ruritania either. If Category C innocent parties 

are harmed, the legal responsibility for those consequences falls entirely on the 
 Zendian adversary under LOAC. 
In active defense scenarios calling for threat neutralization, there are many 
valid concerns about a counterstrike that does harm to some innocent party. But 
at least in some scenarios involving innocent third-party computers (that is, in 

Category A), a Ruritanian response against those compromised computers could 

be conducted within the bounds of LOAC, and the harm resulting to those third 

parties would be the responsibility of Zendia and not Ruritania.
Of course, Ruritania would have to address several other concerns before 
feeling con˜dent in the legality and wisdom of a counterstrike. First, even if a 

counterstrike is entirely legal, it may come with other costs, such as those associ
-ated with public opinion or ethical considerations. If a counterstrike disables the 

hospital computer and deaths result, there may be censure for Ruritania, even if 

the counterstrike was within Ruritania™s legal rights to conduct. Second, Ruritania 

would have to take reasonable care to determine that the incoming cyberattack was 

indeed coming from the computer in question, because Zendia might have also 

planted evidence so as to prompt a counterstrike against a computer that was not 

involved in the attack at all. Third, Ruritania would still have to make reasonable 

efforts to ensure that its attack on the hospital computer did not have unintended 

cascading effects (e.g., beyond the particular node on the hospital network from 

which the attack was emanating).
from being so used. Accordingly, there exists a right for a threatened state 
ﬁto use force to neutralize a continuing threat located in the territory of a 

neutral state, but not acting on its behalf, when the neutral state is unable 

or unwilling to ful˜ll its responsibility to prevent the use of its territory as 

a base or sanctuary for attacks on another nation.ﬂ
6 Note also that under 
item 3 of UN Security Council Resolution 1368 (adopted on September 

12, 2001),
7 which calls on all member states ﬁto work together urgently to 
bring to justice the perpetrators, organizers and sponsors of these terror
-ist attacksﬂ and stresses that ﬁthose responsible for aiding, supporting, or 

harboring the perpetrators, organizers and sponsors of these acts will be 
6 Department of Defense, Of˜ce of General Counsel, 
An Assessment of International Legal 
Issues in Information Operations, 
Second Edition
, 
November 1999.
7 United Nations Security Council Resolution 1368 (2001), accessed at http:/
/daccessdds.
un.org/doc/UNDOC/GEN/N01/533/82/PDF/N0153382.pdf?OpenElement.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 249BOX 7.2
 Avoiding Harm to Innocent Parties
The principle of distinction requires military forces to minimize harm to inno
-cent partiesŠthat is, non-combatants that are not actively engaged in helping to 
prosecute the war. But three categories of ﬁinnocent partiesﬂ must be distinguished, 

especially in the cyber context. 
Category AŠ
An innocent party that is compromised by an adversary and 
then used to shield the adversary™s actions. For example, an adversary (Zendia) 

that uses human civilians as shields to protect its antiaircraft sites is using this kind 

of innocent party. Zendia would also be doing so if it launched a cyberattack against 

Ruritania through the use of a compromised and innocent third-party computer 

(e.g., one belonging to civilians).
Category BŠ
An innocent party that is caught up in some effect that was 
unpredicted or could not have been expected. For example, a Zendian civilian 

truck in the desert is struck inadvertently by the empty drop tanks of a Ruritanian 

˜ghter-bomber en route to its target, and all those inside the truck are killed. Or, a 

Ruritanian cyberattack strikes a Zendian generator powering the Zendian ministry 

of defense, leading to a cascading power failure that disables hospitals in which 

Zendian patients then die.

Category CŠ
An innocent party that is granted special protection under the 
Geneva Convention, such as a hospital, and is then used as a facility from which to 

launch attacks. For example, the Zendian adversary that places mortars on the roof 

of a hospital is using Category C innocent parties. Or, Zendia launches a cyberattack 

on Ruritania using the servers and Internet connections of a Zendian hospital.
Distinguishing between these kinds of innocent parties is important because 
the categories of parties harmed have different implications for responsibility. If 
 Category A innocent parties are harmed, some responsibility attaches to Zendia 
for placing innocent parties in harm™s way. Some degree of responsibility may 
 
attach to Ruritania if the attack did not meet the requirements of
 proportionalityŠ
that is, if the military value of the target shielded was small by comparison to the 
loss of Zendian civilian life. If Category B innocent parties are harmed, the respon
-sibility does not fall on Zendia, and if Ruritania took reasonable care in route plan
-ning, no responsibility attaches to Ruritania either. If Category C innocent parties 

are harmed, the legal responsibility for those consequences falls entirely on the 
 Zendian adversary under LOAC. 
In active defense scenarios calling for threat neutralization, there are many 
valid concerns about a counterstrike that does harm to some innocent party. But 
at least in some scenarios involving innocent third-party computers (that is, in 

Category A), a Ruritanian response against those compromised computers could 

be conducted within the bounds of LOAC, and the harm resulting to those third 

parties would be the responsibility of Zendia and not Ruritania.
Of course, Ruritania would have to address several other concerns before 
feeling con˜dent in the legality and wisdom of a counterstrike. First, even if a 

counterstrike is entirely legal, it may come with other costs, such as those associ
-ated with public opinion or ethical considerations. If a counterstrike disables the 

hospital computer and deaths result, there may be censure for Ruritania, even if 

the counterstrike was within Ruritania™s legal rights to conduct. Second, Ruritania 

would have to take reasonable care to determine that the incoming cyberattack was 

indeed coming from the computer in question, because Zendia might have also 

planted evidence so as to prompt a counterstrike against a computer that was not 

involved in the attack at all. Third, Ruritania would still have to make reasonable 

efforts to ensure that its attack on the hospital computer did not have unintended 

cascading effects (e.g., beyond the particular node on the hospital network from 

which the attack was emanating).
held accountable,ﬂ and under related developments in international law, 
even neutral states have af˜rmative obligations to refrain from harboring 

perpetrators of terrorist attacks. The United States has asserted the right 

of self-defense in this context on a number of occasions, including the 

1998 cruise missile attack against a terrorist training camp in Afghanistan 

and a chemical plant in Sudan in which the United States asserted that 

chemical weapons had been manufactured; the 1993 cruise missile attack 

against the Iraqi intelligence service headquarters which the United States 

held responsible for a conspiracy to assassinate President George H.W. 

Bush; and the 1986 bombing raid against Libya in response to Libya™s 

continuing support for terrorism against U.S. military forces and other 

U.S. interests. 

Discrimination.
 Nations have agreed to refrain from using cer
-tain weapons, such as biological and chemical weapons, at least in part 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.25
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
because they are inherently indiscriminate weapons (that is, they cannot 
be directed against combatants only). However, there is no ban as such 
on indiscriminate weapons per seŠthe harm to non-combatants is mini
-mized through adherence to requirements of proportionality.
It is worth emphasizing that 
jus ad bellum
 and 
jus in bello
 are two dif
-ferent bodies of law, applicable at different times. Once armed con˚ict has 

started (whether or not 
jus ad bellum
 has been followed in the starting of 
that con˚ict), 
jus in bello
 is the body of law that applies.
7.2.2
 Applying the Law of Armed Con˜ict to Cyberattack
This section addresses some of the issues that might arise in apply
-ing international law to cyberattack. Some issues arise when a nation is 

the target of a cyberattack and must consider legal issues in formulat
-ing an appropriate and effective responseŠand its decision depends on 

(among other things) whether it is in an ongoing state of hostilities with 

the perpetrator of that cyberattack. Other issues arise when a nation may 

wish to launch a cyberattack against another party prior to the outbreak 

of hostilities but without intending to give the other side a legal basis for 

regarding its action as starting a general state of hostilities.
8 Still other 
issues arise when cyberattack is conducted in the context of an ongo
-ing con˚ictŠthat is, while hostilities are in progress. And a different set 

of standards and legal regimes may govern responses to cyberattacks 

launched by non-state actors. 
To be fair, many or most of the same issues addressed below arise 
when kinetic weapons are used in con˚ict. But cyberweapons are newer 

and have certain characteristics not shared with kinetic weapons, which 

implies that fewer precedents and analyses are available and that the 

application of LOAC principles may not be as straightforward as they are 

when kinetic weapons are involved.
On the broad question regarding cyberattack, the committee starts 
with two basic premises that guide subsequent discussion:
9 8 Department of Defense, Of˜ce of General Counsel, 
An Assessment of International Legal 
Issues in Information Operations, 
Second Edition
, 
November 1999.
9 These points are addressed in a number of legal analyses, including Michael Schmitt, 
ﬁComputer Network Attack and the Use of Force in International Law: Thoughts on a 
Normative Framework,ﬂ 
Columbia Journal of Transnational Law
 37:885-937, 1999; Duncan B. 
Hollis, ﬁNew Tools, New Rules: International Law and Information Operations,ﬂ pp. 59-72 

in 
Ideas As Weapons: In˜uence and Perception in Modern Warfare, 
G. David and T. McKeldin, 
eds., Potomac Books, Inc.,
 2009; and Jason Barkham, ﬁInformation Warfare and International 
Law on the Use of Force,ﬂ 
New York Uni
versity International Law and Politics
 34:57-113, 2001. 
Schmitt™s and Hollis™s analyses are summarized in Appendix D.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 251

Cyberattack cannot be regarded as a more ﬁbenignﬂ form of war
-fare or as always falling short of ﬁarmed attackﬂ or ﬁuse of forceﬂ simply 
because a cyberattack targets computers and networks. The magnitude, 

scale, and nature of a cyberattack™s effects, both direct and indirect, have 

to be taken into account in ascertaining its signi˜cance, and it is not sim
-ply the modality of the attack that matters.
10
 
Despite the fact that cyberattack is a relatively new form of weapon, 
acknowledged armed con˚ict involving the use of cyberweapons is sub
-ject to LOAC and UN Charter law. That is, LOAC™s precepts regarding 

jus ad bellum
 and 
jus in bello
 continue to have validity in a cyberattack 
context. Nevertheless, because of the novelty of such weapons, there will 

be uncertainties in how LOAC and UN Charter law might apply in any 

given instance. An effects-based analysis suggests that the ambiguities are 

fewest when cyberattacks cause physical damage to property and loss of 

life in ways that are comparable to kinetic attacks and traditional war is 

involved, because traditional LOAC provides various relevant precedents 

and analogies. The ambiguities multiply in number and complexity when 

the effects do not entail physical damage or loss of life but do have other 

negative effects on another nation.
11
Appendix D summarizes several other views on cyberattack as a use 
of force.
Also, as Hollis notes,
12
 traditional LOAC and the UN Charter are 
largely silent on how to address con˚ict involving non-state actors, even 

though non-state actors (in particular, terrorist groups) are playing larger 

roles in the security environment today. This point is addressed in Section 

7.2.3.1 (on terrorists), Section 7.2.3.2 (on multinational corporations), and 

Section 7.2.3.3 (on individuals).
7.2.2.1
 Prior to the Outbreak of HostilitiesŠApplying 
Jus ad Bellum
 An important question of 
jus ad bellum
 in this report is whether, or 
more precisely, when, a given cyberattack constitutes a ﬁuse of forceﬂ or 

an ﬁarmed attack.ﬂ But as a number of analysts have noted,
13
 the relevant 
10 
Department of Defense, Of˜ce of General Counsel, 
An Assessment of International Legal 
Issues in Information Operations, 
Second Edition, November, 1999.
11 
See Jason Barkham, ﬁInformation Warfare and International Law on the Use of 
Force,ﬂ 
New York Uni
versity International Law and Politics
 34:57-113, 2001.
12 
Duncan B. Hollis, ﬁNew Tools, New Rules: International Law and Information Op
-erations,ﬂ pp. 59-72 in 
Ideas As Weapons: In˜uence and Perception in Modern Warfare, 
G. David 
and T. McKeldin, eds.,
 Potomac Books, Inc.,
 2009.
13 
Michael Schmitt, ﬁComputer Network Attack and the Use of Force in International 
Law: Thoughts on a Normative Framework,ﬂ 
Columbia Journal of Transnational Law
 37:885-
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.252
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
question is not so much whether a cyberattack constitutes a ﬁuse of forceﬂ 
but rather whether a cyberattack 
with a speci˚ed effect
 constitutes a ﬁuse 
of force.ﬂ That is, the effects of a given cyberattack are the appropriate 
point of departure for an analysis of this question, rather than the speci˜c 

mechanism used to achieve these effects.
7.2.2.1.1 
The Uncertainties in Identi˚cation and Attribution
Application of LOAC in a cyber context requires identi˜cation of the 
party responsible for an act of cyber aggression. But as noted in Chapter 

2, it may be dif˜cult even to know when a cyberattack has begun, who the 

attacker is, and what the purpose and effects of the cyberattack are/were. 

Indeed, it may be dif˜cult to identify even the nature of the involved 

party (e.g., a government, a terrorist group, an individual), let alone the 

name of the country or the terrorist group or the individual. Knowing the 

nature of the party is an important element in determining the appropri
-ate response.
14
 And, of course, knowing which country, terrorist group, 
or individual is in fact responsible is essential if any speci˜c response 

involving attack is deemed appropriate.

What, if any, is the responsibility of an attacking nation to ascertain 
the physical location of a computer or network that it attacks? Where 

kinetic weapons are involved, attacking a particular target requires 

knowledge of the target™s physical location. But it is often possible for 

a cyberweapon to attack a target whose location is known only as an IP 
address or some other machine-readable address that does not
 necessarily 
correspond to a speci˜c or a known physical location. Yet physical loca
-tion may matter (a point that relates to notions of territorial integrity) 

in determining whether a given cyber target belongs to or is under the 

control of an adversary.

What degree of certainty about the identity of an attacker is needed 
legally before a cyberattack may be launched to neutralize it? How, if at 

all, does this differ from what is needed for policy purposes? 
Box 7.3 provides some scenarios in which such questions arise.
937, 1999; Jason Barkham, ﬁInformation Warfare and International Law on the Use of Force,ﬂ 
New York Uni
versity Journal of International Law and Politics
 34:57-113, 2001; Department of 
Defense, Of˜ce of General Counsel, 
An Assessment of International Legal Issues in Information 
Operations, 
Second Edition, November 1999. An exposition by Brownlie in 1963 discusses a 
ﬁresults-orientedﬂ approach, but of course without reference to cyberattack per se. See Ian 
Brownlie, 
International Law and the Use of Force by States
, 1963.
14 
Sections 2.4.2 and 2.4.3 describe some of the issues involved in making such a 
determination.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 253
BOX 7.3
 Uncertainties in Identification and AttributionŠ
Possible Examples
The following examples illustrate possible scenarios in which uncertainties in 
identi˜cation and attribution arise.
During con˚ict between the United States and Zendia, a U.S. cyberattack 
is launched on a computer controlling a Zendian air defense network. 
A normally 
reliable human informant passes on a message to the United States, but the mes
-sage is unfortunately incomplete, and the only information passed along is the 
computer™s electronic identi˜er, such as an IP address or a MAC (Media Access 

Control) address; its physical location is unknown. The open question is whether 

this computer is a valid military target for a U.S. cyberattack and the extent to which 

the United States has an obligation to ascertain its physical location prior to such 

an attack.
During a time of international tension (say, U.S. forces are on an elevated 
alert status), the United States experiences a cyberattack on its military communi
-cations that is seriously disruptive.
 The United States must restore its communica
-tions quickly but lacks the intelligence information to make a de˜nitive assessment 

of the ultimate source of the attack. The open question is whether it can lawfully 

act against the proximate sources of the attack in order to terminate the threat and 

restore its communications capability, even though it is by no means certain that 

the ﬁproximate sourceﬂ is actually the ultimate source and may simply have been 

exploited by the ultimate source. (A proximate source might be a neutral nation, 

or a nation whose relations with the United States are not particularly good. If the 

latter, a U.S. attempt to neutralize the attack might thus exacerbate tensions with 

that nation.)
One practical consequence of these uncertainties is that a nation seek
-ing UN action in response to a cyberattack would be unlikely to see 
rapid action, since much of the necessary information might not be avail
-able promptly. (Indeed, consider as a benchmark the history of long and 

extended Security Council debate on authorizations for armed con˚ict 

involving kinetic force.)
7.2.2.1.2 
Criteria for De˚ning ﬁUse of Forceﬂ and ﬁArmed Attackﬂ
15
 Traditional LOAC emphasizes death or physical injury to people and 
destruction of physical property as criteria for the de˜nitions of ﬁuse of 

forceﬂ and ﬁarmed attack.ﬂ But modern society depends on the existence 
15
 A related perspective can be found in Jason Barkham, ﬁInformation Warfare and 
International Law on the Use of Force,ﬂ 
New York Uni
versity International Law and Politics
 34:57-113, 2001.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.25
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
and proper functioning of an extensive infrastructure that itself is increas
-ingly controlled by information technology. Actions that signi˜cantly 
interfere with the functionality of that infrastructure can reasonably be 

regarded as uses of force, whether or not they cause immediate physical 

damage. Thus, cyberattacks on the controlling information technology 

for a nation™s infrastructure that had a signi˜cant impact on the function
-ing of that infrastructure (whether or not it caused immediate large-scale 

death or destruction of property) would be an armed attack for Article 51 

purposes, just as would a kinetic attack that somehow managed to shut 

down the system without such immediate secondary effects.
How far would a cyberattack on a nation™s infrastructure have to go 
before it was regarded as a use of force or an armed attack? Scale of effect 

is one important factor in distinguishing between an armed attack and a 

use of force. For example, an armed attack would presumably involve a 

use of force that resulted in a large scale of effect. It is unclear if there are 

other differentiating factors in addition to scale of effect. (Neither ﬁarmed 

attackﬂ nor ﬁuse of forceﬂ necessarily requires the use of traditional kinetic 

weapons.)
Schmitt™s examples of cyberattacks that do and do not qualify as a 
use of force are useful for establishing a continuum of scale.
16
 At one end, 
Schmitt argues that a cyberattack on an air traf˜c control system resulting 

in a plane crash and many deaths clearly does qualify as a use of force, 

whereas a computer network attack on a single university computer net
-work designed to disrupt military-related research occurring in campus 

laboratories does not. In between these two ends of the spectrum are a 

number of problematic cases (Box 7.4) that raise a number of questions.

What is the minimum length of time, if any, for which a serious 
disruption to critical infrastructure must last for it to be regarded as a use 

of force or an armed attack? (This is not to say that time is the only vari
-able involved in such an assessment.)

Under what circumstances, if any, can a non-lethal and continuing 
but reversible cyberattack that interferes with the functionality of a target 

network (e.g., against a photo reconnaissance satellite) be regarded as a 

use of force or an armed attack?

Under what circumstances, if any, can a cyberattack (e.g., against a 
stock market™s data, against a factory process) whose disruptive but not 

actually destructive effects build slowly and gradually be regarded as a 

use of force or an armed attack? 
16
 Michael Schmitt, ﬁComputer Network Attack and the Use of Force in International 
Law: Thoughts on a Normative Framework,ﬂ 
Columbia Journal of Transnational Law
 37:885-
937, 1999.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 255
BOX 7.4
 Cyberattacks as a Possible ﬁUse of Forceﬂ
The following examples illustrate possible scenarios that raise questions 
about the appropriate de˜nition of the ﬁuse of force.ﬂ
A cyberattack temporarily disrupts Zendia™s stock exchanges and makes 
trading impossible for a short period.
 Bombs dropped on Zendia™s stock exchanges 
(at night, so that casualties were minimized) would be regarded as a use of force or 
an armed attack by most observers, even if physical backup facilities were promptly 

available so that actual trading was disrupted only for a short time (e.g., a few 

hours). The posited cyberattack could have the same economic effects, except that 

the buildings themselves would not be destroyed. In this case, the cyberattack may 

be less likely to be regarded as a use of force than a kinetic attack with the same 

(temporary) economic effect, simply because the lack of physical destruction would 

reduce the scale of the damage caused. However, a cyberattack against the stock 

exchanges that occurs repeatedly and continuously, so that trading is disrupted 

for an extended period of time (e.g., days or weeks), would surely constitute a use 

of force or even an armed attack, even if no buildings were destroyed.
A cyberattack is launched against the ground station of a Zendian military 
photo-reconnaissance satellite. 
Neither the satellite nor the ground station is physi
-cally damaged, but Zendia is temporarily unable to download imagery. The open 

question is whether such an act might plausibly be interpreted as a use of force, 

based on the argument that the inability to download imagery might be a prelude to 

an attack on Zendia, even if no (permanent) damage has been done to Zendia.
A cyberattack has effects that build slowly and gradually
. For example, 
a cyberattack against a stock exchange might corrupt the data used to make 

trades. Again, no physical damage occurs to buildings, and in addition trading 

continues, albeit in a misinformed manner. Over time, the effects of such an attack 

could wreak havoc with the market if continued over that time.
1 If and when the 
effects were discovered, public con˜dence in the market could well plummet, and 

economic chaos could result. An open question is the degree of economic loss, 

chaos, and reduction in public con˜dence that would make such an attack a use 

of force.
A cyberattack is aimed at corrupting a manufacturing process
. In this 
scenario, the manufacturing process is altered in such a way that certain ˚aws 

are introduced into a product that do not show up on initial acceptance testing 

but manifest themselves many months later in the form of reduced reliability, oc
-casional catastrophic failure, signi˜cant insurance losses, and a few deaths. Here, 

one open question relates to the signi˜cance of the effects of the attack, recogniz
-ing the ﬁboiling the frogﬂ phenomenonŠa sudden change may be recognized as 

signi˜cant, but a gradual change of the same magnitude may not be. 
1 As a demonstration that slowly accumulating error can have large consequences, consider 
that the Vancouver stock exchange index introduced in 1982 was undervalued by 48 percent 
22 months later compared to its ﬁtrueﬂ valueŠthe reported value of the index was 524.881, 
whereas the correctly calculated value should have been 1009.811. This discrepancy was the 
result of roundoff error, accumulated over time. See B.D. McCullough and H.D. Vinod, ﬁThe 
Numerical Reliability of Econometric Software,ﬂ 
Journal of Economic Literature
 37(2):633-665, 
June 1999.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.256
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
The question of scale above points to a more general problemŠthe 
inability to distinguish at the point of discovery that a cyberattack is 
taking place between one that seeks to cause large-scale damage (which 

would almost certainly constitute an armed attack) and one that seeks to 

cause only very limited damage (which might constitute a use of force 

if not an armed attack). The problem of a nation ˜guring out when a 

given act that may appear to be hostile isŠor is notŠa precursor to more 

serious hostile actions that will create additional damage is not unique 

to cyberattack, as illustrated by the Tonkin Gulf incident (in which the 

United States was arguably too quick to see a grave provocation) and 

Stalin™s refusal to believe reports of Nazi preparations and initial incur
-sions in June 1941. Similarly, an airplane penetrating a nation™s airspace 

without authorization may simply be off course, or it may instead be 

carrying nuclear weapons with hostile intent. The nation in question has 

an obligation to try to determine if the airplane represents a true threat, 

but it surely has a right to shoot down the airplane if it reasonably makes 

such a determination. The open question is what the nation can do if it is 

uncertain about the threatening nature of the airplane.
Although waiting to see what the attack does is the only certain way 
to determine the scale and extent of its effects, waiting may not be a viable 

option for decision makers when they are noti˜ed that a cyberattack on 

their nation is underway. In addition, leaders of a state often wish to cali
-brate a response to an attack to be of the same scale as that attackŠand 

if decision makers do not know the scale of the attack, how are they to 

calibrate a response?
17
 The scale question also raises the issue of whether there is, or should 
be, a class of ﬁhostileﬂ cyber actions (that is, certain kinds of cyberattack) 

that are recognized as not so immediately destructive as to be clear acts of 

ﬁuses of forceﬂ or ﬁarmed attack,ﬂ but that nonetheless entitle the target 

to some measure of immediate real-time responseŠcommensurate self-

defenseŠthat goes beyond just trying to protect the immediate target. 

(Such a regime might have some counter-escalation effects, because a 

potential aggressor would not be assured of immunity from a response 

from its victim.) A regime designed with an overriding priority to discour
-age escalation of cybercon˚ict would not recognize the existence of such 

a class but rather obligate the target to accept the initial consequences of 

those hostile cyber actions and respond (whether by force or otherwise) 

only afterward.
17
 Jason Barkham, ﬁInformation Warfare and International Law on the Use of Force,ﬂ 
New York Uni
versity International Law and Politics
 34:57-113, 2001.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 257
7.2.2.1.3 
De˚nition of ﬁThreat of Forceﬂ
Article 2(4) prohibits nations from threatening the use of force. When 
the coercive instruments are traditional weapons, a threat generally takes 
the form of ﬁWe will do destructive act 
X if you do not take action 
Y (that 
is, trying to compel the adversary to take action 
Y) or if you do take action 
Z (that is, trying to deter the adversary from taking action 
Z).ﬂ

Does a threat to use existing vulnerabilities in an adversary com
-puter system or network constitute a threat of the use of force under the 

UN Charter? Because an existing vulnerability can be used for cyberattack 

(which can be a use of force) or cyberexploitation (which is not considered 

a use of force, as discussed in Section 7.2.2.1.5), the answer is not clear.

Does it matter how those vulnerabilities got there? Does introduc
-ing vulnerabilities into an adversary™s system or network constitute a 

threat of force, especially if they remain unused for the moment?
Box 7.5 provides examples illustrating how such questions might arise.
7.2.2.1.4
 Distinctions 
Between Economic Sanctions and 
Blockades
18
Under international law, economic sanctions appear not to constitute 
a use of force, even if they result in death and destruction on a scale that 
would have constituted a use of force if they were caused by traditional 

military forces, although this interpretation is often questioned by the 

nation targeted by the sanctions. Article 41 of the UN Charter gives the 

Security Council authority to decide what measures count as ﬁnot involv
-ing the use of armed force,ﬂ and it explicitly recognizes that measures not 

involving the use of armed force include the ﬁcomplete or partial inter
-ruption of economic relations.ﬂ
19
 In this instance, international law does appear to differentiate between 
different means used to accomplish the same end. That is, economic sanc
-tions and blockades could easily result in similar outcomes, but there 

are two key differences. First, sanctions are, by de˜nition, a refusal of 

participating nations to trade with the targeted party, either unilaterally 

(by virtue of a national choice) or collectively (by virtue of agreement to 

adhere to UN mandates regarding sanctions). That is, sanctions involve 

refraining from engaging in a trading relationship that is not obligatory. 

By contrast, blockades interfere with trade involving any and all parties, 
18
 See also Jason Barkham, ﬁInformation Warfare and International Law on the Use 
of Force,ﬂ 
New York Uni
versity International Law and Politics
 34:57-113, 2001, whose analysis 
roughly parallels the argument of this subsection.
19
 See http://www.un.org/aboutun/charter/chapter7.htm.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.258
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 7.5
 Threats of ForceŠPossible Examples
The following examples illustrate possible scenarios that raise questions 
about the de˜nition of the ﬁthreat of force.ﬂ
Zendia introduces cyber vulnerabilities into the critical infrastructure of its 
adversary Ruritania, but does not take advantage of them
. Since Ruritania suffers 
no ill effects from the fact that its infrastructure now has a number of vulnerabili
-ties, no armed attack or even use of force has occurred. Ruritania learns of the 

Zendian penetration because its cybersecurity experts have detected it technically. 

Does the Zendian action of introducing cyber vulnerabilities constitute a threat of 

force against Ruritania? Does it make a difference if these vulnerabilities could 

be used equally well for cyberexploitation as for cyberattack? Does the possibility 

that Zendia could take advantage of those agents on a moment™s notice make a 

cyberattack on Ruritania imminent, and if so, does it justify a Ruritanian strike on 

Zendia (cyber or otherwise) as an act of anticipatory self-defense?
A possibly helpful analogy is that of digging a tunnel underneath a border 
that terminates underneath a military facility. If Zendia digs such a tunnel under the 

Zendia-Ruritania border, and Ruritania discovers it, Ruritania may well regard it as 

a hostile act. But whether the tunnel amounts to an indication of imminent hostilities 

that would justify a Ruritanian strike on Zendia depends on many other factors.
Zendia discovers cyber vulnerabilities in the critical infrastructure of its 
adversary Ruritania, but does not take advantage of them
. These vulnerabilities are 
found in software used by both Zendia and Ruritania and supplied by a third-nation 

vendor. If Zendia noti˜es Ruritania of these vulnerabilities during a time of tension 

between the two nations, has Zendia threatened to use force against Ruritania? 
willing and unwilling. Second, effective economic sanctions generally 
require coordinated multilateral actions, whereas blockades can be con
-ducted unilaterally, though the coordination mechanism may or may not 

be tied to UN actions.
20
From the standpoint of effects-based analysis, traditional LOAC thus 
has some inconsistencies embedded within it regarding means used for 
20
 Some economic sanctions can be imposed unilaterally and still be effective. For ex
-ample, if the Zendian armed forces use a sophisticated weapons system that was originally 
produced in the United States, spare parts for that system may only be available from the 

United States. The United States could unilaterally choose to refrain from selling spare parts 

for that system to Zendia without violating LOAC, and such an action could have signi˜cant 

effects on the Zendian armed forces as the weapons system deteriorated due to a lack of 

spare parts. In addition, multilateral sanctions need not necessarily involve the United Na
-tions, as demonstrated by the Arab boycott of Israel, the Arab oil embargo of 1973, and the 

2008 ˜nancial sanctions against Iran.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 259
economic coercion, even if cyberattack is not involved. At the very least, 
it draws distinctions that are not entirely clear-cut. Accordingly, it is not 
surprising that such inconsistencies might emerge if cyberattack is used 

for economic coercion without the immediate loss of life or property. 

Legal analysts must thus determine the appropriate analogy that should 

guide national thinking about cyberattacks that result in severe economic 

dislocation. In particular, are such cyberattacks more like economic sanc
-tions or a blockade (or even some form of kinetic attack, such as the min
-ing of a harbor)? 
This question is particularly salient in the context of Internet-enabled 
commerce. The UN Security Council could decide to impose economic 

sanctions on a nation in order to compel that nation to follow some 

directive, and in principle those sanctions can be quite broad and sweep
-ing. If a large part of the target nation™s commerce was enabled through 

international Internet connections, the omission of such commerce from 

the sanctions regime might be a serious loophole.
21
 On the other hand, 
cyberattacks against the target nation might be required to prevent such 

commerce from taking place in a manner analogous to the UN™s use of 

naval and air forces to enforce certain past economic sanctions.
 Box 7.6 provides some scenarios in which the question of the most 
appropriate analogy arises.
One last caveat regarding the economic dimension of cyberattack: It 
is possible to imagine cyberattack as a tool for pursuing goals related to 

economic competition and/or economic warfare. It is clear that the laws 

of armed con˚ict and the UN Charter prohibit the use of forceŠcyber as 

well as kinetic forceŠin pursuit of purely economic or territorial gain. But 

the legitimacy of cyberattacks that do not constitute a use of force for eco
-nomic gain is not entirely clear. (As noted in Section 2.6.2, some nations 

do conduct espionage for economic purposes (an activity not prohibited 

by international law), and cyberattack might well be used to conduct 

espionage. And, as noted in Section 4.2.2, destructive cyberattacks might 

be used to gain economic advantage.)
7.2.2.1.5 
The De Facto Exception for Espionage
Espionage is an illegal activity under the domestic laws of virtually 
all nations, but not under international law. For example, Hays Parks has 

written:
21
 As a practical matter, many of the nations that are subject to sanctions are often not 
heavily dependent on Internet commerce, or at least they are not today. In addition, sanc
-tions are often not generalized but rather are targeted at speci˜c goods such as arms.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.26
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 7.6
 Cyberattack as Blockades or SanctionsŠ
 Possible Examples
The following examples illustrate possible scenarios that raise questions 
about whether to treat a cyberattack as a blockade or an economic sanction.
A continuing cyberattack that effectively disconnects Zendia™s access to 
the global Internet, when Zendia is the target of UN economic sanctions. 
In the 
modern era, a nation™s economic relations with the outside world may be more 
dependent on the Internet than a nation was dependent on maritime shipping in 

the mid-20th century. Should this type of cyberattackŠperhaps performed openly 

by a permanent member of the UN Security CouncilŠbe regarded as a blockade 

enforced through electronic means or as the enforcement of economic sanctions?
 Does it matter if the cyberattack targets only the Zendian connections to the out
-side world versus targeting internal communications nodes and routers?
A cyberattack that shuts down a key industry or segment of the armed 
forces of the targeted nation.
 Economic sanctions and blockades can be narrowly 
tailored to affect only certain industries. For example, sanctions and blockades 

could prevent the sale or distribution of spare parts necessary for the continuing 

operation of a certain industry. The same is true for spare parts needed to maintain 
and operate certain weapons systems. But a cyberattack could also have similar 
effectsŠand in particular could be carried out in such a way that the industry or 

military segment targeted was degraded slowly over time in a manner similar to 

its degradation due to the lack of spare parts. Thus, this kind of cyberattack could 

have effects identical to that of either blockades or economic sanctions, though 

one is regarded as a use of force and the other not.
Each nation endeavors to deny intelligence gathering within its territory 
through domestic laws . . . . Prosecution under domestic law (or the 

threat thereof) constitutes a form of denial of information rather than 
the assertion of a 
per se
 violation of international law; domestic laws are 
promulgated in such a way to deny foreign intelligence collection efforts 
within a nation™s territory without inhibiting that nation™s efforts to col
-lect intelligence about other nations. No serious proposal has ever been 
made within the international community to prohibit intelligence collec
-tion as a violation of international law because of the tacit acknowledge
-ment by nations that it is important to all, and practiced by each.
22
22
 W. Hays Parks,
 ﬁ
The International Law of Intelligence Collection,ﬂ pp. 433-434 
in 
National Security Law
, John Norton Moore et al., eds., 1990, cited in Roger D. Scott, 
ﬁTerritorially Intrusive Intelligence Collection and International Law, 
Air Force Law Re
view
 46:217-226, 1999, available at http://permanent.access.gpo.gov/lps28111/Vol.46 (1999)/
scottfx4[1].doc.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 261
If this legal approach is accepted, espionage conducted by or through 
the use of a computerŠthat is, cyberexploitationsŠis permissible under 
the LOAC regime, even if techniques are used that could also be used for 

destructive cyberattack. For example, cyberattacks may be used to disable 

cybersecurity mechanisms on a computer of interest so that a keystroke 

monitor can be placed on that computer. 
Nevertheless, espionage may raise LOAC issues if a clear distinction 
cannot be drawn between a given act of espionage and the use of force. For 

example, Roger Scott notes that certain forms of espionageŠfor instance 

involving ships, submarines, or aircraft as the collection platformsŠhave 

indeed been seen as military threats and have been treated as matters of 

armed aggression permitting a military response rather than domestic 

crimes demanding a law enforcement response.
23
 One common thread here appears to be that the collection platform 
is or appears to be a military assetŠa plane, a ship, a submarineŠthat 

could, in principle, conduct kinetic actions against the targeted nation. In 

all of these cases, the question of intent is central to the targeted nation 

at the time the potentially hostile platform is detected. Furthermore, the 

distinction between a cyberattack and a cyberexploitation may be very 

hard to draw from a technical standpoint, since both start with taking 

advantage of a vulnerability.

Does the introduction into an adversary system of a software agent 
with capabilities for both exploitation and destructive action constitute a 

use of force? It may be relevant to consider as an analogy the insertion 

into a potential adversary of a human agent skilled both in espionage and 

in sabotage.

Does the introduction of a remotely reprogrammable software 
agent into an adversary system constitute a use of force? A possible 

analogy in this case may be a preplanted mine that can be detonated by 

remote control from a long distance away.

Does a non-destructive probe of an adversary™s computer network 
for intelligence-gathering purposes to support a later cyberattack itself 

constitute a use of force? (An analogy might be drawn to the act of ˚y
-ing near an adversary™s borders without violating its airspace in order 

to trigger radar coverage and then to gather intelligence on the technical 

operating characteristics of the adversary™s air defense radars. Though 

such an act might not be regarded as friendly, it almost certainly does not 

count as a use of force.)
23
 Cited in Roger D. Scott, ﬁTerritorially Intrusive Intelligence Collection and Interna
-tional Law, 
Air Force Law Re
view
 46:217-226, 1999; available at http://permanent.access.gpo.
gov/lps28111/Vol.46 (1999)/scottfx4[1].doc.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.262
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Box 7.7 provides some scenarios in which such questions arise.
7.2.2.2
 During Ongoing HostilitiesŠApplying 
Jus in Bello
If an armed con˚ict is ongoing, cyberattacks on any military target 
(e.g., military command and control systems or an adversary™s defense 
industrial base) would satisfy the condition of military necessity. At the 

same time, the legality of such use would be subject to the 
jus in bello
 conditions regarding proportionality, distinction, and so on, just as they 

would affect decisions involving the use of kinetic weapons in any given 

instance. Note also that the attack/defense distinctionŠcentral to apply
-ing 
jus ad bellum
Šis not relevant in the midst of armed con˚ict and in the 
context of 
jus in bello
. Some of the issues raised by 
jus in bello
 for cyberat
-tack are described below. 
7.2.2.2.1 
Proportionality of Military Action
The proportionality requirement stipulates that military actions be 
conducted in a way that the military gain likely from an attack outweighs 

the collateral damage of that attack. For example, the electric power grid 

is often discussed as a likely target for cyberattack. In a full-scale nation
-wide mobilization, the electric power grid supports a nation™s war effort, 

and thus it might appear to constitute valid military targets in a con˚ict. 

But for an attack on it to be regarded as proportional, a judgment would 

have to made that the harm to the civilian population from disrupting 

electrical service was not disproportionate to the military advantage that 

might ensue from attacking the grid. 
Several characteristics of cyberattack affect proportionality judgments.

Predicting and understanding the actual outcome of a cyberattack 
is very intelligence-intensiveŠestimates of likely collateral damage and 
likely intended damage will depend on myriad factors (as discussed in 

Section 2.3.5). And much of this intelligence will be dif˜cult to obtain, 

especially on short notice. Thus, the a priori predictions of outcome and 

actual outcomes will often be highly uncertain. Of course, commanders 

must proceed even in the face of many uncertainties about the charac
-teristics of the target in both kinetic and cyber targeting, and they are 

not required to take into account outcomes and effects that are known 

to be very unlikely. But the open question is how commanders should 

account for uncertainties in outcome that are signi˜cantly greater than 

those usually associated with kinetic attacks in the sense that there may 

not be an analytic or experiential basis for estimating uncertainties at all. 

Under such circumstances, how is the proportionality judgment to be 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 263
made? What is clearly the 
wrong
 way to account for such uncertainties is 
to ignore them. Although it is a natural human tendency to ignore factors 
whose signi˜cance is unknown, in practice such behavior amounts to 

assigning zero weight to them.

Because the outcome of a cyberattack may depend on very small 
details known only to the party attacked, such parties may have greater 
BOX 7.7
 The LOAC Exception for EspionageŠ
 Possible Examples
The following examples illustrate possible scenarios that pose questions 
about whether a given cyber offensive action should be treated as cyberattack or 
cyberexploitation.
A cyber offensive action introduces a two-part software agent into an 
adversary system
. The software agent is designed with two parts. One part is 

used for cyberexploitation, monitoring traf˜c through the system and passing the 

traf˜c along to a collection point. A second part is potentially used for cyberat
-tack, awaiting an instruction to ﬁdetonate,ﬂ at which point it destroys the read-only 

memory controlling the boot sequence of the machine where it resides. Until the 

agent detonates, no damage has been caused to the system, and no use of force 

has occurred. On the other hand, the potential to do damage has been planted, 

and perhaps the act of planting the agent with a destructive component can be 

regarded as a threat of force. Under what circumstances, if any, does this offensive 

action constitute a use of force or the threat of force? The clandestine nature of 

the agent complicates matters furtherŠan essential dimension of ﬁthreatﬂ is that 

it must be known to the party being threatened, and there is a strong likelihood 

that the system owner will not know of the agent™s existence. Still, the owner could 

discover it on its own, and might well feel threatened after that point.
A cyber offensive action introduces an upgradeable software agent into 
an adversary system
. As introduced, the agent is an agent for cyberexploitation, 
monitoring traf˜c through the system and passing it along to a collection point. But 

through a software upgrade transmitted to the agent by clandestine means, the 

agent can then take destructive action, such as destroying the read-only memory 

controlling the boot sequence of the machine where it resides. A similar analysis 

applies in this instanceŠthe agent as introduced does not constitute a use of force, 

as it has no destructive potential. But it can easily be turned into a destructive 

agent, and perhaps the act of upgrading the agent with a destructive component 
can be regarded as a threat of force or an imminent attack. Under what circum
-stances, if any, does this offensive action constitute a use of force or the threat of 
force? 
A probe is launched to map an adversary™s computer network.
 As such, 
this operation is a cyberexploitationŠit is gathering intelligence on the network. 

Such an attack causes no damage to the network but provides the attacker with 

valuable information that can be used to support a subsequent cyberattack. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.26
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
opportunity to claim collateral damage from a cyberattack when in fact 
no such damage occurred. And the attacking party might well have a dif
-˜cult time refuting such claims, even if it were willing to divulge details 
about the precise nature of the cyberattack in question. So, for example, 

a cyberattack against an air defense network might lead to claims that 

the attack also shut down electric power to a hospital. The possibility of 

false claims exists with kinetic attacks as well, but claims about collateral 

damage from a cyberattack are likely to be even more dif˜cult to refute.

The damage assessment of a cyberattack necessarily includes indi
-rect as well as direct effects, just as it does when kinetic weapons are 

involved. These indirect effects, if they relate to effects on civilians, count 

in the proportionality judgment. Thus, for example, if a cyberattack to dis
-able a dual-use telephone switching station for several hours is contem
-plated, the fact that medical patient lives may be lost because the station 

serves a hospital must be factored into the judgment about whether the 

attack meets the proportionality requirement if such an outcome can be 

reasonably foreseen.

Some cyberattacks are potentially reversible. To the extent that the 
damage caused is reversible, a lesser amount of collateral damage should 

also be expected, and thus the calculation of weighing the military utility 

against collateral damage of a given cyberattack will be tilted more in 

favor of proceeding rather than refraining from the attackŠthat is, revers
-ibility will make the action more likely to be proportional, and could 

result in a cyberattack being preferred to a kinetic attack with all else 

being equal. (Indeed, even if the military effect is somewhat less, there 

may still be a LOAC obligation to use the less damaging cyberweapon if 

the collateral damage would be substantially lower.)
As an example, consider an electric power grid that serves both 
military and civilian purposes. The grid could be a legitimate military 

target, even if the civilian use is extensive, as long as the military use is 

very important to the enemy™s war effort. If the grid™s control centers are 

bombed, it may take a very long time to restore service when the war is 

over, but if they can be shut down by cyberattacks, it may be possible 

to restore service much more quickly. The military gain is achieved even 

by a short-term disruption (at least if the cyberattack can be repeated 

as needed), while in terms of impact on the civilian population there 

is a big difference between a loss extending for a few weeks or even 

longer during hostilities and one stretching long into the postcon˚ict 

reconstruction phase.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 265
7.2.2.2.2 
Distinctions 
Between Military, Ci
vilian, and Dual-Purpose Assets
Under traditional LOAC 
jus in bello
, only a nation™s military forces are 
allowed to engage in armed hostilities with another nation. In addition, 
a nation is entitled to attack combatants but must refrain from attacking 

non-combatants as long as the latter avoid any participation in the con
-˚ict. Cyberattacks raise a number of questions in this context:

Does compromising the computers of non-combatants violate pro
-hibitions against attacking non-combatants?

Under what circumstances does a cyberattack on national infra
-structure that affects both civilian and military assets constitute a LOAC 

violation?

What responsibilities does a nation have to separate civilian and 
military computer systems and networks?

Must military computer systems and networks be made identi˜
-able as such to a potential attacker if a nation is to claim immunity for 

civilian systems and networks?
Box 7.8 provides some possible scenarios in which such questions arise.
7.2.2.2.3 
Distinctions 
Between Military and Ci
vilian Personnel
The LOAC principle of distinction also confers different rights and 
responsibilities on combatants and non-combatants. Combatants are the 
only parties who are entitled to use force against the enemy. Combatants 

must also be trained in the law of war, serve under effective discipline, 

and be under the command of of˜cers responsible for their conduct.
24
 Whenever they are engaged in combat operations (and subject to the 

permissibility of employing a legitimate 
ruse de guerre
), they must be 
identi˜able (usually by carrying arms openly and wearing a distinctive 

uniform) as combatants. Lawful combatants captured by the enemy may 

not be punished for their combatant acts so long as they complied with 

the law of war; must be treated in accordance with agreed standards 

for the treatment of prisoners of war; and must be released promptly 

at the cessation of hostilities. The enemy is also entitled to target lawful 

combatants deliberately. Non-combatants have an af˜rmative duty to 
24
 Put differently, accountability mechanisms under LOAC are established through the 
doctrine of superior orders (i.e., someone higher in the chain of command has responsibility 
for the known or likely actions of someone lower in the chain of command) and the obliga
-tion to disobey manifestly illegal orders (someone lower in the chain of command has an 

obligation to obey lawful orders and a concomitant obligation to refuse to obey orders that 

are outside the scope of international standards).
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.266
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 7.8
 Ambiguities Raised by Cyberattack Against 
 Dual-Purpose AssetsŠPossible Examples
The following examples illustrate possible scenarios that raise questions re
-lated to attacks on dual-purpose assets.
A cyberattack can be routed to its ultimate target through intermediary 
computers. 
If the United States wishes to conduct a cyberattack on Zendia, it may 
wish to route its attack through the personal computers owned and operated by 
Zendian citizens. (For example, a botnet used to attack Zendia may well use such 

computers.) Does the compromise of the Zendian citizen computers constitute an 

ﬁattackﬂ on Zendian citizens?
One important point is that not all actions that harm the Zendian citizens 
constitute an attack for LOAC purposes. In the case of a personal computer being 

compromised for launching a cyberattack against Zendia, the harm to its Zendian 

owner is minimal, because that computer is likely just as useful to its owner as 
before. Even if it is not, it is hard to imagine that the owner might die as a result of 
the compromised computer, or even that the property damage suffered is signi˜
-cant, and, on the assumption that the attack has a proper military objective, any 

damage to civilian interests would be acceptable as collateral damage.
On the other hand, if the cyberattack was deemed to be a use of force or 
an armed attack against Zendia, the compromise of Zendian citizen computers to 
prosecute the attack might be regarded in the same veinŠthus making the attacker 
responsible for attacking civilians. In addition, the Zendian government might well 

take action against Zendian citizens, with unknown consequences for them (and 

possibly implicating human rights law, as discussed in Section 7.2.5).
A cyberattack can be directed against dual-use assets with both civilian 
and military uses.
 Traditional LOAC allows attacks on dual-use targets if the condi
-tions of military necessity, proportionality, distinction, and discrimination are met. 

The principle of distinction requires that the attacker distinguish between military 

and civilian targets and refrain from attacking the latter.
In traditional armed con˚ict, a combination of visual identi˜cation and geog
-raphy often suf˜ces to identify a valid military targetŠfor example, a tank is easily 
recognizable as a military vehicle and, if it is located behind enemy lines, can 
reasonably be presumed to be an enemy vehicle. But a computer is not so easily 
recognized, as both its functionality and geographic location are often not easily 
available to a would-be attacker.
For example, the commingling of civilian and military communications chan
-nels on media such as the Internet or the public switched telephone network 

might provide an adversary with a plausible military rationale for attacking facilities 

associated with these media. Moreover, given that civilian and military computer 

systems can be dif˜cult to distinguish, a question arises as to whether a nation that 

does not provide machine-readable indications of a computer™s status (military or 

civilian) would have the right to challenge the legality of a cyberattack that dam
-aged or destroyed a civilian computer. 
A large-scale cyberattack can be directed against (elements of) the critical 
infrastructure of a nation.
 As noted earlier, restraints on the use of biological and 
chemical weapons exist in part because they are inherently non
-discriminating 
weapons. Although there is no speci˜c ban on the use of non-discriminating weap
-ons per se,
 the proportionality requirement means that the military value of a given 
attack must be weighed against collateral damage. LOAC requires military forces 

to refrain from using a non-discriminating weapon when a more discriminating 

weapon would be equally effective, and also to refrain from attacking a military 

target when the only available means to do so is likely to cause disproportionate 

civilian damage. 
In a cyberattack context, this prohibition appears likely to apply to attacks that 
cannot be limited to speci˜c (military) targets. Thus, a computer network attack 

based on the Morris worm, for example, might be prohibited, because its effects 

were wholly indiscriminate and no effort was made to discriminate between ap
-propriate and inappropriate targets. The open question is whether the harm caused 

to civilians rises to a level that quali˜es as disproportionate. Mere inconveniences 

would not, but death on a large scale would. In between are cases such as the 

inability to conduct ˜nancial transactions electronically, periodic interruptions in 

electrical power, major disruptions in travel and transportation schedules, and 

outages in communications capability. 
refrain from participating in combatant activities, and are legally immune 
from deliberate targeting;
25
 non-combatants who engage in combatant 
activities are subject both to military action and, if captured, to criminal 

prosecution. 
Today, there is a growing dependence of the modern military on 
25
 Note, however, that the systems used to launch cyberattacks are legitimate military 
targets, and civilians who qualify for the narrow category of ﬁcivilians accompanying the 
armed forcesﬂ (presumably those who operate and maintain those systems)Ševen if they 

do not actually press the button that launches a cyberattackŠare both eligible for prisoner-

of-war status and also legitimate military targets for the enemy.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 267
BOX 7.8
 Ambiguities Raised by Cyberattack Against 
 Dual-Purpose AssetsŠPossible Examples
The following examples illustrate possible scenarios that raise questions re
-lated to attacks on dual-purpose assets.
A cyberattack can be routed to its ultimate target through intermediary 
computers. 
If the United States wishes to conduct a cyberattack on Zendia, it may 
wish to route its attack through the personal computers owned and operated by 
Zendian citizens. (For example, a botnet used to attack Zendia may well use such 

computers.) Does the compromise of the Zendian citizen computers constitute an 

ﬁattackﬂ on Zendian citizens?
One important point is that not all actions that harm the Zendian citizens 
constitute an attack for LOAC purposes. In the case of a personal computer being 

compromised for launching a cyberattack against Zendia, the harm to its Zendian 

owner is minimal, because that computer is likely just as useful to its owner as 
before. Even if it is not, it is hard to imagine that the owner might die as a result of 
the compromised computer, or even that the property damage suffered is signi˜
-cant, and, on the assumption that the attack has a proper military objective, any 

damage to civilian interests would be acceptable as collateral damage.
On the other hand, if the cyberattack was deemed to be a use of force or 
an armed attack against Zendia, the compromise of Zendian citizen computers to 
prosecute the attack might be regarded in the same veinŠthus making the attacker 
responsible for attacking civilians. In addition, the Zendian government might well 

take action against Zendian citizens, with unknown consequences for them (and 

possibly implicating human rights law, as discussed in Section 7.2.5).
A cyberattack can be directed against dual-use assets with both civilian 
and military uses.
 Traditional LOAC allows attacks on dual-use targets if the condi
-tions of military necessity, proportionality, distinction, and discrimination are met. 

The principle of distinction requires that the attacker distinguish between military 

and civilian targets and refrain from attacking the latter.
In traditional armed con˚ict, a combination of visual identi˜cation and geog
-raphy often suf˜ces to identify a valid military targetŠfor example, a tank is easily 
recognizable as a military vehicle and, if it is located behind enemy lines, can 
reasonably be presumed to be an enemy vehicle. But a computer is not so easily 

recognized, as both its functionality and geographic location are often not easily 

available to a would-be attacker.
For example, the commingling of civilian and military communications chan
-nels on media such as the Internet or the public switched telephone network 

might provide an adversary with a plausible military rationale for attacking facilities 

associated with these media. Moreover, given that civilian and military computer 

systems can be dif˜cult to distinguish, a question arises as to whether a nation that 

does not provide machine-readable indications of a computer™s status (military or 

civilian) would have the right to challenge the legality of a cyberattack that dam
-aged or destroyed a civilian computer. 
A large-scale cyberattack can be directed against (elements of) the critical 
infrastructure of a nation.
 As noted earlier, restraints on the use of biological and 
chemical weapons exist in part because they are inherently non
-discriminating 
weapons. Although there is no speci˜c ban on the use of non-discriminating weap
-ons per se,
 the proportionality requirement means that the military value of a given 
attack must be weighed against collateral damage. LOAC requires military forces 

to refrain from using a non-discriminating weapon when a more discriminating 

weapon would be equally effective, and also to refrain from attacking a military 

target when the only available means to do so is likely to cause disproportionate 

civilian damage. 
In a cyberattack context, this prohibition appears likely to apply to attacks that 
cannot be limited to speci˜c (military) targets. Thus, a computer network attack 

based on the Morris worm, for example, might be prohibited, because its effects 

were wholly indiscriminate and no effort was made to discriminate between ap
-propriate and inappropriate targets. The open question is whether the harm caused 

to civilians rises to a level that quali˜es as disproportionate. Mere inconveniences 

would not, but death on a large scale would. In between are cases such as the 

inability to conduct ˜nancial transactions electronically, periodic interruptions in 

electrical power, major disruptions in travel and transportation schedules, and 

outages in communications capability. 
civilians and civilian-provided services and expertise that blurs tradi
-tional distinctions between military and civilian activity and personnel. 
As a legal matter, civilians formally attached to the armed forces (e.g., as 

contractors) are entitled to some of the privileges of combatants (such as 

prisoner-of-war status if captured). Civilians engaged in self-help activi
-ties (which might resemble combatant activities) are subject to the regular 

criminal laws.
In light of the often-specialized expertise needed to launch computer 
network attacks (expertise that may be provided by civilians), an impor
-tant question is thus raised about what it means to ﬁlaunchﬂ an attack or 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.268
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
to ﬁuse force against an enemy.ﬂ
26
 Box 7.9 describes a possible continuum 
of civilian involvement in cyberattack.
In addition, the instruments of cyberattackŠcyberweaponsŠare eas
-ily available to private groups and individuals as well as governments, 
thus raising the possibility that private groups and individuals could 

join a con˚ict nominally prosecuted between nation-states. This point is 

further discussed in Section 7.2.3.3 below.
7.2.2.2.4
 Neutrality in a Cyberattack
A cyberattack that is conducted at a distance, especially one con
-ducted over the Internet, is likely to involve message traf˜c that physi
-cally transits a number of different nations. A cyberattack on Zendia 

initiated by the U.S. government may ˜rst be transmitted to Ruritania and 

then to Armpitia and ˜nally to Zendia. Moreover, it is entirely possible, 

likely even, that neither Ruritania nor Armpitia would be aware of the 

fact that they were carrying attack traf˜c at all.
26 
Such a question applies in many other contexts, such as civilians ˚ying missile-armed 
drones remotely, designing nuclear weapons, or working in an ammunition or uniform-
making factory.
BOX 7.9
 Drawing the LOAC Line for Civilian ImmunityŠ
Possible Examples
In a war involving the United States, civilians working in a U.S. munitions plant 
are likely not to enjoy LOAC protection from attack, as they are making a direct 

contribution to the U.S. war effort. In a cyber context, one can imagine several 

gradations of civilian involvement in launching a cyberattack, and where the line 

of LOAC protection should be drawn is an open question. That is, in which of the 

following scenarios is the civilian entitled to LOAC protection?
A civilian posts a vulnerability notice for the open source Linux operating 

system that a U.S. cyberattack exploits. 
A civilian contractor for the DOD identi˜es the presence of this vulner
-ability on a Zendian system.
A civilian exploits the vulnerability by introducing a hostile agent into the 

Zendian system that does not damage it but that can be directed to cause 

damage at a subsequent time.
A civilian dictates to a military of˜cer the precise set of commands needed 

to activate the hostile agent.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 269

Given that a computer of military signi˜cance can be located any
-where in the world, under what circumstancesŠif anyŠis it entitled to 
protection under LOAC provisions for neutrality?

What, if any, are the obligations of neutral nations to prevent cyber
-attacks from emanating from their territory? (ﬁEmanating from 
Xﬂ means 
that 
X is an intermediate node in the attack pathway.)

What, if any, are the obligations of belligerents to avoid routing 
cyberattacks through the computers of neutral nations?
Box 7.10 provides some scenarios in which such questions arise.
A paper by George Walker addresses some of the issues that arise in 
scenarios similar to those described in Box 7.10.
27
 Walker notes that legal 
guidance regarding information warfare (cyberattack) and neutrality will 
have to be found by analogy to existing international law, since existing 

law on neutrality does not address issues related to cyberwarfare. He 

argues that some LOAC principles, such as those related to telegraphy, 

will apply to Internet messages and more conventional communications, 

and further that there are many principlesŠprimarily in the law of naval 

warfare but also some from the law of land and air warfareŠthat may 

be cited by analogy in cyberwarfare involving neutrals. His reasoning is 

based on the premise that aerial warfare and especially naval warfare are 

conducted in ﬁ˚uidﬂ mediums, much like the Internet™s electronic path
-ways that are, like the high seas, no nation™s property. He also points to a 

relatively well-developed set of rules or general principles in the law of 

the sea, the law of naval warfare, and the law of air warfare, from which 

useful analogies for information warfare may be drawn. As an example 

of a useful analogy from the law of naval warfare, Walker suggests that 

a nation aggrieved by cyberattacks should have the right to take such 

actions as are necessary in the territory of a neutral that is unable (or 

perhaps unwilling) to counter enemy cyberattacks making unlawful use 

of that territory.
A contrary conclusion might be drawn by an analogy to telephone and 
telegraph communications as they were handled in the Hague Conven
-tion of 1907. Section 5, Article 8 of that convention stipulates that a neutral 

nation need not ﬁforbid or restrict the use on behalf of the belligerents of 

telegraph or telephone cables or of wireless telegraphy apparatus belonging 

to it or to companies or private individuals.ﬂ
28
 If there is no obligation of the 
neutral to stop the transit, there is no right of the belligerents to act against 

the transit. If the analogy between telegraph/telephone communications 
27 
George K. Walker, ﬁInformation Warfare and Neutrality,ﬂ 
Vanderbilt Journal of Trans
-national Law
 33(5):1079-1200, November 2000.
28 
See http://avalon.law.yale.edu/20th_century/hague05.asp#art5.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.27
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 7.10
 Cyberattack and NeutralityŠPossible Examples
The following examples illustrate possible scenarios that raise questions 
related to neutrality in a cyberattack context.
A cyberattack is launched against Zendia that requires transit through 
Ruritania, a declared neutral nation.
 In this instance, the open question is whether 
the transiting of a cyberattack is more like an over˚ight by military airplanes (in 
which case the intermediate nation has an obligation to stop such over˚ights or 

allow the other belligerent to do so) or more like the use of telephone and telegraph 
cables that are provided impartially to both sides (in which case the 1907 Hague 
Convention explicitly states that the intermediate nation is 
not obligated to prevent 
such use).
1During con˚ict between the United States and Zendia, a U.S. cyberat
-tack is launched on a computer controlling production in a Zendian defense plant. 

However, the computer itself is located in Ruritania, a declared neutral nation that 

provides computerized production control services to any nation willing to pay for 

them. 
A question arises because the effects of attacking a given computer may not 
be felt at all in the immediate geographic vicinity of the computer, thus raising the 

question of which geographic location is relevant to the determination of legitimacy 

for attack. That is, is the computer operating in Ruritania a valid military target?
A cyberattack is launched against the United States by an unknown party 
that depends on the use of compromised computers belonging to citizens and 

companies of Ruritania, a declared neutral nation. 
Under the doctrine of ﬁself-
 defense in neutral territory,ﬂ Ruritania must take action that eliminates the threat (in 
this case, the cyberattack) emanating from its territory,
2 allow or assist the United 
States to do so itself, or possibly face the consequences of a response from the 
United States. Complications arise regarding the sequencing of a self-defense 

response, because in the time that it takes to make a determination that Ruritania 

is unwilling or unable to stop the cyberattack, the damage to the United States may 

have been done, or the opportunity for an effective self-defense response lost.
1 Note an interesting side effect of a policy decision to avoid routing through neutral nations. 
If U.S. policy required avoidance of routing through neutrals, and if a target nation knew that 
policy, then said target could effectively shield itself from U.S. cyber operations by peering 
only with neutrals.
2 At the very least, such action would require the government of the putatively neutral nation 
to have the legal standing to stop such behavior and to demonstrate some plausible degree 
of cooperation in doing so.
and packet-switched Internet communications is valid (in both cases, the 
country transited has no real way of knowing the ultimate destination of 

transiting messages, and selective interference with the communications of 

belligerents is not practical), an analyst might conclude that belligerents do 

not have the right to interfere with nodes located in the neutral nation. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 271
7.2.2.2.5 
Co
vert Action
Covert action is statutorily de˜ned in the United States as ﬁan activ
-ity or activities of the United States Government to in˚uence political, 
economic, or military conditions abroad, where it is intended that the role 

of the United States Government will not be apparent or acknowledged 

publicly.ﬂ
29
 As discussed in Section 7.3.1, U.S. domestic law addresses 
agency responsibilities within the U.S. governmentŠcovert action is the 

responsibility of the intelligence agencies, whereas military activities are 

the responsibility of the Department of Defense. 
At the same time, international law is not sensitive to which agencies 
of a given government take action. This fact has at least two implications. 

First, 
jus ad bellum
 and the UN Charter apply to covert actionŠand an 
action with a scale of effect that would constitute a use of force or an 

armed attack if performed by U.S. military forces would be regarded in 

the same way even if it were designated as covert action by the President 

of the United States. Second, 
jus in bello
 would apply to any U.S. covert 
action involving the use of cyberattack during armed con˚ict.
7.2.2.2.6 
An Operational NoteŠ
Jus in Bello
 in Practice
U.S. military commanders undergo formal training in the laws of 
armed con˚ict so that they can appropriately direct their forces during 

combat. In most cases, senior commanders have the assistance of lawyers 

who can and do review a proposed course of action (such as an air tasking 

order) for LOAC compliance. 
Operating under combat conditions, commanders with signi˜cant 
experience in a particular kind of situation and with particular weapons 

have a good intuition for the outcome of a legal review of a proposed 

course of action. A LOAC review may result in adjusting the parameters 

of an attack at the margins, but the outcome of the review is largely a 

given (that is, the proposed action will be allowed) because the com
-mander with a certain amount of accumulated experience is unlikely to 

propose a course of action that is far outside the boundaries of what a 

legal review would allow. Under such circumstances (that is, in a kinetic 

war), the LOAC review process can be expedited if and when the com
-mander and the lawyers have both internalized the same general outline 

of what is and is not allowable under their shared legal paradigm. 
But when there is little or no experience on which to draw, the con
-gruence between the course of action proposed by commanders and what 
29 
50 USC 413b(e). See also Joint Explanatory Statement of the Committee of Confer
-ence, H.R. 1455, July 25, 1991, Intelligence Authorization Act of FY 1991.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.272
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
the lawyers would say is more likely to break down. This is particularly 
relevant if cyberweaponsŠwhich have been used much less often in com
-bat compared to kinetic weaponsŠare to be used. Today, relatively few 
commanders have substantial experience with cyberattack, and relatively 

few military lawyers have experience in rendering LOAC judgments 

about cyberattack (and lawyers are often reluctant to set new precedents 

in practice). Thus, where cyberattack is concerned, it is less likely that 

commanders and lawyers will have internalized similar boundaries of 

what is and is not acceptable.
One important consequence of this state of affairs is that one might 
expect LOAC review of cyberattack plans to be more challenging than 

review of kinetic attack plans. Consistent with this point, James Miller, 

former deputy assistant secretary of defense for requirements, plans 

and counterproliferation reported to the committee that because of the 

potential for unintended effects in cyber networks and sensitivity to the 

vulnerability of U.S. networks as well as the precedent-setting nature of 

decisions, LOAC review for cyber operations in Kosovo was indeed very 

challenging. 
7.2.2.3
 A Summary of Applying LOAC to Cyberattack
During acknowledged armed con˚ict (notably when kinetic and other 
means are also being used against the same target nation), cyberattack is 

governed by all the standard LOAC criteria of 
jus in bello
Šmilitary neces
-sity, proportionality, distinction, and so on, although the legal analysis in 

any given situation involving cyberattack may be more uncertain because 

of its novelty relative to kinetic weapons.
In other cases (that is, in less than acknowledged armed con˚ict), the 
legal status of a cyberattack is judged primarily by its effects, regardless 

of the means, according to the criteria of 
jus ad bellum
 and of the Charter 
of the United Nations. Therefore, if the effects (including both direct and 

indirect effects) to be produced by a cyberattack would, if produced by 

other means, constitute an armed attack in the sense of Article 51 of the 

UN Charter, it is likely that such a cyberattack would be treated as an 

armed attack. Similarly, if a cyberattack had the same effects and was 

otherwise similar to governmentally initiated coercive/harmful actions 

that are traditionally and generally not treated as the ﬁuse of forceﬂ (e.g., 

economic sanctions, espionage, or covert actions such as planting infor
-mation or in˚uencing elections), such a cyberattack would likely not be 

regarded as an action justifying a use of force in response.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 273
7.2.3
 International Law and Non-state Actors
International law binds nations, and only in exceptional cases binds 
non-state actors such as corporations, individuals, or terrorist groups. 
However, there are both domestic and international legal doctrines that 

restrict, and in most cases prohibit, non-state actors from actions that 

would be international use of force if undertaken by nation-states, and 

nations do have obligations in some circumstances to prevent these actors 

from acting in such ways that violate international law.
30
7.2.3.1
 International Law and Non-state ActorsŠTerrorists
Traditional LOAC emerged from the need to regulate nation-to-nation 
con˚ict between national military forces. But other forms of con˚ict in the 

1990s and 2000s (such as terrorism) have blurred many of the distinctions 

between the LOAC and domestic law enforcement. 
In such instances, both military and civilian dimensions are relevant 
and raise questions about the applicability of LOAC and law enforcement 

approaches.
31
 The dif˜culties arising are hard enough to resolve when 
the aggressive act is a tangible actionŠthat is, the use of deadly force to 

harm persons or destroy property. But they are compounded when the 

aggressive act is in cyberspace and its harm can only be assessed by con
-sequences that are not fully knowable except with the passage of time. 
These issues come to the fore in an international security environ
-ment involving subnational groups and non-state actors. In this new 
30
 Even prior to the September 11, 2001, attacks on the United States, a nation-state 
was responsible for the acts of private groups inside its territory over which it exercised 
ﬁeffective control.ﬂ (See, for example, Article 8 of the ILC (International Law Commission) 

State Responsibility Articles, available at http://untreaty.un.org/ilc/texts/instruments/

english/commentaries/9_6_2001.pdf, pp. 47 ff; and the ICJ (International Court of Justice) 

Nicaragua decision (arguing for ﬁeffective controlﬂ) and the ICTY (International Criminal 

Tribunal for Yugoslavia) Tadic decision (arguing for ﬁoverall controlﬂ).) In the aftermath of 

those attacks, the United States took the position that the mere harboring of these actors, 

even in the absence of control over them, suf˜ces to make the state where the terrorists are 

located responsible for their actions (UN Security Council, ﬁLetter Dated 7 October 2001 

From the Permanent Representative of the United States of America to the United Nations 

Addressed to the President of the Security Council,ﬂ UN Doc. No. S/2001/946 (2001)), and 

many parts of the international community, including the UN Security Council, concurred 

with this position (see Derek Jinks, ﬁState Responsibility for the Acts of Private Armed 

Groups,ﬂ 
Chicago Journal of International Law
 4(1):83-96, Spring 2003).
31 
Human rights advocates sometimes assert that human rights law also applies even 
when LOAC applies. Although this assertion is categorically rejected by the U.S. govern
-ment, the political reality is that this argument is likely to resonate with some outside ob
-servers and thereby raise the level of world scrutiny for all U.S. uses of military force, thus 
adding to the political pressures on the United States in a crisis.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.27
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
environment, questions have arisen as to whether terrorists are subject 
to LOAC, to criminal law, or to some other body of law that has yet to 
be established. Although the Supreme Court held that common Article 3 

of the 1949 Geneva Conventions applied to the con˚ict against Al Qaeda 

and the Taliban authorized by Congress on September 14, 2001 (
Hamdan 
v. Rumsfeld
), it is generally fair to say that the details of how LOAC does 
and does not apply in a con˚ict with terrorists are far less developed and 

clear than in a con˚ict between nation-states.
Nevertheless, a number of practical considerations arise in dealing 
with non-state actors given that these actors (call them terrorists for now) 

will almost surely be operating from the territory of some nation-state. 

Therefore, any action taken against them may raise issues about violating 

the sovereignty of that nation and its rights and obligations with respect 

to terrorist operations from or through its territory.
All of the above issues apply in contemplating cyberattacks as they 
might be conducted by terrorists. Cyberattack weapons are inexpensive 

and easily available but may have the potential to cause widespread 

damage and destruction, characteristics that may make such weapons 

attractive to terrorists. 
The important question is whether, when, and why a cyberattack by 
a non-state actor should be treated primarily as a law enforcement matter, 

a national security matter, or a mix of the two. (The ˜rst manifestations 

of a cyberattack are likely to require investigation to determine its source. 

But once such a determination has been made, this threshold question will 

inevitably arise.)
One relevant question in making such a determination is whether 
the attack has serious enough consequences (death or destruction) that it 

would qualify as a use of force or an armed attack on the United States 

had it been carried out with kinetic means. A second question concerns 

the geographic origin of the attack. A third question may be the nature 

of the party responsible for the attack (e.g., national government, ter
-rorist group). As a factual matter, none of these pieces of information 

may be known at the time the attack becomes known (as discussed in 

Section 2.4.1 on tactical warning and attack assessment); nevertheless, 

these questions will be prominent in the minds of senior decision makers 

because the answers may have profound implications for the legitimacy 

of a response.
If and when the geographic origin of the attack becomes known (call 
it Zendia), Zendia may have one of several stances toward cooperation 

with the United States. At one extreme, Zendia may cooperate fully with 

the United States in stopping the attack emanating from its soil, where full 

cooperation can mean anything from placing Zendian law enforcement 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 275
and security services at U.S. disposal to giving permission for the United 
States to act as it sees ˜t in its response to the attack. At the other extreme, 
Zendia may simply refuse outright any and all U.S. requests for assistance 

and cooperation. And Zendia™s cooperation may fall onto 
any
 point along 
this spectrum, raising a variety of legal and policy issues. For example:

Even if Zendia wishes to cooperate fully, it may not have the legal 
authority to address the hostile activity in question. That is, the activity 

may not violate any Zendian law. If Zendia is a signatory to the Cyber
-crime Convention, it is obligated to extend such cooperation if the cyber 

activity emanating from Zendian soil is considered a criminal matter 

under Zendian law. Nevertheless, not all nations are signatories to the 

convention, and the convention itself is oriented toward a law enforce
-ment approach (that is, investigation, arrest, prosecution, and legal due 

process) that is often too slow given how rapidly a cyberattack can unfold. 

Finally, ﬁpermissionﬂ can be ambiguous, as in those instances when there 

is some doubt or question about who speaks for the ﬁlegitimateﬂ govern
-ment of Zendia.

If Zendia explicitly refuses to cooperate, the United States could 
assert the right of self-defense in neutral territory discussed in Section 

7.2.1.2. To be sure, such a decision would be a policy decision and would 

depend on a host of factors such the scope and nature of the proposed U.S. 

action, whether Zendia is capable of resisting unilateral U.S. actions taken 

in response, and other areas of U.S.-Zendian cooperation or contention. 

(For example, if Zendia has nuclear weapons capable of reaching U.S. 

targets, the decision-making calculus for policy may change considerably 

though the legal issues do not.)

Perhaps the most problematic response is a posture of limited, 
grudging, or excessively slow Zendian cooperation, or words that indicate 

cooperation but are unaccompanied by matching actions. For example, 

permission for the United States to undertake various actions might be 

slow in being granted, or unduly circumscribed in a way that impeded 

further investigation or action; information provided to the United States 

might be incomplete. Under these circumstances, the Zendian response 

could conceivably take a very long time and would be unlikely to be fully 

satisfactory to the United States. Yet even if the response is inadequate 

for U.S. purposes, it might still be enough to sway the court of world 

opinion against an aggressive U.S. response and perhaps even to forestall 

it. Even though a deliberate stalling is probably equivalent to an outright 

refusal to cooperate, making the determination that Zendia is being delib
-erately uncooperative may be problematic in the absence of an explicit 

statement.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.276
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
7.2.3.2
  
International Law and Non-state ActorsŠMultinational 
Corporations
Barkham
32
 notes that many multinational corporations exercise power 
and in˚uence that at times rivals those of small nation-states. Interna
-tional law (including LOAC) also does not directly constrain the actions 
of such corporations to any signi˜cant extent. On the other hand, they are 

subject to the laws of those nations in which they have a presence, and 

sometimes those laws result from government-to-government agreements 

(of which the Convention on Cybercrime (discussed below in Section 

7.2.4) is an example).
Of signi˜cance to this report is the fact that certain multinational cor
-porations will have both expertise and resources to launch cyberattacks 

of a signi˜cant scale should they choose to do so. If they did, such mul
-tinational corporations might threaten cyberattacks against weak nation-

states to gain concessions or launch cyberattacks against economic com
-petitors to place them at a competitive disadvantage (e.g., by disrupting 

production). 
7.2.3.3
 International Law and Non-state ActorsŠPatriotic Hackers
LOAC presumes that armed con˚ict is initiated only at the direc
-tion of government, only by its authorized military agents, and speci˜
-cally not by private groups or individuals. Thus, governments maintain 

armed forces to participate in armed con˚ict, under the government™s 

direction. 
But in the Internet era, another type of non-state actor that compli
-cates the legal landscape for cyberattack is the ﬁhacktivistﬂ or patriotic 

hacker. During times of con˚ict (or even tension) with another nation, 

some members of a nation™s citizenry may be motivated to support their 

country™s war effort or political stance by taking direct action (Box 7.11). 

Hacktivists or patriotic hackers are private citizens with some skills in the 

use of cyberattack weapons, and they may well launch cyberattacks on 

the adversary nation on their own initiative, that is, without the blessing 

and not under the direction or control of the government of their nation. 
Apart from their possible operational interference with other, govern
-ment-authorized actions, the actions of these patriotic hackers may greatly 

complicate the conduct of diplomatic action. For example, if Zendian 

patriotic hackers launch cyberattacks against the United States, the United 

States is entitled to respond as though the Zendian government were 
32
 Jason Barkham, ﬁInformation Warfare and International Law on the Use of Force,ﬂ 
New York Uni
versity International Law and Politics
 34:57-113, 2001.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 277
responsible. Whether it should do so is a policy question.
33
 What if the 
patriotic hackers are part of the Zendian diaspora and are located in ter
-ritories other than Zendia? What actions should the United States take to 
respond to Zendian patriotic hackers if the Zendian government says in 

response to a U.S. inquiry, ﬁWe do not endorse or encourage these attacks 

by our citizens, but at the same time, they are not doing anything that we 

have the ability (or perhaps the legal authority) to stop, so the best thing 

for you to do is to cease your aggressive actions against Zendia.ﬂ? Note 

the similarity of this situation involving Zendian patriotic hackers to the 

situation discussed in Section 7.2.3.1 involving cyberterrorists operating 

from Zendian soil.
As noted in Section 7.2.1.2, states likely have af˜rmative obligations to 
refrain from harboring perpetrators of terrorist attacks. To the extent that 

Zendia supports patriotic hackers in their activities, other nations targeted 

by these parties may have a legitimate complaint to bring forward in an 

appropriate international tribunal by asserting that Zendia is indeed har
-boring perpetrators of terrorist activityŠindeed, these other nations may 

well be entitled to invoke inherent rights of self-defense consistent with 

Article 51. One signi˜cant question in this regard is whether a failure to 

suppress the activities of patriotic hackers should count as support for 

them.
7.2.4
 The Convention on Cybercrime
The Convention on Cybercrime commits signatories to the adoption of 
ﬁa common criminal policy aimed at the protection of society against cyber
-crime . . . by adopting appropriate legislation and fostering international 

co-operation.ﬂ
34
 The convention establishes a common minimum standard 
of relevant offenses to be applied at the national level in several areas. 

Five criminal offenses are speci˜cally de˜ned to protect the con˜dentiality, 

integrity, and availability of computer data and systems, namely:

Illegal access
Šintentional access to the whole or any part of a com
-puter system without right, where the offence may be considered to have 
33
 As a precedent, the International Court of Justice held in the 1980 
U.S. 
v. Iran
 case that 
the actions of a state™s citizens can be attributed to the government if the citizens ﬁacted on 
behalf on [sic] the State, having been charged by some competent organ of the Iranian State 

to carry out a speci˜c operation.ﬂ Further, the court found that the Iranian government was 

responsible because it was aware of its obligations under [international law] to protect the 

U.S. embassy and its staff, was aware of the embassy™s need for help, had the means to assist 

the embassy, and failed to comply with its obligations. See United States Diplomatic and 

Consular Staff in Tehran (
U.S. 
v. Iran
), 1980 I.C.J. 3, 29 (May 24). Cited in Barkham, 2001.
34 
Council of Europe, Convention on Cybercrime, November 23, 2001. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.278
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 7.11
 Hacktivism During International Conflict and Tension
A number of incidents of privately undertaken cyberattacks have been 
publicized:
Immediately after the start of the second intifada in Israel in late Septem
-ber 2000, Palestinian and Israeli hackers conducted a variety of cyberattacks on 
each other™s national web presences on the Internet.
1 In the aftermath of the early 2001 incident between the United States and 
China in which a U.S. EP-3 reconnaissance aircraft collided with a Chinese F-8 

interceptor, both Chinese and U.S. hackers attacked the web presence of the other 

nation. In both cases, attacks were aimed mostly at website defacement and denial 

of service.
2 In the wake of the May 1999 bombing by the United States of the Chinese 
embassy in Belgrade, the U.S. National Infrastructure Protection Center issued 

an advisory (NIPC Advisory 99-007) noting ﬁmultiple reports of recent hacking 

and cyber activity directed at U.S. government computer networks, in response 

to the accidental bombing of the Chinese embassy in Belgrade. . . . Reported 

activity include[d] replacing of˜cial web pages with protest material and offensive 

language, posting similar language in chat rooms and news groups, and denial of 

service e-mail attacks.ﬂ
3 American hackers have been known to attack jihadist websites. For ex
-ample, an American was reported by 
Wired to have hijacked www.alneda.com, a 
widely used website for jihadist recruitment.
4 His motive for doing so was said to 
be a decision made after the September 11 attacks: ﬁI was going to use every skill 

I had to screw up the terrorists™ communication in any way I could.ﬂ
Russian hackers are widely reported to have been responsible for the cy
-berattacks on Estonia in 2007 (see Box 3.4 in Chapter 3) and Georgia in 2008.
5Allen and Demchak generalize from experiences such as these to predict that 
future con˚icts between nations may involve:
 Spontaneous attack action in cyberspace by ﬁpatriotsﬂ on each side.
Rapid escalation of their actions to a broad range of targets on the other 
side. Allen and Demchak posit that because ﬁhacktivistsﬂ are interested in making 

a statement, they will simply attack sites until they ˜nd vulnerable ones.
Involvement of sympathetic individuals from other nations supporting the 
primary antagonists.
1 Associated Press, ﬁCyberwar Also Rages in Mideast,ﬂ October 26, 2000, available at 
http://www.wired.com/politics/law/news/2000/10/39766.
2 Michelle Delio, ﬁA Chinese Call to Hack U.S.,ﬂ 
Wired
, April 11, 2001, available at http://www.
wired.com/news/politics/0,1283,42982,00.html.
3 See NIPC Advisory 99-007, available at http://www.merit.edu/mail.archives/netsec/1999-
05/msg00013.html.4 Patrick Di Justo, ﬁHow Al-Qaida Site Was Hijacked,ﬂ 
Wired, August 10, 2002, available at 
http://www.wired.com/culture/lifestyle/news/2002/08/54455.
5 ﬁExpert: Cyber-attacks on Georgia Websites Tied to Mob, Russian Government,ﬂ 
Los Ange
-les Times
, August 13, 2008, available at http://latimesblogs.latimes.com/technology/2008/08/
experts-debate.html.
SOURCE: Adapted largely from Patrick D. Allen and Chris C. Demchak, ﬁThe Palestinian-Israel: 
Cyberwar,ﬂ 
Military Review
 83(2), March-April 2003.
occurred if security measures are infringed with the intent of obtaining 
computer data or other dishonest intent or where computer systems are 

networked.

Illegal interception
Šintentional interception without right, made by 
technical means, of non-public transmissions of computer data to, from, 

or within a computer system, including electromagnetic emissions from 

a computer system carrying such computer data.

Data interference
Šintentional damage, deletion, deterioration, 
alteration, or suppression of computer data without right.

System interference
Šintentional serious hindering without right of 
the functioning of a computer system by inputting, transmitting, damag
-ing, deleting, deteriorating, altering, or suppressing computer data.

Misuse of de
vicesŠ
intentional production, sale, procurement for 
use, import, distribution, or possession of a computer password, access 

code, or device, including a computer program, designed or adapted 

primarily for the purpose of committing any of the other four offenses. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 279
BOX 7.11
 Hacktivism During International Conflict and Tension
A number of incidents of privately undertaken cyberattacks have been 
publicized:
Immediately after the start of the second intifada in Israel in late Septem
-ber 2000, Palestinian and Israeli hackers conducted a variety of cyberattacks on 
each other™s national web presences on the Internet.
1 In the aftermath of the early 2001 incident between the United States and 
China in which a U.S. EP-3 reconnaissance aircraft collided with a Chinese F-8 

interceptor, both Chinese and U.S. hackers attacked the web presence of the other 

nation. In both cases, attacks were aimed mostly at website defacement and denial 

of service.
2 In the wake of the May 1999 bombing by the United States of the Chinese 
embassy in Belgrade, the U.S. National Infrastructure Protection Center issued 

an advisory (NIPC Advisory 99-007) noting ﬁmultiple reports of recent hacking 

and cyber activity directed at U.S. government computer networks, in response 

to the accidental bombing of the Chinese embassy in Belgrade. . . . Reported 

activity include[d] replacing of˜cial web pages with protest material and offensive 

language, posting similar language in chat rooms and news groups, and denial of 

service e-mail attacks.ﬂ
3 American hackers have been known to attack jihadist websites. For ex
-ample, an American was reported by 
Wired to have hijacked www.alneda.com, a 
widely used website for jihadist recruitment.
4 His motive for doing so was said to 
be a decision made after the September 11 attacks: ﬁI was going to use every skill 

I had to screw up the terrorists™ communication in any way I could.ﬂ
Russian hackers are widely reported to have been responsible for the cy
-berattacks on Estonia in 2007 (see Box 3.4 in Chapter 3) and Georgia in 2008.
5Allen and Demchak generalize from experiences such as these to predict that 
future con˚icts between nations may involve:
 Spontaneous attack action in cyberspace by ﬁpatriotsﬂ on each side.
Rapid escalation of their actions to a broad range of targets on the other 
side. Allen and Demchak posit that because ﬁhacktivistsﬂ are interested in making 

a statement, they will simply attack sites until they ˜nd vulnerable ones.
Involvement of sympathetic individuals from other nations supporting the 
primary antagonists.
1 Associated Press, ﬁCyberwar Also Rages in Mideast,ﬂ October 26, 2000, available at 
http://www.wired.com/politics/law/news/2000/10/39766.
2 Michelle Delio, ﬁA Chinese Call to Hack U.S.,ﬂ 
Wired
, April 11, 2001, available at http://www.
wired.com/news/politics/0,1283,42982,00.html.
3 See NIPC Advisory 99-007, available at http://www.merit.edu/mail.archives/netsec/1999-
05/msg00013.html.4 Patrick Di Justo, ﬁHow Al-Qaida Site Was Hijacked,ﬂ 
Wired, August 10, 2002, available at 
http://www.wired.com/culture/lifestyle/news/2002/08/54455.
5 ﬁExpert: Cyber-attacks on Georgia Websites Tied to Mob, Russian Government,ﬂ 
Los Ange
-les Times
, August 13, 2008, available at http://latimesblogs.latimes.com/technology/2008/08/
experts-debate.html.
SOURCE: Adapted largely from Patrick D. Allen and Chris C. Demchak, ﬁThe Palestinian-Israel: 
Cyberwar,ﬂ 
Military Review
 83(2), March-April 2003.
Criminal possession may be de˜ned as the possession of a number of such 
devices. No criminal liability is imposed where the intent is for reasons 

other than to commit any of the other four offenses.
The Convention on Cybercrime also identi˜es a number of ordinary 
crimes that are often committed through the use of computer systems, 

including forgery and fraud.
The convention de˜nes a computer system to be ﬁany device or a 
group of interconnected or related devices, one or more of which, pursu
-ant to a program, performs automatic processing of data.ﬂ Computer data 

is de˜ned to be ﬁany representation of facts, information or concepts in a 

form suitable for processing in a computer system, including a program 

suitable to cause a computer system to perform a function.ﬂ
The convention calls for signatories to adopt domestic laws that crimi
-nalize the above offenses, to provide domestic law enforcement agen
-cies with the authorities and powers necessary for the investigation and 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.28
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
prosecution of such offenses (as well as other offenses committed using a 
computer system), and to establish an effective regime of international co-
operation, including provisions for extradition and mutual law enforce
-ment assistance. Notably, the convention does not establish espionage as 

an act that violates international law. 
As of December 21, 2007, 43 nations had signed the Convention on 
Cybercrime, of which 21 have rati˜ed it.
35
 The U.S. Senate rati˜ed the 
convention in August 2006 and took the view that prior U.S. legislation 

provided for all that the convention required of the United States. Many 

but not all European nations have also rati˜ed the treaty.
The convention is signi˜cant to the extent that it commits the parties 
to regard the commission of the various listed offenses as matters that 

are actionable for the law enforcement authorities of the nation in whose 

jurisdiction the offenses were committed. (The convention is silent on 

what actions may be taken by the nation of the victim of such offenses.) 

That is, if these offenses are committed within the jurisdiction of a signa
-tory nation, that nation is obligated to respond to them as criminal actsŠ

and in particular is required to establish mechanisms for law enforcement 

cooperation to investigate and prosecute these acts should they occur. 

Thus, if a cyberattack is launched on the United States in a way that 

involves another signatory to the Convention on Cybercrime, that nation 

is obligated to cooperate with the United States in trying to identify the 

perpetrator.
Of course, not all of the nations of the world have signed on to the 
Convention on Cybercrime, and a nation™s prosecution of cybercriminals 

and/or its cooperation with an attacked state may be less than zealous. 

Indeed, the convention also allows a signatory to refuse to provide assis
-tance if the request for assistance concerns an offense that the signatory 

considers a political offense or if carrying out the request is likely to preju
-dice the signatory™s sovereignty, security, public order, or other essential 

interests.
36
 The signatory may also postpone action on a request if such 
action would prejudice criminal investigations or proceedings conducted 

by its authorities.
37
 In short, a signatory nation may decline to cooperate with its obliga
-tions under the convention on fairly broad grounds, and the convention 

lacks an enforcement mechanism to assure that signatories will indeed 

cooperate in accordance with their obligations. Even in the case of a fully 

cooperative nation, it may still take a long time to identify a perpetrator 
35 
See http://conventions.coe.int/Treaty/Commun/ChercheSig.asp?NT=185&CM= 
8&DF=&CL=ENG.
36
 Council of Europe, Convention on Cybercrime, Article 27(4).
37 
Council of Europe, Convention on Cybercrime, Article 27(5).
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 281
and to use legal means to shut down his/her/its criminal cyber activity. 
Thus, the Convention on Cybercrime would appear to have limited util
-ity in addressing hostile cyberattacks on a prompt time scale, and none at 
all if a nation refuses to cooperate on any of the broad grounds described 

above.
7.2.5
 Human Rights Law
Human rights are restraints on the actions of governments with 
respect to the people under their jurisdiction. They can be national in 

origin (i.e., the civil and political rights under the U.S. Constitution), they 

may be contained in an international human rights treaty (i.e., the Con
-vention on the Elimination of Discrimination Against Women), or they 

may be inherent in customary international law.
A central point of contention in human rights law today is the extent 
of its applicability in situations in which the law of armed con˚ict is 

operative, that is, in acknowledged armed con˚ict or hostilities. The posi
-tion of the U.S. government is that the moral and ethical imperatives of 

minimizing unnecessary human suffering are met by the requirements 

of LOAC (
jus in bello
), and thus that human rights law should not place 
additional constraints on the actions of its armed forces. By contrast, 

many human rights observers and non-government organizations would 

argue that human rights law can and should apply as well as LOAC (
jus 
in bello
) in acknowledged armed con˚ict.
As for the governing regime prior to armed con˚ict, the relevant ques
-tion is the extent to which human rights law applies before the consider
-ations of 
jus ad bellum
 are addressed, that is, before combat.
The major treaty relevant to human rights law is the International 
Covenant on Civil and Political Rights (ICCPR), rati˜ed by the United 

States in September 1992. Although a variety of human rights organiza
-tions strongly disagree, the United States has argued that the ICCPR does 

not apply extraterritorially, and so it would not regulate U.S. behavior in 

other countries. This position is based on the text of Article 2 of the ICCPR 

(the Covenant applies to ﬁ. . . all individuals within its territory and sub
-ject to its jurisdiction . . . ﬂ) and supported by the negotiating history. 
If the U.S. position is accepted, cyberattacks that do not rise to the 
level of armed con˚ict have no implications from an ICCPR/human 

rights perspective. If the contrary position is accepted, then two of the 

rights enumerated in the ICCPR may be relevant to the cyber domain 

in particular. Article 17 (protecting privacy and reputation) might speak 

to cyberattacks intended to harm the reputation of an individual, e.g., 

by falsifying computer-based records about transactions in which he or 

she had engaged, or to uncover private information about an individual. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.282
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
Article 19 (protecting rights to seek information) might speak to cyberat
-tacks intended to prevent citizens from obtaining access to the Internet or 
other telecommunications media.
A variety of other rights, such as the right to life, are potentially 
relevant as well, although they do not seem as closely tied to the cyber 

domain. Respecting these other rights would suggest, for example, that 

a cyberattack intended to enforce economic sanctions would still have to 

allow transactions related to the acquisition of food and medicine.
7.2.6
 Reciprocity
Although U.S. policy will be based on an analysis of what future 
legal regime would best serve the interests of the United States (includ
-ing whatever political value can be found in asserting the stance), that 

analysis must take into account the extent and nature of the effects of such 

regimes on other parties, both other nation-states and subnational entities, 

and the likelihood that these other parties might feel obligated to comply 

with such a regime.
For example, the United States may decide that an expansive de˜ni
-tion of ﬁuse of forceﬂ prohibiting most uses of cyberattack would help to 

protect the viability of the U.S. information technology infrastructure in 

the face of international threats. But such a de˜nition would also prohibit 

most prekinetic con˚ict uses of cyberattack by the United States as well. 

Alternatively, it may decide that other key nations would not comply 

with an expansive de˜nition,
38
 and thus that a restrictive de˜nition might 
 better serve U.S. interests by allowing most uses of cyberattack.
7.3
 DOMESTIC
 LAW
 As noted in Section 7.1, domestic law (which includes the Constitu
-tion of the United States, federal statutes, and self-executing treaties) 
constrains both government institutions and private individuals. For 

example, U.S. domestic law regulates the division of labor regarding 

operational activities between the DOD and the intelligence agencies for 

reasons of government accountability and oversight. Generally, activities 

of the Department of Defense (DOD) are governed by Title 10 of the U.S. 

Code, and activities of the intelligence community (IC) by several sections 

of Title 50. U.S. domestic law also provides substantive law governing 
38 Many analysts believe that China is an example of a nation that might well be unwill
-ing to give up a cyberattack-based avenue of asymmetric confrontation against the United 
States. See for example, Timothy Thomas, 
Decoding the Virtual Dragon, 
Foreign Military 
Studies Of˜ce, Fort Leavenworth, Kans., 2007.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 283
what private parties can and cannot do, both through highly cyber-spe
-ci˜c statutes and more general laws on property, self-defense, and so on.
 In general, a state is entitled to use any method for law enforcement 
within its territory or with respect to its citizens that is consistent with 
its domestic law. Within the United States, domestic law regulates police 

conduct and electronic surveillance, and imposes limits on searches or 

arrests without probable cause and on the unreasonable use of force 

in making lawful arrests or during other enforcement activities. Under 

international law, a state must avoid conduct that amounts to torture, 

genocide, or other blatant and generalized violations of human rights 

described in the ICCPR.
7.3.1
 Covert Action and Military Activity 
Chapter 4 addresses some of the operational and policy consider
-ations underlying covert action. But the legal framework governing covert 

action is also important.
As noted in Chapter 4, covert action has a statutory de˜nition. How
-ever, the 1991 Intelligence Authorization Act also included a provision, 

now codifed at 50 USC 413b, that distinguished between covert actions 

and ﬁtraditional military activities,ﬂ ﬁtraditional counterintelligence activi
-ties,ﬂ ﬁtraditional diplomatic activities,ﬂ and ﬁtraditional law enforcement 

activities.ﬂ The legislation does not de˜ne any of the traditional activities, 

but the conference report stated the intent of the conferees that:
39
ﬁtraditional military activitiesﬂ include activities by military personnel 
under the direction and control of a United States military commander 

(whether or not the U.S. sponsorship of such activities is apparent or 
later to be acknowledged) preceding and related to hostilities which are 
either anticipated (meaning approval has been given by the National 

Command Authorities for the activities and for operational planning for 

hostilities) to involve U.S. military forces, or where such hostilities in
-volving United States military forces are ongoing, and, where the fact of 

the U.S. role in the overall operation is apparent or to be acknowledged 

publicly. In this regard, the conferees intend to draw a line between ac
-tivities that are and are not under the direction and control of the military 

commander. Activities that are not under the direction and control of a 
military commander should not be considered as ﬁtraditional military 
activities.ﬂ 
 Covert action requires a written presidential ˜nding in advance of the 
action that the action is necessary to support identi˜able foreign policy 
39
 Conference Report on H.R. 1455 (House of Representatives), July 25, 1991, available 
at http://www.fas.org/irp/congress/1991_cr/h910725-ia.htm.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.28
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
objectives of the United States, submission of the ˜nding to the chairmen 
of the congressional intelligence oversight committees, and noti˜cation 
of congressional leaders of the action. By contrast, no ˜ndings, special 

approval, or noti˜cation are needed for conducting any of the tradi
-tional military activities, although activities conducted by the uniformed 

military are subject to the guidance of and restrictions imposed by the 

law of armed con˚ict, and, in practice, many highly sensitive military 

operationsŠif conducted outside the framework of a general armed con
-˚ictŠhave been brought to the attention of congressional leadership. 
Finally, 50 USC 413b(f) states that ﬁno covert action may be conducted 
which is intended to in˚uence United States political processes, public 

opinion, policies, or media.ﬂ In practice, U.S. decision makers have some
-times interpreted this provision to mean that no covert action may be 

conducted that is likely to have such an effect in the United States. Under 

this interpretation, the use of cyberattack to disseminate false information 

as part of a covert action might be illegal if such information made it back 

to the U.S. news media. 
The matter is complicated by the fact that for certain kinds of covert 
action, DOD assets will be needed to execute the applicable plans. Under 

such circumstances, it is less clear whether the planned action is or is not 

subject to noti˜cation as covert action. In addition, because the mecha
-nism for covert action authorization calls generally for the noti˜cation of 

the appropriate congressional leaders, delay in execution may be possible 

and negotiation about its terms may be necessary if these leaders object 

to the action.
The domestic legal requirements for undertaking a covert action 
require only that the President personally ˜nd that the action supports 

identi˜able foreign policy objectives of the United States and that the 

action is important to the national security of the United States. Thus, as 

a legal matter, the requirements for a ˜nding regarding an action employ
-ing lethal force are the same as for a ˜nding not employing lethal force, 

and a covert action may use enough lethal force (or destructive force) that 

it would clearly be a ﬁuse of force,ﬂ where ﬁuse of forceﬂ is used in the 

sense of the UN Charter. Nevertheless, as a practical matter, congressional 

overseers and executive branch managers of covert actions are more likely 

to pay more attention to actions that result (or could result) in death and 

destruction than those that do not. The same is true for covert actions 

that are likely to be disclosed, or likely to result in failure, or in friendly 

personnel being captured. 
Given this legal environment, it is not surprising that executive branch 
decision makers have adopted an expansive view of actions that might 

be considered traditional military activities, and that includes actions that 

have a very direct military effect on potential military adversariesŠeven 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 285
if such actions would constitute covert action if undertaken by the intel
-ligence community. Indeed, in recent years (that is, since the terrorist 
attacks of September 11, 2001), the dividing line between covert action 

(undertaken by the intelligence community) and military operations 

(undertaken by the Department of Defense) has become increasingly 

blurred. 
Consider, for example, the large amount of intelligence information 
about adversary systems that is needed to conduct cyberattacks against 

them. In a targeting context, military collection of the information needed 

for a cyberattack is essentially indistinguishable from traditional intelli
-gence collection. At the same time, a covert operation undertaken by the 

intelligence community to in˚uence events in another country may well 

look like a military operation. Even intelligence collection and exploita
-tion operations may entail some attack activity (and hence appear mili
-tary-like) in order to gain or preserve access.
Collection activitiesŠpresumably including activities requiring cyber
-attack in some form for their successful executionŠwould not constitute 

covert action. Both tapping an adversary™s underwater cable to obtain mil
-itary traf˜c ˚ows and planting a Trojan horse key logger in an adversary 

computer system in its ministry of defense would constitute intelligence 

collection activities, even if such activities were very sensitive.
On the other hand, activities that are intended to in˚uence the con
-duct, behavior, or actions of an adversary without the involvement of the 

United States becoming known are covert actions requiring ˜ndings if 

they are not traditional intelligence activities or otherwise exempt, and the 

dividing line between activities that should be regarded as covert action 

and those that should not becomes unclear. For example:

Intelligence preparation of the battle˜eld is a traditional military 
activity and thus does not constitute covert action. But a cyberattack may 

be designed to alter the functionality of an adversary™s tactical command 

and control systems long in advance of actual hostilities on the ground, 

and thus may be regarded as a covert action.

Strategic deception conducted under the U.S. military chain of 
command is a traditional military activity and thus does not constitute 

covert action. (An example of strategic deception is the attempt to per
-suade an adversary that an attack will occur in one place when it will 

actually occur in another.) But a cyberattack may be developed that alters 

the data streams on which an adversary™s intelligence and surveillance 

capabilities rely, and thus may be regarded as a covert action.

Collecting telemetry on experimental missile launches is a tradi
-tional intelligence collection activity. But a cyberattack may be designed to 

corrupt or alter the telemetry received by the adversary receiving stations 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.286
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
so that the adversary must redo the test or, even worse, inadvertently 
use bad data in its R&D efforts, and thus may be regarded as a covert 
action.
From an administrative or organizational standpoint, command struc
-tures may blur the lines between Title 10 authorities (governing the armed 

forces) and Title 50 authorities (governing the intelligence community). 

For example, as noted in Chapter 3, the U.S. Strategic Command has 

responsibility for network warfareŠand the Joint Functional Component 

Command for Network Warfare is commanded by the director of the 

National Security Agency, an element of the intelligence community. Such 

blurring requires those in the command structure to be careful about the 

roles they are playing when they take any given action.
Perhaps the most important point about the distinction between 
covert action and traditional military activities is that the distinction is 

essentially irrelevant outside a domestic context. Nations that are the 

target or subject of an act that they regard as hostile are not likely to care 

whether the United States classi˜es it as a covert action or as a military 

activity. Thus, the entire discussion above relates only to decisions within 

the U.S. government about how it should organize itself to conduct vari
-ous activities.
7.3.2
 Title III and the Foreign Intelligence Surveillance Act
Domestic electronic surveillance conducted in the United States for 
purposes of criminal investigation related to any of a list of speci˜cally 

enumerated offenses is regulated under the federal Wiretap Act of 1968 

as amended (also known as ﬁTitle IIIﬂ). Under Title III, law enforcement 

authorities may seek court authorization to conduct real-time surveillance 

of electronic communications for these purposes. The court authorization 

must be issued by a judge who concludes that there is probable cause to 

believe that a crime relating to one of these enumerated offenses has been, 

is being, or is about to be committed. 
Originally enacted in 1978, the Foreign Intelligence Surveillance 
Act (FISA) established a framework for the use of ﬁelectronic surveil
-lanceﬂ conducted to obtain ﬁforeign intelligence informationﬂ (de˜ned as 

information about a foreign power or foreign territory that relates to the 

national defense, the security, or the conduct of the foreign affairs of the 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 287
United States).
40
 For any such surveillance, the statute requires the attor
-ney general and related law enforcement authorities to seek and secure a 
warrant from a special court known as the Foreign Intelligence Surveil
-lance Court (FISC). A FISC order must specify (among other things) a 

statement of the means by which the surveillance will be conducted and 

an indication of the period of time for which the electronic surveillance 

must be maintained. 
 Since 1978, FISA has been repeatedly amended to account for new 
technologies and new concerns about terrorism and civil liberties. The 

most recent amendments came in 2008. The new statute allows the attor
-ney general and the director of national intelligence to jointly authorize 

the ﬁtargeting of persons reasonably believed to be located outside the 

United States to acquire foreign intelligence information.ﬂ The statute 

requires the government to adopt ﬁtargeting procedures
ﬂ to meet this goal 
and ﬁminimization proceduresﬂ to avoid the retention or distribution of 

information concerning U.S. citizens that is obtained from such surveil
-lance. The statute imposes no probable cause requirement for such sur
-veillance, but more restrictive provisions apply when the person targeted 

overseas is a U.S. national.
Certain cyberexploitations may be regarded as forms of electronic 
surveillance, and if conducted against U.S. persons or in the United States 

may under some circumstances be subject to FISA or Title III regulation. 

Such a cyberexploitation might, for example, require the implantation of 

software payloads to ex˜ltrate information surreptitiously. Such infor
-mation may include important documents relevant for exploitation or 

information such as login names and passwords that might be useful for 

conducting a later cyberattack. 
It is dif˜cult to speculate on how FISA might be relevant to cyberat
-tacks. But there is at least one documented case of a court-approved Title 

III warrant being used to authorize a cyberexploitation.
41
 On June 12, 
2007, an FBI agent ˜led an af˜davit to a magistrate judge in support of 

an application for court authorization to send a message to a computer 

used to administer a speci˜c MySpace.com user account. The message 

was designed to cause this computer to transmit back to the FBI technical 

data identifying the computer and/or the users of the computer. Whether 
40
 More detailed descriptions of FISA and its impact on intelligence gathering can be 
found in Elizabeth Bazan, 
The Foreign Intelligence Sur
veillance Act: An O
ver
view of Selected 
Issues
, Congressional Research Service, Washington D.C., July 7, 2008 (available at www.
fas.org/sgp/crs/intel/RL34279.pdf); Elizabeth B. Bazan (ed.), 
The Foreign Intelligence Sur
-veillance Act: O
ver
view and Modi˚cations
, Nova Science Publishers, Hauppauge, N.Y., 2008; 
and Whit˜eld Dif˜e and Susan Landau, 
Pri
vacy on the Line: The Politics of Wiretapping and 
Encryption, 
Updated and Expanded Edition, MIT Press, Cambridge, Mass., 2007.
41
 See http://politechbot.com/docs/fbi.cipav.sanders.af˜davit.071607.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.288
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
and how often the FISC has approved the use of cyberexploitation, or the 
nature of such exploitation (if any), is not known from information that 
is publicly available.
7.3.3
 Posse Comitatus
The Posse Comitatus Act (codi˜ed at 18 USC 1385), along with admin
-istrative action and other related law, prohibits the U.S. armed forces from 

executing domestic law, unless such actions are explicitly authorized by 

statute or the U.S. Constitution. (For example, Title 10, Sections 371-381 

of the U.S. Code explicitly allow the Department of Defense to provide 

federal, state, and local police with information (including surveillance 

and reconnaissance), equipment, and training/expertise. Other legisla
-tion has allowed the DOD to assist in matters related to counterterrorism, 

weapons of mass destruction, and drug traf˜cking.) Questions arise most 

often in the context of assistance to civilian police. 
Under the Posse Comitatus Act, the Department of Defense would 
appear to be forbidden from conducting either cyberattack or cyber
-exploitation in support of domestic law enforcement to enforce domestic 

law in any context where there was no speci˜c statutory exemption, but 

would have the authority to conduct such operations domestically if they 

were part of the exercise of presidential authority to act as commander-

in-chief under Article II.
7.3.4
 The Computer Fraud and Abuse Act and Other Federal Law
A variety of federal laws, including 18 USC 1030 (the Computer Fraud 
and Abuse Act, described in Section 5.2) and 18 USC 1029 (dealing with 

fraud and related activity in connection with access devices), prohibit 

individuals and corporations from undertaking cyberattack activities. 

Neither of the statutes mentioned above exempts military agencies from 

their prohibitions, although the legislative history of each does not sug
-gest that Congress intended it to apply to military operations abroad.
However, the Computer Fraud and Abuse Act may be relevant to 
possible military cyberattack activities because the various technologies 

of cyberattack often involve the compromise of third-party computers in 

order to conceal and otherwise support attack activities against an adver
-sary computer system or network. A party launching a cyberattackŠsuch 

as the United StatesŠmay wish to conceal its identity in such an action. 

Or, it may wish to augment the computing resources available to it for 

such purposes at little additional cost.
The issue of public appropriation of private resources depends on 
whether those private resources are owned by individuals or corporations 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 289
in the United States. The law in this area is voluminous and mixed, and 
the current status of the law about the government™s rights to use private 
computers of Americans without owner permission in the conduct of a 

cyberattack is quite unclear.
A different analysis, although still murky, applies to the use of private 
resources owned by individuals or corporations outside the United States. 

Subsection (f) of 18 USC 1030 (the Computer Fraud and Abuse Act) explic
-itly states that Section 1030 ﬁdoes not prohibit any lawfully authorized 

investigative, protective, or intelligence activity of a law enforcement 

agency of the United States, a State, or a political subdivision of a State, or 

of an intelligence agency of the United States.ﬂ In this context, an activity 

might be ﬁlawfully authorizedﬂ explicitly (as through a warrant granted 

by the FISC) or implicitly authorized by being undertaken under the legal 

authority of the President, the bounds of which are evolving and thus not 

precisely known. 
On the presumption that there is no other relevant legislative author
-ity, there appears to be no domestic legislative impediment for the U.S. 

government to commandeer the computers of private citizens abroad 

to create a cyberattack capacity for use by the government, perhaps for 

use in a botnet or perhaps in any attempt to conduct a cyberattack with 

plausible deniability. Whether such commandeering is legitimate under 

the international laws of armed con˚ict is not clear, although the fact that 

the ﬁzombi˜cationﬂ of a computer can leave the computer almost entirely 

intact and whole for the user™s purposes is surely relevant to a LOAC 

analysis. (As always, whether such actions would be wise or appropriate 

on policy grounds is an entirely separate matterŠthis paragraph speaks 

only to the legal aspect of the issue.) 
If none of these approaches worked to allow the U.S. government to 
assemble a network of computers for a powerful and hard-to-trace cyber
-attack, there would be the theoretical option to obtain the needed access to 

large numbers of third-party computers by ﬁrentingﬂ them from a private 

source. But botnets for hire are, as a practical matter, available only from 

criminals, since it is a criminal act to assemble a botnet in the ˜rst place. 

And although it is not without precedent,
42
 cooperating with or paying 
criminals to conduct operations relevant to national security is highly 

problematic, is politically controversial, and may itself be illegal.
Given the leverage available with using third-party computers for 
cyberattack, government may wish to ˜nd other avenues for clarifying 

the legal landscape for doing so. One approach would be for the U.S. 
42 One such example of U.S. government cooperation with criminals was the CIA use of 
Ma˜a assistance in the attempt to assassinate Fidel Castro in 1960. See ﬁTrying to Kill Fidel 
Castro,ﬂ 
Washington Post
, June 27, 2007, p. A06.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.29
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
government to simply ask owners of personal computers for permission 
to use their computers, or to pay a fee to owners willing to make their 
computers available for such use.
43
Such approaches would obviously eliminate the clandestine nature of 
such use, but it might well place at the disposal of the U.S. government 

resources far in excess of what it would otherwise have available. In any 

event, the committee recognizes that such approaches would be contro
-versial, and it is not advocating them in any way.
7.3.5
 The War Powers Resolution
The War Powers Resolution of 1973 was intended to be an assertion 
of congressional authority relevant to warmaking. A more detailed discus
-sion of the War Powers Resolution is contained in Section 6.2.1.
7.3.6
 Executive Order 12333 (United States Intelligence Activities)
Initially promulgated on December 4, 1981, and amended a number 
of times since then (most recently in July 2008), Executive Order 12333 

regulates the conduct of U.S. intelligence activities.
44
 Section 2.2 of Execu
-tive Order 12333 sets forth ﬁcertain general principles that, in addition to 

and consistent with applicable laws, are intended to achieve the proper 

balance between the acquisition of essential information and protection 

of individual interests.ﬂ Using a de˜nition of ﬁUnited States personﬂ 

speci˜ed in Section 3.4(i) of this order (a United States person is ﬁa United 

States citizen, an alien known by the intelligence agency concerned to be 

a permanent resident alien, an unincorporated association substantially 

composed of United States citizens or permanent resident aliens, or a 

corporation incorporated in the United States, except for a corporation 

directed and controlled by a foreign government or governmentsﬂ), Sec
-tion 2.3 of Executive Order 12333 establishes constraints on procedures for 

agencies within the intelligence community to collect, retain or dissemi
-nate information concerning United States persons. Section 2.5 requires 

the attorney general to ˜nd probable cause to believe that the U.S. person 

who is the target of the surveillance is an agent of a foreign power.
43
 A partial precedent for using civilian assets for military purposes can be found in the 
Civil Reserve Air Fleet (CRAF). Under the CRAF program, civilian airlines commit to mak
-ing available some of their aircraft for military airlift purposes when DOD military aircraft 
are inadequate to meet a given demand. In return, the government makes peacetime airlift 

business available to these civilian airlines. See U.S. Air Force Fact Sheet, 
Ci
vil Reser
ve Air 
Fleet
, available at http://www.af.mil/factsheets/factsheet.asp?id=173.
44
 The full text of Executive Order 12333 as of July 2008 is available at http://www.
tscm.com/EO12333.html.whitehouse.gov/infocus/nationalsecurity/amended12333.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.LEGAL AND ETHICAL PERSPECTIVES ON CY
BERATTACK
 291
U.S. law (including FISA, Title III, state wiretap law, the Electronic 
Communications Privacy Act, and Executive Order 12333) may restrict the 
ability of government agencies to collect information within the United 

States on cyberattacks, just as it places such restrictions on collection on 

other subjects, including collection of stored information found on the 

networks of victims, perpetrators, or ﬁhopﬂ sites, as well as collection 

through wiretapping of communications. The signi˜cance of this point 

is that when a system or network in the United States is the target of a 

cyberattack, and the perpetrator of that attack is unknown to U.S. authori
-ties (as is almost always the case), collection of that information must be 

done in accordance with the appropriate and necessary legal authorities. 
Absent the consent of the network owners to government collection of 
the information described above, the legal authorities for law enforcement 

and (in certain circumstances) counterintelligence provide the broadest 

basis for such collection. Thus, responsibility for collecting the informa
-tion required for attack assessment and attribution will normally rest 

with the FBI (which uniquely possesses both federal law enforcement 

and counterintelligence collection authorities (including FISA)) and other 

domestic law enforcement agencies. (Analysis of that information can 

beŠand under the National Infrastructure Protection Center prior to the 

establishment of the Department of Homeland Security, wasŠperformed 

jointly by law enforcement, the intelligence community, and military per
-sonnel (and by private sector parties if necessary).) Such information is 

necessary to characterize the nature of an incoming cyberattack, and is of 

course necessary if any kind of counter-counterattack is to be launched. 
In addition, Executive Order 12333 regulates the conduct of covert 
action by stipulating that ﬁno agency except the CIA (or the Armed Forces 

of the United States in time of war declared by Congress or during any 

period covered by a report from the President to the Congress under the 

War Powers Resolution (87 Stat. 855)1) may conduct any special activ
-ity unless the President determines that another agency is more likely 

to achieve a particular objective,ﬂ where ﬁspecial activitiesﬂ are de˜ned 

as ﬁactivities conducted in support of national foreign policy objectives 

abroad which are planned and executed so that the role of the United 

States Government is not apparent or acknowledged publicly, and func
-tions in support of such activities, but which are not intended to in˚uence 

United States political processes, public opinion, policies, or media and 

do not include diplomatic activities or the collection and production of 

intelligence or related support functions.ﬂ
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.292
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
7.4
 FOREIGN
 D
OMESTIC
 L
AW
Foreign nations are governed by their own domestic laws governing 
destructive (that is, attack) computer actions. U.S. cyberattack activities 
that terminate or transit foreign nations may be subject to such law, 

though enforcement of those laws may be as a practical matter dif˜cult. 

Foreign domestic law also has an impact on the ability of the United States 

to trace the origin of cyberattacks or cyberexploitations directed against 

the United StatesŠfor example, if a certain cyber action is not criminal
-ized in Zendia, Zendian law enforcement agencies may not have the legal 

authority to investigate it, even if the action is relevant to a cyberattack 

action against the United States routed by Ruritania through Zendia.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.8Insights from Related Areas 
This chapter seeks to contrast and compare cybercon˚ict with con
-˚ict/warfare involving certain other kinds of weapons: nuclear, space, 
biological, and non-lethal.
8.1
 NUCLEAR
 W
EAPONS
 AND
 N
UCLEAR
 W
AR
As noted in Chapter 6, nuclear history and policy are useful points 
of departureŠframing notions and metaphorical checklistsŠfor under
-standing issues related to cyberattack, in large part because of the effort 

that has been devoted to the subject of nuclear con˚ict over the years. In 

particular, many questions asked regarding nuclear con˚ict are relevant 

to cyberattack, even though the answers to these questions will be very 

different in the two cases.
Consider ˜rst some important differences. Perhaps the most impor
-tant difference is that the use of a nuclear weapon provides a very impor
-tant thresholdŠthere is no sense in which the use of even a single nuclear 

weapon could be regarded as unimportant or trivial. Indeed, a nuclear 

explosion anywhere in the world, especially one that does damage, is 

unambiguously detectable even if it is not attributable. By contrast, cyber
-attacks are being used all the time, not necessarily with government 

sponsorship or approval, but by criminals and hackers and on a large 

scale as well. Cyberexploitation also occurs on a large scale, often with 

no one noticing.
A second key difference relates to attribution. For much of the Cold 
293
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.29
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
War, the bipolar nature of the worldŠthe United States and Soviet 
UnionŠwould have made it relatively easy for the United States to attri
-bute a nuclear attack. Although a number of other nations had achieved 
nuclear capabilities as well, these nations either were allies of the United 

States (and thus could be presumed to not have hostile intent that might 

lead to the use of nuclear weapons against it) or were generally incapable 

of striking the United States.
To the extent that the latter proposition is not true, then the United 
States would have two techniques to determine the identity of an attacking 

state. First, a network of satellites keeps track of missile launches around 

the world, and thus the national origin of missile launches can be ascer
-tained. (Missiles launched from the sea are more dif˜cult to attribute.) 

In addition, radiological analysis of a nuclear explosion‚s residues might 

identify the nation responsible for manufacturing the weapon, provided 

there is on ˜le a record of the radiological ﬁsignaturesﬂ that would be pro
-vided by nuclear weapons from various nations. And nuclear weapons are 

generally presumed to be under the tight control of the nation™s national 

command authority, and thus the use of a Zendian nuclear weapon could 

be presumed to be a willful act of the Zendian government. 
None of these conditions applies to attribution of cyberattack, as 
noted in Chapter 2. When it comes to cybercon˚ict, the world is distinctly 

not
 bipolar, and indeed nation-states are not the only relevant actors. The 
true geographic origin of a cyberattack is very dif˜cult to identify. There 

are no characteristic technical signatures of a given cyberattack that can 

be unambiguously associated with a speci˜c nation. Finally, a cyberattack 

cannot be presumed to have been undertaken at the direction of a national 

government, regardless of where it originates. 
Yet another important difference is that the acquisition of nuclear 
weapons requires an enormous and expensive infrastructure for develop
-ment, testing, and deployment of those weapons, and thus the threshold 

for obtaining nuclear weapons is much higher than that for cyberweap
-ons. The elements of such an infrastructure are much easier to observe and 

identify than the infrastructure needed to acquire cyberweapons. Cyber
-weapons can be acquired on a small budget behind closed doors using 

technology that is widely and easily available. In theory, both nuclear 

weapons and cyberweapons can be purchased, but the sale of a nuclear 

weapon would be much more visible to national intelligence agencies 

than the sale of a cyberweapon (some of which can be downloaded for 

free on the Internet).
Consequently, deterrence through the threat of retaliation has much 
less credibility for cyberwarfare than for nuclear warfare, a point that in 

itself is an important difference between cyber and nuclear warfare. (Of 

course, it is also true that as some of the features of a bipolar adversarial 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.INSIGHTS FROM RELATED AREAS
 295
regime become less relevant or applicable to the state of nuclear affairs 
today, traditional theories of nuclear deterrence also begin to fray around 
the edges.
1)Finally, from an analytical point of view, theories and simulations of 
escalation dynamics and control have been developed to help understand 

how a nuclear con˚ict might unfoldŠhow con˚ict might transition from 

non-nuclear to nuclear, the scale and scope of ˜rst nuclear use, how such 

use might lead to subsequent nuclear use, and how nuclear con˚ict might 

be terminated. There are few similar theories (at least not in the public 

literature) about how cybercon˚ict might unfold, but given the lack of 

real-world experience with cybercon˚ict, such theoretical development 

might well be worthwhile.
2 Chapter 9 provides a few sketchy specula
-tions on this matter.
There are also a number of similarities between the two domains. 
From a technical standpoint, one similarity between nuclear weapons 

and cyberweapons is the superiority of the offense over defense. In both 

instances, attack operationsŠi.e., operations that result in destruction 

or damageŠare much easier to undertake than defensive operations, 

i.e., operations to prevent an attacker from in˚icting damage. But the 

consequences of this similarity are very different in the two cases. In the 

nuclear domain, this undeniable technical reality has forced the nuclear-

armed nations of the world to rely on a strategy of deterrence by threat of 

retaliation. In the cyber domain, the dif˜culties of attack attribution leave 

a comparable threat with far less credibility.
From an operational perspective, military planners have consid
-ered the use of nuclear weapons for both strategic and tactical purposes 

(though debates rage about the wisdom of using nuclear weapons for 

tactical purposes). In targeting, they can be aimed at adversary military 

capabilities (counterforce targeting) and societal infrastructure (counter
-value targeting). Both can be used in ˜rst-use and second-use scenarios. 

It is technically possible to create automated responses to nuclear attack 

or cyberattack. At the same time, there are many dif˜culties in develop
-ing a highly reliable and automated assessment regarding both the actual 

fact of an attack and the appropriate party against which to respond, and 

thus, the wisdom of such responses in both cases is subject to some con
-siderable question. Finally, both nuclear attack and cyberattack can lead 

to unintended and unforeseen consequences as well as cascading effects 
1 See, for example, David E. Sanger and Thom Shanker, ﬁU.S. Debates Deterrence for 
Nuclear Terrorism,ﬂ 
New York Times
, May 8, 2007.
2 Of course, the validity of theories of nuclear escalation and controlŠor of U.S. nu
-clear doctrine for that matterŠhas not been tested empirically. Some might regard the 
net
 outcomeŠmany untested theories of nuclear con˚ict and a scarcity of theories of 
 cybercon˚ictŠas more of a similarity between the two domains than a difference.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.296
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
and liabilities, and attack scenarios involving nuclear weapons and cyber
-weapons are highly complex.
From an organizational point of view, both nuclear attack and cyber
-attack are complex subjects. They both require deep understanding of 
technology and policy available only in specialized communities. A great 

deal of intelligence-based preplanning is needed to construct plausible 

and realistic attacks with both kinds of weapon, and options can be 

created in each case for a range of desired effects. Institutionally, both 

are managed under the U.S. Strategic Command, and the reach of both 

nuclear weapons and cyberweapons is potentially global.
Other adversary nations and subnational groups are drawn to nuclear 
weapons and cyberweapons (as well as to other weapons of mass destruc
-tion) at least in part because they may serve as equalizers that afford the 

ability to compete directly but asymmetrically with the United States in 

con˚ict situations. 
Finally, cyberwarfare and nuclear con˚ict may be intimately related 
under some circumstances. For example, the command and control net
-works used to control nuclear weapons might be targets of cyberattack. 

A large-scale use of cyberattack weapons that threatens the survival of 

the targeted nuclear-armed nation could result in its use of nuclear weap
-ons. As noted in Section 6.1.1, U.S. declaratory policy regarding nuclear 

weapons suggests that the United States could respond to certain kinds 

of cyberattacks against it with nuclear weapons.
The last point also raises the possibility that the United States might, 
under some circumstances, choose to refrain from using cyberattacks that 

are intended to have large-scale, society-damaging effects, at least against 

nuclear-armed states. This point is explored further in Section 9.2 on esca
-lation dynamics and control.
8.2
 SPACE
Operations in space provide a few lessons for understanding cyberat
-tack and cyberexploitation. (For purposes of this discussion, operations in 

space are limited to operations involving satellites.) 
Satellites can be attacked in a number of ways. They can be destroyed 
by kinetic impact (such as by a direct-ascent missile) or by directed energy 

weapons (either land-based or space-based) that cause the satellite to 

overheat or that destroy on-board optical or infrared sensors. Such ﬁhard-

killﬂ options render a satellite permanently inoperative.
ﬁSoft-killﬂ options interfere with the satellite™s operation, rendering it 
non-functional, but in a reversible manner. One might, for example, jam 

its command uplink so that it cannot receive commands from the ground. 

In the absence of such commands, a satellite might not be able to execute 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.INSIGHTS FROM RELATED AREAS
 297
a given mission or it might even drift out of position. A satellite may use 
an unencrypted command link, so that an adversary could manipulate the 
satellite™s functions. A more fanciful approach for soft kill might entail the 

unfurling of a large aluminized Mylar bag around the adversary satellite 

that prevented commands from reaching it or from using its on-board sen
-sors. Attacks on the ground control stations of a satellite could also render 

a satellite non-functional, although a nation that relied on satellites heavily 

would be likely to have backup ground stations for such contingencies.
Apart from attacks on ground stations, attacks on satellites would 
almost certainly be non-lethalŠthere would be no military value in 

attacking a crewed space vehicle. But an attack on an important satellite 

would undoubtedly have strategic impact. That is, if undertaken before 

kinetic con˚ict had broken out, such an attack would be regarded by the 

satellite-owning nation as a major provocation, and it undoubtedly would 

qualify as a hostile ﬁuse of forceﬂ against that nation. If it were undertaken 

after kinetic con˚ict had broken out, it would inevitably be regarded as a 

signi˜cant escalation of the con˚ict.
Some kinds of cyberattack share some of these characteristics. As 
noted in Chapter 2, the immediate effects of cyberattack are almost always 

non-lethal, but the consequences of certain kinds of cyberattack, such as 

attacks on the infrastructure of a nation, could have large-scale strategic 

impact. And, depending on how they were con˜gured, cyberattacks may 

result in hard kill or soft kill of their targets.
Intelligence collection is another point of legal similarity between 
operations in space and cyber operations. Today, there is broad interna
-tional acceptance of the principle that reconnaissance satellites can transit 

freely and without prior approval over national boundaries. Similarly, 

cyberexploitations have not traditionally been regarded as violations of 

international law.
3 8.3
 BIOLOGICAL
 W
EAPONS
Biological weapons and cyberweapons share a number of similaritiesŠ
indeed, the term ﬁvirusﬂ as an instrument of cyberattack was adopted in 

recognition of a mode of large-scale attack with certain similarities to how 

biological viruses spread and attack hosts.
It is helpful to consider biological weapons and cyberweapons with 
respect to two categoriesŠcharacteristics of the weapons themselves, 
3 Public opinion and perceptions of these two acts are quite differentŠthere is little 
public outcry against the reconnaissance satellites of other nations directed against the 
United States, but there is a great deal of public outcry against cyberexploitations directed 

against the United States.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.298
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
and characteristics of the infrastructure needed to produce and use such 
weapons.
One major similarity of biological weapons and cyberweapons is that 
the release of the weapons agent and/or its effects may well not be imme
-diately detectable. A biological virus can be released quietly in a crowded 
football stadium (no loud explosions), and people will become sick days 

later. A computer virus can be released on the Internet without notice, 

and can lie dormant on targeted computers for extended periods without 

anyone noticing symptoms such as degradation in computer performance 

and so on. And its effects will be noticed only if the virus is triggered. 
In both cases, the weapon can replicate without requiring human 
interventionŠbiological viruses or bacteria can multiply; computer 

viruses and worms copy themselves. One result is that weapons effects 

may continue after and beyond the point of the initial attack. The disease 

caused by a bioweapon may propagate through secondary contagion 

(i.e., human carriers of a disease), whereas the effects of a cyberattack 

may propagate or cascade beyond the point of the initial attack (as other 

computers are attacked).
It is possible for cyberattack weapons to be selective about the targets 
on which they in˚ict damageŠfor example, a virus or a worm may be 

con˜gured to cause damage only to selected systems even if it propagates 

to a large number of systems. In principle, biological weapons might be 

tailored to cause disease only in individuals with a certain biological sig
-nature, even if it infects others without causing disease.
4Furthermore, much of society is constructed in ways that enhance 
the ef˜cacy of biological weapons and cyberweapons. The effective
-ness of biological weapons is enhanced by high population densities in 

urban areas and by poor health care and public health/epidemiological 

reporting systems; the effectiveness of cyberweapons is enhanced by high 

dependence on interconnected information technology and a lack of con
-certed attention to cybersecurity on a societal scale.
ﬁBlowbackﬂ from biological weapons and from cyberweapons is 
an important concern. Blowback refers to the phenomenon in which a 

weapon loosed on an enemy blows back against the weapons user. A 
4 See, for example, British Medical Association, 
Biotechnology, Weapons and Humanity,
 Harwood Academic Publishers, Amsterdam, the Netherlands, 1999; and Claire M. Fraser 
and Malcolm R. Dando, ﬁGenomics and Future Biological Weapons: The Need for Pre
-ventive Action by the Biomedical Community,ﬂ 
Nature Genetics
 29(3):253-256, November 
2001, available at http://cmbi.bjmu.edu.cn/news/report/2001/insight-anthrax/feature
/Genomics%20and%20future%20biological%20weapons.pdf. The issue of such targeted 

weapons was raised as early as 1970 in the professional military literature. See Carl Larson, 

ﬁEthnic Weapons,ﬂ 
Military Re
view
 50(11):3-11, November 1970, available at http://usacac.
army.mil/CAC/Repository/Materials/MilitaryReview-197011300001-DOC.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.INSIGHTS FROM RELATED AREAS
 299
biological virus used by Zendia against Ruritania may, in an unknown 
period of time, affect Zendian citizens en masse. Similarly, a Zendian 
computer virus targeted against Ruritanian computers may eventually 

infect Zendian computers.
8.4
 NON
-L
ETHAL
 W
EAPONS
Non-lethal weapons constitute yet another area from which some rel
-evant insights may be gleaned. Box 8.1 provides some illustrative exam
-ples of non-lethal weapons.
A preliminary similarity is the struggle over appropriate terminology 
regarding non-lethal weapons, a struggle that reprises the analogous issue 
BOX 8.1
 Non-lethal WeaponsŠIllustrative Examples
Traditional Instruments
Ł Night sticks and truncheons
Ł Water cannons that shoot jets of water at high pressure
Ł Rubber bullets 
Ł Tear gas
Ł Pepper spray
Ł DogsToday™s Instruments
Ł Tasers
Ł  
Flashbangs (which create loud sounds or sudden bursts of light or bad 
smells)Ł Projectile netting 
Ł  
Carbon ˜laments (for use against electrical grids, to short out switching 
stations) Ł  
Loud music (e.g., Noriega and the use of Nancy Sinatra's ﬁThese Boots 
Are Made for Walkingﬂ) 
Future Systems
Ł Sticky or slippery foams
Ł Non-nuclear electromagnetic pulse weapons for use against vehicles
Ł Malodorants 
Ł  
Sound cannons (for projecting loud sounds at standoff distances, e.g., 
against small boats)
Ł  
Active denial systems (e.g., a vehicle-mounted millimeter-wave heat ray 
that creates intense heat pain through clothing without actually causing 
burns) 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.300
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
raised in Chapter 1 about information warfare, information operations, 
cyber operations, and so on. Non-lethal weapons have come to desig
-nate a category of weapons that are explicitly designed and primarily 
employed so as to incapacitate personnel or materiel while minimiz
-ing fatalities, permanent injury to personnel, and undesired damage to 

property and the environment. But there are no assurances or guarantees 

of non-lethalityŠno matter how carefully designed or carefully used, a 

given ﬁnon-lethalﬂ weapon may result in fatalities if it is used against a 

particularly vulnerable person. One proposed alternative calls such weap
-ons ﬁless lethal,ﬂ but objections have been raised to that term as well as 

indicating that such weapons would be used to create undead zombies. 

A clumsy term might be ﬁweapons with signi˜cantly reduced probability 

of lethality,ﬂ but clumsy terms are hard to use in discourse.
One policy issue raised by non-lethal weapons involves a seductive 
quality about them that has the potential of lulling users into a sense of 

complacency about their use. For example, the 
New York Times
 reported 
on a study by the sheriff™s of˜ce in Orange County, Florida, in which the 

of˜cers on patrol were all equipped with tasers and were trained to use 

them.
5 One immediate effect was that the number of citizen fatalities due 
to police action decreased dramaticallyŠthe hoped-for effect. A second 

immediate effect was a dramatic increase in the frequency of police use of 

force overall. That is, prior to the introduction of tasers, the police might 

not have used force in any wayŠthey might have talked the person down 

or waited him out or might have found some way to resolve the matter 

without using force. But with tasers in hand, they were more willing to 

use force (that is, to use a weapon) than before. This effect had not been 

anticipated.
A similar issue arises with cyberweapons, which are also non-lethal 
with respect to their immediate effects. Perhaps more importantly, they 

offer the opportunity to avoid the use of traditional lethal weaponsŠand 

for policy makers seeking to take actions short of the use of such weap
-ons, they may be similarly seductive. That is, if policy makers see them 

as weapons without lethal effects, they may be more inclined to favor 

options calling for their use
6 or to specify rules of engagement for using 
them in the ˜eld that are more permissive than would be the case for 

kinetic weapons.
5 Alex Berenson, ﬁAs Police Use of Tasers Soars, Questions Over Safety Emerge,ﬂ 
New 
York Times
, July 18, 2004.
6 The search for actions that are ﬁshort of forceﬂ is apparent in almost every instance 
in which economic sanctions are proposed against some nation. That is, economic sanctions 
are almost always the ˜rst actively adversarial action taken against nations that offend the 

international order.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.INSIGHTS FROM RELATED AREAS
 301A related point is whether the existence of non-lethal weapons (or 
perhaps cyberweapons) places legal or moral/ethical obligations to use 
them before lethal weapons are used. Similar questions have arisen in the 

context of using smart versus dumb bombs. It can be argued that both 

morality and the law of armed con˚ict requires the use of the weapons 

that are the most discriminating in their ability to minimize collateral 

damageŠby this argument, a military force would be required to use 

smart bombs (that is, weapons that can be more accurately aimed) before 

it used dumb bombs (weapons that are less discriminate in their destruc
-tion). To date, the United States and other nations have resisted any such 

argument, but these issues may recur from time to time in the future as 

weapons become even more discriminate. 
Finally, both law enforcement agencies and the Department of Defense 
have equities and interests in the area of non-lethal weapons. But their 

interests and priorities are different, and it is hard to point to a single 

authoritative voice within the U.S government on the subject. Similarly, 

the U.S. Air Force and the National Security Agency (and perhaps other 

intelligence agencies as well) also have an interest in cyberattack and 

offensive cyber operations, and the different interests and priorities of 

these institutions will have to be reconciled.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.9Speculations on the 
 Dynamics of Cybercon˚ict
9.1
 DETERRENCE
 AND
 C
YBERCONFLICT
To what extent is deterrence of cybercon˚ict possible? How 
might a nation™s cyberweapons be useful in deterring an adversary™s 
cyberattack? 
In the language of defense policy, deterrence is an often-used and 
highly elastic concept, and it is hard to ˜nd an authoritative statement of 

its precise meaning. For purposes of this document, the de˜nition pro
-vided by the U.S. Strategic Command is a reasonable starting point:
1Deterrence [seeks to] convince adversaries not to take actions that threat
-en U.S. vital interests by means of decisive in˚uence over their decision-
making. Decisive in˚uence is achieved by credibly threatening to deny 
bene˜ts and/or impose costs, while encouraging restraint by convincing 
the actor that restraint will result in an acceptable outcome. 
The threat ﬁto impose costsﬂ is the foundation of classical deterrence, 
more speci˜cally deterrence by threat of retaliation or punishment. This 
concept was the underpinning of U.S. nuclear policy toward the Soviet 

Union during the Cold War, and continues to be central to the reality of 

dealing with other nuclear states today. At the same time, an opponent 

that can be deterred by the threat of imposing costs is, almost by de˜ni
-1 Deterrence Operations: Joint Operating Concept, Version 2.0, December 2006, avail
-able at http://www.dtic.mil/futurejointwarfare/concepts/do_joc_v20.doc.
302Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SPECULATIONS ON THE DYNAMICS OF CY
BERCONFLICT
 303tion, a rational opponentŠthat is, one who can calculate that the costs of 
a certain action outweigh the gains possible from taking that action and 

thus does not take that action. But it is well known and widely under
-stood that some actors are not rational in this sense of the term. Such 

ﬁnon-rationalﬂ actors may indeed be able to make rational cost-bene˜t 

calculations, and still take the ﬁnon-rationalﬂ course of action because of 

political or religious ideology, a belief in luck, or even insanity.
The threat ﬁto deny bene˜tsﬂ is the rationale for the deployment of 
defensive capabilitiesŠcapabilities that can interfere with the success 

of an attack. Antiballistic missile defenses, for example, are intended to 

prevent hostile ballistic missiles from striking friendly targets. Chemical 

protective suits are intended to reduce the effectiveness of chemical weap
-ons against friendly forces. Offensive counter air operations are intended 

to destroy hostile aircraft before those aircraft take off to conduct attacks 

against friendly targets and territory.
A re˜nement on the concept of deterrence as described above is the 
notion of tailored deterrenceŠdeterrence ﬁtailoredﬂ to speci˜c adversar
-ies in speci˜c strategic contexts. For example, the U.S. Strategic Command 

notes that:
Exercising decisive in˚uence over the decision calculations of adversary 
decision-makers requires an understanding of their unique and distinct 

identities, values, perceptions, and decision-making processes, and of 
how these factors are likely to manifest themselves in speci˜c strategic 
contexts of importance to the US and its allies. Speci˜c state and non-

state adversaries thus require deterrence strategies and operations tai
-lored to address their unique decision-making attributes and characteris
-tics under a variety of strategically relevant circumstances. Such tailored 

deterrence strategies and operations should be developed, planned, and 

implemented with reference to speci˜c deterrence objectives that identify 

who we seek to deter from taking what action(s), under what conditions 

(i.e., Deter adversary X from taking action Y, under Z circumstances). 
Box 9.1 describes the key questions of tailored deterrence.
It remains an open question as to whether the concepts of deterrence 
are relevant when applied to the domain of cybercon˚ict per se (that 
is, cybercon˚ict without reference to con˚ict in physical domains). For 

example, a credible threat to impose costs requires knowledge of the party 

on which the costs should be imposedŠand as discussed in Chapter 2, 

attribution of a cyberattack is a very dif˜cult and time-consumingŠand 

perhaps insolubleŠproblem. 
Moreover, even if the adversary is known, and known to be a speci˜c 
nation-state, the costs to be imposed must be judged by the adversary as 

greater than the gain that might result from his aggressive actions. Thus, 

the United States must be able to identify cyber targets in or of the adver
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.304
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 9.1
 Tailored Deterrence
Tailoring an approach to deterrence requires answering four questions as 
described below.  Speci˜c answers to all four questions would represent a speci˜c 
tailoring.
1. 
Who is being deterred?
   By de˜nition, deterrence is intended to in˚uence 
an adversary™s decision-making process in such a way that the adversary chooses 

to refrain from taking an action that is undesirable to the United States.  Further, 

the mechanisms through which deterrence can operate depend strongly on the 

party the United States is trying to in˚uence.  Possible answers for the question 

ﬁWho is being deterred?ﬂ include:
The national leadership of an adversary nation
Leaders of subnational groups 
Private citizens of the adversary nation 
2. 
What is the undesirable action to be deterred?
  Depending on the undesir
-able action to be deterred, different threats and different targets (below) might be 

required.  Possible actions to be deterred include:
Nuclear attack 
 Attack with conventional forces
Attack with biological or 
 Cyberattack
 chemical weapons
 Adversary interventions in other locales
3. 
What threat is the basis for the deterrent?
  By de˜nition, deterrence involves 
a threat of some kind.  A common approach to determining the deterrent threat is 

the threat of ﬁin-kindﬂ actionŠdeterring 
X action by an adversary calls for threat
-ening to do 
X to the adversary.  But in-kind action is not inherently necessary for 
deterrence, and much of the U.S. approach to deterrence has explicitly called for 

threats that are not symmetric.  For example, the United States has long reserved 

the right to use nuclear weapons against an overwhelming conventional attack 

or against attacks using biological or chemical weapons.  Some of the possible 

threats that might be used to deter an adversary include:
Nuclear attack
 Conventional attack
Attack with biological or
 Cyberattack
 chemical weapons
 Economic or diplomatic pressure
4. 
What is the target of the U.S. threat?
  
A threat must be directed at a target 
or targets whose loss would be important enough to the adversary decision maker 

to make him refrain from taking the undesirable action.  Some possible targets 

might include:
Nuclear forces
 LeadershipBiological or chemical
 Key industries
 weapon forces or 
 Economic infrastructure
 stockpiles
 Population
Conventional forces
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SPECULATIONS ON THE DYNAMICS OF CY
BERCONFLICT
 305sary nation whose loss would be costly to the adversary, and it must be 
able to attack them with high con˜dence of success.
In a nation that is not highly dependent on information technology, 
such assets would be hard to ˜nd. Even if the nation did have valuable 
information technology assets, speci˜c individual targets (perhaps num
-bering in the dozens or hundredsŠa wild guess!) most valuable to the 

adversary are likely to be very well protected against cyberattack. The 

civilian IT infrastructure at large may be less well protected, but large-

scale attacks on such infrastructure raise ethical and moral questions 

about targeting civilians. The military IT infrastructure could be targeted 

as well, but the degree to which it is well protected may be unknown to 

the attacker (see discussion in Chapter 2 regarding intelligence require
-ments for successful focused cyberattacks).
In addition, an attacker that launches a cyberattack should also be 
expected to take action to change its own defensive posture just prior to 

doing so. As discussed in Chapter 2, much can be done to invalidate an 

adversary™s intelligence preparations, which are necessary for discrimi
-nating counterattacks. And since the attacker knows when he will launch 

the attack, he can create a window during which his defensive posture 

will be stronger. The window would last only as long as it would take for 

new intelligence efforts to collect the necessary information, but it would 

likely be long enough to forestall immediate retaliation.
A threat to deny bene˜ts to a cyberattacker also lacks credibility in 
certain important ways. In principle, defensive technologies to harden tar
-
gets against cyberattacks can be deployed, raising the dif˜culty of attack
-ing them. But decades of experience suggest that deploying these technol
-ogies and making effective use of them on a society-wide basis to improve 

the overall cybersecurity posture of a nation is dif˜cult indeed. And there 

is virtually no prospect of being able to reduce a cyberattacker™s capabili
-ties through offensive action, because of the ease with which cyberattack 

weapons can be acquired. Thus, counterforce capabilitiesŠwhich in the 

nuclear domain have been justi˜ed in large part as necessary to reduce 

the threat posed by an adversary™s nuclear weaponsŠdo not exist in any 

meaningful way in contemplating cybercon˚ict.
2How do the considerations above change if, as in the real world, the 
states involved also have kinetic capabilities, which may include nuclear 

weapons, and physical vulnerabilities? That is, each side could, in princi
-ple, use kinetic weapons to attack physical targets, and these targets might 

be military or dual purpose in nature as long as they are legitimate targets 
2 This statement is NOT intended to indicate acceptance or rejection of the counterforce ar
-gument in the nuclear domainŠit is only to say that regardless of whether the counterforce 
argument is valid in the nuclear domain, it has little validity in the cyber domain.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.306 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
under LOAC. Because a transition from cyber-only con˚ict to kinetic con
-˚ict would likely constitute an escalation (and would in any case make the 
con˚ict more overt), this point is discussed in more detail below.
9.2
 ESCALATORY
 D
YNAMICS
 OF
 C
YBERCONFLICT
 B
ETWEEN
 NATION
-S
TATES
The escalatory dynamics of con˚ict model how a con˚ict, once started, 
might evolve. Of interest are issues such as what activities or events might 

set a cybercon˚ict into motion, what the responses to those activities or 

events might be, how each side might observe and understand those 

responses, whether responses would necessarily be ﬁin kind,ﬂ how dif
-ferent kinds of state might respond differently, and so on. What follows 

below are some speculations on some of the factors that might in˚uence 

the evolution of a cybercon˚ict. 
The actors involved are presumed to be nation-states with signi˜cant 
kinetic and cyber capabilities at their disposal, and the situation in ques
-tion is one of open tension and high rhetoric between two states that have 

traditionally been rivals. Important questions to be addressed (summa
-rized in Box 9.2) are discussed in the remainder of this section, but the 

discussion is intended to raise issues rather than to answer questions.
9.2.1
 Crisis Stability
Where kinetic weapons are concerned, crisis stability refers to that 
condition in which neither side has incentives to attack ˜rst. Crisis stabil
-ity is especially important for nuclear weapons, where the existence of an 

invulnerable submarine-based nuclear missile force means that an adver
-sary could not escape retaliation no matter how devastating or successful 

a ˜rst strike it could launch against the United States. Where cyberweap
-ons are concerned, there is no conceivable way for a nation to eliminate or 

even signi˜cantly degrade the cyberattack capability of another nation.
3 But the question remains whether a second-strike cyberattack capability 

is the enabling condition for crisis stability in cyberspace.
A related question is that of incentives for preemption. Suppose that 
preemptive attacks by Ruritania on Zendia are undertaken in order to 

prevent (or at least to blunt) an impending attack by Zendia on Ruritania. 
3 Even in the case of a nuclear electromagnetic pulse attack directed against the electronic 
equipment in another nation (Zendia), there is no reason to assume that all of Zendia™s 
cyberattack capabilities are necessarily resident within Zendia™s boundaries. Because cyber
-attacks can originate from anywhere, some of Zendia™s cyberattack capabilities might have 

been deployed in other nationsŠindeed, some Zendian attack agents might already have 

been clandestinely deployed in U.S. systems.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SPECULATIONS ON THE DYNAMICS OF CY
BERCONFLICT
 307BOX 9.2
 Questions About the Escalatory Dynamics of 
Cyberconflict Between Nation-States
Crisis Stability
What is the analog of crisis stability in cybercon˚ict?  
What are the incentives for preemptive cyberattack?
Escalation Control and Management
How can intentions be signaled to an adversary in con˚ict? 

How can cybercon˚ict between nations be limited to con˚ict in cyberspace?
How should cyberattack be scoped and targeted so that it does not lead 
an adversary to escalate a con˚ict into kinetic con˚ict?  
How can a modestly scoped cyberattack conducted by a government be 

differentiated from the background cyberattacks that are going on all of 

the time?  

How can the scale and scope of a commensurate response be ascertained?
Complications Introduced by Patriotic Hackers

How can ﬁfree-lanceﬂ activities on the part of patriotic hackers be handled?
Incentives for Self-restraint in Escalation
What are the incentives for self-restraint in escalating cybercon˚ict?  
Termination of Cybercon˜ict 
What does it mean to terminate a cybercon˚ict?
If Zendia is planning a cyberattack on Ruritania, a preemptive cyberattack 
on Zendia cannot do much to destroy Zendia™s attack capability; at best, 

Ruritania™s preemptive attack on Zendia might tie up Zendia™s personnel 

skilled in cyber operations. On the other hand, it is hard to imagine cir
-cumstances in which Ruritania would realize that Zendia was planning 

an attack, as preparations for launching a cyberattack are likely to be 

invisible for the most part. 
A second relevant scenario is one in which Zendia is planning a 
kinetic attack on Ruritania. Intelligence information, such as photographs 

of troop movements, might well indicate that preparations for such an 

attack were being made. And under these circumstances, Ruritania might 

well choose to launch a preemptive cyberattack against Zendia, with the 

intent of delaying and disrupting Zendia™s preparations for its own (that 

is, Zendia™s) kinetic attack.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.308 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
9.2.2
 Escalation Control and Management
In a time of tension or crisis, national leaders are often understandably 
concerned about inadvertent escalation. For example, Nation 
A does X, 
expecting Nation 
B to do 
Y in response. But in fact, Nation 
B unexpectedly 
does 
Z, where 
Z is a much more escalatory action than 
Y. Or Nation 
A may do 
X, expecting it to be seen as a minor action intended only to show 
mild displeasure and thinking that Nation 
B will do 
Y in response, where 
Y is also a relatively mild action. But due to a variety of circumstances, 
Nation 
B sees 
X as a major escalatory action and responds accordingly 
with 
Z, an action that is much more signi˜cant than 
Y. Nation 
A perceives 
Z as being way out of proportion, and in turn escalates accordingly.
9.2.2.1
 Signaling Intentions Through Cybercon˜ict
Nothing in the alphabet of options above is speci˜c to cybercon˚ictŠ
such issues have been an important part of crisis management for a long 
time. But managing such issues may well be more dif˜cult for cybercon
-˚ict than for other kinds of con˚ict. One reason is the constant background 

of cyberattack activity. Reports arrive hourly and daily of cyberattacks of 

one kind or another on U.S. computer systems and networks, and the vast 

majority of these attacks do not have the signi˜cance of a serious cyber
-attack launched by a party determined to do harm to the United States. 

Indeed, the intent underlying a given cyberattack may not have a military 

or a strategic character at all. Organized crime may launch a cyberattack 

for pro˜t-making purposes. A teenage hacking club may launch a cyberat
-tack out of curiosity or for vandalism purposes. 
A dearth of historical experience with nations or terrorists using 
cyberattack against the United States further complicates efforts at under
-standing what an adversary might hope to gain by launching a cyberat
-tack. And other nations are in a similar position, lacking the experience 

and facing the same background of cyberattacks. In the absence of contact 

with cyberattackers (and sometimes even in the presence of such contact), 

determining intent is likely to be dif˜cult, and may rest heavily on infer
-ences made on the basis of whatever attack attribution is possible. 
Thus, attempts to send signals to an adversary through limited and 
constrained military actionsŠproblematic even in kinetic warfareŠare 

likely to be even more problematic when cyberattacks are involved.
9.2.2.2
 Preventing Cybercon˜ict from Transitioning to Physical Space
If national command authorities decide to retaliate in response to a 
cyberattack, an important question is whether retaliation must be based 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SPECULATIONS ON THE DYNAMICS OF CY
BERCONFLICT
 309on a ﬁtit-for-tatﬂ response. Assuming the perpetrator of a cyberattack 
is known to be a hostile nation, there is no reason in principle that the 
retaliation to a hostile cyberattack could not be a kinetic attack against 

the interests of that hostile nationŠthat is, allowing a kinetic response 

to a cyberattack expands the range of options available to the victim. An 

extreme case is that in the event of a cyberattack of suf˜cient scale and 

duration to threaten a nation™s ability to function as a modern society, the 

attacked nation might choose to respond with kinetic force to the nation 

causing such problems. On the other hand, the attacked nation may have 

an interest in refraining from a kinetic responseŠfor example, it may 

believe that a kinetic response would be too provocative and might result 

in an undesired escalation of the con˚ict.
Decision makers may also see cyberattacks as instruments to be used 
in the early stages of a con˚ict (cf. Section 3.2). National decision makers 

considering a cyberattack (whether in response or as a ˜rst use) appear 

to have incentives to refrain from conducting cyberattacks that might 

induce a strong kinetic reaction unless kinetic con˚ict had already broken 

out. The obvious approach would be to conduct cyberattacks that are in 

some sense smaller, modest in result, targeted selectively against less pro
-vocative targets, and perhaps more reversible. (The similarity of such an 

approach to escalation control in other kinds of con˚ict is not accidental, 

and it has all of the corresponding complexities and the uncertainties.)
There is no reason to suppose that hackers and criminal elements will 
moderate their activities in times of crisis or con˚ict (see also Section 9.2.3 

regarding patriotic hackers). Thus, if a cyberattack is intended to send a 

signal from the United States to Zendia, how is Zendia to recognize that 

signal? Overtly taking credit for such an attack goes only so far, especially 

given uncertain communications in times of tension or war, and the near 

certainty of less-than-responsible behavior on the part of one or both 

sides.
Finally, it seems likely that escalation issues would play out differ
-ently if the other nation(s) involved are near-peer competitors or not. 

Escalation to physical con˚ict is of less of concern to the United States if 

the nation has weak conventional forces and/or is a non-nuclear state. 

But a nation with nuclear weapons, or even with strong conventional 

forces in a position to damage U.S. allies, is another matter entirely, and 

relationships with such states may well need to be specially managed, 

paying particular attention to how escalation may be viewed, managed, 

and controlled, and most importantly, how miscalculation, misperception, 

or outright error may affect an adversary™s response.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.31
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
9.2.2.3
 Determining the Impact and Magnitude of Cyber Response 
If an adversary conducts a cyberattack against the United States, a 
˜rst question for U.S. decision makers will be knowledge of the attack™s 
impact and magnitude. Such knowledge is necessary to inform an appro
-priate U.S. response. (If, for example, the United States wishes to make a 

commensurate response, it needs to know what parameters of the incom
-ing attack would characterize a commensurate response.)
But in many kinds of cyberattack, the magnitude of the impact of the 
˜rst cyberattack will be uncertain at ˜rst, and may remain so for a consid
-erable period of time. Decision makers may then be caught between two 

challengesŠa policy need to respond quickly and the technical fact that it 

may be necessary to wait until more information about impact and dam
-age can be obtained. (As noted in Section 2.5, these tensions are especially 

challenging in the context of active defense.)
Decision makers often feel intense pressure to ﬁdo somethingﬂ imme
-diately after the onset of a crisis, and sometimes such pressure is war
-ranted by the facts and circumstances of the situation. On the other hand, 

the lack of immediate information may prompt decision makers to take a 

worst-case view of the attack and thus to assume that the worst that might 

have happened was indeed what actually happened. Such a situation has 

obvious potential for inappropriate and unintended escalation.
9.2.3
 Complications Introduced by Patriotic Hackers
Past experience strongly indicates that con˚ict or increased tension 
between two nations will result in the ﬁpatriotic hackersﬂ of both nations 

(and perhaps their allies) taking action intended to harass or damage the 

other side. Such activities are not under the direct control of the national 

government, and as discussed in Section 7.2.3.3 may well interfere with 

the efforts of that government to manage the crisis vis-à-vis the other 

side.
4 Indeed, the government of a targeted nation is likely to believe 
that a cyberattack conducted on it is the result of deliberate adversarial 

action rather than the actions of ﬁunauthorizedﬂ parties. Thus, unauthor
-ized activities of the patriotic hackers of Zendia against the United States 

may lead the United States to believe that the Zendian government has 

launched a cyberattack against it. A U.S. cyberattack against Zendia may 

be seen by the Zendian government as a cyber ˜rst strike against it.
Yet another complication involving patriotic hackers is the possibility 
that they might be directed by, inspired by, or tolerated by their govern
-4 Such activities also have some potential for complicating the operational efforts of that 
governmentŠfor example, because cyberattacks against the same target may interfere with 
each other.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SPECULATIONS ON THE DYNAMICS OF CY
BERCONFLICT
 311
ment (or a rogue section within it), but in ways in which the government™s 
hand is not easily visible. Under such circumstances, hostile acts with 
damaging consequences could continue to occur (with corresponding 

bene˜ts to the nation responsible) despite of˜cial denials. At the very 

least, the possibility that patriotic hackers may be operating could act as 

a plausible cover for government-sponsored cyberattacks, even if there 

were in fact no patriotic hackers doing anything.
9.2.4
 Incentives for Self-restraint in Escalation
One set of incentives is based on concerns about an adversary™s 
response to escalation. Understanding this set of incentives is
 necessarily 
based on a sense of what kinds of offensive cyber actions, whether cyber
-attack or cyberexploitation that might be mistaken for cyberattack, might 

lead to what kinds of adversary responses (in cyberspace or in physical 
space). In this regard, an essential difference between
 cyberattack and the 
use of nuclear, chemical, biological, or space weapons is readily appar
-entŠthe initial use of any nuclear, chemical, biological or space weapon, 

regardless of how it is used, would constitute an escalation of a con
-˚ict under almost any circumstances. By contrast, whether a given cyber
-attack (or conventional kinetic attack for that matter) would be regarded 

as an escalation depends on the nature of the operationŠthe nature of 

the target(s), their geographic locations, their strategic signi˜cance, and 

so on.
A second set of incentives is based on concerns about ﬁblowbackﬂŠ
the possibility that a cyberattack launched by the United States against 

Zendian computers might somehow affect U.S. computers at a later time. 

Understanding the likelihood of blowback will require a complex mix of 

technical insight and intelligence information.
9.2.5
 Termination of Cybercon˜ict 
How could the United States indicate to Zendia that it was no longer 
engaging in cyberattacks against it? Given that a cyberattack might well 

involve the placement of hardware and/or software agents within the 

Zendian IT infrastructure (both civilian and military), would the United 

States direct such agents to self-destruct? Would it inform Zendia of the 

IT penetrations and compromises it had made? On what basis would 

the Zendian government believe a claim by the United States that it had 

issued such a directive? (And, of course, all of the same questions apply 

in reverse as well.)
On the other hand, such actions may be more analogous to cleanup 
and recovery efforts after a kinetic war. Con˚ict termination in a kinetic 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.312
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
war means that both sides stop shooting at each otherŠand refrain from 
taking further destructive actions. This point suggests that software 
and/or hardware agents within an adversary™s IT infrastructure must 

be designed so that they are under the positive control of the launching 

nationŠand thus that fully autonomous agents are inconsistent with 

positive control. In addition, an attacker may need to keep careful track of 

where these agents are implanted, so that subsequent ﬁcyber de-miningﬂ 

operations are possible when hostilities have terminated.
9.2.6
 The Role of Transparency 
Where kinetic weapons are concerned, transparency and con˜dence-
building measures such as adherence to mutually agreed ﬁrules of the 

roadﬂ for naval ships at sea, prenoti˜cation of large troop movements, and 

non-interference with national technical means of veri˜cation have been 

used to promote stability and mutual understanding about a potential 

adversary™s intent. 
Secrecy surrounding cyberattack policy works against transparency. 
In addition, military operations on land, sea, and air are easily distinguish
-able from most non-military movements, whereas it is likely to be dif˜cult 

to distinguish between military and non-military cyber operations.
9.2.7
 Catalytic Cybercon˜ict 
Catalytic con˚ict refers to the phenomenon in which a third party 
instigates con˚ict between two other parties. These parties could be 

nation-states or subnational groups, such as terrorist groups. The canoni
-cal scenario is one in which the instigator attacks either Zendia or Ruri
-tania in such a way that Zendia attributes the attack to Ruritania, or vice 

versa. To increase con˜dence in the success of initiating a catalytic war, 

the instigator might attack both parties, seeking to fool each party into 

thinking that the other party was responsible. 
As also noted in Section 2.4.2, high-con˜dence attribution of a cyber
-attack under all circumstances is arguably very problematic, and an insti
-gator would ˜nd it by comparison very easy to deceive each party about 

the attacker™s identity. Thus, a catalytic attack could be very plausibly 

executed. In addition, if a state of tension already exists between the 

United States and Zendia, both U.S. and Zendian leaders will be pre
-disposed toward thinking the worst about each otherŠand thus may be 

less likely to exercise due diligence in carefully attributing a cyberattack. 

A Ruritanian might thus choose just such a time to conduct a catalytic 

cyberattack.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SPECULATIONS ON THE DYNAMICS OF CY
BERCONFLICT
 313
9.3
 CYBERCONFLICT
 B
ETWEEN
 THE
 U
NITED
 S
TATES
 AND
 NON
-S
TATE
 A
CTORS
 Competition with nation-states is not the only kind of con˚ict that 
might involve the United States. For example, the United States might 
be the target of a cyberattack by a non-state party (such as a terrorist 

group).
A terrorist group, by de˜nition, does not operate as a nation-state, and 
there would inevitably be dif˜culties in identifying the relevant terrorist 

group (many terrorist groups would surely like to be able to conduct a 

cyberattack against the United States), thus complicating the ﬁimpose 

costsﬂ strategy. 
In addition, if the terrorist group were operating under the auspices 
of a failed state, a cyber counterattack would be likely to ˜nd few suit
-able targets in the failed state and thus would have little impact. (Kinetic 
counte
rattack might be feasible, as indicated by the experience of the 
United States in attacking Afghanistan immediately after the September 11, 
2001, terrorist attacks on the World Trade Center and the
 Pentagon.) If the 
terrorist group were operating under the unwitting cover of another state, 

all of the attribution problems described in Section 2.4.2 would apply, and 

the discussion in Section 7.2.1.2 on the merits of self-defense in neutral 

territory would be relevant.
Criminal groups conducting cyberattacks for illicit monetary gain are 
also important non-state actors. If they operate across national boundar
-ies, law enforcement efforts to shut down the operations of such groups 

are likely to take a long time, if they are successful at all. Thus, one might 

plausibly consider, in addition to the usual law enforcement efforts, a dif
-ferent response paradigm that could call for cyberattacks to terminate or 

attenuate their activities. 
Against non-state parties, deterrence by retaliation may be particu
-larly ineffective. First, a non-state group may be particularly dif˜cult to 

identify. A lack of identi˜cation means uncertainty about the appropriate 

focus of any retaliatory action, and also that the decision-making cal
-culus of the non-state group is likely to be poorly understood. Second, 

a non-state group is likely to have few if any information technology 

assets that can be targeted. Third, some groups (such as organized hacker 

groups) regard counterattacks as a challenge to be welcomed rather than 

something to be feared. A criminal group might react very strongly to a 

counterattack by a much stronger cyberattack than was initially launched. 

Fourth, a non-state group such as a terrorist or insurgent group might 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.31
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
seek to 
pro
voke
 cyber retaliation in order to galvanize public support for 
it or to antagonize the public against the United States.
5A particularly challenging problem is the prospect of an extended 
cyber-guerilla campaign against the United States by a non-state actor 
(perhaps with state sponsorship) operating globally over periods of 

month or years. In many ways, coping with such a campaign is similar 

to the physical space kinetic analog of an extended terrorist campaign 

against the United States. For example:

The set of possible targets is nearly in˜nite, suggesting that harden
-ing every possible target against attack is an implausible strategy. 

Knowing the adversary™s value calculus (what the adversary val
-ues and how he values it) is fraught with uncertainty, which makes strate
-gies based on deterrence by retaliation less effective as a policy tool. For 

example, if the United States cannot determine assets that the adversary 

values, credible retaliation is impossible to threaten. If the adversary-

valued assets are in a friendly state, attacking those assets might have 

negative repercussions.

Penetration of the entities responsible for hostile actions against the 
United States (that is, turning an insider) is likely to be very problematic 

because of the dif˜culty of identifying an insider with whom to engage. 

A continuing campaign, whether kinetic or cyber, could be very 
effective in instilling fear, terror, and uncertainty in the population regard
-less of the actual level of damage being in˚icted.
6 There may also be factors that differentiate the situation as com
-pared to the kinetic analog. For example, kinetic terrorism usually has 

dramatically visible effects, whereas the effects of a sustained guerilla 

campaign of cyberattacks may be far less visible, especially against the 

background noise of daily cyberattacks from myriad sources. Uncertainty 

and an undermining of con˜dence in information technology may be the 

most likely result of a cyber campaign. Also, state sponsorship may pro
-5 The notion of provoking U.S. retaliation as a technique for gaining the sympathies of 
the Islamic world at large is a basic tenet of Al Qaeda™s strategy against the United States. 
See, for example, Rohan Gunaratna, 
Inside Al Qaeda™s Global Network of Terror
, Columbia 
University Press, New York, 2002.
6 For example, in the D.C. sniper case of 2002, 10 people were shot over a period of 
3 weeks (Jessica Reaves, ﬁPeople of the Week: John Muhammad and John Malvo,ﬂ 
Time
, October 24, 2002, available at http://www.time.com/time/nation/article/0,8599,384284,00.

html). Inhabitants of the greater D.C. area were terrorized and fearful because of the sniper, 

despite the fact that there were 18 ﬁtraditionalﬂ homicides during that time (Susan Kim, 

ﬁFear Lingers in DC Area,ﬂ 
Disaster News Network
, November 12, 2002, available at http://
www.disasternews.net/news/article.php?articleid=57).
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SPECULATIONS ON THE DYNAMICS OF CY
BERCONFLICT
 315
vide those responsible with access to intelligence that could amplify the 
potency of guerilla cyberattacks.
How might the United States combat such a campaign? Although it 
is probably possible to harden genuinely critical targets of cyberattack 
and thereby make a truly devastating attack more dif˜cult, the number 

of possible lucrative targets is large. Thus, such a campaign could still be 

expected to have some non-trivial degree of success. Because the locus 

of an attack can be shifted arbitrarily and essentially instantaneously, 

active threat neutralization would provide at best transient relief, if any 

at all. Moreover, enlisting the assistance of foreign national authorities 

is problematic because a shifting geographic locus can easily negate the 

effectiveness of any assistance offered.
An alternative to the methods described above is to use techniques 
such as deception and in˜ltration coupled with covert cyberattack. Decep
-tion might be used to induce operatives to violate operational cybersecu
-rity by opening themselves to cyberattack (e.g., to visit putatively useful 

websites that might be able to infect visitors with a selectively acting 

Trojan horse). In˜ltration may be dif˜cult (as described above) but would 

have to be a priority effort. But whether this alternative would in fact be 

more effective against a cyberterrorist group is an open question.
9.4
 THE
 P
OLITICAL
 S
IDE
 OF
 E
SCALATION
The discussions in previous sections in this chapter address escalation 
dynamics primarily from a military standpoint. Yet escalation dynamics 

inevitably has a political and psychological component that must not be 

overlooked.
For example, Section 2.5 (on active defense) points out that U.S. 
cyberattacks undertaken under the rubric of active defense may not 

be perceived by others as innocent acts of self-defense, even if they are 

intended by the United States as such. While in most con˚icts, both sides 

claim that they are acting in self-defense, cybercon˚icts are a particu
-larly messy domain in which to air and judge such claims. Another pos
-sible misperception may arise from intelligence collection activities that 

might involve cyberattack techniques. As noted in Section 2.6.1, the tools 

needed to conduct a cyberexploitation may not be very different from 

those needed to conduct a cyberattack. On the other hand, a nation™s 

tolerance for being the target of a cyberattack may be much lower than 

its tolerance for being the target of a cyberexploitation.
Thus, consider the political rami˜cations in the following trouble
-some scenarios:
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.316
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES

Zendia might believe that it has been attacked deliberately by 
the United States even when the United States has not done so. Indeed, 
because of the ongoing nature of various attack-like activities (e.g., hack
-ing and other activities) against the computer systems and networks of 

most nations, the Zendian conclusion that Zendian computer systems are 

being attacked is certainly true. Attribution of such an attack is a different 

matter, and because hard evidence for attribution is dif˜cult to obtain, 

the Zendian government might make inferences about the likelihood of 

U.S. involvement by giving more weight to a general understanding of 

U.S. policy and posture toward it than might be warranted by the speci˜c 

facts and circumstances of the situation. Evidence that appears to con˜rm 

U.S. involvement will be easy to ˜nd, whether or not the United States is 

actually involved, and the lack of U.S.-speci˜c ﬁ˜ngerprintsﬂ can easily be 

attributed to U.S. technological superiority in conducting such attacks.

An active defense undertaken by the United States of its systems 
and networks against Zendia could have signi˜cant political conse
-quences. For example, even if the United States had technical evidence 

that was incontrovertible (and it never is) pointing to the Zendian gov
-ernment, the Zendians could still deny that they had launched such an 

attackŠand in the court of world opinion, the Zendian denial could carry 

some weight when considered against past U.S. assertions regarding simi
-lar issues. That is, U.S. cyberattacks (counter-cyberattacks, to be precise) 

undertaken under the rubric of active defense may not be perceived as 

innocent acts of self-defense, even if they are. The result could be a ˚urry 

of charges and countercharges that would further muddy the waters and 

escalate the level of political tension and mistrust. 

The United States plants a software agent in a Zendian military 
system but does not activate it (cf. Section 2.2.4). Zendia (being attacked) 

may well regard the hostile action as beginning at the moment the U.S. 

agent is planted, whereas the United States may believe that the hostile 

action begins only when the agent is activated.

The United States launches a cyberattack against a Zendian military 
factory, but the direct damage from this attack is not visible to the naked 

eye (Section 2.3.1.1). Without CNN images of smoking holes in the ground 

or troops on the move, an outside observer must weigh competing claims 

without tangible evidence one way or the other. Under such circumstances, 

the reputations of the different parties in the eyes of each other are likely 

to play a much larger political role.

The United States plants software agents in some of Zendia™s criti
-cal networks to collect intelligence information. These agents are designed 

to be reprogrammable in placeŠthat is, the United States can update these 

agents with new capabilities. During a time of crisis, Zendian authorities 

discover some of these agents and learn that they have been present for a 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.SPECULATIONS ON THE DYNAMICS OF CY
BERCONFLICT
 317
while, that they are sending back to the United States very sensitive infor
-mation, and that their capabilities can be changed on a moment™s notice. 
Even if no harmful action has yet been taken, it is entirely possible that 

Zendia would see itself as being the target of a U.S. cyberattack.

The United States is the target of a cyberattack against its air traf˜c 
control system that results in a number of airplane crashes and several 

hundred deaths. Initially, no de˜nitive technical attribution can be made 

regarding the perpetrator of the attack, but in a matter of weeks, an 

all-source attributionŠdepending on somewhat uncertain human and 

signals intelligenceŠsuggests that the perpetrator could be Zendia. The 

United States decides on a mixed kinetic and cyber response against 

Zendia but must persuade allies and the rest of the world that its attack 

on Zendia is in fact justi˜ed.

Tensions between the United States and Zendia are high, even 
though diplomats are trying to defuse them. Over a relatively short period 

of time, Zendia conducts a number of cyberexploitations against a variety 

of computer systems and networks important to the U.S. military. Some 

of these activities are successful in compromising some sensitive but 

unclassi˜ed information, but the systems and networks in question do 

not experience any apparent functional degradation. However, in keeping 

with common press usage, U.S. news reports of these activities indicate 

that 300 Zendian ﬁcyberattacksﬂ have taken place against the U.S. mili
-tary. In turn, these reports in˚ame passions in the United States, leading to 

signi˜cant pressures on the U.S. National Command Authority to respond 

aggressively against Zendia.
Factors such as the ones described above suggest that factors other 
than those dictated by military or legal necessity play important roles in 

escalation dynamics, if nothing else because they can strongly affect the 

perceptions of decision makers on either side.
 Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.10
Alternative Futures
As described in Chapters 3-5, the stance of the United States toward 
cyberattack against adversary foreign nations is one that puts no con
-straints on its use apart from those imposed by the law of armed con˚ict 
and related customary international law. But such a stance is not the only 

possible one, and from time to time proposals emerge that, if adopted, 

would constrain activities related to cyberattack for some or all nations, 

including the United States. This chapter explores some of the issues that 

arise in considering such proposals, but does not take a stand one way or 

another on their inherent desirability.
10.1
 REGULATORY
 R
EGIMES
ŠB
ASIC
 P
RINCIPLES
 The laws of armed con˚ict acknowledge an inevitability to con˚ict and 
seek to put restraints on what might otherwise be unrestrained behavior. 

In addition, nations that may engage in armed hostilities with one another 

sometimes enter into legal regimes that regulate the development, testing, 

production, acquisition, deployment, or use of certain kinds of weapons. 

Such regimesŠgenerically arms control regimesŠare generally regarded 

as having some mix of three broad purposes: to reduce the likelihood 

that con˚ict will occur, to reduce the destructiveness of any con˚ict that 

does occur, and to reduce the costs associated with the acquisition of the 

weapons that are the subject of the agreement or with defense against 

those weapons.
Arms control agreements can be bilateral between two nations (such 
318
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.ALTERNATIVE FUTURES
 319
as the Strategic Arms Reduction Treaties between the United States and 
the Soviet Union/Russia) or multilateral among multiple nations (such as 

the Limited Test Ban Treaty signed and rati˜ed by 94 nations). They can 

be cast formally as treaties, informally as memorandums of understand
-ing, or even more informally as coordinated unilateral policies. They 

may place limits on the acquisition of certain kinds of weapons, where 

acquisition can be understood to mean research, development, testing, 

production, or some combination thereof (e.g., a ban on the development, 

testing, production, and deployment of intermediate-range ballistic mis
-siles); on the deployment of certain weapons (e.g., no nuclear weapons in 

space); on the use of such weapons (e.g., prohibitions on the use of laser 

weapons speci˜cally designed, as their sole combat function or as one 

of their combat functions, to cause permanent blindness to unenhanced 

vision
1); or on the circumstances of weapons use (e.g., an agreement to 
refrain from ﬁ˜rst useﬂ of nuclear weapons).
In many cases, and especially when they involve the use of certain 
kinds of weapons, arms control agreements are seen by the signatories as 

con˜dence-building measures, that is, actions taken or not taken that are 

intended to provide a potential adversary with reassurances that some 

other action is not hostile in intent. For example:

The United States and the Soviet Union maintained a ﬁhot lineﬂ 
to facilitate direct contact between the respective national leaders dur
-ing times of crisis on the theory that direct contact would be valuable in 

reducing misunderstanding about national activities that were ongoing 

or imminent. 

The United States and the Soviet Union signed an agreement in 
1989 that bound each side to take steps to prevent interference with com
-mand and control networks in a manner that could cause harm to person
-nel or damage to equipment of the armed forces of the other side.
2 
The United States and Russia have another agreement to notify 
each other 24 hours in advance prior to the launch of a strategic ballistic 

missile.
3 The intent of this agreement is to reassure the other party that 
1 Note that the United States has not rati˜ed the Protocol on Blinding Laser Weapons 
(Protocol IV to the Convention on Certain Conventional Weapons).
2 Agreement of the Government of the United States of America and the Govern
-ment of the Union of Soviet Socialist Republics on the Prevention of Dangerous Mili
-tary Activities, June 1989, available at http://en.wikisource.org/wiki/Prevention_of_ 
Dangerous_Military_Activities_Agreement.
3 Agreement Between the United States of America and the Union of Soviet Socialist 
Republics on Noti˜cations of Launches of Intercontinental Ballistic Missiles and Submarine-
Launched Ballistic Missiles, available at http://www.state.gov/t/ac/trt/4714.htm.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.32
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
in the event that a strategic ballistic missile is launched by the ˜rst party, 
such a launch is not misunderstood as a prelude to hostilities. 

The United States and Russia have agreed to various measures to 
reduce the likelihood of an incident at sea between the naval forces of the 
two countries, and to reduce the likelihood of escalation in the event that 

one occurred. Such measures include steps to avoid ship collisions, avoid
-ing maneuvers in areas of heavy sea traf˜c, requiring surveillance ships to 

maintain a safe distance from the object of investigation, refraining from 

simulating attacks at the other party™s ships, and so on.
4Arms control agreements often contain measures to enhance veri˜
-cationŠa process by which one signatory can develop con˜dence that 

the other side is indeed living up to its obligations under the agreement. 

Some agreements, such as con˜dence-building measures, are self-verify
-ingŠeach nation undertakes to enact or engage in those measures when 

they are called for in the agreement, and if the nation does not do so 

when appropriate, the other nation draws whatever conclusions it may 

draw about the other side™s intentions. Other agreements provide for 

the use of ﬁnational technical meansﬂ (i.e., various technical intelligence 

assets) and/or various kinds of inspections to verify compliance. Still 

other agreements make no provision for veri˜cation at all (such as the 

Biological Weapons Convention), but nevertheless serve as statements 

regarding international norms of acceptable conduct that constrain, at the 

very least, the declaratory policies of the signatories to be consistent with 

the agreements in question.
Many critics of arms control agreements point to a lack of veri˜ca
-tion provisions as a fatal ˚aw in an agreement. They argue that when the 

United States is party to such an agreement, it is invariably bound by both 

the spirit and the letter of the agreement, but that the other partyŠusually 

an adversary or a potential adversary of the United StatesŠis likely to 

violate the agreement in the absence of adequate veri˜cation provisions, 

thus leaving the United States at a relative disadvantage. 
These basic principles of arms control regimes can be applied to 
understanding possible approaches to developing international agree
-ments regulating cyberattack.
4 Agreement Between the Government of the United States of America and the Govern
-ment of the Union of Soviet Socialist Republics on the Prevention of Incidents On and Over 
the High Seas, available at http://www.state.gov/t/ac/trt/4791.htm.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.ALTERNATIVE FUTURES
 321
10.2
 REGULATORY
 R
EGIMES
 FOR
 C
YBERATTACK
 10.2.1
 Direct Approaches Based on Traditional Arms Control 
What purposes could be served by a regulatory regime for cyber
-attack? Traditional arms control theory generally indicates that three 
broad purposes could be served in principle,
5 presuming that the restric
-tions of the regime are observed by all signatories: 

Reducing the likelihood that con˜ict will occur
. Con˜dence-building 
measuresŠarrangements in which signatory parties agree to refrain from 

or to notify other signatories prior to conducting certain activities that 

might be viewed as hostile or escalatory or to communicate directly with 

each other during times of tension or crisisŠare explicitly intended to 

reduce the likelihood of con˚ict due to accident or misunderstanding. In 

addition, agreements to eschew the use of cyberattack may have some 

value in reducing the likelihood of kinetic con˚ict in those cases in which 

cyberattack is a necessary prelude to a kinetic attack.
6 
Reducing the destructi
veness of any con˜ict that does occur
. Limitations 
on targeting cyberattack weapons could prevent damage to the prohibited 

entities, presuming that the scope of a cyberattack can be delimited with 

con˜dence. Moreover, limiting damage to those entities might prevent 

escalation from occurringŠand such escalation could include escalation 

to kinetic or even nuclear con˚ict. Reducing destructiveness might also 

facilitate a more rapid cessation of cyberhostilities.

Reducing ˚nancial costs. 
Limitations on acquisition of weapons for 
cyberattack would not have a signi˜cant impact on ˜nancial costs, simply 

because these weapons are so inexpensive in the ˜rst place. Nor would a 

particular adversary™s agreement to refrain from conducting cyberattack 

relieve the United States from needing to defend against other nations or 

subnational entities that could use such weapons.
Given the possibilities for cyberattack to disrupt national economies 
or to distort the activities of individual companies as well (especially large 
5 These three purposes can be found in Thomas C. Schelling and Morton H. Halperin, 
Strategy and Arms Control
, Pergamon-Brassey™s, Washington, D.C., 1985.
6 Such cases may well be rare. If and when they exist, they are based on the idea that 
cyberattack is to be used for shaping battle˜eld conditions and introducing delay and dis
-ruption into adversary planning. (See, for example, the discussion in Chapter 9 (escalation), 
Chapter 3 (how the United States is likely to use information warfare should it become nec
-essary), and Section 10.3 (regarding China).) If a kinetic attack requires the kind of battle˜eld 
conditions and the delay or disruption that only a cyberattack can provide, then the kinetic 
attack might be inhibited. On the other hand, an adversary may well have alternative (non-

cyber) means for accomplishing these tasks.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.322
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
companies that are very important to a nation), a regulatory regime for 
cyberattack might also reduce the likelihood of economic warfare using 
this military tool.
As an example of an international agreement involving the use of 
cyberattack, Davis Brown, a former deputy staff judge advocate of the 

U.S. Defense Information Systems Agency,
7˛ has proposed to extend the 
law of armed con˚ict to account explicitly for the use of information sys
-tems in armed con˚ict (Box 10.1). 
The argument for the United States entering into an international 
agreement regarding cyberattack
8 is based on the notion that the United 
States would be relatively worse off than any other nation if all nations 

could carry out cyberattacks without restriction because the United States 

is signi˜cantly more dependent on information technology than any other 

nation that is likely to be involved in a major cybercon˚ict. Whether this 

relative disadvantage will endure over the long term depends on whether 

the dependence of other nations on information technology is increasing 

more rapidly than that of the United StatesŠbut it is undeniable from 

any perspective that the United States would have much to lose in all-out 

cybercon˚ict whether or not that loss would be greater or less than that 

suffered by an adversary.
In this view, an agreement regarding cyberattack weapons is based in 
large part on a desire to delegitimize such use against the United States, 

precisely because the United States has so much to lose from a large-scale 

cybercon˚ict. Conversely, aggressive pursuit of cyberattack capabilities by 

the United States is seen as legitimizing cyberattack as a military weapon 

and indeed as encouraging other nations to develop such capabilities for 

use against the United States and its interests. Others argue that other 

nations need no prodding from the United States to develop cyberat
-tack weapons for use against it, and that adversary development of such 

weapons is inevitable regardless of what the United States chooses to do 

in this arena.
Another bene˜t of a formal agreement regarding use of cyberattack 
is that it can help to make explicit many of the concerns that military 

operators will have (or, at least, should have) in using cyberattack as an 

operational weapon. If certain operational practices are prohibited, ques
-tions about whether or not an operator can engage in those practice are 

easier to resolve.
7 Davis Brown, ﬁA Proposal for an International Convention to Regulate the Use of 
Information Systems in Armed Con˚ict,ﬂ 
Har
vard International Law Journal
 47(1):179-221, 
Winter 2006.
8 A possible platform on which such an agreement might be constructed is the Con
-vention on Conventional Weapons, an international agreement that regulates a number of 
individual weapons, including lasers intended to blind humans.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.ALTERNATIVE FUTURES
 323
BOX 10.1
 An Illustrative Draft Convention Regulating the Use 
of Information Systems in Armed Conflict
Davis Brown, a former deputy staff judge advocate of the U.S. Defense Infor
-mation Systems Agency, proposes to extend the law of armed con˚ict to account 
explicitly for the use of information systems in armed con˚ict.  Brown accepts 

conventional LOAC as the initial point of departure and is guided by the principle 

that an act that violates LOAC if carried out by conventional means also violates 

LOAC if carried out by cyberattack.  
Under Brown™s proposal: 
The activities of patriotic hackers against an adversary would be 
prohibited.  
The military forces conducting cyberattack should not be commingled with 
civilians in their workplaces.
Cyberattacks on dual-use infrastructure (e.g., railroads, communications 
centers, pipelines) are legitimate as long as the military advantage gained by 
attacking such targets outweighs the harm to civilians.  
The use of cyberattack to attack civilian infrastructure or targets whose 
destruction would cause severe environmental damage would be prohibited.  
The use of cyberattack weapons whose impact is indiscriminateŠthat 
cannot distinguish between military and civilian targetsŠor that cannot self-
 destruct or be rendered harmless after hostilities terminate would be prohibited.
Cyberattacks on the military payroll system or on non-combatant families 
of military personnel or posting the Social Security numbers of individual service
-men and servicewomen to increase their vulnerability to identity theft would be 
prohibited.Active threat neutralization would be permitted even if it involved damage 
to innocent third parties whose computers had been compromised, if passive 

defense was insuf˜cient to defend against the threat.
Only certain kinds of false identities would be prohibited. These prohib
-ited false identities would include masquerading as an of˜cial in the government 

or armed forces of the target state or of any third state, and masquerading as 

originating from any third state, or as originating with any medical or religious 

establishment in any location. 
Belligerents would be forbidden to use for military purposes domain names 
or computer systems associated with neutral nations, to launch cyberattacks from 

computer systems in neutral states, or to take control of neutral systems in order 

to conduct cyberattacks.
SOURCE: Adapted from Davis Brown, ﬁA Proposal for an International Convention to Regu
-late the Use of Information Systems in Armed Con˚ict,ﬂ 
Harvard International Law Journal
 47(1):179-221, Winter 2006.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.32
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
What about the veri˜ability of any such agreement? Consider ˜rst 
the feasibility of verifying an agreement to refrain from acquiring cyber
-attack capabilities. Many factors suggest that such an agreement would 
not be veri˜able in any meaningful way. The technologyŠhardware 

technologyŠof certain kinds of cyberattack is easily available at Staples, 

Best Buy, and Dell.com, and its acquisition cannot be limited. The knowl
-edge needed to conduct such cyberattacks is more dif˜cult to acquire but 

is also available on the Internet, to say nothing of knowledge developed 

by sophisticated computer scientists. CodeŠsoftware toolsŠto carry out 

cyberattack can be transmitted over the Internet and reproduced trivi
-ally, and is available from many sources. Restricting the development 

of the expertise needed to conduct cyberattacks is equally implausible, 

because the expertise needed to develop defenses against cyberattacks is 

intimately related to the expertise needed to develop cyberattacks them
-selves. Nor would any acceptable inspection regime have a meaningful 

chance to ˜nd software-based cyberattack weapons. Finally, the human 

and technical infrastructure needed to conduct cyberattack would be 

much smaller than (and could easily be embedded within) that needed to 

conduct cyberdefense on a large scale, and thus could be easily hidden.
An agreement might also involve restrictions on the use of cyber
-attack weapons. For example, signatories might agree to refrain from 

striking at national ˜nancial systems or power grids, much as nations 

might avoid targeting hospitals in a kinetic attack, or to refrain from 

using lasers intended to blind soldiers. In order to facilitate the non-attack 

of such facilities, nations might agree to take measures to electronically 

identify systems as being associated with prohibited targets,
9 much as 
the ﬁrobots.txtﬂ protocol today is used to signal search engines to refrain 

from indexing a given website.
10
 A more limited agreement might obli
-gate signatories to refrain from ˜rst-use cyberattacks on national ˜nancial 

systems or power grids.
Obviously, an attacker can ignore such electronic indicators, just as 
a kinetic attacker can ignore red crosses painted on the sides of ambu
-lances in times of war. Moreover, such agreements are not ﬁveri˜ableﬂ 

in advance, in the sense that no amount of information collected before 

a con˚ict can guarantee that restrictions on use will be observed during 

con˚ict. But such agreements do create international norms regarding the 

acceptability of such behavior, and they do something to inhibit training 
9 Davis Brown, ﬁA Proposal for an International Convention to Regulate the Use of 
Information Systems in Armed Con˚ict,ﬂ 
Har
vard International Law Journal
 47(1):179-221, 
Winter 2006.
10
 For more on this protocol, see http://www.robotstxt.org/.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.ALTERNATIVE FUTURES
 325
that calls for such use. The threat of reciprocal use during con˚ict may 
also serve as a deterrent to ˜rst use.
In the case of cyberattack, restrictions on use are complicated by many 
factors. For example, subnational groups under the nominal jurisdic
-tion of a signatory may take actions independently of the government. 
A nation™s military forces may refrain from targeting the power grids of 

an adversary, but patriotic hackers or terrorist groups on that nation™s 

soil might do so without explicit government approval. Thus, compli
-ance with such an agreement might entail a somewhat bizarre scenario 

in which two nations are in con˚ict, perhaps kinetic con˚ict, but each 

is simultaneously conducting actions (perhaps involving law enforce
-ment) to suppress subnational cyber actions intended to advance their 

respective causes. On the other hand, such agreements are likely to be 

more effective prior to the onset of con˚ict, because a signatory would 

have incentives to take suppressing actions in order to avoid undue and 

unwanted escalation.
Moreover, arms control agreements have in the past presumed a state 
monopoly on the arms being regulated. But in the case of tools that might 

be used for cyberattack, the private sector owns and operates much of the 

infrastructure through which cyberattacks might be conducted. Indeed, 

the behavior of individual citizens might be directly affected by a tradi
-tional arms control agreementŠand the degree of intrusiveness on the 

behavior of individuals and the private sector more generally might be 

large indeed depending on the nature of the agreement. 
Furthermore, the technology with which to conduct cyberattacks is 
most assuredly not exclusively or even mostly controlled by governments. 

Private citizens (hackers) conduct many cyberattacks on their own every 

day. Non-state actors such as terrorist groups or transnational criminal 

organizations could develop signi˜cant cyberattack capabilities as well, 

but would be unlikely to adhere to any agreement between the United 

States and any of the nations that might harbor them.
11
 Under such cir
-cumstances, domestic laws in the relevant nations may be the only legal 

means of regulating the activities of such parties (and even then, the effec
-
tiveness of domestic laws depends on the availability of some enforce
-ment mechanism, which may not be present in some of these nations).
Another complication is the functional similarity between cyberex
-ploitation against an adversary™s information systems and cyberattack 

against those information systems. A cyberexploitation may well be inter
-preted by the target as a damaging or destructive act (or at least the pre
-lude to such an act), and yet to eschew the former actions would be to 
11
 Jason Barkham, ﬁInformation Warfare and International Law on the Use of Force,ﬂ 
New York Uni
versity International Law and Politics
 34:57-113, 2001.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.326
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
contradict what amounts to standard operating procedure for essentially 
all nations.
A ˜nal complication discussed in this report arises from the dif˜culty 
of tracing cyberattacks to their ultimate origin. If the ultimate origin of 
a cyberattack can be concealed successfully, holding the violator of an 

agreement accountable becomes problematic. One technological approach 

is to deploy a supporting infrastructure more capable than that of today 

which could support a ﬁuse controlﬂ regimeŠa more technologically 

secure network on a different physical infrastructure whose use would 

be restricted to those willing to subject themselves to a more constrained 

regime regarding behavior (e.g., who would agree to be strongly authen
-ticated) and classi˜ed as critical to national well-being. But deploying 

such an infrastructure has many potential drawbacks, such as prevent
-ing any connection, physical or logical, to the regular Internet through 

which cyberattacks might be launched; retaining the economies of the 

present-day Internet; and preventing the compromise of the strongly 

authenticated machines.
Agreements might also take place among allies, though in such 
instances they may take the form of what might be called coordinated 

unilateral declaratory policies. For example, the NATO nations could col
-lectively agree to refrain from using large-scale cyberattacks against the 

entire critical infrastructure of an adversary nation as a matter of declara
-tory policy. Any such agreementŠor more precisely, discussions leading 

to such an agreementŠwill inevitably stimulate dialogue and debate 

regarding the topic of cyberattack.
Finally, the history of arms control agreements is that they often suffer 
from the too-early/too-late problem. That is, the desirability of an agree
-ment may be anticipated, but the technology, doctrine, and so on are not 

well developed at the time, so it is premature to enter into an agreement. 

Then technology and doctrine advance rapidly, and before it is widely 

realized, it has become too late to enter into an agreement because the 

potential signatories to such an agreement have so much at stake in using 

the weapons that would be controlled by the putative agreement.
10.2.2
 Indirect Approaches Based on 
 Regulation of Non-military Domains
The United States has been a party to many international agreements 
that are not arms control agreements. For example, nations have some
-times agreed on the need to protect some area of international activity 

such as airline transport, telecommunications, maritime activities, and so 

on, and also on standards for such protection. They may declare certain 

purposes collectively with regard to a given area of activity on which 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.ALTERNATIVE FUTURES
 327
they agree, often in the form of a multilateral treaty, and then establish 
consensus-based multilateral institutions (generally referred to as ﬁspe
-cialized agenciesﬂ composed of experts rather than politicians) to which 
to delegate (subject to continuous review) the task of implementing those 

agreed purposes. 
Sofaer and Goodman argue that it has been easier to obtain agreement 
among the nations involved on standards and methods for regulating the 

civilian (commercial) aspects of a given activity than to obtain agreement 

on standards and methods for regulating the military (governmental) 

aspects of the same activity.
12
 For example, civil aviation is regulated 
internationally through agencies that have promulgated numerous agree
-ments and regulations, all by consensus. Over the years, some precedents, 

and some forms of regulation, have been established, again largely by 

consensus, that have enhanced the protection of civilian aviation and 

reduced the uncertainties regarding governmental (military) aviation. 

A similar pattern of international regulation has resulted in increased 

maritime safety. 
In both areas, states have agreed to criminalize terrorist attacks, and to 
prosecute or extradite violators. These commitments have not uniformly 

been kept, but security has been enhanced in these areas of international 

commerce because of the virtually universal support given to protecting 

these activities from identi˜ed threats. 
Sofaer and Goodman proposed a draft multilateral treaty that would 
have initiated a similar process to help improve cybersecurity internation
-ally, even though it would have initially excluded any direct application 

of rules and standards developed to the national security activities of 
member states.
  The proposed treaty would have included:

Agreed principles on the use and protection of cyberspace; 

Maximum emphasis on protecting the system, rather than on pre
-venting its use for socially unacceptable objectives such as pornography; 

Agreement of all parties to cooperate in preventing, prosecut
-ing, and cooperating against improper conduct by any non-government 

group; 

Maximum coverage, so as to limit use of ﬁrogueﬂ territories as 
bases for attacks; 

A program to develop cyber capacities of developing states; and 

Substantial involvement and authority given to the private sector 
in developing and approving standards. 
12
 Abraham D. Sofaer and Seymour E. Goodman, 
A Proposal for an International Con
ven
-tion on Cyber Crime and Terrorism
, Center for International Security and Cooperation, Stanford 
University, August 2000.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.328
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
However, the U.S. government rejected the concept of a multilateral 
treaty with comprehensive aims in favor of a narrower treaty with Euro
-pean allies limited to establishing certain cyber-system crimes and secur
-ing commitments for cooperation in dealing with those activitiesŠthe 
Convention on Cybercrime described in Section 7.2.6.
Sofaer and Goodman argue that the approach they propose would, 
over the long run, provide greater, broad-based international support for 

a meaningful international cybersecurity regime than will result from a 

more limited approach.
10.3
 FOREIGN
 P
ERSPECTIVES
 ON
 C
YBERATTACK
The potential impact of cyberattacks on a nation™s defense posture 
has not gone unnoticed in other nations or in the world community. For 

example, in September 1998, then-Russian foreign minister Igor Ivanov 

wrote to Ko˜ Annan, United Nations secretary-general, warning that the 

effect of information weapons ﬁmay be comparable to that of weapons of 

mass destruction.ﬂ
13
 Likely in response to that letter, the United Nations 
General Assembly subsequently considered an item entitled ﬁDevelop
-ments in the Field of Information and Telecommunications in the Context 

of International Securityﬂ
14
 and has adopted a resolution on this topic sev
-eral times since then. These resolutions have variously called on member 

states to further promote the multilateral consideration of existing and 

potential threats in the information security ˜eld, as well as possible mea
-sures to limit emerging threats, consistent with the need to preserve the 

free ˚ow of information. In addition, they have invited all member states 

to inform the secretary-general of their views on several topics, including 

a ﬁgeneral appreciation of the issues of information securityﬂ; ﬁde˜nition 

of basic notions related to information security that would include unau
-thorized interference with or misuse of information and telecommunica
-tions systems and information resourcesﬂ; and ﬁrelevant international 

concepts aimed at strengthening the security of global information and 

telecommunications systems.ﬂ
15
Although several member states have indeed submitted views on this 
topic, the efforts of the General Assembly have been spearheaded by the 
13
 See letter from Ivanov to Annan, September 30, 1998, available at http://www.
un.org/ga/search/view_doc.asp?symbol=A/C.1/53/3&Lang=E.
14
 UN Document A/RES/53/70, ﬁ
De
velopments in the Field of Information and Telecom
-munications in the Context of International Security
,ﬂ January 4, 1999, available at http://
daccess-ods.un.org/TMP/7333411.html.
15
 United Nations Disarmament Handbook
, United Nations Publications, New York 
City, 2004, available at http://www.un.org/disarmament/HomePage/ODAPublications
/Yearbook/2004/Html/Ch%20V6.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.ALTERNATIVE FUTURES
 329
Russian Federation, and it is not coincidental that important source docu
-ments contributing to the UN General Assembly discussion of the topic 
are authored by senior scholars and others from Russia.
For example, some Russian thinkers have noted the potentially stra
-tegic signi˜cance of information warfare and have connected the conse
-quences of information attacks to potentially nuclear responses: 
From a military point of view, the use of information warfare means 
against Russia or its armed forces will categorically not be considered 

a non-military phase of a con˚ict, whether there were casualties or not. 
. . . Considering the possible catastrophic consequences of the use of 
strategic information warfare means by an enemy, whether on economic 

or state command and control systems, or on the combat potential of the 

armed forces, . . . Russia retains the right to use nuclear weapons ˜rst 
against the means and forces of information warfare, and then against 
the aggressor state itself.
16
 In stating its views on the subject of information security to the United 
Nations, Russia de˜ned information war as ﬁconfrontation between States 
in the information area for the purpose of damaging information systems, 

processes and resources and vital structures, undermining political, eco
-nomic and social systems as well as the massive psychological manipula
-tion of a population in order to destabilize society and the State.ﬂ Infor
-mation weapons were regarded as the ﬁways and means used for the 

purpose of damaging the information resources, processes and systems 

of a State, exerting an adverse in˚uence, through information, on the 

defence, administrative, political, social, economic and other vital systems 

of a State, as well as the massive psychological manipulation of a popula
-tion in order to destabilize society and the State.ﬂ
The Russian Federation has set forth to the United Nations a docu
-ment articulating what it describes as ﬁPrinciples of International Informa
-tion Security.ﬂ
17
 (Selected principles are listed in Box 10.2.) The document 
appears to be intended as a draft resolution of the United Nations General 

Assembly. The intent of the Russian statement of principles appears to be 

an outright prohibition on the national development, creation, and use 

of tools for cyberattack (Principle II.a), on interfering with or unlawfully 
16
 V. I. Tsymbal, ﬁKontseptsiya `Informatsionnoy Voiny™ﬂ (Concept of Information War
-fare), speech given at a Russian-U.S. conference, ﬁEvolving PostŒCold War National Security 
Issues,ﬂ Moscow, September 12-14, 1995, p. 7, cited in Timothy L. Thomas, ﬁDeterring Infor
-mation Warfare: A New Strategic Challenge,ﬂ 
Parameters
 26(Winter):82, 1996-1997.
17
 United Nations General Assembly A/55/140, 
De
velopments in the Field of Information 
and Telecommunications in the Context of International Security
, Fifty-˜fth session, Item 69 of 
the provisional agenda, July 20, 2000, available at http://www.un.org/documents/ga/

docs/55/a55140.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.33
0 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
BOX 10.2
 Selected Russian Principles of International 
Information Security
Principle II
States shall strive to restrict threats in the ˜eld of international information 
security and with that end in view shall refrain from:
(a) The development, creation and use of means of in˚uencing or damaging 
another State™s information resources and systems;
(b) The deliberate use of information to in˚uence another State™s vital 
structures;
(c) The use of information to undermine the political, economic and social 
system of other States, or to engage in the psychological manipulation of a popula
-tion in order to destabilize society;
(d) Unauthorized interference in information and telecommunications sys
-tems and information resources, as well their unlawful use;
(e) Actions tending to establish domination or control in the information 
area;(f) Preventing access to the most recent information technologies and the 
creation of conditions of technological dependency in the information ˜eld to the 
detriment of other States;
(g) Encouraging the activities of international terrorist, extremist or criminal 
associations, organizations, groups or individual law breakers that pose a threat 

to the information resources and vital structures of States;
(h) Formulating and adopting plans or doctrines envisaging the possibility of 
waging information wars and capable of instigating an arms race as well as caus
-ing tension in relations between States and speci˜cally giving rise to information 

wars;
(i) The use of information technologies and tools to the detriment of funda
-mental human rights and freedoms in the ˜eld of information;
(j) The transboundary dissemination of information in contravention of the 
principles and norms of international law and of the domestic legislation of speci˜c 

countries;
(k) The manipulation of information ˚ows, disinformation and the conceal
-ment of information in order to corrupt the psychological and spiritual environment 

of society, and erode traditional cultural, moral, ethical and aesthetic values;
(l) Expansion in the ˜eld of information and the acquisition of control over 
the national information and telecommunications infrastructures of another State, 

including the conditions for their operation in the international information area.
Principle III 
The United Nations and appropriate agencies of the United Nations system 
shall promote international cooperation for the purpose of limiting threats in the 

˜eld of international information security and creating, for that purpose, an inter
-national legal basis to:
(a) Identify the de˜ning features of information wars and to classify them;
(b) Identify the characteristic features of information weapons, and of tools 
that may be regarded as information weapons, and to classify them;
(c) Restrict traf˜c in information weapons;
(d) Prohibit the development, dissemination or use of information weapons;
(e) Prevent the threat of the outbreak of information wars;
(f) Recognize the danger of using information weapons against vital struc
-tures as being comparable to the threat of use of weapons of mass destruction;
(g) Create conditions for the equitable and safe international exchange of 
information based on the generally recognized rules and principles of international 

law;
(h) Prevent the use of information technologies and tools for terrorist or other 
criminal purposes;
(i) Prevent the use of information technologies and tools to in˚uence social 
consciousness in order to destabilize society and the State;
(j) Develop a procedure for the exchange of information on and the preven
-tion of unauthorized transboundary in˚uence through information;
(k) Create an international monitoring system for tracking threats that may 
arise in the information ˜eld;
(l) Create a mechanism for monitoring compliance with the conditions of the 
international information security regime;
(m) Create a mechanism to resolve con˚ict situations in the area of informa
-tion security;
(n) Create an international system for the certi˜cation of information and 
telecommunications technologies and tools (including software and hardware) with 

a view to guaranteeing their information security;
(o) Develop a system of international cooperation among law enforcement 
agencies with a view to preventing and suppressing crime in the information 

area;(p) Harmonize, on a voluntary basis, national legislation in order to ensure 
information security.
SOURCE: United Nations General Assembly A/55/140, 
Developments in the Field of  Infor
-mation and Telecommunications in the Context of International Security
, Fifty-˜fth session, 
Item 69 of the provisional agenda, July 10, 2000, available at http://www.un.org/documents/
ga/docs/55/a55140.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.ALTERNATIVE FUTURES
 331
BOX 10.2
 Selected Russian Principles of International 
Information Security
Principle II
States shall strive to restrict threats in the ˜eld of international information 
security and with that end in view shall refrain from:
(a) The development, creation and use of means of in˚uencing or damaging 
another State™s information resources and systems;
(b) The deliberate use of information to in˚uence another State™s vital 
structures;
(c) The use of information to undermine the political, economic and social 
system of other States, or to engage in the psychological manipulation of a popula
-tion in order to destabilize society;
(d) Unauthorized interference in information and telecommunications sys
-tems and information resources, as well their unlawful use;
(e) Actions tending to establish domination or control in the information 
area;(f) Preventing access to the most recent information technologies and the 
creation of conditions of technological dependency in the information ˜eld to the 
detriment of other States;
(g) Encouraging the activities of international terrorist, extremist or criminal 
associations, organizations, groups or individual law breakers that pose a threat 

to the information resources and vital structures of States;
(h) Formulating and adopting plans or doctrines envisaging the possibility of 
waging information wars and capable of instigating an arms race as well as caus
-ing tension in relations between States and speci˜cally giving rise to information 

wars;
(i) The use of information technologies and tools to the detriment of funda
-mental human rights and freedoms in the ˜eld of information;
(j) The transboundary dissemination of information in contravention of the 
principles and norms of international law and of the domestic legislation of speci˜c 

countries;
(k) The manipulation of information ˚ows, disinformation and the conceal
-ment of information in order to corrupt the psychological and spiritual environment 

of society, and erode traditional cultural, moral, ethical and aesthetic values;
(l) Expansion in the ˜eld of information and the acquisition of control over 
the national information and telecommunications infrastructures of another State, 

including the conditions for their operation in the international information area.
Principle III 
The United Nations and appropriate agencies of the United Nations system 
shall promote international cooperation for the purpose of limiting threats in the 

˜eld of international information security and creating, for that purpose, an inter
-national legal basis to:
(a) Identify the de˜ning features of information wars and to classify them;
(b) Identify the characteristic features of information weapons, and of tools 
that may be regarded as information weapons, and to classify them;
(c) Restrict traf˜c in information weapons;
(d) Prohibit the development, dissemination or use of information weapons;
(e) Prevent the threat of the outbreak of information wars;
(f) Recognize the danger of using information weapons against vital struc
-tures as being comparable to the threat of use of weapons of mass destruction;
(g) Create conditions for the equitable and safe international exchange of 
information based on the generally recognized rules and principles of international 

law;
(h) Prevent the use of information technologies and tools for terrorist or other 
criminal purposes;
(i) Prevent the use of information technologies and tools to in˚uence social 
consciousness in order to destabilize society and the State;
(j) Develop a procedure for the exchange of information on and the preven
-tion of unauthorized transboundary in˚uence through information;
(k) Create an international monitoring system for tracking threats that may 
arise in the information ˜eld;
(l) Create a mechanism for monitoring compliance with the conditions of the 
international information security regime;
(m) Create a mechanism to resolve con˚ict situations in the area of informa
-tion security;
(n) Create an international system for the certi˜cation of information and 
telecommunications technologies and tools (including software and hardware) with 

a view to guaranteeing their information security;
(o) Develop a system of international cooperation among law enforcement 
agencies with a view to preventing and suppressing crime in the information 

area;(p) Harmonize, on a voluntary basis, national legislation in order to ensure 
information security.
SOURCE: United Nations General Assembly A/55/140, 
Developments in the Field of  Infor
-mation and Telecommunications in the Context of International Security
, Fifty-˜fth session, 
Item 69 of the provisional agenda, July 10, 2000, available at http://www.un.org/documents/
ga/docs/55/a55140.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.332
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
using information systems or resources (II.d), and on developing plans or 
military doctrines intended to wage ﬁinformation warsﬂ (II.h). To support 
these goals, the Russian statement calls on the United Nations to create an 

international legal basis to identify the characteristic features of informa
-tion weapons, and to classify them (III.b); to restrict traf˜c in information 

weapons (III.c); and to prohibit the development, dissemination, or use 

of information weapons (III.d).
Of˜cial Russian position statements to the United Nations notwith
-standing, it is widely believed that Russia is fully engaged in, or at least 

developing, the capability for launching cyberattacks, regardless of its 

UN stance.
China™s view on the topic of cybercon˚ict appears to be radically 
different from that of the Russian Federation. One analyst of Chinese 

military forces identi˜es 10 ﬁinformation operationsﬂ methods that the 

Chinese anticipate using:
18

Planting information mines, 

Conducting information reconnaissance, 

Changing network data, 

Releasing information bombs, 

Dumping information garbage, 

Disseminating propaganda,

Applying information deception, 

Releasing clone information, 

Organizing information defense, 

Establishing network spy stations.
China apparently sees great value in acquiring information warfare 
capabilities and developing facility in their use, and indeed sees informa
-tion warfare as an equalizer in potential military con˚icts with a tech
-nologically superior adversary such as the United States.
19
 For example, 
Mulvenon argues that the Chinese see information warfare against the 

information systems of the U.S. military as a way to degrade and delay 

the mobilization of U.S. forces and/or their deployment to Taiwan in the 

event of a crisis over that territory.
20
 18
 Timothy L. Thomas, ﬁChina™s Electronic Strategies,ﬂ 
Military Re
view (
May-June), 
2001. Available at http://leav-www.army.mil/fmso/documents/china_electric/china_elec
-tric.htm.
19
 James C. Mulvenon, ﬁThe PLA and Information Warfare,ﬂ in James C. Mulvenon 
(ed.), 
The People™s Liberation Army in the Information Age,
 Conference Proceedings, The RAND 
Corporation, 1998.
20
 Two PLA authors explicitly endorse what they call ﬁasymmetric information offen
-sives.ﬂ See Wang Jianghuai and Lin Dong, ﬁViewing Our Army™s Quality Building from the 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.ALTERNATIVE FUTURES
 333
The Eligible Receiver exercise of 1997 underscores this point. Accord
-ing to 
Go
vernment Executi
ve,21
 the exerciseŠdesigned to expose weak
-nesses in computer security in unclassi˜ed DOD computer systems using 
off-the-shelf technology and software downloaded from hacker web
-sitesŠdemonstrated how hackers might disrupt troop deployments. 
But the Chinese also believe that political and economic targets as 
well as military targets are fair game for information warfare. Indeed, 

disruption of these institutions is an important element in demoralizing 

an adversary and reducing its will to ˜ght, and so the Chinese view it 

as entirely reasonable to attack ˜nancial systems, power generation and 

transmission facilities, and other elements of critical infrastructure as part 

of con˚ict with another nation (whether or not that con˚ict has become 

kinetic).
Finally, the Chinese also see information warfare as a way of enabling 
the citizenry to participate in a military con˚ict,
22
 in which any citizen 
with a computer can participate in information warfare against an adver
-sary. Indeed, according to Thomas, the information warfare mission is an 

ideal one for the reserve military forces of China, which can enlist many 

individuals who are not quali˜ed or eligible to be frontline soldiers.
The Chinese perspective suggests that the Chinese are likely to view 
any attempt to restrict the use of cyberattack as a way to undermine one 

of China™s few advantages in competing militarily with an adversary such 

as the United States.
Perspective of What Information Warfare Demands,ﬂ 
Jiefangjun bao
, March 3, 1998, p. 6, in 
FBIS-CHI-98-072, March 13, 1998; cited in Mulvenon, 1998.
21
 Katherine McIntire Peters, ﬁInformation Insecurity,ﬂ 
Go
vernment Executi
ve, April 1, 
1999, available at http://www.govexec.com/features/0499/0499s1.htm.
22
 Timothy L. Thomas, ﬁLike Adding Wings to the Tiger: Chinese Information War 
Theory and Practice,ﬂ Foreign Military Studies Of˜ce, Fort Leavenworth, Kans. Undated 
publication, available at http://fmso.leavenworth.army.mil/documents/chinaiw.htm.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Appendixes
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Appendix A
Biographies of Committee 
 Members and Staff
COMMITTEE MEMBERS
William A. Owens
, 
Co-chair
, is the chair and CEO of AEA Hold
-ings based in Hong Kong. He retired as vice chair and chief executive 
of˜cer of Nortel on November 15, 2005. Before joining Nortel in 2004, 

Admiral Owens was chief executive of˜cer and chair of Teledesic LLC 

and president, chief operating of˜cer, and vice chair of Science Applica
-tions International Corporation (SAIC). Before joining SAIC, he was vice 

chairman of the Joint Chiefs of Staff and the second ranking military 

of˜cer in the United States. He had responsibility for the reorganization 

and restructuring of the armed forces in the postŒCold War era. Widely 

recognized for bringing commercial high technology into the Department 

of Defense for military applications, the admiral was the architect of the 

Revolution in Military Affairs (RMA), an advanced systems technology 

approach to military operations that is the most signi˜cant change in 

the system of requirements, budgets, and technology for the four armed 

forces since World War II. From 1991 to 1993, he was the deputy chief of 

Naval Operations for Resources, Warfare Requirements and Assessments. 

Admiral Owens served as commander of the U.S. Sixth Fleet in 1990 and 

1991. Between 1988 and 1991, he served as senior military assistant to 

Secretaries of Defense Frank Carlucci and Dick Cheney, the senior military 
 position in the Of˜ce of the Secretary of Defense. In 1988, the admiral 
was the director of the Of˜ce of Program Appraisal for the secretary of 
the Navy. In 1987, he served as commander of Submarine Group Six, 

the Navy™s largest submarine group, with 20 strategic ballistic missile 
337
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.338
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
submarines, 45 nuclear attack submarines, and more than 15,000 men 
and women. Earlier in his career, he commanded Submarine Squadron 
Four, the USS Sam Houston, and the USS City of Corpus Christi. Admiral 

Owens has written more than 50 articles on national security and wrote 

the book 
High Seas
. His latest book, 
Lifting the Fog of War,
 was published 
in April 2000 and revised and republished in 2008. He is a 1962 graduate 

of the U.S. Naval Academy and holds a B.S. in mathematics. He also holds 

bachelor™s and master™s degrees in politics, philosophy, and econom
-ics from Oxford University and a master™s degree in management from 

George Washington University. The admiral is the founder of Extend 

America, a 5-year state wireless telecommunications venture, and also sits 

on the public boards of Polycom, Wipro, and Daimler AG as well as the 

private boards of Intelius, Force 10 Networks, Unifrax, and AEA Investors 

LLC. Owens is a member of several philanthropic boards including the 

Carnegie Foundation, the Brookings Institution, and the Fred Hutchinson 

Cancer Research Center. He is also a member of the Canadian Council of 

Chief Executives and the Council on Foreign Affairs.
Kenneth W. Dam
, 
Co-chair
, University of Chicago, has devoted his 
career to public policy issues, both as a practitioner and as a professor. 

He served as deputy secretary (the second-ranking of˜cial) in the Depart
-ment of Treasury (2001-2003) and in the Department of State (1982-1985). 

In 1973 he was executive director of the Council on Economic Policy, 

a White House of˜ce responsible for coordinating U.S. domestic and 

international economic policy. From 1971 to 1973 he served as assistant 

director for national security and international policy at the Of˜ce of 

Management and Budget. He began his Washington career as law clerk 

to U.S. Supreme Court Justice Charles E. Whittaker (1957-1958). Professor 

Dam™s entire academic career has been devoted to the University of Chi
-cago, beginning in 1960 and extending, with various leaves of absence, to 

the present. From 1980 to 1982 he served as provost of the University of 

Chicago. Most of his academic work has centered on law and economics, 

particularly with respect to international issues. Professor Dam™s other 

activities include serving as IBM vice president for law and external 

relations (1985-1992) and as president and chief executive of˜cer of the 

United Way of America for a 6-month period in 1992. He has extensive 

experience as an arbitrator. The professor is a member of the board of the 

Brookings Institution and serves as a senior fellow of that organization. 

He is a member of the Shadow Financial Regulatory Committee and of 

the National Research Council™s Science, Technology and Law Panel. 

He has been elected to membership in the American Law Institute and 

the American Academy of Arts and Sciences. He was chair of the Ger
-man-American Academic Council and a board member of a number of 

non-pro˜t institutions, including the Council on Foreign Relations (New 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX A
 339
York) and the Chicago Council on Foreign Relations. He currently serves 
on the board of the Financial Services Volunteer Corps. Professor Dam 
served for 13 years on the board of Alcoa. He received a B.S. in 1954 from 

the University of Kansas, a J.D. in 1957 from the University of Chicago, 

and an LL.D. (hon.) in 1983 from the New School for Social Research. The 

professor served as chair for the CSTB committee that produced the report 

Cryptography™s Role in Securing the Information Society
, and he served on the 
CSTB committee that produced the report 
Global Networks and Local Values: 
A Comparati
ve Look at Germany and the United States
. Thomas A. Berson
, president of Anagram Laboratories, has spent 
his career working both the defensive and the offensive sides of the 

information security battle. After stints as a researcher, a cold warrior, 

and Silicon Valley entrepreneur, Dr. Berson founded Anagram Labora
-tories, a thriving information security consultancy that is celebrating its 

23rd anniversary in 2009. He is attracted most strongly to security issues 

raised at the con˚uence of technology, business, and world events. His 

client base includes Salesforce.com (disruptive at the center of the net) 

and Skype (disruptive at the edge). Dr. Berson is a student of Sun Tzu™s 

Art of War and its applicability to modern information con˚ict. Dr. Berson 

was the ˜rst person to be named a fellow of the International Association 

for Cryptologic Research. His citation reads, ﬁfor visionary and essential 

service and for numerous valuable contributions to the technical, social, 

and commercial development of cryptology and security.ﬂ Dr. Berson was 

an editor of the 
Journal of Cryptology
 for 14 years. He is a past chair of the 
IEEE Technical Committee on Security and Privacy and a past president 

of the International Association for Cryptologic Research. He earned a 

B.S. in physics from the State University of New York in 1967 and a Ph.D. 

in computer science from the University of London in 1977. He was a 

visiting fellow in mathematics at the University of Cambridge and is a 

life member of Clare Hall, Cambridge. Dr. Berson has been a member of 

two previous National Research Council committees: the Committee on 

Computer Security in the Department of Energy and the Committee to 

Review DOD C4I Plans and Programs.
Gerhard Casper
 is president emeritus of Stanford University and 
the Peter and Helen Bing Professor in Undergraduate Education at Stan
-ford. He is also a professor of law, a senior fellow at the Freeman Spogli 

Institute for International Studies, and a professor of political science (by 

courtesy). Mr. Casper studied law at the Universities of Freiburg and 

Hamburg, where, in 1961, he earned his ˜rst law degree. He attended 

Yale Law School, obtaining a master of laws degree in 1962. He then 

returned to Freiburg, where he received his doctorate in 1964. He has 

been awarded honorary doctorates, most recently in law from Yale and 

in philosophy from Uppsala. In the fall of 1964, Mr. Casper emigrated to 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.340
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
the United States, spending 2 years as an assistant professor of political 
science at the University of California at Berkeley. In 1966, he joined the 
faculty of the University of Chicago Law School, and between 1979 and 

1987 served as its dean. In 1989, Mr. Casper was appointed provost of 

the University of Chicago. He served as president of Stanford University 

from 1992 to 2000. Mr. Casper has written and taught primarily in the 

˜elds of constitutional law, constitutional history, comparative law, and 

jurisprudence. From 1977 to 1991, he was an editor of the 
Supreme Court 
Re
view
. His books include a monograph on legal realism (Berlin, 1967), 
an empirical study of the Supreme Court™s workload (Chicago, 1976, with 

Richard A. Posner), and 
Separating Power
 (Cambridge, Mass., 1997), con
-cerning the separation of powers practices at the end of the 18th century 

in the United States. About the Stanford presidency, he wrote 
Cares of 
the Uni
versity
 (Stanford, 1997). He is also the author of numerous schol
-arly articles and occasional pieces. He has been elected to the American 

Law Institute (1977), the International Academy of Comparative Law, the 

American Academy of Arts and Sciences (1980), the Ordre pour le mérite 

for Sciences and the Arts (1993), and the American Philosophical Society 

(1996). At present, Mr. Casper serves as a member of the board of trust
-ees of the Central European University in Budapest as well as a member 

of the board of trustees of the American Academy in Berlin. He is also a 

member other boards, including the Council of the American Law Insti
-tute and the Committee for Economic Development. From 1998 to 2005, 

he was a member of the Trilateral Commission and, from 2000 to 2008, he 

served as a successor trustee of Yale University.
David D. Clark
, NAE, has worked at the Massachusetts Institute of 
Technology™s (MIT™s) Computer Science and Arti˜cial Intelligence Labo
-ratory, where he is currently a senior research scientist in charge of the 

Advanced Network Architecture Group, since receiving his Ph.D. from 

MIT in 1973. Dr. Clark™s research interests include networks, network pro
-tocols, operating systems, distributed systems, and computer and com
-munications security. After receiving his Ph.D., he worked on the early 

stages of the ARPANET and on the development of token ring local area 

network technology. Since the mid-1970s, Dr. Clark has been involved 

in the development of the Internet. From 1981 to 1989, he acted as chief 

protocol architect in this development and chaired the Internet Activi
-ties Board. His current research looks at rede˜nition of the architectural 

underpinnings of the Internet, and the relation of technology and archi
-tecture to economic, societal, and policy considerations. He is helping 

the U.S. National Science Foundation organize its Future Internet Design 

program. In the security area, Dr. Clark participated in the early develop
-ment of the multilevel secure Multics operating system. He developed 

an information security model that stresses integrity of data rather than 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX A
 341disclosure control. Dr. Clark is a fellow of the Association for Computing 
Machinery and the IEEE and is a member of the National Academy of 
Engineering. He received the ACM SIGCOMM award and the IEEE award 

in international communications, as well as the IEEE Hamming Award 

for his work on the Internet. He is a consultant to a number of companies 

and has served on a number of technical advisory boards. Dr. Clark was 

the past chair of the Computer Science and Telecommunications Board 

(CSTB) at the National Research Council. He chaired the committee that 

produced the CSTB report 
Computers at Risk: Safe Computing in the Infor
-mation Age
. Dr. Clark also served on the committees that produced the 
CSTB reports 
Toward a National Research Network
, 
Realizing the Information 
Future: The Internet and 
Beyond, and 
The Unpredictable Certainty: Information 
Infrastructure Through 
2000
. Dr. Clark graduated from Swarthmore College 
in 1966 and received a Ph.D. from MIT in 1973.
Richard L. Garwin
, NAS/NAE/IOM, is an IBM fellow emeritus at 
the Thomas J. Watson Research Center and an adjunct professor of physics 

at Columbia University. Dr. Garwin is a physicist with expertise in intel
-ligence and in nuclear, chemical, and biological weapons and defenses. 

From 1994 to 2001 he chaired the Arms Control and Nonproliferation 

Advisory Board at the Department of State. Dr. Garwin received the 

Enrico Fermi Award of the President and the Department of Energy (1996) 

and the R.V. Jones Intelligence Award of the U.S. government intelligence 

community (1996). In 2003 he received the National Medal of Science and 

in 2000 was named by the National Reconnaissance Of˜ce as one of its 

10 founders of national reconnaissance. Dr. Garwin™s publications include 

Megawatts and Megatons: The Future of Nuclear Power and Nuclear Weap
-ons
 (2003); 
Megawatts and Megatons: A Turning Point for the Nuclear Age?
 (2001); 
Control of Nuclear Arms at Crossroads
 (2000); 
A Defense That Will Not 
Defend
 (2000); 
Boost-Phase Intercept: A 
Better Alternati
ve (2000); 
Feux Follets 
et Champignons Nucléaires
 (1997); and 
Management and Disposition of Excess 
Weapons Plutonium
 (1994). Dr. Garwin has a Ph.D. and an M.S. in physics 
from the University of Chicago (1949, 1948) and a B.S. in physics from 

Case Western Reserve University (1947). He has never been a member of 

any private boards. Many of his papers and much testimony is posted at 

http://www.fas.org/RLG/.
Jack L. Goldsmith III
 has been a professor of law at Harvard Law 
School since 2004. In 2003-2004 he was the assistant attorney general in the 

U.S. Department of Justice™s Of˜ce of Legal Counsel. At that time he was 

also a professor of law at the University of Virginia Law School. Before 

that he served on the faculty of the University of Chicago Law School and 

as special counsel to the General Counsel in the Department of Defense. 

Earlier Mr. Goldsmith was an associate professor at the University of 

Virginia Law School from 1994 to 1997. Mr. Goldsmith received a B.A. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.342 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
in philosophy summa cum laude from Washington and Lee University 
in 1984, a B.A. in philosophy, politics, and economics from Oxford Uni
-versity in 1986, a J.D. from Yale Law School in 1989, and a diploma in 
private international law from The Hague Academy of International Law 

in 1992. After law school he clerked for Judge J. Harvie Wilkinson of the 

United States Court of Appeals for the Fourth Circuit, Justice Anthony M. 

Kennedy of the Supreme Court of the United States, and Judge George A. 

Aldrich of the Iran-U.S. Claims Tribunal. He also previously has served as 

an associate at Covington & Burling. Mr. Goldsmith™s scholarly interests 

include international law, foreign relations law, national security law, 

con˚ict of laws, and civil procedure.
Carl G. O™Berry
 is with the Boeing Company, where he is vice presi
-dent of Network-Centric Architectures. He retired from the U.S. Air Force 

as a lieutenant general in August 1995. Until December 1998 he was vice 

president and director of planning and information technology for the 

Space and Systems Technology Group at Motorola, where he was respon
-sible for groupwide strategic and long-range planning and executive 

management of group information technology solutions and services. 

In addition, he was responsible for information technology architectures 

and road maps, new information technology business development, and 

leadership of information technology innovation and process reengineer
-ing. He was previously deputy chief of staff for Command, Control, Com
-munications and Computers at U.S. Air Force headquarters, a position 

from which he directed Air Force-wide information systems planning 

and policy development. Earlier in his Air Force career, he served as 

commander of the Air Force Rome Air Development Center and as joint 

program manager of the World-Wide Military Command and Control 

System Information System. He also led the development and ˜eld testing 

of an airborne radar sensing/tracking system that was the forerunner of 

the Joint Surveillance and Target Attack Radar System. He has a master™s 

degree in systems management from the Air Force Institute of Technology 

and a bachelor™s degree in electrical engineering from New Mexico State 

University. He served on the NRC committee that produced 
Realizing the 
Potential of C4I: Fundamental Challenges
.Jerome H. Saltzer
, NAE, is a professor of computer science, emeritus, 
in the Department of Electrical Engineering and Computer Science at MIT. 

A member of that department since 1961, he helped formulate the original 

undergraduate curriculum in computer science and led the development 

of the core subject on the engineering of computer systems. At the MIT 

Computer Science and Arti˜cial Intelligence Laboratory he designed one 

of the earliest widely used word-processing systems; he participated in 

the development of the Multics system, for which he designed the kernel 

thread package and with students and colleagues developed the security 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX A
 343mechanisms and what would today be known as a microkernel; and 
together with David Clark and David Reed, he articulated the end-to-end 
argument, a key organizing principle of the Internet. He was also involved 

in the design of a token-passing ring local area network, the networking of 

personal computers, the Kerberos single-login authentication system, and 
digital library systems. Dr. Saltzer was technical director of MIT
 Project 
Athena, a system for undergraduate education and an early example of 

a system organization now called ﬁcloud computing.ﬂ Throughout his 

work, he has had a particular interest in the impact of computer systems 

on privacy and the risks of depending on fragile technology. Dr. Saltzer 

is a fellow of the IEEE and the AAAS; a member of the Association for 

Computing Machinery, the ACM Committee on Computers and Public 

Policy, and the Catalog Raisonné Scholars Association; a former member 

of the Computer Science and Telecommunications Board of the National 

Research Council; and a former member of the mayor™s Telecommunica
-tions Advisory Board for the City of Newton, Massachusetts. Dr. Saltzer 

received an S.B. (1961), an S.M. (1963), and an Sc.D. (1966), from MIT, all 

in the ˜eld of electrical engineering.
Mark Seiden
 is a consultant with MSB Associates. Previously he was 
a senior consultant with Cutter™s Business-IT Strategies Practice and a 

member of the Leadership Group of the Cutter Consortium™s Risk Man
-agement Intelligence Network. He has consulted since 1983 in the areas 

of security, network, and software engineering to companies worldwide, 

with clients including start-ups, major computer and communication 

companies, ˜nancial institutions, law ˜rms, UN agencies, online con
-tent providers, ISPs, research organizations, and non-pro˜ts. As an inde
-pendent consultant and in varying roles at Securify (also known as the 

Kroll O™Gara Information Security Group), his most recent projects have 

included design, architecture, and implementation for e-business systems; 

security for online ˜nancial transaction processing and distributed docu
-ment-processing systems; custom ˜rewalls based on open-source compo
-nents; ˜nding computer criminals; and penetration testing the network 

and physical security of deployed systems, enterprises, and collocation 

facilities. Mr. Seiden has 35 years™ programming experience. He has been 

a Unix and mainframe system programmer; written Macintosh applica
-tions; spent time at IBM Research, Xerox Parc, Bell Labs, and Bellcore; 

and has taught at the university level. Mr. Seiden has been on the board 

of directors of two user groups and is on the Technical Advisory Board of 

Counterpane Security Systems. Mr. Seiden has an M.S. in computer sci
-ence/electrical engineering from Columbia University and as an under
-graduate at Columbia studied math, music, and linguistics.
Sarah Sewall
 is the director of the Carr Center at the John F.
 Kennedy 
School of Government at Harvard University and lecturer in public policy, 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.344
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
and she also directs the Carr Center™s Program on National Security and 
Human Rights. During the Clinton administration, Ms. Sewall served in 
the Department of Defense as the ˜rst deputy assistant secretary for Peace
-keeping and Humanitarian Assistance. From 1987 to 1993, she served as 

senior foreign policy adviser to Senate Majority Leader George J. Mitchell, 

was a delegate to the Senate Arms Control Observer Group, and was on 

the Senate Democratic Policy Committee. Ms. Sewall has also worked at 

a variety of defense research organizations and as associate director of the 

Committee on International Security Studies at the American Academy of 

Arts and Sciences. She was lead editor of 
The United States and the Interna
-tional Criminal Court: National Security and International Law
 (2000) and has 
written widely on U.S. foreign policy, multilateralism, peace operations, 

and military intervention. Her current research focuses on the civilian in 

war and includes facilitating a dialogue between the military and human 

rights communities on the use of force.
Walter B. Slocombe
 practices in Caplin & Drysdale™s of˜ce in Wash
-ington, D.C. He served as undersecretary of defense for policy from 1994 

to 2001, and as senior advisor for national defense in the Coalition Provi
-sional Authority for Iraq in 2003. In 2004, President Bush appointed him 

to the Commission on the Intelligence Capabilities of the United States 

Regarding Weapons of Mass Destruction. He served on the National 

Security Council staff in 1969-1970, and as principal deputy assistant 

secretary of defense for international security affairs in 1977-1979 and 

deputy undersecretary for policy in 1979-1981. He has also been a member 

of various advisory or governing boards of several academic and defense 

analysis institutions and government agencies, including a panel of the 

National Security Agency™s advisory board. Mr. Slocombe was awarded 

the Department of Defense™s Distinguished Public Service Medal (1981, 

1995, 1997, 2001, 2004) and its Joseph Kruzel Award for Distinguished 

Service in the Pursuit of Peace (2000) and has been named an honorary 

submariner by the Fleet Submarine Force. His international service has 

been recognized by awards from the Polish, German, and Korean govern
-ments. Mr. Slocombe has published numerous articles and monographs 

on tax law issues and on defense policy and organization. He is a 1963 

graduate of Princeton University, attended Balliol College Oxford as a 

Rhodes Scholar, and in 1968 received his law degree from Harvard Law 

School where he was note editor of the 
Law Re
view
. William O. Studeman 
retired from the U.S. Navy in 1995 with the 
rank of admiral. A top-level military manager and government leader, 

his ˚ag positions included director of the Navy Long-Range Planning 

Group and executive secretary of the Advanced Technology Panel of 

the CNO Executive Board, director of naval intelligence, and director of 

the National Security Agency. In 1992, President Bush nominated him to 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX A
 345the political position of deputy director of Central Intelligence. Between 
1992 and 1995, Mr. Studeman served as deputy to Robert Gates, James 
Woolsey, and John Deutch and served twice for extended periods as the 

acting director of Central Intelligence. In this capacity, he was the intel
-ligence community™s representative to the President™s Management Coun
-cil and responsible for implementing the National Performance Review 

for downsizing, streamlining, and reengineering the federal government. 

He has conducted extensive operational intelligence tours overseas. Some 

of his key tours included duty as executive assistant to both the director of 

naval intelligence and the vice chief of naval operations; of˜cer in charge 

of the Atlantic Fleet Ocean Surveillance Information Center; commanding 

of˜cer of the Navy Operational Intelligence Center, and assistant chief of 

staff for intelligence, U.S. Sixth Fleet staff at Gaeta, Italy. In addition to 

his management and ISR experience, he has extensive background in anti
-submarine warfare, C4ISR, information warfare, and homeland security. 

In 2005, he retired from Northrop Grumman Mission Systems, where he 

was sector vice president and deputy general manager for intelligence 

and information superiority, and where he also coordinated the sector™s 

homeland security activities and technology partnerships. Before joining 

TRW (which was acquired by Northrop Grumman in December 2002) in 

September 1996, Mr. Studeman worked for a year consulting on defense, 

intelligence, information infrastructure, security, and management issues, 

following 34 years of career military service. He is a distinguished gradu
-ate of the Defense Intelligence School, the Naval War College, and the 

National War College. He received a bachelor™s degree in history from 

the University of the South, a master™s degree in public and interna
-tional affairs from George Washington University, and numerous honor
-ary degrees. Mr. Studeman also serves on numerous government boards, 

including the Defense Science Board and the Presidential Commission 

on WMD.
Michael A. Vatis
 is a partner in the New York of˜ce of Steptoe & 
Johnson LLP. His practice focuses on the Internet, e-commerce, and tech
-nology matters, with special emphasis on issues involving security, intel
-ligence, and law enforcement. He also is an experienced appellate litiga
-tor. Mr. Vatis has spent most of his career addressing cutting-edge issues 

at the intersection of law, policy, and technology. He was the founding 

director of the National Infrastructure Protection Center at the FBI, the 

˜rst government organization responsible for detecting, warning of, and 

responding to cyberattacks, including computer crimes, cyberterrorism, 

cyber-espionage, and information warfare. Before that, Mr. Vatis served 

as associate deputy attorney general and deputy director of the Execu
-tive Of˜ce for National Security in the Department of Justice, where he 

advised the attorney general and deputy attorney general and coordi
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.346 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
nated the department™s activities involving counterterrorism, intelligence, 
and cybercrime. In that capacity, he also helped lead the development of 
the nation™s ˜rst policies on critical infrastructure protection. Mr. Vatis 

served as special counsel at the Department of Defense, where he handled 

sensitive legal and policy issues for the secretary and deputy secretary 

of defense and the general counsel, receiving the Secretary of Defense 

Award for Excellence. After leaving the government in 2001, Mr. Vatis 
served as the ˜rst director of the Institute for Security Technology
 Studies 
at Dartmouth, a federally funded counterterrorism and cybersecurity 

research institute. He was simultaneously the founding chairman of the 

Institute for Information Infrastructure Protection (I3P). I3P, a consortium 

of leading cybersecurity research organizations, worked with industry, 

government, and academia to develop a comprehensive research and 

development agenda to improve the security of the nation™s computer 

and communications networks. Mr. Vatis also served as the executive 

director of the Markle Task Force on National Security in the Informa
-tion Age, a highly in˚uential group of technology company executives, 

former government of˜cials, and civil libertarians that examined how 

the government could more effectively use information and technology 

to combat terrorism while preserving civil liberties. He was the princi
-pal author of the group™s second report, whose recommendations were 

adopted by the 9/11 Commission and included in the 2004 Intelligence 

Reform Act. Mr. Vatis has regularly testi˜ed before congressional commit
-tees on counte
rterrorism, intelligence, and cybersecurity issues. He is also 
interviewed on television, radio, and in print media and has been a guest 

lecturer at many prestigious law schools and universities and a frequent 

speaker at industry conferences worldwide.
STAFF MEMBERS
Herbert S. Lin
, the study director, is chief scientist for the National 
Research Council™s Computer Science and Telecommunications Board, 

where he has been a study director for major projects on public pol
-icy and information technology. These studies include a 1996 study on 

national cryptography policy (
Cryptography™s Role in Securing the Informa
-tion
 Society
), a 1991 study on the future of computer science (
Computing the 
Future
), a 1999 study of Defense Department systems for command, con
-trol, communications, computing, and intelligence (
Realizing the Potential 
of C4I: Fundamental Challenges
), a 2000 study on workforce issues in high 
technology (
Building a Workforce for the Information Economy
), a 2002 study 
on protecting kids from Internet pornography and sexual exploitation 

(Youth, Pornography, and the Internet
), a 2004 study on aspects of the FBI™s 
information technology modernization program (
A Re
view of the F
BI™s Tril
-Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX A
 347ogy IT Modernization Program
), a 2005 study on electronic voting
 (Asking 
the Right Questions About Electronic Voting
), a 2005 study on computational 
biology (
Catalyzing Inquiry at the Interface of Computing and 
Biology
), a 
2007 study on privacy and information technology (
Engaging Pri
vacy and 
Information Technology in a Digital Age
), a 2007 study on cybersecurity 
research (
Toward a Safer and More Secure Cyberspace
), and a 2009 study on 
health care information technology (
Computational Technology for Effecti
ve Health Care
). Before his NRC service, he was a professional staff member 
and staff scientist for the House Armed Services Committee (1986-1990), 
where his portfolio included defense policy and arms control issues. He 

received his doctorate in physics from MIT. Apart from his CSTB work, 

he is published in cognitive science, science education, biophysics, and 

arms control and defense policy. He also consults on K-12 math and sci
-ence education.
Ted Schmitt
 was a consultant for the Computer Science and Tele
-communications Board of the National Research Council until 2008. He 

was involved in the CSTB projects on offensive information warfare, 
 biometrics, and wireless technology. Recently completed projects he 
worked on include a review of health IT standards efforts at the Of˜ce of 
the National Coordinator for Health IT, a comprehensive exploration of 

cybersecurity and the use of IT to enhance disaster management. Before 

joining CSTB, Mr. Schmitt was involved in the development of the digital 

media industry and played an active role in various related media stan
-dards groups. Prior to that, he served as technical director at a number 

of small technology companies in Germany, Sweden, and the United 

States. He started his career in 1984 as a software engineer for IBM, earn
-ing two patents and several technical achievement awards. Mr. Schmitt 

received an M.A. in international science and technology policy from 

George Washington University. He received a B.S. in electrical engineer
-ing in 1984 and a B.A. in German in 1997 from Purdue University, and he 

studied at the University of Hamburg, Germany.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Appendix B
Meeting Participants and 
 Other Contributors
The Committee on Offensive Information Warfare held ˜ve open 
meetings starting in June 2006. These meetings included information-
gathering sessions open to the public, as well as closed segments for 

committee deliberation. The committee heard from numerous presenters 

at these meetings, including the following. 
MEETING
 1, J
UNE
 26-27, 2006
Thomas Wing˜eld, Potomac Institute

Rod Wallace, Nortel

Steven Bellovin, Columbia University
MEETING
 2, O
CTOBER
 30-31, 2006
K.A. Taipale, Center for Advanced Studies in Science and Technology 
Policy 
Stuart Starr, Center for Technology and National Security Policy, 
National Defense University
William Howard, Independent Consultant

Linton Wells, Department of Defense 

Thomas Schelling, University of Maryland (videotaped)

LTC Eric Jensen, Of˜ce of the Judge Advocate General, U.S. Army

Lt. Gen. Bill Donahue, U.S. Air Force (retired)

Joe Dhillon, University of the Paci˜c, McGeorge School of Law
348Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX 
B 
349Neal Pollard, Georgetown University and NCTC
Admiral Elizabeth Hight, Joint Task Force on Global Network 
Operations
Jeff McMahan, Rutgers University

Father J. Bryan Hehir, Harvard University/Catholic Charities
FACT
-GATHERING
 SESSION
, J
ANUARY
 27, 2007
Forrest Hare, U.S. Air Force
MEETING
 3, F
EBRUARY
 20-21, 2007
Sam Gardiner, U.S. Air Force (retired)

James N. Miller, Jr., Hicks and Associates, Inc.

Dorothy E. Denning, Naval Postgraduate School

Dan Kuehl, National Defense University

Jeff Smith, former CIA General Counsel
FACT
-GATHERING
 SESSION
, MARCH 28, 2007
Stephen A. Cambone, former Undersecretary of Defense for Intelligence
MEETING
 4, A
PRIL
 10-11, 2007
Patrick D. Allen, General Dynamics Advanced Information Systems

David Koplow, Georgetown University 

Milo Medin, M2Z Networks

Jeffrey I. Schiller, MIT

Jim Dempsey, Center for Democracy and Technology

Richard Salgado, Yahoo!

Eugene Volokh, UCLA School of Law

Robert Weisberg, Stanford Law School 

Helen Stacy, Stanford University

Naveen Jain, Intelius
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Appendix C
Illustrative Criminal Cyberattacks 
THE
 I
NVITA
 C
ASE
In 2001, the FBI arrested two Russians, Alexey Ivanov, 21, and Vasily 
Gorshkov, 25, who were accused of breaking into dozens of sites ranging 
from Internet service providers to banks.
1 Where they found ˜nancial 
records they could steal, they stole ˜nancial records. Where they couldn™t, 

they contacted the sites saying they knew about a recent break-in and 

offered their services to remediate the problems or they threatened to 

release other information stolen from the site to damage the victim™s 

public reputation. The FBI took advantage of the solicitations for work 

to lure the two suspects to the United States on the pretext of a job inter
-view, where the interviewees were arrested. Approximately 2.3 gigabytes 

(compressed) of evidentiary data was remotely seized from the suspects™ 

server in Russia before it was taken of˚ine by others still in Russia. Both 

were convicted in separate U.S. district courts. Gorshkov was charged 

with damages in excess of $2.5 million and ordered to both serve jail time 

and pay a combined total of nearly $1.5 million in restitution. 
When analyzed, the evidenceŠlists of credit cards numbers, Perl 
scripts for manipulating e-mail and auction accounts, and other hacking 

toolsŠshowed a complex scheme involving the creation of fake anony
-mous e-mail accounts and fake eBay seller and PayPal customer accounts, 

all fueled by the stolen ˜nancial information they possessed. They would 
1 Department of Justice, ﬁRussian Computer Hacker Sentenced to Three Years in Prison,ﬂ 
2002, available at http://www.usdoj.gov/criminal/cybercrime/gorshkovSent.htm.
35
0Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX C
 351
create a fake auction item with a value less than $500 to avoid triggering 
fraud alarms. They would use other fake accounts to bid on the item, 

and they knew how to rig the bidding so they would always win (thus 

not defrauding any real bidders who might report the activity). The fake 

PayPal accounts would be used to clear the transaction, and they even 
used the fake bidder accounts to ﬁrate the seller,ﬂ in
˚ating the credibility 
of the fake accounts.
One very interesting aspect of this case is the automation of all pro
-cesses related to e-mail account creation and management, online pay
-ment account creation and management, web-based transaction process
-ing, and electronic funds transfer. Tens of thousands of stolen credit card 

numbers were carefully used in ways that limited the losses to less than a 

few hundred dollars per card. The automation allowed the group to focus 

on the intrusions, data ex˜ltration and sorting, and other aspects of their 

activity that brought in money. This was all done by a small group of per
-haps a half-dozen individuals,
2 skilled programmers who could not ˜nd 
jobs locally that paid anything near what their skills were worth. Ivanov 

was described by U.S. District Court Judge Thompson as a ﬁmanager or 

supervisor,ﬂ while Gorshkov claimed he was ﬁthe boss.ﬂ (Both statements 

could be true if there are six or more individuals involved.) They claim 

to have worked up to 16 hours per day over about 1 year
3 and to have 
generated $150,000 in 6 months. This is enough to pay the salaries of 20 

(unemployed) Russian rocket scientists at 2003 salary rates.
4THE
 I
SRAELI
 T
ROJAN
 H
ORSE
 I
NDUSTRIAL
 E
SPIONAGE
 C
ASE
In 2005, a couple were arrested in Britain on charges of creating a 
 Trojan horse key logger and installing it on systems at dozens of sites 
by way of CD-ROMs containing what was purported to be a business 
proposal.
5 This has been described as the largest industrial espionage 
case in Israeli history. The espionage activity was primarily targeted at 

competitors to the clients of three private investigation ˜rms, at a cost 
2 Philip Att˜eld, ﬁUnited States v Gorshkov Detailed Forensics and Case Study; Expert 
Witness Perspective,ﬂ in 
Proceedings of the First International Workshop on Systematic Ap
-proaches to Digital Forensic Engineering (SADFE0
5),
 2005, available at http://ieeexplore.ieee.
org/iel5/10612/33521/01592518.pdf?arnumber=1592518.
3 Art Jahnke, ﬁRussian Roulette,ﬂ 2005, available at http://www.csoonline.com/
read/010105/russian.html.
4 Stephanie Overby, ﬁBig Ideas 2003: Passages Beyond India,ﬂ 2003, available at http://
www.cio.com/article/31589/Big_Ideas_Passages_Beyond_India/1.
5 See, for example, Avi Cohen, ﬁScandal Shocks Business World,ﬂ 2005, available at 
http://www.ynetnews.com/articles/0,7340,L-3091900,00.html. See also Bob Sullivan, 
 ﬁIsrael Espionage Case Points to New Net Threat,ﬂ June 9, 2005, available at http://www.
msnbc.msn.com/id/8145520/.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.352
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
of approximately $4,000 per compromised computer. Eighteen people 
were arrested and questioned in the case; however, it was primarily just 
a couple and their 17-year-old son who were responsible for software 

production, distribution, and data collection services. It was reported that 

about a hundred pieces of computer equipment were seized by authori
-ties at the time of arrest. The espionage activity was believed to have gone 

on for a year and a half, partly because the Trojan was highly targeted. 

The suspects were identi˜ed because of a personal vendetta having to do 

with a bitter divorce trial, and not because they were detected in the acts 

of computer intrusion or data ex˜ltration from the corporate victims. 
In this case, the goal was to compromise the con˜dentiality of busi
-ness records by means of unauthorized access and data ex˜ltration from 

compromised computers. The 100 items of equipment seized by authori
-ties were probably development hosts, ˜le servers that received ex˜ltrated 

˜les, and perhaps processing hosts that would assist in sifting through the 

˜les collected by the Trojan horse malware. It is not publicly known how 

sophisticated the operation was, but the number of arrests suggests that 

a signi˜cant amount of high-level intellectual property theft had taken 

place as part of this operation.
OPERATIONS
 ﬁC
YBERSLAM
,ﬂ ﬁB
OTMASTER
 U
NDERGROUND
,ﬂ 
AND
 OTHER
 B
OTNET
 C
ASES
The computer security news media are full of stories of botnetsŠhuge 
numbers of compromised personal computers running Internet Relay 

Chat (IRC) robot programs, or ﬁbotsﬂ for short
6Šbeing used to automate 
many types of criminal activity, from delivery of spam, to theft of software 

license keys, to distributed denial-of-service (DDOS) attacks for extor
-tion or other ˜nancial gain, to click fraud. Four prominent incidents that 

received attention were these:

In one of the ˜rst cases of DDOS-for-hire, Saad ﬁJayﬂ Echouafni, the 
owner of a satellite TV equipment sales company, hired someone known 

for running large DDOS attack botnets, paying him or her $150,000 per 

year. This person, in turn, subcontracted the work to four other indi
-viduals who managed their own botnets. The purpose was to carry out 

extended DDOS attacks against Echouafni™s business competitors. Spe
-ci˜c new attack mechanisms were coded into Agobot, the bot software 

being used by several of the subcontractors, in order to defeat DDOS 
6 For a description of bots and botnets, see ﬁWhat Is a Botnet?,ﬂ available at http://
www.techfaq.com/botnet.shtml.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX C
 353
mitigation techniques employed to protect the targeted sites. The result 
was an estimated $2 million in lost revenue and cost of cleanup.
7
Jeanson James Ancheta entered a plea of guilty to taking control of 
approximately 400,000 personal computers (including computers at the 
Naval Warfare Center at China Lake and the Defense Information Systems 

Agency in Virginia) for criminal purposes, including selling access to 

DDOS botnets and performing click fraud. Ancheta maintained a series 

of servers that coordinated the bot activity, including operating private 

channels for command and control of the bots that were sold to third par
-ties wishing to use them for their own criminal purposes (e.g., denial of 

service attacks and spam transmission), as well as for supporting these 

ﬁcustomers.ﬂ He admitted to collecting more than $107,000 in advertising 

af˜liate proceeds from directing the bots on compromised computers into 

referring him and another unindicted co-conspirator to the adware sites 

(known as ﬁclick fraud.ﬂ) The income from these operations funded the 

servers and hosting costs and allowed Ancheta to purchase a new BMW 

with cash, all of which was returned as part of the plea agreement.
8
Prosecutors in the Netherlands stated publicly that they believe 
three teenage suspects, two of whom were convicted and sentenced in 

February 2007, controlled as many as 1.5 million personal computers 

worldwide using a variant of the ToxBot program. The three were accused 

of using these botnets to steal credit card numbers and other personal data 

and to blackmail online businesses.
9
In June 2007, the FBI reported an event of similar size in the United 
States, part of ﬁOperation Bot Roast,ﬂ involving over 1 million personal 

computers. Arrested were three individuals, two accused of performing 

DDOS attacks and one reported to be one of the most proli˜c spammers 

at the time.
10
 In all of these cases, small groups of relatively young people with 
skills in programming and computer system administration were able 

to successfully compromise and control over a million personal comput
-7 Department of Justice, ﬁCriminal Complaint: United States of America v. Paul G. 
 Ashley, Jonathan David Hall, Joshua James Schichtel, Richard Roby and Lee Graham 
Walker,ﬂ 2004, available at http://www.reverse.net/operationcyberslam.pdf.
8 Department of Justice, ﬁComputer Virus Broker Arrested for Selling Armies of
 Infected 
Computers to Hackers and Spammers,ﬂ 2005, available at http://www.cybercrime.gov
/anchetaArrest.htm.
9 Joris Evers, ﬁ‚Bot Herders™ May Have Controlled 1.5 million PCs,ﬂ 2005, available 
at http://news.com.com/Bot+herders+may+have+controlled+1.5+million+PCs/2100-7350 
3-5906896.html.
10 
Department of Justice, ﬁOver One Million Potential Victims of Botnet Cyber Crime,ﬂ 
2007, available at http://www.ic3.gov/media/initiatives/BotRoast.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.35
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
ers around the world, using very little additional software above and 
beyond modi˜ed versions of publicly available IRC-based botnet and IRC 
server software. These are just the proverbial tip of the iceberg in terms of 

online crime using distributed intruder tool networks, including botnets. 

A migration is beginning to take place, away from the easier to detect and 

mitigate IRC botnets and toward the use of heavily encrypted peer-to-

peer malicious programs for distributed command and control.
THE
 S
TAKKATO
 I
NTRUSIONS
In 2003, a teenager in Sweden began a series of intrusions that lasted 
through 2005 and compromised more than 1000 hosts at supercomputer 

centers, national labs, universities, corporations, and military bases around 

the world.
11
 The initial target of attack was remotely exploitable vulner
-abilities in Linux systems, where a rootkit named SucKIT was installed 

that hides itself on the system and logs all keystrokes. This allowed the 

attacker to steal account/password credentials of people logging into the 

compromised host or using that host to log in to some other host (possibly 

at another site). The attacker would sometimes replace the login message 

with a taunt about how using Linux was a great way to share accounts. 
One aspect of the Stakkato case that is not appreciated by many is the 
clever exploitation of the implicit trust relationships that exist between 

systems based on users having accounts on more than one system, and 

more than one user sharing any given system. The attacker would steal 

passwords to gain access to accounts, and then do suf˜cient mapping of 

login relationships between hosts to infer where these same login/pass
-word combinations might work. He would then log into those systems, 

preferably using administrator accounts, and then repeat the process of 

installing the keystroke logger and further extending his reach into new 

systems and networks: (1) University researchers often have appoint
-ments in multiple institutions, or multiple departments within an institu
-tion; (2) those researchers have contractual relationships with corpora
-tions in industry; (3) supercomputer centers are used by
 researchers in 
academia, in business, and in the military; (4) the same business that 

employs a researcher in one ˜eld (who may require the services of a 

supercomputer center) may also be involved in software or hardware 

engineering and sales. Stakkato probably did not even plan on it, but dur
-ing the compromise of those 1000+ systems, an account at Cisco Systems 

was compromised and was used to obtain a copy of part of the Cisco IOS 

router software base, which was later posted on a Russian website. The 
11
 Leif Nixon, ﬁThe Stakkato Intrusions,ﬂ 2006, available at http://www.nsc.liu.se/
nixon/stakkato.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX C
 355
nature of the login trust relationships between sites was one reason the 
intrusions lasted so long: Some sites would clean up their systems, only 
to ˜nd them compromised again a short time later because they did not 

realize the extent of shared access between systems, nor did they realize 

what the compromise of passwords through keystroke logging means in 

terms of completely mitigating an attack of this nature.
TJX F
INANCIAL
 D
ATA
 T
HEFTS
At various dates between July 2005 and January 2006, intruders used 
access to systems within the corporate network of TJX Companies, Inc., to 

obtain and ex˜ltrate 45.7 million payment card (i.e., credit or debit card) 

records.
12
In March 2007, six suspects were arrested, with four more at large, 
all believed to be involved in the data theft and an elaborate scheme for 

using the stolen data to make an estimated $8 million in purchases of 

gift cards and electronics equipment.
13
 This is on par with the number 
of individuals involved in the Invita case, the ˜rst case in this appendix. 

However the ˜nancial damage involved in the TJX case could be orders 

of magnitude greater than the losses in the Invita case just 5 years earlier. 

Based on estimates of $50 to $250 per record, the TJX breach could cost the 

company in excess of $2 billion. Several pending lawsuits and a regula
-tory investigation are also underway. 
As of the time of this writing, few details about the attack mechanism 
have been made public, but it would be reasonable to assume an attack 

methodology similar to that in the previous cases. Since the attackers were 

in the networks for over a year, there was a great deal of time available to 

quietly exploit stolen credentials and explore the network, identifying the 

crown jewels in terms of ˜nancial information databases.
12
 The SEC Form 10-K ˜ling by TJX claims that, in general, track 2 dataŠall data, in
-cluding the PIN number on debit cards, necessary to clone the cardŠwas either masked off 
with asterisks or stored in encrypted form. TJX does, however, state that, ﬁdespite our mask
-ing and encryption practices on our Framingham system in 2006, the technology utilized 

in the Computer Intrusion during 2006 could have enabled the Intruder to steal payment 

card data from our Framingham system during the payment card issuers™ approval process, 

in which data (including the track 2 data) is transmitted to payment card issuers without 

encryption. Further, we believe that the Intruder had access to the decryption tool for the 

encryption software utilized by TJX.ﬂ This means there is a possibility that payment cards 

could be cloned by the attackers.
13
 Jenn Abelson, ﬁBreach of Data at TJX Is Called the Biggest Ever: Stolen Numbers Put 
at 45.7 Million,ﬂ March 29, 2007, available at http://www.boston.com/business/globe
/articles/2007/03/29/breach_of_data_at_tjx_is_called_the_biggest_ever/.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Appendix D
Views on the Use of 
 Force in Cyberspace
COMPUTER
 N
ETWORK
 A
TTACK
 AND
 THE
 U
SE
 OF
  FORCE
 IN
 I
NTERNATIONAL
 L
AW
In 1999, Michael Schmitt addressed the issue of cyberattack as a use 
of force.
1 Focusing on computer network attack (CNA) (remote-access 
attack, as described in Chapter 2), Schmitt argued that CNA should be 
understood in terms of its effects and said that the consequences of a 

CNA rather than its speci˜c modality were the most important factor in 

its categorization. He focused on the consequences of a CNA because of 

their potentially broad range: ﬁCNA spans the spectrum of consequential
-ity. Its effects freely range from mere inconvenience (e.g., shutting down 

an academic network temporarily) to physical destruction (e.g., as in 

creating a hammering phenomenon in oil pipelines so as to cause them 

to burst) to death (e.g., shutting down power to a hospital with no back-

up generators).ﬂ 
Thus, for example, Schmitt argued that ﬁCNA speci˜cally intended to 
directly cause physical damage to tangible property or injury or death to 

human beings is reasonably characterized as a use of armed force,ﬂ and so 

ﬁpipeline destruction and the shutting of power to the hospital are exam
-ples of CNA which the actor knows can, and intends to, directly cause 

destruction and serious injury.ﬂ He further noted that ﬁarmed coercion 
1 Michael Schmitt, ﬁComputer Network Attack and the Use of Force in International 
Law: Thoughts on a Normative Framework,ﬂ 
Columbia Journal of Transnational Law 
37:885-
937, 1999.
356
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX D
 357
is not de˜ned by whether or not kinetic energy is employed or released, 
but rather by the nature of the direct results caused, speci˜cally physical 

damage and human injury.ﬂ
On the other hand, Schmitt noted that economic coercion is not gener
-ally regarded as rising to the level of a ﬁuse of force,ﬂ so that a CNA that 

seeks economic coercion cannot be considered a use of force. For a CNA to 

be considered a use of force, he argued that it must be more consequential 

than simple economic coercion but does not necessarily have to meet the 

threshold of being considered a use of ﬁarmed forceﬂ as described in the 

previous paragraph. He thus argues that ﬁthe use of force line must lie 

somewhere between economic coercion and the use of armed force.ﬂ
Schmitt then offered a seven-element framework for categorizing 
computer network attack as a use of force:
Ł Se
verity
. If people are killed or there is extensive property damage, 
the action is probably military; the less damage, the less likely the action 

is a use of force.
Ł Immediacy
. When the effects are seen within seconds to minutesŠ
such as when a bomb explodesŠthe operation is probably military; if the 

effects take weeks or months to appear, it is more likely diplomatic or 

economic.
Ł Directness
. If the action taken is the sole cause of the result, it is 
more likely to be viewed as a use of force; as the link between cause and 

effect attenuates, so does the military nature of the act.
Ł In
vasi
veness
. A violated border is still an indicator of military opera
-tions; actions that are mounted from outside a target nation™s borders are 

probably more diplomatic or economic.
Ł Measurability
. If the effect can be quanti˜ed immediatelyŠsuch as 
photographing a ﬁsmoking holeﬂ where the target used to beŠthe opera
-tion has a strong military character; the more subjective the process for 

evaluating the damage, the more diplomatic or economic.
Ł Presumpti
ve legitimacy
. State actors have a monopoly on the legiti
-mate use of kinetic force, while other non-kinetic actionsŠattacks through 

or in cyberspaceŠare often permissible in a wider set of circumstances; 

actions that have not been the sole province of nation-states are less likely 

to be viewed as military.
Ł Responsibility
. If a state takes visible responsibility for any destruc
-tive act, it is more likely to be characterized as a traditional military opera
-tion; ambiguous responsibility militates for a non-military label.
Schmitt provided two examples, each presumably premised on a state 
of non-hostilities existing prior to a computer network attack. In the ˜rst 

example, he posited computer network attacks that disable an air traf˜c 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.358
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
control (ATC) system during bad weather, resulting in the crash of an 
airliner and many civilian deaths. Although no kinetic force was used 
to destroy the airliner, CNA was the cause of the tragedy, as the airliner 

would have been likely to survive bad weather with a functional ATC 

system. The consequences are both severe and manifestly obvious, and 

the action (the CNA) and desired result (the airliner crash) were tempo
-rally proximate. For these reasons, this CNA can be regarded as the use 

of force.
In the second example, he posited a CNA on a university computer 
network designed to disrupt military-related research in campus lab
-oratories. In this attack, no physical damage or suffering occurs, and 

the desired outcomeŠdiminished capability on the battle˜eldŠis both 

remote from the act and also depends on many other factors (e.g., the 

ability of researchers to regenerate data, the possible existence of other 

similar research efforts, and so on). In this instance, the CNA should not 

be regarded as the use of force.
NEW
 T
OOLS
, N
EW
 R
ULES
: I
NTERNATIONAL
 L
AW
 AND
 INFORMATION
 O
PERATIONS
Another more recent analysis by Duncan Hollis argued against extend
-ing traditional laws of armed con˚ict (LOAC) to apply to cyberattack and 

other information operations.
2 Though Hollis accepts the fundamental 
underlying rationale and intent of traditional LOAC (e.g., to minimize 

human suffering, to support reciprocity between states, to prevent mor
-ally reprehensible behavior), he argued that the interpretation of tradi
-tional LOAC vis-à-vis cyberattack suffers from two major problems.
First, Hollis argued that even in the context of state-on-state warfare, 
extension of the traditional LOAC suffers from serious ﬁtranslationﬂ prob
-lems about how these laws apply to cyberattack. For example, a cyberat
-tack on a stock exchange might cause considerable economic damage but 

may not cause immediate death or destructionŠshould such an attack 

count as a use of force? In addition, preserving the distinction between 

civilian entities and valid military targets is extraordinarily dif˜cult when 

cyberattack is concerned. He made the further point that Article 41 of the 

UN Charter de˜nes ﬁmeasures not involving the use of armed forceﬂ to 

include ﬁcomplete or partial interruption of . . . telegraphic, radio, and 

other means of communication.ﬂ (Note, of course, that the UN Charter 

was rati˜ed in 1945, long before the Internet and modern information 
2 Duncan B. Hollis, ﬁNew Tools, New Rules: International Law and Information Opera
-tions,ﬂ pp. 59-72 in 
Ideas As Weapons: In˜uence and Perception in Modern Warfare, 
G. David and 
T. McKeldin, eds.,
 Potomac Books, Inc.,
 2009.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX D
 359
technologies were contemplated and before it could be imagined that the 
medium of an attack on a nation might well be an altogether new and 
different medium.)
Second, he argued that in focusing primarily on state-on-state con
-˚ict, traditional LOAC ignores many of the most important issues that 

arise in today™s security environmentŠthe issue of states acting against 

non-state actors and subnational entities. Hollis points out that the legal 

regimes governing such con˚ict are already in a state of ˚ux (e.g., there 

is no doctrine comparable to the ﬁuse of forceﬂ or the self-defense provi
-sions of the UN Charter). And when cyberattacks may be launched by 

non-state actors from the territories of nation-states, the relevant legal 

regime is even murkier.
For example, in the absence of state sponsorship, a cyberattackŠeven 
a very destructive one, conducted by a terrorist or criminal organizationŠ

does not qualify as an armed attack. A self-defense response is thus not 

sanctioned under the UN Charter. Even if the origin of the cyberattack 

can be traced to a speci˜c state, a military or law enforcement response 

against an entity within that state cannot be undertaken unilaterally with
-out violating that state™s sovereignty. Only if the state in question is 

unable or unwilling to stop the cyberattack may the attacked state take 

countermeasures on its own.
Hollis concluded from his analysis that the translation dif˜culties and 
the insuf˜ciency of traditional LOAC with respect to subnational actors 

call for a new legal framework for governing cyberattack and other infor
-mation operations.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.Appendix E
Technical Vulnerabilities Targeted by 
Cyber Offensive Actions
The discussion in this appendix is based largely though not entirely 
on an earlier National Research Council report on cybersecurity describ
-ing vulnerabilities in the information technology on which the United 
States relies.
1 However, there is no reason to suppose and no evidence 
available that suggests that other nations (or other non-national parties) 

are systematically better than the United States in eliminating vulnerabili
-ties from the information technology that they use.
SOFTWARE
Software constitutes the most obvious set of vulnerabilities that an 
attacker might exploit. In a running operating system or application, 

vulnerabilities may be present as the result of faulty program design or 

implementation, and the exploitation of such vulnerabilities may become 

possible when the targeted system comes into contact with a hostile 

trigger (either remotely or close up). For example, a pre-implanted vul
-nerability in a program may be triggered at a particular time, or when a 

particular input is received.
When vendors ˜nd vulnerabilities, they usually issue patches to ˜x 
them. But the issuance of a patch sometimes increases the threat to those 

who do not install itŠwhen a patch is widely disseminated, it also serves 
1 National Research Council, 
Toward a Safer and More Secure Cyberspace
, The National 
Academies Press, Washington, D.C., 2007.
36
0Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX E
 361
to notify a broad range of would-be attackers that a speci˜c vulnerability 
exists. And if the patch is not installed, a broader range of attackers is 

likely to have knowledge of the vulnerability than if the patch had not 

been distributed at all. And patches are not always installed when the 

vendor issues them because patch installation will from time to time 

damage existing functionality on a system (e.g., causing a critical appli
-cation to stop working until it can be made compatible with the patch to 

be installed).
As a rule, vulnerabilities resulting from design errors or insecure 
design choices are harder to ˜x than those resulting from implementation 

errors. Perhaps still more dif˜cult are vulnerabilities introduced by unin
-tended functionality (the euphemism for adding a function to software 

that helps an attacker but that is not desired by the authorized user or 

developer)Šthe classic ﬁback-doorﬂ vulnerability.
2 Most system evalua
-tion checks the extent to which a product meets the formal requirements, 

and not whether it does 
more than
 intended. Whereas vulnerabilities due 
to faulty design and implementation may be uncovered during the testing 

process or exposed during system operation and then ˜xed, vulnerabili
-ties associated with unintended functionality may go undetected because 

the problem is tantamount to proving a negative.
Today, applications and operating systems are made up of millions of 
lines of code, not all of which can possibly be audited for every changed 

line of source code. A widely used program might have vulnerabilities 

deliberately introduced into it by a ﬁrogueﬂ programmer employed by the 

software vendor but planted by the attacker. (One of the most plausible 

vectors for the surreptitious introduction of hostile code is a third-party 

device driver. In some operating systems, drivers almost always require 

the calling system to delegate to them privileges higher than those granted 
2 As an example of a back door that is harmless, most versions of Microsoft Word from 
Word 97 to Word 2003 contain some unexpected functionalityŠtyping ﬁ=rand()ﬂ in a Word 
document and then pressing the ENTER key results in three paragraphs of ˜ve repetitions 

of the sentence ﬁThe quick brown fox jumps over the lazy dog.ﬂ This particular back door 

is harmless and is even documented by Microsoft (see ﬁHow to Insert Sample Text into a 

Document in Word,ﬂ available at http://support.microsoft.com/kb/212251). Such function
-ality could easily not be documented, and could easily be harmful functionality as well. For 

example, a security interface to a computer might be designed to require the user to enter a 

password and to insert a physical ﬁsmart cardﬂ into a slot before granting her access. But the 

interface could easily be programmed to ignore the smart-card requirement when a special 

password is entered, and then to grant the user many more privileges than would be normal. 

On the other hand, the in-advance installation of a back-door vulnerability always runs a 

risk of premature exposureŠthat is, it may be discovered and ˜xed before the attacker can 

use it. Even worse from the attacker™s standpoint, it may be ˜xed in such a way that the at
-tacked system appears vulnerable but is in fact not vulnerable to that particular attack. Thus, 

the attacker may attack and believe he was successful, even though he was not.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.362
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
to ordinary usersŠprivileges that allow the code within drivers to bypass 
operating system protections.) To ensure that such vulnerabilities are not 
introduced, vendors take many steps such as multiple code reviews dur
-ing the software development process. 
But source code does not always reveal the entire functionality of a 
system. For example, compilers are used to generate object code from 

source code. The compiler itself must be secure, for it could introduce 

object code that subversively and subtly modi˜es the functionality repre
-sented in the source code.
3 Moreover, maliciously constructed code intentionally introduced to 
implant vulnerabilities in a system for later exploitation is typically more 

dif˜cult to detect than are vulnerabilities that arise in the normal course of 

software development.
4 Attackers highly skilled in the art of obfuscating 
malicious code can make ˜nding intentionally introduced vulnerabilities 

a much harder problem than ˜nding accidental ˚aws. Finding such vul
-nerabilities requires tools and skills far beyond those typically employed 

during system testing and evaluation aimed at discovering accidentally 

introduced defects. The discovery process requires detailed analysis by 

human experts, making it extremely expensive. Indeed, it is rarely done 

except for systems in which reliability and security are paramount (e.g., 

nuclear command and control systems).
The introduction of deliberate vulnerabilities into software is facil
-itated by the economic imperatives of software development and the 

opaqueness of the software development supply chain. Today, develop
-ing custom software for every application is impractical in terms of both 

cost and time. Custom software developed for a single purpose must be 

paid for entirely by the party for which it is developed, and thus software 

producers often seek to reduce costs by using commercial off-the-shelf 

(COTS) software and/or outsourcing their software development when
-ever possible (e.g., using commercial operating or database systems), even 

if critical systems are involved.
5 In practice, systems are composed of 
components designed and implemented by many vendors. These vendors 

in turn often subcontract major components, and those subcontractors 
3 A famous paper by Ken Thompson in 1984 described how to hide malicious bi
-nary code in a way that cannot be detected by examining the source program. See Ken 
L. Thompson, ﬁRe˚ections on Trusting Trust,ﬂ 
Communications of the ACM
 27(8):761-763, 
August 1984.
4 Defense Science Board, ﬁReport of the Defense Science Board Task Force on Mission 
Impact of Foreign In˚uence on DoD Software,ﬂ U.S. Department of Defense, September 

2007, pp. 40-41. 
5 Defense Science Board, ﬁReport of the Defense Science Board Task Force on Mission 
Impact of Foreign In˚uence on DoD Software,ﬂ U.S. Department of Defense, September 

2007, p. vi.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX E
 363
may in turn subcontract portions of their work. Because the spread of the 
Internet and high-speed communications capabilities such as broadband 
˜ber optics worldwide has made global development of software not 

only possible, but also desirable for cheaply tapping the broadest range 

of talent,
6 these subcontractors are often located in nations where labor is 
relatively inexpensive. The provenance of each component or subcompo
-nent can only be completely known if mechanisms are in place to track 

each contributor, and every subcontractor represents an opportunity to 

introduce vulnerabilities secretly. 
The use of open source software is often advocated as a solution to 
the security problem described above (advocates assert that the many 

eyes of the open source community focused on software would make it 

dif˜cult or impossible to introduce deliberate ˚aws that will endure), and 

open source software is increasingly being incorporated into systems to 

save time and money in the development process as well. Open source 

software development is essentially a form of outsourced development 

except that the outsourcing is done on an ad hoc basis and even less may 

be known about the circumstances under which the code is originally 

produced than is the case with software produced under an outsourcing 

contract. Vulnerabilities could be deliberately introduced by a cyberat
-tacker, and there is no guarantee that the open source inspection process 

will uncover such vulnerabilities.
7 For example, a particular sequence of instructions and input com
-bined with a given system state could take advantage of an obscure and 

poorly known characteristic of hardware functioning, which means that 

programmers working for an attacking government and well versed in 

minute behavioral details of the machine on which their code will be 

running could introduce functionality that would likely go undetected in 

any review of it.
8As an example of how outsourcing can be used to introduce vulnera
-6 Defense Science Board, ﬁReport of the Defense Science Board Task Force on Mission 
Impact of Foreign In˚uence on DoD Software,ﬂ U.S. Department of Defense, September 
2007, p. 10.
7 Empirical results appear to suggest that open source softwareŠthough available for 
inspection by anyoneŠin practice is not often audited for security. See, for example, Hal 

Flynn, ﬁWhy Sardonix Failed,ﬂ 
SecurityFocus
, February 4, 2004, available at http://www.
securityfocus.com/columnists/218.
8 See, for example, Olin Sibert, Phillip A. Porras, and Robert Lindell, ﬁAn Analysis of 
the Intel 80x86 Security Architecture and Implementations,ﬂ 
IEEE Transactions on Software 
Engineering
, 22(5):283-293, May 1996; and Kris Kaspersky and Alice Chang, ﬁRemote Code 
Execution Through Intel CPU Bugs,ﬂ talk presented at Hack-In-The-Box, Dubai, United Arab 

Emirates, 2008, PowerPoint presentation available at http://nchovy.kr/uploads/3/303/

D2T1%20-%20Kris%20Kaspersky%20-%20Remote%20Code%20Execution%20Through%20

Intel%20CPU%20Bugs.pdf.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.36
4 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
bilities, a ˜nancial services company reportedly outsourced its application 
development to a company in the Far East. The company had been certi
-˜ed as a CMM level-5 company, meaning that it had a well-established 
and documented process for developing software. However, unknown to 

the company, it also employed a few malicious users who inserted a back 

door in the application that was sent to the ˜nancial services client. The 

client performed only a minimal security review as part of its acceptance 

testing, and so the back door went undetected. The back door consisted 

of an undocumented URL that could be accessed remotely, through which 

malicious users were able to obtain customer information such as account 

numbers, statement balances, and other information. The back door was 

discovered months after deployment after the developer™s clients com
-plained about fraudulent charges.
9A ˜nal kind of software error is sometimes called an emergent error.
10
 Emergent errors can arise when correct software is used in a situation or 

environment for which it was not originally designed and implemented. 

For example, a program may work correctly in a given context and envi
-ronment. However, if it is moved to a different computing environment, 

it may begin to work incorrectly. A software component 
Z may be certi
-˜ed as being secure, provided certain conditions are met (such as certain 

constraints on the input values being passed across its interface). It works 

correctly in environment 
A, which guarantees that the values passed are 
indeed restricted in accordance with those constraints. But if it is moved 

to environment 
B, which does not check the values passed to 
Z, the com
-ponent may fail if values are passed that are not consistent with those 

constraints.
HARDWARE
Vulnerabilities can also be found in hardware, although less attention 
is usually paid to hardware. Hardware includes microprocessors, micro
-controllers, ˜rmware, circuit boards, power supplies, peripherals such 

as printers or scanners, storage devices, and communications equipment 

such as network cards. Tampering with such components may require 

physical access at some point in the hardware™s life cycle, which includes 

access to the software and libraries of the CAD/CAM tools used to design 
9 Ed Adams, ﬁBiggest Information Security Mistakes That Organizations Make,ﬂ Se
-curity Innovation, Inc., Wilmington, Mass., available at http://www.issa.org/Downloads/
Whitepapers/Biggest-Information-Security-Mistakes_Security-Innovation.pdf.
10
 Taimur Aslam, Ivan Krsul, and Eugene H. Spafford, ﬁA Taxonomy of Security Vul
-nerabilities,ﬂ in 
Proceedings of the 
19
th National Information Systems Security Conference
, pp. 
551-560, Octobter 1996, available at http://ftp.cerias.purdue.edu/pub/papers/taimur-

aslam/aslam-krsul-spaf-taxonomy.pdf. 
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX E
 365
the circuits embedded in the hardware. On the other hand, hardware is 
dif˜cult to inspect, and so hardware compromises are hard to detect. 
Consider, for example, that peripheral devices or even other circuit cards 

within the main computer housing often have on-board processors and 

memory that can support an execution stream entirely separate from that 

running on a system™s ﬁmainﬂ processor. 
As an experiment to demonstrate the feasibility of making malicious 
modi˜cations to hardware, King et al. developed two general-purpose 

methods for designing malicious processors, and used these methods to 

implement attacks that could steal passwords, enable privilege escala
-tion, and allow automatic logins into compromised systems.
11
 Further
-more, the implementation of these attacks required only small amounts 

of modi˜cation to the baseline uncompromised processor. (For example, 

implementation of the login attack used only 1,341 additional logic gates, 

or 0.08 percent of the 1,787,958 logic gates used in the baseline; yet an 

attacker using this attack would gain complete and high-level access to 

the machine.) Embedded in larger processors involving billions of gates, 

the changes required would be even smaller (and thus more dif˜cult to 

detect) as a percentage of the circuitry involved.
An important exception to the rule that physical access is required in 
order to compromise hardware is based on the fact that many systems rely 

on a ˜eld-upgradable read-only memory (ROM) chip to support a boot 

sequence, and corrupting or compromising the boot ROMs can render a 

system entirely non-functional (as was the case in the Chernobyl virus
12
) or only selectively non-functional. To corrupt or compromise the boot 

ROM that is ˜eld-upgradable, the attacker need only masquerade as a 

legitimate user seeking to upgrade the ROM software. Another attack on 

programmable read-only memory exploits the fact that the relevant chips 

support only a limited number of write cycles. Thus, a programmable 

read-only memory chip can be destroyed by an agent that repeatedly 

rewrites its contents a suf˜cient number of times. With many of today™s 

computer system designs, corruption or destruction of a boot ROM may 

require at least several hours of manual repair to replace the ROM chip 

or some other component (such as a power supply) that may have been 

damaged by improper system operation. In addition, if this attack can be 

mounted successfully on many network routers at more or less the same 

time, it is likely to cause signi˜cant disruption in the overall network itself 
11
 Samuel T. King et al., ﬁDesigning and Implementing Malicious Hardware,ﬂ 
Proceed
-ings of the First USENIX Workshop on Large-Scale Exploits and Emergent Threats
 (LEET), April 
2008, available at http://www.usenix.org/event/leet08/tech/full_papers/king/king.pdf.
12
 The Chernobyl virus is further documented at http://www.cert.org/incident_notes/ 
IN-99-03.html.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.366
 TECHNOLOGY
, P
OLICY
, L
AW
, A
ND
 E
THICS
 O
F U.
S. C
YBERATTACK
 C
APA
BILI
TIES
and impede network repair effortsŠand so restoring the overall network 
to its normal operating condition will take a much longer time.
SEAMS
 BETWEEN
 H
ARDWARE
 AND
 S
OFTWARE
Software and hardware are typically developed independently. Yet 
from a defensive perspective, the two are inseparable.
13
 Attacks designed 
to take advantage of vulnerabilities in the way software and hardware 
interactŠalmost always at some interfaceŠmay go unnoticed because 

testing and evaluation at the seam between them are often incidental 

rather than a focused activity. 
COMMUNICATIONS
 CHANNELS
The communications channels between the system or network and 
the ﬁoutsideﬂ world are still another type of vulnerability. For a system 

to be useful it must in general communicate with the outside world, and 

the communications channels used can be compromisedŠfor example, by 

spoo˜ng (an adversary pretends to be the ﬁauthorizedﬂ system), by jam
-ming (an adversary denies access to anyone else), or by eavesdropping 
(an adversary obtains information intended to be con˜dential).
 One example of a communications channel cyberattack might involve 
seizing control of an adversary satellite by compromising its command 

channels. Satellites communicate with their ground stations through wire
-less communications, and if the command link is unencrypted or otherwise 

insecure, a Zendian satellite can be controlled by commands sent from the 

United States just as easily as by commands sent from Zendia. With access 

to the command link, adversary satellites can be turned off, redirected, or 

even directed to self-destruct by operating in unsafe modes.
CONFIGURATION
 Most information technology systemsŠespecially systems based 
on off-the-shelf commercial componentsŠcan be con˜gured in differ
-ent ways to support different user preferences. Con˜guration manage
-mentŠthe task of ensuring that a system is con˜gured in accordance 

with actual user desiresŠis often challenging and dif˜cult, and errors in 

con˜guration can result in security vulnerabilities. (Many errors are the 

result of default con˜gurations that turn off security functionality in order 
13
 Defense Science Board, ﬁReport of the Defense Science Board Task Force on Mission 
Impact of Foreign In˚uence on DoD Software,ﬂ U.S. Department of Defense, September 
2007, p. 4.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.APPENDIX E
 367
to ease the task of system setup. An example of such an error is a default 
password, such as ﬁsystemﬂ or ﬁpassword,ﬂ that is widely knownŠsuch 
a password will remain in effect until someone chooses to change it, and 

such a change may never occur simply because the need to do so is over
-looked.) Other con˜guration errors result from explicit user choices made 

to favor convenienceŠfor example, a system administrator may con˜gure 

a system to allow remote access through a dial-in modem attached to his 

desktop computer so that he can work at home, but the presence of such 

a feature can also be used by an attacker. 
Con˜guration-based vulnerabilities are in some sense highly fragile, 
because they can be ˜xed on very short notice. All it takes for a con˜gura
-tion vulnerability to be eliminated is for the operator to choose a different 

con˜guration and implement it, which is usually a less demanding task 

than ˜xing an implementation error.
Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and Use of Cyberattack CapabilitiesCopyright National Academy of Sciences. All rights reserved.