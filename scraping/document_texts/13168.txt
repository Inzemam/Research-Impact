DETAILSDistribution, posting, or copying of this PDF is strictly prohibited without written permission of the National Academies Press.  (Request Permission) Unless otherwise indicated, all materials in this PDF are copyrighted by the National Academy of Sciences.Copyright © National Academy of Sciences. All rights reserved.THE NATIONAL ACADEMIES PRESSVisit the National Academies Press at NAP.edu and login or register to get:Œ  
Œ  10% off the price of print titles
Œ  Special offers and discountsGET THIS BOOKFIND RELATED TITLESThis PDF is available at SHARECONTRIBUTORS
http://nap.edu/13168Facilitating Innovation in the Federal Statistical System:Summary of a Workshop68 pages | 6 x 9 | PAPERBACKISBN 978-0-309-21461-2 | DOI 10.17226/13168Hermann Habermann, Rapporteur; Committee on National Statistics; Division ofBehavioral and Social Sciences and Education; National Research CouncilFacilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.Hermann Habermann, 
RapporteurCommittee on National StatisticsDivision of Behavioral and Social Sciences and EducationSummary of a WorkshopFACILITATINGINNOVATION FEDERALSTATISTICALSYSTEMIN THEFacilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.NATIONAL ACADEMIES PRESS  500 Fifth Street, N.W.  Washington, D.C. 20001
NOTICE: The project that is the subject of this report was approved by the Gov
-erning Board of the National Research Council, whose members are drawn from 
the councils of the National Academy of Sciences, the National Academy of Engi
-neering, and the Institute of Medicine. The members of the committee responsible 
for the report were chosen for their special competences and with regard for 
appropriate balance.
This study was supported by a consortium of federal agencies through a grant 
from the National Science Foundation (award number SES-0453930). Any opin
-ions, ˜ndings, conclusions, or recommendations expressed in this publication are 
those of the author(s) and do not necessarily re˚ect the view of the organizations 
or agencies that provided support for this project.
International Standard Book Number-13:
 978-0-309-21461-2
International Standard Book Number-10: 
 0-309-21461-0
Additional copies of this report are available from the National Academies Press, 
500 Fifth Street, N.W., Lockbox 285, Washington, D.C. 20055; (800) 624-6242 or 
(202) 334-3313 (in the Washington metropolitan area); Internet, http://www.nap.
edu.
Copyright 2011 by the National Academy of Sciences. All rights reserved.
Printed in the United States of America
Suggested citation: National Research Council. (2011). 
Facilitating Innovation in the 
Federal Statistical System: Summary of a Workshop. 
Hermann Habermann, rappor
-teur. Committee on National Statistics, Division of Behavioral and Social Sciences 
and Education. Washington, DC: The National Academies Press.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.The National Academy of Sciences is a private, nonpro˜t, self-perpetuating 
society of distinguished scholars engaged in scienti˜c and engineering research, 
dedicated to the furtherance of science and technology and to their use for the 
general welfare. Upon the authority of the charter granted to it by the Congress 
in 1863, the Academy has a mandate that requires it to advise the federal govern
-ment on scienti˜c and technical matters. Dr. Ralph J. Cicerone is president of the 
National Academy of Sciences.
The National Academy of Engineering was established in 1964, under the charter of the National Academy of Sciences, as a parallel organization of outstanding 
engineers. It is autonomous in its administration and in the selection of its mem
-bers, sharing with the National Academy of Sciences the responsibility for advis
-ing the federal government. The National Academy of Engineering also sponsors 
engineering programs aimed at meeting national needs, encourages education 
and research, and recognizes the superior achievements of engineers. Dr. Charles 
M. Vest is president of the National Academy of Engineering.
The 
Institute of Medicine
 was established in 1970 by the National Academy of 
Sciences to secure the services of eminent members of appropriate professions 
in the examination of policy matters pertaining to the health of the public. The 
Institute acts under the responsibility given to the National Academy of Sciences 
by its congressional charter to be an adviser to the federal government and, upon 
its own initiative, to identify issues of medical care, research, and education. Dr. 
Harvey V. Fineberg is president of the Institute of Medicine.
The 
National Research Council
 was organized by the National Academy of 
Sciences in 1916 to associate the broad community of science and technology 
with the Academy™s purposes of furthering knowledge and advising the federal 
government. Functioning in accordance with general policies determined by the 
Academy, the Council has become the principal operating agency of both the 
National Academy of Sciences and the National Academy of Engineering in pro
-viding services to the government, the public, and the scienti˜c and engineering 
communities. The Council is administered jointly by both Academies and the 
Institute of Medicine. Dr. Ralph J. Cicerone and Dr. Charles M. Vest are chair and 
vice chair, respectively, of the National Research Council.
www.national-academies.org
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.vSTEERING COMMITTEE FOR THE 
 WORKSHOP ON FACILITATING INNOVATION IN THE 
 FEDERAL STATISTICAL SYSTEM
THOMAS LOUIS (
Chair
), Department of Biostatistics, Johns Hopkins 
University
LAWRENCE BROWN, Department of Statistics, The Wharton School, 
University of Pennsylvania
EMERSON J. ELLIOTT, Former Commissioner, National Center for 
Education Statistics and Director, Special Projects, National Council 
for Accreditation of Teachers Education, Washington, DC
IVAN FELLEGI, Director (emeritus), Statistics Canada
ROBERT GROVES, Director, U.S. Census Bureau
SALLY C. MORTON, Department of Biostatistics, University of 
Pittsburgh
EDWARD SONDIK, Director, National Center for Health Statistics, 
Centers for Disease Control and Prevention, U.S. Department of 
Health and Human Services
HERMANN HABERMANN, 
Study Director
BRIDGET EDMONDS, 
Administrative Assistant
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.vi
COMMITTEE ON NATIONAL STATISTICS
 2010-2011
LAWRENCE BROWN (
Chair
), Department of Statistics, The Wharton 
School, University of Pennsylvania
JOHN ABOWD, School of Industrial and Labor Relations, Cornell 
University
ALICA CARRIQUIRY, Department of Statistics, Iowa State University
WILLIAM DuMOUCHEL, Oracle Corporation, Waltham, Massachusetts
V. JOSEPH HOTZ, Department of Economics, Duke University
MICHAEL HOUT, Department of Sociology and Survey Research 
Center, University of California, Berkeley
KAREN KAFADAR, Department of Statistics, Indiana University
SALLIE KELLER, Science and Technology Policy Institute, 
 Washington, DC
LISA LYNCH, Heller School for Social Policy and Management, 
Brandeis University
SALLY C. MORTON, Department of Biostatistics, University of 
Pittsburgh
JOSEPH NEWHOUSE, Division of Health Policy Research and 
Education, Harvard University
SAMUEL H. PRESTON, Population Studies Center, University of 
Pennsylvania
HAL STERN, Donald Bren School of Information and Computer 
Sciences, University of California, Irvine
ROGER TOURANGEAU, Joint Program in Survey Methodology, 
University of Maryland, and Survey Research Center, University of 
Michigan
ALAN ZASLAVSKY, Department of Health Care Policy, Harvard 
Medical School
CONSTANCE F. CITRO, 
Director
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.vii
Acknowledgments
This report is a summary of the June 29, 2010, workshop on facilitat
-ing innovation in the federal statistical system. The workshop was 
convened by the Committee on National Statistics (CNSTAT) of 
the Division of Behavioral and Social Sciences and Education (DBASSE) 
of the National Research Council (NRC). Support for the workshop was 
provided by a consortium of federal agencies through a grant from the 
National Science Foundation.
As chair of the steering committee and rapporteur for the workshop 
summary, we wish to thank the members of the committee for their help
-ful guidance and leadership in planning the workshop and moderating 
the sessions.
We acknowledge with appreciation the many people who participated 
in the workshop and contributed to its success, particularly Katherine 
Wallman, chief statistician of the United States at the Of˜ce of Manage
-ment and Budget, who helped us think through the logic of the sessions. 
We thank Robert Parker for preparing a background paper for the work
-shop and everyone who spoke for their stimulating and insightful com
-ments and discussion.
We thank staff of CNSTAT and DBASSE, particularly Bridget 
Edmonds who was responsible for the administration of the workshop. 
This report has been reviewed in draft form by individuals chosen for 
their diverse perspectives and technical expertise, in accordance with 
procedures approved by the Report Review Committee of the NRC. The 
purpose of this independent review is to provide candid and critical 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.viii ACKNOWLEDGMENTScomments that will assist the institution
 in making its
 published report 
as sound as possible and to ensure that the report meets institutional stan
-dards for objectivity, evidence, and responsiveness to the study charge. 
The review comments and draft manuscript remain con˜dential to protect 
the integrity of the deliberative process. We wish to thank the following 
individuals for their review of this report: Emerson J. Elliott, Director, 
Special Projects, National Council for Accreditation of Teacher Educa
-tion; Brian Harris-Kojetin, Statistical and Science Policy Of˜ce, Of˜ce of 
Information and Regulatory Affairs, Of˜ce of Management and Budget; 
Thomas B. Jabine, retired, Silver Spring, Maryland; J. Steven Landefeld, 
Director, Bureau of Economic Analysis, U.S. Department of Commerce; 
and Victoria Velkoff, Assistant Division Chief, Population Estimates and 
Projections, Population Division, U.S. Census Bureau.
Although the reviewers listed above have provided many construc
-tive comments and suggestions, they were not asked to endorse nor did 
they see the ˜nal draft of the report before its release. The review of this 
report was overseen by John E. Rolph, Professor Emeritus of Statistics, 
Department of Industrial Operations and Management, Marshall School 
of Business, University of Southern California. Appointed by the NRC™s 
Report Review Committee, he was responsible for making certain that 
an independent examination of this report was carried out in accordance 
with institutional procedures and that all review comments were carefully 
considered. Responsibility for the ˜nal content of this report rests entirely 
with the rapporteur and the institution.
 Thomas Louis, 
Chair
 Hermann Habermann, 
Rapporteur
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.Contents
1 INTRODUCTION
 12 SCOPE AND IMPORTANCE OF INNOVATION 
 93 BARRIERS TO INNOVATION 
 23
4 
 POSSIBLE REMEDIES TO BARRIERS
 33
5 
 NEXT STEPS
 41
REFERENCES
 45
APPENDIXES
A  WORKSHOP AGENDA
 47
B 
 WORKSHOP ATTENDEES
 51
ix
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.111Introduction
A healthy and vigorous program for innovation is fundamental for 
the continued success of any large-scale organization, including 
the statistical agencies of the U.S. government.
1 The concept of 
innovation for statistical agencies is broad. It includes traditional subjects 
of innovation, such as improvements in survey design and data collection 
procedures, including editing and imputation for missing and incorrect 
data in surveys and administrative records. And it also includes those 
less usually considered, such as questions about the usefulness of federal 
statistics to policy of˜cials and whether new approaches to bridge the 
interface between users and statisticians are required. 
Policy makers often have a different time horizon for needing infor
-mation (a few days, a few months, perhaps as long as a year) from that 
of ongoing statistical series, many of which provide information on a 
long time frame. For policy makers, there may be a tradeoff between 
the timeliness of information and its usefulness. If they can obtain the 
approximate answer to their question in a timely manner, they may ˜nd 
it suf˜cient for their needs, rather than a more accurate answer months 
or even years later.
Designing and ˜elding a survey and producing results often take 
years. Less traditional types of information-gathering modalities can 
reduce this time frame dramatically, although without the generaliz
-1See National Research Council (2009), especially pp. 26-31. This document also describes 
the decentralized U.S. statistical system (see, particularly, Appendix A).
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.2 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
ability and properties of traditional survey methods. For example, the 
National Academy of Public Administration (NAPA) has partnered with 
government agencies to conduct more than a dozen online dialoguesŠ
web-based discussion forums in which stakeholders and the public can 
log on, discuss ideas for addressing one or several related issues, and 
express their perspectives and priorities for government action.
2 One of 
those dialogues was conducted on health information technology and 
privacy. During the week-long online discussion, the dialogue received 
more than 4,000 visits from across the country, generating hundreds of 
ideas and comments. It provided what policy of˜cials deemed was suf
-˜cient information in a short amount of time. 
These types of information collections give rise to several questions. 
Should federal statistical agencies play a role in these types of informa
-tion gathering, and, if so, how? If the federal statistical system does 
not become an active participant in such approaches, is it in danger of 
becoming irrelevant? From the opposite perspective, is there a danger 
in straying too far in the direction of approximate answers and away 
from the traditional rigor of statistically valid information collections? 
Given these questions and the evolving ways of gathering information, 
what kinds and extent of innovation are needed for the federal statistical 
system to be able to play an appropriate role in meeting the needs of the 
public and policy makers for high-quality, timely, and relevant statistics 
to address new and changing social issues and questions?
ORIGIN AND SCOPE OF THE WORKSHOP
On May 8, 2009, the Committee on National Statistics of the National 
Research Council and the American Academy of Political and Social Sci
-ence jointly sponsored a symposium called ﬁThe Federal Statistical Sys
-tem: Recognizing Its Contributions, Moving It Forward,ﬂ in Washington, 
DC. One of the topics considered at that symposium was the health of 
innovation in the federal statistical system.
3 A consequence of the sympo
-sium was an agreement by the Committee on National Statistics to hold 
a workshop on the future of innovation in the federal statistical system. 
That workshop was held on June 29, 2010. 
The original statement of task for the workshop focused on three 
challenges to the statistical system: (1) the obstacles to innovative, focused 
research and development initiatives that could make statistical programs 
more cost-effective; (2) a gap between emerging data visualization and 
2See http://www.napawash.org/continuing-programs/national-dialogues/ [February 
2011].
3For a report on the symposium, see Habermann (2010b). 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.INTRODUCTION 3communications technologies and the ability of statistical agencies to 
understand and capitalize on these developments for their data dissem
-ination programs; and (3) the maturation of the information technol
-ogy (IT) discipline and the dif˜culties confronting individual agencies 
in keeping current with best practice in IT regarding data collection, 
processing, estimation, and dissemination, all the while protecting data 
con˜dentiality.
It was envisioned that the workshop would include invited presen
-tations and discussions to consider these challenges and the potential to 
address them. However, the steering committee decided that it would 
not be possible to consider all three topics in a one-day workshop. It was 
also decided that the time at the workshop would be devoted solely to 
discussions, without any presentations, although there would be back
-ground papers. 
Thus, the workshop proceeded under the following task statement: 
The workshop would address (1) the need for innovation in the federal 
statistical system; (2) the scope of the innovation problem and barriers 
to innovation; and (3) possible approaches to facilitating innovation in 
the federal statistical system.
A major purpose of the workshop would be to generate a wide spectrum 
of views on the state of innovation in the federal statistical system and 
possible ways to facilitate it. 
The workshop agenda appears in Appendix A. The workshop attend
-ees, who included representatives from the federal statistical system and 
the academic and private sectors, are listed in Appendix B. Two papers 
were prepared speci˜cally for the workshop: ﬁChallenges to the Federal 
Statistical System to Continue to Provide Data Relevant to Policy Issuesﬂ 
by Robert P. Parker (2010) and ﬁBarriers to Innovation and Possible Rem
-ediesﬂ by Hermann Habermann (2010a). In addition, a previously pub
-lished paper by Don Dillman (1996), ﬁWhy Innovation Is Dif˜cult in Gov-ernment Surveys,ﬂ was provided as background material. Thomas Louis 
(Johns Hopkins School of Public Health), chair of the workshop steering 
committee, suggested including the Dillman paper since its main points 
are as relevant in 2010 as they were in 1996. 
REPORT AND WORKSHOP ORGANIZATION
This report is a descriptive summary of what transpired at the work
-shop. It is therefore limited to the views and opinions of the workshop 
participants. However, it does not strictly follow the agenda of the work
-shop, which had four sessions. Instead, it is organized around the themes 
of the discussions, which migrated across the four sessions. For example, 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.4 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
comments on the barriers to innovation were made in Session I, and com
-ments on barriers and remedies were made in Session II. Moreover, there 
was no clear distinction between the need for innovation and the scope 
of innovation. 
The introductory remarks that opened the workshop and a list of 
workshop highlights are summarized below. Chapters 2-5 cover, respec
-tively, the scope and importance of innovation in federal statistics, barri
-ers to innovation in federal statistics, possible remedies, and next steps.
INTRODUCTORY REMARKS
Introductory comments were made by Thomas Louis, Constance 
Citro, and Katherine Wallman. In his introductory comments, Louis noted 
the impressive history of innovation in the federal statistical system, yet 
he stressed that it is time to consider how to move forward. He referred 
to the background paper by Habermann, which provides some examples 
of outstanding innovation and research accomplishments of the federal 
statistical system. 
As discussed in that paper, the terms ﬁresearchﬂ and ﬁinnovationﬂ are 
both used in this summary. They are related to one another, but comple
-mentary. ﬁResearchﬂ is used, as in any ˜eld, in reference to systematic 
inquiry to discover facts or frame theories, and ﬁinnovationﬂ is oriented 
to applicationsŠthat is, to design, invention, or development that yields 
products or services creating new value. For innovation to occur, the 
fruits of research must be applied to existing processes. Research may 
not always be necessary for innovation to occur, and even when new 
research results are produced, they may not be suf˜cient for innovation. 
Furthermore, the necessary research need not come from the federal gov
-ernment. The federal statistical system, however, must have the vision 
and the commitment for use of research to drive innovation. In discussing 
innovation, then, one is of necessity considering a complex process, usu
-ally involving research, whose end result is a change in existing processes 
of a statistical agency.
 Louis said that among the most prominent accomplishments of the 
federal statistical system is the work of Morris Hansen and his colleagues 
at the Census Bureau. Although such seminal work occurs only infre
-quently, the innovation environment in the federal statistical system is 
still rich. Some examples include work on the seasonal adjustment of 
time-series data (such as unemployment rates); models for small-area esti
-mates of poverty; fully out˜tted, mobile medical testing facilities for the 
National Health and Nutrition Examination Survey; and the development 
of a generalized and integrated data warehouse by the U.S. Department 
of Agriculture to provide easy access to historical survey and census data 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.INTRODUCTION 5from farmers and ranchers. These innovations have often been accom
-plished by, or in collaboration with, academic or contractor institutions. 
The federal statistical system continues to be aware of the need 
to foster an environment that supports and contributes to innovation, 
Louis said. For example, the Interagency Committee on Statistical Policy, 
chaired by the U.S. Of˜ce of Management and Budget (OMB), has created 
a subcommittee on innovation, which has worked in such areas as sam
-pling methods and dissemination procedures and engaged in discussions 
with the academic community on the need for statisticians in the federal 
government. 
However, although the environment for innovation is rich and the 
research accomplishments of the federal system are formidable, Louis 
echoed the point in Habermann™s paper that the demands of the nation 
require ever more innovation. New technologies have opened doors that 
did not exist even 10 years ago. Users are examining the cost and time for 
traditional survey approaches and asking if quicker, cheaper approaches 
with less accuracy are acceptable. 
Robert Groves (U.S. Census Bureau) noted, for example, that the 
federal statistical system would not be able to continue its current busi
-ness model of surveys with its current methods much longer because 
costs are escalating beyond the tolerance of the taxpayer to meet these 
costs. Constance Citro (Committee on National Statistics) pointed out 
that, although it is rare indeed for businesses to reinvent themselves, and 
even rarer for government agencies to do so, the data needs and the chal
-lenges to provide for such needs are growing. Consequently, the federal 
statistical system needs to assess how it is going to meet the demands and 
challenges of the future: indeed, that issue is the purpose of the workshop. 
Louis also introduced the theme of competition between the opera
-tional demands of an agency™s day-to-day activities and the need to refo
-cus these activities. He noted that innovation for tomorrow and beyond 
is often bumped by operational pressures and that it is important to keep 
in sight the demands of the futureŠno matter how pressing today™s 
responsibilities. In order to be able to meet the ever-changing and increas
-ing demands discussed above, Louis said that it is critical to have the 
right culture, to have the right people in place, and to have a reward 
system that encourages risk and innovation. With respect to the inherent 
risk of trying to innovate, Citro said that the federal statistical system 
should embrace the process of innovation even though some ideas will 
be failures. 
With respect to having the right people and reward system in place, 
Katherine Wallman (U.S. Of˜ce of Management and Budget) asked what 
the system would have to do in order to recruit the people who will be 
needed. She also introduced the themes of con˜dentiality, burden, and 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.6 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
OMB™s role in the redesign of household surveys. Although preserv
-ing the con˜dentiality of individually identi˜able data is of paramount 
importance, innovation is needed to provide more data to the public, 
including data on small areas. The survey system depends on the will
-ingness of potential respondents to participate. Work is needed both to 
encourage their participation and to reduce the burden on them. The tra
-ditional ﬁstovepipeﬂ approach to surveys (with agencies independently 
designing surveys without considering the data requirements of other 
agencies), as Groves also mentioned, may not be adequate for the future. 
Wallman noted that OMB is engaged in initiatives to understand how 
surveys can best be integrated and their costs reduced. 
At least three major forces are currently affecting the federal statistical 
system. The ˜rst is the ever more dif˜cult environment that data collec
-tion organizations face. For example, because of increasing resistance to 
survey participation, the Census Bureau has said it would be a signi˜cant 
accomplishment if the mail return rate for the 2010 census equaled that of 
2000. The second is the need to respond ever more quickly to the needs 
of the business community, the public, and the political community. The 
third is the gap between emerging data visualization and communica
-tions technologies and the ability of the statistical agencies to incorporate 
and capitalize on these developments. Exacerbating these factors is the 
absence of a central focal point or agency with statistical research as its 
mission. Research now is scattered among the statistical agenciesŠand 
few have the critical mass of research statisticians that may be needed to 
deal with these factors. 
WORKSHOP HIGHLIGHTS
As intended, the workshop was a forum for the free exchange of 
ideasŠprimarily on barriers to innovation, possible remedies, and next 
steps. There were no attempts to arrive at a consensus, nor were any 
conclusions drawn. To provide some structure, several of the participants 
presented their views of some recurring themes, and these are presented 
here. 













considered mis˜ts. In fact, the ideas developed by these ﬁcreative 
mis˜tsﬂ are often the most innovative.













-tistics has become very specialized, and future innovation could 
require major initiatives. For example, administrative records show 
great promise and are widely believed to be critical for future 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.INTRODUCTION 7data collections. However, without a major effort, their use seems 
always to be a year away.












and sometimes it is the inability to implement new ideas.











-ment to innovation, so collaboration is critical.













statistical agencies to provide the necessary leadership and to fol
-low through on the ideas discussed at the workshop.




leadership in eliminating bureaucratic barriers in contracting and 
recruitment.










-ulate academic work on federal statistical problems.













-ance on how to stimulate innovation.





















through developing and disseminating annual or biannual reports 
on key innovations and research.











research agenda.


in developing a marketing program with academic institutions 
and in establishing a culture of innovation in the federal statistical 
system.
















-ci˜c innovation projects while discussion proceeds on the larger 
issue of innovation in the federal statistical system. 










-tralized research approach, although with each agency having the 
ability to retain local creativity.




is not clear that the federal statistical system has the necessary will 
to engage them.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.2Scope and Importance of Innovation 
This chapter, reporting largely on the ˜rst workshop session, 
addresses the question: Why is innovation in the federal statistical 
system needed? The main arguments of the background paper by 
Robert Parker (2010) are summarized ˜rst, followed by relevant points 
from the background paper by Hermann Habermann (2010a), and then by 
participants™ comments. As noted in Chapter 1, many of the participants 
also commented on barriers and possible remedies; those comments are 
summarized in Chapters 3 and 4, respectively.
CHALLENGES TO THE FEDERAL STATISTICAL SYSTEM
In his paper, Parker focuses on the importance of continued innova
-tion by the system. He discusses several cases in which users are asking 
for more relevant policy data and identi˜es some of the challenges in 
providing these data. Parker notes that in looking ahead there are risks 
and challenges that will require the system to change. The identi˜cation 
of such challenges is not new, as evidenced by statements made over more 
than a decade:
 The challenge for the 21st century is to build on to the remarkable statis
-tical system developed in the 20th century. . . . We need to take advantage 
of new methods of information collection and dissemination and devote 
adequate resources to improve the quality, coverage and timeliness of 
federal statistical programs. . . . Federal statistics are not a ﬁhot buttonﬂ 
issue; politicians do not run for of˜ce on a strong plank for improving 
them (Knapp, 1996).
9Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.10 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
* * *
We are in the early stage of a technological revolution that will dramati
-cally increase the demand for statistics and their use in policy debates, as 
well as in many other areas of society. This revolution is created by the 
advent of the Internet and the World Wide Web. . . . I believe that three 
principal challenges must be faced if the system is to successfully meet 
the demands placed on it by this technological revolution. The three chal
-lenges are relevance, validity, and timeliness (Bradburn, 1999). 
* * *
Many new problems are facing the statistical agencies, and it will take an 
enormous effort to solve them. Indeed, the agencies are fully aware and 
understand there is a need for innovative thinking (Spar, 2009). 
One of the essential functions of any statistical agency is to produce 
relevant data, a requirement recognized by the Committee on National 
Statistics in a volume that lays out the principles that determine an effec
-tive statistical agency (National Research Council, 2009). The ˜rst of these 
principles is that ﬁa federal statistical agency must be in a position to pro
-vide objective information that is relevant to issues of public policy.ﬂ One 
of the most important reasons for innovation, then, is ensuring the ability 
to provide users with policy-relevant data. In his paper, Parker offers four 
examples of areas in economic statistics in which innovation is needed to 
provide relevant data for major policy issues and that illustrate the need 
for innovation by the federal statistical community: 
1.
  
data on intangible assets (based on work by the U.S. Department 
of Commerce); 
2.
  
measures of economic welfare (see Stiglitz, Sen, and Fitoussi, 2009); 
3.
  
indicators related to the most recent recession and recovery (see 
Advisory Committee on Measuring Innovation in the 21st Century 
Economy, 2008;
 Blank, 2010; Krueger, 2010); and
4.
 measures of international economic activity. 
These areas are all critically important to the nation, as has been noted 
by others. For example, the problems involved in the measurement of 
economic progress and welfare and, more speci˜cally, the challenge of 
de˜ning and measuring gross domestic product were raised in a recent 
New York Times Magazine
 article (Gertner, 2010) on the utility of gross 
domestic product (GDP). Because of their importance, these examples, as 
developed by Parker, are described in more detail below. 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.SCOPE AND IMPORTANCE OF INNOVATION
 11Data on Intangible Assets
The need for innovation is not unique to the federal statistical system. 
Innovation is essential for the business community if the United States is 
to be economically competitive in the world. Recognizing this, in 2008 the 
Commerce Department™s Advisory Committee on Measuring Innovation 
in the 21st Century Economy issued a report calling for new measures 
of innovation to be prepared by the Bureau of Economic Analysis (BEA), 
the Bureau of Labor Statistics (BLS), and the National Science Founda
-tion (NSF). For its work, the committee adopted the following de˜ni
-tion of innovation (Advisory Committee on Measuring Innovation in the 
21st Century Economy, 2008, p. 3): ﬁThe design, invention, development 
and/or implementation of new or altered products, services, processes, 
systems, organizational structures, or business models for the purpose 
of creating new value for customers and ˜nancial returns for the ˜rm.ﬂ 
The committee, then, was concerned with developing new measures of 
innovation in the business community that would result in improved 
returns for the business and added value for the customer and be more 
cost-effective. It is worth noting that if this de˜nition were to be applied 
to the federal statistical system, statistical agencies would supply more 
relevant, timely, and reliable data and be more cost-effective in doing so.
Carl Schramm, chair of the advisory committee and president and 
chief executive of˜cer of the Ewing Marion Kauffman Foundation, 
described the need for new measures of innovation as ﬁcentral to under
-standing the economy as it evolves and responds to growing world com
-petition. . . . Improvements to our measurement of innovation will help 
to ensure continued economic strengthﬂ (Parker, 2010). The measures 
the advisory committee called for include a comprehensive accounting 
of the effect of high-tech goods and services on growth and productiv
-ity, as well as new data on research and development and innovation-
related inputs.
1 BEA reported that there are dif˜cult conceptual issues to 
be resolved in order to collect new data on such intangible investments 
(Aizcorbe, Moylan, and Robbins, 2009). In addition, the collection of these 
data may be dif˜cult because they may not be available from the usual 
business accounting records. Furthermore, it may be that ˜rms can pro
-vide such estimates only at the enterprise level, yet the data are needed 
at the establishment level. Thus, statistical agencies will need to develop 
new methods to distribute ˜rm-level data to the establishment level for a 
variety of types of intangible investments.
1The annual Business R&D and Innovation Survey, just released in 2009 by the U.S. 
Census Bureau for the National Center for Science and Engineering Statistics, is intended 
to expand the available data on R&D and innovation.  See http://www.nsf.gov/statistics/
srvyindustry/ [June 2011].
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.12 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
GDP and Measurement of Economic Welfare and Prosperity
The 
Report by the Commission on the Measurement of Economic Perfor
-mance and Social Progress
, known as the Sarkozy report, argued that there 
is no suf˜cient statistic for judging the health of the economy (Stiglitz, 
Sen, and Fitoussi, 2009).
2 Joseph Stiglitz, one of the authors of the report, 
said that policy makers ﬁfocused too much attention on GDP as an indica
-tor of economic success, and there was no indication in the GDP ˜gures 
that a crisis was brewing. Although GDP is the best-developed broad 
measure of economic performance, it can provide a misleading gauge of 
the quality of life or sustainability of an economyﬂ (Parker, 2010). 
Although not in speci˜c response to the Sarkozy report, BEA in 2010 
published an article related to the report and some of its recommenda
-tions (Landefeld et al., 2010). The article reported that BEA had looked at 
changing its presentation of the various measures in the GDP accounts 
and announced that it plans to publish additional detail based on the 
current accounts (p. 12):
This article explores each of these issues and relates them to the need for 
expanded or supplementary measures for the national accounts, high
-lighting what such estimates might reveal relative to the conventional 
statistics presented by GDP and other aggregate statistics from the ac
-counts. In particular, it explores how the accounts might be extended to 
provide new measures of (1) the distribution of growth in income across 
households, other sectors, and regions and (2) the sustainability of trends 
in saving, investment, asset prices, and other key variables important 
to understanding business cycles and the sources of economic growth. 
With regard to various alternative indicators, such as the genuine progress 
indicator, the world development indicators, and the Index of Sustainable 
Economic Welfare, BEA reported that ﬁwhile these efforts have been much 
discussed and debated, there has never been suf˜cient consensus on the 
dif˜cult issues involved to produce a common set of concepts or methods 
or a widely accepted regular set of estimates that were used for analytical 
or policy purposesﬂ (Landefeld et al., 2010).
This article was followed by the 
New York Times Magazine 
article by 
Gertner (2010), which noted: 
For decades, academics and gad˚ies have been critical of the measure 
[GDP], suggesting that it is an inaccurate and misleading gauge of pros
-perity. What has changed more recently is that G.D.P. has been actively 
challenged by a variety of world leaders, especially in Europe, as well as 
by a number of international groups, like the Organization for Economic 
2The commission was created in 2008 by French President Sarkozy to identify the limits 
of GDP as an indicator of economic performance and social progress
.Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.SCOPE AND IMPORTANCE OF INNOVATION
 13Cooperation and Development. The G.D.P., according to arguments I 
heard from economists as far a˜eld as Italy, France and Canada, has 
not only failed to capture the well-being of a 21st-century society but 
has also skewed global political objectives toward the single-minded 
pursuit of economic growth. ﬁThe economists messed everything up,ﬂ 
Alex Michalos, a former chancellor at the University of Northern British 
Columbia, told me recently when I was in Toronto to hear his presenta
-tion on the Canadian Index of Well-Being. The index is making its debut 
this year as a counterweight to the monolithic gross domestic product 
numbers. ﬁThe main barrier to getting progress has been that statistical 
agencies around the world are run by economists and statisticians,ﬂ 
Michalos said. ﬁAnd they are not people who are comfortable with hu
-man beings.ﬂ The fundamental national measure they employ, he added, 
tells us a good deal about the economy but almost nothing about the 
speci˜c things in our lives that really matter.
Parker suggested that part of the reason statistical agencies have 
not embraced alternative concepts is their desire that components of, for 
example, the index of well-being, be measures that (1) have a theoretical 
relationship to the concept being measured; (2) are reliable; and (3) for the 
weights used to combine them, are based on some reasonable calculation. 
Consequently, the Canadian Index of Well-Being (CIW) is not produced 
by Statistics Canada but by a group of nonpro˜t foundations. Even if the 
ﬁdomainsﬂ covered by the index are reasonable, many economists and 
statisticians do not believe there is suf˜cient theoretical foundation to 
assign the appropriate weights to the domains. This problem of calculat
-ing weights also applies to other measures cited by Gertner, such as the 
planned Key National Indicators System
3 and the Human Development 
Index.
4 These factors do not mean that the measures do not have value 
in assessing progress; it does mean that more conceptual and theoreti
-cal work needs to be done before they will be produced by government 
statistical agencies. 
Nevertheless, the measures discussed in the Gertner article do pose a 
challenge for statistical agencies. Should they attempt to develop statisti
-cally valid measures of prosperity in addition to the conventional mea
-sures? BEA has expressed its reasons for not doing so, but other agencies 
may choose to look at more narrowly de˜ned welfare measures consistent 
with their areas of responsibility, such as health, education, and the envi
-3For a detailed report on the indicators project, see U.S. Government Accountability Of˜ce 
(2004, 2011). 
4See http://hdr.undp.org/en/statistics/hdi/ [June 2011].
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.14 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
ronment.
5 The challenge of providing measures of welfare and prosperity 
is that the current methods are not those usually used by statistical agen
-cies. This difference raises the question of whether the agencies should 
avoid those measures or perhaps limit their participation to just collecting 
input series. But even the latter step has signi˜cant risks, as some of the 
items would require the collection of opinion-type data, now usually col
-lected only by polling ˜rms. To deal with these problems Parker suggests 
ﬁthat agencies and related professional associations may need to develop 
guidelines on what the agencies should and should not collectﬂ (p. 6). 
Indicators of Recession and Recovery
 In October 2009, Alan Krueger, then the chief economist in the U.S. 
Department of the Treasury, addressed the annual meeting of the National 
Association of Business Economists (NABE) on how the weaknesses in the 
˜nancial and regulatory systems also ﬁrevealed an important weakness 
. . . in data and statistics that policymakers and others use to assess the 
performance of the economy to predict its future prospects, and to evalu
-ate the effectiveness of public policiesﬂ (Parker, 2010). Krueger, who pre
-viously headed the Princeton Data Improvement Initiative, which evalu
-ated the reliability of the government statistical agencies™ main economic 
indicators, included as weaknesses a lack of timeliness, insuf˜cient detail, 
and lack of relevance of certain key statistics as well as data gaps. More 
recently, Commerce Department Undersecretary Rebecca Blank addressed 
an NABE seminar on federal statistics on the same topic. The rest of this 
section summarizes their major concerns, as laid out by Parker. 
Krueger and Blank both noted that most key data series are released 
with a lag, making it dif˜cult to monitor existing or proposed stabilization 
policies. For example, the Federal Reserve Board™s ˚ow of funds accounts 
provides information on sector balance sheets and related transactions, 
but they are only produced quarterly and with a 3-month lag. Similarly, 
its Survey of Consumer Finances provides a detailed look at the state of 
households™ ˜nancial health only once every three years, with well more 
than a year™s lag between the last year of the survey and the release date. 
BEA™s GDP data by industry are produced annually with a 5-month lag. 
Krueger and Blank said that more timely data on how different industries 
were affected by the recent recession would have been valuable in assess
-5It also should be noted that in calculating GDP, BEA follows international guidelines, 
as do almost all other countries. Thus, changes to GDP would require agreement at the 
international level.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.SCOPE AND IMPORTANCE OF INNOVATION
 15ing various policy options.
6 Also, more timely Census Bureau longitudi
-nal ˜rm-level data would enable policy makers to study births and deaths over the economic cycle and to determine which ˜rms contract (or grow) 
more than others in a time of economic change. Likewise, more timely 
longitudinal household-level data would show what happens to families 
when one member experiences unemployment.
Krueger and Blank also found that there is an almost complete lack 
of information for a number of key economic variables. They pointed to 
little or no data on investment in intangibles; almost no data relating to 
loan originations (because the measures on characteristics of mortgages 
collected by the Mortgage Bankers Association are incomplete); no data 
on alternative sources and characteristics of bank lending; and few data 
to determine why the ˜nancial collapse created a credit crisis that led 
to the recession. They also noted that there is limited information about 
the amount saved from mortgage re˜nancing activity, which limits the 
ability to estimate the aggregate economic effects of re˜nancing. Krueger 
suggested that one possible solution to ˜lling these and related data gaps 
would be to establish some sort of ﬁrapid responseﬂ data-gathering capac
-ity in the statistical system that could be tailored to answer speci˜c, one-
shot questions, such as changes in consumption by households. 
Krueger and Blank also noted that the available GDP accounts pro
-vide information as to whether the economy is contracting or expand
-ing, but not about the sustainability of growth or about the distribution 
of income; neither do the accounts provide information as to whether 
resources are being used to maximize well-being. For example, neither 
the negative effects of pollution nor the positive effects of leisure time are 
valued in GDP. Because of these lacks, some analysts studying the future 
health of the economy also look at other statistics, such as the poverty 
rate, data on consumer wealth or the state of the environment, and data 
from household time-use surveys. In supporting his concerns about reli
-ance on GDP, Krueger also referred to the ˜ndings of the Sarkozy report 
(Stiglitz, Sen, and Fitoussi, 2009), discussed above. 
Some of the issues raised by Krueger and Blank involve data cur
-rently collected by the private sector or by ˜nancial regulatory agencies. 
Improvements might be made by statistical agencies partnering with 
these organizations. However, the preparation of sampling frames by 
statistical agencies may require additional detail on products of large 
˜nancial institutions and dealing with new types of organizations. As 
with new data on innovation, some of these data will be available only at 
the enterprise level, so the agencies would need to develop new methods 
6A proposal to fund quarterly industry GDP was included in the 2011 BEA budget request 
to Congress. 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.16 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
to distribute enterprise-level data to the level of establishments. Similarly, 
if funding is available only to prepare national-level data, it may be nec
-essary to develop other techniques to provide more detailed geographic 
detail. The Census Bureau recently developed small-area estimates for 
health insurance coverage using a model that combines survey data with 
population estimates and administrative records.
7 Measures of International Economic Activities
In the May 2010 issue of BEA™s monthly journal, the 
Survey of Cur
-rent Business
, Howell and Yuskavage (2010) discuss the agency™s planned 
changes in the GDP accounts to more closely align them with new inter
-national guidelines. One example is the issue of whether the United States 
will have the source data to implement the recommended change for 
goods that are sent abroad for further processing and then return without 
change in ownership. The current treatment is to ﬁimputeﬂ a change in 
ownership and record the values as exports and imports of goods. The 
recommendation would stop the imputation, exclude the merchandise 
from exports or imports, and include the difference in the two values 
as a service. The article reports on research to determine if data can be 
collectedŠby the Census Bureau, BLS, and BEAŠto meet the new guide
-lines and if users of these data are in favor of the change. Those three 
agencies would need to conduct signi˜cant research to determine not 
only if the necessary source data can be collected, but also whether those 
new data will be suf˜ciently reliable because they will affect both the U.S. 
international transactions accounts and the U.S. GDP. 
The article also discusses needed improvements to the data collected 
by BEA on international trade in services. For example, BEA has expanded 
the mailing list used for these surveys to re˚ect information from the 
Census Bureau™s Company Organization Survey and has instituted a new 
survey of travel expenditures both abroad and in the United States.
8 Col
-lecting these expenditures has proven to be a dif˜cult task, and it is not 
clear whether the new survey will be successful. 
Both the Census Bureau and BLS play an important role in the prepa
-ration of the U.S. international transactions accounts, note Howell and 
7For more details on the methodology for these estimates, see the Small Area Health 
Insurance Estimates Program on the Census Bureau™s website, see http://www.census.gov/
did/www/sahie/index.html [May 2011].
8Such sharing was made possible by the enactment of the Con˜dential Information 
Protection and Statistical Ef˜ciency Act of 2002. Further sharing of these lists would be 
possible with the enactment of the data synchronization legislation recommended by the 
Department of Commerce™s Advisory Committee on Measuring Innovation in the 21st 
Century Economy (2008), discussed above. 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.SCOPE AND IMPORTANCE OF INNOVATION
 17Yuskavage (2010). The Census Bureau provides the merchandise trade 
data used to prepare the estimates of international trade in goods, and 
BLS provides the price indexes used to de˚ate most components of those 
goods estimates. Each of these programs faces data collection issues that 
affect the reliability of the U.S. accounts. In January 2010, the Census 
Bureau introduced a new methodology for the estimation of low-value 
imports and exportsŠthat is, small transactions whose value falls below 
the exemption levels for ˜ling the administrative documents used to 
generate the merchandise trade data.
9 It is hoped that future evaluation 
studies will con˜rm the utility of the new methodology. 
Parker™s paper also notes that BLS continues to face problems in col
-lecting prices for intracompany transfers. In his paper, Parker states that 
a study conducted in 2001 concluded that BLS should make changes to 
improve the consistency of transfer prices by collecting data consistent 
with administrative de˜nitions from the Internal Revenue Service or the 
Customs Service or by investigating the use of export price indexes from 
other countries. It does not appear that signi˜cant research has been con
-ducted into new or improved data collection methods in this important 
area. 
Duplication in Federal Household Surveys
Parker provided another example from household surveys, summa
-rizing a report from the U.S. Government Accountability Of˜ce (2006):
At the time of GAO™s review, OMB had approved 584 ongoing federal 
statistical or research surveys, of which 40 percent were administered 
to individuals and households. . . . The seven surveys GAO reviewed 
could be considered to contain necessary duplication. GAO identi˜ed 
three subject areas, people without health insurance, people with dis
-abilities, and housing, covered in multiple major surveys that could 
potentially involve unnecessary duplication. Although they have simi
-larities, most of these surveys originated over several decades, and 
differ in their purposes, methodologies, de˜nitions, and measurement 
techniques. These differences can produce widely varying estimates 
on similar subjects. For example, the estimate for people who were 
uninsured for a full year from one survey is over 50 percent higher 
than another survey™s estimate for the same year. While agencies have 
undertaken efforts to standardize de˜nitions and explain some of the 
differences among estimates, these issues continue to present challeng
-es. In some cases, agencies have reexamined their existing surveys to 
reprioritize, redesign, combine, and eliminate some of them. Agencies 
have also used administrative data in conjunction with their surveys 
9For details, see http://www.census.gov/foreign-trade/aip/lvpaper.html [May 2011].
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.18 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
to enhance the quality of information and limit respondent burden. 
These actions have been limited in scope, however. In addition, two 
major changes to the portfolio of major federal household surveys are 
underway. The American Community Survey is intended to replace the 
long-form decennial census starting in 2010. . . . Of˜cials are also rede
-signing the Survey of Income and Program Participation which is used 
in estimating future costs of certain government bene˜t programs. In 
light of these upcoming changes, OMB recognizes that the federal gov
-ernment can build upon agencies™ practices of reexamining individual 
surveys. To ensure that surveys initiated under conditions, priorities, 
and approaches that existed decades ago are able to cost-effectively meet 
current and emerging information needs, there is a need to undertake 
a comprehensive reexamination of the long standing portfolio of major 
federal household surveys. The Interagency Council on Statistical Policy 
(ICSP), which is chaired by OMB and made up of the heads of the major 
statistical agencies, is responsible for coordinating statistical work and 
has the leadership authority to undertake this effort.
The critical challenge in this situation, Parker noted, is for the sta
-tistical system to innovate, to move beyond its traditional stovepipe 
approaches to integrated data collection approaches across agencies. As 
Robert Groves noted, the traditional stovepipe approach to surveys may 
not be adequate for the future, and escalating costs will prevent agencies 
from continuing business as usual. The effort to move away from dupli
-cated data collections toward integrated, more cost-effective ones is one of 
the major challenges for the statistical system. As the GAO report states, 
innovation is required to standardize de˜nitions, reduce respondent bur
-den, and increase the use of administrative records. 
The 2020 Decennial Census
Parker also discussed the decennial census in his paper, noting that it 
is the only data collection required by the U.S. Constitution. The decen
-nial census has also been the focus of numerous studies by the National 
Research Council on how to improve the data collection and make it 
more cost-effective, most recently looking at planning for the 2020 census 
(National Research Council, 2010). In an article highlighting the con
-clusions of the National Research Council report, panel chair Lawrence 
Brown emphasized several challenges, including the exceptionally high 
cost of the 2010 census and growth of these costs relative to those of recent 
Canadian censuses; the continuing social and technological changes in the 
United States; the need for a focused research and development program 
for 2020 census planning; and reaction to the report by the Census Bureau 
staff (Brown, 2010). With regard to the later, he wrote (p. 31):
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.SCOPE AND IMPORTANCE OF INNOVATION
 19We are heartened by the positive reaction of the Census Bureau to our 
panel™s report and by the concrete steps that the Census Bureau is 
taking to begin 2020 census planning now, with the development of a 
small number of visions of alternative ways of conducting the census 
and plans for R&D beginning in 2011-2012. R&D focused on these alter
-natives could lead to more cost-effective ways of updating the Master 
Address File (to the bene˜t of the [American Community Survey] and 
other household surveys in addition to the census); the strategic use 
of the Internet and other response modes to save paper and improve 
data quality; the possible use of administrative records in nonresponse 
follow-up operations; and the full implementation of hand-held tech
-nology for a ﬁpaperlessﬂ census.
CROSS-CUTTING ISSUES
In his background paper, Habermann (2010a) took a different 
approach to the issue of delineating the scope of the innovation problem. 
Rather than concentrating on speci˜c examples, such as measurement of 
economic welfare, he focused on areas that cut across all the statistical 
agencies. The areas that he asserted warrant more attention include

















and bias; 











of their strengths and limitations;




sets of disclosure rules; 




























dissemination strategies of agencies;












-˜cial statistics; 











to adapt advances in self-tracking technologies (the use of smart 
phones, other electronic equipment, and software applications to 
track and transmit detailed information on daily living) to sample 
survey design and operations; 



timely data that are ﬁgood enoughﬂ; and










costs and cater to respondent preferences, while understanding 
and neutralizing mode effects.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.20 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
Habermann™s paper notes that many of these are traditional prob
-lems in sample survey methodology, whereas others are created by new 
dynamics in both society and technology. He pointed out that some ana
-lysts have gone further to assert that it is not only speci˜c areas that 
are ripe for innovation, but also that the survey research ˜eld itself is 
decades behind other disciplines. For example, he quoted Robert Fay 
(2009, p. 845), who stated
1.
  
that research on memory has achieved a signi˜cant body of ˜ndings;
2.
  
that the results show potential promise for understanding aspects of 
the limitations of survey research and the potential for improving it;
10 and 
3.
  
that the survey research community appears largely unaware of most 
of these developments.
WORKSHOP DISCUSSIONS
The examples in the Habermann and Parker papers were developed 
not to provide a complete list of issues and problems, but instead to illus
-trate both the critical need for innovation and the breadth of the innova
-tion that is needed. 
Lynda Carlson (National Science Foundation) agreed with Parker 
about the importance of innovation in providing policy-relevant data, 
stating that innovation is important in order for the statistical system to 
get the right data for policy makers. More than the need to provide policy-
relevant data, she asserted, innovation is needed to shake up moribund 
agency processes and surveys. 
In discussing the need for innovation, Groves said that escalating 
costs are driving the need for innovation. The costs of surveys have been 
rising, and the costs are expected to continue to rise as nonresponse rates 
increase. He argued that these escalating costs will not be tolerated by tax
-payers in the future, so that the federal statistical system will not be able 
to continue its current business model of surveys with current methods. 
Nancy Gordon (U.S. Census Bureau) noted that statistical agencies 
have and will continue to have real competition from other sources of 
information. Although this nonfederal information is generally of very 
low quality, the information is provided more quickly than traditional 
surveys, and many users are not focused on quality. She stressed that the 
federal statistical system must innovate in order to survive. 
Richard Newell (Energy Information Administration) discussed the 
10
For example, Fay points out that some survey questions tax the limits of memory, and 
the potential bene˜ts of framing problems of recall in terms of current research on memory 
should seem self-evident.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.SCOPE AND IMPORTANCE OF INNOVATION
 21provision of information as a public good, which is one of the most 
important functions of a statistical agency. He noted that if competitors 
to the federal statistical system can provide data more cheaply and more 
quicklyŠeven if of lower qualityŠthen the fundamental nature of infor
-mation as a public good can be signi˜cantly affected.
One of the suggested responses to the rising costs of traditional sur
-vey methods is increased use of administrative records. Clyde Tucker 
(Bureau of Labor Statistics) pointed out that taking advantage of admin
-istrative data not only involves understanding how to make linkages 
and the accuracy of administrative data, but also requires organizational 
change and innovation in the way statistical agencies carry out surveys.
With respect to the need for innovation, Jennifer Madans (National 
Center for Health Statistics) argued that innovation involves not only 
big projectsŠtectonic shifts in the methods and processes of statistical 
agenciesŠbut also the everyday processes of doing smaller things. 
Graham Kalton (Westat) agreed that innovation is important to pro
-duce statistics in a cost-effective way. He also suggested that it is because 
the statistical system is mature that big innovation projects are needed. 
In the early days of the statistical system, innovation was comparatively 
easy. Now, for example, improvements in the consumer price index are an 
enormous undertaking, and needed changes require substantial innova
-tion projects. 
This point was also made in the paper by Dillman (1996). He noted 
that in the 20 years previous to 1996, fundamental change had come 
rapidly to survey methodology: for example, in 1976, mail surveys were 
treated as something to avoid, and telephone survey methods were not 
considered acceptable for any important surveys. Furthermore, although 
mixed-mode surveys were occasionally done, questions on whether 
people gave different answers using different modes were not seriously 
considered. 
Norman Bradburn (National Opinion Research Center) addressed the 
question of the importance of innovation by considering the workshop 
itself: Why is innovation the topic of an entire workshop? He answered 
that it is because the statistical system is mature, and people are looking 
for something transformative. What is needed is major innovation that 
will enable the federal statistical system to respond to the ever-growing 
challenges that it faces.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.3Barriers to Innovation 
This chapter covers ways to improve the extent and pace of innova
-tion in the federal statistical system by addressing the barriers to 
innovation, most of which were discussed in the workshop™s third 
session. The main arguments on this topic from the papers by Dillman 
(1996) and Habermann (2010a) are summarized ˜rst, followed by the 
points made by the workshop participants. 
STRUCTURAL BARRIERS
In Dillman™s (1996) paper, he re˚ects on his days at the U.S. Census 
Bureau in the early 1990s and his involvement in projects to reduce mea
-surement and nonresponse errors. He observes that three interconnected 
features of large government survey organizations make it dif˜cult to 
create an environment of innovation:
1.
 the coexistence of research and operations cultures,
2.
  
major differences in the dominant value systems of the research 
and operations cultures, and
3.
  
the dif˜culty of resolving these differences in a hierarchical 
organization.
Coexistence of Research and Operations Cultures
As he notes (Dillman, 1996, p. 115):
23
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.24 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
Government survey agencies face tasks unlike those usually faced in 
universities or private sector work. Some government surveys are of 
great scale and complexity, so that not only do they present huge opera
-tional problems, but much of the speci˜c knowledge for designing and 
implementing the surveys must come from research which only the host 
agency can design and implement.
A circumstance is thereby created that might be likened to, for example, 
an aircraft manufacturer attempting to operate an airline while continu
-ing to design aircraft. Putting pilots and ˚ight attendants into the same 
room with aeronautical and thermal systems engineersŠeach repre
-senting multi-million dollar enterprises with equal investment in the 
outcome of their common research projectŠcould produce some unpre
-dictable as well as strange outcomes.
It is perhaps inevitable that tension will develop between (a) employ
-ees responsible for the visible outcomes of the organization, whom the 
public and Congress are aware of and keep account of, and (b) employees 
who are part of the research arm of the organization, who are responsible 
for learning why and how things work and how to improve them. From 
the perspective of the operations culture (Dillman, 1996, p. 115):
Good research project is ﬁpracticeﬂ in order to form impressions of 
whether something works. Control groups are not really necessary, and 
the fewer treatment groups the better. From this perspective the real 
value of research is as the rehearsal is to a stage performance, where one 
dares not fail. At the same time, those from the research culture have in 
mind carefully designed treatment factors and a full factorial design. 
Preordained rules of assignment to treatment and control groups as well 
as rules for interpretation of evidence must be scrupulously followed.
Both of these cultures are essential to success. However, as Dillman 
notes, the perceived needs of one culture can often interfere signi˜cantly 
with the needs of the other. The results of the coexistence of these two 
cultures are ﬁdifferences in the core value systems of each culture and a 
division of responsibility that results in the overemphasis of some issues 
at the expense of othersﬂ (Dillman, 1996, p. 116). This is a major barrier 
to innovation. 
Two Value Systems
As described by Dillman, the values and skills of the people in the 
two cultures are signi˜cantly different. Statistics is the core value of those 
in the research culture. However, people trained in measurement and 
nonresponse issues are few in number, and, Dillman asserts, they gener
-ally lack in˚uence in the design process. The give and take of working 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.BARRIERS TO INNOVATION
 25groups may result in decisions about sampling error being made by 
statisticians and decisions about measurement error and nonresponse 
being made by operations staff. However, Dillman argues that the skills 
that are valued in the operations culture have almost nothing to do with 
reducing measurement and nonresponse errors; rather, the valued skills 
involve organizing large numbers of people to get tasks done accurately, 
on time, and at a low cost. The result is that, although measurement and 
nonresponse issues have emerged as increasingly important sources of 
data collection error, there has not been a corresponding emergence of 
signi˜cant numbers of professionals to design theoretically based projects 
needed to ensure the development and implementation of appropriate 
innovations for resolving the error. Dillman characterizes this situation 
as a barrier to innovation. 
Dif˜culty of Resolving the Culture Differences
Dillman notes that government statistical agencies, such as the Census 
Bureau, are highly complex organizations with many different tasks.
1 Not 
only are there several levels of hierarchy inside the organization, which 
makes identifying the originator of any material dif˜cult, but also, and 
more importantly, there are several levels of hierarchy outside the statisti
-cal agency. He noted, for example, that the then-proposed 2000 research 
and development program of the Census Bureau might go through a 
minimum of eight entities outside the agency. Differences in organiza
-tional hierarchies may be resolved in a number of ways, such as by which 
entity is the most powerful or by who won the last time. As a result, 
compromises are common, and the decisions made by organizational 
hierarchies are often based on different issues from those that originally 
led to the negotiation. Dillman asserted that, in particular, measurement 
and nonresponse issues are decided in this kind of complex hierarchical 
process, and they ﬁloseﬂ to operations issues on one hand and statistical 
issues on the other. He notes (Dillman, 1996, p. 119):
From the standpoint of innovation in a rapidly changing technological 
environment, though, hierarchical processes make such cultural and 
value system concerns more dif˜cult to resolve. The down-side of hier
-archy for innovation is that it forces large amounts of critical information 
upwards through a series of smaller and smaller funnels. This process is 
slow, but the information that eventually gets through represents only 
1Although the focus of his article is on government statistical agencies and the Census 
Bureau in particular, Dillman noted the general nature of the issues. The solutions he 
presents are not unique to government survey organizations, he wrote, but also apply to 
universities and corporations.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.26 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
a part of the original message. In addition, the information ˜nally com
-municated may bear very little resemblance to the original message.
A further problem of hierarchical decision making, according to 
Dillman, is that horizontal ˚ows of innovative ideas and the promotion 
of active discussion of these ideas at an early stage are discouraged. In the 
absence of a more formal regularized process to discuss possible innova
-tions, the ideas that do ˚ow horizontally are usually by word of mouth. 
One result is that the ideas often become distorted and misunderstood by 
those in the hierarchy. He ends by noting that ﬁthe effects of hierarchical 
processes [are] to slow down and sometimes thwart altogether needed 
innovation and changeﬂ (Dillman, 1996, p. 120). 
OTHER BARRIERS
The paper by Habermann (2010a) agrees with Dillman about the 
problems produced by the coexistence of different cultures in a statistical 
agency, but it considers several additional barriers:












agencies;
 











both to take a long-term view of research and innovation;












for innovation funds;













conventional logic is welcomed;











leaders;

































and contractors; and







Several of these barriers concern leadership in the federal statistical sys
-tem. This theme of the importance and need for leadership was echoed 
by many of the workshop participants. 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.BARRIERS TO INNOVATION
 27WORKSHOP DISCUSSIONS
Leadership
In discussing the critical path to innovation, John Haltiwanger (Uni
-versity of Maryland) pointed out the necessity for somebody at the top of 
an organization to take responsibility for innovation. Leaders must make 
it clear that they want innovation, and they want it now. Innovation does 
not just happen. With respect to not being able to attract suf˜cient num
-bers of new staff with the correct skill set, he observed that prospective 
students know which organizations are research friendly and that leader
-ship is needed to create research friendly organizations. 
Following on this subject, Ivan Fellegi (Statistics Canada) noted that 
one of the principal barriers to attracting staff is one of image; however, 
he said, the image of a statistical agency can be changed. In identifying 
the barriers to innovation, he pointedly observed, one need not look any 
further than to the participants in the workshop, who included the leader-ship of many U.S. federal statistical agencies. He suggested that, although 
it is not easy, successful statistical of˜ces can create an environment for 
innovation. Leaders create this environment or culture through their own 
behavior and the structures they put in place. Moreover, leadership is 
required to ensure that the right questions are being asked and that the 
answers to the questions are correctly and appropriately dealt with. 
This theme of the importance of leadership was picked up by sev
-eral other participants. Ruth Ann Killion (U.S. Census Bureau) noted 
that mangers are responsible for developing a culture of innovation, and 
Andrew White (National Center for Education Statistics) suggested that 
implementing a culture of innovation comes from the senior leaders of 
an agency. He essentially agreed with Fellegi, commenting that everyone 
attending the workshop is responsible for instituting that culture. 
Jennifer Madans noted that this type of meeting has been held before, 
and little if anything has come from the effort. She observed that the lead
-ers of the statistical systemŠall of the people in the roomŠare respon
-sible for the lack of progress. Although it is true that a decentralized sys
-tem makes it hard to have a joint response, she said, the federal statistical 
system nevertheless needs to act or die. 
Clyde Tucker commented on the importance of leadership in the area 
of administrative data. If the federal statistical system is to accomplish the 
necessary organizational change so that the system can take advantage of 
administrative data, then leadership will be needed to do so. Leadership 
is particularly important for administrative data, because statisticians are 
trained and in their usual activities are used to working with surveys and 
not administrative data. 
Constance Citro noted that agency staff often do not know how the 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.28 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
data they provide to the public are used. To understand the problems and 
attributes of the data that agencies produce, it is critical that they analyze 
those data. It is leadership that sets the direction for an agency to ensure 
that this kind of analysis is performed. 
Richard Newell asked if the barrier was the inability to implement 
existing ideas as opposed to developing new ideas. In order to be innova
-tive, agencies must have a thirst for new knowledge, and leaders have to 
create an environment for slaking such a thirst. 
Communication and Collaboration
In addition to leadership, the other most frequently mentioned bar
-rier to innovation is the lack of communication and collaboration within 
and between agencies. This issue was raised by Brian Harris-Kojetin (U.S. 
Of˜ce of Management and Budget), who said that in his observations not 
only do different agencies that experience the same problem not talk to 
each other, but even within an agency there can be signi˜cant problems 
of communication. 
Marilyn Seastrom (National Center for Education Statistics) devel
-oped this theme with reference to speci˜c issues that are common to 
agencies in the federal statistical system. She suggested that the key to 
innovation in cost savings, data dissemination tools, data visualization, 
and metadata standards is collaboration among agencies. 
Barry Nussbaum (U.S. Environmental Protection Agency) suggested 
that the problem of communication extends to the fundamental issue of 
understanding the needs of users. This is critical for success in innovation: 
staff have to work with data and understand how they were acquired and 
what their properties are. To do that requires working in the weeds of data 
acquisition, where one can truly understand the properties of data and 
the basics of data collection. 
In this context, Haltiwanger said a related problem is the inability 
of researchers inside and outside the government to drill down in their 
analysis. He observed that this inability to go deeper into the relationships 
among variables is due to a lack of data sharing among agencies, limited 
access to microdata, and lack of federal and state cooperation. In general, 
he said, improving communications within an agency could bear a great 
deal of fruit in terms of breaking down barriers to innovation.
Citro noted that one of the barriers related to communication is a lack 
of understanding between the user community and the research commu
-nity and between the federal statistical agencies and private contractors. 
Allen Schirm (Mathematica Policy Research) pointed to the workshop 
itself as an example of the need to broaden interactions and establish bet
-ter communication. He noted the absence of signi˜cant numbers of young 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.BARRIERS TO INNOVATION
 29people at the workshop. He commented that it would also be bene˜cial 
if the Interagency Committee on Statistical Policy (ICSP) Working Group 
on Innovation had participation from the private sector.
Operational and Innovation Cultures
Several participants responded to the points in the Dillman (1996) 
paper on the coexistence of an operations culture and a research culture. 
Lynda Carlson agreed that operational matters often trump work on 
innovation. In response to earlier comments from Graham Kalton about 
the need for large, major innovation projects, Madans suggested that 
implementation of big innovation projects can set up a tension between 
who is thought to be doing innovation and who is not. One of the results 
of this tension can be a lack of communication between the operations 
staff and the research staff. It is important, therefore, to build innovation 
into everyone™s job. 
Thomas Louis also suggested that one of the challenges is to make 
innovation a part of the usual work of staff. Nussbaum reported on 
experiences at the U.S. Environmental Protection Agency (EPA), stating 
that the secret to innovation at the EPA is not to call it innovation. In fact, 
setting up a bureaucratic process that is supposed to innovate inhibits 
individual initiative. 
Fear of Failure
Carlson proposed another barrier to innovationŠthe fear of failureŠ
that was not discussed in any of the background papers. She noted that 
innovation is by its very nature risky and that the budget and perfor
-mance process as practiced by the federal government militates against 
taking risk. It is safer not to try to innovate and thus avoid the penalties 
that these systems would impose for failure. 
 Ronald Fecso (U.S. Government Accountability Of˜ce) agreed that 
fear is an important barrier, and performance plans impede risk-taking 
by encouraging people to take the easier path of the status quo. It is 
important to get over the fear of failure, he said. Moreover, the system 
needs to focus more on understanding user needs and answering the 
important new questions and not just on improving the answers to exist
-ing questions. 
Edward Spar (Council of Professional Associations on Federal Statis
-tics) emphasized the point that with risk comes the possibility of failure. 
Although this may appear to be obvious, people must accept this and 
learn to live with it. In this vein, Ron Bianchi (Economic Research Service, 
U.S. Department of Agriculture) suggested that the concept of a risk-free 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.30 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
idea is in a sense vacuous, since a risk-free idea is equivalent to a work-
free zone.
Case Studies
Several workshop participants mentioned the lack of successful case 
studies as a barrier to innovation, commenting on the need for better 
case studies of innovation that could be used by agencies. According to 
Thomas Mesenbourg (U.S. Census Bureau), components of such studies 
include who drove the innovation project, who opposed it, what chal
-lenges were encountered, and what were the keys to success. Newell 
observed that it might be useful to identify a set of best practices and to 
include in the case studies the human capital dimension and descriptions 
of the research infrastructure and internal practices. Sally Morton (Univer
-sity of Pittsburgh) provided a cautionary note with respect to case studies. 
Although they may be helpful, she said, barriers are changing over time 
and what worked previously may not succeed now. 
Christopher Carroll (Council of Economic Advisers) extended the 
idea of case studies to comparisons with others outside the system. It is 
important for each agency to compare how it is doing with others. More 
speci˜cally, the statistical system and individual agencies should seek to 
understand why federal statistics are different from other statistics that 
are ostensibly measuring the same thing. For example: Why do different 
estimates for employment result from household surveys and payroll 
surveys?
Lack of Statistical Expertise
Harris-Kojetin said in his view the most important barrier is a lack of 
skilled people and expertise. In this regard, it is important to recognize 
that there is a wide demand for statisticians outside government, and they 
may have expertise that is lacking inside the government. Therefore, the 
federal statistical system should remove any barriers that prevent linking 
communities inside and outside government that employ statisticians. For 
example, the federal system should look to other mature organizations 
that have encountered the barriers discussed in the background papers 
and in the workshop discussions. 
This theme of insuf˜cient skilled personnel as a barrier was taken up 
by Kalton, who emphasized the importance of updating skills. He pointed 
out that this need to update skills is more important than in the past. 
Statistics has evolved into many subdisciplines, each of which requires 
particular high-level skills. An example of this was provided by Judith 
Rowe (Princeton University), who pointed out that there are two kinds of 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.BARRIERS TO INNOVATION
 31administrative data, mandatory and voluntary, and that they require dif
-ferent kinds of statistical solutions. Carlson added that the skills needed 
for innovation projects are often lacking in both agencies and government 
contractors. 
Organizational and Process Barriers
Some barriers can be thought of as structural in natureŠthat is, they 
exist because of processes imposed on an agency as a unit in the federal 
government. Other barriers may be amenable to individual agency initia
-tive. Haltiwanger pictured the federal statistical system as a huge, lum
-bering organization, which he called a barrier to innovation. Innovation 
needs to be a grassroots activity, he argued, and it is better to have many 
smaller activities rather than a few major ones. For innovation to succeed, 
it is not necessary to have a grand plan with huge numbers of people. 
Agencies have to understand how to build incubators of innovation and 
allow them to ˚ourish. Robert Groves also liked the idea of multiple 
grassroots projects.
Among the system-wide barriers that were noted during the discus
-sion, several related to the nature of the budget process and procurement 
rules. Michael Horrigan (Bureau of Labor Statistics) said that one of the 
barriers to innovation is that the budget process requires more certainty 
than one has when trying to innovate. It is dif˜cult to obtain funding for 
projects in the absence of a guaranteed outcome, and being up-front about 
the risk endangers the likelihood of obtaining funding. 
In the same vein, Mesenbourg asserted that one needs a clear impera
-tive or mandate to fund large improvement projects. As an example, he 
stated that the recent recession did create such a mandate for improve
-ments in data collection in the service sector, and the Longitudinal 
Employer-Household Dynamics Program became a very easy sell in the 
wake of the recent ˜nancial crisis. 
With respect to procurement and recruitment, Carlson said that cur
-rent government-wide rules make it dif˜cult, if not impossible, to enter 
into ˚exible agreements with contractors to pursue innovation projects. 
Groves suggested that there are different barriers for small and 
large agencies, and therefore the solutions may be different for different 
agencies. Particularly for small agencies, coalitions across agencies and 
improved contracting procedures are important, he said. The issue then 
becomes one of how to systemically encourage coalitions and alliances.
Newell pointed to a different kind of structural problem: a monopo
-listic environment and lack of competition that can lead to stagnation 
and a failure to innovate. Agencies that ˜nd themselves in a monopolis
-Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.32 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
tic position may not be attentive to changing demand and may develop 
institutional structures that resist change. 
With respect to organizational barriers in an individual agency, 
Haltiwanger said that in his view the location of a research organization 
within the agency is very important. Agency research organizations are 
properly dedicated to the function of research, although they can still be 
integrated into the work of the agency. 
Users as a Barrier
With respect to the barriers to innovation, Eva Jacobs (Bureau of 
Labor Statistics) noted that sometimes the user is the barrier. For example, 
users of the consumer price index (CPI) and other surveys do not like 
change in the time series or the questions that are asked. In order to pro
-duce anything new in the CPI, you have to sell it, she saidŠboth to labor 
organizations and to business organizations.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.4Possible Remedies to Barriers 
This chapter covers the workshop discussions of ways to remedy 
the barriers to innovation discussed in Chapter 3. The background 
papers by Dillman (1996) and Habermann (2010a) are summarized 
˜rst, followed by the discussion of the workshop participants. 
OVERCOMING THE ENVIRONMENTS 
THAT HINDER INNOVATION
In his paper, Dillman outlined three steps to overcome the three inter
-connected features of large government survey organizations that make it 
dif˜cult to create an environment of innovation, discussed in Chapter 3. 
First, he noted that for research to positively affect government sur
-vey practice, much of it must be done on government surveys, but the 
professionals are not there in suf˜cient numbers to do this. In particular, 
he singled out the need to bring into the government professionals who 
are able to resolve issues of measurement and nonresponse error.
The second step is to build the capacity to understand and deal with 
sources of nonsampling error into the operations culture. This is neces
-sary because many of the decisions that are made at the operations level 
directly affect measurement and nonresponse. As examples, his paper 
mentions ﬁquestion wording and order, the way a form or questionnaire 
is constructed on a page, the information included as part of an address, 
the class of postage used, whether letters include dates, the contents of 
those letters, whether letterhead stationery is used, and the kind of mail 
33
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.34 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
processing equipment purchasedﬂ (Dillman, 1996, p. 122). He stresses the 
importance of instilling this capability into the information technology 
parts of an organization, since, on one hand, the acquisition of informa
-tion technology is one of the main driving forces in innovation, and, on 
the other hand, information technology units are often concerned with 
operational ef˜ciency and not reduction of survey error. Adoption of 
new technologies should contribute to the reduction of survey errors, not 
exacerbate them.
The third step he proposed is to take measures to eliminate problems 
in reliable and timely communications that may be caused by the overly 
hierarchical nature of the organization. These measures have two com
-ponents. One is that communication should not be viewed as a control 
function but as a means to promote the ˚ow of information to as many 
people as possible in as short a time as possible. The other is to ensure 
that neither the research nor the operations culture entirely dominates the 
other. He notes (Dillman, 1996, p. 123): ﬁA government survey organiza
-tion that allows either the research culture or operations culture to control 
the other will neither be innovative in an effective way nor will it conduct, 
in the long run, high quality surveys. The organizational structure needed 
is one that encourages each to in˚uence the other and allows disagree
-ments to be worked out quickly, at lower levels under an umbrella of 
shared purpose.ﬂ 
Dillman also observes that the barriers and remedies that he pro
-poses are not unique to federal statistical agencies (Dillman, 1996, p. 124): 
ﬁUniversities, large corporations, and others all ˜nd themselves strug
-gling with how to facilitate needed innovation, rather than unnecessarily 
thwarting it.ﬂ
LEADERSHIP AND FOCUS
As did the workshop participants, the Habermann paper (2010a) 
stresses the importance of leadership: 
It is the leadership of each agencyŠincluding the senior managersŠwho 
are responsible for fostering an innovative spirit and for carrying out 
innovation in that agency. It is leadership who are responsible for in
-spiring and rewarding staff, and for developing solutions in spite of the 
constraints placed on the agency. It is, after all, agency leadership that 
must ensure that the necessary investments in innovation are made and 
the necessary changes to business processes are accomplished. Moreover, 
it is not suf˜cient to manage an agency; one has to manage a techni
-cal agency. Leadership then can assist in attracting and retaining staff 
through improved (less bureaucratic) working conditions and fostering 
a spirit of excitement. Leadership must also wrestle with the dif˜cult 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.POSSIBLE REMEDIES TO BARRIERS
 35problem of encouraging change in an environment where day-to-day 
operational outputs are of paramount importance to the public.
Although there is no silver bullet to solve the problem of ˜nding 
tomorrow™s leaders for the statistical agencies, Habermann™s paper sug
-gests that there is a system-wide change that might make a signi˜cant dif
-ference for the future. This change would elevate the status of the heads 
of statistical agencies in their department and with Congress, as well as 
allow for easier access for these leaders to the decision-making processes 
of the executive branch. Currently some, though not all of the heads of the 
statistical agencies, are presidential appointees requiring Senate con˜rma
-tion (known as PAS). The change would be to require that each agency 
head be a PAS with a term appointment. In his paper, Habermann asserts 
that such a change would raise the visibility of all the statistical agencies 
and make it easier for them to promote their budgets and to gain the 
appropriate measure of independence necessary for success. 
 Although leadership is a necessary condition for innovation, it may 
not be suf˜cient. In particular, Habermann™s paper addresses three other 
areas that, in his view, require system-wide attention: recruitment, work
-ing relations with academic researchers and with private contractors, and 
a more centralized focus for research and innovation. 
Recruitment
Habermann™s paper acknowledges that there are many excellent stat
-isticians in the federal statistical system. However, their numbers are not 
suf˜cient to meet the demands placed on the system for more innovation. 
Moreover, as mentioned earlier, the skill set required for research and 
innovation is relatively rare. The primary method of attracting researchers 
into the federal statistical system is through recruitment of new gradu
-atesŠwho must be U.S. citizensŠat the master™s and doctorate levels. 
However, many otherwise excellent candidates are not U.S. citizens, and, 
with few exceptions, they cannot be hired by federal statistical agencies. 
To change this would be a signi˜cant task and would require legislation, 
and the paper acknowledges that such a change is unlikely in the current 
political climate. Consequently, according to Habermann™s paper, consid
-eration might be given to another idea: creating a private not-for-pro˜t 
research center, devoted to the problems of the federal statistical system, 
which is not hindered by the hiring constraints of federal agencies. 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.36 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
Relations with Academic Researchers and Private Contractors
Even if the federal statistical system did employ signi˜cant numbers 
of staff with the correct skill set, it would still be bene˜cial, and in fact 
necessary, for them to work cooperatively with researchers in academic 
institutions and the private sector. System-wide leadership is needed for 
agencies to develop the ability to enter into ˚exible cooperative agree
-ments with academic and other institutions. Although there are coop
-erative agreements in some agencies, even in these cases it is often the 
department that makes the ˜nal decision. According to Habermann™s 
paper, it would be helpful if all statistical agencies could have ˚exibility 
in their grant-making ability and in working with universities to support 
graduate students.
A Central Focus for Research and Innovation
The ability to undertake signi˜cant innovation projects requires a 
critical mass of research personnel in many agencies. This critical mass 
is lacking in most agencies. Even if the agencies were able to recruit 
noncitizens, the inability to create such a critical mass would still exist 
simply because of the numbers of staff required. Moreover, the absence of 
a central focus makes it dif˜cult for the statistical system, acting a whole, 
to prioritize and focus on system-wide innovation problems. 
Habermann™s paper discusses two options that could aid in the solu
-tion of these problems. One approach would be to empower a single 
agency (e.g., the Census Bureau, the Bureau of Labor Statistics) to act 
as the focus for innovation for the entire statistical system. Direction 
for the single-agency research program could come from the Statistical 
Policy Of˜ce of the Of˜ce of Management and Budget (OMB) through 
the Interagency Committee on Statistical Policy (ICSP). Such an approach 
would require a level of integration that does not now exist in the federal 
statistical system, and the success of this approach would require success
-ful solutions to the problems of recruitment and working relationships 
discussed above. 
If it is not possible to simplify the recruitment process or to hire non
-citizens, and if the contracting rules prove intractable to change, then a 
more innovative approach to providing a central focus for research and 
innovation may be required. Habermann™s paper discusses the approach 
of a private not-for-pro˜t research center. The employees would not be 
federal employees and therefore would not be subject to the recruit
-ment and retention rules of the federal government. Such a center could 
take advantage of contracting rules that would allow ˚exible working 
relationships with the government. It would also require authority from 
OMB through the ICSP. In this approach, research would take place at 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.POSSIBLE REMEDIES TO BARRIERS
 37the center, at universities, and by federal contractors (under contract 
with the center). Habermann™s paper notes that the number of employ
-ees at this center need not be large. 
WORKSHOP DISCUSSIONS
Although several possible remedies to overcoming the barriers to 
innovation were discussed by the workshop participants, changes in lead
-ership and research programs were among the most commented on. Three 
other topics in the discussion were periodic review and feedback from 
users, innovation incubators, and the criteria for successful innovation. 
Leadership
The need to improve leadership was mentioned by many participants 
as critical to improving innovation, and some had speci˜c ideas about 
how leadership can provide remedies to innovation barriers. 
Robert Groves said that statistical agencies need to reexamine the 
existing boundaries between agencies. In particular, he suggested, leader
-ship was needed so that the system could reconceptualize agency bound
-aries and the nature of collaborative activities between agencies, as well as 
the boundaries with outside entities. Noting that small and large agencies 
have different barriers and therefore different solutions, he said that one 
issue is how to systemically encourage coalitions and alliances. 
Cynthia Clark (National Agricultural Statistics Service) observed that 
leadership is needed to develop policies that encourage the movement 
of staff between different organizations and that this would help break 
down some of the existing barriers between agencies. 
Steven Landefeld (Bureau of Economic Analysis) stressed the impor
-tance of leadership in providing the correct incentives for innovative 
work and changing the incentives as conditions warrant. Since the federal 
statistical system is a decentralized one and likely to stay that way, he 
pointed out the need for more centralized leadership and direction. He 
extended the concept of incentives to advisory committees, noting that it 
is also important for advisory committees to have the correct incentives to 
maximize their usefulness. Landefeld stated that, although there is never 
going to be a Statistics USA centralized statistical system, in his view 
stronger leadership is needed at the top with the authority to make some 
decisions about priorities in the budget process and about cross-cutting 
priorities. 
The need for incentives for outside researchers and for agency staff 
was also noted by John Eltinge (Bureau of Labor Statistics).
Clark noted the need to make greater use of cooperative agreements 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.38 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
with states and land grant universities as well as the need to encourage 
the development of interdisciplinary teams. Constance Citro remarked 
that it might be bene˜cial to extend the ability that the National Agricul
-tural Statistics Service has for making cooperative agreements to other 
agencies, but that would require new legislation. 
Research
Several of the workshop attendees remarked on the importance of 
research in enhancing innovation in the federal statistical system. Both 
Landefeld and Steven Dillingham (Bureau of Transportation Statistics) 
observed that cross-cutting research could be centralized, as suggested in 
Habermann™s paper. Landefeld, however, said that individual agencies 
would still need the ability to carry out research on speci˜c topics relevant 
to their missions, such as national accounts. 
Manuel de la Puente (Social Security Administration) pointed out 
that extramural research can bring into an agency outside people with 
new skills and abilities. To promote the synergies of extramural research, 
it is important to pair up outside researchers with internal agency staff. 
Edward Sondik (National Center for Health Statistics) agreed, asserting 
that it is stimulating for staff to be involved in extramural work. 
Both Thomas Louis and Roderick Little (University of Michigan) 
commented on the type of research being performed by federal agencies. 
Little said that research by the federal statistical system may be skewed 
too far toward the observational end of the spectrum and not enough 
toward the experimental design end. Louis concurred, saying that it is 
critical for experiments to have the ability to compare approach A with 
approach B. In building a productive research program, it is necessary to 
attract researchers from outside the federal system. One way to do this, 
according to Groves, is through the use of the Intergovernmental Person
-nel Act. This allows researchers, primarily from academic institutions, to 
leave the academic world for a speci˜ed period of time, work in a statisti
-cal agency, and then return.
Periodic Review and Feedback from Users
The importance of a periodic review of statistical programs to over
-come barriers to innovation was stressed by several participants. Allan 
Schirm and Little discussed the need for regular evaluations of statistical 
programs, including their ˜tness for use. David Banks (Duke University) 
said that it would be useful to hold a workshop every ˜ve years on how 
to organize a statistical agency as if for the ˜rst time. 
With respect to review and evaluation, Groves noted that creative 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.POSSIBLE REMEDIES TO BARRIERS
 39destruction of statistical programs is not usually practiced by statistical 
agencies, although external pressures, such as budgets, can induce it. 
With respect to periodic reviews, Clyde Tucker pointed out that 
20 years have passed since enactment of the Government Performance 
and Results Act, and there have been few serious interagency efforts to 
develop quantitative performance metrics. He noted that the best example 
of such a metric is the OMB standard on nonresponse bias. 
Both E.J. Reedy (Ewing Marion Kauffman Foundation) and Edward 
Spar (Council of Professional Association on Federal Statistics) com
-mented on the issue of feedback from users. Reedy stated that agencies, 
from the top down, need to interact with users to provide and get feed
-back and connect with data users. He suggested that agencies should put 
a notice about seeking feedback on the websites where their data reside, 
so users see it when they want to download data. Spar observed that 
agencies usually provide information to users on what they (the agen
-cies) are doing; they need to make greater efforts to understand the users™ 
perspectives. In obtaining that feedback, William O™Hare (Annie E. Casey 
Foundation) suggested that clearer communication can build public sup
-port. In that vein, agencies need to learn how to use Facebook, Twitter, 
and other social networking tools, he said. 
Innovation Incubators
Several participants supported the concept of innovation incubators 
or laboratories in which ideas for innovation could be developed and 
tested. Ron Bianchi noted that this could be coupled with the concept of 
promoting contests for innovation, as is done at the National Aeronautics 
and Space Administration.
Eltinge said it is important that the statistical system and the indi
-vidual agencies learn how to infuse new technologies into the system. The 
example he used was how, in the 1940s, Iowa farmers learned to accept 
the mechanization of agriculture and hybrid seed corn. 
John Haltiwanger suggested that the statistical agencies could work 
with foundations, communities, and corporations, such as IBM, that have 
experience with building incubators and allowing them to ˚ourish. The 
hard part is ensuring that the innovation ideas from incubators are not 
left to wither and die. He noted that it takes senior management buy-in to 
move incubation products into the mainstream of an organization. 
Emerson Elliott (National Council for Accreditation of Teacher Educa
-tion) suggested that OMB could establish a culture of innovation. For that 
to take place, the ICSP would be very important. In this respect, Eltinge 
observed that the statistical system cannot keep living off previous capital 
investments in innovation; it needs to make new investments in capital.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.40 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
Peter Meyer (Bureau of Labor Statistics) suggested a speci˜c incuba
-tor project: a Wikipedia type of website across the statistical agencies, 
which he called Statipedia. Such a website could be used to build a com
-mon online glossary of terms and to share experiences and knowledge. 
Thus, for example, computer source code and technical innovations could 
be shared across agencies. Barry Nussbaum was enthusiastic about the 
idea and offered cooperation in hosting the website.
Criteria for Successful Innovation
Ivan Fellegi identi˜ed three criteria for a successful research or inno
-vation program. First, such a program has to be directly linked to the 
operational activities of the agency, so that it is driven by acute issues 
of practice or by opportunities detected in practice. In addition to being 
directly linked, there needs to be distance between research and practice, 
and there also needs to be a balance between the independence of the 
research and its relevance.
He also offered comments on the ideas discussed in Habermann™s 
paper. He agreed with the crucial role of leadership for maintaining inde
-pendence while ensuring relevance. However, he thought that research 
centralized in one agency or in a federally funded research and develop
-ment center was going too far, because of the distance problem. He said 
that the research function would not be aware of the operational require
-ments and would not be relevant to the practice issues of the agency. 
Instead, Fellegi outlined four speci˜c steps that could be taken to 
foster innovation in statistical agencies:
1.
  
the bureaucratic barriers to ef˜cient and effective contracting and 
recruitment could be removed, with the lead to this taken by OMB;
2.
  
an organized marketing of the problems and opportunities of 
the federal statistical system to academic institutions could be 
undertaken; 
3.
  
case studies of successfulŠand unsuccessfulŠexamples of innova-tions could be compiled and disseminated; and 
4.
 progress could be measured periodically.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.5Next Steps
The last workshop session was devoted to possible next steps. The 
participants were invited to identify, in view of the previous discus
-sion, ways that innovation could play a more prominent role in the 
federal statistical system. 
OVERVIEWS
Katherine Wallman began the discussion with an overview of several 
important points made throughout the workshop discussions as well as 
her own views:













mis˜ts,ﬂ who can produce new ideas.












require major initiatives, as pointed out by Graham Kalton.






widely believed to be critical for future data collections, their use 
always seems to be a year away, as John Haltiwanger noted.











said, is a lack of ideas, and sometimes it is the inability to imple
-ment new ideas.


Thompson (National Opinion Research Center) noted; collabora
-tion is critical.
41
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.42 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM













-ent at the workshop to provide the necessary leadership and to 
follow through on the ideas discussed at the workshop.




leadership in eliminating bureaucratic barriers in contracting and 
recruitment.










-ulate academic work on federal statistical problems.













-ance on how to stimulate innovation.




















Edward Sondik followed Wallman™s overview with some ideas on 
next steps for the federal statistical system: 












be developed and disseminated.











federal statistical system could develop a joint federal statistics 
research agenda.


take the lead in developing a marketing program with academic 
institutions. 











culture in the federal statistical system.
Thomas Louis stressed the importance of accountability and agreed 
with others on the importance of a periodic review and evaluation of sta
-tistical programs. He also made the general comment that it is important 
for at least a subset of the agencies to work on speci˜c innovation projects 
while discussion proceeds on the larger issue of innovation in the federal 
statistical system. He stressed that he is not implying that innovation is 
not taking place, but perhaps the discussion today could lead to a differ
-ent angle to implementing innovation projects. For example, he suggested 
looking at innovation in an existing area, like seasonal adjustment, that 
proceeds from databases to tables and ˜gures with reasonably seamless 
connections. The project need not be a new procedure but an embodiment 
of many new changes. It is important for such a project to be examined by 
a variety of agencies to disseminate the lessons learned. 
Lawrence Brown (University of Pennsylvania) asked Hermann 
Habermann (Committee on National Statistics), who was charged with 
writing the summary of the workshop, what he had heard. Habermann 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.NEXT STEPS 43commented that this could be a seminal moment for the federal statisti
-cal systemŠan opportunity for the system to consider how it wants to 
pursue research and innovation. He noted that many participants favored 
some cross-cutting centralized research approach, although with each 
agency having the ability to retain local creativity and focus. In this con
-nection, he said, the statistical system could build on past successes of the 
Federal Committee on Statistical Methodology. He observed that many 
opportunities to encourage innovation had been suggested, such as the 
need to remove bureaucratic barriers to contracting and recruitment, but 
it is not clear that the system has the necessary will to follow through. 
Much of the remaining discussion focused on the importance of lead
-ership and the ICSP in particular, interagency efforts, and case studies 
and best practices.
LEADERSHIP
Jennifer Madans asked if the system would be able to use this work
-shop on innovation and create a more interactive statistical system. She 
noted that much of what had been discussed was under the purview of 
the ICSP and that it needed different ways of communicating. 
Groves said he supports the development of a system-wide research 
agenda that identi˜es common research problems, but he cautioned that 
addressing turf issues will be dif˜cult. He said that it probably would be 
necessary for the ICSP to explore legal and sustainable limits of collabora
-tion across agencies. 
Although she supports efforts to blur the traditional bureaucratic 
boundaries, Madans said that thought was needed to ensure that smaller 
agencies would not get gobbled up by some of the bigger agencies. 
INTERAGENCY EFFORTS
Marilyn Seastrom offered an example of concrete cross-agency inno
-vation, the Statistical Community of Practice and Engagement.
1 Mark 
Harris (National Agricultural Statistics Service) mentioned another exam
-ple, the Federal Committee on Statistical Methodology, although he noted 
that it is more involved with the documentation of best practices than 
with cutting-edge innovation. He pointed out that some of its projects 
have been incredibly productive as a result of the creativity and par
-ticipation of staff from many agencies. He also commented that often the 
1See http://www.apdu.org/conference/2010/Bianchi_APDUPresentation9-16-10.ppt#260,6, 
SCOP Goals = OMB Goals [February 2011]. SCOP was subsequently renamed SCOPE, Statistical 
Community of Practice and Engagement.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.44 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
problem with developing successful projects is not in getting the correct 
people, but in getting agencies to offer any people at all. 
Nathaniel Schenker (National Center for Health Statistics) mentioned 
the importance of transferring methods and techniques invented at one 
agency to others. Wallman asked how one can institutionalize the idea 
that interagency collaborative work is part of what is expected of statisti
-cal agency staff, rather than something extra that is not important to their 
jobs. 
John Eltinge emphasized the importance of ensuring that interagency 
initiatives resonate and be consistent with the mission of an agency™s 
department as well as appropriate congressional committees. In this con
-nection, he suggested that since selling risk and cost may be dif˜cult, the 
statistical system could consider framing initiatives as value added rather 
than as innovations.
In considering next steps to innovation, David Banks stressed the 
point made by Schenker about the importance of transferring innovative 
ideas from one agency to another. Nancy Gordon supported the concept 
but cautioned that to be successful it is necessary to deal with the ﬁnot 
invented hereﬂ syndrome.
CASE STUDIES AND BEST PRACTICES
Schenker returned to the idea of case studies and suggested that 
what is needed is a prestigious way to publish papers on case studies 
and innovative ways of using existing techniques. With respect to best 
practices, Roderick Little cautioned that best practices can be the opposite 
of innovation: a best practice may be considered the best thing to doŠso 
why try something else?
CLOSING
In his closing comments, Louis returned to the reason that innovation 
is critical for statistical agencies at this time. One of the important reasons 
is that the assumptions and models on which the statistical system was 
built are changing. He made the analogy that, at one time, ﬁBiostatistics 
Departmentﬂ was the equivalent of a brand name for all things in biosta
-tistics, but that is no longer true. This analogy holds for the federal statis
-tical system: it is no longer the only place where federal statistics is done 
in every sense. Increasingly, for example, there are other sources for data. 
He suggested that although it might not be a suf˜cient step, the system 
may ˜nd it necessary to elevate the amount and visibility of innovation 
and research to maintain its brand name in federal statistics.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.References
Advisory Committee on Measuring Innovation in the 21st Century Economy. (2008).
 In
-novation Measurement: Tracking the State of Innovation in the American Economy. 
A re
-port to the Secretary of Commerce. Available: http://www.innovationmetrics.gov/
Innovation%20Measurement%2001-08%20rev%20040908.pdf [May 2011].
Aizcorbe, A.M, Moylan, C.E., and Robbins, C.A. (2009). BEA brie˜ng: Toward better mea
-surement of innovation and intangibles. 
Survey of Current Business,
 January, 10-23.
Bianchi, R. (2010). 
The Horizontal Approach to Open Government Through Collaboration, Data 
Sharing, and IT Consolidation. Session on Innovations in Data Access, Dissemination, and 
Visualization. Association of Public Data Users 2010 Annual Conference, September 
20-21, U.S. Department of Agriculture Economic Research Service, Washington, DC. 
Blank, R. (2010). 
What Did We Learn About Gaps in Our Statistics During the Recent Recession?
 Presentation at the National Association for Business Economics Professional Develop
-ment Seminar, April 13, Arlington, VA.
Bradburn, N. (1999). The future of federal statistics in the information age. 
Journal of Of˜cial 
Statistics, 15
(3).
Brown, L. (2010). Science policy news: Envisioning the 2020 census. 
Amstat News, May, 29-31.
Dillman, D.A. (1996). Why innovation is dif˜cult in government surveys. 
Journal of Of˜cial 
Statistics, 12
(2), 113-124.
Fay, R.E. (2009). 
Why Is Survey Research 20 Years Behind?
 Section on Survey Research Meth
-ods, Joint Statistical Meetings. Available: http://www.amstat.org/sections/srms/
Proceedings/y2009/Files/303419.pdf [May 2011].
Gertner, J. (2010). The rise and fall of the GDP. 
New York Times Magazine,
 May 10, 60-71. 
Habermann, H. (2010a). 
Barriers to Innovation and Possible Remedies.
 Paper prepared for the 
Committee on National Statistics Workshop on Facilitating Innovation in the Federal 
Statistical System, June, National Research Council, Washington, DC. Available: http://
www7.nationalacademies.org/cnstat/Habermann%20Paper.pdf [May 2011].
Habermann, H. (2010b). The future of innovation in the federal statistical system. 
Annals 
of the American Academy of Political and Social Science, 631
(1), 194-203, Kenneth Prewitt 
special editor. 
45
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.46 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
Howell, K., and Yuskavage, R. (2010). BEA brie˜ng: Modernizing and enhancing BEA™s 
international economic accounts. 
Survey of Current Business,
 May, 6-20. 
International Monetary Fund. (2009). Balance of Payments and International Investment Position 
Manual, 6th Edition. 
Washington DC: Author.
Knapp, J. (1996). Measurement for the future: The vital role of statistics. 
Review of Business, 
17
(3-7).
Krueger, A. (2010). Stress testing economic data. 
Business Economics, 
April, 110-115.
Landefeld, J.S., Moulton, B.R., Platt, J.D., and Villones, S.M. (2010). GDP and beyond: Mea
-suring economic progress and sustainability. 
Survey of Current Business, 90
(April), 12-25.National Research Council. (2009). 
Principles and Practices for a Federal Statistical Agency, 
4th Edition
. Committee on National Statistics. C.F. Citro, M.E. Martin, and M.L. Straf 
(eds.). Division of Behavioral and Social Sciences and Education. Washington, DC: The 
National Academies Press. 
National Research Council. (2010). 
Envisioning the 2020 Census
. Panel on the Design of the 
2010 Census Program of Evaluations and Experiments. L.D. Brown, M.L. Cohen, D.L. 
Cork, and C.F. Citro (eds.). Committee on National Statistics. Division of Behavioral 
and Social Sciences and Education. Washington, DC: The National Academies Press. 
Parker, R.P. (2010). 
Challenges to the Federal Statistical System to Continue to Provide Data 
Relevant to Policy Issues. Paper prepared for the Committee on National Statistics 
Workshop on Facilitating Innovation in the Federal Statistical System, June, National 
Research Council, Washington, DC (revised draft, June 21). Available: http://www7.
nationalacademies.org/cnstat/Parker%20Paper.pdf [May 2011].
Spar, E. (2009). Challenges facing federal statistics in the United States. 
Amstat News,
 No
-vember.
Stiglitz, J.E., Sen, A., and Fitoussi, J.-P. (2009). 
Report by the Commission on the Measurement 
of Economic Performance and Social Progress
. Available: http://www.wikiprogress.org/
images/Stiglitz_Report.pdf [May 2011].
U.S. Census Bureau. (2009). 
Import and Export Low Value Estimation
. December 10. Available: 
http://www.census.gov/foreign-trade/aip/lvpaper.html [May 2011].
U.S. Census Bureau. (2011). 
Small Area Health Insurance Estimates Program
. February. Avail
-able: http://www.census.gov/did/www/sahie/index.html [May 2011].
U.S. Government Accountability Of˜ce. (2004). 
Informing Our Nation: Improving How to 
Understand and Assess the USA™s Position and Progress
. GAO-05-1. November 10. Wash
-ington, DC: U.S. Government Printing Of˜ce.
U.S. Government Accountability Of˜ce. (2006). 
Federal Information Collection: A Reexamination 
of the Portfolio of Major Federal Household Surveys Is Needed
. GAO-07-62. November 15. 
Washington, DC: U.S. Government Printing Of˜ce. Available: http://www.gao.gov/
new.items/d0762.pdf [May 2011]. 
U.S. Government Accountability Of˜ce. (2011). 
Key Indicator Systems: Experiences of Other 
National and Subnational Systems Offer Insights for the United States.
 GAO-11-396. March 
31. Washington, DC: U.S. Government Printing Of˜ce. Available: http://www.gao.
gov/new.items/d11396.pdf [May 2011]. 
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.Appendix A
Workshop Agenda
FACILITATING INNOVATION IN THE 
FEDERAL STATISTICAL SYSTEM
Tuesday, June 29, 2010
National Academies Keck Center, Room 100
500 Fifth Street, NW, Washington, DC
Abstract: This workshop is intended to generate a wide spectrum of 
views on the state of innovation in the federal statistical system and 
possible ways to facilitate innovation in areas that are important for the 
future of the system. Representatives from the statistical system and the 
academic and private sectors are being invited to sit at a central table, 
with room for attendees on each side. The intent is to have a free-˚owing 
set of discussions, which will be captured in a workshop summary to be 
widely distributed. Session I will focus on why innovation is necessary 
for the health of the federal statistical system and its ability to provide 
information for the public and decision makers. Session II will address 
areas in which innovation is not as well developed as would be desirable 
in terms of the cost, quality, timeliness, and relevance of federal statistics. 
Session III will address barriers to innovation and possible remedies. A 
panel will then discuss next steps in Session IV. 
47
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.48 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
8:30 am
 Welcome and Introductory Remarks
   Conference Overview 
   
ŠThomas Louis, Johns Hopkins School of Public 
Health, and Chair
   
Welcome on Behalf of CNSTAT and the National 
Academies
   
ŠConstance Citro, Director, Committee on National 
Statistics
  The Federal Perspective
   
ŠKatherine Wallman, Chief Statistician, U.S. Of˜ce of 
Management and Budget
9:00
  Session I:  The Importance of Innovation in Federal 
Statistics
  Chair:
  Thomas Louis, Johns Hopkins School of Public 
Health 
 Discussants:
   
Ron Bianchi, Economic Research Service, 
  U.S. Department of Agriculture 
   
Lawrence Brown, The Wharton School, University of 
  Pennsylvania (CNSTAT chair)  
   
Lynda Carlson, National Center for Science and 
  Engineering Statistics, National Science Foundation
   
Kevin Cecco, Statistics of Income Division, 
  Internal Revenue Service
   
John Haltiwanger, Department of Economics, 
  University of Maryland
   
Mark Harris, National Agricultural Statistics Service, 
  USDA (member, ICSP working group on innovation)
   
Brian Harris-Kojetin, Statistical and Science Policy 
  Of˜ce, Of˜ce of Management and Budget
   
Michael Horrigan, Bureau of Labor Statistics
   
Graham Kalton, Westat
   
Jennifer Madans, National Center for Health Statistics
   
Thomas Mesenbourg, U.S. Census Bureau
   
Sally Morton, Graduate School of Public Health, 
  University of Pittsburgh
   
Richard Newell, Energy Information Administration
   
Barry Nussbaum, Of˜ce of Environmental Information,
   U.S. Environmental Protection Agency 
   
Marilyn Seastrom, National Center for Education 
  Statistics
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.APPENDIX A 49   
Michael Sinclair, Bureau of Justice Statistics
   
Alan Zaslavsky, Department of Health Care Policy, 
  Harvard Medical School
10:00
  
Session II:  Scope of the Innovation Problem in Federal 
Statistics
  Chair:
  Thomas Louis, Johns Hopkins School of Public 
Health
 Discussants:
  See list for Session I
12:00 pm
 Lunch 
1:00
  Session III:  Barriers to Innovation and Possible 
Remedies
  Chair:  
Lawrence Brown, The Wharton School, University 
of Pennsylvania
 Discussants:
   
David Banks, Department of Statistical Science, 
  Duke University
   
Cynthia Clark, National Agricultural Statistics Service, 
  USDA
   
Manuel de la Puente, Of˜ce of Research, Evaluation, 
  and Statistics, USDA
   
Steven Dillingham, Bureau of Transportation Statistics
   
Emerson Elliott, National Council for Accreditation of 
  Teacher Education
   
John Eltinge, Bureau of Labor Statistics (member, ICSP 
  working group on innovation)
   
Ivan Fellegi, Statistics Canada (emeritus)
   
Robert Groves, U.S. Census Bureau
   
Stuart Kerachsky, National Center for Education 
  Statistics
   
J. Steven Landefeld, Bureau of Economic Analysis
   
Roderick J.A. Little, Department of Biostatistics, 
  University of Michigan
   
E.J. Reedy, Ewing Marion Kauffman Foundation
   
Allen Schirm, Mathematica Policy Research, Inc.
   
Ed Spar, Council of Professional Associations on 
  Federal Statistics
   
John Thompson, National Opinion Research Center at 
  the University of Chicago
   
Katherine Wallman, Statistical and Science Policy Of˜ce, 
  OMB
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.50 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
3:00
 Break
3:30
 Session IV:  Next Steps
  Chair:
  Katherine Wallman, Statistical and Science Policy 
Of˜ce, OMB
 Panelists:
   
Lawrence Brown, The Wharton School, University of 
  Pennsylvania
   
Thomas Louis, Johns Hopkins School of Public Health
   
Edward Sondik, National Center for Health Statistics
 General Discussion among discussants from previous session
4:30
  Concluding Comments
ŠThomas Louis and Constance 
Citro
5:00
 Adjourn
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.Appendix B
Workshop Attendees
1Heibatollah Baghi, George Mason University
David Banks, Department of Statistical Science, Duke University
Daniel Beckler, National Agricultural Statistics Service, U.S. Department 
of Agriculture
Vladislav Beresovsky, National Center for Health Statistics
Ron Bianchi, Economic Research Service, U.S. Department of 
Agriculture
Dara Blachman, Federal Interagency Forum on Child and Family 
Statistics
Chet Bowie, National Opinion Research Center at the University of 
Chicago
Norman Bradburn, National Opinion Research Center at the University 
of Chicago
Lawrence Brown, The Wharton School, University of Pennsylvania
Stephanie Brown, Energy Information Administration
Paul Bugg, Statistical and Science Policy Of˜ce, Of˜ce of Management 
and Budget
Verita Buie, National Center for Health Statistics
Maria Fe Caces, Of˜ce of National Drug Control Policy, Of˜ce of 
Management and Budget
Virginia Cain, National Center for Health Statistics
1Af˜liations are as of the time of the workshop (June 2010).
51
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.52 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
Lynda Carlson, National Center for Science and Engineering Statistics, 
National Science Foundation
Christopher Carroll, Council of Economic Advisers
Kevin Cecco, Statistics of Income Division, Internal Revenue Service
Korrine Chiu, U.S. Government Accountability Of˜ce
Asaph Young Chun, National Opinion Research Center at the 
University of Chicago
Kristen Cibelli, Of˜ce of Management and Budget
Constance Citro, Committee on National Statistics, National Research 
Council
Cynthia Clark, National Agricultural Statistics Service, U.S. Department 
of Agriculture
Michael P. Cohen, Bureau of Transportation Statistics (retired)
Steven Cohen, Agency for Healthcare Research and Quality
Lawrence Cox, National Institute of Statistical Sciences
Darryl Creel, RTI International
Frank (Les) Davis, Information Policy, Census, and National Archives 
Subcommittee, U.S. House of Representatives
William Davis, Social Security Administration
Manuel de la Puente, Of˜ce of Research, Evaluation, and Statistics, 
Social Security Administration
Kevin Deardorff, U.S. Census Bureau
Marshall DeBerry, U.S. Department of Transportation
Steven Dillingham, Bureau of Transportation Statistics
Ben Duffy, U.S. Census Bureau
Cheryl Eavey, Methodology, Measurement, and Statistics Program, 
National Science Foundation
Emerson Elliott, National Council for Accreditation of Teacher 
Education
 John Eltinge, Bureau of Labor Statistics
Suzann Evinger, Statistical and Science Policy Of˜ce, Of˜ce of 
Management and Budget
Trena Ezzati-Rice, Agency for Healthcare Research and Quality
Robert Fay, Westat
Elena Fazio, National Center for Health Statistics
Ron Fecso, U.S. Government Accountability Of˜ce
Ivan Fellegi, Statistics Canada (emeritus)
Dennis Fixler, Bureau of Economic Analysis
Joe Garrett, Knowledge Networks
Peter Gibson, U.S. Census Bureau
Nancy Gordon, U.S. Census Bureau
Deborah Grif˜n, U.S. Census Bureau
Robert Groves, U.S. Census Bureau
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.APPENDIX B 53Hermann Habermann, Committee on National Statistics, National 
Research Council
John Haltiwanger, Department of Economics, University of Maryland
Mark Harris, National Agricultural Statistics Service, U.S. Department 
of Agriculture
Brian Harris-Kojetin, Statistical and Science Policy Of˜ce, Of˜ce of 
Management and Budget
Ted Horan, Social Security Administration
Michael Horrigan, Bureau of Labor Statistics
Eva Jacobs, Bureau of Labor Statistics (retired)
Donsig Jang, Mathematica Policy Research, Inc.
Matt Jans, U.S. Census Bureau
Ron Jarmin, U.S. Census Bureau
Peter Jennings, Towson University
Graham Kalton, Westat
Alan Karr, National Institute of Statistical Sciences
Courtney Kennedy, Abt SRBI
Stuart Kerachsky, National Center for Education Statistics
Ruth Ann Killion, U.S. Census Bureau
Ellen Kramarow, National Center for Health Statistics
Karol Krotki, RTI International
J. Steven Landefeld, Bureau of Economic Analysis
Cheryl Landman, U.S. Census Bureau
Michael Larsen, George Washington University
Michael Lawrence, Biostatistics Center, Knowledge Networks
Daniel Levine, Westat
Roderick J.A. Little, Department of Biostatistics, University of Michigan
Thomas Louis, Johns Hopkins School of Public Health and Workshop 
Chair
Jennifer Madans, National Center for Health Statistics
Shelly Martinez, Statistical and Science Policy Of˜ce, Of˜ce of 
Management and Budget
Krisztina Marton, Committee on National Statistics, National Research 
Council
Linda McCaw, Social Security Administration
Pauline Mendola, National Center for Health Statistics
Thomas Mesenbourg, U.S. Census Bureau
Peter Meyer, Bureau of Labor Statistics
Albertha Mitchell, Social Security Administration
Susan Mitchell, RTI International
Dagmara Mocala, Council of Economic Advisers
Mary Moien, National Center for Health Statistics
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.54 FACILITATING INNOVATION IN THE FEDERAL STATISTICAL SYSTEM
Francisco Moris, National Center for Science and Engineering Statistics, 
National Science Foundation
Rebecca Morrison, U.S. Census Bureau
Sally Morton, Graduate School of Public Health, University of 
Pittsburgh
Jeri Mulrow, National Center for Science and Engineering Statistics, 
National Science Foundation
Richard Newell, Energy Information Administration
Terry Nuriddin, Statistics of Income, Internal Revenue Service
Barry Nussbaum, Of˜ce of Environmental Information, U.S. 
Environmental Protection Agency
Barbara O™Hare, U.S. Census Bureau
William O™Hare, Annie E. Casey Foundation
Maria Owings, National Center for Health Statistics
Jennifer Park, National Institutes of Health
Jennifer Parker, National Center for Health Statistics
Robert Parker, Consultant
Tom Petska, Statistics of Income, Internal Revenue Service (retired)
Steve Pierson, American Statistical Association
Adrienne Pilot, Council of Economic Advisers
Michael Planty, Bureau of Justice Statistics
Ricky Rambharat, U.S. Department of Treasury
Barbara Rawdon, U.S. Department of Commerce
Andrew Reamer, Brookings Institution
E.J. Reedy, Ewing Marion Kauffman Foundation
Ed Robison, Bureau of Labor Statistics
Judith Rowe, Princeton University (retired)
Adam Sa˜r, Bureau of Labor Statistics
Robert Sands, U.S. Census Bureau
Susan Schechter, U.S. Census Bureau
Nathaniel Schenker, National Center for Health Statistics
Allen Schirm, Mathematica Policy Research, Inc.
Kathleen Scholl, U.S. Government Accountability Of˜ce
Marilyn Seastrom, National Center for Education Statistics
Stephanie Shipp, Science and Technology Policy Institute
Howard Silver, Consortium of Social Science Associations
Michael Sinclair, Bureau of Justice Statistics
Darius Singpurwalla, Science and Technology Policy Institute
Monroe Sirken, National Center for Health Statistics
Edward Sondik, National Center for Health Statistics
Edward Spar, Council of Professional Associations on Federal Statistics
Tiffani St. Cloud, Association of American Medical Colleges
Marie Stetser, Of˜ce of Management and Budget
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.APPENDIX B 55Miron Straf, Division of Behavioral and Social Sciences and Education, 
National Research Council
Jennifer Tancreto, U.S. Census Bureau
Gloria Terrell, National Agricultural Statistics Service, U.S. Department 
of Agriculture
John Thompson, National Opinion Research Center at the University of 
Chicago
Clyde Tucker, Bureau of Labor Statistics
Ritu Tuteja, National Center for Health Statistics
Katherine Wallman, Statistical and Science Policy Of˜ce, Of˜ce of 
Management and Budget
Shawna Waugh, Energy Information Administration
Michael Weber, Statistics of Income, Internal Revenue Service
Daniel Weinberg, U.S. Census Bureau
Jennifer Whitaker, U.S. Census Bureau
Andrew White, National Center for Education Statistics
Adeline Wilcox, Department of Veterans Affairs
Diane Willimack, U.S. Census Bureau
Gooloo Wunderlich, Committee on National Statistics, National 
Research Council
Mandi Yu, National Institutes of Health
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.COMMITTEE ON NATIONAL STATISTICS
The Committee on National Statistics (CNSTAT) was established in 1972 
at the National Academies to improve the statistical methods and infor
-mation on which public policy decisions are based. The committee carries 
out studies, workshops, and other activities to foster better measures and 
fuller understanding of the economy, the environment, public health, 
crime, education, immigration, poverty, welfare, and other public policy 
issues.  It also evaluates ongoing statistical programs and tracks the statis
-tical policy and coordinating activities of the federal government, serving 
a unique role at the intersection of statistics and public policy.  The com
-mittee™s work is supported by a consortium of federal agencies through a 
National Science Foundation grant.
Facilitating Innovation in the Federal Statistical System: Summary of a WorkshopCopyright National Academy of Sciences. All rights reserved.