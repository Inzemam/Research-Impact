DETAILSDistribution, posting, or copying of this PDF is strictly prohibited without written permission of the National Academies Press.  (Request Permission) Unless otherwise indicated, all materials in this PDF are copyrighted by the National Academy of Sciences.Copyright © National Academy of Sciences. All rights reserved.THE NATIONAL ACADEMIES PRESSVisit the National Academies Press at NAP.edu and login or register to get:Œ  
Œ  10% off the price of print titles
Œ  Special offers and discountsGET THIS BOOKFIND RELATED TITLESThis PDF is available at SHARECONTRIBUTORS
http://nap.edu/10235Broadband: Bringing Home the Bits336 pages | 6 x 9 | PAPERBACKISBN 978-0-309-08273-0 | DOI 10.17226/10235Committee on Broadband Last Mile Technology, Computer Science andTelecommunications Board, National Research CouncilBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.Committee on Broadband Last Mile TechnologyComputer Science and Telecommunications BoardDivision on Engineering and Physical SciencesNational Research CouncilNATIONAL ACADEMY PRESSWashington, D.C.

Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.NATIONAL ACADEMY PRESS  2101 Constitution Avenue, NW  Washington, DC 20418NOTICE: The project that is the subject of this report was approved by the Governing Boardof the National Research Council, whose members are drawn from the councils of theNational Academy of Sciences, the National Academy of Engineering, and the Institute of
Medicine. The members of the committee responsible for the report were chosen for theirspecial competences and with regard for appropriate balance.The majority of the support for this project was provided by the Defense Advanced Re-search Projects Agency under contract No. N00174-99-C-0052 and the National Science Foun-dation under grant No. ANI-9908155. Additional support was provided by the Association
for Computing MachineryÕs Special Interest Group on Data Communication, Hewlett-Packard, Intel Corporation, Interval Research Corporation, WorldCom, Sun Microsystems,Texas Instruments, and Qwest. Any opinions, findings, conclusions, or recommendations
expressed in this material are those of the authors and do not necessarily reflect the views ofthe sponsors.International Standard Book Number 0-309-08273-0Additional copies of this report are available from:National Academy Press2101 Constitution Ave., N.W.Box 285Washington, DC 20418
800-624-6242202-334-3313 (in the Washington metropolitan area)http://www.nap.eduCopyright 2002 by the National Academy of Sciences. All rights reserved.Printed in the United States of AmericaBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.The National Academy of Sciences is a private, nonprofit, self-perpetuating soci-
ety of distinguished scholars engaged in scientific and engineering research, dedi-
cated to the furtherance of science and technology and to their use for the generalwelfare. Upon the authority of the charter granted to it by the Congress in 1863,the Academy has a mandate that requires it to advise the federal government on
scientific and technical matters. Dr. Bruce M. Alberts is president of the NationalAcademy of Sciences.The National Academy of Engineering was established in 1964, under the charter
of the National Academy of Sciences, as a parallel organization of outstandingengineers. It is autonomous in its administration and in the selection of its mem-
bers, sharing with the National Academy of Sciences the responsibility for advis-ing the federal government. The National Academy of Engineering also sponsorsengineering programs aimed at meeting national needs, encourages education
and research, and recognizes the superior achievements of engineers. Dr. Wm. A.Wulf is president of the National Academy of Engineering.The Institute of Medicine was established in 1970 by the National Academy of
Sciences to secure the services of eminent members of appropriate professions inthe examination of policy matters pertaining to the health of the public. The
Institute acts under the responsibility given to the National Academy of Sciencesby its congressional charter to be an adviser to the federal government and, uponits own initiative, to identify issues of medical care, research, and education.
Dr. Kenneth I. Shine is president of the Institute of Medicine.The National Research Council was organized by the National Academy of Sci-
ences in 1916 to associate the broad community of science and technology withthe AcademyÕs purposes of furthering knowledge and advising the federal gov-ernment. Functioning in accordance with general policies determined by the Acad-

emy, the Council has become the principal operating agency of both the NationalAcademy of Sciences and the National Academy of Engineering in providingservices to the government, the public, and the scientific and engineering commu-
nities. The Council is administered jointly by both Academies and the Institute ofMedicine. Dr. Bruce M. Alberts and Dr. Wm. A. Wulf are chairman and vicechairman, respectively, of the National Research Council.National Academy of SciencesNational Academy of Engineering
Institute of Medicine
National Research Council
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.vCOMMITTEE ON BROADBAND LAST MILE TECHNOLOGYNIKIL JAYANT, Georgia Institute of Technology, ChairJAMES A. CHIDDIX, AOL Time Warner
JOHN M. CIOFFI, Stanford University
DAVID D. CLARK, Massachusetts Institute of Technology
PAUL GREEN, Tellabs (retired)
KEVIN KAHN, Intel Corporation
RICHARD LOWENBERG, Davis Community Network
CLIFFORD LYNCH, Coalition for Networked Information
RICHARD METZGER, Lawler, Metzger & Milkman LLC
ELIZABETH MYNATT, Georgia Institute of Technology
ELI M. NOAM, Columbia University
DIPANKAR RAYCHAUDHURI, Rutgers University
BOB ROWE, Montana Public Service Commission
STEVEN S. WILDMAN, Michigan State UniversityStaffMARJORY S. BLUMENTHAL, DirectorJON EISENBERG, Senior Program Officer
DAVID DRAKE, Project Assistant
DAVID PADGHAM, Research AssistantBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.viCOMPUTER SCIENCE AND TELECOMMUNICATIONS BOARDDAVID D. CLARK, Massachusetts Institute of Technology, ChairDAVID BORTH, Motorola Labs
JAMES A. CHIDDIX, AOL Time Warner
JOHN M. CIOFFI, Stanford University
ELAINE COHEN, University of Utah
W. BRUCE CROFT, University of Massachusetts at Amherst
THOMAS E. DARCIE, AT&T Labs Research
JOSEPH FARRELL, University of California at Berkeley
JEFFREY M. JAFFE, Bell Laboratories, Lucent Technologies
ANNA KARLIN, University of Washington
BUTLER W. LAMPSON, Microsoft Corporation
EDWARD D. LAZOWSKA, University of Washington
DAVID LIDDLE, U.S. Venture Partners
TOM M. MITCHELL, WhizBang! Labs, Inc.
DONALD NORMAN, Nielsen Norman Group
DAVID A. PATTERSON, University of California at Berkeley
HENRY (HANK) PERRITT, Chicago-Kent College of Law
BURTON SMITH, Cray Inc.
TERRY SMITH, University of California at Santa Barbara
LEE SPROULL, New York University
JEANNETTE M. WING, Carnegie Mellon UniversityMARJORY S. BLUMENTHAL, DirectorHERBERT S. LIN, Senior Scientist
ALAN S. INOUYE, Senior Program Officer
JON EISENBERG, Senior Program Officer
LYNETTE I. MILLETT, Program Officer
CYNTHIA PATTERSON, Program Officer
STEVEN WOO, Program Officer
JANET BRISCOE, Administrative Officer
MARGARET HUYNH, Senior Project Assistant
DAVID DRAKE, Senior Project Assistant
JANICE SABUDA, Senior Project Assistant
JENNIFER BISHOP, Senior Project Assistant
DAVID PADGHAM, Research Assistant
BRANDYE WILLIAMS, Staff AssistantBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.vii
Since its inception, the Computer Science and TelecommunicationsBoard (CSTB) has examined how the nationÕs networked infrastructurehas been evolving. At the close of the past decade, the popular appeal of
the Internet was evident and growing, and with it the range and richness
of the uses to which the Internet might be put. The vision of a popular
Internet leads inevitably to thoughts about how people use it in their
homesÑand then to the arresting observation that most people get thebest possible access to the Internet from outside their homes, if they can
get it at all. That observation led CSTB to frame an assessment of broad-
band technologies in what the telecommunications industry has tradi-
tionally called the last mileÑthe link to homes (and small offices). Thisproject complements prior CSTB studies of the core of the networkÑthebackbone, the architecture, broad categories of applications, and specific
categories of networking technologyÑin its concern to (literally) bringnetworking home.The key questions about broadband technology in the last mile aredeceptively simple. First, what is feasible, technically and economically?
But feasibility is a nuanced quality: it is in the eye of the beholder, and
beholders differ considerably in terms of their assumptions and prefer-
ences. Those same conditions confound answering the second key ques-
tion: how can public policy foster dissemination of broadband in the last
mile? Many industries are involved in supplying broadband technology,
and their existence and strategies are already shaped by public policy.
And many outside those industries, trying to figure out what is going on,Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.viiiPREFACEhave their own views of what policy is or should be. Moreover, recentindustry trends, from mergers to business failures, feed speculation of all
kindsÑexcept for an expectation that broadband deployment will accel-erate. Thus, to have any claim to completeness, an assessment of broad-
band in the last mile must combine consideration of technology, econom-
ics, and law and policy.Accordingly, CSTB convened a committee of 14 people with expertisein the following areas: the different kinds of technology that could be
used in the last mile; the economics, law, and policy of the telecommuni-
cations and networked content industries; and trends in the home and
local use of various kinds of networks and their applications.1 The com-
mittee combined people with academic, other nonprofit, and commercial
experience, and it embraced both supply- and demand-oriented perspec-
tives. The committee met five times in plenary session and received exten-
sive input through briefings, a workshop, and solicited white papers. In
addition, it had two plenary conference calls and made extensive use of e-
mail and a private Web site for electronic exchange and deliberation.The committee thanks the many people who helped to make thisreport possible, although of course the responsibility for the final result is
its own.A number of individuals provided valuable information throughbriefings to committee meetings. Aubrey Bush and Rodger Ziemer of the
National Science Foundation (NSF) presented the charge to the commit-
tee. Dale Hatfield, then chief of the Federal Communications Commission
(FCC) Office of Engineering and Technology, and John Berresford, FCC
antitrust attorney, presented the range of telecommunications policy con-
cerns from a regulatorÕs perspective. Jeffrey Chester, executive director,Center for Media Education; Eugene Kimmelman, co-director, Consum-
ers Union; and Mark Cooper, director of research, Consumer Federation
of America, discussed concerns emerging from consumer advocates. An-
drew Sharpless, then senior vice president of interactive media at Discov-
ery Communications, described the perspective of an online content pro-
vider; David Kettler, then executive director and vice president of science
and technology with Bellsouth, and C. Lincoln (ÒLinkÓ) Hoewing, assis-tant vice president, Internet and Technology, Verizon, presented incum-
bent telephone company perspectives; William St. Arnaud, CANARIE,
Inc., described the Canadian experience and the larger opportunities in
local investment in deploying optical fiber; Milo Medin, chief technology
officer and senior vice president of engineering, Excite@Home Network,
discussed the cable industryÕs approach to Internet service and broad-1David Butler, who had recently retired from AOL at the time the study started, resignedfrom the committee for personal reasons in 2000.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.PREFACEixband deployment; Jorge Reina Schement, professor of telecommunica-tions and co-director of the Institute for Information Policy, Pennsylvania
State University, provided context for considering universal service is-
sues by describing the big picture of communications and information
consumption across different population segments; Ted Darcie, director,
AT&T Labs Research, analyzed the merits of different broadband tech-
nologies and explained AT&TÕs thinking about its choices; Douglas Sicker,FCC Office of Engineering and Technology, discussed perspectives on
DSL and HFC technologies; James Hannan, vice president of network
technology, Sprint Broadband Wireless, discussed wireless broadband;
James Stratigos, vice president and general manager of EchoStar Data
Networks, discussed satellite broadband; Kevin Lu, executive director of
the Integrated Access and Operations Department, Telcordia, discussed
fiber in the last mile; George Abe, venture partner, Palomar Ventures,
characterized venture capitalistsÕ view of investment opportunities; Tho-
mas G. Krattenmaker, senior counsel at Mintz Levin, outlined challenges
in thinking about regulatory options; Glenn Woroch, a University of Cali-
fornia at Berkeley economist, presented an economic model of asymmet-
ric regulation of the broadband race; Andrew Cohill, director of the Vir-
ginia Tech Communications Network Services and director of the
Blacksburg Electronic Village, outlined concepts for a comprehensive
municipal fiber plan; Richard Esposto, director of market activation, West-
ern Integrated Networks, discussed conditions and options confronting
local government, drawing on his immediately previous work of many
years with the Sacramento cable commission; Joseph Van Eaton, principal
partner with Miller & Van Eaton, discussed local franchises and licensing;
and Richard Civille, Washington director for the Center for Civic Net-
working, discussed economic development and aggregating demand for
rural telecommunications. Some of these individuals and a number of
other people provided white papers to the committee (these are available
online at <http://www.cstb.org> and are listed in Appendix C).This project owes its existence to the support of its sponsors, in thisinstance an unusually large and diverse group, reflecting combined pub-
lic and private interest in the topic. The majority of funds came from
government or nonprofit sources: the National Science Foundation, the
Defense Advanced Research Projects Agency, and the Special Interest
Group on Data Communication of the Association for Computing Ma-
chinery. Small contributionsÑfrom Hewlett-Packard, Intel Corporation,Interval Research Corporation, WorldCom, Sun Microsystems, Texas In-
struments, and QwestÑwere developed by members of the ComputerScience and Telecommunications Board, who recognized that without
those resources the project could not be undertaken. In view of the poli-
tics of broadband, it is important to note and emphasize that as is typicalBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.xPREFACEof CSTB projects, the sponsors enabled but did not influence the outcomeof the project. From among these, the consistent encouragement of NSFÕsAubrey Bush and members of CSTB are especially noted.CSTB committees are often assembled with experts from very differ-ent backgrounds, and this committee was certainly no exception. It is to
the credit of our distinguished members that they constantly derived
strength from the diversity in their team and realized an end result char-
acterized by a substantial, and in some ways unexpected, degree of con-
sensus. My thanks to each and every member of the team for their dili-
gence and commitment. On behalf of the team and myself, I extend special
thanks to David Clark, who played a major role in launching this study
and served as its Òvirtual co-chair,Ó contributing to and inspiring the
work of the committee on many occasions. The CSTB staff, by now well
known for its standards of broad excellence, performed once again with
supreme distinction. Thanks to D.C. Drake for facilitating our work in
every way possible and to Marjory Blumenthal for relentlessly challeng-
ing the committee to be comprehensive as well as creative, and finally,
many thanks to Jon Eisenberg for his role in anchoring the report of the
committee and for representing its work with remarkable timeliness and
sophistication.Nikil Jayant, ChairCommittee on Broadband Last Mile TechnologyBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.xi˘ˇ
This report has been reviewed in draft form by individuals chosen fortheir diverse perspectives and technical expertise, in accordance with pro-
cedures approved by the NRCÕs Report Review Committee. The purposeof this independent review is to provide candid and critical comments
that will assist the institution in making its published report as sound as
possible and to ensure that the report meets institutional standards for
objectivity, evidence, and responsiveness to the study charge. The review
comments and draft manuscript remain confidential to protect the integ-
rity of the deliberative process. We wish to thank the following individu-
als for their review of this report:Robert Broderson, University of California at Berkeley,Eugene Cacciamani, Hughes Network Systems,
Vincent Chan, Massachusetts Institute of Technology,
Andrew Cohill, Blacksburg Electronic Village and VirginiaPolytechnic Institute,David Kettler, H.I.G. Capital,
Tom Krattenmaker, Mintz, Levin, Cohn, Ferris, Glovsky and Popeo,P.C.,Milo Medin, Excite@Home,
Sharon L. Nelson, University of Washington Law School,
Andrew Odlyzko, University of Minnesota,
Paul W. Shumate, IEEE Lasers and Electro-Optics Society,
Marvin Sirbu, Carnegie Mellon University, and
David Waterman, Indiana University.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.Although the reviewers listed above have provided many construc-tive comments and suggestions, they were not asked to endorse the con-
clusions or recommendations, nor did they see the final draft of the report
before its release. The review of this report was overseen by Lewis
Branscomb, Harvard University (emeritus). Appointed by the National
Research Council, he was responsible for making certain that an indepen-
dent examination of this report was carried out in accordance with insti-
tutional procedures and that all review comments were carefully consid-
ered. Responsibility for the final content of this report rests entirely with
the authoring committee and the institution.xiiACKNOWLEDGMENT OF REVIEWERSBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.xiii!
ABSTRACT1
SUMMARY AND RECOMMENDATIONS5

1SETTING THE STAGE43
The Broadband Challenge, 43
Perspectives on Broadband, 45
A Brief History of the Communications Infrastructure, 47
From Promise to Broad Deployment: What Has ChangedSince the Mid-1990s?, 50Broadband Deployment Trends, 52
Reaching All Americans, 54
Access Economics and Evolving Applications, 57
Scope of This Report, 602WHAT IS BROADBAND?62
Why Define ÒBroadbandÓ?, 62Overview of the Technical Characteristics of Broadband, 65Speed, 65
Latency and Jitter, 67
Symmetry Between Upstream and Downstream Capacity, 67
Always-On, 69
Connectivity Sharing and Home Networks, 71
Addressability, 74Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.xivCONTENTSControls on Applications and Content, 75Implications of Network Design/Architecture, 77Approaches to Defining Broadband, 783BROADBAND APPLICATIONS AND CONTENT82
Broadband Applications: Promise and Reality, 82
Classes of Broadband Applications, 83Faster General Internet Access and General InternetApplications, 84Browsing and Related Activities, 84
Messaging, 85
Fast File Downloading, 85
Games, 87
Speed and Response-Time-Sensitive InternetApplications, 87Application Rental, 87
Network Storage, 88
Static Image Delivery, 88Audio, 89Audio Delivery, 89
Compression-Quality Trade-offs, 91
Specific Audio Applications, 93Video, 98The Mechanics of Video Delivery, 102
Telepresence, 103Telemetry, 105
New Kinds of Publishing, 105Peer-to-Peer Applications, 105
ÒLocal InterestÓ Content, Including Video, 107
Home Content Hosting, 107
Push Content, 109Multiplexing Applications Demand in Homes, 109Internet Appliances, 111
Distributed Work and Education, 112
ÒTele-webbing,Ó 113
Communities and Community Networks, 113Social Factors and Impacts of Broadband, 114Availability of Content, 114
Broadband Impacts, 116Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.CONTENTSxv4TECHNOLOGY OPTIONS AND ECONOMIC FACTORS120
Local Access Technologies in Context, 120
Essential Features of the Local Access Technology Options, 121Wireline Options, 122Hybrid Fiber Coax, 123
Digital Subscriber Line, 125
Advanced Wireline OfferingsÑFiber Opticsin the Loop, 129Powerline, 135
Wireline Roadmap, 136Wireless Options, 139Fixed Terrestrial Wireless, 139
Mobile Wireless, 142
Satellite, 144
Wireless Roadmap, 146The Diverse Technology Landscape, 148Layering and Unbundling, 149
Economics of Infrastructure Investment, 152Understanding Costs, 152
Take-Rate Tyranny, 153
Paying for Broadband, 155
Focus on the Consumer, 156
The Pace of Investment, 158
Investment, Risk Taking, and Timelines, 160Uncertain Investment Prospects in the PrivateSector, 161Investment Options for the Public Sector, 162MooreÕs Law and Broadband, 163Economics of Scaling Up Capacity: Congestion andTraffic Management, 1635BROADBAND POLICY AND REGULATION167
The Context for Broadband Policy, 167
Policy Implications of Technological Change, 171Regulation in the Face of Rapid Change, 171
Asymmetrical Regulation and Achieving TechnologyNeutrality, 174Competition, 177Unbundling and Resale Mandates, 180When Unbundling Works, 182
Implications for Investments by Incumbents, 184Facilities-Based Competition, 184
Structural Separation, 185Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.xviCONTENTSHow Much Competition Is Enough?, 186Assessing the Degree of Competition, 188
Open Access and Evolving Complements to Facilities-BasedCompetition, 189Access Issues in Multidwelling Units, 192
Access to Poles, Conduit, and Rights-of-Way, 193Expanding Access and Universal Service Policies, 194Rationales for Intervention, 194
Implicit Transfer Mechanisms Used for UniversalTelephone Service, 197Other Mechanisms for Increasing Access to Broadband, 200Loans and Grants, 200
Tax Incentives, 202
Vouchers, 203
Research to Develop Technology Alternatives, 204Looking Forward, 205The Local Role in Broadband, 206BIBLIOGRAPHY216

APPENDIXESABroadband Technologies245

BA Brief History of Telecommunications Regulation296

CList of White Papers Received307

DBiographies of Committee Members309

EList of Acronyms318
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.1
This report examines the technologies, economics, policies, and strat-egies associated with the broadband challenge (the Òfirst mileÓ or Òlast
mileÓ high-speed connectivity problem, depending on oneÕs perspective)
and makes recommendations aimed at fostering broadbandÕs deployment
and use. Following roughly a decade of development and experimenta-
tion and a recent period of rapid growth, first-generation broadband ser-
vices, using primarily cable modems and digital subscriber line (DSL), are
available in many markets. This progress is offset by recent business fail-
ures and uncertainty about the pace of future investmentÑfactors that in
part reflect slow growth in subscriptions for broadband services. Today,
dial-up connections over the public telephone network remain the domi-
nant way homes and small businesses connect to the Internet or other
online services. Broadband, though, not only provides higher-perfor-
mance options for connecting to familiar Internet and other online ser-
vices, but its capacity and Òalways-onÓ nature also enable new network-
based activities. Together, these capabilities promise significant social and
economic benefits. The Computer Science and Telecommunications Board
initiated this study in an effort to understand the hows and whys of
broadband deployment and use.The Committee on Broadband Last Mile Technology found thatbroadband should be defined in a dynamic and multidimensional fash-
ion, and it offers two complementary approaches to characterizing what
constitutes broadband service: (1) local access link performance should
not be the limiting factor in a userÕs capability for running todayÕs appli-
cations, and (2) broadband services should provide sufficient perfor-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.2ABSTRACTmanceÑand wide enough penetration of services reaching that perfor-mance levelÑto encourage the development of new applications. Thesedefinitions reflect the central Òchicken-and-eggÓ conundrum: an applica-
tion will not be made available unless a sufficient number of subscribers
have broadband connections with performance high enough to support
the application, yet service providers will not invest in higher-perfor-
mance broadband until they know that there will be sufficient demand
for the service. Residential broadband capabilities today, with speeds typi-
cally ranging from several hundred kilobits per second to several mega-
bits per second downstream and several hundreds of kilobits per second
upstream, support familiar applications such as Web browsing, e-mail,
messaging, interactive games, and audio download and streaming. The
next performance plateau, which is not widely available at present, pro-
vides downstream speeds of several tens of megabits per second, thus
enabling new applications such as high-quality streaming video or rapid
download of full-length audiovisual files. With the addition of compa-
rable upstream speeds, computer-mediated multimedia communications
Ñto enable more effective telecommuting and distance education, forexampleÑbecome possible. Fiber-to-the-home (FTTH) would offer thehighest performanceÑgigabit speeds both up- and downstream. Invest-ment in FTTH has lagged other options because of costs and uncertainty
about demand for its capabilities. Some investment currently is providing
opportunities for experimenting with technology alternatives and appli-
cations and for learning about demand. At the same time, a variety of
wireless options provide either cost-effective alternatives (especially for
remote locations) to wireline or mobility and ubiquity that complement
wireline technologies.Development, deployment, and adoption will be an ongoing processthat works through several mechanisms: incremental upgrades and
reallocation of capacity in existing broadband infrastructure, improved
end equipment that permits faster performance over the existing infra-
structure, and installation of new infrastructure. These improvements may
or may not require new technology, but all require investment premised
on market demand and willingness to pay. Indeed, many factorsÑnotsimply technologyÑwill shape the pace and distribution of broadbanddeployment.While broadband is sometimes characterized in terms of a horse racebetween DSL and cable and between the incumbents that use these tech-
nologies, the committee believes that the long term will be technologically
diverse, reflecting geographical and market variation, the maturity of and
experience with different technologies, topography, and the condition of
existing infrastructure. Because local conditions vary, broadbandÕs avail-ability will be quite uneven, especially in the earlier stages. The natureBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.ABSTRACT3and number of competitors will vary considerably by geographical loca-tion: from areas able to attract noÑor only oneÑincumbent terrestrialprovider (likely an incumbent local exchange carrier or cable operator) to
easier-to-serve, higher-demand areas likely to attract one or more facili-
ties-based providers in addition to the incumbents. This variability and
flux will be troublesome to industry, regulators, and policy makers alike,
implying that provider strategy and government intervention will have
to change over time as the market and services evolve.The present policy framework for broadband, which revolves aroundthe Telecommunications Act of 1996, is problematic and is unsuited in
several respects to the new era of broadband services. Although it does
not explicitly recommend revision of the act (or comment on contempo-
rary legislative proposals), the committee anticipates such examination
and is cognizant that implementation of some of its recommendations
would require revisions to either legislation or implementing regulation.
The committeeÕs recommendations, outlined and condensed below (com-plete versions are presented in the Summary and Recommendations chap-
ter of this report), are intended as principles to guide broadband policy
over the next several years:¥Prioritize widespread deployment and defer new regulation in the earlystages. Presupposing how broadband services and markets will evolve
risks misjudgment regarding outcomes and strategies. Wider broadband
availability (in the context of other recommended measures) will help
stimulate new applications, which will help increase demand, which will
in turn make deployment, upgrade, and new market entry more attrac-
tive. At the same time, government should enhance its monitoring of
deployment, investment, use patterns, and market outcomes to provide a
firmer foundation for any future action. The familiar goals of universal
access to important capabilities and consumer satisfaction remain, but the
knowledge of how best to achieve them in a broadband world must be
developed. There is sufficient time to observe and analyze as deployment
and use unfold and to defer measures that could result in a premature
stall in investment.¥Structure regulation to emphasize facilities-based competition and en-courage new entrants. The policy goal, simply put, should be to increase the
extent of competition through facilities ownership (and voluntary busi-
ness arrangements to open facilities) rather than through long-term reli-
ance on mandated unbundling. It is reasonable to maintain existing rules
for unbundling existing telephone copper plant facilities. But unbundling
rules should be relaxed in exchange for investment in new facilities that
can broaden service availability and/or increase performanceÑsubject toappropriate mechanisms to address extensions of market power. SomeBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.4ABSTRACTlocales will not see facilities-based competition, and competition in someareas will change; both situations present policy challenges. Where un-
bundling is warranted, particularly with respect to new facilities, logical
layer unbundlingÑunbundling at a higher service-level of communica-tion, as in cable open accessÑshould be preferred in the long run tophysical unbundling because it promises technical advantages and ad-
ministrative ease.¥Take active steps to promote deployment and facilities-based competition,including at the local level. The degree of competition and prevalence of
technology options will vary by region, state, and municipality. Federal
rules should continue to bound the range of outcomes, but in many cases,
local decision making based on local conditions and needs is appropriate.
Various sorts of incentives and local arrangements, detailed in this report,
can encourage broadband deployment. While a few communities have
already undertaken broadband initiatives, the majority have not and
could benefit from efforts to enhance local capacity. The committee rec-
ommends supporting planning grants for localities to explore options;
providing cost-sharing for field trials, including local-government-spon-
sored initiatives; and establishing a national clearinghouse to raise aware-
ness, provide technical assistance, and disseminate best practices for local
and regional efforts to accelerate broadband deployment.¥Support research and experimentation. Government should support
research and experimentation that would foster the emergence of new
competitors; increase understanding of economic, social, and regulatory
factors; and spur the development of new content and applications that
would make broadband more compelling and useful and foster growth in
demand and use. Many of the conditions evident today reflect current
technologies, business models, and policy interventionÑall of which aresubject to change. Research is valuable for creating new options and low-
ering costs, and it should be pursued vigorously across both technical and
nontechnical arenas.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.5
INTRODUCTIONBroadband is a means to multiple, diverse ends encompassing family,work, and society generally. In addition to enabling entertainment and
e-commerce applications, broadband can enrich the InternetÕs exploita-
tion as a public space, making electronic government, education, and
health care applications richer and more compelling and useful, and it
can provide new modalities for communication, notably within commu-
nities or families. Broadband commands attention because it enables dra-
matically different patterns of use that offer the potential for significant
changes in lifestyle and business.This report from the Computer Science and TelecommunicationsBoardÕs Committee on Broadband Last Mile Technology examines the
technologies, policies, and strategies associated with broadband local ac-
cess connectivity (often referred to as the Òfirst mileÓ or Òlast mileÓ prob-
lem, depending on oneÕs perspective) and makes recommendations aimed
at fostering its deployment. The committeeÕs findings and recommenda-
tions are confined to broadband in the United States and focus largely on
broadband for residences (with some discussion of broadband for small
businesses and broader connectivity issues for communities).Broadband service to the home depends on high-speed data trans-mission across local access facilitiesÑthe communications links and re-
lated hardware that connect the premises and the rest of a telecommuni-
cations network, most notably between the home or small business and
the set of interlinked data networks that make up the Internet. TheseBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.6SUMMARY AND RECOMMENDATIONSfacilities fall into two categories: (1) existing facilities built by an incum-bent telephone or cable company for the purpose of delivering voice or
cable TV service and (2) new facilitiesÑsuch as fiber optic cable, wireless,or satelliteÑconstructed specifically for the purpose of delivering broad-band. Before broadband, dial-up connections over the public telephone
network were the dominant way in which homes were connected to the
Internet or other online services. The performance of these modem con-
nections has reached a plateau defined by the bandwidth of telephone
circuit switches (more than 50 kilobits per second [kbps] under optimal
conditions, but possibly less depending on factors such as line, interior
wiring, and modem quality), and further improvements have required
new technology approaches.At present, two access technologies that leverage existing infrastruc-tureÑdigital subscriber line (DSL) and hybrid fiber coax (HFC; or cablemodem)Ñare maturing, as evidenced by wide availability, industry stan-dards, multiple product vendors, volume pricing, and deployment expe-
rience; othersÑsuch as terrestrial wireless and fiber-to-the-home (FTTH)Ñare being developed and deployed on a smaller scale. The range oftechnology options captures part of what makes broadband vexingÑfi-ber promises maximum bandwidth; wireless offers pervasiveness, flex-
ibility, and potentially faster deployment; and satellite offers nationwide
coverage (albeit with some gaps and limited total capacity). Today, DSL
and HFC are most prominent, shape consumer experience, and fuel much
of the politics that surrounds broadband. Looking forward, as other tech-
nologies such as fiber and wireless surmount cost and other deployment
barriers and become more pervasive in residential broadband, providers,
consumers, and policy makers alike will face new issues.The committeeÕs work started in late 1999 and was completed in fall2001, a period encompassing significant broadband deployment and both
boom and bust in the telecommunications and Internet markets. Until
recently, only universities and large businesses and organizations had
high-speed Internet access, reflecting a favorable economic return on in-
vestment in providing service to these customers. In contrast, residences
and small businesses (and smaller offices of larger organizations) have
been less likely to attract investment. Also, many homes are relatively
distant from neighboring homes or are connected today by hard-to-up-
grade telecommunications infrastructure, and some are in remote loca-
tionsÑall factors that entail higher per-premises costs and inhibit deploy-ment.Following roughly a decade of development and experimentation,residential (and small business) broadband services have been available
in selected markets for several years and more recently have become
mass-market. Cable operators, incumbent local exchange carriers (ILECs),Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS7and competitive local exchange carriers offering data services (dataCLECs) have been the largest players, complemented by overbuilders
(using HFC, wireless, or fiber) and satellite-based providers. The past
couple of years have been a period of dramatic growth in broadband
deploymentÑby summer 2001, more than 8 percent of U.S. householdswere subscribers to broadband service (only a comparative handful had
service in 1999). Mid-2001 data also indicate that broadband-capable cable
systems reach roughly 60 million households and that a substantial frac-
tion of telephone company central offices support DSL (DSL availability
for individual customers is subject to line-to-line variability). At the same
time, many communities, especially smaller or more remote ones, lack
broadband today, and some households in communities with general
availability cannot obtain service owing to particular conditions (e.g., tele-
phone line condition or length, or residence in a multidwelling unit with-
out broadband).The study period has also been marked by deployment difficulties.There have been numerous reports of poor customer service in terms of
both installation delays and poor operational reliability, with charges and
countercharges as to whether the data CLECs or incumbents were re-
sponsible for reported difficulties and delays in establishing DSL service.
The 2001 wave of CLEC bankruptcies and shutdowns called into question
the unbundling strategy contemplated in the Telecommunications Act of
1996.If the committee had completed its work in mid-2000, it might wellhave done so with a rosier assessment of prospects for investment, the
strength of broadband overbuilders and competitive local exchange carri-
ers, and so forth. In formulating its recommendations, the committee was
mindful of how much the situation had changed just during the course of
its work and of how these changes underscore the perils of basing policy
on short-term trends (either positive or negative).Broadband deployment has been the subject of scrutiny by legisla-tors, regulators, communities, the computing industry, and the public at
large, and a number of potential barriers have been noted by these groups.
Political attention has escalated along with that devoted to the Internet;
like the Internet, broadband is linked to social and economic benefits.
With sustained improvements in the InternetÕs core and in network con-nectivity within many businesses and other organizations, the last mile to
residences and small enterprises has come to be viewed by some as a
critical bottleneck. Key questions include these:¥What is broadband?¥Why do people need it?¥How much demand is there for broadband?Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.8SUMMARY AND RECOMMENDATIONS¥How important and urgent is deployment of broadband?¥What is the likely shape of broadband deployment in the comingyears?¥Is the pace of deployment reasonable and adequate, or are therefailures that necessitate intervention?¥How will broadband deployment be paid for?¥How might the present policy regime for broadband be made moreeffective?The multifaceted and dynamic future anticipated by the committee inthe findings and recommendations below will be troublesome to regula-
tors and policy makers. This future implies that different forms of inter-
vention will be required in different geographical regions; that interven-
tion should change over time as players enter and leave the market and as
the working definition of broadband changes (which could change the
number of real options); and that problems will arise, given the typical
slow pace of the policy-making process. Finally, the ebb and flow of com-
petition will inevitably lead to claims and recriminations of predatory
pricing, obstructionist incumbents, partial regulation, and so on. The re-
mainder of this summary presents the committeeÕs key findings and rec-ommendations with respect to these vexing questions.While implementing some of the committeeÕs recommendationswould require changes to the Telecommunications Act of 1996, many
would not. Viewing the actÕs provisions as only one of a number of factorsshaping broadband deployment, the committee believes that revision of
the act or associated regulation is not critical at present, but that changes
in light of the realities of broadband will become increasingly important
over time. At the same time, the committee has not shied away from
making recommendations simply because they would be inconsistent
with the provisions of the present act. Further, the committee anticipates
that in view of the public spotlight enjoyed by broadband, there will be
multiple efforts to change the act itself as well as to undertake more
evolutionary changes within the actÕs framework. Rather than commenton the merits of any particular pending legislation (the committee is ex-
plicitly not doing this), the committee offers its recommendations as
guidelines, as broadband policy evolves over the next several years.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS9FINDINGSFinding 1. Broadband Is a Convergent Platform Capable ofSupporting a Multitude of Applications and Services.Although the term ÒbroadbandÓ can be used to refer to other services,
such as digital television, that are not necessarily carried using Internet
technology, the main focus of this reportÑand the issue of most interestto service providers, consumers, and policy makers alikeÑis broadbandInternet connectivity. Although broadband is often associated with par-
ticular facilities or transmission technologies used for its implementation,
it is a more general concept. With convergence, everythingÑvideo, au-dio, text, and so forthÑhas become a digital stream that can be trans-ported across the Internet. Taken together with the InternetÕs layereddesign, this phenomenon makes broadband Internet a platform that is
capable of supporting many different types of applicationsÑthe familiare-mail, World Wide Web, games, audio, and video; new applications not
yet in widespread use; and applications yet to be invented. The InternetÕsdesign also permits broadband Internet to be run over many different
types of communications linksÑDSL, HFC, fiber, wireless, and so forth.At present, however, such services as television and telephony are differ-
ent products employing distinct facilities.The convergent nature of broadband will permit, if not foster, indus-try convergence and consolidation across traditional industry lines
Ñcabletelevision and telephone service are viewed today as separate markets,
but the distinction will make less sense over time. Convergence is a poten-
tial enabler of competition: with multiple broadband providers that com-
pete in terms of performance and services, users can switch providers to
find the most attractive combination of price and performance. A stove-
piped policy environmentÑin which different rules apply to broadbandservices depending on whether they are provided using cable, public
telephone network, wireless, or other technologiesÑwill come under in-creasing pressure. Technology trends suggest another mismatch between
present policy and the nature of broadband services. To obtain greater
performance, access networks will likely converge on similar architec-
tures in which fiber reaches close to premises, and high-speed coax, up-
graded DSL, or wireless links connect to the premises themselves. An-
other option is for fiber to be run all the way to the premises. In either
case, treating different ÒflavorsÓ of broadband under disparate regulatory
regimes becomes more problematic.While the similarities are more important than the differences, thereis a complicating factor: the capabilities of broadband services based on
different access technologies will vary somewhatÑe-mail is possible overBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.10SUMMARY AND RECOMMENDATIONSalmost any sort of link (though the experience will be better over a fasterlink), while high-quality video streaming demands a high minimum
speed. The higher ultimate capacity and lower cost associated with pro-
viding high downstream capacity mean that the cable operators using
HFC would have an easier time entering the telephone market than ILECs
would have delivering high-quality video over present-generation DSL,
and the latency inherent in geosynchronous satellite services makes them
less suitable for telephony, videoconferencing, or games that require low
transmission delays. More generally, access technologies have cost and
performance trade-offs that vary across different deployment scenarios.Finding 2. Broadband Should Be Defined in aDynamic and Multidimensional Fashion.Policy makers and others have struggled to come up with reasonabledefinitions of broadband (versus narrowband), and many groups have an
interest in such definitions. Broadband definitions are important for moni-
toring progress in deployment at the national, state, or local level. Defini-
tions are also an important component of specific policies, such as eligibil-
ity for tax credits or compliance of providers with build-out mandates.Broadband development, deployment, and adoption should beviewed as an ongoing process that works through several mechanisms:
incremental upgrades in the broadband infrastructure, reallocation of ex-
isting capacity to broadband, improved end equipment that permits faster
performance over the existing infrastructure, and installation of new in-
frastructure. TodayÕs first-generation broadband technology is not theend point in terms of performanceÑwhat is considered broadband todaywill not be viewed as broadband in the future, much as 300-baud modems
appear inadequate compared with todayÕs 56-kbps modems. Upgradesmay or may not require the development of new technologies, but all
require investment premised on market demand and willingness to pay.
Much like dial-up, which went through a succession of upgrades until it
reached the limits imposed by the capacity of telephone switches, broad-
band has launched a new cycle of incremental upgrades and opportuni-
ties for yet more new infrastructure deployment. Unlike dial-up, for which
the carrier and the Internet service provider (ISP) were distinct and up-
grades required only new modems at each end, broadband requires more
extensive upgrades to facilities and terminal equipment.An examination of local access technologies on the horizon, othercomputing and communications capabilities, and potential applications
makes apparent several quantitative performance and application clus-
ters. TodayÕs residential broadband capabilities, which are typified byBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS11several hundred kilobits per second to several megabits per second down-stream and several hundreds of kilobits per second upstream, support
such applications as Web browsing, e-mail, messaging, games, and audio
download and streaming. At downstream speeds of several tens of mega-
bits per second, new applications are enabled, including streaming of
high-quality video, download of full-length (70- to 90-minute) audiovi-
sual files in tens of minutes rather than hours, and rapid download of
other large data files. Reaching this plateau would enable true televisionÐpersonal computing convergence. With comparable upstream speeds,
computer-mediated multimedia communications become possible, in-

cluding distance education, telecommuting, and so forth. With FTTH, a
new performance plateau with gigabit speeds both up- and downstream
would be reached; what applications would take full advantage of this
capacity remains to be seen.This interplay between technology capabilities and application re-quirements is captured in a more general fashion by the two complemen-
tary approaches to defining broadband presented below.¥Broadband Definition 1. Local access link performance should not be thelimiting factor in a userÕs capability for running todayÕs applications.For example, todayÕs typical Web browsing is not significantly im-proved by speeds in excess of 1 megabit per second (Mbps) because of
speed-of-light limits on round-trip travel time across the Internet. In other
words, upgrading a userÕs 1-Mbps link with one 10 times faster would notspeed up the transfer of a typical Web page. To take another example: for
streaming media, increasing local access performance significantly above
the rate at which such content is typically streamed today would not
improve the userÕs experience (though, per definition 2, increased capa-bilities would help spur higher-quality streams).¥Broadband Definition 2. Broadband services should provide sufficientperformanceÑand wide enough penetration of services reaching that performance
levelÑto encourage the development of new applications.Capacity improvement and application innovation are tightly coupledin a Òchicken-and-eggÓ fashion: an application will not be made available
until a critical fraction of subscribers receives a high enough level of per-
formance to support it, yet service providers will not deploy higher-per-
formance broadband until there is sufficient demand for it. The perfor-
mance of a broadband service should, therefore, be good enough and
improve sufficiently to facilitate this cycle and not impede it. Definition 2Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.12SUMMARY AND RECOMMENDATIONSalso implies a broadband penetration threshold effect: enough users musthave a higher-performance service to create a sufficiently large market to
attract application developers.Two different notions underlie these definitions. Under definition 1,the presumption is that existing applications and capabilities of the rest of
the network will be unleashed by improvements in the local access seg-
ment. The presumption of definition 2 is that application innovation will
materialize if performance constraints are eased. The implications of defi-
nition 2 are familiar todayÑcurrent broadband service offerings do notprovide high enough performance to support applications such as high-
quality video, while investment in higher performance awaits demonstra-
tion of demand and willingness to pay. The parties demanding improved
performance include, along with segments of the public, applications de-
velopers and content suppliers that see the potential for new markets that
they might serve (but for the availability of more bandwidth) and policy
makers who project potential social and economic benefits that would
result from deployment of higher-performance service.While bandwidth is the most significant performance parameter interms of enabling new applications, others are also important. ÒAlwaysonÓÑa characteristic of almost all broadband services todayÑis impor-tant to enabling certain types of applications. It changes the way in which
people experience broadband as a service. Symmetry, which refers to the
relative down- and upstream bandwidths, also has implications for the
types of applications that are supported. Some applications, such as Web
browsing, make modest demands on the upstream channel as they re-
quire receipt of much less data than they transmit, while others, such as
videoconferencing, require more symmetric bandwidth. Delay affects the
performance of time-sensitive applications, notably, applications such as
telephony and online games that involve real-time interactions with
people.Finding 3. Demand for Broadband Is Evident.In the United States, some form of broadband is reportedly now avail-able to more than half of U.S. households, and subscription rates grew
rapidly during the period from 1999 to 2001. Penetration has been much
higher than the average in markets where broadband has been available
for several years. For example, in Portland, Maine, an early test market for
Time Warner Cable, about one-quarter of households are cable modem
subscribersÑa mass market that illustrates the appeal of broadband wellbeyond a handful of early adopters. Similarly, in the current worldwide
leader, Korea, where favorable conditions have already made broadband
available to much of the population, broadband subscription rates areBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS13reported to be even higher: more than one-quarter of households. In theUnited States, numerous anecdotal reports of frustration about delays in
obtaining broadband service, reliability problems, and nonavailability all
support a view of a rising tide of demand and use (as well as problems).
These developments indicate that broadband access is valued by a broad
base of Internet users, not just a small group of technology lovers, and
that broadband is viewed as an important communications service. At
present, it is difficult to forecast what the ultimate total Òtake-rateÓ will
be, though the 1990s penetration of personal computers (PCs) and Internet
service to roughly half of U.S. households suggests growth at least up to
this level.Notably, todayÕs demand level has been based mainly on a limited setof applications (e-mail, Web browsing, file sharing, and limited audio and
video streaming). Indeed, there is a significant gap between the capabili-
ties of current broadband services and some of the cutting-edge applica-
tions that have been touted but are not generally available to the public.
Continued growth in demand for higher-speed services can be foreseen
based on applications being used or tested by early adopters in enterprise
and campus networks, experimental initiatives in both industry and aca-
demia, and the possibilities afforded by increasingly cheap home net-
works and specialized consumer electronics. With new applications,
wider penetration, and broadbandÕs use as a convergent platform formultimedia content delivery, much wider demand and use can occur.Finding 4. Deployment as a National and Local ImperativeToday, broadband is for the most part an adjunct to home PC use anda means of faster Web browsing, and narrowband alternatives provide
some measure of access to commonly used content and services. Thus,
one cannot say with confidence today that broadband access in the home
is critical to being a functioning member of society. But in light of robust
demand and the likelihood that with growing use, new content and appli-
cations will make use of broadband capabilities, it is reasonable to project
that broadband will take on increasing socioeconomic importance in the
future.There are several principal arguments for taking steps to foster broad-band deployment:¥Spillover benefits. Because broadband can support many different
types of applications and services, its full potential is unlikely to be appar-
ent from scrutiny of any one category. When one looks at a promising
individual application today, such as telework, it is easy to see that what
existsÑin terms of capabilities, use, or benefitsÑfalls short of what someBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.14SUMMARY AND RECOMMENDATIONShave forecast. But what broadband promises, because of its capacity andgeneral-purpose nature, is the chance to try multiple applications of dif-
ferent types and to provide various mixes that can be valuable to different
users. The economic and social benefits in the aggregate will, therefore,
exceed those of one application, giving rise to spillover benefits not readily
captured by any one stakeholder. For example, broadband deployed for
mass entertainment can also carry noncommercial content. To the extent
that broadband providers themselves are not able to fully capture the
benefits of investment in performance enhancements, a broader societal
interest in promoting broadband performance improvements arises from
these spillover benefits. The willingness of broadband providers to invest
will be less than that implied by the broader societal interest arising from
these spillover effects.¥The link between performance and applications innovation and ties toother high-technology sectors. If broadband is to support new, rich multime-dia applications, the gap between computing and deployed last mile com-
munications performance will have to be closed. In the short term, this
would translate into upgrading from todayÕs hundreds of kilobits persecond to tens of megabits per secondÑwhich all of the present genera-tion of wireline broadband technologies can support, with appropriate
investment (shorter loop lengths in the case of DSL and smaller cluster
sizes and/or more spectrum dedicated to broadband in the case of HFC),
and which is well within the capabilities of FTTH. Although the perfor-
mance of broadband services today nearly always exceeds that available
through dial-up access, the first-generation systems frequently provide
only modest improvements in speed over older technology, and sustained
upgrades would be needed to satisfy both broadband definitions 1 and 2.¥Per-passing costs of initial investment. Some infrastructure costs must
be borne regardless of how many customers in a given area actually sub-
scribe to a service. Because of the major, even dominant, role of these
per-passing costs for wireline infrastructure, investment becomes, in es-
sence, a decision contingent on a finding of collective demand. For wire-
less, the penalty can be somewhat but not fully offset via a strategy
whereby the cluster size served by a common feed is decreased as rates of
subscription and demand increase. (A similar principle also applies to
wireline technologies that permit such clustering, such as HFC, but with
less impact on the per-passing costs than is the case for wireless.) Also,
early adopters will not be able to obtain broadband service until a service
provider decides to make an investment deemed capable of attracting a
broad subscriber base. As a service provided over a network, broadband
stands in marked contrast with computers, which individual consumers
can purchase as the need arises, and which providers produce for a mar-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS15ket not tied to a geographic area. Similarly, an individual can upgrade to ahigher-performance computer to meet individual demand, whereas broad-
band services will tend to have capabilities aimed at the average user.The committee took note of the fact that other countries, recognizingthese arguments and the potential societal importance of broadband, have

opted for more active strategies than those of present U.S. policy or those
that the committeeÕs recommendations below would contemplate, espe-cially at the national level. These national strategies in other countries do
not match the U.S. context, in terms of political system, the historical
private sector role in telecommunications, geographic diversity and popu-
lation dispersion, or the nature of the existing telecommunications infra-
structure. That is not to say that the goals and means of these strategies
are not appropriate in their own contexts.Finding 5. Many Factors Pace Deployment.There is a sense in some quarters that something is ÒbrokenÓ with
respect to broadband rollout. There are several areas of frustration: con-
cerns over an insufficient rate of penetration of some form of broadband;
associated concerns that some areas will end up being left out; concerns
that the process of upgrading broadband service could stall, leaving con-
sumers with only the performance offered by first-generation technology;
concerns about business failures leaving customers with no broadband
alternative; and concerns that the quality of what is being deployed will
be inadequate in terms of performance, reliability, or customer service.
Given the realities of the situation, what is reasonable to expect with
respect to deployment?Finding 5.1. Broadband deployment will not occur overnight.The rapid evolution of some aspects of the Internet can lead observersto think that if something does not happen within 18 months, it will not
happen. But the phenomena associated with deployment cycles measured

in months have generally been in the non-capital-intensive software arena
(even here, real change may lag perception), in a sector unconstrained by
regulatory uncertainty. In contrast, even with a conservative estimate of
$1,000 as the average cost of wiring an individual residence, the total cost
of building new broadband infrastructureÑsuch as rewiring to provideFTTH to all of the roughly 100 million U.S. householdsÑwould be $100billion. A major portion of this figure is in construction costs that are not
amenable to dramatic cost reductions. Even for cable and DSL, where
delivering broadband is a matter of upgrading existing infrastructure,Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.16SUMMARY AND RECOMMENDATIONSeconomics constrain the pace of deployment. Some broadband deploy-ment will be accomplished as part of the conventional replacement and
upgrade cycles associated with telephone and cable systems, but provid-
ing broadband also requires additional investment in infrastructure up-
grades and broadband-specific equipment. In either new builds or incre-
mental improvements, an accelerated pace of deployment and installation

will be associated with an economic opportunity cost.The bottom line is that broadband deployment and upgrading aregated by a complex policy and economic context, not justÑor even mainlyÑby technology. Furthermore, it is early in the diffusion process, and toosoon to judge the final outcome. Thus, todayÕs frustrations do not neces-sarily justify heavy-handed intervention.Finding 5.2. The investment rate depends critically on theperspective and time horizon of the would-be investor.For an owner of existing facilitiesÑthe incumbent local exchange car-riers and cable multiple system operatorsÑrealistic investment is incre-mental, builds on the installed base, and must provide return on a rela-
tively short timescale. An incremental strategy also reflects the view that
there is not sufficient demand for the added bandwidth of all-fiber re-
placement to justify its greater capital costs compared with those for an
upgrade of existing plant.Once a provider has a broadband-capable system, that provider willspend on upgrades only enough to continue to attract subscribers and
retain existing customers by providing a sufficiently valuable service. An
incumbent will also naturally weigh the benefits of investment in new
services against the costs of cannibalizing from existing ones. For ex-
ample, an ILECÕs incentive to invest in broadband upgrades may be di-minished by the prospect that the new technology may be used to provide
services that compete with the ILECÕs existing voice and data services.Viewing an incumbentÕs incentives to invest in upgrades from the per-spective of the two broadband definitions provided above, it may be hard
for the incumbent to justify spending so that the local access link is not the
performance bottleneck, or to be in front of the demand so as to stimulate
new applications. Facilities-based competition, and associated pressures
to attract and retain customers, could help propel performance upgrades.Two types of nonincumbent investor have also entered the broad-band market, tapping into venture capital that seeks significant returnsÑand generally seeks a faster investment pace. One is the competitive local
exchange carrier (CLEC), which obtains access to incumbent local ex-
change carrier facilities (central office colocation space and the lines run-
ning from there to each subscriber) to provide broadband using DSL. TheBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS17other is the overbuilder, which enters a market by building its own, newfacilities (most commonly, HFC for residential subscribers, but also ter-
restrial wireless or fiber). Companies may also combine these strategies.
Satellite broadband providers in essence overbuild the entire country (or
regions thereof through spot beams), although with the capacity to serve
only a fraction of the total number of households, and with a cost struc-
ture different from that of terrestrial providers. The drying up of Internet-
related venture capital that occurred in 2000-2001Ñand the associatedfailure of several CLECsÑsignals difficulties in sustaining deploymentefforts.In addition to providing financial incentives for private sector invest-ment, the public sector can complement and stimulate private sector ef-
forts by making long-term investments in infrastructure that ease market
entry and foster competition among broadband providers. Such invest-
ment is most likely to occur at the state, regional, or local level, although
federal support can play an important role. But decision making for such
investments is not a simple matter, and, if present trends are any indica-
tion, such investments will be confined to those locales that project the
greatest returns from accelerated access to broadband, possess a greater
inclination for a public sector role in entrepreneurship, and are best
equipped to navigate a complex set of choices.Finding 6. The Shape of Broadband DeploymentWhile the long-term outcome of broadband deployment is certainlynot clear, the characteristics of the technologies and related economic
factors do permit the overall shape of deployment to be predicted with
some confidence in the short term.Finding 6.1. The broadband vision is rapidly evolvingand is linked to the Internet and computing.Broadband is related to several classes of telecommunications ser-vicesÑsome stable (telephony), some somewhat stable (entertainmenttelevision), and one that is evolving rapidly (the Internet and associated
developments in computing, embedded information technology, and
wireless communications). Telephony and television exist in useful forms
today without the need for a new generation of access technology, which
suggests that the real driver of the broadband vision is the Internet and
the associated computing milieu. The future form of the Internet itself is
quite uncertain, with the current market downturn injecting possible un-
certainty into the overall cycle of investment and the perception of overall
value and utility, which suggests a need for caution when making predic-
tions. BroadbandÕs linkage to the Internet suggests that broadband willBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.18SUMMARY AND RECOMMENDATIONSchange more rapidlyÑand less predictablyÑthan what was experiencedas telephony and television developed.Finding 6.2. Current trends appear to be able to sustaindeployment over the next several years, but beyond that point
the outcome is less evident.Substantial deployment of broadband has already taken place, andboth cable operators and ILECs appear to have a commitment to continue
along this path (though the pace may be affected by the investment cli-
mate, consumer demand, and competitive forces). Significant cost reduc-
tions in equipment as mature broadband technologies have reached the
mass market are another positive indicator. These factors suggest that
infrastructure and business may be robust enough to permit widespread
deployment and sustained performance improvements. However, pen-
etration may fall short of universal access, investment in additional facili-
ties may or may not occur, and investment in performance improvements
may stall.Finding 6.3. Broadband is not a horse race among technologies.While popular accounts tend to focus on which technology or playersare ÒaheadÓ in broadband deployment, broadband is not a horse race
among technologies, with an eventual winner. The long-term outcome
will be diversity in technology options, for several reasons:¥Location matters. The United States is very heterogeneous in many
dimensionsÑdensity and dispersion of population, demographics, topog-raphy, and condition and age of infrastructureÑand it is not reasonableto expect Òone size to fit all.Ó Technology diversity promotes greater ubiq-
uity of service, as cable systems fill in where DSL cannot reach today, for
example.¥Continuing incremental investment in existing infrastructure. Becauseof investor expectations for short-term return on investment, incumbents
will continue to make use of existing equipment and plant and the incum-
bentsÕ deployment will be based on incremental upgrades.
¥Continued exploitation of technology skills. Companies possessing par-ticular expertise will exploit opportunities where these skills give them an
advantage. For example, designing, launching, and operating a satellite
system all require know-how very different from that required to up-
grade a cable or telephone system.¥Varying levels of technology maturity. Before wide-scale deployment,technologies must undergo an extensive development process to reduce
the costs of components, installation, and management. More mature tech-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS19nologies will see wider deployment at the same time that less maturetechnologies are being developed in test markets.Looking forward, the following trends are apparent for the varioustechnology options:Cable and DSL. Incremental investment building on existing technologybases will continue, together with some investment in new facilities when
the right conditions exist. Particularly in denser urban and suburban ar-
eas, wireline broadbandÑHFC and DSLÑis being utilized successfully,albeit with some growing pains. The incumbents (both ILECs and cable
system operators) have considerable advantage, because wireline tech-
nologies have in common that the labor of installing the line is a signifi-
cant cost component. Since there is no obvious way to decrease these costs
dramatically, options that require investment in new wireline infrastruc-
ture are at a disadvantage. Also favoring the incumbents are their existing
customer base and other revenue sources. There have, nonetheless, been
efforts in more attractive markets to overbuild the incumbents to permit
new players to enter the broadband (and associated cable TV or tele-
phone) markets.Fiber-to-the-Home. Given its potentially enormous capacity, format ver-satility, and long lifetime, FTTH is a logical technology end point (comple-
mented by wireless where mobility is desired). Already, fiber is being
driven closer to user premises as part of routine improvements to the
public telephone network, cable systems, and wireless base-station feeds,
and the technology evolution paths for both DSL and HFC rely on fiber
optic links that reach closer and closer to the premises. For new installa-
tions, the total life-cycle costs of a fiber-based infrastructure are, generally
speaking, lower than those for other wireline alternatives because of
fiberÕs long life and because it lends itself to architectures that have nointermediate electronics (which would require periodic maintenance and/
or upgrade) in the path between premises and point of presence. The
advantages of FTTH are offset by two cost penalties: (1) instead of lever-
aging existing wireline plant, a provider incurs the cost of installing new
fiber optic cables (and, depending on the architecture, splicing the cable)
and (2) at present, the terminating equipment is more expensive, reflect-
ing the cost of the optoelectronics and todayÕs lower product volumes.The costs of terminating equipment can be expected to drop as the tech-
nology is engineered for mass deployment and production volumes in-
crease. Because they ultimately are tied to the cost of labor, fiber instal-
lation costs are less susceptible to cost reduction, but there have been
advances in splicing equipment, and a variety of techniques have beenBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.20SUMMARY AND RECOMMENDATIONSproposed to reduce fiber installation costs in particular situations (includ-ing creative ways of exploiting existing rights-of-way).Meanwhile, there is considerable scope for incremental gain from allaccess technologies and a great deal of inherent capacity in HFC (because
of coaxial cableÕs very large theoretical bandwidth). Also, a gap currentlyexists between the capacity of FTTH links and the capacity of typical links
to the Internet core, which means that with FTTH deployment, the capac-
ity bottleneck is simply pushed upstream (except for applications that
rely only on local bandwidth). Pervasive deployment of fiber to the pre-
mises thus awaits investor belief that the necessary demand exists, a leap
of faith that the demand will emerge once very bandwidth-intensive ap-
plications take hold, or a long-term investment horizon. FTTH will be
more attractive where there is either no existing infrastructure or where a
provider opts to compete with the incumbents by providing a very-high-
capacity alternative. FTTH is being used in green-fields developments, in
some community-based initiatives, and by a few overbuilders in small-
scale deployments. As a general rule, FTTH will be deployed when a
combination of economics, demand, and capabilities (compared to alter-
natives, including the infrastructure already in place) justifies the invest-
ment.Wireless. Wireless technology offers mobility and the most flexible de-ployment scenarios. In the shorter term, satellite and fixed wireless are
being used to support market entry by providers that lack wireline assets.
Fixed wireless may also offer a longer-term residential broadband option,
especially in less densely populated areas or areas able to support a larger
number of facilities-based competitors, and satellite has an obvious niche
in reaching remote areas. To reach the most remote few percent of U.S.
households, the high fixed cost of building and launching satellites is
offset by low per-passing costs. While so-called third-generation (3G)
wireless will provide more capabilities than present systems do, the
throughput per user falls short of a reasonable definition of broadband.
Wireless local area networking technology using the IEEE 802.11b stan-
dard is beginning to emerge as an alternative model for untethered broad-

band access in public places (using both commercial and noncommercial
models). Looking forward, advances such as robust multicarrier modula-
tion and space-time processing with antenna arrays will benefit wireless
across the boardÑnot only higher-performance fixed wireless, but alsoenhanced mobile cellular systems, which offer ubiquity and mobility, and
wireless local area networks (LANs), which provide complementary ÒlastmetersÓ access. Wireless is expected to continue to lag wireline in band-
width, but its greater flexibility, anticipated performance improvements
that would make it Ògood enoughÓ for many applications, and the equip-
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS21ment cost reductions that come from reaching mass-market volumes canmake it a long-term competitor.Finding 6.4. There will be substantial geographicalvariation in the nature of competition.Diversity in technology will be accompanied by diversity in the com-petitive landscape, with different degrees of ÒnaturalÓ competition
Ñcom-petition that is facilities-based or that occurs through voluntary business
arrangements with facilities owners. With broadband, local conditions
are very important, and the distribution of broadband availability will be
quite uneven, especially in the earlier stages. No matter what regulatory
approaches are applied (short of policy embracing a single monopoly
provider), all of the following outcomes are likely to occur in one or
another region of the United States:¥Type 0Ñno terrestrial providers of broadband. This situation is not
uncommon today despite significant deployment, but it can be expected
to become less common as the near-ubiquitous public telephone and cable
networks are upgraded to support broadband. There is no region of the
lower 48 states that entirely lacks service today, because some form of
satellite-based broadband is possible wherever the user is able to install
an antenna dish with line-of-sight view of the satellite (albeit with cost
and performance inferior to what would be possible with access through
alternative technologies if they were to be available).¥Type 1Ñone terrestrial facilities-based provider in the area (e.g., cable butnot DSL, or vice versa). This common circumstance will diminish to theextent that the incumbent telephone companies and cable operators both
expand their broadband coverage. It will persist where the market is
perceived to be large enough to support the first entrant but not large
enough to attract a second incumbent provider.¥Type 2Ñtwo terrestrial facilities-based providers. This will be a com-
mon long-term outcome. The incumbent telephone and cable provider
will both upgrade to support broadband, but no other provider will enter
the market. One or both may choose to support multiple higher-level
service providers such as Internet service providers. Alternatively, one of
the incumbents and an overbuilder (using wireline or wireless technol-
ogy) could provide broadband service.¥Type 3Ñone or more facilities-based providers that install new infra-structure to compete with the incumbents. This has occurred in limited fash-ion so far, with companies such as RCN overbuilding with HFC, and
Sprint and WorldCom overbuilding with terrestrial wireless in selected
markets. The financial viability of type 3 competitionÑand prospects forBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.22SUMMARY AND RECOMMENDATIONScompetition beyond that offered by the incumbent telephone and cablecompaniesÑwill be tested over the next few years.Finding 6.5. The vitality of the CLEC industry is in doubt,but the source of apparent troubles is uncertain.In 2001, the vitality of the data CLEC industry, which has providedbroadband retail competition in a number of markets, came into doubt.
Charges and countercharges were made as to whether the CLECs or in-
cumbents were responsible for reported difficulties and delays in estab-
lishing service, a number of Federal Communications Commission (FCC)
proceedings were held on the matter, and fines were assessed against
ILECs. The possibility that incumbent-deployed technology (such as fi-
ber-fed remote terminals) might complicate or preclude copper loop un-
bundling added an element of uncertainty. A wave of CLEC bankruptcies
and outright shutdowns disrupted service and left some consumers with-
out any broadband alternative. It is unclear whether the CLECsÕ apparent
woes were due to the better engineering and operational practices of the
incumbents, to unrealistic undercapitalization, intrinsically flawed busi-
ness models, poor management, anticompetitive practices, failures of their
business partners, or insufficient added value relative to the incumbent,
or to some combination of these factors. Where this alternative no longer
exists, there is less price pressure on ILECs offering broadband and one
less option for access to alternative ISPs.Finding 6.6. Unlike the underlying communicationstechnologies, the capabilities of deployed broadband
are not on a MooreÕs law-like curve.Unfavorable comparisons are sometimes made between sustained im-provements in the performance-to-price ratio of computing and lagging
improvements in the capacity of broadband local access links. From this
perspective, and consistent with broadband definition 1 above, local ac-
cess links are a bottleneck. The communications technologies themselves
Ñmost notably, ongoing improvements in fiber optic transmission speedsÑhave in fact kept pace with or surpassed improvements in computing.The gap that exists is between deployed access technology and computing
technology, reflecting economic considerations rather than an inherent
mismatch.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS23Finding 7. The Relationship Between Broadband and Content andApplications Businesses Is Critical and Is in Flux.TodayÕs debate over ISP access to cable broadband systems puts aspotlight on a more general possibility that is motivated by a range of
factorsÑthat increased ties between communications technologies andthe content and applications that run over them could result in an Internet
that is balkanized (even as the industry consolidates), is less open in
character, or is less supportive of application and service innovation. Past
experience with content-conduit relationships suggests a range of pos-
sible long-term outcomes for broadband. Telephony has long followed a
common carrier model in which content and conduit have been cleanly
separated. Cable operators today have considerable control over the con-
tent carried by their systems. Such content-conduit ties are cited as a
source of financial strength; cable-unique services helped fuel the
industryÕs growth beyond its community antenna television roots. Theseties are also associated with business and regulatory complications.With dial-up Internet access, the ISP and phone carrier are separateentities; customers are free to select from among a wide array of ISPs.
Internet connectivity is usually understood to mean access to the full
range of content and applications available via the Internet, though there
are ISPs offering services ranging from full connectivity to delivery of
comprehensive, proprietary content and services. The availability of ser-
vices offering full connectivity, together with ISP diversity, has been an
enabler of experimentation with new applications and services. Going
forward, broadband Internet service providers have a choice of offering
full, unrestricted connections to the Internet or evolving toward a more
defined package of services (using Internet technology). In the early days,
when the business side was still developing and the user base was smaller
and generally more sophisticated, users expected to be able to do any-
thing with their Internet connection, services were geared more toward
these users, and with a few exceptions, the ISPs were not strongly differ-
entiated in terms of the content or services they provided. When cable
operators started offering broadband, they opted to do so through exclu-
sive ISPs, more recently evolving to offer a set of ISP choices.Today, the provider industry is more mature (and more consolidated,especially in broadband), users are not all technology-savvy, and provid-
ers are becoming more sophisticated about consumer behavior and about
how to make money. ISPs are seeking opportunities for additional rev-
enue streams by bundling additional services, establishing preferred con-
tent and services (even restricting access to particular content and ser-
vices), and defining tiered services. These factors all suggest the rise of
alternatives to traditional Internet access that offer a more limited, de-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.24SUMMARY AND RECOMMENDATIONSfined set of content and services that could change the fundamental na-ture of the Internet as experienced by consumers. While consumers may
differ in their preference for one type of service or another, it would
represent a significant shift in the communications landscape if they were
to lose the option of full, open Internet broadband connectivity. Volun-
tary measuresÑand those adopted in order to obtain permission for merg-ersÑhave given cable broadband customers some choice of ISP and thusdecreased restrictions on access to Internet content. These responses to
critics may address concerns about the potential market power of facili-
ties owners, but their effectiveness remains unproven.RECOMMENDATIONSThe present policy framework for broadband, which revolves aroundthe Telecommunications Act of 1996, is problematic and is unsuited in
several respects to the new era of broadband services. The significance of
broadband data communications was appreciated in general terms by
some of the key players that shaped the act (and is reflected in multiple
sections of the act dealing with advanced services), but the central role of
the Internet (and the rapid rise in popularity of applications running over
the Internet, such as the World Wide Web) in the communications land-
scape was not fully anticipated. Framed before the Internet was fully
commercial, the Telecommunications Act of 1996 devotes much of its
attention to the voice telephony market and maintains distinct rules for
the various communications networks (telephone, cable, cellular, broad-
casting, and so on). To stimulate competition, the act employs both facili-
ties-based competition, in which providers compete head-to-head using
their own facilities, and unbundling, in which incumbent telephone com-
panies are required to provide network elementsÑmost notably, the cop-per lines that run from the central office to each subscriberÑto competi-tors at regulated prices.Recommendation 1. Prioritize Widespread Deployment and DeferNew Regulation in the Early Stages.The committee is mindful that there is a tension between permittingprivate sector deployment of broadband to proceed without any hin-
drance from government intervention and societyÕs desire to guide theoutcome. Decision makers will have to balance the inevitable calls to
shape broadband toward some particular end against the ÒnaturalÓ tra-
jectory defined by user preferences, private sector investment, and the
market. The committeeÕs specific, pragmatic strategic preference is to pro-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS25mote broad deployment relatively quickly and to foster facilities-basedcompetition.Recommendation 1.1. Avoid present-day policy making that is basedon presumptions about the final form of broadband markets.Some forms of intervention to expand access could deter investmentfrom taking place at all, which suggests prioritizing widespread though
not universal deployment over addressing access gaps early on. Because
government intervention may affect private sector investment decisions,
it should be undertaken with great care in this nascent area in order to
avoid unintended consequences. Also, resolving the chicken-and-egg di-
lemma depends on broadband reaching some critical level of penetration
if new content and applications are to take off. Once a mass market is
achievedÑwhich brings with it prospects of new applications and busi-ness opportunitiesÑthere is a likelihood that demand and willingness topay will increase, which in turn may attract new players to provide com-
petition, and decrease the need for regulation. Also, learning more about
the nature of consumer desires and the shape that the technology and
associated markets ÒnaturallyÓ take will help inform the policy debate. Itis, for example, premature to conclude that facilities-based competition is
or is not feasible in many locations. As the shape of broadband deploy-
ment starts to become clearer, a firmer basis for broadband policy will be
in place.Recommendation 1.2. Complementary to favoring policiesfacilitating rapid deployment over intervention, develop and
implement enhanced monitoring of deployment, investment,
and market outcomes and develop metrics to permit independent
evaluation and rating of performance.The committee acknowledges that the approach reflected in Recom-mendation 1.1 is different from that of others who advocate increased
early attention to ensuring access to all or who argue that it is essential to
shape the behavior of incumbents (telephone or cable) or to otherwise
regulate the competitive environment early on. There is, indeed, some
risk that if facilities-based competition does not materialize, the commit-
teeÕs recommendations could lead to a stagnant scenario in which incum-bents face little competition and deploy and upgrade broadband services
slowly. Thus, attention should be paid to distribution and performance
variations as well as to overall rates of deployment. It is also essential for
regulators to watch for undesirable outcomes that would have long-term
consequencesÑmost notably, abuse of market power. Monitoring wouldBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.26SUMMARY AND RECOMMENDATIONSprovide a basis for distinguishing between unrealized concerns and ac-tual provider behavior, and would help inform public debate about the
need for possible regulatory intervention.Detailed data on market penetration are hard to gather, inconsistentlydescribed, and often proprietary. Likewise, it is difficult to acquire solid
data or assess commercial claims about costs and markets. To monitor the
shape of broadband deployment and refine policy responses, govern-
ment at all levels needs a consistent picture of data on total market pen-
etration, the extent of competition, and other key indicators of future
trajectories. Since national averages tell very little about variation in levels

of local competition, these data must be gathered at a fine grainÑevencommunity by communityÑand they must be updated on a regular basis.At this point in the deployment of broadband, when the mature formof the market has not emerged, it is more important to watch for signs that
the market is not serving important policy goals than to predict the final
outcome now. These concerns suggest the following as key indicators to
track:¥What percent of the population is situated in what sorts of competitivecontextÑregions of type 0 through 3? Which of these regions are expandingand contracting over time?¥For different applications, is the performance perceived by the consumerimproving or deteriorating? This is a measure of whether, by broadbanddefinition 1, services available are actually broadband. Sound metrics of
performance and means of monitoring their trends would have to be
developed and agreed to.¥Are new applications that depend on high bandwidth emerging? If they
do not, it would be an indication that by broadband definition 2, the
services being deployed are not broadband.¥How effective are emerging alternatives to formal regulation? Open ac-
cess policies aim to limit the market power of incumbents (both local
exchange carriers and cable operators) in providing broadband services,
reflecting concerns that facilities-based competition may not provide a
robust alternative in all circumstances and that incumbentsÕ ability to
leverage past monopoly status should be bounded. Existing unbundling
and resale rules require incumbent local exchange carriers to provide
would-be competitors with access to the local loop, so public attention to
open access has focused mainly on cable system operators. The year 2001
saw the development of a potential template for the industry as a whole:
conditions on the AOL-Time Warner merger, which were agreed to by the
Federal Trade Commission, were developed in the face of significant pres-
sures to block the merger. Ongoing scrutiny of that industry, such as that
to be carried out by the appointed monitor of the AOL-Time WarnerBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS27merger, is needed, to determine if emerging alternatives to formal regula-tion will prove adequate.¥Is subscriber access to certain Internet content or services being blockedor impaired (as compared with other content)? The open access issue is one
manifestation of a broader question of the extent to which nondiscrimina-
tory access to Internet content and services will continue with a shift to
broadband. Impairment of subscriber access in any industry segment
would be an indication of undesirable consequences arising from vertical
integration of content and broadband communications businesses.Recommendation 2. Structure Regulation to EmphasizeFacilities-Based Competition and to Encourage New Entrants.Recommendation 2.1. In the long term and in the case ofinvestment in new facilities, policies should favor facilities-based
competition over mandated unbundling.Current regulation of the ILECs contemplates three forms of competi-tionÑ(1) facilities-based competition, (2) competition enabled via unbun-dling of ILEC network elements, and (3) competition through resale of
ILEC services. In facilities-based competition, providers rely substantially
on their own local access facilities rather than on local access facilities
owned and operated by other providers (a facilities-based provider might
make use of backhaul links from other providers). Unbundling, in which
ILEC network elements are made available to would-be competitors at
regulated prices, was initiated as part of the 1996 telecommunications
actÕs attempt to stimulate competition in both the local and long-distancemarkets and to reflect the advantages of scale and scope enjoyed by ILECs.
For cable operators, the only access requirements have arisen in the con-
text of mergers and acquisitions. Current regulation is ambivalent and
sometimes ambiguous as to which is the preferred approach.Per the taxonomy presented in Finding 6.4, the policy goal with re-spect to competition, simply put, should be to increase the prevalence of
type 3 conditions in place of type 2, shift type 1 conditions to type 2, and
so on. Increasing the extent of competition through facilities ownership
(and voluntary business arrangements to open facilities) rather than re-
lying on regulation that mandates unbundling is important for several
reasons:¥It reduces the need for persistent regulatory intervention. Until there are
effectively competitive facilities-based alternatives to the incumbent mo-
nopolist, full deregulation is very unlikely to come about, and there will
be a continued need to regulate such things as the terms and conditions of
access to incumbent unbundled elements.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.28SUMMARY AND RECOMMENDATIONS¥It permits the natural (i.e., competition-shaped) character of broadbandservice and industry structure to be discerned. This helps define an end-pointgoal for regulation in those regions where competition is less robust.
Otherwise, since broadband cannot be precisely defined without learning
much more about consumer preferences and the shape of the market
where consumers have a real choice, regulators could strive toward the
wrong outcomes.¥It promotes diversity. Facilities-based competition better supportsdiversity in both the technology base (which makes broadband more
adaptable to changing user needs and circumstances) and more diversity
in types of cost structures (which makes broadband more robust in the
face of changing business circumstances).¥It avoids deterring competitors from investing in their own infrastruc-ture. While unbundling is often offered as a stepping-stone to facilities-based competition by providing a revenue stream to a start-up firm, it can
also inhibit facilities-based competition by reducing the incentives for
competitors to build new facilities (or upgrade existing ones).¥It removes a disincentive to new investment by incumbents. To the ex-
tent that the unbundling requirements are extended to new network ele-
ments deployed by incumbents to offer advanced services, such as fiber-
connected remote terminals, it is a disincentive for investment by the
incumbent in such enhanced facilities, because the incumbent cannot cap-
ture all of the benefits of its investment. In making this observation, the
committee is not necessarily accepting at face value ILECsÕ assertions that
their investment decisions are driven chiefly by unbundling requirements
when there are other plausible explanations (such as the benefits of not
having to face the threat of CLEC competition or pressures for financial
results). Nonetheless, the incentive level is critical, especially if invest-
ment is to occur in lower-density or poorer areas where the business case
may be less attractive.¥It avoids costs and organizational complications associated with coordi-nation between incumbents and competitors. Organizational coordination
problems arise because the incumbentÕs and competitorÕs interests are notaligned, a difficulty manifested in delays and confusion in provisioning
DSL service. The coordination issues give rise to extended regulatory
proceedings, with the associated delays and expenditure of resources.¥It facilitates technical optimization of total bandwidth. Crosstalk among
telephone lines constrains DSL performance. Bit rates and corresponding
ranges can be improved when transmissions can be coordinated so as to
minimize interference. Logical-layer unbundling (see below) is another
way to facilitate this.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS29In its focus on investment in new facilities and the long term, thecommittee distinguishes between how to treat the existing telephone cop-
per plant facilities and new facilities. The case for the present unbundling
of the copper plant rests on the premise that the public should benefit
from past investment made when the telephone companies enjoyed a
(regulated) monopoly position. Also, changing present policy would se-
verely disrupt the business plans of todayÕs CLEC industry. Thus, it isreasonable to maintain unbundling rules for the present copper plant.It is when looking to the future, to investment in new facilities, thatreconsideration of unbundling is most important. Because the objective is
to minimize disincentives for new investment, existing unbundling rules
should be relaxed only where the incumbent makes significant invest-
ment to extend service to areas not served by existing infrastructure or in
facilities constructed to enable new capabilities. Investment for routine
maintenance or minor upgrades should not be sufficient to result in ex-
emption from unbundling requirements. That assessment must also take
into account the extent to which an incumbentÕs control over the existingplant can be leveraged to gain an anticompetitive advantage in offering
broadband over new facilities.At least in more densely populated, more affluent areas, facilities-based competition appears to be possible. That is not to say that sustain-
ing facilities-based competition will be easy, and policy should reflect this
reality. If more facilities-based entrants in an area are successful, each
provider will have a lower take-rate and increased facilities competition
may be accompanied by higher prices. But the policy objective of compe-
tition is not simply lower prices; the aim is also to increase quality, stimu-
late investment in upgrades, and provide meaningful consumer choiceÑand consumer education about these other factors may be necessary.Facilities-based competition can be stimulated by reducing barriers toentry. Certain forms of accessÑsuch as access to rights-of-way and (pos-sibly incumbent-controlled) poles and conduitsÑstem from privileges
granted or property controlled by governments and are not a direct prod-
uct of the innovative activities of a competitive firm. Governments should
devote increasing attention to this type of access so as to reduce obstacles
to new facilities-based entrants.Recommendation 2.2. Favor alternatives to physical unbundling.In cases where facilities-based competition is found to be insufficient,the most common regulatory alternative is some form of mandated un-
bundling. An example is the currently debated opening up of cable sys-
tems to unaffiliated ISPs. When policy objectives call for the opening upBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.30SUMMARY AND RECOMMENDATIONSof incumbentsÕ facilities, this goal can be achieved in several ways, either
at a low level, by unbundling the physical links of the provider, or by
unbundling some higher-level service. In physical-layer unbundling, a
competitor to the incumbent gains direct access to the electronic signals
on the wire (or light on a fiber) running from the subscriber to a central
office or remote terminal; can adopt whatever transmission scheme it
chooses to; and is free to compete on speed, quality, and other transmis-
sion characteristics. However, the ultimate performance and reach of the
physical links may be impaired by such low-level sharing. Options for
enhancing DSL, such as coordinated assignment of copper pairs and coor-
dination of transmitted signals among pairs, cannot be implemented if
competitors are free to implement their own technology. Similarly, low-
level unbundling of cable, for example, allocation of different frequency
bands to different providers, raises the risk of interference among signals
and overall loss of quality and operational stability. No individual pur-
chaser of unbundled access has an incentive to internalize the interference
problems its traffic causes for others.Logical-layer unbundling exploits the layered way in which broad-band services are implemented. It is the basis of todayÕs cable open accessinitiatives. Higher-layer services concerned with transmitting bits are
implemented on top of protocols concerned with transmitting electrical
signals across the wire, which means that they can be implemented inde-
pendent of the particulars of the physical layer connection. That is, a
competitor need not control the actual signals running over the wires if it
can implement its service using bit transport capabilities provided by the
incumbent. In addition to facilitating measures to address the crosstalk
problem, logical-layer unbundling may be a more practical way of pro-
viding unbundling as fiber is pushed deeper into the telephone network
and the termination point shifts from the central office to remote termi-
nals.A principal disadvantage of logical-layer unbundling for the com-petitor is that the performance characteristics of the link implemented by
the incumbent may restrict the types of services the competitor may offer
and limit the competitorÕs ability to differentiate itself from the incum-bent. Nonetheless, in the long term, particularly with respect to new fa-
cilities, logical-layer unbundling would provide a better foundation for
technology-neutral broadband regulation, provided that facilities owners
are not permitted to exercise market power with respect to transport.The current situations of the ILECs and the cable providers differsomewhat. The physical links of the ILECs, specifically the local loops
and subloops, are currently subject to physical-layer unbundling require-
ments, which has allowed a number of data CLECs to enter markets. TheBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS31cable debate about open access has, in contrast, been centered at a higherservice level. In the long run, a convergence toward a uniform open ac-
cess policy based on logical-layer unbundling may be the best outcome.
The cable industry claims that it will implement logical-layer unbundling
voluntarily. If this outcome does not occur, mandated open access may
well be the regulatory response (unless a much more competitive land-
scape appears). In the case of ILECs, regulators should consider whether
the goal of robust competition among different services offered by differ-
ent providers could be better achieved in the long run through logical-
layer unbundling rather than physical-layer unbundling, especially as the
telephone plant evolves to make increased use of remote terminals.Recommendation 2.3. Anticipate that facilities-basedcompetition will not occur in all places, and fashion
appropriate policies to address these gaps.While their boundaries are difficult to forecast and will likely changeover time, it is reasonable to anticipate areas where there is a single terres-
trial provider. These type 1 areas will generally exist where population
density is lowest and the per-passing cost burden is highest, making the
business case for entry by a second facility owner unattractive. In these
areas, policy makers will face the challenge of how to address a noncom-
petitive broadband market. Questions that must be addressed in fashion-
ing such policy include whether and how to intervene, how long to wait
before assuming that a rough equilibrium situation of only a single facili-
ties-based carrier has been reached, what impact either mandated unbun-
dling or voluntary facilities-sharing has on the competitive landscape,
and to what extent satellite-delivered broadband (with less attractive price
or performance) provides sufficient competition to the terrestrial facility
owner.Local conditions may also change over timeÑespecially early onÑand thus the extent of and approach to intervention will have to change.
This flexibility will challenge traditional regulatory approaches, which
move more slowly. Consider the most complex case: a competitor with-
draws (transforming a type 3 region into a type 2 region, for example). A
result may be a need to increase regulation of the survivor. This outcome
would certainly be characterized by the provider as unfair after-the-fact
rule changing, but this sort of eventuality must be anticipated. Thus pro-
viders might face a changing and nonuniform set of business conditionsÑa situation that, while potentially confusing for providers, reflects the
realities of their operating environment.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.32SUMMARY AND RECOMMENDATIONSRecommendation 2.4. Ensure appropriate radio spectrum forbroadband and associated capabilities.Wireless is well suited for certain less densely populated regions,offers an additional path for entry by new facilities-based competitors,
and, if suitably configured, is unique in its support for mobile use. Both
licensed and unlicensed spectrum plays a role in enabling various wire-
less broadband alternatives as well as local area and mobile capabilities
that complement and supplement wireline broadband access. The com-
mittee did not examine in detail whether current spectrum allocations are
sufficient or appropriate, but notes that spectrum availability is a precon-
dition to any wireless deployment. Nor did the committee evaluate the
merits of various allocation schemes or the trade-offs between allocations
for fixed versus mobile, licensed versus unlicensed, or unshared versus
shared uses. Efforts to examine spectrum policy to support broadband
and related services (both current and contemplated), such as those being
undertaken by the Federal Communications Commission, should be con-
tinued.Recommendation 3. Reflect the Convergent Nature of Broadbandand Target Policy at the Appropriate Layer.The Telecommunications Act of 1996, which for the most part as-sumes the continued existence of a number of distinct services that run
over distinct communications technologies and separate infrastructure,
does not fully reflect the convergent nature of broadband (different com-
munications infrastructures are able to deliver a similar set of services
using a common platform, the Internet) nor the evolution toward a com-
mon technology end point (deep penetration of fiber, complemented by
short runs to the premises).Recommendation 3.1.  Move toward a more coherent,
consistent policy framework for broadband.Failure to move toward a more coherent, consistent policy frameworkcould lead to policy-induced distortions in technology deployment. For
example, even as several major cable operators have entered into open
access agreements, the industry has considerably greater control over
access and content than do the telephone companies, which fall under
industrywide common carrier rules. A more coherent policy would also
better accommodate technological innovation beyond todayÕs HFC andDSL systems. Progress in rationalizing the overall regulatory framework
(which would require revision of the Telecommunications Act of 1996)ÑBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS33to address the mismatch between convergent services and stovepipedregulationÑwould also help reduce uncertainty and thus could stimulateinvestment. In the process of reconciling policy across technologies (and
associated industries), policy should emphasize broad deployment and
facilities-based competition (Recommendations 1 and 2) and not simply
apply existing regulations that were designed to deal with circumstances
particular to individual technologies (or associated business). Also, tech-
nology convergence notwithstanding, policy should be able to accommo-
date a diversity of business models as incumbents and entrants alike
experiment with different business strategies. These realities are gener-
ally appreciated by the Federal Communications Commission as well as
by the regulated industries themselves; the issue today is how and when
the regulatory framework should be reformulated.Recommendation 3.2. If regulation of a broadband-deliveredservice is contemplated, it should be done in a service- rather
than a technology-centric fashion.Reflecting political or social interests, various communications ser-vicesÑsuch as todayÕs broadcasting and telephonyÑare subject to regu-lation. It is reasonable to anticipate that services delivered over broad-
band will be subject to similar scrutiny, and thus it is prudent to identify
the most appropriate means of regulating them. Formulation of any fu-
ture regulation should focus on the service rather than on the particular
transmission technology.Flexible service-centric approaches that tolerate technology diversityare essential, because broadband-delivered services are subject to faster
change and greater variationÑbecause of the general-purpose nature ofthe broadband infrastructure over which they runÑthan are conventionalservices. For example, if broadband is to be used to provide telephone
service intended to substitute for conventional telephone service, regula-
tors should focus on the marketing of the service to ensure that the prom-
ised reliability and 911 service are in fact delivered, rather than on the
technical means by which the service is provided (whether over the
Internet or otherwise). Defining regulated services this way not only en-
courages convergence by relying on a technology-independent way of
describing the service, but it also tolerates service diversity by permitting
different types of services to be defined. One might, for the purposes of
regulation, define two classes of telephone service: (1) a service intended
to substitute for conventional phone service (providing high reliability
and 911 service) and (2) a less costly service for more discretionary uses.
Another reason to move toward a service-centric approach is that theBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.34SUMMARY AND RECOMMENDATIONSassumptions underlying regulation of services are frequently tied to thecharacteristics of particular technologies. For example, regulation of
broadcasting has been fashioned in an environment of over-the-air chan-
nel scarcity, a condition that need not apply to broadband-delivered ser-
vices.Recommendation 4. Take Active Steps to Promote Increased orAccelerated Deployment, Including at the Local Level.As described above, the economics associated with investment inbroadband suggest that, absent some additional impetus, achieving na-
tionwide broadband deployment may be a protracted process. In at least
some parts of the countryÑtype 0 and 1 regionsÑthere may be little or nobroadband deployment or facilities-based competition, and intervention
may be required. Type 2 areas, in which the telephone and cable incum-
bents constitute a duopoly, are also places for government at all levels to
explore intervention that would encourage new entrants where the mar-
ket appears to be capable of supporting more participants. Many of these
incentives should be locally based, because there is considerable local
diversity in the conditions for broadband deployment.Recommendation 4.1. Establish a federal and state policyframework supportive of local initiatives that ease market
entry and foster competition.Current broadband policy is largely federal in scope, and it assumes,at least implicitly, a uniform national approach. But the degree of natural
competition and prevalence of technology will vary by region, state, and
municipality, and policy at all levels will have to accommodate this diver-
sity. Federal rules should continue to bound the range of outcomesÑforexample, by preventing local governments from raising unreasonable bar-
riers to entry or from discriminating in providing access to public facili-
ties, and by preventing a proliferation of inconsistent local rules that can
complicate and deter investment. But because it is communities them-
selves that have the most at stake in regard to broadband service, there
are appropriate forms of local decision making, based on local conditions
and needs. Particularly at the municipal level, various sorts of incentives
and local arrangements can encourage and even shape the form of broad-
band deployment that occurs (e.g., localities may target their communica-
tions purchases as a way to encourage an entrant).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS35Recommendation 4.2. Explore public sector initiativesthat foster market entry.Initiatives involving public sector actors may provide an alternativeto imposing unbundling requirements on incumbents in order to provide
increased competition in type 0, 1, and 2 circumstances. These initiatives
should be articulated, researched, and evaluated with a focus specifically
on reducing barriers to entering competitors by building or facilitating
enabling infrastructure.A decision to provide a publicly funded broadband serviceÑwhichmight be done in an attempt to introduce service where there currently is
noneÑcan affect the number of broadband providers in a given area. Incases where a market is capable of supporting only one private provider,
the introduction of a public network to compete with it could have the
effect of driving the private sector network out of operation. Similarly, the
creation of a public network could deter future entry into a market ca-
pable of supporting only a very limited total number of players. Also,
where government bodies enter into exclusive arrangements with a single
company, there is the risk of regulatory capture. These factors all argue
that local governments should concentrate on taking steps to encourage
and facilitate competition among private sector players, rather than creat-
ing new quasi-monopolistic entities. Options include these:¥Fiber condominium arrangements with public participation. A locality
declares its intention to build out fiber along its streets and invites any
interested parties to purchase some share of the fibers installed (and pos-
sibly installs additional dark fiber for future use).¥Customer-owned condominium arrangements. Customers own links to
a suitable aggregation point. This option would most likely take the form
of a condominium arrangement in which a group of households would
coinvest in new wireline infrastructureÑprobably fiberÑthat serves aneighborhood or community; this arrangement might be facilitated by
local governments.¥Partnerships with the private sector to install (and possibly maintain)fiber. The town itself, the schools and municipal departments, businesses
and other private sector players in the town, the citizens themselves, and
any interested broadband providers can sign up.¥Municipal investment in wholesale second-mile fiber facilities, or fiberconduit. Second-mile fiber facilities provide connectivity to neighborhoodsthat can be shared by competing broadband providers who in turn pro-
vide broadband to individual homes and shared conduit that decreases
each providerÕs installation costs. Municipal investment in either wouldbe analogous to the investment in streets as an enabler for local com-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.36SUMMARY AND RECOMMENDATIONSmerceÑhere enabling the value-added flow of bits instead of the flow ofcars and trucks.In each case, the locality provides motivation, coordination, and re-sources for joint action. It may share in the cost of the common construc-
tion and may also prohibit the digging up of the streets again for some
period after the construction. Typically, some provision would also be
made to lease colocation space to service providers at the fiber termina-
tion points to facilitate Internet interconnection. By avoiding the extra
cost of uncoordinated overbuildingÑkeeping down the per-passing costsÑthis approach attempts to provide competition at per-passing costs com-parable to those of a single provider. Local and regional government or
quasi-governmental agencies can also act in effect as anchor tenants that
underwrite some of the cost of installing infrastructure, reducing the costs
for other government agencies, private sector firms, or even individual
customers.Recommendation 4.3. Relax federal, state, and local rulesto ease market entry or to stimulate investment.Local governments can also relax rules that deter or preclude over-builders from entering a market, such as by providing access to rights-of-
way, forms of relief for opening of facilities to competitive higher-level
service providers, and so on. Local policies that tend to protect the incum-
bents from facilities-based entrants should be strongly discouraged or
even preempted at the state or federal level.Various forms of regulatory reliefÑsuch as a relaxation of franchisefees or obligationsÑcould be granted in return for infrastructure build-outor upgrade commitments. One option would be to provide relief from
certain forms of regulation, such as mandated access in exchange for
specified deployments of new or upgraded facilities. Another option
would be to reduce the business risk associated with facilities construc-
tion by providing assurances that compensation would be provided for
future regulatory imposition of unbundling requirements. Regulators
might also provide a Òsafe harborÓ (exceptions from heavy regulation) for
providers in a type 1 situation if they behave comparably (in terms of
prices and service quality) to providers in a type 3 situation. Finally, in
cases where broadband providers fail, governments at all levels can take
steps to expedite a transfer of assets to ensure continuity of service for
affected customers.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS37Recommendation 4.4. Provide financial incentives forinvestment in underserved and high-cost areas.Examples of financial incentives would include tax credits given forbuilding out infrastructure in underserved areas, or incentivesÑinclud-ing tax credits and changes in permitting and zoning rulesÑgiven toproviders that invest in infrastructure upgrades exceeding specified build-
out or performance targets or that make investments in training and sup-
port of developers and users. Another option would be to provide gov-
ernment-guaranteed loans for infrastructure upgrades and build-out in
high-cost areas.Recommendation 5. Increase Local Capacity to PromoteBroadband Deployment.The recommendations above point to a number of specific measuresthat local or regional governments might pursue to promote broadband
deployment in their communities. These opportunities also represent a
considerable challenge for many communities that lack experience and
knowledge in managing the complex legal, regulatory, and economic is-
sues these options encompass. A few communities have already taken
significant initiative with respect to broadband, but the majority are just
now exploring the options before them. Therefore, mechanisms to en-
hance local capacity can play a critical role. Because one of the motivators
for broadband is demand for work- and business-related applications and
associated applications such as continuing education, in some circum-
stances it will be appropriate to link broadband initiatives with broader
economic development efforts.Recommendation 5.1. Support planning grants forlocalities to explore options.Because an exploration of the complex set of issues confronting eachcommunity requires expertise, the engagement of various sectors within
the community, and input from the public at large, federal and state
governments should support planning grants to communities that dem-
onstrate serious interest in taking steps to advance broadband deploy-
ment.Recommendation 5.2. Provide cost sharing for field trials,including local-government-sponsored initiatives.Cost-sharing grants or subsidies for communities that have limited-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.38SUMMARY AND RECOMMENDATIONSperformance or no broadband would support experimentation with pre-market technologies and alternative organizational models. Such trials
would permit governments and private sector firms to obtain more realis-
tic experience with the performance of technology alternatives, help in-
dustry move up the learning curve of emerging technologies, test alterna-
tive organizational approaches and access models (such as municipally
owned fiber or conduit available to multiple providers), and test demand
stimulation strategies (e.g., locally developed content and applications).
While there may be municipalities that have existing public utilities ca-
pable of embarking on such a program, a more likely mode is through
partnership with private firms.Recommendation 5.3. Establish a national clearinghouseto raise awareness, provide technical assistance, and
disseminate best practices for local and regional efforts
to accelerate broadband deployment.A mechanism for sharing best practices for local and regional policies,regulation, and planning would help communities that are facing com-
plex decisions. For instance, model regulatory frameworks would illus-
trate the range of possible outcomes, provide regional and local govern-
ments a starting point in negotiating with providers, and help overcome
the knowledge and experience imbalance that local and regional govern-
ments may experience. Efforts by the National Association of Telecom-
munications Officers and Advisors and the Association for Community
Networking are promising first steps. In-depth, authoritative information
will be needed if best practices are to be useful to communities across the
capability spectrum. A national clearinghouse would permit maximal
sharing of best practices but would not necessarily supplant state or re-
gional efforts, which may be better positioned to focus on local circum-
stances and needs.Recommendation 6. Defer Development of a Universal Service Policyfor Broadband Until the Nature of Broadband Services, Pace ofDeployment, Distribution of Access, andSocial Significance Become Clearer.The Telecommunications Act of 1996 devotes considerable attentionto measures that continue support for near-universal telephone service.
Existing universal access programs such as the high-cost fund support
(which, by helping to expand or upgrade rural public telephone networks,
can also provide a foundation for DSL deployment, as well as extend or
improve dial-up service) and the e-rate program (which funds InternetBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS39access in many schools, libraries, and health care institutions) have helpedto increase broadband access. The 1996 act has instigated efforts to de-
velop policy for expanding broadband access (such as the Federal-State
Joint Board on Universal Service).A number of the committeeÕs recommendations aim to increase thebreadth of deployment. While the committee anticipates demands that
universal service programs be extended to residential broadband, its view
is that it would be premature to embark on a comprehensive new univer-
sal service program until the overall shape of residential deployment and
the nature of broadband services are better understood. The committee
does not believe that, at least at present, a social contract analogous to that
developed for telephony would be appropriate for broadband.It is already apparent that broadband is a desirable and useful ser-vice, and it is reasonable to presume that it will take on increasing social
importance in the future. But there is a difference between a serviceÕsbeing useful and showing great promise, which has motivated the recom-
mendations in this report aimed at widening deployment, and a serviceÕsbeing critical to meaningful participation in society (as telephone service
has come to be understood). In the early stages of deployment and accep-
tance, policies aimed at fostering rapid, widespread deployment, comple-
mented by broadband access through schools, libraries, and other public
centers, are appropriate.Further, defining an appropriate universal service policy will be com-plicated. For voice, the shared understanding of what society should ex-
pect from the telephone industry, which became the goal of federal and
state regulators, has been that a more or less uniform telephone service
should be available to residential customers at a roughly uniform price.
However, broadband is not a uniform service. Different users have differ-
ent needs, and different technologies deliver different variants with dif-
ferent features as well as cost and performance characteristics. Also, as
the two definitions for broadband advanced by this committee indicate,
as technology and use evolve, what is broadband today will not be con-
sidered so in the future. One cannot employ a simple universal definition
for broadband such as Òfaster than 200 kilobits per second.Ó The cost
could be made uniform only through substantial transfer payments within
the systemÑan approach that was possible in the simple, more staticworld of telephony but that is very hard to carry out in the less well
defined, changing, competitive world of broadband. This suggests that
natural cost and service variations must be accepted (which must be dis-
tinguished from exercise of market power). For instance, satellite-based
service is capable of reaching essentially all parts of the country. As a
result, there will be relatively few people who will literally be unable to
obtain some form of broadband (assuming these services are marketed toBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.40SUMMARY AND RECOMMENDATIONSthem). Thus, the geographical access divide is much smaller if the re-quirements are relaxed for what must be the same across regions, and if
such trade-offs as lower reliability (e.g., satellites are susceptible to rain
fade), higher latency, lower data rates, or higher up-front and monthly
costs are permitted.Recommendation 7. Support Research and Experimentation.Recommendation 7.1. Support research and development on accesstechnologies, especially targeting the needs of nonincumbent players
and other areas that are not targets of stable, private sector funding.Much of current research has reflected the interests of incumbents.Research that looks at the needs of nonincumbent overbuilders should be
specifically encouraged. Such systems will in all likelihood make use of
less mature technology alternatives. And as overbuilds, they have lower
levels of subscription (lower take-rates) and need to be cost-engineered to
anticipate this outcome. Particular research targets include these:¥Architectural options and other means of cost reduction in fiber accessnetworks, including new techniques for using coarse wavelength-divisionmultiplexing and low-cost in-home receivers and/or transmitters.¥Enhanced wireless capabilities, including capacity and other enhance-ments for wireless that provide robust, spectrally efficient, and scalable
broadband wireless access to homes; architectures for synergistic co-
existence of various wireless access technologies (fixed, mobile, in-home,
ultrashort-range, and so on); technologies for true mobile broadband wire-
less services beyond 3G; convergence of fixed and mobile Internet archi-
tectures and protocols; and new information-delivery paradigms for
broadband mobile Internet services.¥Technologies that foster the accommodation of multiple competitive ser-vice providers over facilities. Such open access-ready systems might not be anatural research and development target of large incumbent providers
but will be the preferred form for a variety of public sector or public-
private deployments.¥Quality of service for homogeneous and heterogeneous access scenarios inthe local access link and home, including for applications that make intensiveuse of the upstream channel.¥System robustness and reliability, reflecting the increasing importanceof broadband services to individuals and organizations.Because the primary objective is to develop technologies that can bepractically implemented by a broadband provider, research and develop-
ment programs should encompass systems and economic perspectives,Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SUMMARY AND RECOMMENDATIONS41not just individual technologies or components. Doing this sort of re-search requires overcoming several institutional problems. Much of the
computer science community traditionally has viewed cost reduction as
an engineering topic for industry to pursue rather than as a legitimate
research topic. Further, few academic research centers devote attention to
systems engineering issues, which have generally been addressed by in-
cumbents and their equipment suppliers.Recommendation 7.2. Support research on economic,social, and regulatory factors.With broadband a nascent service, now is an especially opportunetime to study potential social and economic implications and to develop
an understanding of these factors so as to inform government policy mak-
ing and industry strategies. Areas for further research include these:¥Social and economic impacts of broadband connectivity and availability.Such understanding will help localities assess the case for local broad-
band initiatives and help fashion any future broadband universal access
programs.¥Alternative business models and better understanding of consumer be-havior and its relationship to currently available and prospective applica-
tions and services.¥Economic and regulatory barriers that may hinder the nonincumbentfacilities provider. For example, the cost of the first mile is not the onlybarrier to deployment. Small neighborhoods (new construction, pockets
of dense development, and so on) may be able to justify the construction
of new facilities. But this construction cannot occur unless there is some
larger network to connect to that serves to aggregate traffic from these
neighborhoods. This is what might be called the Òsecond-mileÓ prob-
lemÑaggregation of traffic to the point where it is economically viable toconnect to the rest of the broadband world.¥Improving our understanding of why local access performance has laggedthat in other computing and communications sectors and what strategies mighthelp to close that gap.¥Comparing U.S. progress with that in other countries, and evaluatinghow progress abroad relates to national broadband policies and strate-
gies.Historically, a substantial fraction of funding for telecommunications eco-nomics research has come from industry itself. The increasing politiciza-
tion of broadband (and telecommunications more broadly) argues for
increased support from less directly interested parties, such as the federal
government and foundations.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.42SUMMARY AND RECOMMENDATIONSRecommendation 7.3. Support development of alternativebroadband content and services.More diverse content and applicationsÑbeyond mass entertainmentand more commercially oriented contentÑcould create new sources ofdemand and help attract individuals and communities to make further
investments in broadband. Examples of such content include information
of local interest; enhanced access to government information and ser-
vices; and materials related to education, health, and culture. Not all such
services require broadband (narrowband may be sufficient, and a way of
reaching a wider audience in the short term), but broadband supports
much richer content. Traditional means of providing such content, such
as cable public, educational, and government channels or public radio
and television broadcasting, do not obviously translate to broadband, so
further consideration about how to achieve such ends will be required.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.43THE BROADBAND CHALLENGEBroadband, the darling of techno-sophisticates and an object of inter-est to a growing number of politicians and government officials, as well
as to the general public, is often misunderstood. The term itself, originat-
ing in the characterization of a communications channelÕs capacity (in
contrast to narrowband), has come to be used as, among other things, a
marketerÕs label for advanced cable television service, the 21st-century
incarnation of the early 1990s Òinformation superhighway,Ó and one ele-
ment of the next stage in the development of the Internet. Broadband has
been a beacon for investors and a stimulus for entrepreneurs and main-
stream businesses, and it has intensified debates about the public interest
in information and communications infrastructure. It is as an enhanced
means of access to the Internet that broadband has begun to have real
traction in terms of actual deployment and use, and it is in this sense that
the term has become commonly understood. Years of assertions by tech-
nology gurus, business executives, and marketers about the potential
promise of broadband have given way to a small but rapidly growing
U.S. population who are using a first generation of broadband for faster
Internet access from their homes.Today, people are asking about when most, if not all, of the pop-ulation will partake of it. Basic questions about who pays for and who
benefits from broadband are being discussed in communities, state and
regional government entities, and in the Federal Communications Com-
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.44BROADBANDmission and Congress at the national level1Ñas well as in trade associa-tions, consumer advocacy and other public interest groups, and by civic
organizations, telecommunications and Internet policy scholarship fo-

rums, and groups concerned with international economic development.
That such a diversity of organizations share a common interest in broad-
band underscores how much the Internet has become accepted as impor-
tant to the U.S. economy and society, a marked contrast to the early and
mid-1990s when the federal Information Infrastructure Task Force worked

hard to proselytize the Internet and related services.2 Various factions
point to broadband as a compelling reason for shifts in telecommunica-
tions policy; these include proponents of both more and less government
intervention. Understanding the nature of broadband and what is in-
volved in getting it to more consumers is one of the major goals of this
report.Broadband, in the sense of high-capacity communications channels,is already present throughout much of the communications infrastruc-
ture. Fiber optic links with very large capacity are already commonplace
within the networks of telecommunications carriers and are available for
local access in many locations, albeit at high costs affordable by only
larger businesses or organizations. The broadband challenge on most
peopleÕs minds today is how to make higher-capacity connections avail-able on a more pervasive, affordable basis. In particular, how can one best
extend high-speed connectivity to users in homes, small businesses and
smaller offices of larger organizations, local governments, and so forth?
Widespread useÑmarked by new patterns of information flowÑnot onlywould benefit the individuals connected, but also could lead to qualita-
tive changes in how people interact with family, community, and the
workplace, with potentially profound social and economic implications.
Broadband is viewed by some as a double-edged sword: networking
could promote economic development, yet electronic commerce also has
the potential to displace local businesses. (Present and potential applica-
tions and impacts are considered in Chapter 3 in this report.)Extending the reach of broadband generally implies building on theexisting communications infrastructure base, either incrementally or
through significant investment in new infrastructure. It is an expensive1Broadband-related bills introduced in the 107th Congress include S. 1056 (CommunityTelecommunications Planning Act of 2001), H.R. 2139 (Rural America Broadband Deploy-ment Act), H.R. 1542 (Internet Freedom and Broadband Deployment Act of 2001), H.R. 267(Broadband Internet Access Act of 2001), S. 150 (Broadband Deployment Act of 2001), and
S. 88 (Broadband Internet Access Act of 2001).2For the flavor of that period, see CSTBÕs 1996 report The Unpredictable Certainty and its
1994 report Realizing the Information Future, National Academy Press, Washington, D.C.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SETTING THE STAGE45undertaking to deploy broadband to households and to small businessesand other small organizations. Each of these is a small economic unit, and
most premises are located a significant distance from a so-called point of
presenceÑwhich is a location where a communications service providercan get economies of scale by aggregating traffic from many customers
onto its core, high-capacity links that connect to other parts of the net-
work, including access to the Internet. (In the telephone network, these
points generally are located at central offices, while in hybrid fiber coax
cable systems, these points are known as head ends.)The link between the point of presence and the customer
Ñusingeither existing communications infrastructure or new facilitiesÑis fre-quently referred to as the Òlast mile,Ó because it represents a bottleneck
that constrains the benefits the consumer gets from the rest of a network,
which is literally at some distance. Greater difficulty and cost are associ-
ated with dispersed populations, whether they have low density, with
homes being far apart and farther from the local point of presence, or are
remote, with an entire community, whatever its density, being many miles
from the nearest existing aggregation point.PERSPECTIVES ON BROADBANDA major goal of this report is to examine whether broadband deploy-ment is working and what, if anything, needs fixing. There are very dif-
ferent perspectives on what is happening and how well the process is
working. In the course of its work, the Committee on Broadband Last
Mile Technology learned about several different views described below,
all of which shaped its thinking:¥Incumbents (incumbent local exchange carriers [ILECs] and cable systemoperators). Deployment of consumer broadband is very costly, and dreamsof ÒovernightÓ nationwide deployment are not realistic. There is good
evidence of market demand, and capital is being expended at substantial
rates. Sustained demand is expected to justify the continued investment.
The current round of failures in certain sectors, most notably the troubles
of a number of nonincumbent digital subscriber line (DSL) providersÑand the associated shift in investment climateÑwill slow progress to someextent but do not represent a fundamental problem. Private sector invest-
ment is healthy. Fundamentally, nothing is ÒbrokenÓ; it is simply early inthe process.¥Consumers. Consumers with access to broadband are experiencingmuch-improved Internet service compared with what dial-up provided.
Some high-end, demanding users may be disappointed with the quality
or predictability of their service. Many consumers are being told eitherBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.46BROADBANDthat broadband is coming Òvery soon nowÓ or that they should not expect
service to be available for a long time; both groups are very unhappy.
Some consumers find that their neighbors can receive service but they
cannot. Further, for many the installation process has been a nightmare,
and there seems to be no consistent way to navigate these problems.
Inconsistent coverage and quality leave many concerned about whether
they will ever be adequately served. Already, some consumers view
broadband as an important service, not a luxury, and believe that more
needs to be done to ensure that it is available to them.¥Observers of market structure. In most locations, the number of broad-band providers with their own facilities is not greater than two. This is an
inadequate level of competition, giving rise to fears that the long-term
outcome, if not shaped by regulatory intervention now, will fall short of
the desired competitive market. There is a risk of vertical integration that
leads to restricted access to certain content, seemingly arbitrary restric-
tions on what consumers are permitted to do with their broadband ser-
vice, and so on. The basic concern is that we may be making progress with
deployment but advancing toward a very undesirable long-term outcome.
Some observers cite the substantial and still ongoing struggle to ÒbreakÓincumbent narrowband and video monopolies, and worry that without
firm measures to discipline the market now, we will repeat this history
with broadband.¥Societal visionaries. There are possible benefits to society, some as
yet unvisualized, that would reach beyond the returns anticipated by the
private sector. Opportunities cited include regional economic develop-
ment, better education, improved health care, and a more informed citi-
zenry. Simply depending on private sector investment to fund broadband
deployment does not reflect the complementary economic and social
policy objectives that would justify the commitment of public resources to
promote it. In terms of what is actually available at present, the public
policy case for universal broadband is weakÑthe ÒbetÓ is that public
investment could help realize social objectives and stimulate demand and
private-sector investment. The circumstances are somewhat like those
that confronted the builders of the U.S. highway systemÑit certainly hadsome obvious foreseeable impacts, but it would have been hard to predict
all of the transformations that resulted from public investment. Similarly,
one might have been able to justify building parts of the highway system
privately based on constructing toll roads and predicting commercial use,
but that would likely have left the country short of a national system. In
the case of broadband, noncommercial investment in content and services
could start to shift the picture.¥Communications technology visionaries. In the long term, two lastmile technologies will dominate: fiber for maximum performance andBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SETTING THE STAGE47wireless for coverage and mobility. Pervasive deployment of fiber-to-the-home (FTTH) and ultimately Òfiber-to-the-desktopÓ are inevitable. Fiber
Õsbenefits include not only enormous potential bandwidth but also longer
service lifetime, upgradability and ability for rapid turn-on of new ser-
vices that any format-transparent medium provides. In addition, unlike
wireless, FTTH solutions are not constrained by spectrum availability or
the rate at which regulatory processes can make spectrum available.
Completion of the last mile bottleneck using these two technologies would
also provide a remedy to the current economic leveling-off of both the
telecommunications and computer industries.¥Computer industry. The ratio of performance to cost of computerscontinues to grow rapidly (a phenomenon closely related to MooreÕs law,which says that the number of transistors on an integrated circuit doubles
every 18 months), and communications rates should grow at a similar
pace. To keep pace with processor speed, disk size, and so on, communi-
cations should become 10 times faster every 5 years. In some situations,
such as local area networks or long-haul fiber optic circuits, speed im-
provements have been consistent with processor improvements. But in
the residential market, it has taken a very long time to surpass dial-up
speeds, and there are fears that motivation will be lacking for the service
providers to invest in a way that will provide ongoing improvements in
speed. Broadband deployment may stall at a speed that is an improve-
ment over dial-up but which does not keep pace with what is needed,
thus acting as a brake on the computer industry. Similarly, operators of
other segments of the network (i.e., backbone Internet service providers
[ISPs] and long-haul data carriers) may view the last mile is a potential
bottleneck to growth in their traffic volume and revenue.Finally, a note on perspective as it influences terminology. While ÒlastmileÓ is the more commonly used term for the local access network, the
challenge is frequently put in terms of building the Òfirst mileÓÑthat is,building out from end users to the network. From this perspective, the
last mile might be thought of as a more supply-driven concept, while first
mile refers to a more user-centered view that emphasizes social and eco-
nomic benefits at the local level. This report uses these terms interchange-
ably.A BRIEF HISTORY OF THECOMMUNICATIONS INFRASTRUCTUREThe character and evolution of the existing communications infra-structure provide lessons applicable to todayÕs broadband deploymentchallenge. Some options for broadband decrease costs by using existing
infrastructure for new purposes. And the business models, policy, andBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.48BROADBANDregulation developed in the contexts of older communications infrastruc-ture continue to be applied to the new technology. That base has many
faces: there are multiple communications networks, which have emerged,
evolved, and coexisted in largely self-contained fashion. Thus, it is help-
ful to briefly review the communications past and its evolution over re-
cent decades to a digital infrastructure capable of supporting broadband.Traditional circuit-switched telephony is, with the exception of high-capacity lines leased by large customers, a way of providing analog
narrowband last mile access. The public telephone network was origi-
nally built for voice communications but for some four decades has been
used increasingly for data communications. At its coreÑin the channelsthat aggregate communications from many usersÑthe telephone networkhas long had large, and growing, bandwidths. At the edges, with the
exception of a few customers (chiefly larger organizations) that have been
able to lease high-bandwidth private lines, customers have historically
been connected through relatively low capacity twisted pair links (this is
often referred to as the Òlocal loopÓ). Analog telephony has evolved todigital, with high-speed digital signal transmission commonplace
throughout the public telephone network except in the last mile segment.
Digital transmission over the last mile has been possible for many years
with the addition of dial-up modems. Integrated Services Digital Net-
work (ISDN) never took off in the consumer market, and more recently,
DSL technologies add equipment at both the customer premises and the
central office to leverage the existing last mile twisted pair infrastructure
in order to provide higher data rates.Two-way wireless networks, which originated as consumer servicesto provide analog cellular telephony, complement these other infrastruc-
tures. Digital transmission also extends into the last mile in the current
generation of cellular telephony (although analog cellular networks con-
tinue to be used). In recent years, a second generation of digital services
has been deployed in more populated areas; these services support very
limited data communications, including access to some Internet services.
Second-generation services have grown dramatically in popularity as ser-
vice prices have dropped and handsets have improved in size and battery
life. So-called third-generation service, which will offer greater bandwidth
(though less than the hype would suggest), inspires considerable specula-
tion. Even with todayÕs generation of technology, various forms of accessto Internet-like servicesÑmost notably text messenging, but also includ-ing access to information and commerceÑhave proved popular in coun-tries other than the United States, fueling speculation about their poten-
tial in the U.S. market.Broadcasting in the form of radio and television has been in place formany decades. While radio and TV have very large bandwidths and mayBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SETTING THE STAGE49make use of digital signal transmission, none of these services fits todayÕscommon understanding of broadband. This is in part because, unlike the
more general purpose, generally Internet-based broadband offerings of
today, they integrate physical- and higher-layer functionality. That is, the
services are aimed at particular types of communication or content (e.g.,
broadcast radio or television), much as the public telephone network has
been designed to support a particular set of voice communications ser-
vices, and they have emerged, evolved, and coexisted in self-contained
fashion. Some proposed applications are data-centric, however, and may
play a role complementary to the digital communications services dis-
cussed in this report. Since the 1980s, direct broadcast satellite has used
satellite transmission to provide many channels of service over very wide
areas, and this technology has been further developed to provide two-
way broadband service delivery.Cable television networks started out as a way of extending the reachof the broadcast networks. As this analog, one-way infrastructure grew, it
began to distinguish itself from broadcasting through development of its
own content. In more recent years, cable networks have joined telephony
networks in the public debates about broadband because recent and on-
going upgrades have added support for two-way communication at com-
paratively high bandwidths.The widespread use of computers in the homeÑmost notably andvisibly today in the form of the general-purpose personal computer, or
PCÑhas helped to transform expectations for consumer electronics,which historically focused on entertainment and specific personal ser-
vices. Computers in the home provide a broader base of support for work,
education, and other nonentertainment activities within the home. The
general-purpose nature of PCs implies both breadth and a multitude of
options for future use. The home PC, in turn, has proliferated in part
because of its potential for connectivity outside the home (today chiefly
through the Internet). Capability (e.g., storage, processing speed, and
support for audio and video) in home PCs and the richness of the content
available through the InternetÑand therefore the bandwidth needed toaccess it easilyÑhave increased in tandem. These trends have been themost obvious drivers of those seeking broadband in the last mile. Fore-
casts of future demand involve extrapolations from the rapid growth in
adoption and speed that has been experienced thus far. An important
caveat is that these figures derive from the early adopters: home penetra-
tion by PCs, which grew relatively quickly in the 1990s, has been leveling
off, and there is reason to believe that the explanation goes beyond simple
costs.In each of these instances, there have been well-defined roles for regu-lators at all levels of government. In the case of broadcasting, the air-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.50BROADBANDwaves were declared public property and the Federal CommunicationsCommission (FCC) was assigned the task of standardizing frequency
bands and interference masks for terrestrial transmission, and it licensed
the use of spectrum segments for particular well-defined services. In tele-
phony, geographical boundaries served as a foundation for defining the
respective roles of state and federal regulators.3 Cable franchising was
deemed to be largely a local responsibility.4 In a series of FCC proceed-
ings known as the Computer Inquiries, computers and related data pro-
cessing functions were deemed to be an area that would be largely un-
regulated.FROM PROMISE TO BROAD DEPLOYMENT:WHAT HAS CHANGED SINCE THE MID-1990S?TodayÕs debates about broadband have their roots in the 1990s, whenthe growth of the Internet and increasing experience with conventional
approaches to data communications triggered broad discussions about
national (or global) information infrastructure (NII). These general con-
cepts, as well as development of the first generation of broadband local
access technologies, set the stage for considerable speculation about a
broadband future and invoked a vision of rewiring America to take ad-
vantage of these new capabilities. Although the 1980s and 1990s saw the
deployment of a series of experimental broadband trials, it was not until
1998 that deployment began in earnest.While not all of the original NII visions have not come to pass, whathas been proved since the mid-1990s is the impact of the InternetÑasingle, general-purpose communications platform capable of delivering a
wide range of content and applications. But interest in Internet access has
not been enough to resolve other uncertainties, and incremental ap-
proaches have been successful. So the wholesale rewiring of America that
had been hoped for by many in the early and mid-1990s did not come to
pass. Instead, leveraging of existing wiring has dominated the broadband
scene, accompanied by limited investment in wireless infrastructure and
only spotty investment in new wireline infrastructure deployment.3In broad terms, federal regulators have primary responsibility for long-distance service,while state regulators have primary responsibility for local service. State commissions alsoregulate intrastate long-distance service, and the FCC regulates local telephone companies
insofar as they provide origination and termination services for long-distance calls. Thedivision of responsibilities between state and federal regulators is determined by the Com-munications Act of 1934, as amended.4Cable franchising authorities are local (municipal or county), except in states where astatewide authority has this power.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SETTING THE STAGE51A major change since the mid-1990s is the nature of the regulatoryenvironment, occasioned primarily by the Telecommunications Act of
1996. The 1996 act asserts the goal of marketplace competition, but early
experience has shown problems in achieving competition and raises ques-
tions about how much competition is realistic to expect (see Chapters 3
and 4 in this report). An important question today is whether the frame-
work established in the act deserves rethinking in light of the subsequent
evolution of communications technologies and services.Still, despite these changes in the environment, many contemporaryissues related to broadband are, in fact, not new, as demonstrated by a
review of three earlier reports by the National Research CouncilÕs Com-puter Science and Telecommunications Board (CSTB) (see Box 1.1). For
more than a decade, broadband in the last mile has been understood to be
a key to maximizing the benefits of the communications and informationBOX 1.1Review of Past CSTB Reports Related to BroadbandThe Computer Science and Telecommunications BoardÕs (CSTBÕs) 1994 reportRealizing the Information Future (itself preceded by a 1988 CSTB report, Toward aNational Research Network, which validated the concept of nationwide networkingin support of research and higher education) articulated both the potential benefits
from broadening access to a flexible and general infrastructure such as the Internetand the challenge of spreading those benefits across the economy in a commercialcontext. The 1994 report observed that there were multiple visions for information
infrastructure, reflecting different values and objectives among stakeholders, and itflagged differing orientations of nonprofit and for-profit sectors, noting a concern thathas continued to grow in some quarters about the role of the entertainment industries
in financing, and therefore in shaping, the evolving infrastructure. The report arguedfor a particular vision: an integrated approach to communications and informationinfrastructure. It pointed to the economics of the last mile as a determinant of how
broadly the benefits would be experienced and as the most important factor inachieving a unified infrastructure.The Unpredictable Certainty, a CSTB report published in 1996, examined howthe vision of an integrated, versatile infrastructure might be implemented. That reportwas more direct in emphasizing the importance of the Internet, describing its role infostering progress in different communications and information industries. It exam-
ined issues and options confronting multiple industries, characterized the differentbusiness models, and reported on some of the technical and business experimenta-tion that was beginning to accelerate. That report balanced affirmation of the eco-
nomic challenge presented by the last mile with observations about the potentialwithin the homeÑand within sectors such as education and health care that canachieve a certain synergy with homes in leveraging infrastructureÑif only more ca-pacity were deployed in the last mile. The report was commissioned with the hopethat it would produce a road map of technology deployment. Its message is that toomany factors militate against that happening.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.52BROADBANDinfrastructure. Now, as then, there are multiple technologies and indus-tries that can advance the infrastructure in general and broadband in
particular. Optical fiber systems continue to promise the most bandwidth,
but at the highest cost and risk. Private investment is still viewed as an
essential ingredient, but it continues to be inhibited by uncertainty about
what consumers will buy and what business models will succeed. Today,
as then, it is understood that government action (or inaction) has the
potential to both inhibit and promote investment.BROADBAND DEPLOYMENT TRENDSFCC data based on reports from carriers show rapid growth in broad-band subscriptions by residential and small business customers, with the
total growing from roughly 1.8 million in December 1999 to 5.2 million
subscribers in December 2000 (see Figure 1.1).5 Looking specifically at
residential users, an October 2000 report from the National Telecommu-FIGURE 1.1 Penetration of broadband to residential and small business custom-ers, December 1999 to December 2000. NOTE: (1) ÒTotalÓ includes wireless, satel-
lite, and fiber subscribers. (2) ADSL = asymmetric digital subscriber line. (3) ÒOth-er wirelineÓ includes symmetric DSL services. SOURCE: Federal Communications
Commission (FCC). 2001. High-speed Services for Internet Access: Subscribership as ofDecember 31, 2000. Industry Analysis Division, Common Carrier Bureau, FCC,Washington, D.C.0123456Dec 99Mar-00Jun-00Oct-00Jan-01Subscribers, millionTotal LinesCoaxial CableADSLOther Wireline       June 2000Dec 20005Interpretation is complicated because the figure includes small business as well as resi-dential customers and because ADSL is separated from other forms of DSL, which arelumped under Òother wireline.ÓBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SETTING THE STAGE53nications and Information Administration (NTIA) indicates that 4.4 per-cent of all U.S. households, or 10.7 percent of households with Internet
access, had broadband access as of August 2000.6 Market research reports
from 2000 provide consistent figures; for example, a November 2000 study
by the Cahners In-Stat Group found that roughly 9 percent of U.S. house-
holds that access the Internet use a form of broadband Internet access.7Reports from mid-2001 show further growth: a total of more than 5 mil-
lion cable modem subscribers and more than 3 million DSL subscribers.8There have, however, been hints that growth has been slowing, at least in
some market segments: second-quarter 2001 reports from Verizon and
AT&T Broadband show growth below the 2000 rate, and early 2001 also
saw contraction in the competitive local exchange carrier (CLEC) busi-
ness.9 Penetration rates can be much higher than the average in markets
where broadband has been available for several years. For example, in
Portland, Maine, an early test market for TimeWarner Cable, about one-
quarter of households have become cable modem subscribers.Access ratesÑthe fraction of households that could subscribe to broad-
band if they chose toÑare substantially higher than current subscriptionrates. A survey of Internet users commissioned by the General Account-
ing Office indicated that some form of wireline broadband access was
available to 52.4 percent of Internet usersÑ25.4 percent via both cable andDSL, 16.9 percent via cable only, and 10.1 percent via DSL onlyÑas ofMay 2000.10 As of mid-2001, approximately 60 million homes reportedly
had cable modem service available, and 52 million homes had DSL ser-
vice available.11 Availability and use of broadband are both correlated
with town size. Nielsen/Netratings found that broadband users in the6National Telecommunications and Information Administration (NTIA). 2000. FallingThrough the Net: Toward Digital Inclusion. NTIA, Washington, D.C.,  October. Available online
at <http://www.ntia.doc.gov/ntiahome/digitaldivide/index.html>.7Cahners In-Stat Group. 2000. Broadband ConsumersÑProfiles and Strategies, Report No.BBWIS00-05SP. See also ÒBroadband Subscriptions Will Rise 77% Through 2004,Ó BroadbandWeek, available online at <http://www.instat.com/rh/bbw/is0005sp_story.htm>.8The National Cable & Telecommunications Association (NCTA) estimates 5.5 millionsubscribers as of August 2001. See <http://www.ncta.com>.9AT&T Broadband reportedly signed up 259,000 customers during the fourth quarter of2000, but only 131,000 during the second quarter of 2001. Verizon signed up 90,000 custom-ers in the fourth quarter of 2000 and 120,000 during the second quarter of 2001 (ChristopherStern, 2000, ÒBroadband Market Growth Slows,Ó Washington Post, August 28, p. E01).10Determining the fraction of homes with DSL service available is more complicated thanin the case of cable. DSL availability depends on central office equipment, line length, andthe characteristics of the specific loop, while availability of cable modem service for the
most part depends only on whether the subscriberÕs system has been upgraded.11Remarks of Robert Sachs, NCTA, June 11, 2001; Cablevision Blue Book, Cahners Busi-ness Information, New York, June 2001.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.54BROADBANDtop 25 local markets (by size) constituted nearly two-thirds of all broad-band users in the United States.12REACHING ALL AMERICANSPast communications infrastructure has been the subject of efforts byindustry and governments to extend benefits to ever-larger segments of
the population. In the case of telephony, the effort has been in the form of
interventions expressly aimed at reaching all Americans regardless of
location or income level. At the same time that broadband services have
reached many, the differences in access to bandwidth among segments of
the population are becoming pronouncedÑincluding bandwidth dispari-ties between work and home or between urban and rural areas.The economic challenges in extending communications services tohouseholds can be seen in the history that led to todayÕs baseline. Thepenetration of communications technologies takes time, reflecting the time
it takes to build the necessary infrastructure and attract subscribers. As
Figure 1.2 shows in displaying the penetration of several communications
technologies over the period 1970-2000, broadband is in the early stages
of this process. For example, broadcast radio and television allows a net-
work service provider to reach wide areas using relatively few transmis-
sion facilities (terrestrial or satellite). Yet even this kind of infrastructure
does not reach quite all households and areas, reflecting broadcaster
choices about where and in what to invest (decisions that benefit from the
rights to a service area associated with a government license). Broadcast
television reaches many households, though reception is of varying qual-
ity. Broadcasting has been largely dependent on advertising support,13and expanding access has depended in part on consumer electronics ad-
vancing so that radios and television sets became increasingly affordable
(in the pre-cable-TV era). Cable service grew faster. It is available to
roughly 97 percent of homes, and 68 percent of households subscribe.14Direct broadcast satellite service covers the full continental United States
(assuming the household has an unobstructed view of the satellite). It
benefited from attractive economics: high capacity meant that it could
offer a wide range of content via a subscription model, and once the very12Nielsen/Netratings. 2001. ÒNew York Local Market Dominates Broadband Usage, Ac-cording to Nielsen/NetratingsÓ (press release). Nielsen/Netratings, New York. May 15.
13While public broadcasting has increasingly relied on commercial sponsorship, it stillrelies on tax subsidies, charitable support, and listener donations.14Cable TV Financial Databook, 2000, p. 10, as cited in National Cable & Telecommunica-tions Association, 2001, Industry Statistics, available online at <http://www.ncta.com/industry_overview/indStat.cfm>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SETTING THE STAGE55high fixed cost of the satellites and other transmission facilities was paid,an unlimited number of receivers could be added within the satellite
footprint with minimal incremental investment.It took decades to achieve a reach to over 94 percent of households,15using copper wiring in the last mile, but the technical path to deploy-
mentÑpervasive copper wiring backed by a centralized circuit switchÑwas, at least in retrospect, straightforward compared with what one ob-
serves with broadband today. This near-universal reach reflects both costs
to network service providers and regulatory programs that promoted so-
called universal service and provided financial support to providers to
help realize that objective (regulatory history is briefly described in Chap-
ter 5 in this report). The web of internal support flows that historically
have characterized universal service policies has been complex; it evolved
over time, notwithstanding the relatively homogeneous and slowly evolv-
ing technology that was the subject of these policies.FIGURE 1.2 Penetration of communications technologies, 1970-2000. NOTE:Broadband data include residential and small business subscribers. SOURCE:DBS data from Yankee Group (1999); computer and Internet data from NTIA
(1998-2000); cable data, 1995-2000, from Nielsen Media Research-NTI (2000); andbroadband data from Federal Communications Commission (2001).010203040506070
80
901001970198019902000Households, MillionTelephoneCable TVComputerInternetDBSBroadbandYear15Alexander Belinfante. 2001. ÒTelephone Penetration by Income by StateÓ (data through
2000). Industry Analysis Division, Common Carrier Bureau, Federal Communications Com-mission. July. Available online at <http://www.fcc.gov/Bureaus/Common_Carrier/Re-ports/FCC-State_Link/IAD/pntris00.pdf>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.56BROADBANDThe oft-cited penetration numbers for different communications ser-vices can mask considerable variations in the nature or quality of the
service. Both basic and higher tiers of capabilities have arisen in all of the
traditional or conventional communications infrastructures. For example,
touchtone and multiparty capability emerged as options in telephony,
FM emerged as a Òhigher-qualityÓ option compared with AM in radio,
and color emerged as a Òhigher-qualityÓ option compared with black-
and-white TV. Cable came along to provide yet another TV option, but
over a different infrastructure, with service tiers determined by the nature
and amount of the programming content. Even dial-up Internet access is
subject to variation. The speed ceiling is limited by the audio bandwidth
of the public telephone network, but the floor depends on the quality of
the individual telephone line. As a practical matter, what has been univer-
sally available is a lowest-common-denominator service, although up-
grades in provider networks tend to raise that floor over time (for ex-
ample, touchtone service has become the norm in telephony, and party
lines have gone by the wayside).As is seen in many markets, saturationÑor at least high and slowlygrowing levels of penetrationÑtends to prompt the introduction of en-hanced, higher-value and higher-priced offerings in the hopes of increas-
ing provider revenues. Sometimes this is in the form of new content or
applications, and at other times it reflects upgrades to the hardware and
software of the communications network itself. And, over time, new com-
munications technologies arise that complement the existing ones, offer-
ing new or significantly enhanced capabilities. The experiences of the
20th century suggest that few new technologies completely replace earlier
ones, and that whatever substitution occurs does so over a long timescale.
As demonstrated by the rapid rise of direct broadcast TV, new technolo-
gies can, however, pose a significant challenge to the existing players.Complicating an understanding of broadband in the last mile is theevolution of the community context. On the one hand, the community can
compensate in part for a lack of home access by providing access to broad-
band capabilities in publicly owned spaces (e.g., schools and libraries)
and through private organizations (e.g., businesses as employers). On the
other hand, the community can stimulate home access demand by gen-
erating content and opportunities for civic interactionsÑas well as sup-porting organizational use of the Internet, telecommuting and distance
learning, public awareness and education about how to benefit from
broadband, and so on. The lowest-common-denominator level of com-
munications infrastructureÑbasic telephone service; television via broad-cast, cable, or satellite; and dial-up Internet accessÑmay have been takenfor granted in all but the areas hardest to serve. However, differences
among communities raise questions about how broadband relates to localBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SETTING THE STAGE57economic development for purposes of attracting broader economic op-portunities (and a higher quality of life) for citizens (through access in
homes as well as schools, hospitals, and libraries). There is, of course, a
tension between the well-connected home as a place from which its resi-
dents can access people, information, and economic activity that may be
based physically quite far awayÑand that same home as an entity with aspecific physical location, which drives needs to access people, informa-
tion, and economic activity locally. TodayÕs islands of broadband havethe potential to intensify other differentiators of home and community
experience, which has led to the invocation of broadband in the evolving
consideration of a Òdigital divide.Ó Communities compose the social level
where interhome (and intercommunity) differences in access, burden, and

benefit are most apparent, and they are on the frontlines of the integration
of business and nonprofit influences on local activity. Although 1990s
public debates over information and communications infrastructure took
a national perspective, communities may play a larger role in moving
forward in the new century.ACCESS ECONOMICS AND EVOLVING APPLICATIONSBecause many costs are per-house-passed rather than per-customer-served and because of economies of scale, individual or isolated con-
sumers cannot induce providers to deploy expensive infrastructure at a
reasonable price. Thus, investors and industries search for clusters of
consumers who will pay for service before the investors and industries
will commit to upgrade or deploy infrastructure. One key recurring ques-
tion is what types of service the customer will pay for and at what levels.
Both the reach of different services and their enhancement paths reflect
differences in industry and provider business models. Consumers usu-
ally pay for the in-home hardware (and software) required to use a com-
munications service, but it varies as to whether they purchase it directly
or lease it from a service provider. Cable television reflects consumer
willingness to pay for access to programming content, in contrast to broad-

cast content, which is for the most part paid for by advertising. Consum-
ers who place a telephone call to an Internet service provider (ISP) pay
that provider for Internet access service, in addition to what they pay for
telephone service and for the equipment they use, and in addition to what
they may pay to access certain kinds of content or services through the
Internet. What people will pay regularly for information and communica-
tion services remains an open question as the choices proliferate. Provid-
ers of traditional services approach this question with concerns about
preserving traditional revenue streams as well as cultivating new ones.
Providers of new content and services have been struggling to find theBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.58BROADBANDright mix of advertising and subscription revenue models. Related ques-tions arise about who owns and/or manages the technology and content
used in the homeÑconsumer or service providerÑand what are the life-cycle costs and benefits from the perspective of consumer and provider.Thus, debates continue about the role of information and contentÑnotably entertainmentÑas a stimulus to broadband deployment. The ver-sion in the late 1990s and early 2000s has centered on open access: what
does it take to ensure that consumers can access information from any
source available through the Internet? Do preferential arrangements be-
tween ISPs and entertainment programming providers undesirably con-
strain consumer choice? Do such arrangements play an important role in
stimulating investment? The entertainment industries have proven busi-
ness models for serving consumers (e.g., broadcasting or cable television),
but the questions revolve around how and with what consumers are
served in a more complex world. These issues have brought consumer
advocates and Internet-related public interest groups into the discussion
as well.The Unpredictable Certainty16 had challenged the conventional wisdom
of the time that called for a Òkiller app,Ó a single use of communications
infrastructure significant enough in scale
Ñthat is, generating enough rev-
enue from customersÑto bring down the risk in infrastructure invest-ments. The experience of the late 1990s confirmed the absence of a new
killer application, and the experience of the early 2000sÑthe recognitionof weak performance or nonviability among many dot-com venturesÑshowed that even broad categories of seemingly successful applications
(such as various instances of electronic commerce) are not, in isolation,
sufficient to drive investment in last mile technologies. Only two proven
Òkiller appsÓ have emerged. One, e-mail, is the same application that
proved of enduring value in the data networks that preceded the com-
mercial Internet. The other, World Wide Web access, is in fact not really a
single application, but rather a general-purpose platform supporting a
wide variety of content and services. While ISPs have been able to derive
considerable revenue (if not always profitability) from providing Web
access, few companies have demonstrated success in deriving substantial
revenue or profits from Web-delivered content and services themselves.Although popular discussions of broadband tend to focus on PC ap-plications, typically uses of the Web, these are only one of many possible
applications of broadband. The growing trend toward digital storage and16Computer Science and Telecommunications Board, National Research Council. 1996.The Unpredictable Certainty: Information Infrastructure Through 2000. National Academy Press,Washington, D.C.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SETTING THE STAGE59communicationsÑone facet of what is frequently termed convergenceÑis also stimulating interactions with other kinds of equipment and ser-
vices. Today, as described in Chapter 2 in this report, home networks are
largely about connecting PCs together and sharing a link to the outside
but will increasingly also involve interactions among computers, enter-
tainment devices, and other appliances.Recent developments have underscored the political aspects of busi-ness and policy decisions related to broadband and have added to al-
ready significant regulatory and financial uncertainty, except in instances
when court decisions and administrative decision making have been clari-
fying. The popular debates over open access illustrate how politics can
have influence, but future, especially long-term, policy making relating to
broadband should have more solid analytical foundations. Providing
them is one mission of this report.Recent developments also raise questions about how future informa-tion and communications infrastructures may deviate from the classic
Internet as experienced in the mid to late-1990s. Certain wireless tech-
nologies and certain approaches to the ISP business provide illustrations
of something that falls short of a Òfull-serviceÓ Internet. Viewed as a
Òhalf-full glass,Ó such offerings may expand Internet access and other
activities to new groups of consumers; viewed as a Òhalf-empty glass,Óthey may deprive consumers of choices with various economic and social
benefits associated with unfettered access to all Internet content. The long-
term implications are unknown, but it is important to understand the
nature of the technical alternatives and their economic and other conse-
quences.In the meantime, the investment climate for major telecommunica-tions infrastructure upgrades is uncertain. Company and investor disap-
pointment over some previously touted technologies may be one factor.
For example, ISDN, which was implemented slowly and was perceived
as having significant shortcomings, has been adopted by only a modest
number of users. The failure of the much-anticipated Iridium satellite
telephone service underscored concerns about the financial risk of bold
communications infrastructure investments. Many of the Internet start-
ups that captured attention in the late 1990s tended to leverage more than
add to the infrastructure. The optical networking start-ups tended to fo-
cus on the core of the network and access for very large business users.
Start-ups that focused on local access, primarily DSL-based competitors
enabled by regulatory developments, found themselves foundering in
2000-2001, and a more general slowdown in the telecommunications sec-
tor was apparent in mid-2001. Even in the face of this uncertainty, incum-
bents have invested in infrastructure upgrades to meet what they see as
continued demand for broadband, and a new player in the form of geo-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.60BROADBANDsynchronous satellites has introduced a new option for broadband. It isunclear at present to what extent uncertainty in some segments of the
business could contribute to an overall slowdown in investment, and
caution should be exercised in projecting long-term prospects for broad-
band based on the present downturn.SCOPE OF THIS REPORTThe world of broadband is significantly more complex than that ofthe traditional or conventional communications infrastructures. This re-
port is designed to assess the nature of broadband, its deployment and
acceptance, expectations about future deployment, and the potential
longer-term technical and social implications of broadband access. The
challenging and sometimes necessarily speculative nature of this analysis
makes it inherently imperfect. Notwithstanding these limitations, an ad-
ditional goal of this report is to make useful recommendations about how
best to maximize the potential impact and rewards of broadband, gener-
ally exploring what will be required to achieve ubiquitous broadband
access, in the sense of both expanding the geographical reach of broad-
band facilities and addressing affordability issues.The focus of this report is on providing access to fixed (i.e., nonmobile)users, but the label Òlast mileÓ also applies to mobile applications, and the
report touches on mobile issues as appropriate. For example, to the extent
that one wishes to support near-seamless communications across fixed
and mobile locations, the two are coupled.Broadband poses many analytical challenges that go beyond thecomplex technical and economic landscape. One problem is the lack of a
common information base: detailed information is often proprietary; in-
formation presented in governmental proceedings is tailored to those pro-
ceedings; and systematic detailed data on deployment are hard to come
by. Perhaps an even bigger challenge relates to the generally poor track
record of both those within industry and outside observers in forecasting
information technology (IT) developments or its economic parameters.
Finally, basic assumptions will continue to shift. For example, changes
underway include the nature of installation (do-it-yourself/off-the-shelf
versus professional installer) and the specification of what can be shared
(e.g., a shift from built to leased wireless towers or from single-user to
shared conduit or fiber bundles). The future may well see change in li-
censing requirements (e.g., per-site versus per-system licensing of wire-
less service). Finally, the roles of the key playersÑconsumer, community,communications-industry sectors, and all levels of government from town
to federalÑcontinue to be in flux.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.SETTING THE STAGE61Notwithstanding these and other challenges, the Committee onBroadband Last Mile Technology has attempted to put forth, by consen-
sus, views about the broadband last mile that seek to have value in the 2-
to 10-year time frame. While such a time frame might seem to be daunting
in the face of the rate at which some of the basic technologies are advanc-
ing (MooreÕs law and its kin), the processes of deployment and accep-tance have always proceeded much more slowly, and there seems to be
no particular reason to expect a significant change in these time constants
going forward.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.62
WHY DEFINE ÒBROADBANDÓ?The term ÒbroadbandÓ has become commonplace for describing thefuture of digital communications. It is widely used to refer to a range of
technologies being offered or developed for the delivery of data commu-
nications services. Broadband refers most commonly to a new generation
of high-speed transmission services aimed at residential and small busi-
ness users. On its face, the term refers to the substantial bandwidth that a
high-speed connection can provide to a user.1 But is there a well-defined
threshold that marks the boundary between broadband and narrowband
services above which one can say a service is broadband? This chapter
explores this and other dimensions of how one defines and characterizes
broadband.There is an obvious lower bound of broadbandÑthat is, whether theservice offers higher capacity than dial-up access (which is limited to 56
kilobits per second [kbps] per phone line) or even ISDN service (the basic
service offers two 64-kbps channels; experienced service can be at 128
kbps or higher), which was introduced with the promise of providing
higher-speed service but was never widely adopted in the U.S. residential
market. The speeds offered by broadband local access services, such as
cable modem and DSL, generally start well above this threshold (in the1Greater communications capacity translates into the ability to deliver a given amount ofinformation faster, so ÒspeedÓ is often used synonymously with ÒcapacityÓ in this context.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?63hundreds of kilobits per second effective bandwidth or better), but theyspan a wide range of speeds, with consequences for the types of applica-
tions they are able to support. A service may, for example, be fast enough
to support rapid Web browsing or a few channels of telephony, but too
slow to support even a single TV-quality video stream.Various groups have struggled to develop appropriate definitions ofbroadband, and these definitions have changed over time. In the 1980s
and early 1990s, broadband referred to rates greater than 45 megabits per
second (Mbps), and ÒwidebandÓ referred to rates between 1.5 and 45
Mbps. Then, circa 1995, broadband commonly referred to anything 1.5
Mbps and higher in most circles; thus, it was an order of magnitude
greater in capacity than ISDN service.2 Mandated to report to Congress
on deployment, the FCC, in its 2000 report on broadband deployment,3defined an Òadvanced telecommunications serviceÓ as one that is at least
200 kbps in each direction. The speed and two-way requirement at-
tempted to capture the intent expressed in the Telecommunications Act of
1996Ñthat the speeds of what the act terms Òadvanced telecommunica-tions servicesÓ should exceed the rates offered by the technologies avail-
able to residential customers at the time of the actÕs passage.4 At the time
of the actÕs passage, residential customers were generally limited to dial-up service (then typically no more than 33.6 kbps). Hinting that a defini-
tion should also be, at least in part, driven by the requirements of user
applications, the FCC report also observed that the 200-kbps threshold it
selected is roughly the threshold above which the time it takes to load a
Web page becomes comparable to the time it takes to turn the page of a
book. But a 200-kbps service would be inadequate to support even a
single TV-quality video stream to each house, let alone the multiple such
streams that a family might reasonably use, which would require mul-
tiple megabits per second. Nor do TV-quality video streams represent the
most bandwidth-demanding application one could imagine in the future.These definitional questions also arise in an international context asother countries explore policy options concerning broadband. For ex-2For a historical view of prospective services, see IEEE Network special issue on the North
Carolina Information Highway, November/December 8(6), 1994.3Federal Communications Commission. 2000. Inquiry Concerning the Deployment of Ad-vanced Telecommunications Capability to All Americans in a Reasonable and Timely Fashion, andPossible Steps to Accelerate Such Deployment Pursuant to Section 706 of the Telecommunications
Act of 1996 (Second 706 report). CC Docket No. 98-146, Second Report, FCC 0-290 (rel.August 21). Available online at <http://www.fcc.gov/Bureaus/Common_Carrier/Orders/
2000/fcc00290.pdf>.4The FCC report defines a broader class of servicesÑÒhigh-speed services,Ó defined as
services that exceed 200 kbps in at least one directionÑof which advanced telecommunica-tions services are a subset.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.64BROADBANDample, two recent Swedish governmental commissions took a look at thissame question (but without having to factor in the U.S. statutory lan-
guage, as did the FCC) and adopted substantially higher-speed thresh-
olds: symmetric 2 Mbps and 5 Mbps.5 In the end, neither the definitions of
the FCC or those of the Swedish commissions are entirely satisfactory
(indeed, FCC staff speaking at the committeeÕs 2000 workshop acknowl-edged difficulties associated with the FCC definition).Defining broadband is more than an academic exercise. Numerousgroups would stand to benefit from workable definitions of what consti-
tutes broadband. They include:¥Consumers, who would like to be able to evaluate service offeringsto see if the offerings are likely to meet their needs;¥Service providers, who would like to develop, invest in, and deployservices that consumers will need and want;¥Application and content developers, who would like to understandand track the connectivity performance options available to consumers;¥Policy makers or regulators, who seek to monitor broadband servicedeployment and measure the impact of policy or regulatory decisions on
deployment, define the characteristics of services eligible for tax credits or
loans, or define the characteristics of services required in build-out com-
mitments associated with regulatory relief; and¥Public interest groups, which seek to evaluate capabilities availableto consumers and to understand the implications of alternative policy
approaches that influence those capabilities.Framed in this way, defining the term ÒbroadbandÓ in some sense
also involves (1) identifying the kinds of applications that consumers are
likely to find useful and desirable and (2) determining the benefits that
different segments of the public anticipate from access to broadband ser-
vices. The definition of broadband used by each of these groups will
reflect that groupÕs expectations and, consequently, can have a significanteffect on decision making. Too limited a definition, such as establishing
too low a data transmission rate as the broadband threshold, could result
in a mismatch between expectations and capabilities, while a definition
that is unrealistic in terms of technological capabilities, costs, or consumer
demand could prompt inappropriate or poorly aimed policy interven-
tions. The absence of a consensus on definitions will confuse political5Swedish Special Infrastructure Commission (June 1999): Broadband should be definedas at least 2 Mbps (symmetrical) to the user. Swedish IT Commission (November 1999):Minimum 5 Mbps to the user.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?65debate on the subject and require ongoing debates about what definitionsto use.OVERVIEW OF THE TECHNICAL CHARACTERISTICSOF BROADBANDCommunications capacity, or speed, is only one of a set of perfor-mance characteristics of a service. That it is not the whole picture is easily
seen in the contrast between dial-up access, where the modem must place
a telephone call and negotiate a connection with the ISPÕs modem, and theservices available today that are generally considered broadbandÑwhichfrequently offer Òalways-onÓ connectivity as well as high speed. Along
with speed and always-on are additional parameters such as bandwidth
symmetry and addressability that are important components of a defini-
tion of broadband. Each of these is considered in the sections that follow.SpeedThe speed or bandwidth of a serviceÑthe rate at which one can trans-fer data to and/or from the homeÑis a function of multiple factors. Be-cause the effective bandwidth reflects the capacity of the end-to-end con-
nection between sender and receiver, the speed seen by a user can be
constrained at any one of a number of points between the userÕs computerand the computer providing a particular service. However, speeds within
the core network have been rising, at least in the United States and other
developed nations, and the capacity of the network link between the user
and the broadband providerÕs network is one of the crucial factors thatdetermines how the broadband service can be used.The better-than-dial-up criterion for broadband assures that a serviceis at least a little better than what was available before, but it does not
address the question of whether the service is good enough. And while a
2- or 5-Mbps threshold would seem ample for most applications envi-
sioned today, it might, on the one hand, prove inadequate in the future,
or, on the other, raise questions about whether its costs today would
exceed what customers are willing to pay for today. Later, this chapter
explores several approaches to answering the fundamental question, How
fast is fast enough?As indicated earlier, the effective speed for interacting with an Internethost is not merely a function of the performance of the broadband local
access linkÑit depends on the entire path between the host and the user,and also on the loading on the host computer. As a result, depending on
the circumstances, improvements in the performance of one link does not
necessarily improve overall performanceÑit may only shift the bottle-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.66BROADBANDneck. Network infrastructure such as caching and content hosting withinthe local ISP access networks also has a substantial effect on perceived
performance to the end user and loading on the connections to the core
Internet.Where are the bottlenecks, and how might they shift as broadbandaccess technologies are upgraded? Today, for dial-up users interacting
with most commercial hosts, the bottleneck is the last mile dial-up con-
nection. With the current generation of deployed broadbandÑcable mo-dems, DSL, or wireless servicesÑthe location of the typical bottleneck, atleast for routine Web access, is less clear. It may be in the last mile, within
the local ISP network, at the upstream linkage between the cable-modem
or DSL ISP and the Internet core, closer to the host, or even in the userÕsPC.From an applications perspective, DSL and cable modem broadbandofferings today remove barriers to many applications. Advanced fiber-
to-the-home (FTTH) networks with very high capacities (such as gigabit
ethernet) enable additional applications, but they also illuminate a new
set of barriersÑsuch as the cost of core Internet connectivity at extremelyhigh speedsÑwhich present an obstacle to the widespread deployment ofthese applications. An FTTH network offers enormous amounts of band-
width (e.g., gigabit Ethernet speeds) within the service area, but the fiber
networkÕs connection to the core Internet service providers may in fact beconcentrated into a much slower link (say T1, 1.544 Mbps) that is shared
by all users of the network. In this regard, residential fiber broadband
networks will come to resemble the networking situation on university or
corporate campuses, where local bandwidth is plentiful, but connectivity
beyond the local campus is a comparatively constrained shared resource.6The link to core Internet service providers is typically going to be paid for
on a leased basis, and its costs rise as the bandwidth of the link increases.
In contrast, high local bandwidth within the community incurs mainly
the fixed capital costs of installing and lighting the fiber network (which
can be financed for a long period of time). Thus, where very fast FTTH
networks are deployed, they can have the property that access to hosts
within the community served is very fast, but that more general access to
Internet sites is much slower; it may thus be possible to exchange
high-definition video with a neighbor or a local community center, but
difficult in the short term to extend this level of performance beyond a
modest geographical region.6This phenomenon has been experienced by universities that saw new bandwidth-intensive applications such as Napster clog their backbone Internet connections.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?67Latency and JitterWhile the net throughput is the most significant enabler of manyapplications, two additional parameters are crucial for applications that
depend on real-time delivery of information or interaction, such as tele-
phone or interactive game playing. ÒLatency,Ó or delay, is a measure of
how long it takes to deliver a packet across the network to its destination.
Latency is a function of the distance the packet travels (speed of light,
which is of particular significance for traffic carried over geosynchronous
satellites), the length of time the packet waits in queues within the net-
work, and the delay that results from retransmission when a packet is
dropped due to congestion within the network. Latency especially affects
applications that depend on interaction, such as human-to-human con-
versations, games, and the like. ÒJitterÓ measures the variation in latency,
resulting from such factors as variations in the path taken by each packet,
variable queue lengths, or variations in the level of congestion within the
network. Even if the average latency is acceptable, high jitter may make
the application unusable nonetheless.Symmetry Between Upstream and Downstream CapacityToday, telecommunications services, including broadband, do notnecessarily provide the same capacity up- and downstream. At one ex-
treme, digital cable television service and direct broadcast satellite service
provide a very high data rate digital connection into the home. These
services may also provide a low data rate return pathÑover the same linkor over an alternative return link using a phone lineÑto enable enhancedservices such as pay-per-view. However, most users probably would not
think of these services as broadbandÑthey expect broadband to includehigh-speed Internet access (perhaps along with these predominantly one-
way services). On the other hand, broadband does not necessarily imply
that one must have anything close to symmetric bandwidth to and from
the premisesÑthough some would argue that it will, over time, as a con-sequence of the minimum bandwidth particular applications require.The asymmetric services typically found in todayÕs residential broad-band services were designed with one of two asymmetrical application
classes in mind. One class is Web browsing, where a low-bandwidth
upstream connection serves to carry a userÕs requests for Web pages, andthe higher downstream connection returns the content the user has re-
quested; e-commerce or other applications in which users interact via
entering information in Web forms involve a similarly asymmetric com-
munications model. The other class, audio or video delivery, in which a
small amount of data is sent upstream to select and direct delivery of aBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.68BROADBANDparticular stream (delivery of packets for playback in near-real time), iseven more asymmetric.While Web browsing has been a dominant application of residentialbroadband, accompanied by more limited audio/video streaming, peer-
to-peer applications have surged recently. These applications, which use
many individual computers instead of a central server to distribute con-
tent, require significant upstream capacity for each computer. They have,
as a result, presented ISPs with traffic loads that are at odds with the ISPsÕassumptions about asymmetric traffic7 and have raised questions about
what shape user demand will take in the long term. Similar pressures
result from other applications in which users host content on their local
machines, creating upstream demand whenever this content is requested.
These pressures, at odds with the capabilities of todayÕs networks, havealso led some broadband ISPs to prohibit customers who subscribe to
consumer/residential services from running servers on their computers.It is not clear at this point how traffic patterns will evolve as applica-tions mature and as the population of broadband network users moves
beyond early adopters. There is at least some reason to believe that the
traffic patterns will in fact be asymmetric, though perhaps not as strongly
as some of the broadband ISPs initially assumed in their network design
and pricing models. But it is also important to recognize that some of the
demand for symmetric bandwidth is a political rather than a business or
engineering proposition. If the networks are designed to make it impos-
sible, or very expensive, for individuals to originate the kind of traffic
associated with the provision of services or content to significant audi-
ences, it would foreclose the possibility that high-traffic upstream ser-
vices will emerge on a highly distributed, grass-roots basis. This prospect
points toward a model of the future broadband-enabled Internet as an
environment dominated by commercially provided services connecting
to customersÑan outcome that in the view of some would fall short ofbroadbandÕs full potential.More generally, while much of the focus on broadband has been onits potential as a channel for delivering information, broadband also pro-
vides a more general communications channel (into and out of the pre-
mises). On the one hand, e-mail and instant messaging are prominent
examples of communications applications that do not depend on large
amounts of upstream bandwidth (or downstream, for that matter), but7For example, according to Jim Hannan of Sprint Wireless at the committeeÕs June 2000workshop, ÒAs a point of data, in our experience, we would love it if [the ratio of down-stream to upstream] were 10 to 1. You know, our network model said worst case: 8 to 1.Unfortunately, our experience is 2 1/2 or 3 to 1, downstream to upstream.ÓBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?69that provide evidence of demand for convenient, Internet-based commu-nication. On the other hand, as consumers start transmitting video clips
(produced using increasingly inexpensive digital video cameras), band-
width requirements could increase significantly. On the horizon are a
number of communications applicationsÑtelephony being the most ob-viousÑthat place increasing demand on the upstream channel.The detailed discussion of application classes below suggests that thejury is still out on the long-term implications of such applications for
symmetry demands in broadband services. Nevertheless, a number of
pressures for increased upstream capacity are evident.Always-OnIn addition to higher bandwidth, a broadband connection also gener-ally provides an always-available connection to the Internet. One princi-
pal implication of always-on broadband service is that, for the first time,
residential users have nearly instant access to Web or other Internet ser-
vices on demand. Before the advent of broadband services, residential
and many small business Internet users were confined to using a dial-up
line to access the Internet. With dial-up, the user faces a noticeable de-
layÑthe sum of the time it takes to place a call between the user and ISPmodems, the time it takes for the two modems to negotiate a connection,
and the time it takes to log in (generally by authenticating the user via a
password) to the ISP. The delay is increased if the user makes a habit of
turning off the PC between sessions, since the time it takes the computer
to boot up must also be added to the time it takes before a user can access
the Internet. By eliminating the need to place a telephone call, broadband
services greatly reduce the time required. While there is some delay asso-
ciated with negotiating communications parameters when the customerÕsmodem is powered up, these devices are designed to be left on all of the
time, meaning that there is continuous connectivity between the modem
and the network to which it is attached. Laptop computers have had
power management features for some years; more recently this capability
has been added to desktop computers. Power management capabilities
make it possible to have computers ÒsleepÓ (quickly switched to a low-
power state) and then be reawakened whenever the user wishes to access
Internet resources.The term Òalways-onÓ might conjure up visions of some sort of com-
pelled use in which computers or applications must be left running all of
the time. Always-on does not imply this; it refers merely to a characteris-
tic of broadband networks that enables network communications to be
initiated at any time. Users remain free to close software programs or shut
down computers as they wish. Of course, some applications and com-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.70BROADBANDputer devices will be designed to work best when they are always con-nected, and many users may choose to keep some computers or applica-
tions in an always-connected state.Research has shown that removing the start-up delay changes theway that users perceive and use the Internet. Because the overhead asso-
ciated with accessing the Internet becomes very small, there is more ca-
sual use of the network for very short tasksÑsending a short message orlooking up a piece of information. This change also has the effect of sig-
nificantly reducing the length of a typical Òsession,Ó as users begin to
regard the network as an always-available utility, even though total use
may stay the same or increase. Users also may change their behavior to
leave their PCs on more of the time, either fully powered up or in sleep
mode.8The popularity of instant messaging (and chat rooms) despite the factthat the majority of household Internet users connect via dial-up service
demonstrates the high level of user interest in using the Internet for com-
munications applications with a real-time dimension (in contrast to the
delays associated with e-mail). However, because dial-up users are un-
likely to be connected to the Internet at any given time, it is generally not
assumed in todayÕs applications that they are always connected. In analways-connected broadband environment, these applications become
much more powerful. For example, the value of an Internet telephony
application is limited if calls can only be placed if the person being called
happens to have an active dial-up Internet connection at the time the call
is placed. Many other applications are most useful when the equivalents
of telephony ringing and signaling capabilities are available.Bandwidth aside, the combination of quick access and new applica-tions is compelling. Indeed, one sees this value reflected in value-stratifi-
cation practices of several DSL service providers. They provide two tiers
of residential serviceÑa cheaper one that requires users to go through alog-in screen when they wish to connect and a more expensive one that
provides continuous connectivity. Results from the INDEX project at the
University of California, Berkeley, which was designed to learn how much
people are willing to pay for various levels of bandwidth on demand,
provide further support for the proposition that a considerable fraction of
the value that users attach to broadband may stem from its always-on
quality. In that experiment, users tended to keep a basic 8-kbps service,
which was provided free and was on all the time, but on average they
placed a surprisingly low value on their waiting time, which in the ex-8Ken Anderson and Anne Page McClard. 1998. Always On: Broadband Living Enabled. 
Tech-nical report, Broadband Innovation Group, MediaOneLabs. October.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?71periment could be avoided by purchasing a higher-bandwidth capabilityon demand.9There will be important new applicationsÑhealth monitoring, secu-rity, and the likeÑwhich will be possible only with the always-on charac-teristic, but users will choose whether they want to use those applications.
The notion is familiarÑtelephones are generally left connected, ready torespond to a ring signal. What always-on should conjure up, however, are
concerns about security. TodayÕs end-user computing devices are vulner-able to a variety of network attacks.10 Always-on connectivity increases
their exposure to these threats (see below).Connectivity Sharing and Home NetworksAnother attribute that users sometimes associate with broadband ac-cess is that of a premises network. Dial-up access is generally done from a
single machine. The speed of the dial-up connection is slow even for a
single machine, so trying to share that bandwidth among multiple ma-
chines is not generally very desirable. Moreover, it is common for each PC
to have an analog modem. Thus, users have generally arranged to time-
share the household phone lines sequentially among a number of ma-
chines in a home (though quite possibly not without disharmony resulting
from contention over access to the phone lines). A broadband connection,
however, by virtue of its always-on nature and greater capacity, makes it
reasonable to support multiple machines concurrently. Thus, broadband
Internet access and use of home networks will increasingly be interre-
lated.11Spurred in large part by the initial deployments of broadband ser-vices to the home, a variety of home networking technologies are avail-
able in the consumer market (Box 2.1). The year 2000 represented some-
thing of a turning point for the mass-marketing of these devices, seen in
the increasing number of vendors offering products and in falling prices.9Hal R. Varian. 2000. Estimating the Demand for Bandwidth. Technical report, University of
California at Berkeley. August 1999, revised August 29, 2000. Available online at <http://www.index.berkeley.edu>.10See CSTB, NRC. 1998. Trust in Cyberspace. National Academy Press, Washington, D.C.11Another possibility, most plausible with wireless access in which each device has itsown antenna, is that the devices within the home would each have their own connection to
the network infrastructure. While this configuration, in which there is no home network,may have advantages for the consumer in terms of ease of management, it also has thelimitation that interdevice communications would have to be routed through the local ac-
cess link to the core network and then return through another local access link. Such anarchitecture would likely preclude such applications as having a DVD player transmit aprogram to a remotely located video display.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.72BROADBANDBOX 2.1In-Home Networking TechnologiesWired EthernetThis is the industry-standard networking technology commonly used in office andbusiness settings. Ethernet today routinely runs at 100 Mbps, which provides adequateperformance for many applications, even video applications. (Quality-of-service manage-ment, which is not provided by standard Ethernet, may, however, be required for very-
high-end applications.) The primary difficulty with using wired Ethernet is that most homesare not wired with the requisite category 5 wiring. There are long-term efforts aimed atpromoting the installation of networking-compatible wiring in new construction;1 rewir-
ing of existing dwellings is generally restricted to early technology adopters who are will-ing to deal with the cost and disruption associated with installing new wires within ahouse. With a wired infrastructure in place, Ethernet is a very inexpensive solution, with
interface hardware available from many vendors and frequently incorporated into com-puters. It also offers ample headroom for future speed upgrades (1 gigabit per second[Gbps]s has been demonstrated over four category 5 twisted pairs of 150 feet). For the
slowly growing set of users that have the requisite wiring, Ethernet is a likely technology ofchoice.Phone Line NetworkingPhone line networking operates by using a high-frequency carrier superimposed overa homeÕs existing analog voice telephone wiring, allowing any standard phone jack withinthe house to become a network port. For homes that have phone jacks already installed in
locations where networked devices are likely to be located, as is the case in many U.S.homes, this is an attractive solution. An industry standards group, the Home PhonelineNetworking Alliance (HPNA), has defined two standards: HPNA 1, which provides a

1-Mbps data rate, and HPNA 2, which increases the data rate to 10 Mbps while maintain-ing backward compatibility with the first version. The HPNA specification does not inter-fere with the normal voice operation of the phone line, and it operates in a different band
from a G.992.2 asymmetric digital subscriber line (ADSL) (G.lite) so that it can coexistwith that standard as well. HPNA products are currently offered by a number of vendorsfor attachment to existing computers via parallel port, universal serial bus (USB), or via a
peripheral component interconnect (PCI) add-in card. Additionally, a number of PC ven-dors are shipping home PCs with HPNA integrated into the system directly. The technol-ogy is relatively inexpensive and HPNA is being bundled with home computers today,
much as most home PCs include analog modems. HPNA has the drawback of interferingwith broadcast radio and some, but not all, types of DSL.1Wiring AmericaÕs Homes, sponsored by the Home Automation Association.See <http://www.homeautomation.org/wah.html>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?73Wireless NetworkingWireless solutions are very attractive in that they require no wires to be installed. Theyallow networked computers to be located anywhere within the home, and they supportmobility within the house. In the past, wireless technologies suffered from being too ex-
pensive for broad consumer acceptance, had lackluster performance, and were toopower-hungry for use in battery-powered devices. More recently, two standards using theunlicensed 2.4-gigahertz (GHz) band that overcome these shortcomings have emerged:
802.11b and HomeRF. 802.11b has been defined by the Institute of Electrical and Elec-tronics Engineers (IEEE) and supported by the Wireless Ethernet Compatibility Allianceindustry consortium. It uses direct sequence spread spectrum rather than frequency hop-
ping, and operates at up to 11 Mbps for data. A number of vendors have announced802.11b products. 802.11b is also being widely supported in business environments andpublic access points and is also being used in a number of community access initiatives.
With both standards, there are issues of interference with other uses and other technolo-gies that make use of the same radio spectrum.Products using a new standard from IEEE (802.11a), which use the 5-GHz band andpromise data rates of 54 Mbps, are under development. Another wireless LAN standardoperating in the 2.4-GHz band, 802.11g, would boost speeds to as much as 54M bit/secwhile proving backward compatibility with the 802.11b. Another relevant wireless stan-
dard is Bluetooth. Currently Bluetooth targets data rates of less than 1 Mbps, althoughwork is ongoing to define higher-speed versions. However, it focuses now and probably inthe future on short-range Òpersonal area networking,Ó at less than 10 meters (m). While
Bluetooth will likely have applications in the home, the range may restrict it from being ageneral-purpose solution for home networking. Also, because both Bluetooth and thecurrent generation of wireless LANs use the same spectrum, there are still unresolved
issues of how to efficiently share the spectrum and avoid interference.Powerline NetworkingBecause power outlets are ubiquitous in homes, there has been long-standing interestin technology that would provide high-speed networking over household AC power wir-ing. However, there is a great deal of interference present on power wiring, because thesewires are used to supply power to motors and other very electrically noisy devices. In
addition, many homes utilize both phases of the supply power in different circuits withinthe home; communicating across outlets connected to different phases requires installa-tion of bridges between the phases, which may be difficult for consumers themselves to
install.In multidwelling units there are also potential interference problems, analogous tothose faced in wireless networking, associated with multiple users using common lines. To
date, the most common use of networking over the powerlines has been for X-10 homecontrol devices that permit remote operation of lights and the like. In the year 2000,several companies began shipping, or announced, powerline-based data networking prod-
ucts, with claims of data rates up to 10 Mbps. The HomePlug Powerline Alliance availableonline at <www.homeplug.org> has been formed and is promoting its 10-Mbps baselinestandard. Field trials and certification lab are reportedly approaching.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.74BROADBANDIn 2001, a number of products that integrate home networking technologyhave been announced. Gateways connect to DSL or cable modems and
provide home networking via a variety of technologiesÑthe range aloneindicates progress in standards-setting and growing technology maturity
in this arena. Vendors also are integrating these functions into the mo-
dems themselves, aided by the minimal cost of adding home networking
functionality to the silicon that implements the modem. Such integration
extends to computers and Internet appliances as well, with these devices
incorporating one or more home networking technologies. These trends
work toward making broadband installation a simpler process for the
consumer, eliminating the need for additional wiring, and lessening the
need for visits by installers.Finally, even for a single computer on a broadband connection, usersoften have an expectation of being able to multiplex among a number of
applications. Dial-up access, in contrast, often constrains a user to be
doing one thing at a time with the system. This may be because it is
simply too slow to have multiple activities sharing the connection, or it
may even be because the resulting effective slowdown of the connection
simply renders one of the applications unusable. For example, listening to
Internet audio while also downloading files is likely to make the audio
drop out over a dial-up connection, whereas simultaneously listening to
Internet radio, downloading files, and surfing the Web is quite feasible
over a high-speed connection. Although rooted in what is enabled by the
speed of the connection, this change is as much a change in user behavior
as it is about a new technological capability.AddressabilityA critical requirement of many applications is that a userÕs computerbe addressable in some fashion by software running on computers else-
where on the Internet. This means that someone on the Internet can ini-
tiate communications with the user, much as a telephone caller can place
a call to a subscriber by dialing the subscriberÕs telephone number. Ad-dressability also enables such functionality as a user being able to run a
server that other Internet users can access (a capability demonstrated
with Napster and Gnutella).While addressability is commonplace in the business use of the Inter-net, it is the exception for residential users today. One reason is provider
policyÑnot all service providers allow inbound connections in their poli-cies. Another reason is the technical means of connecting the user to the
Internet: Addressability is most easily provided when each computer de-
vice within the home has its own globally addressable Internet Protocol
(IP) address. Many residential customers are provided dynamically as-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?75signed addresses, and even if they have a static address, they may onlyhave one or a fewÑmeaning that each computer within the home maynot have a globally routable address as a result of the use of network
address translation by either the ISP or within the home gateway used to
provide connectivity to multiple computers within the home.Addressability is a double-edged sword. Being able to address homecomputers from other computers attached to the Internet enables power-
ful new applications, but it carries with it issues of security and privacy
that will need to be solved. For example, exposing computers to the

Internet on a continuous basis makes them more attractive and poten-
tially vulnerable targets for attacks aimed at destroying data stored on
them or otherwise disrupting their operation, viewing information stored
on them, or manipulating them for use in launching attacks on other
Internet services. ISPs may take some steps to help protect users, such as
filtering out possibly hostile traffic (e.g., blocking transmission of NetBIOS
packets, which could be used to alter or delete files and are generally only
intended for use within local area networks), but the security of home
computers depends in large part on the security of the computers or
gateways installed within the home. That security depends, in turn, on
the adequacy of add-on devices such as firewalls, which users have to
configure to filter traffic and deliver warnings appropriately, and on the
quality of typical home-system software, which tends to be low from the
perspective of security.12 Another risk is posed by always-connected, ad-
dressable sensor devices such as cameras. Breaches of security could en-
able outsiders to read or take control of these devices, allowing them to
view or otherwise monitor what happens within peopleÕs homes. Andtampering with control devices could cause direct physical harmÑforinstance, someone with access to a householdÕs networked climate con-trols might maliciously turn off the heat during a cold spell. In a develop-
ment that signals increased awareness of security issues and suggests a
willingness to trade off flexibility for additional security (despite argu-
ments in favor of the end-to-end principle in technical communities), con-
sumers have been purchasing gateways that incorporate firewalls as well
as installing software-based firewalls on individual computers.Controls on Applications and ContentQuestions about potential limitations on the content and applicationsthat will be available to the typical consumer of a broadband service have
figured in the cable open access debate, which features a conflating of12See CSTB, Trust in Cyberspace, 1998.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.76BROADBANDpractice, motivation, and perceived impacts that varies with point of view.The issues are outlined here because they contribute to both perceptions
and realities of commercial broadband offerings, which will be imple-
mented based on choices made by providers that must decide among
technological and strategy options. Given the newness of the market-
place, it is easy for critics to assume intent based on experience with
traditional media, especially cable, and it is hard to predict what practices
will succeed in the broadband marketplace, regardless of their fate with
traditional media. About the only certainties at this point are that the
service providers are trying to make money, that content providers seek
access to users, and that provider policies and practices are evolving at
the same time as the technologies and businesses.Already, there are various models for Internet service, ranging fromthe ISP that provides only basic IP connectivity to the ISP that provides a
modest bundle of services and content, to ISPs such as America Online
(AOL) and Microsoft Network (MSN) that aim to provide a wide range of
products and services. Providers can seek various degrees of control over
particular applications that run over their service or restrict access to
particular content, perhaps simply by making it much easier to access
preferred content. This may happen for various reasons, and the effects
may be either primary (to promote use of certain content) or secondary (to
make use of certain content less convenient).If some content (e.g., from sources with business relationships withproviders) is cached and easily accessed, other content may appear to be
harder to get to. Uncached Web content will, for example, be slower to
loadÑespecially if the source is far from the user and/or on a networkwith poor connectivity to the userÕs. In the extreme case, access to non-cached content might be poor enough to make it seem effectively filtered;
consumer advocates express this concern about the fate of content from
nonprofit sources, but the concern remains hypothetical.Service providers provision bandwidth, especially upstream, basedon a particular business modelÑwhich makes assumptions about who issending how much of what to whomÑor on the assumption that a certainfraction of traffic can be cached. Or, providers might use restrictionsÑsuch as restrictions on virtual private networks or on operating house-
hold-based serversÑas a means of value stratification, charging more tothose who value, use, and will pay for more flexibility or capacity.Actions that restrict upstream communication raise concerns aboutinnovation enabled by end usersÕ being able to originate content or appli-
cations. A targeted approach by ISPs might alleviate some concerns. For
example, a provider that is concerned with upstream bandwidth scarcity
might more effectively deal with excessive bandwidth use (relative to
provisioning assumptions) by applying measures that monitor or restrictBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?77bandwidth consumption rather than by prohibiting all users from, say,running servers. While some legacy equipment might not support band-
width monitoring or control, most ISP equipment today would permit
this. Opinions will differ as to whether restrictions reflect legitimate op-
erational considerations; valid business decisions to differentiate custom-
ers; or unreasonable attempts to limit customer access to applications,
content, and services.Assessment of provider conduct should distinguish between the useof caching and similar techniques, which are aimed at improving access
to some content by moving it (via distributed copies) to locations closer to
users, and the use of filtering, which limits access to some content en-
tirely. Steering or restricting customers to certain content runs counter to
the traditional Internet model, in which Internet service is deemed syn-
onymous with access to all Internet content. The success of these Òwalled-gardenÓ models depends on whether consumers want the preferred con-
tent (or, in the view of critics, have no alternative). Actual consumer
preferences and reactions to their experiences as users confronting differ-
ential ease of access to content are an important but unknown factor.Implications of Network Design/ArchitectureAnother parameter that deserves consideration is whether Òbroad-bandÓ refers exclusively to Internet service or is a more inclusive term
that refers to a set of data communications services. Is the point of broad-
band to bring the Internet to the home or small business at much higher
speed and with characteristics such as always-on, or is broadband really
about delivering to the home a bundle of digital services, which include
IP service, that are demultiplexed at a gateway? Cable television systems
today deliver both IP data and digital television signals. Higher-quality
pictures and greater system capacity than analog cable systems could
deliver were the original motivation for deploying hybrid fiber coax (HFC)
in cable systemsÑIP data capabilities were added later. This video viaMPEG (a standard for video compression from the Motion Picture Ex-
perts Group) streams is largely one-way (possibly with a low-capacity
return channel to allow the selection of content or other interactive fea-
tures), and the content is offered through various service bundles and
pay-per-view options defined by the service provider. Looking forward,
to what extent will services be delivered using plain-vanilla IP versus
more specialized protocols and architectures? Running video and audio
over plain IP, for example, is not without problems today, and these,
together with business considerations, may well lead providers to devise
other network protocols and systems to deliver audio and video along-
side IP (for other applications), perhaps coming out of the set-top box intoBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.78BROADBANDproprietary or consumer-electronics-oriented interfaces that feed TVs andother appliancesÑpossibly with additional features such as intellectualproperty protection engineered in at a very low level.Another characteristic of broadband networks is the increasing so-phistication of network monitoring capabilities. Usually discussed in the
context of quality of service, commercial broadband providers are moti-
vated to track individual (per-home) usage patterns to accurately assess
and supply different levels of broadband capabilities. For example, users
could pay for larger upstream bandwidth to support a home business.APPROACHES TO DEFINING BROADBANDThe discussion above suggests the pitfalls of picking a specific band-width threshold as defining broadband, and Chapter 3 displays the wide
variety of requirements posed by different classes of applications. A bet-
ter approach may be to define a broadband service as one that meets a
certain set of objectivesÑobjectives that will change over time.One important task in engineering any system is to examine thetrade-offs between the performance of different components. The first
definition offered here takes into account the multiple performance pa-
rameters that affect the overall performance of a broadband service. For
example, one can compensate for limited bandwidth by compressing the
data being transmitted, a technique that is widely relied on today. Or, one
can take advantage of ample local storage capacity as might be found on
todayÕs computer hard drives to store content so that it does not have tobe transmitted over the connection at the time it is needed.13 This perspec-
tive motivates one definition of broadband:Broadband Definition 1. Local access link performance should not be the limitingfactor in a userÕs capability for running todayÕs applications.To illustrate how this definition could be used in practice, considerhow this applies to Web browsing. Speed here is inherently limited by
factors independent from those imposed by the bandwidth of the local
access connection. The speed-of-light transit time poses a fundamental
limit to the rate at which data can be sent across the network using the
data transmission protocols on which the Web is based. For todayÕs typi-cal Web page, a user Òcruising the WebÓ will not see any material perfor-mance improvement once his or her access link has a capacity of about13One local storage strategy, caching, keeps local copies of frequently used items. An-other strategy, replication, preloads information so that it is available for later use.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?791 Mbps.14 In other words, upgrading an individual user
Õs 1-Mbps linkwith one 10 times faster would not speed up the transfer of a typical Web
page. So for this application and at this point in time, an access link
provides broadband service when it provides a capacity approaching 1
Mbps. It is important to realize that this is a statement about todayÕs Webcontent and protocols and todayÕs network. The availability ofhigher-performance links would likely give rise to richer content that
would take advantage of that availability and would also provide incen-
tives to colocate caches or streaming servers close to the broadband access
point, leading to an improved user experience as a result of the faster local
access link.This viewpoint can also be useful in identifying where to make in-vestments to alleviate potential bandwidth bottlenecks within the net-
work. With a major source of congestion residing in the transit circuits
that connect broadband providers to the Internet, improving local access
performance above that bound will not improve the net performance seen
by the user accessing the Internet. Everywhere in the Internet (except
possibly on the access link), the average traffic of a sufficiently large num-
ber of users aggregated together on a given link will be constant on aver-
age, even if the traffic demands of individual users varies considerably.
However, the guarantee is statistical in nature, meaning that there is al-
ways the potential for fluctuations that result in congestion somewhere in
the network. In contrast, an individual access link is subject to much more
predictability. An unshared link (e.g., a DSL connection to the central
office) will be a bottleneck only if it is simply too slow (has too little
bandwidth). Even for local access technologies with a shared local me-
dium (e.g., an HFC system or the feeder to a DSL remote terminal), the
implications of sharing can be understood fairly easily, because one knows
(based on provisioning and traffic engineering) how many potential users
there are on any given segment. Thus, where there is a compelling appli-
cation for which the access link bandwidth is identified as the limiting
factor, a well-defined investment in upgrading the capacity of the link can
solve the problem. But for most other links within the network, where
loading can only be addressed on a statistical basis and where there are
many options for making investments that might improve matters, it may
be less clear where to investÑwhich in turn may mean that making an14The transfer of a ÒtypicalÓ Web page (one used by the World Wide Web Consortium asa benchmark for performance) from a server for which the network latency is a typical 100milliseconds. If one varies the bottleneck bandwidth and plots the total page transfer time,
the curve approaches an asymptote of about 6 seconds when the transfer speed reachesabout 1 Mbps.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.80BROADBANDinvestment in the local access link will not improve application perfor-mance. (Other strategies may be used in such circumstances, such as cach-
ing or replication within the network of the access provider.)Broadband Definition 1, however, gives an answer that is only correctfor a given set of applications at one point in time. What happens when
new applications come along? In fact, the performance of broadband ac-
cess will be a key factor influencing the emergence of new applications,
since new applications that demand higher transfer speeds cannot take
off until there is a critical mass of users with the access capacity to use
them. This motivates an alternative definition of broadband:Broadband Definition 2. Broadband services should provide sufficient perfor-manceÑand wide enough penetration of services reaching that performancelevelÑto encourage the development of new applications.This definition implies that a broadband access system is definedboth by a technical evolution path and an economic evolution path that
will allow it to play its part in the chicken-and-egg application cycle. The
subscriber link is viewed as a potential bottleneck that inhibits innovation
and constrains the development of new services elsewhere in the net-
work. Those providing services over the Internet who feel constrained by
the premises-link bottleneck may not be able to fully incorporate the ben-
efits of relaxing this bottleneck in their own investment decisions (i.e.,
their incentives to ÒsubsidizeÓ broader deployment fall short of the true
collective benefits)Ñbecause they are unable to internalize the benefitsrealized by other service providers.One example of how this view comes into play is the asymmetry ofbroadband services. Anticipating a number of new applications that re-
quire greater upstream capacity, one can project increasing demand for
upstream bandwidth arising from new applications. Yet, if connections
remain highly asymmetric over the long run, then applications that need
significant upstream capacity will be slower to appear. Because it takes
into account the dynamic interplay between deployed technology and
applications as well as the interplay between technology and economic
developments, this second definition is likely to be the more useful one in
planning and policy making.Whichever of these definitions one adopts, it is quite apparent that asingle numberÑbe it 200 kbps or 2 MbpsÑis not a useful definition ofbroadband (even if one focuses only on the bandwidth issue). However,
not all values (from zero to infinity) will be equally meaningful. Applica-
tions such as those discussed in Chapter 3 tend to cluster into classes
characterized by bandwidth and other performance requirements. This
suggests that there will be a series of milestones along the way, withBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.WHAT IS BROADBAND?81multiple peaks that may well correspond to, or catalyze, application andinfrastructure deployment milestones.TodayÕs residential broadband capabilities, which are typified by sev-eral hundred kilobits per second to several megabits per second down-
stream and several hundreds of kilobits per second upstream, support
such applications as Web browsing, e-mail, messaging, games, and audio
download and streaming. These are possible with dial-up, but their per-
formance and convenience are significantly improved with broadband.
At downstream speeds of several tens of megabits per second, new appli-
cations are enabled, including streaming of high-quality video, such as
MPEG-2 (a standard defined by the Moving Picture Experts Group) or
high-definition television (HDTV), download of full-length (70- to 90-
minute) audiovisual files in tens of minutes rather than hours, and rapid
download of other large data files. Reaching this plateau would enable
true television-personal computing convergence. With comparable up-
stream speeds, computer-mediated multimedia communications become
possible, including distance education, telecommuting, and so forth. With
FTTH, a new performance plateau with gigabit speeds both up- and
downstream would be reached. The applications that would take full
advantage of this capacity remain to be seen.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.82

BROADBAND APPLICATIONS: PROMISE AND REALITYBroadband is a means to an end: It refers to capabilities that peoplewill use, but the question is, how and why? There is much excitement in
some quarters, but many consumers who are unsophisticated about infor-
mation technology and networks and do not yet have experience with
broadband connectivity have expectations that are very much at odds
with current reality. Indeed, as the discussion below suggests, there is
much potential for future applications that enrich or complement tradi-
tional content and communications channels, but excitement about them
should be tempered by an appraisal of the time frame in which these
applications could be realized.In practice, what broadband customers see today is largely a betterversion of the Internet access that they enjoyed with dial-up ISP service,
featuring Web-page viewing, e-mail access, messaging, and the like. This
experience is enriched by improved access to audio materials (most nota-
bly, music and Internet radio) and, albeit less frequently today, video. A
few new broadband-only applications are available today, such as net-
work backup and storage. This incrementalism may be inevitable for eco-
nomic reasons, but it also disconnects the application experience of today
from that anticipated as a result of enhancements to familiar applications,
the introduction of new applications, and the integration of diverse broad-
band-based activities into everyday life.As the examples in this chapter illustrate, technology capabilities areone constraint on new applications. Current-generation DSL and cableBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT83modem technology are unable to provide large quantities of high-qualityvideo-on-demand. And distributing content within the home in a useful
wayÑi.e., at least as well as do todayÕs conventional consumer electronics
(television, radio, and stereo systems)Ñremains a significant Òsystems
integrationÓ problem involving broadband hardware and software, in-
home networking, and consumer appliance design.There are, nonetheless, a number of places with experience in newbroadband applications. The limited pool of users with broadband at
home today, together with a larger set of users who access the Internet at
high speeds in the workplace or through the networks of academic insti-
tutions, provides some indication of the sorts of applications that could
emerge on a mass-market basis. Experimentation in industry and aca-
demic laboratories provides another source of indications of potential
applications. These early adopters and their applications may not gener-
alize completely, and not all of these services will necessarily succeed
from a business standpoint, but they do illustrate how people respond to
the availability of broadband and integrate it into their activities at large.
This chapter explores the characteristics of a variety of present and future
applications and examines some of their technical and related socioeco-
nomic features.CLASSES OF BROADBAND APPLICATIONSKey technical characteristicsÑthe bandwidth (upstream and down-stream), latency, jitter, addressability, and Òon-nessÓ (always-on), as de-
fined in Chapter 2Ñdistinguish several currently deployed or potential
classes of applications. This section outlines the overall characteristics of
each class and provides one or more specific examples of applications
within each class. Notwithstanding their seeming variety, possible appli-
cations by and large depend on a few core, or primitive, signal or traffic
types and connection characteristics, such as always-on. These core traffic
types are characterized by their basic data rates, by whether they rely on
file download or streaming (which in turn may have particular latency
and jitter requirements), and the like. Performance and quality trade-offs
reflect the interaction between the broadband link and other capabilities
such as coding and compression and local storage.Although there is no rigorous taxonomy of broadband applications, itis useful to draw associations between key characteristics of broadband
and major application classes. For example, video-on-demand and other
media streaming applications rely on the availability of downstream
bandwidth, while information appliances require always-on service even
though the bandwidth requirements may be low (see Table 3.1). Also of
interest are ÒcompositeÓ applications that rely on a set of capabilities. ForBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.84BROADBANDexample, shared sports viewing requires substantial upstream and down-stream bandwidth simultaneously. Furthermore, the composite broad-
band use in a home may be made up of multiple applications being used
simultaneously by different family members.Faster General Internet Access and General Internet ApplicationsBrowsing and Related ActivitiesThe primary motivation today for residential broadband access issimply to improve the performance of the overall Web browsing experi-
ence. While many factors actually influence the perceived speed of Web
browsingÑincluding, most notably, the performance of the server itself
and the performance of the serverÕs connection to the rest of the InternetÑ
moving from dial-up speeds to broadband speeds on a consumerÕs Inter-
net access link will almost always provide dramatic perceived speed im-
provements in general Internet usage.In addition to making the general Web experience more enjoyable,this speed improvement can also mean that new types of content become
usable by the consumer. There is, for example, a widely held belief among
commerce site operators that it is essential to minimize page-load times.1Commerce sites thus depend on network performance in designing their
pages, and any increase in that performance (either on average or for
specific users that they can identify) means that they can increase the
richness (and hence possibly the value) of their pages. For example, small
images might be replaced by higher-resolution pictures that more closely
approximate the quality available in print catalogs.1One rule of thumb, the Ò8-second rule,Ó states that if it takes longer than 8 seconds for apage to appear on the consumerÕs screen, there is a high likelihood that the consumer will
abandon the site. See, for example, Zona Research, 1999, The Economic Impacts of Unaccept-able Web Site Download Speeds, available online at <http://www.zonaresearch.com/
deliverables/white_papers/wp17/>.TABLE 3.1Mapping Between Broadband Service Capabilities and
Application ClassesBroadband CapabilityApplication Class
Large downstream bandwidthStreaming content (e.g., video)
Large upstream bandwidthHome publishing

Always-onInformation appliances
Low latencyInteractive games
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT85Other Web usage, such as simply reading long articles (for example,from online news sources), becomes more enjoyable with greater band-
width, and hence the Web is a more attractive medium when the effective
speed of information display approaches that experienced in physical
page turning. Finally, certain types of real-time applications, such as
streaming stock quotes, depend upon speed and timeliness to be valu-
able. Such applications can often run continuously in a part of the screen
and attract user attention intermittently. However, to be effective, band-
width must be sufficient for the performance of these applications and
that of whatever other network interactions the user may be involved
with.MessagingMessaging of various kinds continues to show up in surveys as animportant application. For example, a Jupiter MediaMetrix assessment of
AOL usage for January 2001 reported that of 22 billion minutes spent on
AOLÕs online service, 4.7 billion were spent on AOL e-mail, 2.8 billion on
internal instant messaging, and 6.2 billion minutes on AOL instant mes-
saging with users outside of AOLÕs online service; this contrasts with 2.1
billion inside all AOL content channels.2 Although many saw it as an
application geared toward entertainment, messaging is also seeing in-
creased use in a variety of business environments. While not demanding
in terms of bandwidth (dial-up bandwidths are sufficient), broadband
enhances messaging because it is always on.Fast File DownloadingMany users are familiar with downloading e-mail attachments or soft-ware upgrades. But many bulk file transfers are simply not practical with-
out broadband. For example, downloading an entire application that

might otherwise be delivered on a CD would require many hours over
even the best dial-up connectionÑa 60-megabyte (MB) file would take
about 4 hours on a link with a sustained 35-kbps transfer rate. For most
people, this length of time is simply impractical, particularly if the dial-up
line is also used for voice communications or is subject to periodic discon-
nection. On the other hand, a constant connection to the network at even
modest broadband speeds may make such transfers reasonable.It is important not to underestimate the impact of fast file-download-ing capability on a very wide range of applications, including audio and
video. Streaming is complicated compared with file downloading, and2See ÒAOLÕs Minutes.Ó 2001. The Washington Post, March 8, p. E11.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.86BROADBANDthe main reasons that people do it, other than for real-time delivery, isbecause the files are so large that users do not want to wait while the files
download; the files are too big to store locally conveniently (although
storage space is rapidly becoming very inexpensive); and/or there are
intellectual property protection concerns (but application of digital rights
management technologies to stored files can provide protection compa-
rable to that of encrypted streams). If one can move music files in a few
seconds, videos in a minute or two, or an entire newspaper or book in a
minute, many applications become practical. In addition, the economics
are becoming more appealing with the spread of very large, cheap storage
units. Downloading is of particular value when one wants the content for
portable appliancesÑsuch as e-book readers or music playersÑthough
making this easy for consumers depends on addressing the in-home con-
nectivity issues discussed below. Some typical figures for media bit rate
and data file size, together with user-oriented parameters such as down-
load time and the size of the data file acquired give a practical sense of the
relationships between media type, broadband link capacity, and down-
load times (see Table 3.2). Already, surveys correlate audio and video
downloading with broadband,3 while indicating that (as of early 2001)
fewer than half of home computer users used a media player.43ÒSurvey Says: DSL Users Addicted to Broadband,Ó April 3, 2001, available onlineat <http://www.sbc.com/News_Center/1,3950,31,00.html?query=20010403-1>. PierreBouvard and Warren Kurtzman. 2000. The Broadband Revolution: How Superfast Internet Ac-cess Changes Media Habits in American Households. Arbitron Company, New York. Availableonline at <www.arbitron.com> and <www.colemanresearch.com>.4ÒReality Bytes.Ó 2001. The Wall Street Journal, January 29, p. B8, using figures from
Jupiter Research and Media Metrix.TABLE 3.2Time (in seconds) to Download Various Media Types for
Different Access SpeedsAccess SpeedMediaTypical File Size, MB64 kbps288 kbps640 kbps64 Mbps
Image0.112.52.781.250.0125
Audio single1.923852.823.80.238
Audio album34.64,3309614334.33
Video album1,000.0125,00027,80012,500125
NOTE: AssumptionsÑ
¥Bit rates after compression are 64 kbps (audio) and 1.85 Mbps (video).
¥Single song (audio single) is 4 minutes; music album is 72 minutes; image is 1,000 by
1,000 pixels, compressed to 0.8 bits per pixel.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT87GamesThe interactivity demands of some games were alluded to above.Multiplayer games are of considerable interest because they connect grow-
ing numbers of people in a shared activity (Òmassively-multiplayer role-
playing gamesÓ), providing both social and demand-stimulating dimen-
sions. As of fall 2000, for example, Everquest involved up to 100,000
simultaneous users out of more than 300,000 paying subscribers. Of those
subscribers, 30 percent had broadband connections. According to Sony,
which provides Everquest, availability and reliability are key require-
ments; latency is less important in this game than in the shooter variety;
and bandwidth demand is moderated by a design that presents graphics
on the client software and transmits only changes in graphics and in game
and character state.5Speed and Response-Time-Sensitive Internet ApplicationsWhile activities based on Web browsing are generally improved byfaster network connectivity, a small number of Internet-based applica-
tions are particularly sensitive to connection speed, latency, and response
time. The two most prominent are day trading and some forms of multi-
player games (in which delays of as little as 50 milliseconds can impair
game play). Note that these activities are not generally done through Web
browsers, but rather through special-purpose interface software. Both of
these call for functionality not easily achievable through any other means,
suggesting they will continue to drive interest in broadband.Application RentalThe most common model for consumer software distribution is one inwhich consumers purchase applications on CD-ROM or for Internet
download. These are one-time purchases; except for upgrades, there is no
recurring cost. In many cases, software vendors choose to sell their soft-
ware in large bundles, of which the office-application suites are the most
common instance. An alternative model is being explored by software
vendors is the rental of particular applications on a by-use basis. Simple
examples include financial planners and simple tax-preparation software
built out of Web forms. While greater bandwidth would offer faster down-

load times, it is unclear to what extent acceptance of this model depends5Robert Gehorsam, personal communication, briefing to CSTB Committee on IT and Cre-ativity, November 9, 2000.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.88BROADBANDon bandwidth or on consumer acceptance of a model in which the indi-vidual does not own the software. In many cases (for example, tax prepa-
ration software), users may want to control the data locally for privacy
and security reasons. Other applications, such as games, could be ob-
tained through rental, and there would be no such concerns.Network StorageNetwork storage applications provide users with an alternative tostoring data on local hard drives or on removable storage media such as
floppy disks or CD-ROM. There are two major advantages to this service.
First, people use network-based storage rather than run their own local
servers to do such things as sharing photos. It is hard to know whether
storage will migrate into the home or out of the home when material can
be stored in either placeÑmuch undoubtedly depends on pricing, confi-
dence about access controls for out-of-the-home storage for certain kinds
of materials, and so forth. Second, network-based storage provides re-
dundant off-site storage. This is likely to be attractive to small and home
businesses and to people who require disaster recovery (which might
well include anyone with a PC who has had a disk crash). Privacy issues
can be handled by only placing encrypted data on the remote store. For
small business it seems likely, for reasons of performance, management,
and support, that content will be hosted remotely by commercial Web
hosting services rather than at the small business site.The requirements depend on what sort of data is being stored. Forexample, photo (or video) storage may require relatively high upstream
capacity to permit uploading in a reasonable time (and not tie up the
connection). But file-system backups, which normally need to transfer
only periodic, incremental updates, depend more on the always-on na-
ture of the connection rather than the bandwidth (unless the volume of
modified data is very large). One can imagine the emergence of a genera-
tion of operating systems with automatic continuous backup across the
network as an optionÑgreatly reducing the likelihood of data loss due to
disk crashes or other computer failures.Static Image DeliverySeveral interesting video applications depend on the ability to deliverstill photos or short video clips. The emergence of inexpensiveÑalbeit
more expensive than their analog counterpartsÑdigital still and video
cameras enables easy capture of photos.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT89AudioBecause many audio applications do not demand especially highbandwidth, in notable contrast to video applications, they often work
with at least some level of functionality over a fast dial-up connection. All
of the currently deployed broadband technologies are fast enough to sup-
port the key audio applications that have emerged to date. These include
conventional voice similar to telephony; voice as a complement to games
and other interactive applications; and a full range of sound applications,
beginning with music but including other types of content (e.g., news and
other spoken word). As a result, some experience has been gained with
the delivery of audio applications over the Internet in general, and via
residential broadband in particular. This experience supports a key theme
of this chapterÑfor many applications, the bandwidth provided by broad-
band services is a necessary but not a sufficient condition by itself to make
an application work effectively. Factors such as which home networking
technologies are used, the availability of special-purpose appliances, and
the nature of user interfaces are also critical enablers of widespread use of
audio applications. While there is much interest in broadband for video
delivery, this chapter devotes considerable attention to audio as well,
both because it is an important application and because understanding of
audio applications is better grounded than that of video applications,
given early efforts to deploy various audio applications.Audio DeliveryFundamentally, there are two ways to approach audio deliveryÑafile can be downloaded to a local computer and then played, or the data
can be streamed from a remote computer to the local computer, played
more or less as it is received. Clearly, the file transfer model is appropriate
only for distributing prerecorded material; conversations by their very
nature have to be conducted in a streaming mode, and streaming is also
essential for ÒliveÓ content that has high time value (such as commentary
on a sporting event). The use of streaming delivery does mean that the
audio is necessarily listened to in real time. While some streaming appli-
cations use encryption to make it difficult to keep a copy, some streaming
applications permit a copy to be saved to a file for replay or other later
use.Streaming audio requires an end-to-end network connection that isfast enough to handle the actual encoded size of the audio file on a sec-
ond-by-second basis (one end may be at a content server located some-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.90BROADBANDwhere within the broadband providerÕs network). In some applications, atechnique known as buffering can be used to prevent transient network
delays from interrupting playback. Audio is played from the end of the
buffer as newly received audio is added to the start of the buffer. Still,
network delay and jitter must be kept within bounds so that the buffered
data are sufficient to imperceptibly smooth over these delays. The accept-
able buffer size depends on human factors that vary according to the
application. A few-second pause between when a request is made to play
a song and when the song starts playing is probably acceptable, but a
significantly longer delay is likely to be annoying. Delays of anywhere
near this magnitude in a voice conversation are very distracting, how-
ever, as is familiar to anyone who has contended with even the half-
second round-trip delay on a geosynchronous satellite circuit.There are other circumstances in which the length of the delay affectsacceptability. If one is streaming a live event, the sensation of being live is
dependent on the stream delay. If users have access to the event through
other media, they may notice even relatively small delays. For example,
there are data streams that deliver information on sporting events. If a
user runs one of these concurrently with an audio streaming feed of the
sporting event, the inconsistencies may be noticeableÑfor example, a play
is reported on the data feed before it is heard over the audio feed.Another parameter affecting the performance of streaming audio isthe packet loss rate. Typically, lost packets are not retransmitted because
the resulting delays (the sum of the time it takes to determine that a
packet is lost, the time it takes to transmit a request across the network,
and the time it takes for the replacement packet to be delivered) would
make the playback jerky.6 For typical audio applications, occasional
packet loss turns into distortion and sound disruption and causes vari-
able quality as the sound is reproduced. Depending on what the audio is
and how often packet loss happens, this effect can be very annoying,
though it may not be enough to make the application unsatisfactory.
People do accept a certain degree of impairment due to interference when
listening to the radio and tolerate brief dropouts when using cell phones
or wireless handsets for wireline phones.In the file download model, the key question is how long the user iswilling to wait to receive the file. Simple calculation of the transfer times6With a low-latency network connection and a sufficiently large buffer, limited retrans-mission may be tenable, but this is not the typical practice in streaming protocols. Indeed,lower performance is observed in applications where a Transmission Control Protocol (TCP)
connection (which builds in retransmission of lost data) is used in place of the raw UserDatagram Protocol (UDP)-based transport. The time taken by the TCP algorithm to handlepacket loss translates into much higher delay and jitter figures.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT91required for a 5-minute musical recording at different bandwidths yieldsan indication of the timescales involved (Table 3.3). Note that these times
assume that the server transmitting the music has sufficient capacity to
support the transfer rate offered by the last mile link and that there is no
backbone network congestion that would reduce the effective transfer
rate. In many real-world applications, either or both of these may turn out
to be the actual limiting factors.The acceptable download time depends considerably on the details ofthe application. For example, in a download-first and listen-later applica-
tion, it may not be satisfactory if it takes more than a few seconds to cue
up a song (and streaming may be a more appropriate approach). If the
application downloads a collection of music in the background for later
listening, however, this transfer time may be acceptable. But if the goal is
to download a compilation of music and immediately listen to it Òoff-
lineÓ on a portable device, taking more than a few seconds to download
each song is probably unacceptable.Compression-Quality Trade-offsCompression is a key determinant of the network performance re-quirements for an application such as audio. Compression algorithms for
media rely on two basic principlesÑthe removal of redundancy and the
reduction of irrelevancy in the input signal. While mathematically lossless
compressionÑin which the original signal can be completely restored
upon decompressionÑis used in some archival, legal, and medical appli-
cations, the pragmatic goal in most media applications is some degree of
perceptual losslessness.
TABLE 3.3Download Times (in seconds) for a 5-Minute Music
SelectionNetwork Capacity (kbps)Low Fidelity (3 MB)High Fidelity (30 MB)
504804,800
1002402,400
2001201,200
50048480

80030300
1,00024240
1,50016160

5,0004.848
NOTE: A file size of 3 MB at low fidelity and 30 MB at CD-quality encoding is assumed. The
sustained file transfer rate is assumed to be the same as the network bandwidth.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.92BROADBANDWhile acceptable spoken voice quality is provided by a data rate aslow as 4 kbps, music playback covers a wider range of data rates. Present
storage and transmission costs generally mean that the maximum practi-
cal compressed signal data rate for many applications is 32 to 64 kbps.
MP3-type encoding is commonly used today to compress audio at a vari-
ety of compression ratios. MP3 at 64 kbps provides a quality roughly
analogous to (analog) FM radio qualityÑacceptable in some applications,
particularly if it is to be played back through a low-quality system, but
not as good as a CD played using high-quality equipment. Compact disk
(CD) quality using todayÕs compression algorithms requires 128 kpbs.7The gap may also be growing between what generally available band-
width supports and state-of-the-art audio. Consumer electronics compa-
nies are currently beginning to promote a series of super-high-fidelity
recording schemes using higher-capacity DVD (digital versatile disk)
media that provide a much higher quality than that of CD audio. Multi-
channel sound proposed for future HDTV-class applications would re-
quire a higher bit rate, with 320 kbps being a conservative figure for 5-
channel sound.8The wide range of bandwidth-quality trade-offs for sound is illus-trated by radio broadcasting that is being streamed across the Internet. At
the low end, services such as spinner.com stream sub-FM radio quality
music at roughly 20 kbps. Much content is streamed at rates in the range
of 20 to 100 kbps, with the low end serving dial-up users and the high end
aimed at users in the workplace or with residential broadband. Toward
the high end of that range, the quality lies somewhere between FM radio
and CD quality. And at the high end lies uncompressed full-fidelity radio
broadcasting at a data rate of 1.4 Mbps, as was demonstrated at the Octo-
ber 2000 meeting of the Internet 2 consortium. The majority of applica-
tions moving audio over the network today, however, operate toward the
lower end of the quality-bandwidth curve.The range of technology options today supports the observation thatthere are very different thresholds for what constitutes Òminimally ac-
ceptableÓ music quality and what constitutes ÒhighÓ quality. This is a
very subjective matterÑmany people are willing to listen to AM radio, a
large number find FM radio acceptable, and some significantly prefer
CDs over FM because of the quality difference. In addition, acceptability
varies from one recording to another; some lossy algorithms work reason-7Released in 1980, the CD audio specification (the so-called red book standard) makes useof an inefficient compression scheme that requires about 1.5 Mbps. Today, considerablybetter compression algorithms are available.8Fortunately, the bit rate grows less than linearly with the number of channels.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT93ably well most of the time, but occasionally, particularly for certain typesof music, they produce artifacts that are very audible and annoying to
some minority of listeners, who will reject the compression strategy on
this basis.Applications such as telephony also require two-way delivery to andfrom the home. The same coding issues that arise for other audio also
arise here, and there are tighter constraints posed by the more limited
upstream bandwidths in todayÕs broadband technologies. However, data
rates alone will not compensate for inexpensive or poorly positioned mi-
crophones or for ambient noise. If one is to use a broadband connection to
the Internet to substitute for conventional voice telephony conversations,
a good handset will still be needed. It will, for example, be problematic to
hold conversations having good sound quality using the PC analog of a
speakerphone that is not close to the speakerÕs mouth, just as it is with
conventional telephony.Specific Audio ApplicationsTo better understand the requirements of audio-based applicationsover broadband, it is important to examine a set of specific applications
and practicalities of each application, including what consumers are likely
to expect.Playback of Music. TodayÕs music-playback applications are attractive topeople who like the convenience of playing music on their computers,
who want free music via peer-to-peer applications, who want to listen to
radio stations that do not broadcast in their geographic region, or who
want to listen to events that they cannot get access to in other ways. This
content is often not reproduced on high-fidelity equipment. As noted
above, options for music content distribution available today are also
generally inferior in quality to that of a well-produced audio CD. In order
for network-delivered audio to substitute for audio CDs, at least for people
who are particular about sound quality, it will be necessary to move up
the quality-bandwidth curve somewhat from where typical applications
are today.While a number of PC-based audio applications have enjoyed wide-spread use, it is unlikely that consumers will want to be forced to sit near
a PC whenever they listen to music. The configuration of a home will
depend on household income, personal preference, and the like, but most
homes have devices in various locations. For example, the average num-
ber of radios per U.S. household in 1998 was 5.6.9 Multiple audio CD
players are also commonplace, and many homes have one or more high-
performance stereo systems. Normally, each of these is controlled locallyBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.94BROADBANDby selecting radio stations or inserting CDs and selecting tracks. If thesedevices are to be replaced by network-based playback, one of two con-
figurations will be required: (1) specialized appliances in each room that
are connected to a computer that is in turn connected to the broadband
network or (2) specialized appliances that directly connect to the broad-
band network, probably through a home network. End-to-end streaming
audio also depends on the performance of the in-home networkÕs being
roughly as good as that of the wide area network. This is generally not a
problem with todayÕs technologies; the slowest on the market now run at
about 1 Mbps (HPNA 1.0 and HomeRF), and the trend in home networks
is to support roughly 10 Mbps (HPNA 2.0, 802.11b, and HomeRF), with
higher rates possible in the future (see Box 2.1 in Chapter 2). Depending
on whether the desired content is stored locally or not, supporting mul-
tiple devices throughout a house may require delivery of multiple chan-
nels of sound. Current-technology broadband may be adequate to sup-
port two such connections with appropriate coding, but the presence of
multiple radios suggests that audio could support demand for higher
bandwidths.Audio applications place considerable demands on the distributionnetworks within the home. If audio playback is to be available in all the
places where people are likely to want the broadband equivalent of radios
or CD players, the home network has to be near-ubiquitous. In some
homes, this may require wireless, powerline networking or the addition
of Ethernet cabling and jacks. In other homes, many rooms already have a
telephone jack, and phone-line networking is a reasonable option. An-
other option is to distribute the audio signal itself using radio frequency
transmitters and receivers. Indeed, appliances are beginning to appear
that use radio connections to a Òbase stationÓ for listening to radio or
music that comes over a network. One could also imagine base station
technology that does very low power broadcasting on FM radio frequen-
cies (assuming that FCC spectrum use issues can be resolved) in order to
leverage the existing installed base of radio receivers within the homeÑ
although this does not address the control interface issue.Audio applications also require a control interface to select programs,switch from one track to another, and so forth. Each playback device
requires some sort of input device, such as a keyboard or touchscreen.
With a large collection of digital music, navigation becomes complicated,
comparable to choosing selections from several shelves full of audio CDs.9U.S. Census Bureau. 2000. Statistical Abstract of the United States. U.S. Census Bureau,Department of Commerce, Washington, D.C., p. 567. Available online at <http://www.census.gov/prod/2001pubs/statab/sec18.pdf>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT95There is a variety of architectural options for audio in the home. Forexample, audio could be streamed directly to the player or restreamed
from local storage on the home computer to the listening point. Cost
considerations make it unlikely that each playback device would have its
own large store for audio built in, so at least some music is likely to be
stored in some sort of household audio library, whether on a general-
purpose computer or on some sort of specialized network device. Access
controls will also be important; one would not want people outside the
household to be able to request music from the home music archive (at
least not through an appliance-type interface). Intellectual property is-
sues raise additional access-control issues: presumably, one would expect
to be able to play music that one has licensed on any appliance within
oneÕs home, but this capability is somewhat at odds with both the digital
rights management systems being proposed by the music industry (such
as the Secure Digital Music Initiative, SDMI), which sometimes tie an
audio file to a single device. Comparable complications are raised by the
prospect of having remote access to central repositories from multiple
devices: does one, for instance, maintain a table of repositories and pass-
words in each device or install digital certificates in each device? Stan-
dards are also importantÑwill consumers be able to select appliances
from a variety of vendors or will they be locked into purchasing compo-
nents (and even content) from a single company?In summary, bandwidth is only one of multiple technology issues.Until these challenges are addressed, playing audio music over the Inter-
net is likely to be an activity that supplements rather than replaces more
conventional music-listening options for most people.Listening to the Radio over the Net. Fundamentally, listening to radiocalls for the same types of facilities as those for listening to audio, but
there are a few differences and added complications. Radio is more likely
to be streamed from the source rather than stored locally in the home in
an audio storage server. Also, the control interface will be different: A
radio service involves selecting channels rather than individual pieces of
music (although the rise of video-on-demand makes one wonder about
an audio equivalent). If current products are any guide, the interface may
well resemble radios of today, with buttons used to select preset favorite
channels. Some means of access to directories of radio stations on the
Web, analogous to tuning in stations by frequency, is probably also re-
quired. And, faced with a greater number of choices, people may seek out
new services along the lines of those being introduced in television ser-
vices, such as Tivo and Replay. These include program guides and the
capability of scanning program guides automatically for programs of in-
terest. Another possible feature would be the capability of saving the last,Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.96BROADBANDsay, half-hour of a broadcast to permit selecting a particular song or othermaterial for local storage and later playback (there are, of course, interest-
ing intellectual property rights issues to be worked out in this sort of
scenario).Network-Based Voice Telephony. In recent years, there has been growinginterest in running telephony over general-purpose data networks, in-
cluding the public Internet, instead of over the public telephone network.
As an application of dial-up Internet service, Internet telephony arose as a
less expensive alternative to conventional telephony. The decreased costs
to users are a result of several factors: (1) by utilizing the Internet, which
is typically made available to residential users on a flat-rate basis, Internet
Protocol (IP) telephony avoids the per-minute charges generally assessed
by long-distance carriers; (2) because a long-distance call can be placed
with these services through a local call to an ISP, these services allow
bypassing the per-minute access charges that long distance companies are
required to pay local exchange carriers to terminate long-distance calls.
From an overall industry perspective, there are also players moving to-
ward replacing specialized telephone gear with IP-based equipment, seek-
ing both to reduce costs and to introduce new functionality. There may
also be efficiencies that result from running data and voice over a com-
mon network. IP telephony is being used today by some households and
within some enterprise networks; it is increasingly also being used inter-
nal to the networks of a number of telecommunications carriers. Both
deployments raise a series of complex policy issues.10With residential broadband, which offers much greater bandwidthand always-on connectivity, IP telephony has the potential to move from
a relatively marginal, hard-to-use application to a mass-market applica-
tion. Depending on the architecture of a particular service, it might be a
service that consumers run over their Internet connections simply by in-
stalling additional software and possibly making arrangements with a
third party. Or, it may be a value-added service offered by the broadband
service provider. In either case, IP telephony provides a way to bypass the
local exchange carrier for telephone service. Price may not be the only
selling point: Because IP telephony permits much more rapid innovation
in services, the ease with which new features can be added may prove an
additional customer draw.Voice telephony applications do not require especially high band-width, with 64 kbpsÑor less with compressionÑin each direction being10See Chapter 4 of Computer Science and Telecommunications Board, National ResearchCouncil, 2001, The InternetÕs Coming of Age, National Academy Press, Washington, D.C.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT97sufficient to provide the quality that people are used to from the conven-tional phone system. But these applications are much more sensitive than
the pure ÒlisteningÓ applications in terms of network delay, jitter, and
packet loss. Multiway conference calling raises additional architectural
and performance issues. There are several ways that this can be done: as a
series of point-to-point connections between individual participants and
a control unit, or on a distributed basis using multicasting. For multiway
conference calling control of delay and jitter is even more critical because
of the number of sites involved. Whether meeting these requirements is
best done by increasing network capacity or by incorporating quality-of-
service mechanisms into networkÑand if the latter, which sort of mecha-
nisms at what places in the networkÑis an open question.Unlike conventional telephony, IP telephony comes in many variet-ies. In one major class, conversations are transmitted across the Internet
end-to-end. Another possibility is to use IP-based voice service part of the
way, perhaps only on the local access link, and connect calls to the tradi-
tional voice telephone system through a gateway. Here again the key
barriers to acceptance are not bandwidth but the integration of network-
based voice telephony with convenient handsets and ÒdialingÓ (call setup)
devices. Given the popularity of cordless phones, it is unlikely that plac-
ing and receiving calls from PCs will find mass-market acceptance (al-
though one might speculate about a PC role as a kind of base station).
Other features that are important enablers of widespread adoption in-
clude the integration of ancillary services such as answering machines,
voice mail, caller ID, and call waiting.A number of companies have deployed IP telephony solutions, and itis a service that some broadband providers have chosen to add to their
service bundles. But it is also possible that residential IP telephony may
turn out to be a red herring. Voice telephony is important enough to most
people that they are not willing to replace it with an unreliable service
unless there is a compelling economic justification. Also, the voice tele-
phone system works wellÑit is reliable, easy to use, and inexpensive (and
getting more inexpensive every week it seems, at least within the United
States). Except for people who are tremendously sensitive to the modest
costs of long distance today (with rates of $0.05 to $0.07 per minute avail-
able as part of various calling plans) or who often place costly interna-
tional calls (where IP telephony can effectively skirt the very steep tariffs
still imposed by some countries), IP telephony may not be attractive un-
less it comes as an absolutely simple and seamless by-product of a broad-
band connection.Audio Filtering and Searching. Audio, radio, and telephony are, for themost part, translations of existing applications to the network environ-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.98BROADBANDment. This section concludes with a novel audio applicationÑaudiosearching and filteringÑwhich illustrates the potential for audio applica-
tions to pose considerably greater bandwidth requirements. The funda-
mental idea behind this class of applications is that one can use a com-
puter program to ÒlistenÓ for certain keywords in one or more audio
streams using speech recognition technology. When the program recog-
nizes one of the keywords it is looking for, it takes various actions, such as
saving a segment of the audio stream, notifying a person, or putting the
stream on speaker. (This, of course, presupposes the availability of large-
vocabulary, speaker-independent keyword recognition software.) Key
networking issues include how many streams need to be monitored and
how large the streams are.A reason for mentioning this particular application is that for all ofthe other applications discussed here, the number of channels is basically
limited by the ability of a small number (members of a household, for
example) of human beings to pay attention to the audio streams; even if
the streams are being recorded for later playback rather than for immedi-
ate presentation, a household playing different music in each room and
with four people on the phone could only use on the order of 10 concur-
rent audio channels. With sufficient computing power, one can imagine a
search application consuming dozens of audio streamsÑperhaps even
conceivably hundreds. Of course, from the point of view of minimizing
network traffic, it might be better to push the searching and filtering
application into the network, nearer the source of the audio, rather than
keeping it close to the edges of the network. But it remains to be seen
whether the infrastructure will appear to make such efficiencies possible.
One advantage of filtering and searching in the home, at the edge of the
network, is that one can conduct searches privately. It is also the case that
the amount of computational power available to search and filter would
scale much better if provided at the edges of the network than in the core.
That is, if streams are available to the edges of the network (say, via
broadcast), then the amount of filtering and searching that can be done is
limited only by the number of end points that consumers have. If the
filtering must be done within the network, then the capacity can be more
difficult to grow in proportion to the number of users. These are the sorts
of trade-offs between computing, communications, and storage that in-
evitably arise when new applications are being envisioned.VideoVideo applicationsÑconsidered broadlyÑform a useful complementto the audio applications discussed above in terms of understanding what
broadband connections may enable and what else other than mere con-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT99nectivity must be in place. In the public mind, video applications areperhaps the premier consumer applications for broadband, and they ex-
emplify the gap between consumer expectations and what broadband
today can actually deliver. Many people have vague ideas that broad-
band connections will support multiple channels of on-demand, person-
alized HDTV-quality videoÑboth commercially produced content and
interactive videoconference or videophone connections to family, friends,
offices, and other destinations. It is not unreasonable to imagine the cur-
rent or next generation of networks delivering hundreds of channels of
broadcast video (including pay-per-view), and there has been experimen-
tation with video-on-demand delivered from broadband providersÕ local
caches, but such services have not been deployed on anything approach-
ing a widespread basis. In practice, most of the video that is available over
the Internet for normal users today, even those on a commercial broad-
band connection, is relatively small images at low and often uneven qual-
ity, but improvement in quality over time is expected with improvements
in broadband price and performance. Improvements in Internet-based
video would not necessarily mean that TV will migrate completely to the
Internet: Some observe that existing television is an effective delivery
channel for passive entertainment, while others anticipate an ultimate
convergence (see Box 3.1).In addition to sufficient bandwidth and appropriate means of con-trolling the displays, the growth and multiplication of video applications
will be driven in large part by the availability of new capabilities. One
such capability is inexpensive flat panel displays (or other technologies
delivering the same functionality, such as projectors of some kind) that
could be spread throughout the home or office. These technologies could
ultimately enable a range of currently exotic applications, from immersive
videoconferencing (where one wall of a room simply seems to open into
another remote room) to social shared-entertainment experiences (imag-
ine people watching a sports event with friends who are immersively
videoconferenced in from a remote location, or a group of musicians
playing with each other across the Internet11). Cameras are also an impor-tant technological enabler, as many of these video applications involve at
least some in-home origination of video signals. Current inexpensive
video cameras (i.e., so-called webcams) offer only a very small, low-qual-
ity image, but the cost-to-performance ratio of digital cameras continues
to improve. In-home capabilities for storing and manipulating videoÑ
exemplified by incorporation of video capture and editing capabilities11Interactive, networked music performances are already being attempted.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.100BROADBANDBOX 3.1Internet, Television, and the Multiple Meanings of ÒInternet TVÓTrends in both television and Internet technologies make clear that the Internetand television will become increasingly intertwined in the future. The label ÒInternetTVÓ has multiple meanings, all of which deal with some form of convergence be-
tween conventional television and Internet service. Following are the definitions offour principal options:1.Delivery of conventional television or Internet-specific content over the Internet.Rather than watching television programs broadcast over the air or over cable, tele-vision programs would be accessed over the Internet and then watched using either
streaming for real-time viewing or file transfers for delayed viewing. Today, this sortof content would have to be viewed on a computer, but the technology could beincorporated into future television sets (or provided through an external adapter) to
facilitate television access over the Internet.2.Adoption of an Internet-like (e.g., browser) interface for identifying and selectingtelevision content. In this case, the Internet would be used to enable a more interac-
tive approach to controlling the television experience and would supplement thetelevision content with additional information.3.Internet content that complements television content. Subscription servicesÑin-
cluding WebTV and AOL TVÑcomplement the traditional television viewing ex-perience by allowing viewers either to interact with TV programs or to accesscomplementary information via the Internet. Television stations and networks in-
creasingly also have Web sites with information that extends, complements, and
promotes their programs and schedules.4.Use of a home TV set to view Internet sites, as offered by WebTV, perhaps inconjunction with conventional television viewing. These kinds of applications of Inter-net TV create an interactive television experience. This technology could be an inter-mediate stage toward realizing option 1.SOURCE: Adapted in part from A. Michael Noll. 2000. ÒInfrastructure Implications of InternetTV.Ó TV over the Internet: Implications for Infrastructure, Content, Policy, and Strategy. ColumbiaInstitute for Tele-information, New York, November 10.into some personal computers and by the advent of digital video record-ersÑcomplement the capabilities described above.Video applications face many of the same issues as audio applicationsin terms of getting video content to the correct appliances through in-
home distribution networksÑthe computer, the television, or perhaps
some type of ÒvideophoneÓ applianceÑas well as similar issues of inte-
grating control with actual content distribution. But video permits a num-
ber of possible variants with interesting implications for both users and
the broadband providers that carry these applications. These include:Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT101¥Interactivity. Another trend is toward interactivityÑtransforming
video from a passive experience into an active one. Interactive television
is providing exposure to consumer options for, say, selecting a camera at
a sporting event. Such early experience with interactivity raises questions
about the locus of control (at the transmitter or the receiver), the relative
costs of bandwidth and the other technology needed to implement the
interaction, and the potential for approximations to interactivity, such as
broadcast of navigable objects.¥Video for social communication. Another possibility is the combina-
tion of traditional entertainment with social communication. The scenario
is that people are watching a sporting event, with the traditional live
broadcast coming into the homeÑbut also sharing live video with friends
who are watching the same game at the same time in different cities or
simply different homes. This implies fairly high bandwidth peer-to-peer
video communication in conjunction with passive video delivery. It is a
very different conceptÑimplying very different behaviorÑfrom todayÕs
scheduled videoconferences.¥Home and community video. Developments in video capture andediting technology enable new options for user-generated video.12 One
obvious application is home movies. Another is further decreasing the
technical barriers to community access-type video production and deliv-
ery.¥Large numbers of simultaneous video streams. People can interact with
video content quite differently from how they interact with audio. One
audio signal per room (or perhaps one per person if headphones are
used) at a time is a basic limitÑplaying 10 radio channels at once simply
creates cacophony. But with enough display screens, a room or an indi-
vidual can make use of many video signals at once. People can divide
their attention by simply looking from one screen to another. One can
imagine people receiving a number of different video signals continu-
ously (for example, multiple TV-type feeds) with the sound usually sup-
pressed. Another source of multiple video streams could be a new class of
video display devicesÑvideo picture frame appliances that periodically
download images for display from the Internet. With the always-on capa-
bilities of broadband and an in-home network, one can easily see these
evolving into video portals that look out on favorite scenes, into the homes
of family and friends, and the likeÑperhaps at fairly high resolution, but
with a relatively low frame rate.12Hal Varian. 2000. ÒCool Media: A New Generation Is Turning the Tables on Televi-sion.Ó The Industry Standard. November 20, p. 293.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.102BROADBANDThe Mechanics of Video DeliveryAs with audio, video can be delivered through two models: streamedvideo and download-and-play (file transfer). As with audio, interactive
video applications require a streaming model. With respect to the down-
load model, video is more challenging than audio is, because the multi-
gigabyte size of a typical video file is large enough that local disk stor-
ageÑeither temporary or permanentÑis a challenge, given the capacity
of disks today. Simply fetching high-resolution video from a disk to dis-
play it after downloading is challenging for consumer-grade personal
computers today. Moving high-resolution video around the home from
one device to another is also problematic, owing to bandwidth require-
mentsÑthis calls for in-home networks faster than those typically pur-
chased by consumers today. For streaming, bandwidth requirements for
video are much more complex and varied than for audio. This is due in
part to the much larger range of quality trade-offs and to the fact that
video is often accompanied by one or more channels of synchronized
audio.Another complication has to do with the way that video scales. Whilean audio transmission is always roughly scaled to the frequency range of
human hearing, a video transmission defines a Òwindow,Ó a rectangle of
pixels that are rendered on some sort of display. If the display has more
pixels than the video transmission includes, there are various interpola-
tion methods that can be used to ÒstretchÓ the video, but these produce
artifacts and quality problems that are quite visible to the human eye if
used too liberally. If there are more pixels in the transmission than the
display device can render, there are decimation algorithms that can be
used to scale the display down; these are less intrusive than the extrapola-
tion/interpolation algorithms if the degree of downsizing is not too great,
and they at least permit zooming (magnification) of particular parts of an
image. TV screens define one ÒstandardÓ window; computer monitors
define a few others, but it is often the case that one is putting multiple
video windows on a single monitor or TV screen (picture-in-picture). If a
wide range of flat panel displays becomes commonplace around the home,
then matters will become even more complex.Within a video transmission window, there are issues of pixel depth(i.e., how much color detail each pixel offers) and of compression within
and across video frames. There are very sophisticated algorithms avail-
able to reduce bandwidth through lossy compression, but these can pro-
duce visually annoying artifacts. Another variable is the frame rateÑin
essence the number of images that are transmitted per secondÑwhich
will determine how much resolution the video transmission can provide
for rapid movement and how jerky the playback will appear. Some appli-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT103cations may call for very low frame rates, while others may require 30frames per second (a common standard for video) or more to provide a
satisfactory viewing experience.Latency and jitterÑand packet loss ratesÑare much more seriousissues for streaming video than audio because of the enormously higher
data rates involved. Any kind of delay or packet loss snowballs rapidly
into a very visible problem (presumably because it is hard to have a big
enough buffer in RAM and because there is little redundacy when inter-
frame compression algorithms are used). A body of experience suggests
that, for many applications, reasonable results can be obtained by giving
priority to a good-quality audio signal and simply doing the best that one
can with video, using the remaining bandwidth. This seems to be true in
a great deal of talking-head-type video and videoconferencing.Finally, there are some major shortcomings today in protocols andstandards for managing video delivery. Ideally, display devices (or dis-
play windows mapped onto display devices) would be able to tell a video
source what their capabilities are. The applications that manage these
displays would be able to assign priorities to different characteristics of
the composite video and audio streams being transmitted to them. At a
higher level, there is a need for identifying which of multiple video
streams need to take precedence at a given moment. And all of this is
complicated by models that stream video signals into the home through a
single gateway that redistributes the signals to appropriate appliances
using a home network.With all of these variables, it is hard to tabulate simple bandwidthrequirements for various video applications. There is also more room for
subjective judgment about what constitutes acceptable video qualityÑa
judgment that is more content-dependent than is the case with audio. In
the audio world, it often suffices to differentiate between requirements
for voice-quality and music-quality audio. In contrast, whereas a video
transmission channel with a given set of parameters may be quite satisfac-
tory for a Òtalking headÓ or a concert but completely unacceptable for a
sporting event, that channel might be reasonable for a video-camera-based

portal to a remote location that is shown in a digital picture frame but
unusable for a videoconference between individuals. Another variable is
the impact of audio in improving perceived video quality.TelepresenceWhen video is considered as a personal communications medium,most people probably think of teleconferencing. However, widespread
broadband may also make practical a more general capability of tele-
presenceÑhaving a continuous video window open into another space.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.104BROADBANDWhereas teleconferencing brings to mind a fairly formal notion of com-munication, similar to a telephone call, telepresence can enable much
more informal interaction. For example, in a business setting it may en-
able casual interactions between lab spaces that could permit easier col-
laborations. Though early telepresence trials were constrained by techni-
cal shortcomings, this work also pointed to the significant role that social
practices play in their acceptance and usefulness and suggested that it is
difficult to predict when telepresence applications will be successfully
implemented.13In a personal setting, telepresence may enable a parent to have acontinuous window on a child at a day care facility, thus enabling a closer
ongoing relationship, even with working parents. Telepresence could pos-
sibly enable new forms of extended-family relationships over distances.
An interesting attribute of telepresence is that it potentially poses higher
bandwidth demands than one might expect from videoconferencing ap-
plications. This is because the premise of telepresence is that the window
is always open, to enable spontaneous observations and interactions. One
example that is a simple evolution of telephone use today is school chil-
dren holding shared homework sessions, connecting their respective
homes for many hours of working, chatting, and collaborating on assign-
ments.Telepresence can encompass not only audio and video, but also hap-tic interaction, force feedback, and control of remote devices (teleopera-
tion). One especially demanding application of telepresence has been seen
in experiments with distributed music performances, which require mini-
mal latency and jitter. Telepresence for music is under consideration for
concerts, studio production, and master classes.14Thus, the bandwidth requirements for telepresence are not limited bythe number of people actively engaged in watching the video stream at
any given moment. One can easily hypothesize the need for more video
streams to be maintained to or from a location than the number of users at
that location. Ultimately, such casual real-time applications may drive
much higher bandwidth requirements.13See Steve Harrison and Paul Dourish. 1996. ÒRe-Place-ing Space: The Roles of Place andSpace in Collaborative Systems.Ó Proceedings of the ACM Conference on Computer-SupportedCooperative Work CSCWÕ96 (Boston, Mass.). ACM, New York. Draft version available onlineat <http://www.parc.xerox.com/csl/members/dourish/papers/place-paper.html>.14Chris Chafe, Stanford University, personal communication, briefing on digital music-making to CSTB Information Technology and Creativity Committee, January 12, 2001.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT105TelemetryTelemetry applications involve primarily numerical data streams.They are expected to grow with the proliferation, and networking, of
embedded computing and communications systemsÑsmart appliances
and so onÑas well as networking capabilities within and from the home.
Sensors and controls are being developed for a variety of functions in a
household, such as temperature and energy management, utility moni-
toring, appliance operation, and security. More sophisticated health-moni-
toring systems are also being developed. For example, it may become
possible to undertake skin cancer screening from home, which requires
an ability to capture and send high-resolution images.There is growing interest in telemedicine services that require broad-band access. Possible connections include patient-to-doctor (e.g., in rural
health care, where travel to the doctorÕs office is difficult), patient-to-
physical therapist (e.g., supporting rehabilitation after a patient returns
home following hip surgery), and patient-to-family (e.g., to allow a family
to watch a newborn in neonatal intensive care).Telemetry applications rely critically on the always-on characteristicsof broadband and the ability of broadband to multiplex many data streams

(for example, to allow a medical device or an appliance to emit and trans-
mit a data stream regardless of what else is going on over the broadband
connection), in contrast to dial-up connections. In many cases the data
streams involved are low bandwidth. However, some applications, such
as webcams or health-monitoring devices that transmit images, could
result in demand for capacity that is higher upstream than downstream.
Although primarily deployed for planning communication with a medi-
cal service, the same broadband connections might also support emer-
gency response capabilities similar to or enhancing todayÕs telephone-
based systems. Such services presume, of course, reliable always-available
connections.New Kinds of PublishingPeer-to-Peer ApplicationsPeer-to-peer communication was the original design premise of theInternet. Particularly with the rise of the Web, the focus of communica-
tions on the Internet shifted to the client server as central Web servers
became the primary residence of Internet content. Recently, however,
peer-to-peer communications among end systems on the Internet has un-
dergone a renaissance, owing at least in part to the grass-roots movement
toward sharing content.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.106BROADBANDNapster, developed as a way of exchanging MP3-encoded music files,became a widely used peer-to-peer content distribution application. By
offloading the file transfer to exchanges between individual computers, it
relies much less on third-party servers than would be the traditional prac-
tice of many users downloading content from a single server. Napster still
relies on a central directory server to provide people with pointers to
content, but other peer-to-peer applications have emerged that largely
remove this constraint. Gnutella, for example, is a Napster offshoot that
allows users to conduct a search among linked, decentralized computers
offering content; however, it still depends on some means for users to
obtain the Internet address of at least one such linked computer (whether
through a Web page, e-mail, or instant messaging). Although these recre-
ational services have received a lot of attention,15 and their fate rests in
part on the outcome of litigation and negotiations with the publishing
industry, similar technologies have taken off for research activities.16The motivations for deployment of these applications are several.Technical arguments include immunity from single-point failure and dis-
tribution of traffic load throughout the network. Much of the interest in
Napster has, however, stemmed from another factorÑthe relative protec-
tion that peer-to-peer models offer from attempts to control the content
distribution. A central Web server is a relatively easy target if one seeks to
suppress undesired or illegal activityÑin the case of Napster, the distri-
bution of music in violation of copyrightÑwhile a distributed network of
computers exchanging files is harder to detect and, because it potentially
involves thousands or millions of participants, to take action against.17There are additional compelling arguments for peer-to-peer applica-tions. By their nature, they do not require the installation of servers or
arrangements with businesses that offer hosting services (or other capa-
bilities). Thus they offer a speed and ease of deployment applications
much in the spirit of the InternetÕs pure end-to-end modelÑa new appli-
cation depends only on software running on the individual computers
and adequate network performance, and not on the installation of soft-
ware on a hosting server. The appeal is twofold: nimbleness that comes
from not having to coordinate with any other party when rolling out15Similar services have also been introduced, such as AIMster, which leverages AOLÕsInstant Messenger for file transfer.16Intel has been encouraging such applications through the Intel Philanthropic Peer toPeer Program (see <http://www.intel.com/cure/program.htm>).17For an examination of technical and other factors surrounding intellectual propertyrights in a networked world, see Computer Science and Telecommunications Board, Na-tional Research Council. 2000. The Digital Dilemma. National Academy Press, Washington,D.C.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT107content or applications, and the freedom and control over oneÕs owncontent that come from not having to involve a third party. Given such
attributes, pilot efforts are underway to use the technology in business,
the scientific community, and so forth.18ÒLocal InterestÓ Content, Including VideoAlthough the mass appeal of community-access television is debat-able, cable has provided a vehicle for communities, organizations, and
individuals to gain some experience and to experiment with video con-
tent production. Broadband promises to generalize and build on that ex-
perience by enabling a more varied menu of content not constrained by
finite studio and broadcast time slots. In the short term, constraints on
long-haul bandwidth may preclude wide-area transmission, but most of
the interest would be local in any event. Local-interest video program-
ming requires high bandwidth within a community, suggesting that it is
most likely to take off with fiber and most likely to be linked early to
community-wide fiber networks. The traveling parent who wants to
watch the local Little League game will have to settle for very low quality
video, or pay very dearly (if that is even possible, since the limiting fac-
tors will be community connectivity to the core net, not just the traveling
parentÕs connectivity). However, the ability for remote family and friends
to see (literally) local activities is socially valuable; the sharing of family
photos, Web sites for children (beginning prenatally in some instances),
and other grass-roots activity begun with narrowband suggest the poten-
tial for growth.Home Content HostingThere are many applicationsÑdistinguished by their not requiringdelivery of information that changes in real timeÑthat lend themselves to
either a model of local hosting or a model in which users upload content18The surge of popularity in peer-to-peer applications also raises speculative questions ofwhether the Internet really is evolving toward being the basis of a distributed computer. Ifthe answer is yes, then one might think of computer bus speeds as giving some sort of an
upper limit to broadband speeds. Today, the 32-bit bus of a 1.5-GHz Pentium 4 runs at 48Gbps in both directions (peak, or at least half of that speed in both directions). This viewwould support the eventual migration toward a fiber to each home (which, as is discussed
elsewhere in this report, is something that may take some time to happen). There may alsobe an accompanying trend that, as speeds increase beyond the human limits of audio andvideo, the bandwidth demands become more symmetric.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.108BROADBANDto content servers. These include, for example, Web page hosting, makingphotos available for others to download, sharing music. (In contrast, there
is no substitute for upstream capacity for applications that depend on
transmission of delay-sensitive real-time content out of the home, as is
required for telephony, videoconferencing, or  webcams. Also, home con-

trol and other applications that access sensor information and then take
control actions must access the actual home.) The content-hosting alterna-
tive still requires upstream capacity, but it involves the transfer of content
only once each time it is modified; those accessing the content download
or stream it from one or more third-party servers located somewhere in
the Internet.19 Use of hosting services is a common practice for both busi-ness and personal content, and a number of businesses provide services
in this area. Third-party hosting offers several advantages. The provider,
who specializes in that sort of service, takes on responsibility for appro-
priate interconnection and colocation arrangements to ensure good per-
formance for users throughout the Internet. A third-party hosting pro-
vider also generally provides other desirable functionality, such as
redundant facilities, backup power, and data backup.The choice between these two alternativesÑlocal hosting or use of ahosting providerÑdepends on many factors. First, there are trade-offs,
depending on how often things change versus how often they are used.
For example, a home webcam might change once per minute and have to
push a new image to a server at that point, but if the image is only ac-
cessed rarely, then most of those server updates will have been pointless
and the network would be less loaded if users directly accessed the cam-
era. Consumer preference, including such considerations as wishing to
maintain personal control over content, also plays a role. The emergence
of a ÒNapster cultureÓ suggests demand for the local hosting approach,
but the future of this model is unclear, as is the future of peer-to-peer
itself, in part because many of todayÕs broadband services provide limited
upstream capacity and because ISPs may discourage or prohibit users
from running their own servers or consuming large amounts of upstream
bandwidth. The balance might tip as significantly more upstream band-
width is made available in the local access segment.19Note that this model can also be applied to near-real-time content, such as audio orvideo broadcasts of live events; one copy of a stream can be pushed out to buffers on local
content servers for multiple users to access, as demonstrated by AkamaiÕs technology forstreaming video. However, unlike uploaded content, streamed uploading implies a steady-state demand for upstream content.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT109Push ContentVarious business models assume an ability for different kinds of par-ties to push content into homesÑthat is, rather than await a specific re-
quest, always-on connectivity would enable these parties to transmit con-
tent into homes on a variety of schedules. Some of these arrangements
would be highly functionalÑupdates to device software, regular and au-
tomatic updates to databases maintained in the home, diagnostic probes
(which would trigger responses), and so on. Other arrangements may be
part of the ÒpriceÓ of a device or service, such as advertising.Multiplexing Applications Demand in HomesUnderstanding how demand for networked capabilities and serviceswill evolve is extraordinarily difficult. It is apparent that there are mul-
tiple broadband applications of interest and that some sort of composite
of this is likely to typify future broadband use. To complement rampant
speculation, a number of scholarly and corporate entities have begun to
develop model homes of the future, which are laboratories, showcases, or
both, for potential windows into new options for home life. These possi-
bilities leverage many developments, as explained in a variety of specula-
tive media pieces:The fusion of technology and materials is making new forms possible.Add the potential of artificial intelligence, biometric sensing, roboticsand mass customization, and itÕs little wonder that designers are imag-ining a new generation of houses in which people rule their environ-
ments, rather than submit to them. Web-linked companies already arerolling out model homes with all the click-and-drag amenities availabletoday. They trumpet a lifestyle in which work, play and shopping are
only a palm-held device away. ItÕs the profusion of gadgets, and thedependence on them and the linkages among them, that will define thefuture of this house.20These visions imply bandwidth demand associated with both individualhousehold members and devices; people will use networks to communi-
cate with each other, and devices will communicate with each other (and
with people) directly, too. The descriptions suggest movement toward
more symmetric communication capabilityÑin the limit, equal upstream
and downstream capacityÑfor homes; but how much remains an open
question. In the meantime, the descriptions clearly argue for in-home20Linda Hales. 2001. ÒBlobs, Pods and People.Ó The Washington Post Magazine, March 25,p. 37.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.110BROADBANDnetworking and multiple access points in homes, and suggest choices stillto be worked out about how data is managed in the home. How the data
get sent around or through the home becomes a critical factor in a number
of applications, as does the interplay between storage in the home and
remote storage. And whether people will have to reboot their homes
under various circumstances raises other questions, from how to contain
various risks to interactions of the information infrastructure with power
supply in the household to disaster recovery options (familiar to busi-
nesses and encouraged by commercial insurance).There are perils in scrutinizing any one application too closely. Al-though it is important to appreciate how the technical requirements of
applications vary, the promise of broadband is simultaneous support for
a large number and a wide variety of applications rather than just one or
two. Moreover, the broadband vision involves several people in a house-
hold using different applications concurrentlyÑperhaps more than one
application per individualÑas well as more network-based interaction
among people in multiple locations (from extended family to work or
study collaborators to fellow hobbyists). At the same time, people are
already experimenting withÑand being subjected to more hype aboutÑ
mobile computing and communications devices. The eventual context for
broadband is thus one of anytime, anywhere networking and an informa-
tion infrastructure that is pervasive and integral to many places and ac-
tivities. The individual and social implications of this aggregate of activ-
ity suggest new behavioral patterns that themselves may stimulate new
applications. The impact on quality of life can be much greater than that
suggested by any one application, and its full potential hinges on growth
in number of users as well as uses, since some applications involve shar-
ing among households (and/or between households and a variety of pub-
lic and private institutions).The enabling technology remains only a piece of the picture, of course,
and it interacts with expectations for how it would be used. In the com-
mitteeÕs June 2000 workshop, Andrew Cohill, speaking from the experi-
ence of the Blacksburg Electronic Village initiative in Blacksburg, Vir-
ginia, noted that the aggregate bandwidth demand as conventional
applications (communications such as telephony and entertainment such
as radio and television) migrate to the Internet would exceed the band-
width available from todayÕs DSL and cable services. The expectation for
significant outflow as well as inflow of content opens up the possibility of
new kinds of connections from the home to points outside. For example, a
familyÕs (or friendsÕ and familyÕs) virtual private network (VPN) could be
established to promote social sharing, much as corporate VPNs enable
protected communication among co-workers and others granted access,
regardless of location.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT111Internet AppliancesThe majority of existing and potential broadband applications as-sume a person at the end of the pipe actively using the content being
served, whether he or she is watching a movie, shopping on the Web, or
talking to a doctor. With this assumption, there is a potential upper bound

on the demand for broadband, as it is limited by the number of people in
a typical home. However, some futurists, as well as some commercial
appliance vendors, anticipate a demand that is more accurately bounded
by the number of information appliances in the homeÑautonomous con-
sumers and producers of content that rely on the always-on capabilities of
a broadband connection.Although the scenario of the dishwasher that independently calls therepairman for service has met with appropriate skepticism, there are al-
ready information appliances in the marketplace and in peopleÕs homes.
Internet photo frames are a good example. Marketed by various compa-
nies, these frames are essentially an LCD (liquid crystal display) with a
phone connection packaged as a traditional picture frame. In current ver-
sions, the frames connect to the Internet at off-hours (e.g., 3:00 a.m.) and
download new photos that have been sent to the appropriate Web site by
family members and friends. A simple extension of this idea would be
wall art that loads art pieces from various museum collections.Connecting these displays to live content (perhaps including a timedelay) offers the ability of viewing, say, the London skyline and bridges
fresh each day. A poster of Africa in a childÕs bedroom could be replaced
with live webcam images from safari rides and waterholes.21 Returning to
the theme of families sharing photos, appliance designers predict aes-
thetically pleasing (and privacy-preserving) representations of the well-
being of a loved one. In one scenario, opening the portable photo frame of
a family member while traveling triggers switching an art piece in the
home from black-and-white to color.Returning to the dishwasher, while there are sound objections to ap-pliances requesting people to arrive at the ownerÕs home, it is less far-
fetched for an appliance under warranty to preorder new parts upon
detecting a failure, or for prescribed medications to directly request re-
fills. Although business models for new Internet services (e.g., online
grocery reordering) may not work, some extensions to existing services
may prove to be economical and desirable.21See <http://www.africam.com>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.112BROADBANDDistributed Work and EducationDistributed work and educationÑwhich depend on e-mail, file trans-fer, and sometimes on audio- and videoconference capabilitiesÑhave long
been touted as applications for information networks; both have already
benefited from narrowband Internet access. Following significant growth
in the 1990s, a sizable minority of companies are believed to offer a
telecommuting option to some employees, presumably as a result of the
proliferation of personal computing and communications options as well
as the impetus provided by a variety of situations (e.g., California earth-
quakes) that have increased transportation problems.22 At the same time,there have also been reports of dissatisfaction on the part of both employ-
ees and employers.Forecasts have included expectations of growing use of multiple me-dia (e.g., enabling simultaneous transmission of data and voice or of at
least two streams of data) and of conferencing involving multiple media,
including video as well as audio links. One enabler would be availability
of connectivity comparable to the 10 Mbps typical of low-end office local
area networks, with more symmetric bandwidth enabling more symmetri-

cal use.One small study examined reactions of people working at home to atransition to DSL service and found overall satisfaction based on the in-
crease in their productivity attributed to higher-speed connectivity; people
also noted that the productivity benefit depended on whether other home-
based workers with whom they collaborated also had such connectivity.23That kind of comment underscores the potential for qualitative change in
an activity from widespread availability of a capabilityÑchange not vis-
ible when availability is unevenly distributed among a population, such
as a group of teleworkers.Distributed education, like distributed work, involves remote accessto information and communications. Discussions of distributed education
are more likely to involve use of still and moving images with broadband;
they also involve conferencing for interaction among multiple students.
Note that distributed education is expected to benefit both adults and
children.22Patricia Riley, Anu Mandavilli, and Rebecca Heino. 2000. ÒObserving the Impact ofCommunication and Information Technology on ÔNet-WorkÕ.Ó Telework and the New Work-place of the 21st Century
. U.S. Department of Labor, Washington, D.C. Available online at<http://www.dol.gov/dol/asp/public/telework/p2_3.htm>.23Riley, ÒObserving the Impact of Communication Technology,Ó 2000.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT113ÒTele-webbingÓA new sort of composite application that some have begun to callÒtele-webbing,Ó which combines Internet access with conventional televi-
sion viewing, is beginning to appear. Simplistically, accessing the Web
while also watching television would qualify for this description, and
indeed it is common for people to engage in other activities while also
watching entertainment television that has low attention demands. Thus,
the consumer who scans e-mail while watching a sitcom could be said to
be tele-webbing. More interesting, however, are cases now emerging
where the television watching and Web access are interrelated. For ex-
ample, many sports Web sites now provide real-time Web applications
that feed game statistics to a browser. Having such a site open while
watching a televised sports event provides a deeper experience of the
event. For an even more real-time experience, experiments have been
done with making race-car telemetry information available concurrently
with a race broadcast. This allows a measure of user selectivity in how the
race is experienced, since the user can focus attention on a particular
driver. Finally, various levels of viewer interactivity have been evaluated
for making television game shows (which have long elicited vicarious
play-along-at-home experiences) truly interactive. All of these ideas in-
volve taking advantage of a second screen that the user can selectively use
for added experiences. Importantly, all these applications involve con-
straints on tolerable latency for the data streams relative to the primary
video streams. This class of applications may be another example of where
the total bandwidth demand to a home may exceed what the user can
consume at any instant because the value of these applications lies at least
in part in the userÕs ability to instantly shift attention from one video feed
to another screen full of information.Communities and Community NetworksCommunity networking efforts to date provide a window into theinteractions and synergistic possibilities presented by greater networking
capabilities among people in a given area, who presumably have at least
some shared interest in a common set of information or in communicating
with each other. With disappearance of a number of the pioneering bulle-
tin-board-type community networks, network communications have
tended to become less geographically focused. And as dial-up Internet
access via commercial ISPs has become widespread, community network-
ing initiatives have, for the most part, focused less on building local infra-
structure and more on content and services. Contemporary approaches to
community networks are likely to emphasize a variety of service activitiesBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.114BROADBANDthat accompany deployment and facilitate use, such as information re-sources and training, economic incubation, pilot and demonstration proj-
ects, and development of public-private partnerships. But regardless of
how it is labeled, the attention to local interests has persisted; it is ex-
pressed in the various Web sites established by local governments,
schools, libraries, athletic consortia, religious institutions, and so onÑa
diverse group of sources that defies the categorization of the more con-
trolled local access cable television or local radio station and that offers
the potential of upgraded offerings where capabilities are available.Note that on a small scale, multiunit dwellings (e.g., apartment build-ings) can serve as microcommunities: the availability of broadband to
individuals in the component units is constrained by decision making of
the owner; where the owner is supportive, all units can have this capabil-
ity, but the reverse tends to be true as well. Also, in some communities,
special centers have been established that offer broadband capabilities
together with the hardware and software to take advantage of themÑa
physical portal.24 These communications centers complement the concen-
trations of demand in such public-interest (and often publicly supported)
facilities as medical and education centers of different kinds. Thus, it is
important to recognize that community networks have both infrastruc-
tural and content dimensions.SOCIAL FACTORS AND IMPACTS OF BROADBANDThere is much potential for future applications that enrich or comple-ment traditional content and communications channels, but excitement
about them should be tempered by an appraisal of the time frame in
which these applications could be realized and the nontechnical obstacles
that retard their deployment. Much of the expectation surrounding broad-
band involves more than new technologyÑit also requires a transforma-
tion of societal structures, media, and other institutions. This section
briefly discusses some of these factors.Availability of ContentOne obstacle is the availability of content. A recent television com-mercial from Qwest exemplified the expectationsÑbeing able to access
every book ever published in any language and every movie ever made24Richard Civille, Michael Gurstein, and Kenneth Pigg. 2001. ÒAccess to What? First MileIssues for Rural Broadband,Ó white paper; see Appendix C.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT115available, on demand over the Internet. In reality, we are some time awayfrom widespread video-on-demand; thousands of channels of ÒradioÓ
over the Internet; abundant, high-quality educational video content; and
so forth.25In addition to technical obstacles, the familiar chicken-and-egg phe-nomenon comes into play. Without a mass market of consumers with
broadband access, it is hard to develop a business model that justifies
investment in new content (or translating old content). One new media
businessperson, Andrew Sharpless, addressed the committee from his
vantage at that time of developing new online services for Discovery
Communications. He suggested that at least 10 million households would
need to use broadband before meaningful content would emerge, and he
noted that cable experience shows that serving 50 million customers is
key to lining up advertisers (with online services, a top rating by Jupiter
Media Metrix had become key to advertiser interest by 2000).26Intellectual property rights issues are another large factorÑthe inter-ests and holdings of broadband providers, users, and rights holders are
not necessarily aligned. The 2000-2001 rise of Internet radio raised a set of
issues related to content use fees, and the popularity of Napster and other
content-sharing technologies heightened rights holdersÕ concerns about
control over their intellectual property, making intellectual property more
prominent in the development of business plans.27Finally, although content availability affects demand for broadband,one should not underestimate the volume and value of customer-pro-
vided content. Broadband is not only a mass media technology; it is also
an interpersonal technology. As noted above, messaging and e-mail are
both very popular applications, illustrating the value of broadband for25Unrealistic expectations have been rampant when it comes to home technology, if notthe Internet generally. For example, the Washington Post published an article in 1994 that
suggested that going online will not support new relationships, online banking, real-timegame-playing, ÒbaskingÓ in multimedia, hobnobbing with celebrities, and online shopping,most of which has, in fact, happened, at least to some degree even with low bandwidth. See
Jim Kennelly. 1994. Ò9 Ways Going On-Line Can Change Your Life and 6 Ways It CanÕt,ÓThe Washington Post: Fast Forward, September, pp. 9-13.26Andrew Sharpless, personal communication, briefing to the committee, November 1999.He discussed how Discovery Online scaled back its content expectations because of theseconsiderations.27For an in-depth exploration of the issues surrounding intellectual property rights in adigital, networked environment, see Computer Science and Telecommunications Board,National Research Council, 2000, The Digital Dilemma, National Academy Press, Washing-ton, D.C.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.116BROADBANDcommunication as well as content delivery.28 Multiplayer games, one of
the few profitable Internet applications today, rely on user-provided con-
tent. Telemedicine will rely, in large measure, on user-provided content,
plus some professionally prepared patient education materials. Families
will generate and want to distribute pictures and home movies.Broadband ImpactsOne category of impact on quality of life derives from broadbandÕsinteraction with consumption of media: broadband is associated with the
allocation of more time to media consumption overall, in part because it
puts Internet use on a par with TV and radio use.29 Whether the increase
in media consumption is transient or long term, and what it may imply
for (or as a result of) other activities that may receive less time than media
consumption, remain to be seen. It is not known whether the home is
truly an infinite sink for bits over time or whether there is some limit that
one can compute, based on something like human perception or expecta-
tions about other things going on in the home. In terms of general infor-
mation access, one could argue that broadband provides limited content
beyond that available through dial-up. There is little unique content avail-
able only to broadband users that is not duplicated on cable television
today (e.g., CSPAN). In terms of applications, the prominent examples
deal with entertainmentÑaccess to interactive games, or even a broader
assortment of music than one can find on the local radio channels is
unlikely to compel public policy support, but these applications, along
with day-trading tools and e-commerce, exercise the technology (and,
sometimes, the law) and build an experience base for the underlying
capabilities.30 Attention to individual categories of information or appli-
cations can obscure the larger development, which is a shift to an expecta-
tion of ubiquitous access to a variety of information and applications. But
ubiquity does not imply endless variety: experience with television shows28Some argue that the value of communications applications such as messaging isunderappreciated compared to content delivery. See Andrew Odlyzko. 2001. ÒContent Is
Not King.Ó First Monday 6(2)(February). Available online at <http://www.firstmonday.
org/issues/issue6_2/odlyzko/>.29Pierre Bouvard and Warren Kurtzman. 2000. The Broadband Revolution: How SuperfastInternet Access Changes Media Habits in American Households. Arbitron Company, New York.Available online at <www.arbitron.com> and <www.colemanresearch.com>.30One might draw a limited analogy to the supply of simple games with the Windowsoperating system and Palm devices to help people get used to manipulating a mouse in theformer case and the Graffiti writing system in the latter.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT117that consumers limit themselves to seven to nine channels, implying highcost in searching for acceptable contentÑand that aids in effecting such
search may be an important complement to content innovations per se.
The oft-made contrast between children who are exposed to computer-
based technology early on and adults who are introduced to it at older
ages underscores the potential for cumulative experience to change peo-
pleÕs expectations and behavior.Several emerging applications described above may be more compel-ling from a policy perspective. Telecommuting can have positive impacts
on the environment, local economies, and peopleÕs ability to earn a good
living. Telemetry and monitoring applications can enhance health care
delivery. Basic communications and telepresence applications can help
keep children and elderly parents connected. And broadband can be used
to deliver more sophisticated (multimedia and interactive) educational
content. But many of these applications remain more promise than reality.There is time to consider and act on possible negative impacts (fromthe obvious questions about privacy and security to the more idiosyn-
cratic ones relating to cases of excessive use). For example, public- and
private-sector attempts to deal with spam originating in the narrowband
context are likely to take on new urgency in the broadband context. If any
kind of communications of the past is any guide, people will send infor-
mation whether there is demand or not, and the prospect of video spam
may arouse people even more than fax and e-mail spam have. Security
concerns have arisen, associated with the always-on nature of broadband.
But with anticipated assimilation of broadband into a technology-inten-
sive household, other concerns will arise. For example, just as people
change physical locks after, say, a divorced spouse leaves, a kind of vir-
tual door is developing with broadband, and there may be a kind of
virtual set of keys to change, too. This is also a time to address the impli-
cations of technology options for the disabled: Some of the envisioned
capabilities will make it easier for people with disabilities to remain in
their homes; some may require appropriate design for effective use by
people with disabilities. Consideration of differences in abilities leads
naturally to consideration of human-computer interaction and user inter-
faces; progress in these areas may facilitate use by all.While the lag in compelling applications may contain growth in de-mand for broadband, its silver lining may be to limit the impact of dis-
parities in access and use. Measurements of the disparity are in flux,
given progress in deployment and adoption, but significant differences
have been noted by region, locality, racial and ethnic groups, income,
educational attainment, and age.31 Income and educational attainment
31See NTIAÕs Falling Through the Net series.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.118BROADBANDtend to drive demographic differences; geographic differences reflect thelarger complex of factors governing deployment discussed in Chapter 4.
Progress implies deeper understanding of differences in media consump-
tion among population groups and options for diminishing disparities.
Consumer advocates report an overall bimodal pattern, with clusters of
low-volume and extremely high-volume users of media and differences
in terms of what people use communications for. The bottom half pays
$60 per month for all services, while the top half pays $200 per month.
Different business models are needed to serve the lower half, and observ-
able business models for broadband seem to focus on the upper, more-
lucrative half.32 Of course, it is reasonable to expect that during the transi-
tion from broadband, even people who could shift will not do so at once,
and those who do so first value the capabilities more and will pay more.The picture painted in this chapter, of multidimensional change inhousehold technology and activities, suggests that raising the floor for
residential broadband implies addressing total and life-cycle costs. That
is, the broadband-enabled changes in lifestyle and quality of life that
could occur presume both network deployment and consumer electronics
and applications (software, services), all of which may impinge on house-
hold budgets (for acquisition and operation or regular use costs) and
requirements for know-how (the aggregate of technologies and activities
imply new set-up, use, and maintenance activities). The full, short- and
long-term impacts on household economics deserve further study, per-
haps in conjunction with the model homes and communities that have
been or will be initiated. For example, for connectivity alone, it would be
useful to compare the costs of various scenarios, from current options,
such as multiple phone lines plus cable or satellite, to broadband connec-
tivity (with or without additional home connections), with different ap-
proaches to in-home networking and customer equipment. Business mod-
els make different assumptions about demand and willingness to pay.33Understanding the implications of alternative approaches is a logical ele-
ment of public- and private-sector planning. The combination of failures
and successes in Internet-related and, more generally, media-related ser-
vices underscores a dearth of social science insight into how people use
and respond to new media.32Gene Kimmelman, Consumers Union, personal communication, briefing to the com-mittee, November 1999.33For example, Time Warner CableÕs $40 per month charge was based on the recognitionthat consumers were paying $19.95 per month to an ISP and more for a second phone line.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND APPLICATIONS AND CONTENT119Finally, there are the uncertainties relating to what people want andwill do. Assimilation of these changes, of course, presumes assuring that
the use of these capabilities is perceived as valuable (appealing and rel-
evant) to multiple categories of people. Historically, with television, which
was fundamentally familiar, the introduction of pay-TV programming
led to consumers often electing to buy multiple services, which are dif-
ferentiated. The new, nonincremental and interacting broadband options
are less familiar than were variations on the TV theme. There is some
evidence that willingness to pay increases with consumer control: in the
committeeÕs June 2000 workshop, for example, AT&T researcher Andrew
Odlyzko compared peopleÕs willingness to pay $40 per month for cable
for 100 Mbps consumed 3 hours per day with $70 per month for wireline
phone for 64 kbps used 1 hour per day with $40 to $50 per month for
wireless phone for 8 kbps used less than 10 minutes per day. This line of
argument complements that of consumer advocates and others who ar-
gue for open access (see Chapter 5 in this report), as a counter to a fear
that content coming into the home will be overly controlled by commer-
cial providers. It is not surprising that local efforts that link deployment to
economic development tend to feature awareness and training pro-
grams,34 while various nonprofit and entrepreneurial efforts seek to gen-
erate content that is of interest to specific demographic groups. Recogniz-
ing that socioeconomic context affects willingness and ability to use new
technology does not necessarily make it easier to devise effective strate-
gies, and trial and error is evident.34Glasgow, Kentucky, was a pioneer in providing broadband, but the experience showedslow adoption and uncertainty about why the capability should be used, necessitating ef-
forts to generate awareness, interest, and use. See Anick Jesdanum. 2000. ÒWiring RuralAmerica: Just the Beginning.Ó Associated Press, September 6. Available online at <http://www.msnbc.com:80/news/452691.asp?cp1=1>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.120

Although great technical and business strides have been made inimproving the data transmission speeds of communications networks,
the local access technologies that make up the last (or first) mile connec-
tions in the network have mostly lagged far behind. Enhancing the local
access infrastructure to bring high-speed services to residences and small
businesses requires upgrading or building infrastructure to each premises

served. There are a variety of technology options with different character-
istics and cost structures and variation in willingness to pay among po-
tential customers. This chapter explores the characteristics of the various
local access technologies and the interplay among relevant economic con-
siderations.LOCAL ACCESS TECHNOLOGIES IN CONTEXTWhile this chapter focuses on local access, the other network elementsthrough which content, applications, and services are provided also con-
tribute to the total cost and performance characteristics of broadband
service. Local access links carry communications to and from points at
which communications from multiple premises are aggregated and fun-
neled onto higher-capacity links that ultimately connect to the Internet or
other broadband services. The first point of aggregation, also known as
the point of presence, is most commonly located at a telephone company
central office, cable system head end, or radio tower (which may be at a
considerable distance from the premises) but may also be in a piece ofBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS121equipment in a vault, pedestal, wireless antenna site, or pole-top devicelocated nearby to the premises. Circuits installed or leased by the pro-
vider in turn run from the point of presence to one or more public or
private access points for interconnection with the Internet. The so-called
second mile connects local access facilities with upstream points of aggre-
gation. In connecting to the Internet, broadband providers either pay for
transit service or establish peering agreements with other ISPs to exchange
traffic on a settlement-free (barter) basis. Caches, e-mail and content serv-
ers, and servers supporting specialized services such as video-on-demand
or voice telephony are located at points of presence and/or data centers.
Routers located in points of presence and data centers take care of direct-
ing data packets on to the next point in the cross-network trip to their
eventual destination.ESSENTIAL FEATURES OF THE LOCAL ACCESSTECHNOLOGY OPTIONSThe future of broadband is sometimes described as a shootout amongcompeting technologies that will result in a single technology dominating
nationwide. This view, however, is simplistic and unrealistic; there is no
single superior technology option. Broadband is going to be characterized
by diverse technologies for the foreseeable future. There are a number of
reasons for this:¥Incremental investment in existing infrastructure. While some firms
may have access to large amounts of venture capital, the expectations of
investors in existing firms is for short-term payoffs. As a result, the tech-
nological approach chosen by an incumbent is likely to make use of exist-
ing equipment and plant, and the deployment strategy must be amenable
to incremental upgrades. The infrastructures of the various incumbents in
the broadband marketplaceÑtelephone local exchange carriers with cop-
per loops, cable television companies with coaxial cable, cellular compa-
nies with towers for point-to-point wireless telephonyÑwill continue to
make incremental improvements unique to their respective technologies
to provide and enhance broadband services.¥Continued exploitation of skills. Technologies require distinctive skillsand knowledgeÑthose needed, for example, to design, launch, and oper-
ate a satellite. Similarly, cable and telephone companies understand the
technological challenges associated with their respective systems. Com-
panies that know how to do one or another thing well will attempt to find
market opportunities where these skills give them an advantage.¥Different demographics and density. The United States (and world)population is very diverse in topography, density, wealth, and demandBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.122BROADBANDfor communications services. The particular economic and technical char-acteristics of each broadband technology will provide specific advantages
in serving certain geographical areas or demographic groups. Some may
have an economic advantage in particular locales owing to the nature of
the infrastructure already in place or to inherent physical attributes of the
environment. Planning should reflect the existence of a diverse set of
solutions that depend on particular circumstances rather than a technol-
ogy monoculture.This section discusses the salient characteristics of each technologyoption and provides a brief road map of how existing technology and
anticipated research and development will play out in coming years.Wireline OptionsIn rough terms, access technologies are either wireline or wireless.Wireline includes telephone network copper pairs and the coaxial cable
used for cable television service. Incumbent telephone companies and
cable operators are both in the process of upgrading their infrastructures
to provide broadband services. Wireline infrastructure is also being built
in some areas by so-called overbuilders, who are building new wireline
infrastructure in competition with the incumbent wireline providers. In
the United States, this has largely been through deployment of hybrid
fiber coax to provide some mix of television, data, and voice services.
There are also a few overbuilders that are using or plan to use fiber.The wireline technologies all share the feature that labor and access toa right-of-way are significant components of the cost. These costs are
more significant where infrastructure must be buried than where it can be
installed on existing poles.1 The other major component is the electronicsat each end of the line, where costs are subject to rapid decreases over
time as a result of MooreÕs law improvements in the performance-to-costratio and increasing production volumes. Labor, on the other hand, is not
subject to MooreÕs law, so there is no obvious way within the wirelinecontext for dramatic declines in cost for new installation (though one
cannot rule out very clever solutions that significantly reduce the labor
required for some elements of the installation).1One estimate provided to the committee is that aerial installation is almost twice asinexpensive as when the infrastructure must be buried.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS123Hybrid Fiber CoaxCable systems pass 97 percent of the homes in the United States.2 The
older generation of cable technology uses a branching structure of coaxial
cables fanning out from a central point or head end to the buildings in a
community (see Figure 4.1a). The older systems rely on long chains of
coaxial cables and amplifiers, with each segment feeding into a smaller
coaxial segment.Hybrid fiber coax (HFC) is the current generation of cable systemtechnology. HFC systems carry analog signals that feed conventional tele-
vision sets as well as digital signals encoded onto analog signals that
carry digital video programming and up- and downstream data. In the
new architecture, the system is divided into a number of small coaxial
segments with a fiber optic cable used to feed each segment or cluster. By
using fiber instead of coax to feed into neighborhoods, the systemÕs per-formance and reliability is significantly improved.Another benefit of an HFC upgrade is that the resulting system cancarry two-way data communications, such as Internet access. Additional
equipment is installed to permit information to flow both to and from the
home (see Figure 4.1b). Internet service is provided using a device called
a cable modem in the home and a device known as a cable modem termi-
nation system in the head end. The ability to offer competitive video,
voice, and high-speed data services using the present generation of tech-
nology has attracted several nonincumbent companies to enter a few mar-
kets as overbuilders using the HFC technology.Over 70 percent of the homes in the United States are now passed bythis upgraded form of cable infrastructure. The fraction of homes served
by HFC is continuing to increase as cable companies upgrade connections
to all homes in their franchise areas and can, with continued investment
in upgrades, increase until it approaches the 97 percent of households
that currently have cable service available at their property lines.A technology standard for cable modems known as DOCSIS has beenadopted industrywide. Developed by an industry consortium seeking a
quicker alternative to the more traditional standards development pro-
cess then underway under the auspices of the IEEE, the DOCSIS standard
is stable, and more than 70 modems have been certified as compliant.
Standardization has helped modems become a mass-market product. The
standard provides consumers the assurance that if they purchase certified
modems at retail, or have them built into PCs or other appliances, cable
operators will support them across the country. Further helping push
down costs, several competing suppliers have developed highly inte-2Paul Kagan Associates. 2001. The Kagan Media Index, Jan. 31, 2001.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.124BROADBANDHEAD ENDRF AmplifierTrunk Cable(coax)40+ AmplifierCascades commonHEAD ENDOptical NodeOptical Cable500 Homes PassedTypically 6 orFewer Amplifiersin CascadeFIGURE 4.1Evolution of cable systems to support two-way data. SOURCE:
James Chiddix. 1999. ÒThe Evolution of the U.S. Telecommunications Infrastruc-ture Over the Next Decade. TTG2: Hybrid-Fiber-Coax TechnologyÓ (IEEE work-
shop paper).(a) Tree and Branch Architecture(b) HFC ArchitectureBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS125grated silicon, and single-chip DOCSIS solutions are available to modemmanufacturers. With increasing volumes, a single standard, and single-
chip solutions, the cost of a cable modem at wholesale has already
dropped to $150 or less and can be expected to continue to drop as vol-
umes increase.Digital Subscriber LineDigital subscriber line (DSL) is the current method by which twistedcopper pairs (also known as loops), the decades-old technology used by
the telephone companies to reach the residence, can be upgraded to sup-
port high-speed data access. In some newer builds, analog transmission
over copper wire is only used between the premises and a remote termi-
nal (which may be at curbside or, more commonly in a pedestal or under-
ground vault within a neighborhood), while a digital loop carrier (DLC)
generally using fiber optic cable connects the remote terminal with the
central office. In a traditional, all-copper plant, the first segment of the
loop plant is referred to as the Òfeeder plant,Ó in which hundreds of
phone lines are bundled in a cable that runs from the central office to a
smaller distribution point. From the distribution point, smaller cables
containing fewer phone lines run to pedestals or cabinets within a neigh-
borhood, where they in turn connect to the twisted pairs that run to the
customer premises (see Figure 4.2).All transmission of data over wire involves coding these data in someway consistent with the carrying capacity and noise conditions of the
wire. The familiar dial-up modems code (and decode) data in such a way
that the data can pass through the traditional switches and transmission
links that were designed to carry voice, which more or less limits speeds
to todayÕs 56 kbps. DSL uses an advanced coding scheme that is notcompatible with existing switches. Consequently, new electronics known
as a DSL access multiplexer (DSLAM) has to be installed in any central
office where DSL is to be offered. The DSLAM must in turn be connected
to a switched data network that ultimately connects the central office to
the Internet (see Figure 4.3). DSL service enables the transmission of
packet-switched traffic over the twisted copper pairs at much higher

speeds than a dial-up Internet access service can offer. DSL can operate at
megabits per second, depending on the quality and length of the particu-
lar cable. It is thus the upgrade of choice to bring copper pairs into the
broadband market.DSL standards have existed since 1998, and new versions of thesestandards, which add enhancements to asynchronous transfer mode
(ATM), IP, and voice services over DSL, are expected in 2001 or 2002 from
the International Telecommunication Union (ITU). Large interoperabilityBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.126BROADBANDprograms with dozens of qualified suppliers have been implemented bythe DSL Forum, which has about 400 member companies. The forum
develops implementation agreements in support of interoperable DSL
equipment and services and acts as an industry marketing organization
for DSL services, applications, and technology for DSL in general. Also, to
help reduce the cost of asymmetric DSL (ADSL) deployment by specify-
ing a common product and increasing volumes, several companies formed
a procurement consortium.The present generation of DSL products can, depending on line lengthand conditions, reach 1.5 to 8 Mbps downstream and 150 to 600 kbps
upstream in the near future. The present generation of DSL technology
aimed at residential customers, ADSL, currently supports a typical maxi-
mum of 8 Mbps downstream and 800 kbps upstream (different flavors
deployed by various providers vary somewhat). A related flavor, G.lite,
which makes compromises in order to permit customer self-installation
on the same line being used for analog voice service, supports up to 1.5
Mbps downstream. (Another variant, symmetric DSL [SDSL], supportsMaindistributingframeSAIFeederDistributionPedestalsNIDDrop WireInside WireCustomerPremises20,000 to160,0001,500 to 4,000200 to 8004 to 12Number of Lines Present at a Site22,000 ft9,000 ft3,000 ft500 ftWire Length to Customer (90th percentile) Central office equipmentFIGURE 4.2Telephone company copper loop plant. SOURCE: Adapted from a
figure supplied by John Cioffi, Stanford University.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS127higher, symmetric speeds.) All of these speeds are maximumsÑthe actualspeed obtainable over the DSL link depends on line length, noise, and
other aspects of the line condition as well as on the maximum speed
supported by the particular service that a customer has subscribed to.
Higher-speed versions of DSL, known as very high data rate DSL (VDSL),
are in development. These depend on investment in new fiber in the loop
plant that shortens the copper loop length to enable higher speedsÑtensof megabits per second in both directions. Figure 4.4 summarizes the rate
and distance trade-offs for the various flavors of DSL.DSL is available to a large fraction of homes and businesses in theUnited States over normal phone lines (the exact fraction is hard to deter-
mine because of the factors discussed below). However, not all of the
homes that are passed by telephone cables easily support DSL, and some
homes cannot be offered DSL service at all without major upgrades to the
infrastructure. Certain pairs are unsuited for such upgrades because of
how they were engineeredÑfor example, using bridge taps or loadingcoils. Also, where the loop between central office and premises includes a
digital loop carrier, the remote terminal equipment must be upgraded toGATEWAY(s)DSLAMMuxorDemuxADSLModemADSLModemADSLModemInternetServiceProvidersSplitPOTSNetworkTelephone Company OfficeDigitalDigitalFIGURE 4.3DSL connections at the central office.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.128BROADBANDsupport DSL. More significantly, DSL does not work over wires longerthan a certain distance (18,000 feet for the primary flavor used for residen-
tial service today, ADSL). It should be noted that wire lengths are sub-
stantially shortened by the deployment of remote terminals.CrosstalkÑthe coupling of electrical signals between nearby wiresÑgives rise to interference that degrades the carrying capacity of each cop-
per pair. The level of crosstalk depends on the number of pairs within the
bundle carrying DSL, their proximity, and the power and bandwidths
they use. It is even possible for DSL signals from adjacent lines to create
signals larger than the intended DSL signal on the line. The interference
has the effect of reducing the maximum data rate at a particular loopFIGURE 4.4Rate and maximum distances for various flavors of DSL. SOURCE:
Adapted from a figure provided to the committee by Ted Darcie, AT&T Re-
search.222018161412108642ISDN(duplex)ADSL(for 640 kbps upstream)RADSL(maximum/ideal conditions)VDSLVDSLVDSL110100
Downstream Data Rate (Mbps)Distance (1,000 feet)6.144 Mbps Down640 kbps Up Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS129length (or the maximum loop length for a given data rate). In essence, anissue of spectrum sharing within the cable bundles arises. The term Òspec-trumÓ is appropriate because the crosstalk and interference effects de-
pend on how the signals on the different pairs make use of the different
frequencies used for transmission over the lines. Today, incumbents and
competitive providers using unbundled loops are free to choose among a
number of flavors of DSL, without regard to how the spectrum used by
one service affects services running over other copper pairs.At the request of the FCC, a working group of carriers and vendorsworked to develop a spectrum management standard for DSL. The pres-
ent standard, released in 2001, places forward-looking limits on signal
power, bandwidth, and loop length.
3 By establishing thresholds with
which the current DSL technology is generally compliant, the standard
seeks to prevent future escalation (where each DSL product or service
would try to Òout-shoutÓ the others) and thus place a bound on the level
of crosstalk that will be faced in the future. While the standard is cur-
rently voluntary, it is generally expected that it will provide the technical
basis for future FCC rulemaking. Issues that the standard does not ad-
dressÑwhich are being explored by a Network Reliability and Inter-
operability Council subgroup under American National Standards In-
stitute (ANSI) T1 auspices that is developing guidance to the FCC on
crosstalkÑinclude how many DSL lines are permitted per binder group,what standards apply to lines fed from digital loop carriers, how products
should be certified or self-certified, and how rule compliance should be
enforced.Advanced Wireline OfferingsÑFiber Optics in the LoopOptical fiber has a theoretical capacity of about 25,000 GHz, com-pared to the roughly 155 megahertz (MHz) possible over short copper
pairs, the roughly 10 GHz4 capacity of coaxial cable. (The relationship
3Working Group on Digital Subscriber Line Access (T1E1.4). 2001. American National Stan-dard for TelecommunicationsÑSpectrum Management for Loop Transmission Systems (T1.417-2001). Standards Committee T1. Alliance for Telecommunications Industry Solutions, Wash-ington, D.C.4The practical upper limit for data transmission over coaxial cable has not been wellexplored. The upper cutoff frequency for a coaxial cable is determined by the diameter of
the outer copper conductor. Smaller cables (1/4-inch- to 1/2-inch-diameter) probably havea cutoff frequency well in excess of 10 GHz. It is unclear what the upper limit is on modula-tion efficiency. The 256 quadrature amplitude modulation (QAM) currently in wide use
allows 7 bits per hertz, but in short, passive runs in neighborhoods, much more efficientmodulation schemes are possible, suggesting that HFC could evolve to speeds exceeding100 Gbps to small clusters of customers.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.130BROADBANDbetween hertz and bits per second depends on the modulation scheme;the number of bits per hertz typically ranges from 1 to more than 7.) This
very high capacity and consequent low cost per unit of bandwidth are the
primary reasons why fiber is preferred wherever individual demand is
very high or demand from multiple users can be aggregated. Other con-
siderations in favor of fiber include high reliability, long service lifetime,5protocol transparency, and consequent future-proof upgradability.6 Thus,
fiber predominates in all of the telecommunications links (voice and data)
except the link to the premises, where cost considerations come into play
most, or for untethered devices. Because of their large demand for band-
width, an increasing fraction of large businesses is being served directly
by fiber links. There is also increasing attention to fiber technologies for
local area and local access networks, as evidenced by recent development
of new technologies such as gigabit Ethernet over fiber.One important use of fiber for broadband is that of increasing theperformance of other wireline technologies through incremental up-
grades. Both HFC systems and DSL systems benefit from pushing fiber
further into the system. To increase the performance of DSL, the copper
links must get shorter. As penetration and the demand for higher speed
increase, the upgrade strategy is to push fiber deeper, with each fiber
feeding smaller service areas in which shorter copper connections run to
the individual premises. So a natural upgrade path for copper infrastruc-
ture is to install electronics ever closer to the residence, to a remote termi-
nal located in a pedestal or underground vault or on a telephone pole; to
run fibers from the central office to this point; and only to use copper5In the 1970s, researchers worried about the possibility of fiber degradation over time. Anumber of experiments were conducted and no degradation effects were found. ThusÑbarring an accidental cutÑthe only reason fiber is replaced is when some new transmissionscheme reveals the old fiber to have too much eccentricity of the core or too much material
dispersion. These factors have only come into play in very particular situations. For ex-ample, when OC192 (10 Gbps) transmission was introduced, there were concerns that oldfiber with an out-of-round cross-section would cause problems. But in the end, only a
limited amount of fiber required replacement to support the new, higher-speed transmis-sions.6ÒProtocol transparencyÓ refers to the ability to run any communications protocol over
the fiber by changing the end equipment and/or software. Other communications mediadisplay some degree of protocol transparency, but with fiber, the large RF spectrum on anindividual fiber is entirely independent of other fibers (in contrast to DSL, which has
crosstalk issues; wireless, which has obvious spectrum-sharing; and HFC, which also hasshared spectrum). This transparency property only holds true over the fiber segments thatare unsharedÑwhere passive splitting is done, all must agree on at least the time divisionmultiplexing (TDM) or wavelength division multiplexing (WDM) scheme, and where ac-tive switching is used, all must agree on the packet protocol. True protocol transparencyÑand true future-proofingÑis thus greatest in a home-run architecture.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS131between the remote terminal and the home. Similarly, to deliver higherperformance over HFC, the number of subscribers in each cluster must
shrink, so that the total capacity of a single coaxial segment is shared by a
smaller number of subscribers and the per-subscriber performance goes
up. This also requires that fiber be installed farther out into the distribu-
tion tree.7A basic upgraded architecture is apparent: fiber optic cables radiateout from a central office or head end to local distribution points that serve
small clusters of buildings. At each cluster, a relatively compact set of
electronics couples the fiber to a local distribution plant. For HFC, a short
segment of coax runs from this distribution point to feed a cluster of
homes, while for DSL this is a short copper twisted pair. As the cluster
size continues to decrease, from the hundreds of homes commonplace in
much of the industry today down to tens of homes, HFC and copper pair
systems will come to resemble each other. The networks will not, to be
sure, be the same in all details. For example, different networks will have
different Òactive elementsÓ in different parts; some networks will have
active switching deep into the network, while cable networks will likely
place less emphasis on remote switching in favor of carrying traffic back
to the head end before aggregation or routing. Where active components
are located has implications for where power must be delivered, and thus
implications for cost, ease of installation, and so forth. But the essential
feature is a continuing trend toward pushing fiber deeper into networks.Fiber-to-the-curb (FTTC) is a general term for this class of system.FTTC is also a label for a specific class of technology that makes extensive
use of fiber for local distribution and that local exchange carriers are using
to build or rebuild their telecommunications. A technology being used in
new construction today, it will in turn be a basis for incremental upgrades
of the telephone infrastructure in the future.Whether as the final upgrade step in the incremental path describedabove or for installation by another player, another alternative is to run
fiber to the premises themselves, dubbed fiber-to-the-home. The term
FTTH encompasses multiple architectures. The factors that control what
speeds are actually provided are the technology components that are7Deployment of fiber deeper into incumbent telephone networks also raises interestingquestions about how one would implement unbundling, which was originally premised on
unbundling a copper loop running from the central office to the subscriber. Issues such ascolocation become more complicated when the loop terminates at a curbside pedestal orcontrolled environment vault. Colocation is even more complicated if fiber is pushed deep
enough that it reaches to the poletop or even into the home. Aesthetic and practical con-cerns limit the size and number of these remote terminal units, which in term complicatesthe provision of colocation space.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.132BROADBANDinstalled at the end points of the fiberÑthe residence and the serviceproviderÕs point of presence, which may be located at a head end, centraloffice, or remote terminal. The three principal forms of FTTH are these:¥ÒHome runÓ systems
, where there is a separate fiber or fiber pair thatruns all the way from each residence to the central office or other point of
presence. Because there is no sharing of fibers, this scheme has a higher
cost of installation, but offers the highest ultimate performance with the
appropriate system design and terminal equipment and the most flexibil-
ity. Providers can deploy the technology of their choice independent of
other providers (there are no spectrum-sharing issues, as is the case, for
example, with wireless, and no crosstalk problems, as is the case with
DSL). Also, the end-point equipment attached to each fiber (at the central
office and home) can be upgraded independently.¥The Passive Optical Network (PON) architecture, in which a singlefiber runs from a central office to a simple optical divider, called a passive
splitter (hence the ÒpassiveÓ in PON), which may be quite compact, fromwhich individual fibers in turn run to each of a group of homes. The
absence of active electronics in the field and the overall simplicity yield
lower life-cycle costs.8 The PON architecture also avoids the complica-
tions and expense associated with providing robust power at the remote
switching point. Unlike switched fiber or home runs, the format of the
information on the different paths in a PON system is not totally indepen-
dent. This implies that there may be some upgrade strategies that are not
backward-compatible and would require simultaneous upgrades of head-
end and terminal equipment. Just how must flexibility for upgrade and
change is available in a PON system depends on the details of the design.
As part of an effort to reduce costs, an ATM-specific realization of the
PON architecture has been standardized in the ITU (the Full Service Ac-
cess Network or ATM PON standard).¥FTTH systems with fully active (electronic) elements in the path from thecentral office to the residence, in which fiber runs from the central office toone or more stages of remote terminals at which the signals are switched
among fibers that go on to feed individual premises. Two examples of this
approach are switched Ethernet and HFC using active switching.
Switched Ethernet systems are beginning to be used by companies pro-
viding fiber to the home and businesses, extending what is normally a
local area network technology over a metropolitan area. HFC systems of
the future, instead of using a passive splitter, might have a fiber connect-8Paul Shumate provided estimates to the committee of 20 percent lower capital expensesand a $500 life-cycle cost savings.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS133ing to some electronics that serves a small cluster of homes, using fiberinstead of coaxial cable to connect to individual homes. Unlike the other
two architectures, this approach requires special attention to how to
power the remote switching points, especially where reliability require-
ments (and associated regulatory requirements) demand robustness in
the face of power grid failures.These various forms of FTTH have different cost structures and presentdifferent opportunities for incremental upgrade.FTTH is seen by some as the Òholy grailÓ of residential access. From a
technology perspective, it is a high-performance end point, with enor-
mous headroom for future upgrades. As a result, the sentiment is often
expressed that the nation should strive to deploy that solution directly,
without spending time and diverting investment dollars in intermediate
technology of an incremental nature that might, eventually, be obsolete.From a business perspective, a direct move to FTTH raises severalissues. There is a significant investment in telephone and cable infrastruc-
ture that can meet many of todayÕs broadband Internet access needs withmodest incremental expense.Business choices among the alternatives thus hinge on such factors asthe investment horizon and forecasts for bandwidth demand. While both
DSL and HFC can evolve toward higher performance, it is still unclear
whether the pace of improvement in these technologies will continue to
meet customer needs. A second issue is whether the performance benefits
of FTTH over those of other alternatives would be of sufficient value to
consumers to support the prices needed to cover the at least somewhat
higher costs. The familiar case of the recent slowdown in new PC sales
may offer a useful illustration of this point. New PCs are faster and have
a variety of capabilities that older models do not, but it seems, at least at
present, that many buyers find the older models more than adequate for
what they want to do. If this is the case, then some new, compelling set of
applications that requires those capabilities will have to emerge to really
boost PC sales.The total cost of deploying FTTH is, of course, substantial, involvingboth the basic costs associated with wireline infrastructure deployment
and the premium associated with fiber. Areas being newly developed (so-
called green-field areas) offer an especially attractive market for fiber, to
the extent that the additional costs are modest compared with the basic
installation costs of any local access technology. Indeed, the total life-
cycle costs for fiber are believed to be lower than the costs of alternatives
for new installations. When new wireline infrastructure is installed (e.g.,
in a new housing development), FTTH at present costs more to install, by
at least several hundred dollars a home, than alternatives. The total costBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.134BROADBANDincludes the costs of installing the wireline itself (digging trenches, hang-ing on poles, and so on), which are similar in magnitude for any wireline
overbuilder whatever the specific technology.Unlike copper wires or coaxial cable, however, non-home-run fiberarchitectures require that fiber be spliced together. Splices are more time-
consuming than electrical connections and require specialized expertise
and/or complicated equipment to produce. Not surprisingly, this has
been an area of considerable attention, and increasingly sophisticated
techniques and equipment have been entering the market, but costs re-
main higher. The significant improvements made in splicing technology
and techniques over the past few years mean that this is likely to become
less of an issue; moreover, home-run FTTH systems do not require splic-
ing in the access network. In addition, there are increased costs associated
with the terminal equipment (the lasers and other electronics that trans-
mit and receive light signals over the fiber). Costs here exceed those of
terminal equipment for DSL or HFC, in part because of the higher costs
associated with the optoelectronic components and in part simply be-
cause of lower product volumes typical of any new product. There have
been significant improvements in the cost and performance of fiber distri-
bution technology over the last few years as a result of technical advances
and increased deployments in gigabit Ethernet, wavelength division mul-
tiplexing (WDM), passive optical networks, and optical switching, but
there is still a good bit of room for cost improvements in terminal equip-
ment, splicing, and trenching.A small number of new private sector entrants are planning or start-ing to deploy FTTH as an overbuild. For them, becoming a facilities-based
provider would require installing infrastructure in any event. In addition,
the higher performance potential of fiber and, in light of its longevity and
future-proof quality, a total life-cycle cost not dissimilar to that of alterna-
tives, are viewed as giving these entrants a competitive advantage in the
market.Other deployments are taking place in a different economic context;these include, for example, municipal deployment; deployment as a part
of new residential construction; or deployment as an offshoot of fiber
installations for government or business customers. These scenarios alter
the economic calculus and hence the set of technology choices that can be
justified. Once the high up-front costs of laying fiber are paid, the incre-
mental costs for upgrades are predominantly per-subscriber and not 
per-passing. In return for the high initial investment comes a measure of fu-ture-proofing, as the same fiber can provide decades of useful service.
This sort of economic model will make sense for an investor with a long
investment horizon. For instance, it may be attractive to a municipality
that has to float a bond issue for a one-time investment, and then live withBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS135the resulting investment for the life of the bond. The technology alsoallows the municipality to place responsibility on the individual con-
sumer to make any future incremental investments. It might also make
sense for an individual to finance the fiber installation, much as houses
are financed through decades-long mortgages. This economic model
makes much less sense to a corporation seeking to make continuous incre-
mental investments with a goal of showing short-term returns each quar-
ter.In the long run, all the wireline alternatives have the option of con-verging on FTTH, if the market demands it. For those with existing infra-
structure, the issues are the incremental costs of getting there and the
question of whether the intermediate steps are sustainable. For those con-
templating installing new infrastructure, the issue is the cost-effective-
ness of fiber compared with other technology alternatives available to
them, and whether fiber offers them sufficient advantage in the market-
place.PowerlineThe pervasiveness of powerlines has led to consideration of usingthem to provide broadband connectivity to the home and within the home,

with speeds of 20 Mbps and 1 Mbps, respectively, typically envisioned.
Several experiments have been conducted9 and proposals have also been
made to develop both national and international standards for powerline
communications technology. There has been less of a push to use power-
line connectivity in the United States, in part because the U.S. power
distribution system, in which each secondary transformer serves only a
few households (on the order of 5), makes the per-subscriber capital costs
much higher. In contrast, this ratio is on the order of 50 in Europe, reflect-
ing the higher voltages and lower currents in the European distribution
systems; this difference has tempered continual interest in this technol-
ogy on the part of U.S. companies such as Nortel and Intel. From an
economic viewpoint, powerline communications for the last mile com-
petes against well-established multimegabit per second wired and wire-
less options described in this chapter. In addition to questions about the9One example of recent explorations is a 1999 pilot test by the German company VEBA(now part of e.on), which demonstrated a 2-Mbps per customer result in a trial involvingeight households. Results were found to be good enough to suggest more extensive testing
and plans for commercialization (involving AVACON A.G., a regional utility). This serviceuses a device attached at the meter that in turn provides connectivity at each power outletin the household, providing Internet data and telephone and other value-added services.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.136BROADBANDcost-effectiveness of powerline data transmissions, there is an overarchingand long-standing concern about the interference from powerline com-
munications to wireless applications, including amateur radio, home
stereo, and emergency broadcast services. The United Kingdom, for ex-
ample, has discouraged powerline communications for this specific rea-
son. Powerline communications will not experience widespread de-
ployment until questions about acceptable operating frequencies and

interference thresholds are resolved. For in-home networking, powerline
technology has to compete with more mature wirelessÑ802.11b (11 Mbpstoday, with aggregate speeds up to 100 Mbps possible); Ethernet (com-
monly 10 or 100 Mbps, but capable of speeds up to 1 Gbps); and phone
line networking (10 Mbps). These are difficult technical figures to over-
come for the powerline medium, even before considering the cost of de-
ploying it. Intel backed out of the HomePlug system for home distribu-
tion, partly because of an underwhelming nominal aggregate speed of 14
Mbps but mainly because of the potential interference issues mentioned
earlier. In short, powerline communications may yet play some role (last
mile or in-home), but it is too immature compared with alternatives to
characterize its importance or impact, absolute or relative, as a broadband
technology.10Wireline RoadmapHow can wireline providers offer greater bandwidth in the future?Both DSL and cable modem technologies have demonstrated that they
can work in mass deployment and as a business proposition for provid-
ers. The existence of standards and interoperation among equipment from
different vendors is a signal of technology that is mature in the market-
place. The cable industry has a roadmap for performance innovation that
does not depend on substantial technical innovation, but only on the
business decisions to deploy upgrades that have already been tested in
the field. Similarly, the DSL industry has a roadmap for performance
improvements that depends on redesign of the access network to install
remote electronics in order to shorten the length of the copper pairs. In
both cases, the technologies are relatively mature, so the rate of actualÑasopposed to potentialÑperformance improvement will depend mainly on10For more on powerline communications technology, see David Essex, 2000, ÒAre Power-line Nets Finally Ready?Ó MIT Technology Review, June 21, available online at <http://www.technologyreview.com/web/essex/essex062101.asp> and John Borland, 2001,ÒPower Lines Stumble to Market,Ó CNET News.com, March 28, available online at
<http://news.cnet.com/news/0-1004-200-5337770.html?tag=tp_pr>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS137the costs of upgrade, the depreciation cycle of investment, and competi-tion from other providers.Improvements to DSL performance will run up against the crosstalkinterference problem. The current ANSI standard for DSL spectrum man-
agement falls short of addressing the long-term challenge. The problems
will become much more significant as the penetration of DSL grows and
as the higher data rates contemplated in the DSL upgrade pathÑwhichare more sensitive to interferenceÑbegin to be widely implemented. Theconcern, looking forward, is that spectrum management problems will
complicate and curtail installment and progress of DSL if the current line-
level unbundling regime is maintained. On the horizon are methods for
controlling power levels and bandwidth in ways that mitigate the effects
of crosstalk. These include coordination of spectrum use within a carrierÕsDSLAM (this does not, of course, address intercarrier crosstalk) and
advanced signal processing technology that partially compensates for
crosstalk.While there are many unresolved questions about how one wouldactually implement such a processÑespecially given the contentious rela-tionships among incumbent and competitive carriersÑfurther aggregateperformance improvements could be gained through some sort of sys-
temwide coordination of spectrum use. Indications are that with appro-
priate coordination, symmetric data rates at least 3 times faster than the
fastest asymmetric DSL data rates available today would be possible as
fiber moves closer to the home. There are other possible advantages. With
coordination, the DSLAM and modem equipment could be less complex
(and thus less costly), and coordination would permit dynamic partition-
ing of bandwidth to users on demand that exceeds the factor of 3 indi-
cated above. All of this presumes, of course, some change in the rules of
the game. Making improvements in this area will require new regulatory
approaches (e.g., how and whether to unbundle), new management strat-
egies, and new technology.While both HFC and DSL share the same general featureÑan intrin-sic limit to the data rate of the nonfiber portion of their networksÑthelimit is much higher for coax, which offers the cable industry more op-
tions for incremental investment to obtain incremental performance im-
provements. Companies providing data over cable have upgrade road-
maps that illustrate the cost and performance benefits of various options.
In rough terms, the HFC infrastructure is capable of offering the con-
sumer a factor-of-10 improvement over the next 5 yearsÑby decreasingthe number of homes in each cluster and/or increasing the capacity allo-
cated to data servicesÑat relatively low incremental cost. The total capac-ity of a coaxial cable segment, including both the entertainment TV and
data segments, is several gigabits per second. Beyond this point, the po-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.138BROADBANDtential of HFC to scale is not clear. The incremental deployment of fiber inthe HFC infrastructure would imply that the long-term trend would be to
replace the coaxial link to the home with fiber if performance gains in the
range of 100 times current broadband were required. From todayÕs van-tage point, it would be accompanied by the costs and complications asso-
ciated with deploying fiber to the home.While one can confidently predict that fiber will increasingly be founddeeper and deeper within access networks, and can foresee that fiber will
reach an increasing number of households, it is difficult to predict how
fast this will happen. Fiber-to-the-home has labor costs that are not likely
to yield fully to technical innovation, but the option of technical relief of
these costs is very appealing and should justify research in support of
creative proposals.11 The other major cost component is in optical compo-
nentsÑfor example, lasers and modulators. Right now, there are trendstoward both higher performance (seen in wide area fiber optic networks)
and lower cost. The industry speculation is that the costs of lasers for
consumer premises devices can come down markedly when the volume
demand is demonstrated for the specific elements. The presence of very
cheap lasers in CD players and the falling cost of lasers in local area
networks (e.g., gigabit Ethernet) illustrate at least the potential for inex-
pensive components.A significant shift in the costs of fiber would probably require signifi-cant architectural innovation, not just improving the individual technol-
ogy components of present systems. This sort of systems research works
to find new ways of combining components into more cost-effective and
flexible access systems. PON is an example of an architectural idea intro-
duced in the past that had the effect of significantly reducing costs while
offering other deployment advantages (it requires no active electronics
and no power supply between the central office or head end and the
customer premises). Further innovation is possible, and there are several
fiber metropolitan area network companies claiming that they have a
better architecture overall based on shared media access, optical switch-
ing, IP over SONET, or other innovations. The possibility remains that a

sufficiently low cost solution will emerge from this sort of work to make
fiber viable to the residence in the short-to-medium term.It seems quite likely that within the next 5 to 10 years there will besignificant FTTH deployment beyond initial field trials. Fiber is also likely
to become an important technology for new installation and major up-
grade deployments. Whether the amount of fiber deployed will represent
a significant fraction of the installed base during this period is unclear, as11Efforts in this direction include systems that install fiber in existing sewer pipes.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS139it will depend on many factors, both technical and economic. Fiber willcome to each part of the network when a combination of economics,
demand, and capabilities versus alternatives justifies it. The market will
continue to test whether or not that time has come, and will continue to
push the capabilities of other technologies as far as economically practical
as well. Finally, it is worth noting that some caution is in order when
making predictions on this subject. Some 15 years ago, there were claims
by both infrastructure operators and fiber vendors that FTTH was coming
soon, but high costs, uncertain demand, and other factors meant that
these forecasts did not pan out (though green-fields situations are espe-
cially attractive on a total life-cycle cost basis).Wireless OptionsThere are actually many different systems that make use of wirelesscommunication; they are divided here into fixed terrestrial wireless, mo-
bile wireless, fixed satellite service, and wireless local area networking.
Fixed wireless service is being readied for direct competition with DSL
and cable in major markets, while third-generation mobile and wireless
local area networking alternatives aim to deliver services to mobile pro-
fessionals. Over time, these seemingly disparate market segments are
likely to overlap and converge, as portable computing devices and hybrid
personal digital assistant (PDA) cell-phone-type devices proliferate fur-
ther. In the long run, broadband wireless access may be expected to mi-
grate toward the more unique task of supporting connectivity to the grow-
ing proportion of portable end-user devices. The relative roles of these
wireless options will differ depending on market-demand factors, avail-
ability of capital, competitive strategies, and regulatory issues. The focus
in this discussion, however, is on shorter-term prospects for broadband
residential access, which is generally construed to be a fixed service.Fixed Terrestrial WirelessIn contrast to mobile services, fixed wireless services provide connec-tivity from a base station to a stationary point, such as a home.12 Per-
passing costs are more favorable, especially because the cell size can be
made large initially, and then decreased as subscription rates increase. As
a result, fixed wireless will be an attractive option for providers that do12Connectivity may be either to a single gateway within the home (which in turn isconnected through a home network to computers within the home) or directly to individualcomputers within the home. (As home networks become more commonplace, some of whichthemselves use short-range, low-cost wireless links, the former will likely dominate.)Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.140BROADBANDnot own last mile infrastructure in a desired service area to become facili-ties-based competitors. First-generation, proprietary systems providing
data rates of about 1 to 10 Mbps are commercially available. These make
use of spectrum set aside for and thus referred to as local multipoint
distribution service (LMDS) and multipoint multichannel distribution ser-
vice (MMDS). The LMDS spectrum, located above 20 GHz, is allocated for
point-to-point voice, data, or video transmission. MMDS, which uses spec-
trum in 2.1- and 2.5- to 2.7- GHz bands, was traditionally used to provide
so-called wireless cable video services, especially educational/instruc-
tional programming; but a rule change by the FCC in 1998 opened the
door to two-way data service delivery over MMDS frequencies, and the
channels have been made available to wireless providers for broadband
services.13 LMDS, which offers very high data rates but has more limited
range and requires more expensive equipment, is used primarily for high-
speed business services. The longer range and lower frequencies of MMDS
reduce both infrastructure and customer terminal costs, making it suit-
able for competing with DSL and cable in the residential market.Several operators (including Sprint and WorldCom) have been de-ploying first-generation broadband fixed wireless networks (using MMDS
spectrum) with the objective of providing Internet access with speeds of
roughly 1 Mbps to homes and small businesses. In these systems, each
antenna serves a large service area, and line of sight between the antenna
and receiver is required. Coverage in these systems is roughly 50 to 60
percent of potential subscribers, with the exact figure depending on the
topography and foliage density. Customer premises equipment costs are
in the neighborhood of $500 to $1,000. The total cost of a base transceiver
station is roughly $500,000. Assuming typical coverage over about an 8-
to 10-mile radius, the per-passing cost is roughly $2,000 per square mile.
The actual range that can be achieved will differ significantly depending
on the topography, presence of buildings and trees, and so forth. The area
and number of customers served by a base station (and thus the cost per
subscriber) depends on signal range, desired bandwidth per customer,
and channel capacity.As of early 2001, service providers are testing second-generation prod-ucts that use smaller cells to increase system capacity and enhanced sig-
nal processing to enable non-line-of-sight service. These products are ex-13In response to a proposal submitted by participants in the old wireless cable industry,the FCC amended the rules to permit licensees to provide high-speed, two-way services,such as high-speed Internet access, to a variety of users. With wireless cable distribution of
video entertainment programming proving a nonstarter, the commission concluded thattwo-way wireless could produce a continuing stream of leased channel revenues for theeducational licensees (viable competition for hardwire cable was also a consideration).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS141pected to bring the coverage rate up to about 80 to 90 percent. The costper-passing will be considerably higher because the cell sizes are smaller
(3 to 5 miles), but the systems will have considerably higher overall capac-
ity and coverage. Standards for second-generation LMDS and MMDS
have been initiated in standards bodies such as IEEE 802.16. The technol-
ogy of choice for mass-market MMDS is being explored in standards
bodies and the marketplace, but it is likely that a variation of orthogonal
frequency division multiplexing (OFDM) will be adopted at the physical
level. At this point, deployment appears to be gated more by the availabil-
ity of investment capital and the initial cost and performance of the tech-
nology than by the lack of standards, but agreement on a standard would
permit component vendors to drive prices down farther and, in turn,
could prompt more investment.Other technologies (e.g., wideband code-division multiple access[CDMA]-derivative radios operating at several megabits per second, ultra-
wideband radio, and free space laser beams) are also under consideration
for fixed or semimobile high-speed Internet access. As of 2001, there are
several venture-funded companies (e.g., Iospan Wireless, BeamReach, and
IPWireless using radio frequency transmissions, and Terabeam using free
space laser transmissions) developing broadband wireless Internet access
technologies, and some of these activities may lead to significantly im-
proved cost and performance for fixed wireless.Another alternative for broadband wireless is to extend technologiesdeveloped for wireless local area networks, which make use of low-power
transmitters in unlicensed frequency bands. These have improved sub-
stantially in the past few years, with the mass-market IEEE 802.11b stan-
dard supporting speeds up to 11 Mbps in the 2.4-GHz band. Although the
coverage area for wireless LANs is limited to small areas (microcells with
a typical radius of less than several hundred feet, though favorable topog-
raphy and directional antennas can extend this range), rapidly improving
cost-performance makes it a viable option for public services in locations
such as airports, shopping centers, rural communities, and dense urban
areas. Future 802.11 and European Telecommunications Standards Insti-
tute (ETSI) Hiperlan II standards, which are still under development, are
intended for use in the unlicensed 5-GHz band to provide speeds of
roughly 50 Mbps.There has been a dramatic surge of interest in 802.11b wireless localarea network (WLAN) deployment (by individuals, community network-
ing activists, and corporations) during the period of this committeeÕswork. Much of this investment is driven by the fact that WLANs can be
readily deployed at a grass-roots level with modest investment: a few
hundred dollars for a home, increasing to a few thousand dollarsfor a
small office building or campus. This investment provides mutimegabitBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.142BROADBAND(nominally 11 Mbps for recent 802.11b equipment) access capability toboth fixed and mobile computing devices within the coverage area, as
long as there is an appropriate broadband backhaul service such as Ether-
net, HFC, or DSL to connect the access point. Depending on the number
of users sharing the WLAN infrastructure, the costs per user can be rela-
tively low (hundreds of dollars, as compared with thousands of dollars
for other forms of broadband access), so long as average traffic contrib-
uted by each user is not too high. This favorable deployment cost model,
along with the strategic advantage of being able to handle both fixed and
portable devices with the same access network, seems to be driving a
great deal of commercial interest. Most of the activity is of a grass-roots
natureÑbuilding, store, and mall operators, individual homeowners, andcommunity networking activists are installing their own WLANs that
over time could provide fairly ubiquitous, though not uniform, coverage
in populated areas, in a fashion reminiscent of the early deployment of
networking within communities and educational institutions. Note that
the use of WLAN for Òlast 100 metersÓ access does not eliminate the need
for broadband wired access such as HFC, cable, or fiber, which is still
needed for backhaul of traffic. WLAN may help the overall economics of
each of these wired solutions by increasing the end-userÕs utility andfacilitating sharing of the wired link among multiple devices and/or sub-
scribers. This also applies to rural areas where a single T1 connection
along with WLAN access might be more affordable than DSL or cable
service to each home, depending, of course, on the density of the popula-
tion cluster.Scalable deployment of public unlicensed band services poses addi-tional challenges, such as improvements in spectrum etiquette to prevent
destructive interference among multiple operators. The year 2001 also
saw reports of breaches in the default 802.11b security technology that
will require attention. Looking to the long term, one can anticipate that
access could be provided by a heterogeneous mix that combines short-
range wireless access points (using technologies such as 802.11, Bluetooth,
and new higher-speed solutions) with the more traditional DSL/cable/
fiber/fixed wireless solutions.14 This scenario becomes of particular inter-
est if a large base of users comes to value mobile devices.Mobile WirelessWhile fixed wireless is an important near-term broadband access al-ternative, it is generally agreed that over time, wireless technologies and14See, for example, David Leeper, ÒA Long-term View of Short-Range Wireless,Ó 2001,
IEEE Computer, June, pp. 39-44.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS143the spectrum associated with them will be aimed increasingly at commu-nications for next-generation portable and mobile communication and
computing devices rather than at fixed broadband. Users are likely not
only to seek mobile service but also to look for broadband services that
work in a more seamless fashion between home and mobile environ-
ments. As market demand and performance expectations grow, fixed
wireless will be at a performance (or cost-to-performance ratio) disadvan-
tage compared with wireline alternatives in most areas. At the same time,
providers will likely find it more profitable to use spectrum for the mobile
market, which wireline cannot serve. (This presumes regulatory changes
in the licensing rules for that spectrum.) As a result, fixed wireless will
have a long-term niche only in areas of low to medium population den-
sity, where wireline options will remain costly and the bandwidth fea-
sible with fixed wireless is sufficient to meet demand.In the mobile arena, solutions for third-generation (3G) digital cellu-lar systems based on wideband CDMA have been standardized at the
ITU, and early deployments are expected in 2001-2002, particularly in
Japan and Europe. Deployment is expensive, requiring that the provider
install new infrastructure and that the consumer purchase new phones or
other receiver equipment. The 3G standard, which provides a theoretical
2-Mbps user bit-rate, is in practice limited to medium bit-rate services up
to hundreds of kilobits per second due to both system capacity constraints
and realistic wireless channel properties. Thus, 3G mobile, while a major
step forward from current digital cellular systems, is unlikely to meet the
needs of the full range of broadband access requirements that might be
expected in the mobile services arena over the next 5 to 10 years. How-
ever, given that 3G chipsets will be available in the mass market within 1
to 2 years, there are efforts underway to leverage its wideband CDMA
core technology to provide several-megabit fixed wireless access as well.
There are also interim Ò2.5GÓ solutions, going by the names EDGE, GPRS,
and HDR, which provide packet data services at moderate bit-rates (~10
to 100 kbps per user) using available Ò2GÓ digital cellular infrastructure.
Although the speeds of 3G represent a significant improvement oversecond-generation digital cellular in terms of peak bit-rate, the 3G service
appears likely to fall short of consumer expectations for broadband ser-
vices when they reach the marketplace. Despite the hypeÑand their use-fulness for certain applications notwithstandingÑ3G services may turnout not to meet either the capacity or performance needs of truly scalable
mass-market services that deliver several megabits to each mobile device.
This indicates that there will be continued attention to developing broad-
band mobile technology. One interesting possibility is that derivatives of
WLAN technologiesÑ802.11, Hiperlan, or new standardsÑwill be able tosupply high bandwidth more effectively, so long as additional features toBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.144BROADBANDsupport mobility, user registration, and the like are gradually added in. Incontrast to the 3G model, in which large carriers are using government-
allocated spectrum, the WLAN scenario is a bottom-up, small-operator
approach that leverages unlicensed spectrum. There is the potential for
rapid growth owing to the lower capital investment requirements; the
ability to target service to urban areas, airports, and the like and to ex-
pand as needed; and the absence of spectrum licensing costs.SatelliteBroadband local access via satellite provides another wireless alterna-tive. Satellite services have been available for many years, based on geo-
synchronous Earth orbit (GEO) satellites. These satellites have been used
for telephone communications, television distribution, and various mili-
tary applications. Satellite access clearly has significant advantages in
terms of rapid deployment (once a satellite is launched) and national
coverage, but has cost and performance limitations and system capacity
limitations, particularly for uplink traffic. The utility of satelliteÕs broad-cast capabilities (one-way broadband) has already been seen in digital
video via satellite (e.g., direct broadcast satellite [DBS]), which became
pervasive in the 1990s. This has also been leveraged to deliver a mixed-
technology Internet access service (e.g., DirectPC) with satellite downlink
and dial modem uplink. A bidirectional service, in which both the uplink
and the downlink use the satellite, requires the solution of significant
technical problems at the same time that costs are kept low enough to be
attractive to consumers. An example of such a service is the recently
introduced Starband service, which promises a peak rate of 500 kbps
downstream and 150 kbps upstream, using a 2- by 3-foot antenna, at a
current price of $70 per month plus $400 initial investment (figures that
may change as the market grows).While their coverage is very broad, GEO satellite systems possess anumber of limitations. Power constraints and dish size (which is limited
to a roughly 2-ft diameter for mass-market installation) limit the down-
link transmission from a GEO satellite to about 100 to 200 Mbps today
(systems under development for launch in the 2003 time frame are being
designed to offer at least 400 Mbps downstream). Statistical multiplexing
effects permit this capacity to be shared over more users than is suggested
by simply dividing this number by the peak load per user, but the total
number of customers that can be served per satellite is nonetheless lim-
ited. While other performance characteristics of satellites have increased
significantly (along MooreÕs law-like curves), the efficiency of power pan-els on satellites has not increased substantially over recent decades. New
frequency bands can also be used to increase system capacity given aBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS145finite number of orbital spots. Spot beams and on-board switching wouldprovide roughly a factor-of-10 improvement in capacity at the expense of
reduced geographic coverage and a heavier and costlier payload. There
have been several attempts to develop commercial satellites of this sort
earlier, but there seem to be various technical and cost problems in each
case.Even though GEO satellites may have a limited total capacity forbroadband on a national scale, they may occupy a long-term market niche
if the demand is restricted to a small, bounded set of (mostly rural) sub-
scribers. In this respect, the GEO systems clearly provide an illustration
that the broadband market will be served by a range of technology op-
tions, not a single technology winner.GEO satellite systems also have a high round-trip transmission delay.The propagation time (speed of light) up to the satellite and back is about
250 milliseconds (ms), so the round-trip delay is 500 ms. This compares
with a terrestrial cross-country round-trip delay over a fiber link of be-
tween 75 and 100 ms. This has caused some to conclude that GEO satel-
lites are useless for data purposes. In fact, whether this delay matters
depends on the application being used. For Web access the delay may be
noticeable, but it does not seriously degrade the experience so long as the
end-node software is properly set up. For other applications, the satellite
delay is a more serious issue. For Internet telephony, the long delays
cause a real degradation in usability, since there are well-known human-
factors issues that arise when the round-trip delay in a conversation ap-
proaches 200 ms.An alternative that has received a great deal of attention over the lastseveral years is to use low Earth orbit (LEO) satellites, which in contrast to
GEO satellites do not occupy a constant position in an assigned orbital
slot, and to rely on multiple satellites to provide coverage. LEO satellite
proponents claim that power limitations are less serious than those with
GEO satellites, though both types of system are constrained by power
considerations. LEO satellite technology, while challenging, can be
fielded, as the pioneering Iridium and Globalstar deployments have dem-
onstrated. LEO satellite deployment for broadband data services requires
the solution of additional difficult technical problems, such as antennas
that can track a moving satellite at a price point suited for a consumer.However, the feasibility of LEO satellites for mass-market broadbandaccess is constrained more by economic considerations than the technol-
ogy challenges. A LEO satellite system requires the launching of many
satellites, because in their low Earth orbit, the satellites are in rapid mo-
tion overhead, and there must be enough of them that one is always in
range. This means that the system has a very high initial cost to build and
launch, which in turn implies that there must be a significant user pool toBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.146BROADBANDjustify the investment. (Even if the per-passing cost is low, there must bea sufficient total customer base.) Satellite-based solutions must also com-
pete with terrestrial networks as they expand to reach more customers.15Wireless RoadmapWhile wireless systems come in multiple flavors, some high-levelobservations are broadly applicable. First, a variety of technology options
are possible depending on the planned customer density. Systems that
have very few towers and more expensive residential equipment have
lower per-passing costs and higher per-subscriber costs, which may pro-
vide a more favorable business case for initial deployment. Installing new
antennas on existing cellular towers allows the leveraging of past invest-
ment in towers and related site costs. Thus, for wireless there is at least to
some extent a path that provides incremental performance improvement
for incremental cost. Because little or no wireline infrastructure needs to
be installed, deployment can proceed comparatively rapidly, but the ca-
pacity for adding more customers is limited.System capacity is limited by the amount of radio spectrum available,which depends on the total amount of radio spectrum suitable (in terms
of its propagation characteristics) for broadbandÑthe fraction of that spec-trum which is allocated through government spectrum-licensing policies
to broadband servicesÑand the extent to which clever system design canincrease the performance obtainable from a given amount of bandwidth.One option for increasing performance is to make cell size evensmaller, so that the same frequencies can be reused in more locations (a
strategy called spatial reuse). The need to deploy more transceivers (and
install wireline to connect them to the providerÕs network) makes theseimprovements costly, so that systems with very small cell sizes have costs,
dominated by labor costs that start to approach those of wireline systems.The relative immaturity of wireless broadband technologies com-
pared with wireline alternatives gives reason to believe that innovative
research will yield significant improvements in performance. The total
spectrum available for broadband services is limited by the amount of
spectrum suitable for broadband. MooreÕs law decreases in the cost ofprocessing power that can be inserted into broadband transceivers permit15This economic challenge has been seen in the case of satellite voice services, whereterrestrial cellular voice service, which is much cheaper and requires much smaller hand-sets, was deployed on a more widespread basis than was contemplated when the initialIridium business plans were formulated. If terrestrial broadband services discussed above
are deployed over enough of the world during the time it takes to design and launch a LEOsatellite broadband service, the pool of underserved users with the wealth to purchase thisnew satellite service may be too small to recover the high up-front cost.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS147use of more complex coding schemes, which permit increased data ratesto be affordable. Some of the next-generation technologies under active
consideration make use of increased signal processing to permit non-line-
of-sight operation, which is important to increasing both the number of
viable markets and the fraction of customers that can be served. More
processing power may also permit more of the base-station functions to
be implemented in software, which would permit new services to be
introduced without a hardware upgrade. Another option is to exploit
new wireless innovations such as space-time processing techniques with
multiple antennas (so-called multiple-in, multiple-out, or MIMO, ap-
proaches) or smart antenna beam steering approaches, which hold the
promise of roughly a factor-of-10 improvement in per-user throughput.
These approaches rely heavily on improvements in the processing power
of application-specific integrated circuits (ASICs) or digital signal proces-
sors (DSPs) that enable the requisite signal processing to be performed in
real time in affordable hardware.Even so, the wireless roadmap does not seem to offer performanceimprovements of the same magnitude as are possible with wireline. Even
in the best case, wireless cannot match the ultimate transmission capacity
of wire or fiberÑthough it could surpass the performance of todayÕs de-ployed DSL or cable systems. And in contrast to wireline, wireless does not
have as clear a roadmap regarding the 5-year potential of further re-
search. Wireless will, however, be an important technology option in view
of several potential advantages, which include rapid deployment, lower
initial capital investment, and the ability to serve portable or mobile de-
vices.Over time, as wireline facilities are built out, it is quite possible thatthe wireless spectrum used by fixed service will, for the most part, be
shifted to mobile uses. In this scenario, fixed wireless would shift from
playing a role as a facilities-based alternative in even densely populated
areas to one where it provides niche service in lower-density and remote
areas, particularly in newly developed areas where it complements wire-
line solutions by enabling niche services.Note that even though todayÕs 3G technology may be immature, it isrelatively safe to predict that there will be a growing demand for broad-
band wireless service to portable and mobile devices. This is because of
fundamental trends toward smaller personal computing and communica-
tion devices (e.g., laptops, PDAs, and cellphones) that in the long term are
likely to account for the majority of end-user devices, in contrast to the
fast-growing minority that they represent today. Once tetherless comput-
ing devices become ubiqitous, todayÕs PC-centric broadband access net-work (HFC, DSL, and so on) will have to evolve toward hybrid wired and
wireless networks in which the Òlast mile,Ó Òlast 100 m,Ó or even 
Òlast 10Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.148BROADBANDmÓ are mostly wireless. The cost and performance of broadband wirelessaccess networks will thus be crucial to the userÕs overall experience.In that context, it is worth noting that there are significant challengesassociated with delivering true broadband services, as defined in this
report, to mobile devices. For example, a 5-MHz chunk of 3G spectrum
can support only about 10 simultaneous broadband users per cell, a num-
ber that has to increase by orders of magnitude to make the service viable
beyond narrowband uses. Research and development (R&D) challenges
faced by developers of Ò4GÓ wireless standards include higher speeds (on
the order of 1 to 10 Mbps), maintenance of service quality under mobile
fading conditions, integration of mobile and fixed network architectures,
and greater spectral efficiency, capacity, and scalability. There has been
recent interest in mobile Web access, media streaming applications aimed
at portable devices, and the like, but consumer demand and the shape of
the market are still evolving. Significant R&D investment will be needed
to reach the scalability and cost and performance levels appropriate for
ubiquitous mobile/portable broadband wireless deployment. Supportive
FCC spectrum regulation policies that encourage efficient spectrum us-
age and easier access to new spectrum, rapid technology evolution, and
market competition will also be needed to drive this important scenario
forward.The Diverse Technology LandscapeThe different technology optionsÑincluding HFC, DSL, fiber, wire-less, and satelliteÑare different in detail. Some have higher delay, somehave lower overall bandwidth, some may have higher prices, and so on.
Different technology can be deployed to advantage in different circum-
stances. In dense urban and suburban areas, the present generation of
wireline broadbandÑHFC and DSLÑis being utilized successfully to-day. Fiber will be used in access networks wherever a combination of
economics, demand, and capabilities (compared with alternatives, includ-
ing the infrastructure already in place) justifies it. Fixed wireless is being
used to support market entry by providers that do not own or have access
to existing wireline assets. In less densely populated areas, fixed wireless
may offer a longer-term solution for broadband access. Finally, in the
most remote areas, a small percentage of the U.S. population may best be
served by satellite where the very high fixed cost of construction and
launching satellites is offset by the very low per-passing costs, given the
enormous area that a satellite system can serve. One of the consequences
one may have to accept for living in rural areas is that the available broad-
band service has some particular characteristics, such as higher delay and
greater cost per unit of bandwidth. This may be an issue for certain appli-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS149cations, but one should look at this as just one consequence of technologydiversity, not as a fatal flaw of one or another technology.The market will continue to test whether or not the time has come todeploy fiber, and it will also continue to push the capabilities of other
technologies as far as economically practical. In different parts of the
nation (and the world), with different demographics and population dis-
tribution, these different technology options will play out in a different
mix, but each will play a role in the diverse world of today.LAYERING AND UNBUNDLINGThis chapter devotes considerable attention above to the characteris-tics of different technology options for broadband access. But consumers
do not normally care about the communications technology for its own
sake; they care about the services that can be delivered over itÑInternetapplications (Web, audio, video), entertainment television, and so on.
Hiding these details and separating the underlying communications tech-
nologies and the applications and services accessible to end users are
accomplished through the engineering practice of layering. Communica-
tion systems are often designed (and described) in a layered fashion: that
is, with a physical layer at the bottom that differs, depending on the
particular communications technology chosen; a top layer that represents
the specific applications that users run over the network; and some inter-
mediate layers that help organize the engineering of the overall system.As a simple example, consider the problem of sharing the total capac-ity of a cable system among a number of users and applications. At the
physical layer is a coaxial cable capable of carrying radio frequency sig-
nals. The capacity of the cable system is divided into a number of chan-
nels of 6-MHz bandwidth, each capable of carrying a TV channel or other
information. At the layer above that, one or another form of content is
assigned to each frequency. Most channels are used today to carry a single
TV signal, but channels can also be used for the Internet or for telephone
service. Also, using new digital representations, multiple TV channels can
now be carried in a single 6-MHz channel.The InternetÕs design is layered so that it works over a wide range ofcommunications technologies, including all of the wireline and wireless
broadband technologies discussed above. Consider Internet transmission
over a cable system. First, one or more physical channels are assigned to
Internet transmission. Then, at the lowest layer of the InternetÕs design,the data to be transmitted over an individual cable system channel are
divided into a sequence of small messages called packets. Multiple usersshare a single channel by sending their own packets one after another.
Finally, the packets used by each user are assigned to one or anotherBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.150BROADBANDÒapplication,Ó such as Web access, e-mail, or streaming audio. So the
layers of sharing for the Internet over cable are as follows: a physical
cable, which is divided into channels, then divided into packets, which
are each in turn assigned to a particular user and application.To the user of the Internet, the details of layering are largely irrel-evant. But the detail does matter in the debate about unbundling. The
term ÒunbundlingÓ is used to describe the situation in which the owner of
physical facilities is required to make some portion of that resource avail-
able to a competitor. Unbundling of the incumbent local telephone com-
pany facilities is required by the Telecommunications Act of 1996. There
are two distinct ways of unbundling the local loop: physically and logi-
cally.In the case of the copper infrastructure of the telephone company, oneform of unbundling is physical, where an actual copper pair is assigned to
a competitor. In this way, the competitor has direct access to the electronic
signals being carried over the wire (or to the light carried over a fiber) and
can adopt whatever transmission scheme it chooses. For use of the loop,
the competitor pays the rate negotiated with the incumbent or, in the
absence of a negotiated agreement, the rate established by regulators
through arbitration, and in turn directly implements the service and bills
the customer. Physical-layer unbundling requires that the competitor have
the ability to colocate equipment and upstream connectivity at the net-
work termination point of the loop (typically but not exclusively at the
central office).Physical-layer unbundling offers several potential advantages for thecompetitor. First, it provides the competitor the freedom to select the type
of transmission technology it chooses to implement over the copper loop,
independent of whatever decisions the incumbent may make, permitting
the competitor to compete with the incumbent on the basis of a variety of
attributes, including speed, quality, and maximum loop length. Second,
in the case of a loop running from the central office to the subscriber, it is
in some sense a well-defined, easily separable network element.Physical-layer unbundling may also impair the ultimate performanceof the copper plant. While it holds true for voice signals, the assumption
that copper loops are fully separable is not correct for high-speed data
transmission using DSL because of crosstalk among wires within the tele-
phone plant. This means that ultimate performance and reach are ham-
pered because corrective measuresÑsuch as coordinated assignment ofcopper pairs and coordination of transmitted signals among pairsÑcan-not be implemented if competitors are left free to implement the technol-
ogy of their choosing.Unbundling also raises new issues when applied to new facilities. Asan initial matter, an unbundling obligation may deter an incumbent localBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS151exchange carrier (ILEC) from pushing fiber farther into the neighbor-hood. In addition, plant access on the network end of the loop today is
generally at the central office. To improve the performance and reach of
DSL service, it is natural to deploy fiber deeper into the telephone net-
work. Then the copper pair terminates at a remote terminal, which may
be a curbside pedestal or even a small box on a telephone pole. Issues
raised in this context include these:¥Unbundling at remote terminals is problematical because of spacelimitations and because the relatively small number of subscriber lines
terminated at each remote terminal make colocation and interconnection
(linking the copper loop to the competitorÕs network) more difficult toachieve here than was the case at the central office.¥As fiber is pushed deeper into the network, the copper loops be-come shorter, each remote terminal serves fewer customers, and (if only
the copper is unbundled) each provider would need to separately provi-
sion fiber to interconnect at the remote terminal. The fiber running to the
terminals might also be unbundled, which would require some sort of
time-division multiplexing (i.e., each provider has its own time slots) or
wavelength division multiplexing (each provider has its own wave-
lengths) of the incumbent-owned fiber.¥Continuation of physical-layer unbundling requirements compli-cates establishment of technology-neutral rules because unbundling rules
must take into account the particular details of each new communications
technology used by incumbents.The other unbundling option is logicalÑabove the physical layer.Higher-layer services concerned with transmitting bits are implemented
in some fashion on top of protocols concerned with transmitting electrical
signals across the wire, which means that they can be implemented inde-
pendent of the particulars of the physical-layer connection used to pro-
vide the higher-level service. That is, a competitor need not control the
actual signals running over the wires if it can implement its service using
bit transport capabilities provided by the incumbent. With logical-layer
unbundling, the incumbent specifies the customer-premises equipment
and operates the termination equipment.Logical-layer unbundling offers several advantages. Colocation re-quirements are confined to those necessary for the competitor to intercon-
nect with the incumbentÕs network. Another advantage to logical-layerunbundling is that it may be easier to verify service-level agreements
between the incumbent and competing service provider, because data on
logical-layer service (throughput, quality of service, and so on) can be
compiled more readily. Finally, with logical-layer unbundling, one avoidsBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.152BROADBANDmuch of the argument over such hard-to-measure issues as whether in-cumbent personnel Òmade life difficultÓ for CLEC employees while in-
stalling equipment or agreeing on a frequency plan.A principal disadvantage of logical-layer unbundling for the com-petitor is that the performance characteristics of the link implemented by
the incumbent may restrict the types of services the competitor may offer,
and limits the competitorÕs ability to differentiate itself from the incum-bent. While the motivation of incumbents is certainly a matter of specula-
tion and debate, it is often suggested that one reason incumbents have
favored the lower-speed, asymmetric DSL technology is that symmetrical
high-speed DSL service for business customers could undercut profits on
more expensive T1 data service. Incumbents might also select a transmis-
sion technology that accommodates the typical copper loop but which
may not be optimal for subscribers with longer loops. A competitor re-
stricted to logical-layer unbundling cannot provide a symmetrical service
or otherwise compete with the incumbent by offering higher performance
than the incumbentÕs system permits.The nature of the local access technology affects what unbundlingoptions are viable. In the case of the cable infrastructure, one could pro-
pose that different frequencies could be allocated to different providers,
or that different providers could be assigned a share of the packets being
sent in a single frequency, and so on. In practice, allocation schemes have
not proved workable, and cable open access is being implemented at the
packet level. So the fact that there are different ways of sharing at differ-
ent layers, and that different technologies have different layering struc-
ture, makes the debate about unbundling complex.ECONOMICS OF INFRASTRUCTURE INVESTMENTLike any other business, revenue, at least in the long term, must besufficient for a broadband service provider to be profitable (or at least to
break even, in the case of a public sector enterprise). As the previous
discussion suggests, different technologies have different cost structures
that shape their attractiveness in different market segments. At the same
time, uncertainty about demand for broadband, consumer willingness to
pay, and the interaction of these factors with different business models
shapes investment in broadband deployment.Understanding CostsBroadband deployment costs fall into two broad categories: fixed (orper-passing costs), which are roughly independent of the number of sub-
scribers, and variable (or per-subscriber) costs. Fixed costs include thoseBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS153of upgrading or installing wireline infrastructure within the neighbor-hood and installing or upgrading central office or head-end equipment.
For wireless, the costs of acquiring wireless spectrum licenses are another
per-passing cost. The most significant variable costs are the per-subscriber
capital costs, including line cards, customer-premises equipment, and the
costs of upgrading or installing connections to individual premises. Other
variable costs include installation at the customer premises (which drives
shifts to customer-installed solutions) and customer support and mainte-
nance. Providing upstream connectivity involves both fixed costs, such as
installation of regional or national transport links, and variable costs asso-
ciated with provisioning regional and national connectivity to support
the traffic load imposed by customers.These costs are greatly shaped by density and dispersion. Where newwireline infrastructure is installed, more remote or sparsely populated
areas will have significantly higher per-passing costs, reflecting per-mile
constructions costs, that make investment riskier, and the lower per-pass-
ing costs of satellite or other wireless systems will be more attractive.
Each particular circumstance will involve its own set of cost trade-offs,
however. For instance, because installing remote terminal equipment im-
poses substantial costs, home-run fiber to the premises could turn out to
be cheaper than a fiber-to-the-cabinet strategy in some rural cases.Take-Rate TyrannyPerhaps the most important implication of per-passing costs is theÒtake-rate tyrannyÓ that dominates investment decisions. Because costs
are dominated by the dollars-per-mile cost of installation, investment in
wireline infrastructure has a cost structure in which most of the cost is
determined by the number of houses passed, and a minority of the costs is
determined by the number of subscribers. (Because they lend themselves
to a strategy in which the cell size can be scaled to the take-rate, wireless
systems can have an advantage, though the cost of spectrum must also be
factored in.)A very simplified cost model indicates the general shape of the finan-cial dilemma facing those who invest in broadband infrastructure. If there
are two providers instead of oneÑassuming no differentiation betweenthe products, no first-mover advantage, and that costs are per-passingÑthe costs for each are unchanged but the revenues are halved. As a very
rough example, if a provider makes an incremental investment in the
distribution infrastructure that has a cost of $200 per passing and must
recover this investment in 3 years, this is approximately $5 per month per
passing. If the provider has the whole market and 50 percent of the homesBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.154BROADBANDare subscribers, this would imply that $10 per month of the per-subscriberpayment would have to be allocated for return on this investment. If,
however, there were two providers and each held half of the total 50
percent market share, then each provider would have to collect $20 per
month from each subscriber as a return on this investment, in a market
where the typical consumer payment is just $40 per month. More gener-
ally, when the market is split among multiple providers, some cost and
revenue models for residential broadband become unprofitable. This also
amplifies the advantages held by a provider that can make incremental
upgrades to existing wireline infrastructure (the advantage depends on
the cost of any required upgrades) over a de novo facilities-based com-
petitor.As a result of the take-rate impact on per-subscriber costs, the pro-vider with the highest penetration rate may have a substantial cost advan-
tage over its competitors if per-passing costs are significant. According to
rough figures supplied to the committee,16 the present per-passing costs
to install fiber-to-the-curb are as follows: $150 per passing if only voice is
offered, an additional $150 per passing if data service is provided as well,
plus $300 per passing to provide video. Fiber cable installation adds an-
other $350 to $400 per passing if done aerially and $700 to $800 per home
passed if buried. Given these figures, consider two providers serving a
local market, each offering voice, data, and video. Suppose each passes all
homes, that 50 percent of homes subscribe in aggregate, and that one
provider, the incumbent, serves 60 percent of all broadband homes, while
a more recent entrant serves 40 percent of broadband homes. Both pro-
viders use aerial installations that cost $400 per passing. Then per-sub-
scriber costs for the incumbent would be $1,000/0.30 = $3,333 (plus sub-
scriber-specific installation costs), while for the entrant per-subscriber
costs would be $1000/0.20 = $5,000 (plus subscriber-specific installation
costs). The entrantÕs costs would be 50 percent greater than the incum-bentÕs. This type of relationship means that competition that truly droveprices to costs would eliminate all but one firm unless markets were
evenly divided among competitors or competitors offered differentiated
services that appealed to different subsets of subscribers. The risks for
entrants inherent in this type of relationship are obvious, especially if
subscriptions are at all sticky (e.g., where customer loyalty or switching
costs are significant). Unless competitors can find ways to substantially
differentiate their services, entry may well be risky and vigorous compe-
tition difficult to sustain.16From Mark MacDonald at Marconi.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS155Paying for BroadbandThe economic challenge of building and upgrading broadband infra-structure has proved daunting. Cast simply in terms of consumer willing-
ness to pay and ability to attract investment in terms of that demand, it
may be difficult to sustain high growth in penetration, upgrades, and new
facilities construction. But broadband involves more players than simply
the consumer and the infrastructure owner, and there are various ways in
which the costs could be allocated among the various players. Other in-
dustries that share costs include telephony, in which different types of
customers (e.g., residential versus business) pay different prices; com-
mercial broadcast radio and television, in which consumers are sold as
audiences to advertisers; and newspaper publishing, in which the sub-
scription price is only a fraction of the cost of production and distribution.
Such arrangements have been instrumental in building other communi-
cations infrastructures. Complex arrangements among multiple parties
are possible, as is seen in broadcasting, where both costs and revenue can
be shared between broadcast networks and local affiliates. The critical
role of content suggests that issues related to copyright protection of digi-
tal content will be intertwined with broadband for some time to come.Because broadband is a service capable of supporting each of thesetypes of services and many new ones as well, there are potentially many
different options for cost sharing. Figure 4.5 depicts a cluster of other
players that surround the consumer and broadband infrastructure
builder. Notably, broadband subscribers generally are interested in a wide
range of content and applications that are not provided directly by the
broadband provider itselfÑtoday this is largely the universe of contentand services available through the Web. These services have been sup-
ported through a combination of e-commerce, transaction and subscrip-
tion charges, and advertising (both direct, in the form of banner ads and
the like, and indirect, as when a Web site is used as to draw the user into
other media channels). One opportunityÑand challengeÑis to find waysof better aligning the economic interests of content or applications pro-
viders and infrastructure owners in order to share the costs of the access
link with the end users. Another is to explore how government incentives
or contributions from employers interested in various flavors of tele-
commuting or employee education could contribute to the overall invest-
ment required. New approaches to financing broadband include home-
builders that include fiber connections in the price of the home (and can
then promote the homes as broadband-ready) and municipalities that
provide mechanisms for amortizing the investment over a relatively long
time period.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.156BROADBANDFocus on the ConsumerThe factors discussed in the previous section notwithstanding, theconsumer is the pivot around which all of the economic issues swing.
Without consumer demand and a (somewhat) predictable willingness to
pay (or evidence that advertising will be a large source of revenue), there
is no market. Evidence from early deployment demonstrates demand.
The national average penetration (somewhat more than 8 percent as of
summer 2001) reflects and masks an uneven pace of deployment. In lo-
calities where the service has been available for a reasonable time, cableFIGURE 4.5Paying for broadband.
ConsumersTelecom.InfrastructureBuilders/OperatorsContent andApplicationProvidersAdvertisersEmployers(telework andeducation)Federal, State,LocalGovernment(incentives)BuildingOwners,DevelopersBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS157industry reports on markets that have had cable modem service availablefor several years suggest considerable demand.17Although the committee is not aware of definitive studies of con-sumer willingness to pay for broadband (and the notion proposed in the
past, that consumer willingness to pay for entertainment and/or commu-
nications is a fixed percentage of income, is generally discounted by
economists today), the general shape of the market for communications,
entertainment content, and information technology is beginning to
emerge. Over 50 percent of homes in America have some sort of PC, with
prices that averaged near $2,000 in recent years, and which are now drop-
ping below $1,000 for lower-end machines, illustrating that many con-
sumers are willing to make a significant investment in computing hard-
ware and software. In rough terms, a typical $1,200 home computer
replaced after 4 years costs around $25 per month.A majority of the homes that have PCs are going online and connect-ing to the Internet, and it is a reasonable projection that only a very small
fraction of machines will remain offline in the coming years. Using the
primary residence phone line, and purchasing a somewhat more limited
dial-up Internet service, the price approaches the $10 per month (provid-
ers have also experimented with service and PCs that are provided free,
so long as the consumer will allow advertisements to be displayed during
network sessions, although recent reports from this market segment put
in question the long-term viability of this approach). The entry price to-
day for broadband is not dramatically different from that for high-end
dial-up service. A separate phone line costs as much as $20 per month,
and unlimited-usage dial-up Internet service generally runs $20 or more
per month. Of course, the market offers a range of price and performance
points from which the consumer can pick. At the high-end, high-speed
DSL can cost up to several hundred dollars per month, and business-
oriented cable services are offered at a premium over the basic service.The total consumer expenditure for such a computer plus basic broad-band service is potentially as much as $90 per month, of which the Internet

provider can expect to extract less than half. From this revenue base a
business must be constructed. If 100 million homes were to purchase
broadband service at $50 per month, this would result in total annual
revenues to broadband Internet providers of more than $50 billion, which
is similar in magnitude to current consumer expenditures on long-dis-
tance services.17For example, information supplied to the committee by Time Warner Cable is that take-rates have reached 17.5 percent of subscribers in Boston, Massachusetts, and 25 percent ofsubscribers in Portland, Maine.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.158BROADBANDOne question that the market has not yet explored is whether theconsumer would make a significant capital investment, similar to the
$1,000 to $2,000 that a computer costs today, as part of obtaining Internet
service. For example, if there were a home-run system with fiber running
to the residence (making it a relatively future-proof investment), but the
consumer had to activate that fiber by purchasing the end-point equip-
ment, would this be an attractive option if the equipment costs were
comparable? Would residents be willing to finance the capital costs of
installing that fiber in the first place? While there is no hard evidence,
wealthier consumers, who have demonstrated a willingness to make pur-
chases such as multiple upscale multimedia PCs and expensive consumer
electronics, might well be willing to make such investments, and some
residential developers have opted to include fiber.The Pace of InvestmentThe rapid evolution of some aspects of the Internet can lead observersinto thinking that if something does not happen within 18 months, it will
not happen. But the phenomena associated with deployment cycles mea-
sured in months have generally been in the non-capital-intensive soft-
ware arena. The cost of entirely new broadband infrastructureÑrewiringto provide fiber-to-the-home to all of the roughly 100 million U.S. house-
holdsÑwould be some $100 billion, reflecting in considerable part con-struction costs that are not amenable to dramatic cost reductions. Even for
cable and DSL, for which delivering broadband is a matter of upgrading
existing infrastructure, simple economics gates the pace of deployment.
For both new builds and incremental improvements, an accelerated pace
of deployment and installation would bring with it an increased per-
household cost. Some broadband deployment will be accomplished as
part of the conventional replacement and upgrade cycles associated with
telephone and cable systems. In some cases, this process will have dra-
matic effectsÑtwo examples are HFC replacement of all-coaxial cableplants and aerial replacement of copper with fiber as part of a complete
rehabilitation of old telephone plantÑbut in many others cases, the im-provements will be incremental. To accelerate beyond this pace means
increasing and training an ever-larger workforce devoted to this task. As
more new people are employed for this purpose, people with increasingly
higher wages in their current jobs will have to be attracted away from
those jobs. Similar considerations apply to the materials and manufactur-
ing resources needed to make the equipment that is needed.The investment rate also depends critically on the perspective andtime horizon of the would-be investor. For an owner of existing facili-
tiesÑthe incumbent local exchange carriers and cable multiple systemBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS159operatorsÑrealistic investment is incremental, builds on the installedbase, and must provide return on a relatively short timescale. The ten-
dency to make incremental upgrades to existing telephone and cable

plants reflects the view that a replacement of the infrastructure (such as
with fiber) would necessitate installation costs that can be avoided by
opting to upgrade. The perception is that users would not be willing to
pay enough for the added functionality that might be achieved with an
all-fiber replacement to offset the extra costs of all-new installation.
Changes in either costs or perceived willingness to pay could, of course,
shift the investment strategy.Once the provider has a broadband-capable system, it will only haveincentives to spend enough on upgrades to continue to attract subscribers
and retain existing customers by providing a sufficiently valuable service.
Where facilities-based competition exists, these efforts to attract and re-
tain customers will help drive service-performance upgrades. From this
perspective, the level of investment associated with building entirely new
infrastructure is very difficult for the incumbents to justify. Viewing the
incumbentÕs incentives to invest in upgrades from the perspective of thetwo broadband definitions provided above, investment to meet definition
1 will be easier than that to meet definition 2. That is, it is easier to justify
spending so that the local access link supports todayÕs applications, whileit is harder to justify spending enough to be in front of the demand so as
to stimulate new applications.Two types of nonincumbent investor have also entered the broad-band market, tapping into venture capital that seeks significant returnsÑand generally seeks a faster investment pace. One is the competitive local
exchange carrier, which obtains access to incumbent local exchange car-
rier facilitiesÑprimarily colocation space in central offices and the copperloops that run from the central office to the subscriberÑto provide broad-band using DSL. The other is the overbuilder, which seeks to gain entry
into a new market by building new facilities, most commonly hybrid fiber
coax for residential subscribers, but also fiber-to-the-premises and terres-
trial wireless. Satellite broadband providers in essence overbuild the en-
tire country, though with the capacity to serve only a fraction of the total
number of households. The 2000-2001 drying up of Internet-related ven-
ture capital has presented an obstacle to continued deployment, and the
CLECs have also reported obstacles in coordinating activities with the
ILECs that control the facilities they depend on.Because public sector infrastructure investment generally is based ona long-term perspective, public sector efforts could both complement and
stimulate private sector efforts. The key segment of the public sector for
such investment is likely to be subfederal (state, local, regional), though
the federal sector can provide incentives for these as well as private sectorBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.160BROADBANDinvestment. But decision making for such investments is not a simplematter, and, if present trends are any indication, such investments will be
confined to those locales that project the greatest returns from accelerated
access to broadband or possess a greater inclination for a public sector
role in entrepreneurship.Investment, Risk Taking, and TimelinesThe myth of the ÒInternet year,Ó by analogy to a 
Òdog year,Ó is well
known. Where the Internet is concerned, people have been conditioned to
expect 1-year product cycles, startups that go public in 18 months, and
similar miracles of instant change. The 2000-2001 downturn in Internet
and other computing and communications stocks dampened but did not
eliminate such expectations. In fact, some things do happen very rapidly
in the InternetÑthe rise of Napster is a frequently noted example. Theseevents are characterized by the relatively small investments required to
launch them. Software can diffuse rapidly once conceived and coded. But
this should not fool the observer into thinking that all Internet innovation
happens on this timescale.As noted earlier, broadband infrastructure buildout will be a capital-intensive activity. In rough figures, a modest upgrade that costs $200 per
passing would cost $20 billion to reach all of the approximately 100 mil-
lion homes in the United States. Broadband deployment to households is
an extremely expensive transformation of the telecommunications indus-
try, second only to the total investment in long-haul fiber in recent years.
In light of these costs, the availability of investment capital, be it private
sector or otherwise, imposes a crucial constraint on broadband deploy-
mentÑit is very unlikely that there will be a dramatic one-time, nation-wide replacement of todayÕs facilities with a new generation of technol-ogy. Instead, new technology will appear piecemeal, in new developments
and overbuild situations. Old technology will be upgraded and enhanced;
a mix of old, evolving, and new should be anticipated. Whether national
deployment takes the form of upgrades or new infrastructure, the rel-
evant timescale will be Òold fashionedÓÑyears, not days or months.As a consequence, observers who are conditioned to the rapid pace ofsoftware innovation may well lose patience and assume that deployment
efforts are doomed to failÑor that policies are not workingÑsimply be-cause deployment did not occur instantly. One should not conclude that
there is something wrongÑthat something needs fixingÑwhen the onlyissue is incorrectly anticipating faster deployment.Much private sector investment, especially by existing firms, is incre-mental, with additional capital made available as investments in prior
quarters show acceptable payoff. As a result, the technological approachBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS161chosen by an incumbent is likely to make use of existing equipment andplant, and the deployment strategy must be amenable to incremental
upgrades. The evolution of cable systems is a good example. The previ-
ous generation of one-way cable systems is in the process of being up-
graded to hybrid fiber coax systems, and these in turn are being upgraded
to provide two-way capability, greater downstream capacity, and packet
transport capabilities. The various incumbents now in the broadband
marketplace have very different technology and business pastsÑthe tele-communications providers selling voice service over copper, the cable
television companies using coaxial cable to deliver video, the cellular
companies constructing towers for point-to-point wireless telephony, and
so forth, and each will evolve to support broadband by making incremen-
tal improvements to its respective technologies and infrastructure. In-
cumbents seeking to limit regulatorsÕ ability to demand unbundling have
an incentive to avoid technologies that facilitate such unbundling.Because they exist to take greater risks but possibly provide muchgreater returns by identifying new promising areas, venture capitalists
seek to invest in opportunities that offer high payoff, not incremental
improvements. So it is no surprise that the more mature technologies,
such as cable and DSL, have attracted relatively little venture capital in
recent years. Another investment consideration for the venture capitalist
is the total available market, with niche markets being much less attrac-
tive than markets that have the potential to grow very large. Finally,
because the eventual goal is usually to sell a company (or make an initial
public offering) once it has been successfully developed, venture capital-
ists must pay attention to trends in the public equity markets.18Uncertain Investment Prospects in the Private SectorOver the past few years, broadband infrastructure has to some extentfollowed the overall trend of technology-centered enthusiasm for venture
capital investment and high-growth planning. Broadband may similarly
be affected by the current slowdown in investment and by the more care-
ful assessment of business models to which companies are now being
subjected. At this time, broadband providers, as well as Internet service
providers more generally, are facing problems of lack of capital and cash
flow. This could lead to consolidation, and perhaps to a slowdown in the
overall rate of progress.18In a white paper written for this project in mid-2000, George Abe of Palomar Venturescharacterized venture capital investing as ÒfaddishÓ and observed that 
Òthere is a bit of aherd mentality.Ó There are hints that with the 2001 market drop, venture capitalists have
adopted a longer-term view and are seeking well thought-out opportunities rather thanchasing fads.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.162BROADBANDInvestment Options for the Public SectorIf and when the public sector chooses to intervene financially to en-courage service where deployment is not otherwise happening, it will
have a different set of constraints. Governments have access to bond is-
sues and other financial vehicles that best match one-time capital invest-
ments with payback over a number of years, and they also have access to
a tax base that reduces the risk of default. If a major, one-time investment
is to be made, the implication is that this technology must be as future-
proof as possible, because it must remain viable for the period of the
payoff. The most defensible technology choice in this case is fiber-to-the-
home, with a separate fiber to each residence. Fiber has an intrinsic capac-
ity that is huge, but the actual service is determined by the equipment that
is installed at the residence and at the head end. With dark fiber running
to each customer, the end equipment need not be upgraded for all the
users at once but can be upgraded for each consumer at the time of his or
her choosing. Thus, this technology base permits different consumers to
use the fibers in different ways, for different services, and with different
resulting costs for end-point equipment. The consumer can make these
subsequent investments, reusing the fiber over the life of the investment.
Upgrades are not, however, fully independent as they depend on the
backhaul infrastructure. An upgrade will require not only new central
office or remote terminal line cards, but also a compatible infrastructure
beyond that; the remote terminal or central office rack itself may not be
able to switch or route a higher-speed input due to hardware or software
constraints.Businesses look at risk as an intrinsic part of doing business andmanage risk as a part of normal planning. Some investments pay off;
others may not. For residential access, for example, demand may exceed
expectation, or perhaps not, and a business will mitigate these risks by
investment in a number of situationsÑcommunities, services, and so on.In contrast, a municipality serves only its own citizens, so any risk ofbad planning must be carried within that community. Further, the voter
reaction to miscalculation may amplify the perception of the error, which
can have very bad personal implications for individual politicians. Long-
term investment in services that do not bring visible short-term value to
the citizens may be hard for some politicians to contemplate, because the
payoff from this investment may not occur in a time frame that is helpful
to them. So a planner in the public sector must balance the fact that most
sources of capital imply a long-term investment with the fact that citizens
may not appreciate the present value of long-term investment, and may
assess the impact of investment decisions based on short-term conse-
quences. This may lead to decision making that is either more or less risk-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS163averse (given the level of knowledge among the citizens and apparentlevel of popular demand) than the decision making of the private sector.MooreÕs Law and BroadbandThis report defines broadband deployment as an ongoing process,not a one-time transition. The first proposed definition of what it means
for a service to be broadband reflects this reality: Access is broadband if it
is fast enough on an ongoing basis to not be the limiting factor for todayÕsapplications. With that definition in mind, unfavorable comparisons are
sometimes made between the sustained improvements in the perfor-
mance-to-price ratio of computing (which relate to what is known as
MooreÕs law, the 18-month doubling of the number of transistors on anintegrated circuit) and improvements in the capacity of broadband access
links. In fact, communications technologies, as exemplified by sustainedimprovements in fiber optic transmission speeds, have by and large kept
pace with or surpassed improvements in computing. The gap one sees is
between deployed services and 
underlying technology, not an inherent mis-match of technology innovation.This committee spent some time exploring why broadband local ac-cess has not kept pace with other areas in computing and communica-
tions, and it considered how the economics of broadband service provid-
ers, long-haul communications providers, and computer equipment
vendors might differ. In the end, the committee concluded that present
understanding is too limited to reach definitive conclusions on this ques-
tion. Why productivity growth in access has not kept pace with other
communications sectors is an interesting question worthy of further re-
search.ECONOMICS OF SCALING UP CAPACITY: CONGESTIONAND TRAFFIC MANAGEMENTOnce initial systems are deployed, successful broadband providersare almost certain to experience continued demands on their networks
owing to increased subscribership and increased traffic per subscriber.
These demands have implications both for how the access links them-
selves are configured and managed and for the network links between the
provider and the rest of the Internet. This section provides an overview of
traffic on the Internet and discusses some of the common misunderstand-
ings about broadband technology.The term ÒcongestionÓ describes the situation in which there is more
offered traffic than the network can carry. Congestion can occur in any
shared system; it leads to queues at emergency rooms, busy signals on theBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.164BROADBANDtelephone system, inability to book flights at the holidays, and slowdownswithin the Internet. As these examples illustrate, congestion may be a
universal phenomenon, but the way it is dealt with differs in different
systems. In the telephone system, certain calls are just refused, but this
would seem inhumane if applied to an emergency room (although this is
sometimes being doneÑemergency rooms are closing their doors to newemergencies and sending the patients elsewhere). In the Internet, the ÒbesteffortÓ response to congestion is that every user is still served, but all
transfers take longer, which has led to the complaints and jokes about the
ÒWorld Wide Wait.ÓCongestion is not a matter of technology but of business planning andlevel of investment. In other words, it is a choice made by a service pro-
vider whether to add new capacity (which presumably has a cost that has
to be recovered from the users) or to subject the users to congestion (which

may require the provider to offer a low-cost service in order to keep
them).Shared links can be viewed as either a benefit or a drawback, depend-ing on oneÕs viewpoint. If a link is shared, it represents a potential point ofcongestion: if many users attempt to transmit at once, each of them may
see slow transfer rates and long delays. Looked at in another way, sharing
of a link among users is a central reason for the InternetÕs success. Sincemost Internet traffic is very burstyÑtransmissions are not continuous butcome in bursts, as for example when a Web page is fetchedÑa sharedcommunications path means that one can use the total unused capacity of
the shared link to transfer the burst, which may make it happen faster.In this respect, the Internet is quite different from the telephone sys-tem. In the telephone system, the capacity to carry each telephone call is
dedicated to that one connection for its durationÑperformance is estab-lished a priori. There is still a form of sharingÑat the time the call isplaced, if there is not enough capacity on the links of the telephone sys-
tem, the call will not go through. Callers do not often experience this form
of Òbusy signal,Ó but it is traditionally associated with high-usage events
such as MotherÕs Day. In contrast, the Internet dynamically adjusts therate of each sender on the basis of how many people are transferring data,
which can change in a fraction of a second.The links that form the center of the Internet carry data from manythousands of users at any one time, and the traffic patterns observed there
are very different from those observed at the edge. While the traffic from
any one user can be very bursty (for a broadband user on the Web, a ratio
of peak to average receiving rate of 100 to 1 is realistic), in the center of the
network, where many such flows are aggregated, the result is much
smoother. This smoothness results from the natural consequences of ag-
gregating many bursty sources, not because the traffic is Òmanaged.ÓBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.TECHNOLOGY OPTIONS AND ECONOMIC FACTORS165With enough users, the peaks of some users align with the valleys of otherusers with high odds. One of the reasons that the Internet is a cost-effec-
tive way to send data is that it does not set up a separate ÒcallÓ with
reserved bandwidth for each communicating source, but instead com-
bines the traffic into one aggregate that it manages as a whole.For dial-up Internet users, the primary bottleneck to high throughputis the modem that connects the user to the rest of the Internet. If broad-
band fulfills its promise to remove that bottleneck, the obvious question
is, Where will that bottleneck go? There has a been a great deal of specu-
lation about how traffic patterns on the Internet will change as more and
more users upgrade to broadband. Some of these speculations have led to
misapprehensions and myths about how the Internet will behave in the
future.Cable systems have the feature that the coaxial segment that serves aparticular neighborhood is shared. This has led to the misconception that
broadband cable systems must slow down and become congested as the
number of users increases. This may happen, but it need not. Indeed,
shared media in various forms are quite common in parts of the Internet.
For example, the dominant local area network standard, Ethernet, which
is a shared technology with some of the same features as HFC cable
modems, has proved very popular in the market, even though it, too, can
become congested if too many people are connected and using it at once.
Cable systems have the technical means to control congestion. They can
allocate more channels to broadband Internet, and they can divide their
networks into smaller and smaller regions, each fed by a separate fiber
link, so that fewer households share bandwidth in each segment. Whether
they are, in fact, so upgraded is a business decision, relating to costs,
demand, and the potential for greater revenue. Of course, less sharing
would tend to reduce the cost advantage of HFC relative to other higher-
capacity solutions such as FTTH.DSL is generally thought to suffer from fewer access network conges-tion problems because the user has a dedicated link from the residence to
the central office. It is true that the user will never see contention from
other users over the dedicated DSL link; however, it also means that the
user can never go faster than the fixed dedicated capacity of this link, in
contrast to being able to use the total unused capacity of a shared system.Both the cable and DSL systems bring the traffic from all their users toa point of presence (central office or head end), where this traffic is com-
bined and then sent out over a link toward the rest of the Internet. This
link from the termination point to the rest of the Internet is, in effect,
shared by all of the subscribers connected to that point of presence,
whether the broadband system behind it is a shared cable system or a
dedicated DSL system, making the link a common source of congestionBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.166BROADBANDfor all of the subscribers. The cost of the link depends on both the capacityof the physical link and the compensation that must be paid to other
Internet providers to carry this traffic to the rest of the Internet. The cost
of these links can be a major issue in small communities where it is diffi-
cult to provision additional capacity for broadband. So there is an incen-
tive not to oversize that link. The economics and business planning of this
capacity are similar for a cable or a DSL system.The fact that the links from the point of presence to the rest of theInternet are often a source of congestion illustrates an important point.
The number of users whose traffic must be aggregated to make the total
traffic load smooth is measured in the thousands, not hundreds. So there
may be a natural size below which broadband access systems become less
efficient. For example, if it takes 10,000 active users to achieve good
smoothing on the path from the rest of the Internet, then a provider who
gets 10 percent of the market,19 and who can expect half of his users to be
active in a busy hour, needs a total population of 200,000 households as a
market base in a particular region.Even if the broadband local access links themselves are adequatelyprovisioned, bottlenecks may still exist, owing to such factors as peering
problems between the broadband service provider and the rest of the
Internet, host loading, or other factors. Performance will also be depen-
dent on the performance of elements other than the communications links
themselves, such as caches and content servers located at various points
within the network (or even performance limitations of the userÕs com-puter itself). These problems, which will inevitably occur on occasion,
have the potential to confuse consumers, who will be apt to place blame
on the local broadband provider, whether rightly or wrongly.19For an examination of the smoothing phenomenon, see David D. Clark, William Lehr,and Ian Liu, ÒProvisioning for Bursty Internet Traffic: Implications for Industry Structure,Óto appear in L. McKnight and J. Wroclawski, eds., 2002, Internet Service Quality Economics,MIT Press, Cambridge, Mass.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.167
This chapter provides an introduction to the policy context surround-ing broadband deployment and discusses specific issues that have shaped

the reasoning of the Committee on Broadband Last Mile Technology and
that underlie its recommendations. A more detailed history of U.S. regu-
lation related to broadband appears in Appendix B, which is recom-
mended for any reader not familiar with the complex regulatory context
within which broadband is being deployed. Note that this chapter does notcontain the committeeÕs policy recommendations, although it lays part of
the foundation for them. The committeeÕs findings and recommendations
are presented in ÒSummary and RecommendationsÓ at the beginning of
this volume.THE CONTEXT FOR BROADBAND POLICYBroadbandÑas an extension or phase of the InternetÑhas been im-bued, in media coverage and popular debate, with revolutionary promise
that cuts across traditional policy segmentation. Residential broadband
has ushered in an era of considerable technological innovation and flux.
At the same time that a diverse set of technologies, which are character-
ized by different performance characteristics (bandwidth, symmetry,
transparency, and so on), are available for reaching customers, a powerful
convergent platformÑthe Internet and its core technologiesÑis increas-
ingly favored for delivery of content, applications, and services. Enabled
by this flexible, general-purpose delivery platform, a multiplicity of ap-
plications and content supported through a variety of business modelsBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.168BROADBANDhas emerged. The combination of technological and associated businesschanges generates considerable uncertainty and questions about what
regulatory or other approaches are suited to meeting desired goals in
light of this uncertainty.Broadband has been targeted by traditional political players in thevarious policy arenas, and it has catalyzed the formation of new political
alliances. It is subject to past policy developed in part for other telecom-
munications technologies and is the focus of a number of efforts to shape
new telecommunications policy. The previous chapter explained how the
characteristics of the different technology options are just a piece of the
broadband puzzle. Because the profitability and growth prospects of dif-
ferent kinds of entities are affected by government decisions about what
kind of entity can provide what kind of service, and when and where and
how it can do so, the policy context has a significant impactÑthere are nopure investment decisions, and political activity aimed at shaping the
context is rampant. While many speak of a desire to deregulate, the na-
ture and terms of regulation have become part of the competitive process.
Moreover, there is something fundamentally highly political in the nature
of communications technologies and services, beginning with the impor-
tance of communications media in the political process itself.1 The recent
introduction of a number of pieces of legislation aimed at promoting
broadband is another indicator of heightened interest and sometimes in-
tense politicization. Proposed measures include tax credits, grants, subsi-
dized loans, and other financial incentives for deployment in underserved
or rural areas; support for research on broadband technologies for rural
areas; grants for community planning efforts; changes in the regulation of
incumbent local exchange carriers; and changes in universal service fund
rules.2Viewed through the lens of telecommunications policy, broadbandinvolves a system with players and rules at federal, state, and local levels
and a long history of political activity that features industry associations
old and new, consumer- and issue-advocacy organizations (and consider-1For example, the original schemes for allocating radio and television licenses had apolitical connection, with licenses allocated geographically.2Bills that would provide financial incentives include H.R. 267, Broadband Internet Ac-cess Act of 2001; H.R. 1415, Technology Bond Initiative; H.R. 1416, Broadband ExpansionGrant Initiative; H.R. 1697, Broadband Competition and Incentives Act; H.R. 2139, RuralAmerica Broadband Deployment Act; H.R. 2401, Rural America Digital Accessibility Act;
H.R. 2597, Broadband Deployment and Telework Incentive Act; H.R. 2669, Rural Telecom-munications Enhancement Act; S. 88, Broadband Internet Access Act; S. 150 BroadbandDeployment Act; S. 426, Technology Bond Initiative; S. 428, Broadband Expansion GrantBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION169able activity by lawyers and lobbyists for all parties) seeking to influencelegislation, administrative rule making, and court decisions. Organiza-
tions addressing broadband as part of their lobbying activity have prolif-
erated; they range from mainstream telecommunications trade associa-
tions (such as the United States Telecom Association, the National Cable
and Telecommunications Association, and the Organization for the Pro-
motion and Advancement of Small Telephone Companies) to associations
of new telecommunications competitors (e.g., the Association for Local
Telecommunications Services and the Competitive Telecommunications
Association) to technology-specific associations (e.g., DSL Forum and the
Home Phoneline Networking Alliance), broadband issues-focused asso-
ciations (such as the Competitive Broadband Coalition and the OpenNET
Coalition), and consumer advocacy organizations (such as Consumers
Union, the Center for Digital Democracy, and the Consumer Federation
of America). At issue are considerations such as pricing, service defini-
tions, interconnection terms, and rules for the use of public resources
(e.g., radio spectrum and rights-of-way) as well as a variety of special
needs that are usually met outside of normal market action (e.g., univer-
sal service and public safety). Broadband is also associated with issues of
privacy, security, and access by law enforcement; the complexity of these
particular issues necessitates separate examination, and they are not dis-
cussed in this report.Viewed through the lens of competition policy, the economic regula-tion associated with telecommunications policy is complemented by anti-
trust and other matters associated with the structure and conduct of pro-
vider industries. The action centers on administrative authorizations (with
or without conditions) and legal decisions related to mergers and acquisi-
tions. At issue are basic questions of market power and related conduct,
such as interconnection and access to directories.Initiative; S. 966, Rural Broadband Enhancement Act. Bills that would support researchinclude H.R. 2401, Rural America Digital Accessibility Act, and S. 430, Broadband RuralResearch Investment Act.Bills that would change ILEC regulation include H.R. 1542, Internet Freedom and Broad-band Deployment Act; H.R. 1697, Broadband Competition and Incentives Act; H.R. 1698,American Broadband Competition Act; H.R. 2120, Broadband Antitrust Restoration and
Reform Act; S. 1126, Broadband Deployment and Competition Enhancement Act; and S.1127, Rural Broadband Deployment Act. S. 500, the Universal Service Support Act, wouldextend universal service fund coverage for broadband. S. 1056, the Community Telecom-
munications Planning Act, would provide support for community planning grants. (Na-tional JournalÕs Technology Daily. 2001. Broadband Bill Status. National Journal, Washing-
ton, D.C. Available online at <http://nationaljournal.com/pubs/techdaily/briefroom/
billstatus/broadband.htm>.)Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.170BROADBANDViewed through the lens of consumer protection, legislative and ad-ministrative actions focus on consumer experiences. These include prices
and quality of services, fair and clear billing, broadening of access to
underserved areas and populations, linkage to other consumer concerns
(e.g., education and health care services), and so on.And there are yet other perspectives. Because the greatest deploy-ment uncertainty and expected impact are in the last mile, broadband
policy making at state and local levels looms large. It is at these levels that
community and personal impacts are most evident. At state and local
levels, economic development is increasingly linked to communications
infrastructure because of expectations about how such infrastructure can
contribute to economic opportunity (e.g., through skills and job develop-
ment, attraction of employers, and support for telecommuting) and qual-
ity of life (e.g., in terms of educational and health-care resources and
community information sharing). Many states and a number of localities
have taken a number of initiatives aimed at broadband deployment.
Broadband is primarily an issue of domestic policy, but international per-
spectives arise with respect to competitiveness issues and the interna-
tional context in which the Internet exists.Recognizing that a diverse set of actors plays a role in shaping broad-band policy is important, because it is too easy to narrow the discussion to
state and federal regulation of the price of communications services, a
dominant historic concern in telecommunications. State and federal legis-
lators, regulatory agencies, the courts, and local governments all influ-
ence policy. Decision making takes many different forms: rule making,
tariff setting, court cases, and voluntary agreements. The role of cable
operators and companies using terrestrial wireless and satellite means
that broadband policy encompasses more than traditional telephone rules.
Relevant policy spheres include regulation of retail and wholesale rates;
interconnection and unbundling rules; local cable franchising; access to
poles, conduit, and other rights-of-way; wireless spectrum licensing; uni-
versal service rules; and antitrust law.Finally, the committee notes that, much as is the case with other com-puting and telecommunications sectors, there are often valid conceptual
arguments to be made on behalf of a number of different positions and
interests in each policy debate. Which position represents the appropriate
policy choice is a function of circumstances specific to the matter, but one
rarely has the empirical evidence required to support one position defini-
tively over others. Furthermore, the parties with interests in the outcome
of a policy debate always represent their own positions as unambigu-
ously right and true. Thus, at some level, one is ultimately working with
educated guesses, and some mistakes are inevitable.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION171POLICY IMPLICATIONS OF TECHNOLOGICAL CHANGEThe issues raised by the deployment of broadband technologies andservices are in some ways quite different from the ones that policy makers
face in regulating the narrowband telecommunications sector. In narrow-
band, the principal issues facing policy makers today involve the fashion-
ing of policies that will facilitate the efficient conversion of a mature mar-
ketplace dominated by a single provider to a competitive marketplace
served by different facilities-based and non-facilities-based providers. In
the case of broadband, the marketplace is in its infancy and evolving in
uncertain directions. Although major technological changes in the public
switched telephone network have occurred, such as the movement from
party-line to single-line service or the development and deployment of
vertical services, the development and deployment of broadband services
are occurring over a much shorter time. This leads to difficulties in esti-
mated costs. Trends in the costs of some elements, such as customer pre-
mises equipment, can be estimated on the basis of conventional wisdom
about MooreÕs law and the impact of rising production volumes. Butevery so often, some kind of component or process innovation can lead to
a significant cost change.3 It is not surprising, given this young and evolv-
ing marketplace, that the committee found uncertainty in predictions of
per-subscriber costs and take-rates. At the same time, infrastructure tends
to be enduring, which implies that errors in planning can have long-term
consequencesÑa reality that has contributed to a relatively slow pace ofregulatory evolution as well as conservatism in some segments of the
telecommunications industry, even in the face of rapid change.4Regulation in the Face of Rapid ChangeHistorically, even when there was less-rapid technological change intelecommunications, governmental regulators generally have not at-
tempted to control the process of change directly. The Federal Communi-
cations Commission can exercise influence over technology for many pur-
poses: to encourage or enable new services, which is the emphasis in this
report; to assure certain protections (e.g., against radio frequency interfer-
ence or safety hazards); and to support certain kinds of uses of the infra-3For instance, companies have announced a number of innovations in the mechanics ofdeploying fiber, such as V-group splicing, blow-in of fiber into conduits, and robotic instal-lation in sewer pipes.4For an earlier discussion of different industry cultures, see Computer Science and Tech-nology Board, National Research Council. 1996. The Unpredictable Certainty: Information In-frastructure Through 2000. National Academy Press, Washington, D.C.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.172BROADBANDstructure that are given priority through public policy decisions (e.g., 911emergency services, law enforcement access capabilities,5 and disability
access). Early on, the government posture with respect to the market
dominance of AT&T evolved to reflect evidence that AT&T devoted, with-
out a government mandate but with protected revenue, considerable re-
sources to improving the efficiency and capabilities of its network through
technological advances. Later, government efforts to open previously
closed markets motivated equipment manufacturers and service provid-
ers to develop and deploy equipment and facilities that could take advan-
tage of those commercial opportunities.6 Today, for example, literally
scores of firms are deploying fiber-optic cables and advanced switches
and routers in local and long distance networks to provide voice and data
services, a phenomenon that (along with mobile wireless) has been fueled
recently by tens of billions of dollars in venture capital. Rather than man-
date particular technological solutions, the FCC has tended in recent years
to address technology via selected performance requirements against
which industry groups could develop specific standards, and even these
activities seem to have diminished over time.7 In the turbulent wireless
arena, the FCC has been changing its procedures for issuing radio li-
censes, from adopting auctions for allocation of spectrum to considering a
systemwide rather than site-specific licensing approach.Nonetheless, the FCC has been faulted for some of its approaches tonew technologies.8 More generally, both regulators and investors have
5Communications Assistance for Law Enforcement Act, 47 USC 1001, PL 103-414.6In the 1950s, for example, advances in microwave technology (originally developed forthe government during World War II) created an alternative system for transmitting tele-
phone calls over long distances, in lieu of AT&TÕs embedded system of wires. In 1958, theFCC authorized large businesses to use microwave facilities to construct their own privatenetworks. In 1969, the commission took the next step and permitted firms to compete di-
rectly with AT&T for certain types of services. And in the 1980s, with divestiture bringingthe realities of competition closer, AT&T executives came to revise their own assessment ofthe costs of adding fiber in their long-distance network as competitor actions, such as
SprintÕs Òpin dropÓ advertisements, made the case more compelling.
7In the case of Ò1+Ó access, for example, the FCC did not specify the particular types of
modifications to existing telephone switching equipment that were required to provide
Ò1+Ó access. Instead, it mandated the performance requirements that the carriers would
have to satisfy and allowed the carriers, working with equipment manufacturers, to de-velop the specific technical modifications.8Some argue that both the FCC and AT&T were slow to cultivate cellular telephony,where deployment and commercial service lagged key innovations considerably; that thegranting of licenses for UHF television channels proved to be a costly diversion of resources
and spectrum; and that the approach taken to standard-setting for advanced (Òhigh-defini-tionÓ) television serves to slow progress in that arena. See, for example, ÒA Very LongDistance: A Regulatory Call Put Cell Phones on Hold,Ó Technology Review, May 2001, p. 110.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION173guessed wrong on many technologies; it has been easy for people to bothover- and underestimate the potential of new technology. This point was
emphasized by many participants at the committeeÕs June 2000 work-shop, which included comments on disappointments in such technolo-
gies as Integrated Services Digital Network service and multipoint multi-
channel distribution service (in its video distribution incarnation), among
others, for which the technology proved limited in practice, penetration
never reached anticipated levels, and better alternative technology was
ultimately adopted. Such experiences underscore the fundamental diffi-
culties that regulators have in gauging the coevolution of technologies
and marketsÑand their influence on them.9 The problem of understand-
ing the trends and implications of new technology seems especially acute
for the Internet, since few regulatory agency staff, at least at the FCC,
have been expert in Internet-related technologies.10 The FCC has recentlylaunched several initiatives aimed at increasing its technical capacity in
this and other areas.11One of the most obvious indicators of the difficulty regulators (andother policy makers) have in keeping up with technology change is the
definitions they develop and use. The Telecommunications Act of 1996
refers in general terms to Òadvanced services.Ó Required to report to Con-
gress on deployment of advanced services, the FCC subsequently defined
these to be at least 200 kbps in either direction.12 As discussed in Chapter2 in this report, this sort of definition is problematical: 200 kbps will
increasingly be, at best, a lowest common denominator in an environment9At a June 2000 workshop, Thomas Krattenmaker of Mintz, Levin (and previously theFCC and academia) observed: ÒI would say that any regulation or any response you pro-pose to the FCC that is predicated on your ability to predict what technology will prevail,when, will be a useless recommendation . . . . We are just rife with suggestions, too many of
which the Commission has adopted, that were based on some ability to know when tech-nology and which technology was going to be deployed. I donÕt think weÕre capable ofknowing that, and I know the commissioners are notÑtheyÕre not selected on that [basis].Ó10Casual observation shows that the FCC has engaged a single Internet-oriented indi-vidual in its Office of Plans and Policy since the mid-1990s, and beginning in the late 1990sit engaged chief technologists with Internet expertise, but there are limits to what a couple
of specialists in staff positions can accomplish.11Steps taken include the 1998 establishment of a Technical Advisory Council and the2001 launch of an agencywide ÒExcellence in EngineeringÓ initiative, including hiring and
training measures.12Broadband Second Notice of Inquiry, Federal Communications Commission (FCC, 2000,ÒInquiry Concerning the Deployment of Advanced Telecommunications Capability to AllAmericans in a Reasonable and Timely Fashion, and Possible Steps to Accelerate SuchDeployment Pursuant to Section 706 of the Telecommunications Act of 1996: Second Re-port,Ó CC Docket No. 98-146, FCC, Washington, D.C., August 21).
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.174BROADBANDwhere capabilities of many technologies are growing; it is unclear whether
bandwidth demand will be symmetrical, as the requirement assumes;
and, in any event, the committee believes that use of any static definition
is unwise over the long run. The separation, intellectually and culturally,
of those setting policy definitions from those developing the technology
may be unavoidable, but it has consequences.Thus, broadband is still a very new technology family, as is the Inter-net in general. The great and general potential of the technology seems
clear, but how it might be effectively (and profitably) commercialized is
still unclear. During this stage, one can expect to see much experimenta-
tion with different business and service models by both private and pub-
lic providers. It may be wrong to assume that executives whose public
remarks exude confidence have deep understanding of all dimensions of
the new approaches to networking that they are developing. For example,
several people at the committeeÕs June 2000 workshop acknowledged indiscussions that some of their earlier assumptions had proved wrong and
that their views were evolving with experience.13 Indeed, the years 1999-
2000 saw the nation in the midst of a dot-com and telecommunications
euphoria in the financial markets, while 2001 sees the reverse. All these
observations, therefore, suggest caution in reading too much into the im-
mediate situation and the importance of business strategists and policy
makers staying as flexible as possible during this stage.Asymmetrical Regulation and Achieving Technology NeutralityThe development of Internet-based services that can operate overboth cable and telephone networks has accentuated convergence and tech-
nology neutrality. Cable, DSL, and wireless providers can offer relatively
comparable applications and services. Not only do these alternatives each
offer high-speed access to the Internet, but each also has the potential to
provide services that compete directly with the traditional offerings of
other networks (e.g., cable broadband facilities can be used to provide
voice services, and DSL can carry streaming video).The unsustainability of competition that may arise with asymmetricalregulation is most severe when two products or services are perfect sub-
stitutes for each other. For example, if DSL and cable modem services are13For example, in remarks to the committee, SprintÕs Jim Hannan said of his MMDSoffering, ÒWe donÕt have effective models . . . so we really donÕt understand how the net-work behaves. WeÕre pushing it every day.Ó Hannan observed that projected upstream-to-
downstream traffic ratios were much higher than what was observed when Sprint de-ployed its network; this was attributed largely to customer use of Napster.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION175extremely close substitutes, disparate rule sets are likely to be a signifi-cant problem in the long run, unless bundling broadband access with
other services (cable television or telephone) creates some differentiation.
To the extent they are differentiated in ways that reflect demand hetero-
geneity, this is less of a problem. Still, even if the platforms do not provide
directly compatible services, they may provide services that are nonethe-
less substitutable for each other.Their convergence notwithstanding, these technologies are for his-torical reasons subject to separate and substantively different regulatory
regimesÑa situation characterized by some academics, industry repre-sentatives, and FCC officials as regulation in Òstovepipes.Ó At the FCC,
stovepipes are embodied in bureausÑcable services, common carrier,mass media, and wireless telecommunications. Those bureaus, in turn,
correspond to focused enabling statutes, which reinforce the traditional
linkage of technologies with industries and specific services. Appendix B
contrasts the regulation of telecommunications common carriers (which
affects DSL provision) with that of cable operators. Terrestrial wireless
and satellite are subject to yet another set of distinct regulations. Looking
across the various stovepipes, the greatest constraints appear to apply to
the telephone industry, where rules (retail price regulation and newer
market-opening requirements) are intended to inhibit ILECs from taking
unfair advantage of their historically dominant position as regulated mo-
nopolies in telephony as they enter into other market segments; but one
also sees cable franchising provisions being applied to broadband deliv-
ered over cable.The issue of asymmetrical regulation of broadband has been high-lighted by the current debate over Òopen access,Ó discussed in detail be-
low. Cable operators have maintained that the Internet access service
offered over their networks is a cable service and, consequently, that they
are not required to offer unaffiliated ISPs that wish to reach cable sub-
scribers access to this service. Opponents have claimed that cable opera-
tors are engaged in the provision of a telecommunications service when
they offer high-speed access to an ISP and, hence, sought to have regula-
tors require cable operators to offer that service on a nondiscriminatory
basis to unaffiliated ISPs. (This argument has had traction in the courts;
one response has been a move by some cable companies, which have
resisted being classified as telecommunications services, to embrace the
designation as a way of avoiding franchise payments, illustrating the
maneuvering that goes on.) Other parties have contended that govern-
ment intervention is unnecessary (and may be harmful), because market-
place forces are sufficient to cause cable operators to make access avail-
able to unaffiliated ISPs as soon as technical problems are addressed and
business arrangements supporting access to multiple ISPs are put in place.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.176BROADBANDWhile technical development continues, successful demonstrations andavailability of unaffiliated ISPs in some markets suggest that the technical
problems of supporting multiple ISPs in cable systems can be overcome.14Business aspectsÑsuch as provisioning and troubleshooting systemsÑare a focus of current activity.Further confounding the question are technology trends suggestingthat fiber will be pushed ever deeper into wireline and terrestrial wireless
broadband networks, meaning that provider networks will increasingly
resemble each other even in terms of technology, at least in all but the last
segment of the access link. As the similarity in both product (services) and
delivery technology grows, the distinction between the service-produc-
ing and service-delivering industries falls, but whether or how one recon-
ciles the associated regulatory regimes is an open question.Regulatory legacy and convergence aside, some regulatory issuesspeak to inherent attributes of a technology, confounding any notion of a
technology-neutral policy. Implementing local loop unbundling, for ex-
ample, involves an intimate understanding of the physical environment
of that plant. Policy with respect to public rights-of-way involves the
details of poles and conduit access for wireline systems and tower siting
for wireless. Wireless illustrates another challenge to achieving technol-
ogy neutrality: with different servicesÑincluding fixed terrestrial servicesuch as MMDS and mobile services
Ñassigned to different frequency
bands, allocating scarce spectrum among these would seem to require
making technology- and service-specific trade-offs. In some cases, it is
entirely reasonable to make distinctions: one does not have spectrum
auctions on fiber, for example. However, when obligations of any kind
are imposedÑperformance obligations certainlyÑit is generally very dif-ficult or impossible to be completely technologically neutral. How can
one treat these services on an even-handed basis despite the differences in
the underlying technology?The committeeÕs assessment of technology options (see Chapter 4)suggests that broadband will not involve a technological horse race or
overall regulatory or market choice among technological options. The
various access technologies will fill different niches, and multiple connec-
tions will be available in many markets (many already have two connec-
tionsÑphone and cable linesÑcapable of supporting broadband to the14For example, in June 2001, AT&T announced that its Boulder, Colorado, open accesstrials were successful (Richard Williamson, ÒAT&T Completes First Open Access CableTrial,Ó Interactive Week. June 7). Earthlink subscriber information as of October 2001 indi-cates that its services are available over Time Warner Cable systems in several markets andthat more markets will be added in the near future.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION177home). This diversity suggests that the issue of technology neutrality willbe around for some time to come. To the extent that neutrality is not
achieved, regulatory actions would favor or disfavor options in ways that
could decrease investment incentives or otherwise distort natural market
forces in ways unfavorable to consumers. Decreased choice would reduce
the likelihood that facilities-based competition emerges or would deprive
consumers of particular cost and performance options.The existence of these asymmetries, as well as the looming contradic-tions that convergence in the access technologies themselves poses, is
recognized by regulators. What is less clear is how to craft a solution that
improves the situation. One problem may lie in the concept of neutrality
and regulatorsÕ goals not to pick winners and losers: neutrality may not
be feasible, given the tight coupling between the subjects of regulation
and the details of particular technologies. In avoiding tying regulations to
technology-specific considerations, one has to find some other spaceÑsome more abstract definition of broadbandÑin which to regulate. Hereone is confounded by such factors as the dynamic nature of broadband
and the two-way link between technology-specific performance charac-
teristics such as speed and application requirements. Also, absent the
specific issues that have been the source of much of telecommunications
regulation, what would be the goals of regulation of ÒbroadbandÓ?COMPETITIONThe establishment of robust competition among multiple telecommu-nications providers, including broadband and other providers, is a basic
premise of the Telecommunications Act of 1996 (Box 5.1). This is viewed
by many as the desirable way of making broadband as affordable as
possible, though the view is not universal.15 Two principal paths toward
competition are contemplated in the present policy regimeÑ(1) unbun-dling and resale and (2) facilities-based competitionÑwhich are discussedin separate subsections below. Unbundling arose in the context of policies
aimed at stimulating competition to the ILECs. The 1996 act mandated
unbundling of local loops and other network elements. In contrast to
unbundling, facilities-based competition involves new entrants using their
own equipment and physical network to compete.15For example, the National Telephone Cooperative Association (NTCA) commissioned awhite paper that concluded that the entry of competitors would decrease the take-rateachievable by any single carrier, which could substantially undermine the financial case for
DSL in rural areas where it is already constrained even without competition. NTCA linkedthe issue to its call for only incumbents to be eligible to receive universal service high-cost-area support payments (Telecommunications Reports, January 15, 2001, p. 6).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.178BROADBANDBOX 5.1Key Provisions of the Telecommunications Act of 19961Related to Broadband¥Section 251 of the Telecommunications Act of 1996 establishes a series of obliga-
tions that apply to telecommunications carriers. Some apply to all telecommunicationscarriers (local as well as long distance and others). Some apply only to providers of local
telephone. The most detailed requirements apply to incumbent local telephone compa-nies, such as the Bell Operating Companies. The latterÑthose pertaining to incumbentsÑconsist of a variety of obligations that collectively are designed to facilitate the entry of
new providers into local markets and enhance their ability to compete with the incum-bents. These include, for example, a requirement that incumbents make available parts oftheir local networks to competing providers on just, reasonable, and nondiscriminatory
terms and conditions. The procedures for implementing these requirements for incumbenttelephone companies are set forth in Section 252.¥Section 253 generally preempts, with certain limited exceptions relating to univer-
sal service and other public policy objectives, any state or local statute or regulation thatprohibits or has the effect of prohibiting the ability of any entity to provide any interstateor intrastate telecommunications service.¥Section 254 promotes access to advanced telecommunications and information
services in all regions of the nation. Universal service principles to be implemented by theFederal Communications Commission include ensuring the following: quality services at
reasonable and affordable rates; access to advanced services; access to such services inrural and high-cost areas; that all providers of telecommunications services make an equi-table and nondiscriminatory contribution to the preservation and advancement of univer-
sal service; that specific and predictable support mechanisms are in place to carry outsuch preservation and advancement; that there is access to advanced telecommunicationsservices for schools, health care, and libraries; and that other principles that the joint
(federal-state) board and the FCC may determine are necessary and appropriate for theprotection of the public interest are implemented.¥Section 255 requires telecommunications products and services to be accessible to
people with disabilities. This is required to the extent that access is Òreadily achievable,Ómeaning easily accomplishable, without much difficulty or expense. If manufacturers can-not make their products accessible, then they must design products to be compatible with
adaptive equipment used by people with disabilities, where readily achievable. What isÒreadily achievableÓ will be different for each manufacturer, depending on the costs of
making products accessible or compatible and their resources.¥Section 256 sets broad parameters to establish nondiscriminatory access for the
broadest number of users and vendors of communications products and services to thepublic telecommunications networks that are used to provide telecommunications service
through joint network planning. It defines Òpublic telecommunications network intercon-nectivityÓ as the ability of two or more public communications networks used to provide
telecommunications service to communicate and exchange information without degener-
ation, and to interact in concert with one another. This section also regulates coordinationfor interconnectivity and establishes FCC procedures for oversight. It sets out the parame-1Formally, the Communications Act of 1934, as amended.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION179ters under which the FCC is to review and eliminate federal regulations that may act asmarket-entry barriers for entrepreneurs in providing telecommunications. The FCC wasrequired to conduct such an initial proceeding within 15 months of the lawÕs enactmentand thereafter to conduct similar periodic reviews every 3 years.¥Section 259 mandates that incumbent local exchange carriers (ILECs) make avail-
able to any qualifying carrier any public switched telecommunications equipment or in-
formation as should be requested by the qualifying carrier. It excepts situations underwhich it would be economically unreasonable or against the public interest for the ILEC tocomply. It permits joint ownership and seeks to ensure that the ILEC is not treated as a
Òcommon carrier for hireÓ and that the carrier seeking the use of facilities will be allowed
the use of these facilities on just and reasonable terms. Finally, Section 259 demands atransparent process, requiring the ILEC to report the terms and conditions of any facilities-
sharing arrangements.¥Section 271 requires that the FCC consult with the U.S. Department of Justice and
the relevant state commissions before ruling on a Bell companyÕs request to offer in-regioninterLATA services. Upon application by a Bell company, the FCC has 90 days to considerwhether the applicant has met a 14-point Òcompetitive checklistÓ of market-opening re-
quirements contained in the section and whether the companyÕs entry into the interLATAservice market is in the public interest.¥Section 301 stipulates that the FCC shall review any complaint submitted by a
franchising authority concerning an increase in rates for cable programming services and
issue a final order within 90 days after it receives such a complaint, unless the partiesagree to extend the period for such review.¥Section 302 eliminates the prohibition on local exchange carrier (LEC) provision of
video programming in the LECs service area. LECs and others may offer video program-ming under regulations that vary according to the type of video service being provided(radio-based, common carriage, cable TV systems, or open video systems). With the lawÕsenactment, regulation was lifted for cable programming for a basic service tier that was theonly service subject to regulation on December 31, 1994, in any franchise area in whichthe operator serves 50,000 or fewer subscribers.Acquisitions and joint ventures (Section 302 of the bill, Section 652 of the act) are to alarge extent prohibited, though there are several exceptions for certain small and ruralsystems. The law also permits a LEC to acquire or joint venture under different terms and
condition in cases where the subject market meets the FCCÕs definition of Òcompetitive.ÓThe FCC may waive the acquisition and joint venture prohibitions if it determines that theeconomic viability of the market merits such or that to do so would otherwise be in the
public interest, and if the local franchising authority approves.¥Section 303 allows cable operators to provide telecommunications services with-
out first obtaining a franchise to provide those services. Additionally, no franchising au-
thority may interrupt a cable operatorÕs telecommunications services based on that oper-atorÕs lack of a franchise. The section also prohibits franchising authorities from requiringthat any cable operator provide telecommunications services as a condition for granting a
franchise.¥Section 706 seeks to promote the deployment of 
Òadvanced telecommunicationsservicesÓ in a reasonable and timely fashion. It attempts to do this by means of price
continuesBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.180BROADBANDUnbundling and Resale MandatesUnbundling refers to the breaking down of an incumbentÕs networkinto smaller subcomponents, which can be either technology components
(e.g., a phone line) or service components (e.g., switching), so that these
elements can then be sold separately to other service providers. The goal
is to permit new competitors to compete with the incumbent without
having to incur the costs and the risks of constructing all of these elements
themselves. An important difference between resale of services and physi-
cal unbundling of network elements is how much leeway the competitor
has for differentiation. With simple resale, the competitor is confined to
deriving revenue from the differential between the resale and retail rates,
whereas unbundling gives the competitor latitude to provide differenti-
ated services that combine unbundled elements with elements provided
by the competitor.Most prominent in the context of broadband deployment is unbun-dling of the local loop. The ILEC local access facilities have been the
subject of unbundling rules designed to enable CLECs to offer voice and
data services without having to build their own local access facilities. The
DSL competitor provides the facilities at both ends of the loop (the DSL
modem and DSLAM) and connects them to the actual copper wires thatBOX 5.1 (continued)cap regulation, regulatory forbearance, measures that promote competition in thelocal telecommunications market, and other regulating methods that remove barriersto infrastructure investment. This section also required the FCC to follow up withinquiries into the progress of deployment. Reports issued in August of 1999 and
20002 found deployment reasonable and timely based on subscribership levels, ser-
vice and technology options, and infrastructure investment at the time of the inquir-ies. The August 2000 report observed that advanced services may be unevenly dis-
tributed owing to differences throughout the country in wealth and populationconcentration.2Federal Communications Commission (FCC), 1999, ÒInquiry Concerning the Deployment ofAdvanced Telecommunications Capability to All Americans in a Reasonable and Timely Fash-
ion, and Possible Steps to Accelerate Such Deployment Pursuant to Section 706 of the Telecom-
munications Act of 1996: First Report,Ó CC Docket No. 98-146, FCC, Washington, D.C., August;
and FCC, 2000, ÒInquiry Concerning the Deployment of Advanced Telecommunications Capa-bility to All Americans in a Reasonable and Timely Fashion, and Possible Steps to Accelerate
Such Deployment Pursuant to Section 706 of the Telecommunications Act of 1996: Second
Report,Ó CC Docket No. 98-146, FCC, Washington, D.C., August 21.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION181make up the loop. Under present rules, the CLEC has considerable free-dom to select the particular DSL technologies (and thus such parameters
as speed, ratio between up- and downstream speeds, and the maximum
loop length supported), including technologies not offered by the incum-
bent. CLECs have argued that such differentiation is critical, because the
incumbents have generally not deployed the high-rate, symmetric DSL
services favored by small businesses (one argument is that this reflects
incumbent reluctance to cut into the more costly, profitable T1 data ser-
vices offered by the incumbents). This form of unbundling, in which a
passive network elementÑthe copper loopÑis made available in rawform to the competitor has the additional advantage to the competitor of
helping to isolate the quality and nature of the competitorÕs service frompotential adverse actions of the incumbent (though issues of successfully
provisioning the loop in the first place and dealing with crosstalk within
the cable bundles remain). As an alternative to physical unbundling of
copper loops, the ILEC could also be required to provide access to its DSL
at the packet level (through ATM or IP technologies).Cable has a different context for unbundling, both legally and techni-cally. Owing to the design of todayÕs cable systems, most notably theshared communications medium, strict unbundling along the lines of loop
unbundling for DSL is not practical. The open access arrangements con-
templated by the FCCÕs order in the AOL Time Warner merger (andsimilar arrangements being explored by other cable operators) lie some-
where closer to resale than to physical-layer unbundling. The cable opera-
tor operates the cable system over which the unaffiliated Internet provid-
ers connect to customers and hands off the packets destined for the
unaffiliated providers at the cable system head end. Under the terms of
the AOL Time Warner merger order, the cable operator must not dis-
criminate against the unaffiliated provider on technical quality; by the
same token, the unaffiliated provider does not have latitude to compete
with AOL Time Warner on the basis of the technical quality of the last
mile connection.Resale and unbundling rules raise a variety of concerns on the part ofthe facilities owner and the competitor. When a competitor is dependent
on another for critical inputs, the facilities owner will have the incentive
and perhaps the ability to use its control over the input to disadvantage
the competitor in the downstream market in which the firms compete.
Further, as discussed above, facilities owners express the concern that
they will never be fully compensated for their costs under regulator-set
access prices, and how such prices should be set is a matter of current
debate. Not surprisingly, these issues have been vigorously debated since
resale of telephony began, and they account for a significant fraction of
telecommunications regulatory proceedings and related court cases.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.182BROADBANDWhen Unbundling WorksUnbundling has been playing an important role in broadband com-petition. CLECs have provided service in areas unserved by the incum-
bents, and some credit the CLECs for having stimulated deployment ef-
forts by the ILECs. As discussed above, competitive service providers
have entered the wholesale DSL business by leasing local loops and
colocation space from ILECs. However, CLECsÕ long-term impact on the
competitive landscape is in doubt. The competitive DSL industry faces an
uncertain future at present, reflected in a series of major business failures.
These problems reflect the difficulties inherent in forcing an incumbent
monopolist to open its market to competitive entry, the effects of econo-
mies of scale and scope on smaller players, and, from the vantage point of
2001, the challenges in raising investment capital for any sort of tele-
communications investment. These uncertainties raise questions about
how to think about unbundling in fashioning future policy.Unbundling creates an enforced market structure out of the assets ofan incumbent. One should ask how efficient the resulting market could
beÑhow efficient and effective are control and management with mar-kets based on unbundled versus integrated industry structures, and what
factors facilitate unbundling? The basic thrust of the literature on organi-
zational factors is that, when technologies are easy to understand and
simple, markets are likely to have a comparative advantage as coordina-
tion mechanisms owing to the incentive effects of competition.16 In this
circumstance, unbundling can be effective. But if the interfaces between
players are complex, an integrated business approach will often be more
effective.The technical complexity associated with unbundling for broadbandaccess has been seen in the case of both DSL and cable. In the case of cable
video programming, there is a high-level unbundling today in the form of
certain channelsÕ being set aside for use by local broadcasters; public,
educational, and government access; and leased access. These are logical
unbundling variants with simple technical implications. But more recent
proposals have focused on an unbundling at the Internet Protocol layer.
(There were also early proposals to provide unbundling through the use
of asynchronous transfer mode, or ATM, technology.) Concerns today
center on the optimal technical mechanisms to support shared access and
on establishing operational and management mechanisms for coordina-
tion (provisioning, troubleshooting, and the like) between the cable com-
pany and heretofore unaffiliated ISPs.16See, for example, Oliver E. Williamson, 1975, Markets and Hierarchies, The Free Press,New York.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION183As discussed above, DSL unbundling can occur at the physical level,which permits variation in the DSL service that the competitor provides,
and at the resale level. Where ILECs extend fiber closer to customers,
replacing a portion of the existing copper plant, copper pairs no longer
run all the way from premises to the central office, making physical un-
bundling very complex. Issues that must be solved include whether and
how CLECs should be given access to colocation space in remotely de-
ployed pedestals, equipment vaults, or even equipment located on pole
tops. The incumbents have claimed that this level of complexity inhibits
investment in new facilities and is a barrier to the progress of broadband
deployment. In turn, CLECs are concerned that installation of new facili-
ties such as fiber-fed remote terminals would complicate or preclude the
physical loop unbundling on which their businesses depend. In addition
to making colocation and unbundling more complex, remote terminals
alter the economics of physical-layer unbundling, because competitors
are able to serve far fewer customers from a single colocation point.A specific example of this debate centers on Project Pronto, in whichlocal exchange carrier SBC Communications has proposed a program of
fiber deployment that would enable it to provide high-speed digital ser-
vices to its customers that are being served by long copper loops or with
loops fed from digital carrier loops, and that as a result cannot currently
obtain DSL service. Because the program as originally described would
have deprived the CLECs of the opportunity to select the equipment at
each end of the remaining loop segments, they argued that the program
would make it difficult for them to use the new infrastructure to do any-
thing other than resell SBCÕs DSL service, meaning that they would beunable to differentiate their own service in order to compete with SBC.
SBC argued that unbundling at a remote terminal in DSL at the physical
layer is so costly and complex as to be impractical, making higher-level
unbundling solutions a better alternative. The FCC preferred physical-
layer unbundling, making the planÕs approval contingent on SBCÕs agree-ment to increase the size of the remote terminals to permit competitors to
install termination equipment there rather than simply to resell SBCÕsservice. The issue of incumbentsÕ unbundling obligations when they de-
ploy remote terminals is currently the subject of a pending FCC rule-
making proceeding.In the case of DSL, another major complication is that the individualwires connecting subscribers to central offices cannot be treated as en-
tirely independent of each other, as physical unbundling would imply.
As detailed in Chapter 4, crosstalk, the coupling of electrical signals be-
tween nearby wires, creates interference that can degrade the carrying
capacity of each copper pair, decreasing the data rates supported by a
given line length and decreasing the maximum line length over whichBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.184BROADBANDDSL can run. The interference effect depends on how the signals on thedifferent pairs make use of the different frequencies used for transmission
over the lines, which in turn depends on how the ILECs and CLECs make
and coordinate decisions about provisioning customers whose twisted
pairs share bundles. The problems will grow as the penetration of DSL
grows and as the higher data rates contemplated in the DSL upgrade
pathÑwhich are still more sensitive to interferenceÑbegin to be widelyimplemented. Coordination may be facilitated by technical standards,
which are in development, but which would, if adopted on a mandatory
basis, constitute a regulation of operational network technology. Such a
standard aims to achieve the sort of clean technological interface alluded
to above, thus reducing coordination problems. However, the more the
coordination problems are solved, the less the flexibility of the competitor
to differentiate its service, so in the end, physical-layer unbundling may
be no more attractive then simple resale, though much more complex.Implications for Investment by IncumbentsThere are major incentive issues that bear on expectations for overallinvestment and innovation. The analytical models used to justify forcing
incumbents to unbundle and sell access to network elements implicitly
assume that incumbentsÕ networks are based on a static technology and
involve only facilities already deployed. In reality, networks are con-
stantly being upgraded, and with the upgrades come new capabilities
and services. Competitors argue that incumbents should unbundle new
services and technologies and resell them, as they are required to do with
old services and technologies. Incumbents argue that they have no incen-
tive to invest in new facilities or otherwise innovate if they are forced to
sell their innovations at cost to their competitors. In particular, where
unbundling is mandated at regulated prices, the incumbent bears the risk
of investment but cannot fully benefit from it.Facilities-Based CompetitionUnder facilities-based competition, competitors go head-to-head, us-ing independently built and operated local access infrastructure.17 It is
widely believed by economists, policy officials, and consumer advocates17Facilities-based competitors may still make use of some facilities such as backhaul cir-cuits that are owned by other telecommunications companies, including the ILECs, and allfacilities-based competitors must at some point interconnect with the other ISPs that makeup the Internet.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION185that facilities-based competition is the preferred end state (with the pro-viso that it also results in a reasonably efficient result, which may depend
on the characteristics of the technology or market). A principal argument
is that facilities-based competition is the only circumstance that will per-
mit complete deregulation of local markets.In this view, competition though local loop unbundling or resale is atransitional approach to be used while facilities-based competition is still
developing. As new entrants grow and gain market share, they will find it
economic to replace facilities leased from incumbents with facilities leased

from nonincumbents or self-provided. (The cost of using an incumbentÕsfacilities is not just the price assessed for the network elements used, but
the ongoing difficulties associated with relying on a dominant competi-
tor.) In essence, resale and unbundling rules do not remove the need for
regulation, only shifting it from regulation of end customer prices to regu-
lation of prices charged by facilities owners to reseller-competitors. As
long as competitors are dependent on incumbents for some facilities, such
as loops, regulation of the terms and conditions of the competitorsÕ access
to those facilities, including price, will be required. Competitors are truly
independent of each other only if they have their own facilities (or access
to comparable facilities that are not controlled by a dominant competitor).
There is a fundamental tension between the short-run static efficiencies of
unbundling or resale and the longer-run dynamic efficiencies of facilities-
based competition. Forced unbundling or resale at regulator-mandated
prices may permit competitors to deploy innovative new services. How-
ever, such measures also could lock in the current situation, undercutting
the longer-term goal of full facilities-based competition, especially if the
rule is that competitors will be granted access at controlled prices to any
new facilities that an incumbent puts in place.Structural SeparationUnbundling and resale mandates are among a range of interventionsthat could be invoked to address the market power of incumbent tele-
phone companies by facilitating competitorsÕ access to upstream inputs
controlled by the incumbent. Several options would involve some sort of
separation of the incumbentÕs lines of business. The weakest form, non-structural separation, involves the use of accounting safeguards to sepa-
rate wholesale and retail operations. The most extreme mechanism, di-
vestiture, involves the spin-off of a unit into a separate corporate entity
that is under different control. Structural separation, between these two
in terms of the level of intervention, involves the separation of business
units into distinct corporate entities that remain under common control.
That is, an ILEC would be required to offer access to its facilities andBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.186BROADBANDservices at nondiscriminatory wholesale rates to nonaffiliated retail ser-vice providers as well as to its own affiliated providers.18Structural separation does not necessarily reduce the incumbentsÕ in-centives to discriminate against competitors or cross-subsidize, because
the two affiliated entities remain under common control. That is, the firm
as a whole still benefits if the wholesale entity discriminates in favor of its
retail affiliates and against unaffiliated retail competitors. (The incentive
to discriminate and cross-subsidize is only fully eliminated if retail opera-
tions are divested from wholesale.) But structural separation may dis-
courage the incumbent from engaging in such behavior by making the
transactions between the wholesale and retail entities easier for regulators
and other outsiders to monitor.To the extent that the structural separation approach succeeds, it hasthe potential drawback in the long term of decreasing the incumbentÕsincentive to upgrade the telephone plant because its ability to fully cap-
ture the benefits of that investment is constrained. Another potential
drawback of structural separation is that, if there are valid reasons for
vertical integration (e.g., reduction of transaction and/or coordination
costs), then separation could result in net higher costs for consumers. Past
history with unbundling and interconnection rules also suggests that sig-
nificant regulatory effort could be required to carry out structural separa-
tion. Finally, application of separation rules to the ILECs would also com-
plicate efforts to reconcile policy across broadband delivered by different
technologies or sectors of the telecommunications industry.How Much Competition Is Enough?Will facilities-based competition prove sufficiently robust to permitincreased deregulation of broadband and to forestall the need for future
retail regulation? If robust facilities competition were achieved, it might
be possible to back away from existing unbundling mandates,19 and it
might remove the impetus for initiating new mandates in the future (such
as those contemplated under the rubric of cable open access).In the case of broadband, technology options that provide a founda-tion for facilities-based competition are at hand. Two wireline technolo-18This is somewhat analogous to the separation that has occurred with electricity deregu-lation in a number of states, whereby the electric utilityÕs generation and distribution opera-tions are separated and customers can choose which generation company to purchase powerfrom.19The FCC has an unbundled network elements (UNE) remand process for removingnetwork elements from the list of required elements to be unbundled if they can reasonablybe self-provisioned or are available in the market.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION187giesÑDSL and cable modemsÑthat make use of distinct preexisting com-munications networksÑtelephone wires and hybrid fiber coax cable sys-temsÑare being deployed on a wide scale. The networks that they buildon provide access to the vast majority of the U.S. residential population,
though the cost and feasibility of upgrading to support data services vary
from location to location. A limited amount of facilities-based competi-
tion from new entrants is also visible. Companies are investing in Òover-buildÓ of incumbent cable providers to compete with them, primarily
using HFC. Two wireless technologiesÑterrestrial service using micro-wave transmission and two-way satellite serviceÑare being developedand deployed as well. The long-term economic viability of these competi-
tors is uncertain at present.The bottom-line issue with respect to evaluating competition is mar-ket powerÑwhether a company can keep its product price significantlyabove the competitive level. Associated with this are concerns that a com-
pany facing insufficient competition will let reliability and quality suffer
or will fail to deploy new services. Market power is assessed in terms of
characteristics of the market
Ñhow many competitors there are, what their
relative market share is, what the ability of competitors is to expand out-
put rapidly (using either current capacity or capacity that can easily be
expanded), and how easily new firms might enter the marketÑand indi-vidual firm conduct (whether it is anticompetitive). Some guidelines do
exist, such as those developed by the U.S. Department of Justice and the
Federal Trade Commission (FTC) for use in evaluating proposed merg-
ers, but the analysis in a merger situation is potentially different from that
involved in regulating an ongoing market. More generally, there is no
firm basis in economic theory to say how many competitors are ÒenoughÓin the abstract or across all markets or in all circumstances, and opinions
vary considerably. For example, in remarks before this committee, repre-
sentatives of consumer groups argued in the context of cable open access
that a choice among four providers might well be insufficient.Evolution in technology or business strategy could significantlychange the nature and terms of competition. For example, even if broad-
band access is itself reasonably competitive, a shift toward exclusive bun-
dling of content and search services with broadband access could lead to
the disappearance of stand-alone ISPs as broadband becomes the domi-
nant mode of Internet access. The supposition today is that the various
broadband technologies provide a similar service, an Internet-based plat-
form. However, both the technologies and associated business models are
malleable, so it will be important to track their evolution and interactions
over time to understand whether the different access technologies con-
tinue to be reasonable substitutes for each other, or whether technological
development or business strategies have caused them to diverge. SuchBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.188BROADBANDforces have the potential to lead to a more tiered marketÑor distinctmarketsÑin which different technologies and industries are associatedwith different kinds of service (e.g., different bandwidths, applications, or
prices).Finally, consumers with only one or two providers may derive spill-over benefits from competition in markets with more competitors, be-
cause marketing and pricing programs often do not have sufficient granu-
larity to discriminate in terms of price or quality between market type and
because of negative public reactions to highly differential pricing.Assessing the Degree of CompetitionPrecise data are limited, but the deployment numbers presented inChapter 1 of this report suggest that facilities-based competition in broad-
band is beginning to occur in the United States, with ILECs and cable
operators undertaking large-scale deployments in many locations across
the nation, and overbuilders entering a handful of markets. Wireless is an
alternative in several test markets, and satellite services offer another
option. However, overall availability masks considerable variability in
competition at a local levelÑby state, by community, or even by house-hold.It is a yet-unanswered but critical empirical question whether broad-band local access will turn out to be a natural monopoly (as telephony
was assumed to be for many years) in some or all markets. If so, it may
continue to be dominated by the incumbent telephone companies and
cable system operators, limiting facilities-based competition to at best two
players. The fact that facilities-based competition has proved difficult to
establish in the voice telephony markets that were the primary focus of
the 1996 act, especially for residential service, is not encouraging, but
there are differences between entry into a mature, saturated market and a
new, evolving one.At this point in time it is hard to conclude what the overall shape ofthe market will be. It is, however, apparent that there are some geographi-
cally defined markets that give rise to concerns about whether broadband
service will be available within several years and whether there will be an
adequate level of competition. In hard-to-serve areas, the sheer costs or
business risks may be great enough to call into question the goal of creat-
ing a competitive market. In these areas, the key goal may be providing
service at all. In deep rural areas, where costs are highest, it remains to be
seen whether the performance capabilities, costs, and ability to scale up of
the existing or planned satellite services will be sufficient to keep custom-
ers in deep rural areas at rough parity with others with regard to broad-
band access. Both the extent of coverage (in terms of geographical regionsBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION189and households) and the level of competition will be the subjects of con-tinuing scrutiny by public policy makers and other interested parties.
This suggests the ongoing importance of solid data, collected on a system-
atic basis, to identify where and what level of competition is being cre-
ated.Open Access and Evolving Complements toFacilities-Based CompetitionWhen cable operators began upgrading their systems to providecable-based broadband services, concerns were raised that they could
leverage their established cable television infrastructure and franchises to
exercise market power in broadband services. The position of incumbent
telephone companies could inspire similar concerns, but they have been
required to provide would-be competitors with access to their facilities
(via unbundling or resale), and public attention has been focused on the
cable system operators. The open access debate, which began in 1999, has
catalyzed involvement of consumer advocates, who had had a lower pro-
file in early- and mid-1990s debates about Internet policy, and has pro-
vided an important complement to traditional regulation in shaping
broadband policy. Critical actions were the merger oversight by the FTC
as well as the FCC and court decisions reviewing local efforts to require
open access.One aspect of the open access debate has been implementationÑhowto implement open access, what the actual extent of proposed technical
difficulties is, and how much the additional costs of supporting competi-
tive ISP access over cable facilities would be. When cable modem systems
were first developed in the mid-1990s, little thought was given to provid-
ing outsiders access to the systems or technology to implement such ac-
cess. The technical specifications were developed through industry stan-
dard setting, coordinated by Cable Laboratories and building on company
contributions of know-how. Cable Labs has since evolved those stan-
dards, which have become more supportive of open access, but its cable
industry orientationÑwhich contrasts with the more open, broad InternetEngineering Task Force that developed many of the InternetÕs core stan-dardsÑhas caused it to be viewed with suspicion by competitors andconsumer advocates. In light of the growing attention to open access,
cable operators have been exploring technical options for supporting ac-
cess by multiple ISPs. The goal of opening up an incumbentÕs facilitiescould, in principle, be achieved in several ways, either at a low level by
unbundling the physical links of the provider, or by unbundling some
higher-level service. Early on, low-level access to cable infrastructureÑfor example, allocation of different frequency bands to different provid-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.190BROADBANDersÑfell out of favor, and logical-layer access schemes, in which packetswould be routed to and from the appropriate ISP at the cable system head
end, have been adopted. There is general agreement that open access can
be implemented, and several pilot efforts have been conducted.A central feature in the open access policy debate has been uncer-tainty about business models for broadbandÑhow will cable providersbehave, and what do consumers want? In adding Internet services, cable
operators have had to evolve both their infrastructure and business mod-
els. At least initially, cable operators have tended to select a single ISP to
provide Internet service over their facilities, and the service has typically
been bundled with at least some content or services aimed specifically at
their own customers. This reflects in part an extension of usual cable
industry business practices to the new technology, but also the greater
ease that having a single partner can provide when entering a new, evolv-
ing market. In contrast, as critics frequently observe, much of the dial-up
ISP market has emphasized unrestricted access to Internet content (AOL,
which grew out of a closed content model, is the most notable exception,
but several others, such as MSN, have also based their strategies on a mix
of proprietary and Internet content).The open access debates have been informed by attitudes (positiveand negative) about entertainment industries in general (which are asso-
ciated with content generation and delivery) and television in particular.
Concerns have been expressed that cable operators will seek control over
the Internet content available to their subscribers in a fashion analogous
to what they exercise with conventional television content.One possibility is that particular content would be favored, to thedisadvantage of content from unaffiliated major content companies, niche
sources, or nonprofit organizations, through placement on start-up
screens, differentiated quality of service, or other means. Another is that
cable operators would go one step farther and create a Òwalled gardenÓservice in which outside content is difficult or impossible to access.20 The20A Cisco white paper (Cisco Systems, Inc. 1999. ÒControlling Your NetworkÑA Mustfor Cable Operators,Ó available online at <http://www.cme.org/access/broadband/
cisco_MSOs_white_paper.html>) promoted technology for cable companies to control,perhaps preferentially, content flows from different providers. The white paper addresses
cable operatorsÕ concern about bandwidth-hogging traffic from other content providers
and service quality in a context where the operator has arranged for supply of certainknown content and customer use of other content is unknown but could be large, while in
the short term network capacity is finite. It speaks to cable operatorsÕ concerns about
resource management by noting that Internet technology permits network resources to bemanaged. ÒSustained service quality over the long term requires IP network control, be-ing able to intelligently segment and manage resources by user type, service, destination,or application so that delivery quality does not suffer with growth or the addition of newservicesÓ (p. 2).
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION191term Òwalled gardenÓ arose in the ostensibly benign if parochial context
of cable marketing and of cable literature from the late 1990s. It has been
cited by consumer advocates as evidence of adverse intent,21 though the
kinds of preferences that may arise from a walled garden strategy can
also be viewed as similar to what has been seen elsewhere in television
and newspapers, namely, the use of a transaction with a partner to gener-
ate revenue that can lower the price charged to consumers and the pre-
selection of a menu of content deemed to be of greatest interest to con-
sumers. A walled garden is not, per se, hostile to consumers, because it
may lead to lower prices and increased content. The concerns about re-
stricted choice or walled gardens stem in part from the contrast with the
unfettered, unfiltered access to content throughout the network that has
traditionally characterized Internet services. Additionally, there are con-
cerns about media concentration and the relative market position of
broadband providers that also operate content businesses. Ultimately,
whether and how consumers can access content from other sources will
depend on the industry response to consumer demand (and the condi-
tions attached to industry acquisitions and mergers) unless public interest
is deemed important enough to mandate such access.There are also concerns that those cable operators who are in a mo-nopoly position in their market, which is the case in most markets, will be
able to charge other ISPs or content providers access fees that are higher
than the costs charged to ISPs or content providers affiliated with the
cable operator, giving the latter a competitive advantage. Concerns are
greatest for those affiliations that involve ownership (e.g., AT&TÕs inter-est in @Home or the AOL Time Warner combination). The ILECs, which
are required to unbundle their lines to permit resale competition, have
expressed the view that not imposing such requirements on cable repre-
sents an unfair advantage arising from asymmetrical regulation.Cable companies respond that open access requirements could deterthem from investing in system upgrades to support broadband if they
perceive the likely returns under open access conditionsÑconditions simi-lar to those faced by ILECsÑto be insufficient. These business judgmentsare commonly invoked as threats in a political process; they are, of course,
impossible to verify ex ante.In 2000-2001, the nationÕs two largest cable system operators agreedto provide customers a limited choice of ISPs. The rules under which this
will be done were outlined through conditions placed on the AOL Time
Warner merger by agreement with the FTC in 2001, which will be moni-21See, for example, Center for Media Education, 2001, Broadband Networks and NarrowVisions: The Internet at Risk, CME, Washington, D.C., available online at <http://www.cme.org/access/broadband/at_risk.html>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.192BROADBANDtored by an individual (trustee) appointed to do so. This potential tem-plate for the rest of the industry was hammered out under significant
pressuresÑabove all the threat of the merger being blocked if the FTCÕsconcerns were not addressed. Meanwhile, in 2001, AT&TÑprior to awholesale revision of its business planÑappeared to be moving towardopen access through its business strategy, influenced by regulatory and
legislative scrutiny as well as a larger transition in business emphasis and
strategy. 22
 This change in strategy, ironically, was initiated by AOL (as an
ISP) prior to its cable acquisition. Other cable operators may offer similar
terms to forestall the long-term threat of federal intervention in the cable
broadband business. In addition, overbuilders have begun constructing
hybrid fiber coaxial cable systems in some markets that ISPs will be able
to use to provide high-speed services.Whether this pattern of opening up will prove to be widespread andenduring remains to be seen. Already, similar activity has been stimu-
lated in connection with another Internet technology, instant messaging,
itself a factor in the governmentÕs approval of the AOL Time Warnermerger and an emphasis in the FCC investigation into the merger. The
evolving open access situation, which illustrates a government role differ-
ent from regulation per se, underscores the role of political activity in the
shaping of telecommunications outcomes. It raises the prospect of ISPs
making appeals to federal and state regulators to seek adjustments in
access terms and prices and to antitrust authorities. Under these circum-
stances, it is hard to ascertain what facilities operators or ISPs might do or
might have done ÒvoluntarilyÓ as their judgments about business oppor-tunities evolved.Access Issues in Multidwelling UnitsMuch of the debate about competition and open access assumed thatbroadband access is arranged at the sole discretion of the actual users. In
the case of multidwelling units (MDUs), the establishment of facilities-
based competition also depends on installation of new in-building facili-
ties or working out some form of shared access to this infrastructure.
MDUs, in which landlords may establish partnerships (including exclu-
sive ones) with broadband providers, have become a new battleground22For example, AT&T launched a recently concluded open access trial in Boulder, Colo-rado, at the end of October 2000 that connected eight ISPs: two AT&T affiliates(Excite@Home and WorldNet), two DSL providers (Winfire, Inc., and Flashcom, Inc.), two
national ISPs (EarthLink, Inc., and Juno Online Services, Inc.), and two local ISPs (RMI.net,Inc., and FriendlyWorks, Inc.) (ÒISP Offers ÔOpen-AccessÕ Plan; AT&T Begins Trial in Boul-
der,Ó Telecommunications Reports, November 6, 2000, p. 17).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION193for competitive and incumbent providers in both the residential and com-mercial markets. MDUs are an increasingly attractive and important early
market opportunity in university and many urban communities, which
are characterized by high-density housing, high density of broadband
customers, or both. The committee did not explore the multidwelling unit
issue at length, but notes that it is an area of ongoing debate over compe-
tition and access, particularly because these typically high-density situa-
tions are likely most attractive to would-be overbuilders.Landlord-provider arrangements can both improve the competitive-ness of real estate through improved telecommunications services and
provide an additional revenue stream through business arrangements
with providers. Not surprisingly, agreements often include exclusive ac-
cess provisions, raising concerns on the part of both tenants and other
providers about infringements on their access. Debate relates to access to
buildings by competing service providers, the latitude of building owners
vis-‹-vis tenants to control providersÕ access to their property and there-
fore services available to tenants, and the role of federal and state regula-
tors. CLECs and telecommunications equipment providers, for example,
have formed ÒThe Smart Buildings Policy ProjectÓ23 to address relevant
issues via lobbying.24 This group appears to be at odds with a new class of
providers that focuses on building access, BLECs (building-focused LECs),
which may receive some investment by building owners.25 Meanwhile,
building owners, with their own lobbying arms,26 argue that the issue
falls under a real estate rather than a telecommunications regulation re-
gime. Access and service issues also fall under the purview of local gov-
ernmentsÕ new municipal ordinances and cable franchising agreements.
The whole area of access in MDUs awaits possible direction and clarifica-
tion from the FCC and the courts.Access to Poles, Conduit, and Rights-of-WayAnother dimension of access is access to utility poles and conduits.Facilities-based wireline entrants cannot enter a market if they cannot
obtain access to the poles and conduits to install their facilities. Issues of
concern include prices, terms of access, processing time for an order, and
the rate at which access is provided. The situation is complex, with varied23See <www.buildingconnections.org>.24 ÒLawmakers Ask FCC to Hold Off on Building Access Rulemaking,Ó Telecommunica-tions Reports, September 4, 2000, pp. 9-10.25ÒBuilding Owners, Carriers Spar over FCC Proposal to Block Service, Extend Ban onExclusive Pacts,Ó Telecommunications Reports, January 29, 2001, pp. 27-28.26An example is the Real Access Alliance; see <www.realaccess.org>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.194BROADBANDownership arrangements (e.g., ownership by the electric utility or sharedownership between the electric utility and the ILEC); various cost-sharing
arrangements among users; and circumstances in which different rates
apply to ILECs, CLECs, and cable operators.27 The Federal Pole Attach-
ment Act28 in effect requires utilities to provide cable companies with
nondiscriminatory access to poles, ducts, conduits, and rights-of-way. It
gives the FCC jurisdiction to ensure reasonable rates and access terms
unless a state chooses to regulate these. Various state measures aim to
increase access. Municipalities also have several options for using their
control over rights-of-way to ease entry by new providers.EXPANDING ACCESS AND UNIVERSAL SERVICE POLICIESThe extension of universal service policies to new infrastructure net-works has generally enjoyed public support, as seen in the cases of the
Postal Service, electricity, and the interstate highway system, as well as
telephony. Because broadband technologies and services will not be de-
ployed everywhere at the same time and some areas will lag in service
availability and/or performance, policy makers almost certainly will face
claims from different sectors that they should intervene to ensure that
broadband services are available in a shorter time frame throughout the
country. It is important, therefore, to establish (1) where access is funda-
mentally constrained without government intervention, (2) who is not
likely to be reached after the broadest likely private sector deployment is
achieved, and (3) how and when to intervene.Rationales for InterventionGenerally speaking, competitive markets are assumed capable of de-livering the types and quantities of goods and services that consumers
desire at the prices they are prepared to pay. In some cases, however, a
competitive market may fall short of societal objectives, and governments
may act to promote some kind of equity when the efficient outcomes
associated with the market do not. A key premise of universal service
programs has been the assumption that access to the service is essential
for meaningful participation in the social, economic, and political sys-27Peter Blum. 2001. Pole Attachment Rules: Establishing a State Policy. Slides from briefing
to National Association of Regulatory Utility CommissionersÕ Summer 2001 Telecom Com-
mittee Meeting. Available online at <http://www.naruc.org/Committees/Telecom/pole_attachment.ppt>.28Section 224 of the Communications Act of 1934, as amended, 47 USC 224.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION195tems; drawing a similar conclusion with respect to broadband will, ofcourse, involve assessment of how functionality is tied to broadband ser-
vice and to what extent narrowband alternatives can substitute for broad-
band in providing socially desired services.The price of a good or service deemed essential or socially importantmay limit its accessibility to significant groups of consumers. For example,
the marketplace for food may be competitive, but government nonethe-
less may decide to intervene in order to ensure that low-income consum-
ers are able to buy enough to sustain themselves (e.g., through food
stamps).Consideration of the rural challenge, and contrasting it to certain ur-ban environments, highlights the fact that lack of deployment may reflect
either lack of demand or insufficient density for profits to motivate in-
vestment. Concerns about access can be lumped, roughly, into two cat-
egories: (1) that broadband services be available ubiquitously at some
reasonable price and (2) that broadband services be affordable to most or
all of the population. The appropriate interventions in a given location
depend in part on the regionÕs density and demand characteristics (seeTable 5.1). An affluent urban neighborhood might be characterized by
high density and high demand, while a poor urban neighborhood might
have high density and low demand. A typical rural area would have low
demand and low density, while a rural community with an active tech-
nology user base might have low density but high demand.Both of these concerns, together sometimes referred to as the ÒdigitaldivideÓ problem, have received national and global attention.
29 Access
and use disparities are difficult to gauge, because Internet access is chang-
ing comparatively quickly and because multiple, interdependent factorsTABLE 5.1Density and Demand Factors in Universal Access
High DensityLow Density
High DemandCompetition/marketUniversal service mechanisms, demand
solutions adequateaggregation, new technologies
Low DemandEconomic and community
development approachesMost challenging
29Global forums concerned with digital divide issues include the International Telecom-munications Union Development Forum, the European Union, and the G-8. U.S. founda-tions looking at digital divide issues include the Markle and the Benton Foundations.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.196BROADBAND(age, income, education, ethnicity, and so on) are associated with loweruse rates, and geographical disparities in access overlay these other fac-
tors. Density versus demand is just one possible decomposition of the
problem.ÒDigital divideÓ means different things to different people and in
different situations. There are many Òdivides.Ó On the technology supply
side, the term may refer to unmet demand for high-capacity long-haul
transport facilities, connections to the Internet backbone, as well as high-
speed local access facilities (DSL, cable, or wireless). To some customers,
digital divide means the time it takes to get a high-capacity T1 line in-
stalled, or the price to use existing services. To a business customer with a
business-to-business Web strategy, it means the need for redundant
backup facilities in case one access path is interrupted, for example by a
cable cut. Supply-side problems generally require approaches that en-
courage building facilities, either directly through application of funds or
indirectly by providing incentives or demonstrating or aggregating de-
mand to attract provider investment.On the demand side, digital divide may refer to having less access tocomputers, to Internet connections, and to training or content if one is a
rural resident, senior citizen, Native American or other minority, or in a
family with lower income. Demand-side strategies tend to be best ad-
dressed through a different set of strategies, including development of
locally useful content that stimulates increased interest and applicability,
creating community networking partnerships or providing public access
points or local training in a school, library, community center, or ÒcybercafeÓ that provides lower-cost alternatives to residential service. Such
efforts may also have to face another sort of digital divideÑdepending onhow such performance-enhancing elements as caches or content distribu-
tion systems are implemented, nonprofit groups may be at a disadvan-
tage compared with commercial producers that are able to pay more to
ensure quality of access to their content. These considerations may be
incorporated in economic development programs, although even experts
in rural technology deployment note that ÒinfotainmentÓ may be the most
important driver for demand.30Of course, supply-side and demand-side problems can be related.Low density makes it more expensive to build facilities. Lack of demand
makes it more difficult to recover the cost of building infrastructure. Eco-
nomic development programs (generally at the state and local levels)
naturally treat communications infrastructure, including broadband, as
an element of local economic development. Being more holistic in nature,30Andrew Cohill at June 2000 workshop of the Committee on Broadband Last Mile Tech-nology.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION197programs tend to combine cultivation of demand with provision of ac-cess, education, and opportunities; if successful, they increase willingness
to pay.Implicit Transfer Mechanisms Used for Universal Telephone ServiceIn contrast to programs for which support is explicit, such as the foodstamps program, the support schemes in the telephone industry histori-
cally relied on implicit mechanisms. The history of the telephone industry
shows that government intervention has helped to overcome actual or
perceived barriers of substantial cost differences among geographical ar-
eas as well as to enable basic telephone service access among qualifying
low-income individuals (e.g., through Lifeline and Linkup programs).
For context, note that nationwide telephone subscribership is between 94
and 95 percent, but the penetration level for households with annual
incomes under $5,000 is only 79 percent, as compared with almost 99
percent of households with incomes of at least $75,000 (a few of the high-
income houses may have opted for wireless service instead).31Over the years, although the goal of universal service remained acornerstone of state, and to a lesser extent, federal regulation, the mean-
ing of that term changed as the network evolved. In the 1920s and 1930s,
universal service probably meant a single telephone in a geographic terri-
tory. In the 1940s and 1950s, universal service may have meant access to
party-line service. In the 1960s and 1970s, universal service may have
meant access to single-line service. And, more recently, universal service
has been interpreted to mean touch-tone service and access to more ad-
vanced services.Stated simply, business long distance customers paid more for ser-vice and residential customers paid less for connections to the public
switched network. Similarly, rural customers paid substantially less than
did urban customers compared to the relative cost of their lines. One view
of this situation, commonly held, is that in each case, one group is subsi-
dizing the other. Other observers argue that it is natural that different
types of customers will make different contributions to the common cost
of the network.32 Whether one characterizes them as natural rate differen-
31ÒPhone Subscribership Holds Steady at 94.4%,Ó Telecommunications Reports, December18, 2000, p. 21, summarizing the FCC report Telephone Subscribership in the United States,which is available online at <www.fcc.gov/ccb/stats>.32See J.C. Panzar and S.S. Wildman. 1995. ÒNetwork Competition and the Provision ofUniversal Service,Ó Industrial and Corporate Change, vol. 4, no. 4, pp. 711-719. See also DavidGabel. 1999. ÒRecovering Access Costs: The Debate,Ó in B. Cherry, S. Wildman, and A.
Hammond IV, eds., Making Universal Service Policy: Enhancing the Process ThroughMultidisciplinary Evaluation. Lawrence Erlbaum Associates, Mahwah, N.J.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.198BROADBANDtials or implicit transfers, the following distinctions have been the subjectof telephone policy and practice:¥Business versus residential. Business customers typically are charged
higher rates for local telephone service than residential customers, even
though the cost of serving business customers frequently is lower (be-
cause they are located in areas with higher population densities). These
price differentials relative to other customers are justified on a variety of
grounds, including the Òpositive externalityÓ produced by maximizing
the number of customers connected to the telephone network. That is, the
value of being connected to the telephone network increases as more
subscribers are added. Also, because the existence of a business can de-
pend on communication, businesses typically value communications
more than residences do (including the value businesses attach to calls to
and from residential customers), and it can therefore make sense, even in
competitive markets, to set prices that reflect such different valuations.33¥Long distance versus local service. Typically, the largest single cost of
providing telephone service is the cost of the loop that connects a cus-
tomer to the first point of switching in the telephone network, the Òlocalloop,Ó the centerpiece of the last mile. The cost of a local loop is fixed (i.e.,
it does not vary with the number or duration of calls that are placed or
received, up to its full capacity). Because the local loop is necessary to
providing both long distance and local service (as well as any other tele-
phone-delivered services), its costs are common to both. Economists are
used to saying that there is no a priori appropriate way of allocating
common costs among the different products that are jointly supplied by
the associated assets.34 Historically, regulators required incumbent tele-
phone companies to recover part of the local loop costs from the flat-rated33While the elasticities of the different customer classes are not well understood, it islikely that this results in a situation where customers with the least elastic demands pay thehighest price, which is the general relationship that one gets with Ramsey pricing. An
interesting question is whether this could be a competitive outcome. Historical work byGabel and a formal model by Panzar and Wildman suggest yes, though elasticity was notan issue in the model. Furthermore, more traditional models of competition allow for price
discrimination. Baumol and Willig have argued in New Zealand regulatory proceedingsthat competition will necessarily generate Ramsey prices. (See Panzar and Wildman,  ÒNet-work Competition and the Provision of Universal Service,Ó and Gabel, 
ÒRecovering AccessCosts: The Debate,Ó 1999.)
34In most economic markets, the various products produced with common assets allmake contributions to the common costs. Thus, for motion pictures, the fixed cost of pro-
ducing a film is covered by earnings from theaters, videocassettes, pay television, and over-the-air broadcasting, not to mention foreign markets.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION199monthly charges assessed to end users for local service, part from theshort-haul toll rates paid by end users, and the balance from per-minute
access charges paid by carriers providing interstate and intrastate long
distance service. The precise manner by which the common costs are
allocated will have differentiated impacts on consumers. While it has the
effect of holding down the price of telephone service for those who place
few long distance calls, the practice of recovering part of the fixed cost of
the local loop from usage-based prices, some observe, has been inefficient
and has artificially depressed demand for long distance service.¥Urban versus rural. The cost of providing local telephone service tourban customers is generally lower than the cost of serving rural custom-
ers. The higher population densities enable a telephone company to serve
a greater number of customers from a single switch, and the loops con-
necting an end user to the first point of switching generally are shorter in
urban areas. At the same time, this factor may be offset owing to the
greater benefit obtained from technologies that overcome distance and
dispersion, and there may be more willingness to pay by rural users,
other things equal, given perceived value.35 Federal and state regulators
traditionally have implemented complex cost and price averaging and
other policies to maintain prices for basic telephone service in rural and
other sparsely populated areas at levels comparable to and often even
lower than those paid by subscribers in urban areas.36 State regulators
historically required telephone companies to average their rates over large
geographic areas so that customers in densely and sparsely populated
areas paid the same rates.37 High-cost programs transfer funds for the
purpose of providing service in low-density, expensive-to-serve areas.
Because they support the upgrade of telephone facilities, high-cost funds
can also indirectly contribute to increased DSL availability as well as
increasing dial-up modem line speeds.3835As noted by Richard Civille in his remarks before the committee in June 2000.36Full parity is not the goal. For example, rural customers have much smaller local callingareas (the areas in which local calls are covered by the monthly flat rate) and as a result maypay much higher total bills.37Some rural states adopted forms of rate deaveraging by, for example, requiring custom-ers in some areas to pay a Òzone chargeÓ in addition to the averaged, basic rate.
38An area of current debate is whether the high-cost fund should be explicitly expandedto cover broadband (and, a related question, whether caps on these funds should be relaxedto support advanced services build-out). Proponents of such changes argue that they arevaluable mechanisms for enhancing rural infrastructure. For example, the Federal-State
Joint Board on Universal ServiceÕs Rural Task Force recommended that the FCC adopt aÒno barriers to advanced servicesÓ policy that would permit high-cost funds to be used in
ways supportive of providing advanced services, including reducing loop lengths, remov-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.200BROADBANDThese support mechanisms have gradually been reformed in variousways following passage of the Telecommunications Act of 1996 (e.g., a
shift from usage rates to flat rate recovery). But they still depend in part
on one form or another of implicit transfer and still reflect assumptions
about technology and the market more rooted in voice than in broadband
services. The sustainability of implicit support schemes is in question
when those services are not provided on an integrated basis by a regu-
lated monopoly. Entrants will tend to target the ÒsubsidizingÓ customers,
since the new entrants are not required to offer service at ÒsubsidizedÓrates and, consequently, the price they must offer the existing Òsubsidiz-ingÓ customers need only be lower than the incumbent
Õs price includingthe subsidy, all other things being equal. Similarly, entrants will tend to
ignore the ÒsubsidizedÓ customers because the price they must offer those
customers must be less than the incumbentÕs price, including the subsidy.A very substantial part of the challenge that the FCC and state regulators
face in opening local markets to competition is the need to reform the
historical system of implicit support to make universal service support
compatible with competition. Universal service is not inconsistent with
the introduction of competition, but the historical scheme for maintaining
universal service is inconsistent with competitive markets for local ser-
vices. The issue of which firms should contribute (and benefit from) uni-
versal service funds is, not surprisingly, a subject of ongoing political and
regulatory debate. Despite these drawbacks, proponents of implicit sup-
port mechanisms note that by virtue of the internal, largely unseen trans-
fers, these mechanisms have the advantage that they may be less-politi-
cized and more-stable sources of funding.Other Mechanisms for Increasing Access to BroadbandLoans and GrantsOne avenue being pursued by governments, foundations, corpora-tions, and civic groups is partnering to leverage resources and carry out
programs that expand access for underserved rural and urban popula-ing bridge taps, and otherwise upgrading the network to support DSL (Rural Task Force,Federal-State Joint Board on Universal Service, 2000, Rural Task Force Recommendation to theFederal-State Joint Board on Universal Service, submitted to the Federal Communications Com-mission under CC Docket 96-45, Sept. 29, available online at <http://www.wutc.wa.gov/
rtf/rtfpub.nsf>). Critics question whether the program should be expanded beyond tradi-tional telecommunications services, and the impact of any increased transfer of funds fromlow-cost to high-cost areas.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION201tions. Loans or matching grants could be considered for other instances ofcommunity-initiated efforts to develop local broadband networks.Programs of telecommunications regulatory agencies are comple-mented by other kinds of programs that may also contribute to connectiv-
ity as part of a broader set of programs that support economic develop-
ment and quality of life in underserved areas. The federal government
has supported community access through the Department of Housing
and Urban DevelopmentÕs Neighborhood Networks program39 and the
U.S. Department of EducationÕs Community Technology Center grants.40The Rural Economic Development Act of 1990 (P.L. 101-624) created theRural Development Administration within the U.S. Department of Agri-
culture (USDA), which has other relevant entities and programs, and the
Rural Electrification Administration makes loans and provides technical
assistance to rural telecommunications providers. For example, the
USDAÕs Rural Utilities Service41 supports rural electricity, water, and tele-
communications infrastructure through loans, grants, and technical guid-
ance. The Rural Utilities Service launched a 2001 pilot program to provide
$100 million in 10-year loans to companies building broadband infra-
structure in rural areas. The program is targeted to communities with up
to 20,000 residents, and following the FCC lead, uses a 200-kbps transmis-
sion threshold to qualify for broadband status.42 Telephone cooperatives
provide telephone service and a range of data services in a number of
rural areas, and rural telephone companies have been active in deploying
broadband services.43 Cooperatives can help aggregate demand across a
widely distributed set of customers.44 There are also focused cooperative
39See <http://www.hud.gov/nnw/nnwindex.html>.40See <http://www.ed.gov/offices/OVAE/CTC/factsheet.html>.41According to 7 CFR ¤1735.10 (a), ÒThe Rural Utilities Service (RUS) makes loans tofurnish and improve telephone service in rural areas. Loans made or guaranteed by theAdministrator of RUS will be made in conformance with the Rural Electrification Act of1936 (RE Act), as amended (7 U.S.C. 901 et seq.), and 7 CFR chapter XVII. RUS provides
borrowers specialized and technical accounting, engineering, and other managerial assis-tance in the construction and operation of their facilities when necessary to aid the develop-ment of rural telephone service and to protect loan security.Ó See <http://www.usda.gov/
rus>.42ÒRUS Sets $100M for Rural Broadband Rollout,Ó Telecommunications Reports, December11, 2000, p. 7. See also <http://www.usda.gov/rus/telecom/initiatives/initiatives.htm>.43National Exchange Carrier Association (NECA). 2000. NECA Rural Broadband Cost Study:Summary of Results. NECA, Whippany, N.J. Available online at <http://www.neca.org/broadban.asp>.44Richard Civille, Michael Gurstein, and Kenneth Pigg. 2001. ÒAccess to What? First MileIssues for Rural Broadband,Ó white paper; see Appendix C.  See also the National Tele-
phone Cooperative Association <www.ntca.org>, which publishes Rural Telecommunications.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.202BROADBANDfinancing organizations.45 Finally, a variety of corporate initiatives have
also provided support for community network access.The federal government has also intervened in the form of the e-rateprogram, originating in the Telecommunications Act of 1996 and launched
in 1998, to provide funds (partial or matching support) for high-speed
access for schools, libraries, and health care facilities.46 The e-rate pro-
gram uses funds raised from taxes levied on particular communications
services to expand public access broadband services through these facili-
ties. The program is associated with significant increases in school con-
nectivity, where its influence has been to accelerate, enhance or comple-
ment, or enable that connectivity, and there is evidence that it is
supporting increases in the bandwidth of connections sought by schools
(e.g., movement from Òplain old telephone serviceÓ to T1 and then T3
lines).47Local points of presence and applications have also been supportedthrough an evolving effort that has been more like a demonstration pro-
gramÑthe Technology Opportunities Program (TOP) (originally the Tele-communications and Information Infrastructure Assistance Program)Ñatthe U.S. Department of CommerceÕs National Telecommunications andInformation Administration (NTIA). The program began in 1994 and fo-
cuses on model uses in public sector and nonprofit contexts. Whereas
some $2 billion have been awarded under e-rate, TOP awards total about
$150 million.48 Collectively, these programs increase awareness, foster
deployment and use, and extend broadband beyond those consumers
most likely to go after it on their own.Tax IncentivesAnother option for promoting access is to provide tax incentives forinvestment in high-cost areas. Tax options to promote broadband deploy-
ment in high-cost and/or low-income areas are appealing on two grounds.
First, they avoid long-recognized economic distortions associated with
funding universal service goals through revenues raised by taxing certain
services within the specific industry (the approach used for basic tele-45See National Rural Utilities Cooperative Finance Corporation (<www.nrucfc.org>) andits affiliates.46E-rate involves discounts on eligible facilitiesÕ purchases of telecommunications and
Internet services plus internal networking, with discounts varying with location (e.g., high-cost, low-income).47ÒTelcos, System Integrators See Rising ÔE-rateÕ Revenues,
Ó Telecommunications Reports,September 11, 2000, pp. 46-48. ÒPoorer, Larger Applicants Get More ÔE-rateÕ Funds, Study
Finds,Ó Telecommunications Reports, September 18, 2000, p. 29.48See <http://www.ntia.doc.gov/otiahome/top/grants/briefhistory_gf.htm>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION203phone services, and now, through the e-rate, for broadband connectionsto schools and libraries). Such levies applied selectively within an indus-
try can distort relative prices and, thereby, choices made by the users of
communications services.49 Selective, within-industry levies of this type
also may create financial incentives for investments in economically inef-
ficient facilities and services that bypass the providers and services sub-
ject to the internal tax. Thus, ILECs have frequently argued that many of
the investments in network facilities by CLECs were motivated by the
financial payoff to be realized by providing long distance carriers and
local businesses with the opportunity to avoid local access charges; simi-
lar thinking for plans to use cable plant to offer local service was also one
of the reasons AT&T offered for its purchase of cable operator Tele-Com-
munications, Inc. (TCI). Investments motivated by the avoidance of extra
charges created by policy interventions rather than the pursuit of produc-
tion cost-driven competitive advantage are inefficient and a waste of soci-
etal resources. Tax credits (and other subsidies such as the high-cost fund
support mechanism) still may provide incentives for what is ultimately
uneconomic activity.Second, reliance on tax credits to finance broadband deploymentwould mean that the federal government would have to consider the
financing of communications policy goals in the context of the larger set
of societal trade-offs that necessarily must be addressed in setting and
allocating federal budgets. To the extent that tax credits are used, they
would put the financing of communications policy goals squarely within
the traditional budgetary process. This might force a better integration of
communications policy goals into the larger set of societal goals addressed
through various types of federal funding, so that the relative merits of
communications policy goals might be appropriately assessed in com-
parison with other social policy goals in the allocation of scarce govern-
ment resources. Because telecommunications spending would compete
against many other interests, it might also mean less-stable funding for
telecommunications programs.VouchersAnother way of putting financing Òon the booksÓ is to issue vouchers,
similar to food stamps. As a budget line item, a voucher program is even49For example, contributions to the universal service fund have traditionally been builtinto charges that long-distance carriers pay local exchange carriers for completing their
calls over local networks. Because such policy-driven charges must necessarily be recov-ered in the price of long-distance calls, the price of long distance increased relative to theprice of local service and other communications services.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.204BROADBANDmore evident in the decision-making process. Broadband-specific vouch-ers might be a useful tool for promoting broadband penetration. It is
important, however, that such vouchers be targeted as narrowly as pos-
sible to specific groups of consumers (e.g., low-income consumers or those
living in high-cost service areas) who are not likely to subscribe in the
absence of such aid. There is little point in subsidizing purchases that
would be made without the subsidy. Vouchers are especially attractive in
situations in which infrastructure deployment is not an issue (service
providers already have an incentive to build out an area), but to which
some subset of potential customers in a built-out service area would not
subscribe at prices that service providers would have to charge to cover
their costs.50 In these circumstances, a voucher can be a highly specific
instrument for encouraging subscriptions that would not happen other-
wise. It is less clear that vouchers have advantages over direct payments
to service providers if the goal is to promote infrastructure deployment in
areas that might not otherwise be served. To the extent that providers
might compete to offer services to customers in such areas, there is the
danger that competitive lowering of service prices would transfer some
portion of the voucher to consumersÕ pocketbooks rather than to covering
infrastructure expenses. A more efficient approach in these areas might
be to let providers bid for the right to serve these territories.Research to Develop Technology AlternativesFinally, there is the option of supporting research as a means of pro-moting access. Much of the excitement associated with progress in broad-
band technologies and the diffusion of fiber builds on research and devel-
opment that has enabled new technological approaches and/or lowered
the costs or increased the performance of existing approaches. The federal
government is key in supporting basic research and fostering public dis-
semination of the results of research. Units of the U.S. Department of
Defense (notably the Defense Advanced Research Projects Agency, or
DARPA), the National Science Foundation (NSF), and other federal orga-
nizations are key supporters of communications R&D. Most of that R&D
recently has focused more on technologies and components that enhance
network backbones or development of applications that run over high-
speed networks than on local access networks. But DARPA has had a
program aimed at fiber in the distribution network, and NSF and DARPA
have supported a variety of wireless networking research.50Note that, from a life-cycle or total cost perspective, decreases in the cost of equipmentassociated with use of broadband, ÒCPE,Ó will also affect willingness to pay for service.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION205Looking ForwardFor policy makers, the threshold issue is how to determine whethergovernment intervention to accelerate broadband deployment is neces-
sary or desirable. It appears that the problem is not whether most areas
will ultimately have some form of broadband service, but rather that in
rural areas deployment will occur well after such services are available in
more densely populated areas or that the technology options and/or per-
formance will be different in rural areas.The leading broadband technologies today (in terms of installed baseand technology maturity) are both wire-based, and it seems likely that for
the near term at least, distance and population density will deter their
rapid deployment in remote or sparsely settled areas. Because of the
added per-passing cost of serving rural areas, different kinds of technical
strategies may need to be sought there as compared with those for other
(denser) areas; an example would be greater emphasis on wireless links
from residences to a fiber backbone (possibly leveraging local govern-
ment or electric and water utility rights-of-way).51 With broadband satel-lite servicesÑwhich may be able to serve these areas more cost-effectivelythan the wireline alternatives couldÑhaving recently been introduced tothe market, one finds a situation where there is some form of broadband
available in even the most remote areas of the continental United States. It
is also encouraging that the initial offering prices of the Starband service
suggest that the Òrural penaltyÓ may be small (recurring charges for satel-
lite service at $60 per month versus the $30 to $50 per month typical of
cable or DSL). However, it is unclear at this point whether these services
will be able to achieve and maintain sufficient performance levels to serve
as adequate substitutes for the functionality of wireline services, or how
their cost and price will compare in the long run with wireline service in
more densely populated areas.At todayÕs broadband penetration levels, it seems premature to makeconclusions about the shape of deployment. Consumer technologies gen-
erally display an S-shaped adoption curve, which is marked by an initial
period of slow adoption, followed by more rapid expansion, and, finally,
a leveling off of adoption in the later stages. In the case of narrowband
Internet access, NTIA data collected over the past half-decade show that
overall access has expanded greatly and that some disparitiesÑsuch asacross sex and race/ethnicityÑhave narrowed over time, primarilythrough expansion of dial-up household access and access in the work-
place or public facilities. However, this access has largely leveraged near-51See Civille et al., ÒAccess to What?,Ó 2001.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.206BROADBANDubiquitous public telephone network lines, and thus, with the exceptionof some instances where line quality is very poor, has not been hampered
nearly as much by technological and economic constraints on where and
when new facilities are deployed as broadband would be. Widespread
dial-up use suggests that wide segments of the population find Internet
access to be of value, and thus suggests widespread demand for broad-
band. In the case of residential broadband, deployment has been growing
rapidly from a presently small base, from which vantage point it is hard
to infer the long-term adoption rate, patterns of availability, or the ulti-
mate level of adoption.To the extent that policy makers are simply uncertain about the paceof broadband deployment, the benefits of government intervention to
accelerate that process would have to be clear and substantial in light of
the risk that such intervention may have unintended and undesirable
consequences. Although government policies likely contributed to the
high penetration of telephone service in rural areas, application of such
policies to broadband could, in theory, deter future entry by competing
broadband providers that cannot match the below-cost rates resulting
from averaging and other distributional policies. Another risk is that by
picking particular technologies or defining particular services, some gov-
ernment programs aimed at bringing a technology to all may end up
freezing the technology deployed. Policy makers seeking to promote
rapid, efficient broadband deployment should assess the effectiveness of
strategies that help avoid these risksÑincluding demand stimulation andaggregation, grant and loan programs, and municipal initiatives fostering
market entry and competition. This analysis would require policy makers
to collect and review reliable broadband data on an ongoing and timely
basis. The development of a comprehensive, national universal service
program may well become desirable in the future, once the pace and
scope of broadband deployment become clearer.THE LOCAL ROLE IN BROADBANDSeeking to accelerate or enhance the delivery of telecommunicationsservices in their communities, a number of cities, counties, and states
have considered or launched initiatives aimed at facilitating, encourag-
ing, or directly building infrastructure for broadband. Historically, the
direct local role with respect to telecommunications has been limited
largely to negotiating cable franchises. In addition, local governmentsÑabsent preemption from higher levelsÑhave control over local features ofthe deployment environment, such as public rights-of-way, zoning, per-
mitting, and so on. These practical issues affect decisions about special
facilities, such as Òcarrier hotelsÓ and data centers. Local government
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION207influence has been expressed in conflicts over siting for terrestrial wire-less towers and satellite dishes. Local governments also control access to
rights-of-way and proposals for local investment in conduit that can be
deployed once and that contain cable or wire supporting multiple provid-
ers and services. Today, communities are exploring how to use these
points of leverage as well as other mechanisms and incentives to promote
broadband deployment.Local governments have a direct interest in neighborhood, commu-nity, municipal, and regional infrastructure, and it is within the commu-
nity that existing government, corporate, university, and school networks
are deployed. Local governments may be in a better position than na-
tional providers are to collect and verify local marketplace information,
such as discovering and/or aggregating latent demand for broadband
services, and these governments involve people whose jobs involve satis-
fying local interests. Indeed, where local entities have moved to provide
local infrastructure, it has typically been when no commercial firm was
willing to invest in a given community.Local initiatives are not without their critics, however. For instance,while local decision makers may see benefits from broadband, it can be as
hard for them as for service providers to predict and elicit consumer
demand52 and design sustainable business models for municipal broad-
band enterprises. Telephone and cable incumbents tend to protest local
efforts to serve more than government users with services procured or
provided by government entities.53 Critics also argue that locally based
efforts are less likely to be commercially sustainable in the long run, suf-
fering regularly from lack of access to capital to support upgrades. Local
efforts may also have insufficient economies of scale to be viable in the
long run, and risk becoming overly politicized.Local and regional broadband initiatives cover a wide range of possi-bilities, from focusing on local government infrastructure to facilitating
access for the community at large. Local approaches vary for obvious
reasonsÑsize, local market desirability, and whether existing providershave been introducing broadband service. This variation may ultimately52Civille et al. (ÒAccess to What?,Ó 2001) argue for demand cultivation in combination
with access promotion through community economic development programs. Their ac-knowledgment that growing demand may take workÑthat simple access is not sufficientÑimplicitly supports the view that accelerating deployment is risky.53ÓPrivate-sector carriers say they shouldnÕt have to compete with the entities that regu-late their rates, grant them operating certificates and franchises, control their access to vital
rights-of-way, and tax themÓ (ÒCommunity Size: The Difference in CitiesÕ Telecom
Choices?Ó Telecommunications Reports, December, 4, 2000, pp. 36-38).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.208BROADBANDlimit what can be learned or replicated from any specific instance, but aninformal network of supporters of local efforts has fostered the exchange
of relevant information, including approaches to architecture, contract-
ing, and financing, to maximize opportunities for local officials to learn
from others.54The examples listed in Box 5.2 indicate the sorts of initiatives thathave been undertaken at the local or regional level.55 They include, for
example, public operation of a multiservice network, where a municipal
or county agency is the operator, providing retail services to the end user.
Municipal service monopolies are not unusualÑwater or sewer authori-ties are the dominant model, and public power utilities are found in a
number of localesÑbut the high level of complexity and rate of change intelecommunications technology compared with water or electricity sup-
ply pose a risk. And as noted above, this approach may raise objections
from private sector providers, who see the public service as being unfairly
subsidized. However, if there is no private sector provider on the horizon,
it may be an attractive option.Another option is some form of public-private partnership. Again,this raises concerns about the risk in a government bodyÕs entering intowhat may be a long-term relationship with a selected private sector player.
If the relationship sours, it may be difficult to replace the private sector
player. This sort of approach runs the same risk as that with exclusive
cable franchisingÑcommunities may derive revenue or other benefitsfrom the arrangement, but the partner may not deliver the level or quality
of service desired. Additional complications arise if the public sector has
contributed funding to the venture.The drawbacks of the approaches listed above argue that local gov-ernments concentrate on taking steps to encourage and facilitate com-
petition among private sector players rather than creating new quasi-
monopolistic entities. As a public sector partner with multiple private
providers, a public agency would not be competing with a private sector
retail service provider. Another advantage of this strategy is that it means
that private sector providers do not have to negotiate with each other to54One ongoing effort that attracted the attention of this committee has been the work ofBill St. Arnaud as part of CanadaÕs CANARIE program. See <http://www.canarie.ca/>.55The Community Broadband Deployment Database, established by the National Regu-latory Research Institute at Ohio State University for the Federal Communications Commis-sion, lists more than 200 community broadband programs, covering a range of technolo-
gies, target user groups, and funding sources. See <http://www.nrri.ohio-state.edu/programs/telcom/broadbandquery.php>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION209obtain access to facilities, which reduces the need to regulate their con-duct.Easing access to rights-of-way is the simplest step, but this may not beenough to induce new entrants. Another option is for a local or regional
government agency to install fibers (or conduits through which fibers can
later be pulled) and use this investment to lower the barriers to entry by
private sector players by making the infrastructure available to them.
This approach can be implemented in a number of ways. One is the ÒfibercondominiumÓ model, in which a locality declares its intention to build
out fiber along its streets and invites any interested parties to purchase
some share of the fibers installed (and possibly installs additional dark
fiber for future use). Typically, some provision is made to lease colocation
space for service providers at the fiber termination points. Alternatively,
the locality may enter into partnerships with one or more private sector
companies to install (and possibly maintain) the fiber. The town itself can
sign up, as can schools and municipal departments, businesses and other
private sector players in the town, citizens themselves, and any interested
broadband providers. The locality provides the motivation and coordina-
tion for joint actionÑit shares in the cost of the common construction, butit may also prohibit the digging up of streets again for some period after
the construction. By avoiding the extra cost of uncoordinated overbuild-
ingÑkeeping down the per-passing costsÑthis approach attempts to pro-vide competition at per-passing costs comparable with those of a single
provider. Local and regional government or quasi-governmental agen-
cies can also act in effect as anchor tenants that underwrite some of the
cost of installing infrastructure, reducing the costs for other government
agencies, private sector firms, or even individual customers. The conse-
quence of this action is that more providers may be motivated to enter the
market in the town.Finally, localities may choose to launch experimental pilot projects toexplore new technologies, system architectures, or business models. State
or federal grants can help support communities exploring options or en-
able them to purchase facilities that today are more costly than they will
be in the future when suppliers are able to achieve scale economies in the
production of such equipment. Such pilot efforts can demonstrate the
viability of systems, demonstrate the extent of demand for them at the
local level, and support achievement of scale in use, either by closing
access gaps or increasing interest in use. The state or federal role is appro-
priate, given that results of the experiment can help inform future private
sector or public sector initiatives using similar systems. New develop-
ments can also build in broadband infrastructure, as is beginning to hap-
pen (Box 5.3).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.210BROADBANDBOX 5.2Some Examples of Municipal and Regional Broadband Initiatives¥Blacksburg, Virginia. The Blacksburg Electronic Village (BEV) initiative began in1991 with a public-private agreement between the town of Blacksburg, Bell Atlantic (nowVerizon), and Virginia Polytechnic Institute and State University. When service launchedin 1993, BEV provided Blacksburg residents with dial-up access. Also, starting in 1994,
integrated services digital network (ISDN) and Ethernet have been made available to anincreasing number of townhomes and apartments. Because dial-up access became avail-able from commercial providers, BEV turned over its modem pool customers to the private
sector in 1995, and similarly transferred its Ethernet operations to the private sector in1998. At present, 87 percent of Blacksburg residents are online, according to BEV infor-mation. Currently, efforts are under way to develop a townwide all-fiber network, to inte-
grate wireless with wireline services, and to develop a broadband switch point and ex-change for advanced network services. BEV was prevented from extending service tosurrounding areas because, after industry lobbying, a law was passed to preclude this
government service provider role.1¥Abingdon, Virginia. In December 1995, a group of citizens met to discuss thepotential of providing residents of Abingdon with high-speed Internet connectivity. These
activities led Ôto the launch of the Electronic Village Abingdon (EVA) initiative. In additionto modem and ISDN connections, a fiber-optic connection from the town managerÕs of-fice to the hospital and the Washington County Main Library was established as a partner-
ship between the Town of Abingdon and Sprint. On the basis of results of early trials, theproject was expanded. During Phase I, EVAÕs fiber-optic service was extended in thedowntown area, providing high-speed connections to every building within 150 feet of
the fiber backbone. Phase II, under way in 2001, is a collaborative effort with HighlandsUnion Bank to extend the fiber-optic cable toward the west of Abingdon. The networkprovides 10-Mbps connectivity within the town network and Internet connectivity at 1.54
Mbps. Subscribers need to purchase a fiber-optic transceiver (about $150) and pay a one-time installation charge of $75. Monthly access fees are $35 per month for 10 Mbps anda single Internet Protocol (IP) address. Recently, 100-Mbps service has been added for $70
per month.2¥Berkshire County, Massachusetts. Berkshire Connect was established through a
1997 grant of $250,000 from the Berkshire legislative delegation and the Berkshire Re-
gional Planning Commission. A project task force committee, with representatives fromcultural institutions, local businesses, public access organizations, and local business con-sultants, was established to propose a strategy for enhancing Berkshire CountyÕs infrastruc-ture and to reduce the cost of networking government agencies. The original strategycalled for Berkshire Connect to partner with the private sector and use a mix of public andprivate funds to build the infrastructure, but Global Crossing/Equal Access, the winning
bidder, agreed to build the infrastructure without using public funds. The agreement estab-lishing the service offers volume pricing, with prices for all members decreasing as moresubscribers sign up. Berkshire Connect competes with the incumbent LEC, Verizon, in1Blacksburg Electronic Village (BEV). 2001. ÒAbout the BEV.Ó Available online at <http://www.bev.net/
project/brochures/about.html#2>.2See the Electronic Village Abingdon home page online at <http://www.eva.org/>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION211both the retail and wholesale markets, though it claims more success in the wholesalemarket (providing backbone services to other providers). Berkshire Connect does not offerresidential or last mile service at present, but is currently working to define a business
strategy for last mile service. It is also exploring new business relationships with otherMassachusetts regional networks.3¥LaGrange, Georgia. Through the LaGrange Internet TV initiative, the City of
LaGrange, Georgia, provides Web access to all cable television subscribers in this com-munity of 27,000 residents. In 1998, Charter Communications, Inc., and LaGrange en-tered into a leaseback agreement in which the city financed and constructed a two-way
hybrid fiber coax network (using city funds, without state or federal support). Using World-GateÕs Internet on EVERY TV Service, it allows LaGrange cable TV subscribers to haveWeb access at no additional cost.4¥Glasgow, Kentucky. In 1994, as Glasgow was being wired for cable, town officialsdecided to facilitate Internet traffic via cable as well. The 12-year-old Glasgow fiber-opticsystem, one of the first of its kind, provides relatively inexpensive cable and high-speed
Internet services to 8,000 homes and businesses, or two-thirds of the local market forcable. According to its managers, it has broken even for the past 4 years. Proponents notethat the network has been moderately successful in spurring local economic activity. For
example, Franchino Mold & Engineering Co. is cited as having opened a new facility inGlasgow in 1998, in part because the cityÕs network allowed for an easy exchange of datawith engineers at the companyÕs Lansing, Michigan, headquarters. Two-thirds of Glas-gowÕs businesses and a quarter of its residences now pay for broadband cable. The townÕsnetwork connectivity is also used for a variety of other functions including controllingtraffic lights, coordinating utility repairs, and plotting school bus routes.5¥Washington County, Ohio. Seeing inadequate broadband facilities in the county,the nonprofit Washington County Community Improvement Corporation (CIC) launched anonprofit corporation, Sequelle, to provide terrestrial wireless broadband communica-
tions to southeastern Ohio and the mid-Ohio Valley region, targeting business and educa-tional customers. Using a mixture of state and federal startup funds, it plans to launchservice in 2001.6¥Chicago, Illinois. ChicagoÕs CivicNet is a citywide initiative to build a new broad-band infrastructure for government, businesses, other institutions, and residents. The cityplans to use the $32 million it spends each year on voice and data communications to
become an Òanchor tenantÓ for a high-speed fiber-optic network, to be constructed in
partnership by one or more lead technology vendors. The city also plans to make city-owned or -controlled conduits and tunnels available to reduce installation costs. The3Sources include the Berkshire Connect home page, which is available online at <http://www.bconnect.org/>; ÒFCC Hearing, May 22, 2000,Ó which is available online at <http://
www.bconnect.org/FCChearing5_00.htm>; and a personal communication with Bill Ennen, Donahue
Institute of the University of Massachusetts, April 19, 2001.4See <http://www.lagrange-ga.org>.5See David Armstrong and Dennis K. Berman, 2001, ÒMunicipal Networks Become Rivals for Fiber-optic Telecom Companies: Dissatisfaction Spurs Competition,Ó CNBC and The Wall Street Journal,August 17. Available online at <http://www.msnbc.com/news/615215.asp#BODY>.6For more information, see the Sequelle home page online at <http://www.sequelle.com/>.continuesBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.212BROADBANDultimate goal is for fiber networks to extend to every neighborhood, and ultimately downevery street.7¥Lane and Klamath Counties, Oregon. The Lane Klamath Regional Fiber Consor-
tium, formed by Lane and Klamath Counties and the cities of Coburg, Chiloquin, KlamathFalls, Lowell, Merrill, Oakridge, Springfield, and Westfir, negotiated joint agreements withPacific Fiberlink (now Worldwide Fiber). In return for assistance with permitting and an
exchange in lieu of right-of-way fees, the local governments received 12 strands of fiberinstalled in a contiguous strand extending approximately 200 miles from Coburg to Mer-rill, with points of access in the cities and significant county points along the route. Con-
sortium members plan to use this fiber to increase communication opportunities to all theresidents along the route and in communities adjacent to it.8¥Marietta, Georgia. In 1996, Marietta FiberNet became Georgia
Õs first municipallyowned company to be certified as a competitive local communications carrier. Whollyowned and operated by Marietta, it is structured as a separate business. The companybegan constructing its network in the spring of 1997. Today Marietta FiberNet provides
high-speed voice and data services to local schools, hospitals, and businesses over 170miles of fiber-optic cables.¥Thomasville, Georgia. Thomasville
Õs Community Networks Services (CNS) oper-ates a citywide fiber-optic network capable of supporting high-speed Internet access, ca-ble television, and energy management services, as well as a dial-up Internet access ser-vice. CNS now has more than 3,000 customers for its Rose.Net Internet service and

expects many of those customers to move up to Rose.Net express, a broadband Internetservice, when it becomes available. Thomasville recently entered into an agreement withneighboring Tifton through which it will help launch TiftonÕs proposed Friendly City Net-workÕs Internet service.9¥Grant County, Washington. The Grant County Public Utility District (PUD) initially
launched its fiber network, Zipp, in order to upgrade its electrical substation control. It
later decided that the network could also be used to provide telecommunications servicesin the county. Through Zipp, independent service providers can provide data, voice, andvideo services to their customers. The PUDÕs fiber backbone was completed in 2000, andpilot projects aimed at commercial and residential customers are underway. In 2001, thePUD began marketing to the general public. Major residential fiber construction and build-out are slated to take place between 2001 and 2006 to reach 90,000 homes.10¥Muscatine, Iowa. Muscatine Power and Water (MP&W), the town
Õs incumbent,municipally owned public utility, was first to deploy high-speed facilities in Muscatine.Following a 1996 marketing study and detailed feasibility study, the communications util-
ity was launched following approval by public referendum in 1997. The communications
utility received $18 million in initial funding from the municipal electric utility and7See Department of General Services, Bureau of Telecommunications and Information Technology,City of Chicago. 2000. ÒRequest for Information: Chicago CivicNetÓ (Specification No. B09189503),
November. Available online at <http://www.cityofchicago.org/CivicNet/civicnetRFI.pdf>. See also Tom
Kontzer. 2001. ÒChicagoÕs CivicNet Takes a Step Closer to Reality,Ó InformationWeek.com [January 4].
Available online at <http://www.informationweek.com/story/IWK20010104S0007>.8See <http://www.ruralfiber.net/lkpage.html>.9See Georgia Municipal Association. 1999. ÒTifton and Thomasville Enter Internet Agreement,Ó Octo-ber 7. Available online at <http://www.gmanet.com/news/1999/1007.internet.shtml>. See also Tho-
masville Utilities Community Network Services (CNS). 1999. ÒPress Releases.Ó Available online at
<http://www.tucns.com/press.html>.10See the Zipp Fiber-optic Network home page online at <http://www.gcpud.org/zipp/>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION213completed construction of its fiber network in the spring of 1999. MP&W provides high-speed cable modem Internet access to residential customers and a Municipal Area Net-work for business customers. MP&WÕs telecommunications network consists of a hybridfiber coax system with 125 homes per node, which can deliver a maximum of 4 Mbpsdownstream and 1 Mbps upstream for connected customers. MP&W obtains its connec-tion to the Internet backbone through a division of Iowa Network Services, Inc. (INS), a
telecommunications firm formed by a consortium of 128 independent telephone compa-nies.11¥Ashland, Oregon. Building on Ashland
Õs earlier fiber network initiative, local Inter-net companies are cooperating with the city to establish a new service, dubbed ÒAshlandUnwired.Ó In early 2001, the effort began with a demonstration at Ashland
Õs Starbuckscoffee shop. Using access points running the IEEE 802.11b-standard wireless local area
network technology, it aims to provide wireless Internet access via the cityÕs fiber network.Project A and Open Door Networks, city-certified Internet service providers, have offeredto provide connectivity through the Ashland Fiber Network and assistance to help any
business or organization wishing to provide Ashland Unwired to their customers.12¥Tacoma, Washington. The city
Õs public utility, Tacoma Power, began its network-ing activities with the construction of a fiber-optic network in 1997. In 1998, it launched
cable television service as a competitor to the existing franchisee (TCI, now AT&T). In1998, it began providing Internet service over the cable television network and began fullcable modem service in 1999.13¥San Diego County, California. The High Performance Wireless Research and Edu-
cation Network (HPWREN) project was launched in 2000 to build, demonstrate, andevaluate a noncommercial, prototype, high-performance, wide-area, wireless network in
San Diego County. Built by researchers at the University of California at San Diego undera $2.3 million grant from the National Science Foundation, the network includes back-bone nodes on the UC San Diego campus and a number of rural areas in San Diego
County, including the Pala and La Jolla tribes in remote San Diego County. AmongHPWRENÕs goals are to explore how scientists can make use of the network for real-timedata collection and how the network can be used by rural Native American communities
for interactive computer classes and remote tutoring programs. In addition to the researchand education applications, the HPWREN team is also investigating ad hoc advancednetwork development and experimentation in collaboration with local crisis management
agencies.1411See <http://www.mpw.org>. Case study reported in Federal Communications Commission. 2000.ÒInquiry Concerning the Deployment of Advanced Telecommunications Capability to All Americans ina Reasonable and Timely Fashion, and Possible Steps to Accelerate Such Deployment Pursuant to
Section 706 of the Telecommunications Act of 1996: Second Report,Ó CC Docket No. 98-146, August.
Available online at <http://www.fcc.gov/Bureaus/Common_Carrier/Orders/2000/fcc00290.pdf>.12See Ashland Fiber Network. [Undated]. ÒFrequently Asked Questions.Ó Available online at <http://
www.ashlandfiber.net/index.asp?page=FAQ#1>. See also Ashland Unwired. 2001. ÒOpen Door Net-works and Project A Unveil Wireless Internet Access in AshlandÓ [press release], January 29. Available
online at <http://www.ashlandunwired.com/news.htm>.13See Tacoma Power, Click! Network. [Undated.] ÒProject History.Ó Available online at <http://
www.click-network.com/news/history.htm>.14See the HPWREN home page at <http://hpwren.ucsd.edu/>, as well as Hans-Werner BraunÕs testi-mony before the House Science CommitteeÕs Subcommittee on Research, July 31, Washington, D.C.,available online at <http://www.house.gov/science/research/jul31/braun.htm>. See also ÒWireless In-ternet to Native American Reservations,Ó PopularTechnologies.com, [undated], available online at<http://www.populartechnologies.com/news/01/02/15/0414200.shtml>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.214BROADBANDBOX 5.3Examples of Greenfield DevelopmentsNew community and subdivision developments are increasingly incorporatingbroadband fiber-to-the-curb or fiber-to-the-home with other advanced exterior andinterior networking infrastructure and services. These projects are often joint ven-tures between building developers who own the properties and rights-of-way; con-
vergent telecommunications providers; and real estate investors and homeowners.Several examples follow:¥Centennial, Indiana. HFC Internet, phone, and cable provided to 900 homes
north of Indianapolis by the builder, Estridge Company, and First Mile Technologies.The cost will be repaid through homeownersÕ association fees.
¥DC Ranch, Scottsdale, Arizona. All homes are being built with structured wir-
ing to support in-home networking.¥Celebration, Florida. In a Disney-built new community near Orlando, AT&T,
Sprint, and Jones Communications have formed a joint venture to provide connectiv-ity.1¥Summerlin, Nevada. In a community outside Las Vegas, fiber-to-the-curb is
being installed by the Howard Hughes Corporation and Sprint.2¥Valencia and Newhall Ranch, California. In communities developed by Newhall
Land & Farming, SBC Communications is providing broadband voice, video, and
data to homes through a revenue-sharing venture with the developer.¥Hatchet Ranch, Colorado. Rye Telephone of Colorado City is installing fiber to
500 homes in an 80-square-kilometer new community.31See the Celebration, Florida, home page online at <http://www.celebrationfl.com/>.2For more information, see ÒSummerlin: A Profile,Ó available online at <http://www.
therousecompany.com/whoweare/hughes/summprofile.html>.3Information from <http://www.fone.net.soco/guide/colocity/rtc/home.html>; Robert Pease.2000, ÒRural Areas Present Better Business Case for Fiber to the Home,Ó Lightwave, June,available online at <http://lw.pennnet.com/Articles/Article_Display.cfm?Section=Archives&
Subsection=Display&ARTICLE_ID=73404&KEYWORD=Hatchet%20Ranch>; and Canet-3-
NEWS, 2000, ÒRural Areas Better Business Case for Fiber to the Home,Ó November 2, avail-
able online at <http://www.canarie.ca/MLISTS/news2000/0185.html>.The risk in all of these possibilities is that the local government willnot be equipped with the knowledge or skills to negotiate with a large
private sector provider. If the town does not act carefully, there is risk of
industry capture, an outcome in which a private sector provider manipu-
lates the situation to the point where the town becomes dependent on it
and thus loses any power to negotiate or foster competition. With some
notable exceptions, local governments are less likely to be familiar with
the technology and business side of networking than they are with moreBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BROADBAND POLICY AND REGULATION215traditional government operations, which places them at a disadvantagein planning or acquiring networking infrastructure or services than a
private sector firm would be. The risk can be minimized if the town sticks
to a facilitating role at the infrastructure level and encourages competi-
tion from the outset. Still, industry is not monolithic, and some companies
can be expected to favor and others to resist local efforts to foster market
entry. Local governments, especially in smaller communities, often have
limited capabilities. Action at the higher levels of government is an im-
portant part of this local approach as well, to coordinate experiences, to
catalog best practices, and to define the playing field with overarching
regulation that prevents the obvious forms of mutual abuse.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.216
Abramson, Norman. 1999. ÒInternet Access Using VSATÕs.Ó  San Francisco, Calif.:  ALOHANetworks,  October 5.
Alvarez, Lizette. 2001. ÒIn Capitol, AT&T and Bells Fight to Control Web Access.Ó New YorkTimes. August 29, p. C1.American National Standard T1E1.4 Working Group on Digital Subscriber Line Access.2001. ÒAmerican National Standard for TelecommunicationsÑSpectrum Managementfor Loop Transmission Systems.ÓAnderson, Ken, and Anne Page McClard. 1998. ÒAlways on: Broadband Living Enabled.ÓBroadband Innovation Group, MediaOne Labs, October.Anderson, Ken. 1999. ÒTechnology and Convergence of the Digerati.Ó  MediaOne Labs.
June.Andersen, William, et al. 1999. ÒApplying a Policy of Non-Discriminatory Access to High-Speed Internet Access Over Cable in King County, Washington.Ó  A Report to the
Budget and Fiscal Management Committee, Metropolitan King County Council. Octo-
ber.Andersson, Goete. 2000. ÒSwedenÕs Broad Jump: Debate Is Warming Up for Universal High-speed Service.Ó  tele.com  (501), January 10.  Available online at  <http://www.
teledotcom.com/article/TEL20000824S0034>.Angwin, Julia. 2000. ÒCable Alliances Prompt Some Consumers to Pay Twice for Web Ac-cess,Ó Wall Street Journal, November 20, p. B1.Angwin, Julia. 2000. ÒThe New Media Colossus: AOL-Time Warner Megamerger CreatesBehemoth That Could Dominate Web, Other Media.Ó Wall Street Journal, December 15,p. B1.Arbitron/Coleman (presented by Pierre Bouvard and Warren Kurtzman). 2000. ÒThe Broad-band Revolution: How Superfast Internet Access Changes Media Habits in AmericanHouseholds,Ó October 2. Available online at <http://www.arbitron.com/downloads/
broadband.pdf>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY217Armstrong, David, and Dennis K. Berman. 2001. ÒMunicipal Networks Become Rivals forFiber-optic Telecom Companies: Dissatisfaction Spurs Competition,Ó CNBC and TheWall Street Journal, August 17. Available online at <http://www.msnbc.com/news/615215.asp#BODY>.Armstrong, David, and Dennis K. Berman. 2001. ÒTelecom Companies Confront New Ri-val: The Municipal Network.Ó Wall Street Journal, August 17, p. A1.ARC Group. 2000. Broadband Access: Opportunities in Fixed Wireless. Surrey, U.K.:  ARC
Group.Associated Press. 1999. ÒIBM Offers PC with High-Speed DSL Internal Modem.Ó August 23.
Associated Press. 1999. ÒResearchers Seek to Untangle Effects of Internet.Ó  June 8.
Association for Local Telecommunications Services (ALTS). 2000. Consumer Benefits of the1996 Telecommunications Act. Washington, D.C.:  ALTS, February 2.
Association for Local Telecommunications Services (ALTS). 2000. The State of Competition inthe U.S. Local Telecommunications Marketplace. Washington, D.C.:  ALTS, February.
AT&T. 2000. ÒAT&T ÔCuts The CordÕ to Provide Services Into Homes; Debuts Nation
Õs FirstWireless Local Communications CompanyÓ [news release], March 22. Available online
at  <http://www.att.com/press/item/0,1354,2706,00.html>.
ATM Forum. 2000. ÒVoice and Multimedia Over ATM:  Loop Emulation Service Using
AAL2,Ó AF-VMOA-0145.000, July. Available online at <http://www-comm.itsi.disa.
mil/atmf/vtoa.html#af145>.Austen, Ian. 1999. ÒHigh-Speed Lines Leave Door Ajar for Hackers: Constant ConnectionsThrough Cable or DSL Mean New Security Headaches for Home Users.Ó  New YorkTimes, July 8. Available online at <http://www.nytimes.com/library/tech/99/07/cir-cuits/articles/08hack.html>.Aversa, Jeannine. 1999. ÒFCC WonÕt Regulate Internet. Really.Ó  Washington Post, March 12,p. E3.Bagasao, Paula. 1999. ÒKnowing About Who Has Access: A Matter of Strategy.Ó iMP, De-cember 22. Available online at <http://www.cisp.org/imp/december_99/12_99bagasao.htm>.Baker, Jonathan B., and Susan P. Braman. 1998. ÒDeployment of Wireline Services OfferingAdvanced Telecommunications CapabilityÓ [CC Docket No. 98-147], comment of the
staff of the Bureau of Economics, Federal Trade Commission (FTC). Washington, D.C.:FTC. Available online at <http://www.ftc.gov/be/v980030.htm>.Bar, Francois, et al. 1999. ÒDefending the Internet Revolution in the Broadband Era: WhenDoing Nothing Is Doing Harm,Ó August. Available online at <http://e-conomy.
berkeley.edu/publications/wp/ewp12.html>.Barnett, Malcolm. 2000. ÒFibre Optic Cable: Unsung Hero.Ó  Telecommunications Online,April. Available online at <http://www.telecoms-mag.com/issues/200004/tci/fibre.html>.Bechtolsheim, Andreas, and David Cheriton. 2000. ÒEthernet Broadband NetworkingÓ(white paper), Cisco Systems, August 11. Available online at <http://www4. nationalacademies.org/cpsma/cstb.nsf/files/wp-bb-bechtolsheim-cheriton.pdf/$file/wp-bb-
bechtolsheim-cheriton.pdf>.Belinfante, Alexander. 2001. ÒTelephone Penetration by Income by State (Data through2000).Ó  Industry Analysis Division, Common Carrier Bureau, Federal Communica-
tions Commission. Available online at <http://www.fcc.gov/Bureaus/Common_Carrier/Reports/FCC-State_Link/IAD/pntris00.pdf>Berkowe, Kathleen Hawkins. 2000. ÒOpen Access to Cable Systems for Internet AccessProviders.Ó Media Law and Policy VIII (2).
Berman, Dennis, and Shawn Young. 2001. ÒBells Make a High-Speed Retreat from Broad-band.Ó Wall Street Journal. October 29, p. B1.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.218BROADBANDBerresford, John. 2001. ÒBroadband Is Not for EveryoneÑExtending Existing UniversalService Broadband Would Be a Mistake.Ó ISPWorld, May 8. Available online at<http://www.boardwatch.com/bw/may01/Broadband_Not_Everyone.htm>.Berst, Jesse. 1999. ÒDr. JesseÕs Internet Checkup: The Good and Bad News About the Healthof the Web.Ó  ZDNet, June 25. Available online at <http://www4.zdnet.com/anchordesk/story/story_3553.html>.Berst, Jesse. 1999. ÒInternet Mind Control.Ó  ZDNet, June 21. Available online at <http://www.zdnet.com/anchordesk/story/story_3531.html>.Blackwell, Gerry. 1999. ÒTaking the VoIP Plunge.Ó  ISP-Planet, June 11. Available online at<http://www.isp-planet.com/services/voip-plunge1.html>.Blankenhorn, Dana. 2001. ÒClearing the Last-Mile Hurdle.Ó ISPWorld, May 8. Availableonline at <http://www.ispworld.com/bw/apr01/Last_Mile_Hurdle.htm>.Blumenstein, Rebecca, and Joann S. Lublin. 1999. ÒAmid All the Bets, One Stands Out:AT&T Ventures Into Cable.Ó  Wall Street Journal, November 5, p. A1.Blumenstein, Rebecca, and Stephanie Mehta. 1999. ÒQwest Makes Bid for US West, Fron-tier.Ó  Wall Street Journal, June 14, p. A3.Blumenstein, Rebecca, Leslie Cauley, and Kara Swisher. 1999. ÒInside the Tangles of AT&TÕsWeb Strategy.Ó  Wall Street Journal, August 13, p. B1.Blumenstein, Rebecca. 2000. ÒAT&T Filing Pledges It WonÕt Influence Programming of aMediaOne Venture.Ó Wall Street Journal, April 21, p. B6.Blumenstein, Rebecca. 2000. ÒSome Wonder if Content-less AT&T Will Rue Cable-onlyPlans.Ó  Wall Street Journal, January 14, p. B6.Blumenstein, Rebecca, and Stephanie Mehta. 2000. ÒAs the Telecoms Merge and Cut Costs,Service is Often a Casualty.Ó  Wall Street Journal, January 19, p. A1.Blumenstein,  Rebecca, Don Clark, and Leslie Cauley. 2000. 
ÒAT&T Acts to Gain Control ofExcite from Cable Firms.Ó  Wall Street Journal, March 30, p. B6.Blumenstein, Rebecca. 2001. ÒHow the Fiber Barons Plunged the Nation into a TelecomGlut.Ó Wall Street Journal. June 18, p. A1.
Blumenstein, Rebecca. 2001. ÒReform Act HasnÕt Delivered Promises to Customers.Ó WallStreet Journal. May 3, p. B1.
Booth, William. 2000. ÒThe Big Switch in Urban Renewal: Telecom Firms Bring Shine, Pol-ish, WiresÑBut Few PeopleÑto Old LA Buildings.Ó  Washington Post, January 16, p.A20.Borland, John. 2001. ÒPower Lines Stumble to Market.Ó CNET News.com, March 28. Avail-able online at <http://news.cnet.com/news/0-1004-200-5337770.html?tag=tp_pr>.Bouvard, Pierre, and Warren Kurtzman. 2000. The Broadband Revolution: How SuperfastInternet Access Changes Media Habits in American Households. Arbitron Company, NewYork. Available online at <www.arbitron.com> and <www.colemanresearch.com>.BRDC, Ltd. 2001. ÒThe Development of Broadband Access Platforms in Europe:  Technolo-
gies, Services, Markets.Ó  Commissioned by the European Commission Information
Society Directorate, August. Available online at <http://europa.eu.int/information_society/eeurope/news_library/new_documents/ broadband/index_en.htm>.Breckheimer, Veronica, and Kevin Taglang. 1999. ÒBroadband and the Future of theInternet.Ó  The Digital Beat 1(14), August 20. Available online at <http://www.benton.org/DigitalBeat/db082099.html>.Brewin, Bob. 2000. ÒCable Creeps into the Corporation: Users of Cable for Broadband Con-nectivity Cite Big Savings Over Telco Offerings.Ó  Computerworld, October 16. Avail-able online at <http://www.computerworld.com/cwi/story/0,1199,NAV47_
STO52454_NLTam,00.html>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY219Brewin, Bob. 2000. ÒCarriers Forge Pact to Avoid Interference in Fixed Wireless MicrowaveBands.Ó  Computerworld, July 10. Available online at <http://www.computerworld.com/cwi/story/0,1199,NAV47_STO46911,00.html>.Brewin, Bob. 2000. ÒTelcos Ante up $250 M for ÔLast MileÕ Connection Bidding Rights.
ÓComputerworld, April 10. Available online at <http://www.computerworld.com/cwi/story/0,1199,NAV47_STO43814,00.html>.Brinkley, Joel. 1999. ÒDespite Agreement, Snags Remain for Digital TV.Ó  New York Times,November 22, p. C17.Brinkley, Joel. 2000. ÒDo Viewers Even Want to Interact with TV?Ó  New York Times, Febru-ary 7, p. C5.Broadband Project Office, Manitoba Innovation Network. 2000. ÒAccelerating the Deploy-ment of ManitobaÕs Broadband Network InfrastructureÓ (white paper), June 6.  Avail-
able online at <http://www.min.mb.ca/calendar/White_Paper.pdf>.Burnett, Ron. 1999. ÒCommunications Policy and the New Public Sphere: Towards a NewResearch Agenda.Ó  Community Technology Review (Summer-Fall).  Available online at
<http://www.civicnet.org/comtechreview/communications_policy_and_ the_ne.htm>.Burrows, Peter. 1999. ÒFred WilsonÕs $50 Million Bet on Info Appliances.Ó  Business Week,April 14. Available online at <http://www.businessweek.com/ebiz/9904/em0414.htm>.Cable Datacom News. 2001. ÒCable Modem Customer Count Tops 5.5 Million.Ó March 1.
Available online at <http://www.cabledatacomnews.com/mar01/mar01-1.html>.Cablevision Bluebook. 2001. ÒHigh-Speed Havens of Modems & DSL.Ó June.
Cahners In-Stat Group. 2000. Broadband ConsumersÑProfiles and Strategies, Report No.BBWIS00-05SP.Cahners In-Stat Group. 2000. ÒPercentage of Internet-Connected Households Soars to 60%in 2000; In-Stat Report Reveals Results in Buying and Internet Usage TrendsÓ [press
release], March 28. Available online at <http://www.instat.com/pr/2000/is0001sp_pr.htm>.Cahners In-Stat Group. 2000. ÒMany Routes to 3G DeploymentÑOptions Depend on Start-ing PointÓ [press release], March 27. Available online at <http://www.instat.com/pr/
2000/gw0003in_pr.htm>.Canadian Radio-Television and Telecommunications Commission (CRTC). 1999. ÒCRTCWonÕt Regulate the InternetÓ [news release], May 17.  Available online at <http://
www.crtc.gc.ca/ENG/NEWS/RELEASES/1999/R990517e.htm>.CAnet-3-News. 1999. ÒGlass Is Freedom:  Optical Networks for the Rest of Us,
Ó June 9.
Available online at <http://www.canarie.ca/MLISTS/news/1282.html>.CAnet-3-News. 1999. ÒShould Fiber Infrastructure Be a Public Regulated Facility?Ó July 15.
Available online at <http://www.canarie.ca/MLISTS/news/1298.html>.CAnet-3-News. 2000. ÒNo More Tearing Up of Streets to Install Optical Fiber,Ó April 18.
Available online at <http://www.canarie.ca/MLISTS/news2000/0084.html>.Carroll, Jill. 2000. ÒFCC Will Determine ISP Access to Cable.Ó Wall Street Journal, August 29,p. B2.Caruso, Denise. 1999. ÒA New Model for the Internet: Fees for Services.Ó  New York Times,July 19, p. C6.Cauley, Leslie. 1999. ÒSony Enters Market for Cable-TV Boxes with $1 Billion Order fromCablevision.Ó  Wall Street Journal, September 17, p. B11.Cauley, Leslie, and Nicole Harris. 1999. ÒFixed Wireless Is Attracting Big Investments.ÓWall Street Journal, June 3, p. B4.Cauley, Leslie. 2000. ÒAT&T Faces Challenge over Cable-Phone Goal.Ó  Wall Street Journal,April 28, p. A3.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.220BROADBANDCauley, Leslie, and Nick Wingfield. 2000. ÒAT&T to Test Multiple ISPs on Cable Lines.ÓWall Street Journal, June 8, p. B10.Center for Democracy and Technology (CDT). 2000. Broadband Backgrounder: Public PolicyIssues Raised by Broadband Technology. Washington, D.C.:  CDT, December. Available
online at <http://www.cdt.org/digi_infra/broadband/backgrounder.shtml>.Center for Media Education (CME). 2001. ÒBroadband Networks and Narrow Visions: TheInternet at Risk.Ó Washington, D.C.: CME. Available online at <http://www.cme.org/
access/broadband/at_risk.html>.Cha, Ariana Eunjung. 2000. ÒÔFreeÕ Wireless Networks?
Ó Washington Post, December 8, p.E1.Cha, Ariana Eunjung. 2001. ÒBroadbandÕs a Nice Pace if You Can Get It.Ó Washington Post,February 28, p. G4.Chatterjee, Samir, Cherian S. Thachenkary, and Joseph L. Katz. 1998. ÒModeling the Eco-nomic Impacts of Broadband Residential Services.Ó  Computer Networks 30(14): 1295-
1310.Chen, Kathy. 1999. ÒAT&T Used Carrot and Stick Lobbying Efforts in Local Debates OverAccess to Cable-TV Lines.Ó  Wall Street Journal, November 24, p. A20.
Chen, Kathy. 1999. ÒFCC Backs Away from Regulating Internet Gateway.Ó  Wall StreetJournal, January 29, p. B2.Chen, Kathy. 1999. ÒFCC Chairman Calls for National Policy on High-Speed Internet Ac-cess Via Cable.Ó  Wall Street Journal, June 16, p. B4.Chen, Kathy. 1999. ÒFCCÕs Kennard to Argue Against Rules on Broadband Web Access atthe Local Level.Ó  Wall Street Journal, July 21, p. A4.Chen, Kathy. 2000. ÒComcast Hopes to Offer in 2002 Open-Access Policy.Ó  Wall StreetJournal, March 27, p. A42.Chen, Kathy, and Leslie Cauley. 1999. ÒOregon Ruling Could Hurt AT&T Plan to OfferInternet Access on Cable Lines.Ó  Wall Street Journal, June 7, p. B3.Chervokas, Jason. 1998. ÒThe New Boys Network.Ó  The Industry Standard, June 12. Avail-able online at <http://www.thestandard.com/article/0,1902,649,00.html>.Christopher, Abby. 1999. ÒOpening the Door for Home Networks.Ó  Upside 11(6): 66-70.
Cioffi, J.M. 2001. ÒUnbundled DSL Evolution,Ó T1E1.4 Contribution 2001-088, February,
Los Angeles, Calif.. Available online at <http://www-isl.stanford.edu/people/cioffi/dsm/t1e1pap/1e140880.pdf>.Cioffi, J.M., G. Ginis, W. Yu, and S. Zeng. 2000. ÒSpectrum Management with AdvancingDSLs,Ó ETSI TM6, Monterey TD06, November.
Cisco Systems. 1999. ÒControlling Your NetworkÑA Must for Cable OperatorsÓ (white
paper). Available online at <http://www.cptech.org/ecom/openaccess/cisco1.html>.Cisco Systems. 1999. ÒWhite Paper: Migrating to a New World Business Model.Ó  Cisco.
Civille, Richard, Michael Gurstein, and Kenneth Pigg. 2000. ÒRural Regional Strategies forBroadband Demand.Ó Center for Civic Networking and the Technical University of
British Columbia, June 15.Clark, David D. 1999. ÒHigh-Speed Data Races Home.Ó  Scientific American, October. Avail-able online at <http://www.sciam.com/1999/1099issue/1099clark.html>.Clark, David D. 1999. ÒImplications of Local Loop Technology for Future Industry Struc-tureÓ in S. Gillette and I. Vogelsang, eds., 
Competition, Regulation, and Convergence:Current Trends in Telecommunications Policy Research. Mahwah, N.J.:  Lawrence Erlbaum
Associates.Clark, David D., William Lehr, and Ian Liu. 2002. ÒProvisioning for Bursty Internet Traffic:Implications for Industry Structure,Ó to appear in L. McKnight and J. Wroclawski,
eds., Internet Service Quality Economics. Cambridge, Mass.:  MIT Press.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY221Clark, Don. 2001. ÒMicrosoft Advances on Game, TV Fronts.Ó Wall Street Journal, January 5,p. B2.Claymon, Deborah. 1999. ÒNetÕs Impact Revised Upward.Ó  San Jose Mercury News, June 9.Available online at <http://www0.mercurycenter.com/svtech/news/indepth/docs/econ061099.htm>.CLEC News. 2000. ÒCompetitors Made Gains, Still Face Challenges, ALTS Report Says.ÓCLEC News, February 3. Available online at <http://www.clec-planet.com/news/0002/000203alts.htm>.Cleland, Scott. 2000. ÒResidential Broadband OutlookÑInvestment Implications of aDuopoly?Ó  Washington, D.C.:  Precursor Group, August 11.
Cleland, Scott. 2001. ÒDatatopiaÑWhy Data Transport Growth Stories May Disappoint.ÓWashington, D.C.:  Precursor Group, February 5.
Cleland, Scott. 2001. ÒHow Broadband Deployment Skews Economic/Business Growth.ÓWashington, D.C.:  Precursor Group, February 22.
Cochrane, Peter. 1994. ÒDark Fibre Will Transform Telecommunications.Ó IEEE Spectrum,Technology 94, January.Cohill, Andrew. 2000. ÒTelecommunications for Neighborhoods and Communities: FourKey Areas of Investment
Ó (paper from Blacksburg Electronic Village). Available online
at <http://www.bev.net/project/digital_library/comm_tel.pdf>.Cohill, Andrew, and Jeffrey Crowder. 2000. ÒCommunity-based Broadband Telecommuni-cations Infrastructure,Ó Technical Report 2001-01v3. Virginia Tech. March.  Available
online at <http://www.bev.net/project/digital_library/broadbandv3.pdf>.Cole, Jeff. 1999. ÒBoeing, in a Strategic Shift, to Develop Its Own Satellite Systems andServices.Ó  Wall Street Journal, June 14, p. A3.Cole, Jeff. 1999. ÒLockheed, Partners to Develop System of Multimedia, Internet-access Sat-ellites.Ó  Wall Street Journal
, May 6, p. A3.Communications Business and Finance. 1999. ÒLarry Darby Asks ÔHow Much Broadband Ca-pacity Enough?ÕÓ May 3.
Computer Science and Telecommunications Board (CSTB), National Research Council. 1994.Realizing the Information Future: The Internet and Beyond. Washington, D.C.:  National
Academy Press.Computer Science and Telecommunications Board (CSTB), National Research Council. 1996.The Unpredictable Certainty: Information Infrastructure Through 2000. Washington, D.C.:National Academy Press.Computer Science and Telecommunications Board (CSTB), National Research Council. 1998.Trust in Cyberspace. Washington, D.C.:  National Academy Press.
Computer Science and Telecommunications Board (CSTB), National Research Council. 2000.The Digital Dilemma:  Intellectual Property in the Information Age
. Washington, D.C.:National Academy Press.Computer Science and Telecommunications Board (CSTB), National Research Council. 2001.The InternetÕs Coming of Age. Washington, D.C.:  National Academy Press.
Conklin, J.C. 1999. ÒExtension Cords.Ó  Wall Street Journal, September 13, p. R13.Consumer Federation of America (CFA). 1999. ÒConsumers Demand Open Access to theHigh Speed.Ó  Washington, D.C.:  CFA.
Consumer Federation of America (CFA) and Consumer Action. 1999. Transforming the Infor-mation Superhighway Into a Private Toll Road:  The Case Against Closed Access Broadband
Internet Systems. Washington, D.C.:  CFA and Consumer Action, September. Availableonline at <http://www.consumerfed.org/bbreport.pdf>.Consumer Federation of America (CFA). 1999. ÒWhile Federal Authorities Watch and Waitfor Corporate Interests to Close the Internet, Consumers and Local GovernmentsShould Demand Open Access.Ó  Washington, D.C.:  CFA.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.222BROADBANDCooper, Mark, and Gene Kimmelman. 1999. The Digital Divide Confronts the Telecommunica-tions Act of 1996:  Economic Reality vs. Public Policy
. Washington, D.C.:  Consumers
Union, Consumer Federation of America, February. Available online at <http://www.
consunion.org/pdf/TELECOM-0299.PDF>.Cordella, Paul. 2000. ÒBell Atlantic Paves the Way for In-region Inter-LATA Long DistanceApproval.Ó Media Law and Policy VIII (2).
Covad Communications Company. 1998. ÒDefining Digital LoopsÑAvoiding Re-monopo-lization in a Digital WorldÓ (Working Paper Series, No. 1), June 4. Available online at
<http://www.covad.com/PDF/DigitalLoop.pdf>.Crane, David. 2000. ÒSwedenÕs Broadband-For-All Shames Canada.Ó  Ottawa Business Jour-nal 5(28): 7, March 27.
Crandall, Robert W., and Charles L. Jackson. 2001. The $500 Billion Opportunity:  The
Potential Economic Benefit of Widespread Diffusion of Broadband Internet Access.Washington, D.C.:  Criterion Economics, L.L.C., July. Available online at <http://
www. criterioneconomics.com/documents/Crandall_Jackson_500_Billion_Opportun-
ity_ July_2001.pdf>.Cukier, Kenneth Neil, and Justin Hibbard. 2000. ÒSpectrum Shortage: Giving Away 3GSpectrum May Have More Merit Than Auctions Do.Ó  Red Herring Magazine, October.Culver, Denise. 2001. ÒNew Homes for Broadband.Ó Net Economy, April 2.Davidson, Paul. 2001. ÒLove Thy NeighborÕs Net Link.Ó  USA Today, January 16, p. 8B.Department of General Services, Bureau of Telecommunications and Information Technol-ogy, City of Chicago. 2000. ÇRequest for Information:  Chicago CivicNet
È (Specifica-
tion No. B09189503), November. Available online at <http://www.cityofchicago.org/CivicNet/civicnetRFI.pdf>.Dickson, Glen. 1999. ÒVOD Servers Wait for Demand.Ó  Broadcasting and Cable, May 31.Dodson, Sean. 2000. ÒFree as the Air We Breathe.Ó  The Guardian, October 12. Availableonline at <http://www.guardian.co.uk/online/story/0,3605,380723,00.html>.Donovan, Aaron. 2001. ÒFaster Data Connection Waits Impatiently in Line.Ó New York Times,March 22, p. G3.Dooley, Joe. 2000. ÒNew Local Loop: Make Way for the PON.Ó  Telecommunications (Septem-
ber). Available online at <http://www.telecoms-mag.com/issues/200009/tcs/new_local_loop.html>.Dornan, Andy. 2000. ÒWho Owns the AirwavesÓ (Global Watch column). 
NetworkMagazine.com (March). Available online at <http://www.networkmagazine.com/
magazine/current/0003global.htm>.Drake, William J. 1999. Toward Sustainable Competition in Global Telecommunications: FromPrinciple to Practice. A Report of the Third Annual Aspen Institute Roundtable onInternational Telecommunications. Washington D.C.: Aspen Institute.  Available online
at <http://www.ceip.org/files/projects/irwp/pdf/aspen_sustainable_competition.
pdf>.Dreazen, Yochi. 2001. ÒVerizon Plays Every Angle in Broadband Battle.Ó  Wall Street Journal,August 15, p. A16.Dutta-Roy, Amitava. 1999. ÒNetworks for Homes.Ó  IEEE Spectrum 36(12). Available online
at <http://www.spectrum.ieee.org/pubs/spectrum/9912/hnet.html>.Dvorak, John. 2001. ÒThe Future of the ISP.Ó  ISPWorld Boardwatch, May 8.Economics and Technology, Inc. 1999. ÒBuilding a Broadband America: The CompetitiveKeys to the Future of the Internet.Ó  Boston, Mass.:  E&T, Inc.
Economist. 1998. ÒHold the Line: Connecting American Homes to the Internet RequiresStrong Regulatory Nerves,Ó December 12.
Economist. 1998. ÒTelecoms. Broadband Bottleneck,Ó November 7.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY223Economist. 2000. ÒDivide and Conquer: Spare Computing Capacity Scattered Around a
Zillion Desktops Could Soon Be Worth Real Money,Ó July 29-Aug. 4.
Economist. 2001. 
ÒComputing Power on Tap,Ó June 21.
Eisenach, Jeffrey A. 1999. ÒThe High Cost of Taxing Telecom,Ó The Progress and Freedom
Foundation, September 6. Available online at <http://www.pff.org/telecomtax.htm>.Electric Power Research Institute (EPRI). 1998. ÒUtility-Customer Communications Optionsfor the ÔLast Mile,ÕÓ July.
Ellis, Bob. 1999. ÒLast-Mile Bandwidth and Conference BOF, Policy Survey Results andAnnouncements of Second Survey.Ó  Public Policy Committee,  SIGGRAPH,  May.
Emigh, Jacqueline. 1999. ÒE-Commerce Strategies.Ó  ComputerWorld, September 16.Entman, Robert. 1999. Residential Access to Bandwidth: Exploring New Paradigms. A Report ofthe Thirteenth Annual Aspen Institute Conference on Telecommunications Policy.
Washington, D.C.:  Aspen Institute, August. Available online at <http://www.
aspeninst.org/publications1/pdfs/access.pdf>.Essex, David. 2000. ÒAre Powerline Nets Finally Ready?Ó MIT Technology Review, June 21.Available online at <http://www.technologyreview.com/web/essex/essex062101.asp>.Excite@Home. 2000. ÒExcite@HomeÕs Principal Cable Partners Extend Distribution Agree-ments, AT&T Assumes More Prominent RoleÓ (press release), March 29.
Fanzke, Martia, Monika Marics, and Tom Day. (Undated). ÒMaking Time for Fun: TV Con-sumption and PVR Use in the Home.Ó MediaOne Labs.
Farhi, Paul. 1999. ÒFears Rise of a Digital Divide.Ó  Washington Post, May 25, p. E1.Farhi, Paul. 1999. ÒMicrosoft Invests in AT&T: Firm Stakes Claim in Mingling of Phone, TV,Computer.Ó  Washington Post, May 7, p. E1.Faulhaber, G., and C. Hogendorn. 2000. ÒThe Market Structure of Broadband Telecommu-nications.Ó   Journal of Industrial Economics 45(3): 305-329, September.
Feder, Barnaby. 2001. ÒSatellite Venture Halts Payment on Its Debts.Ó Wall Street Journal,January 17, p. C3.Federal Communications Commission (FCC). 1998. ÒDeployment of Wireline Services Of-fering Advanced Telecommunications Capability.Ó Available online at <http://www.ftc.gov/be/v980030.htm>.Federal Communications Commission (FCC). 1999. ÒFCC Establishes Federal-StateJoint Conference to Promote Advanced Broadband Services,Ó October 8. Available
online at <http://www.fcc.gov/Bureaus/Common_Carrier/News_Releases/1999/nrcc9081.html>.Federal Communications Commission (FCC).  1999. 
ÒFCC Reshapes the FutureÑEstab-lishes New Enforcement and Consumer Information Bureaus to be Effective 11-08-99,ÓOctober 26. Available online at <http://www.fcc.gov/Bureaus/Miscellaneous/News_Releases/1999/nmrc9072.html>.Federal Communications Commission (FCC). 1999. ÒInquiry Concerning the Deploymentof Advanced Telecommunications Capability to All Americans in a Reasonable andTimely Fashion, and Possible Steps to Accelerate Such Deployment Pursuant to Sec-
tion 706 of the Telecommunications Act of 1996.Ó January 28.
Federal Communications Commission (FCC). 1999. Local Competition:  August 1999
 (report
of the Industry Analysis Division, Common Carrier Bureau). Washington, D.C.:  FCC,

August. Available online at <http://www.fcc.gov/Bureaus/Common_Carrier/Re-ports/FCC-State_Link/IAD/lcomp99-1.pdf>.Federal Communications Commission (FCC). 2000. ÒDeployment of Advanced Telecom-munications CapabilityÓ (Second Report), August. Available online at <http://www.
fcc.gov/Bureaus/Common_Carrier/Orders/2000/fcc00290.pdf>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.224BROADBANDFederal Communications Commission (FCC). 2000. ÒInterim Report:  Spectrum Study of
the 2500-2690 MHz Band: The Potential for Accommodating Third Generation MobileSystems.Ó November 15.
Federal Communications Commission. 2000. ÒInquiry Concerning the Deployment of Ad-vanced Telecommunications Capability to All Americans in a Reasonable and TimelyFashion, and Possible Steps to Accelerate Such Deployment Pursuant to Section 706 of
the Telecommunications Act of 1996.Ó  CC Docket No. 98-146, Second Report, FCC
0-290 (August 21). Available online at <http://www.fcc.gov/Bureaus/Common_ Car-rier/Orders/2000/fcc00290.pdf>.Federal Communications Commission (FCC). 2000. ÒNotice of Inquiry on Deployment ofAdvanced Telecommunications Services.Ó CC Docket No. 98-146. Feb. 18.
Federal Communications Commission (FCC). 2001. High-speed Services for Internet Access:Subscribership as of December 31, 2001. Industry Analysis Division, Common CarrierBureau. Washington, D.C.:  FCC.
Fitz, Jonathan. 2000. ÒTake This Bandwidth and Shove It.Ó  Telephony, June 5, p. 170-178.Flint, Joe. 2000. ÒBroadcasters Create iBlast to Distribute Content to PCs Via Wireless Tech-nology.Ó  Wall Street Journal, March 8, p. B8.Flynn, Laurie J. 2000. ÒGeorgia City Putting Entire Community Online.Ó  New York Times,March 27, p. C4.Flynn, Laurie J. 2001. ÒDays of Plenty Are Over at Free Internet Services.Ó New York Times,January 1, p. C1.Forrester Research. 2000. ÒBroadband Misses the Mark (A Technographics Brief),Ó Septem-
ber 1.Fowler, Thomas B. 2000. ÒOptical Networking: A Tutorial and Outlook.Ó  The Telecommuni-cations Review (2000). Available online at <http://www.mitretek.org/pubs/telecom/review00/article3.doc>.Frieden, Rob. 2000. ÒDoes a Hierarchical Internet Necessitate Multilateral Intervention?ÓPresentation given at the 28th Annual Telecommunications Policy Research Confer-ence, Alexandria, Virginia, September 23-25. Available online at <http://www.personal.psu.edu/faculty/r/m/rmf5/TPRC1.ppt>.Fulton, Keith. 1999. ÒJobs, Education, Opportunity: Why Bridging the Digital DivideThrough Community-based Digital Campuses Will Work.Ó  iMP, December.Fusco, Patricia. 1999. Ò106th Congress Unleashes Internet Legislation.Ó  Internetnews.com,November 11.Fusco, Patricia. 1999. ÒExcite@Home Cleaves Customers from Content.Ó  Internetnews.com,November 22.Fusco, Patricia. 1999. ÒFCC/AT&T Policy Shifts Leave ISPs Out of the Game.Ó  Internetnews.com, October 20.Fusco, Patricia. 1999. ÒISPs Form Coalition in Bid For Open Access.Ó InternetNews.com, Feb-ruary 2.Fusco, Patricia. 1999. ÒProdigy, GTE Offer Internet Call Waiting.Ó  InternetNews.com, July19. Available online at <http://www.internetnews.com/isp-news/article/0,10878_
164031,00.html>.Fusco, Patricia. 1999. ÒWho Killed Reciprocal Compensation in Massachusetts?Ó Internet-news.com, May 24. Available online at <http://www.isp-planet.com/politics/whokilled.html>.Fusco, Patricia. 2000. ÒHigh-Speed Competition Arrives in Oregon.Ó InternetNews.com
, Feb-ruary 9.Gabel, David. 1999. ÒRecovering Access Costs: The Debate,Ó in B. Cherry, S. Wildman, and
A. Hammond IV, eds., Making Universal Service Policy:  Enhancing the Process Through
Multidisciplinary Evaluation. Mahwah, N.J.:  Lawrence Erlbaum Associates.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY225Gabel, David, and Milton Mueller. (Undated). ÒHousehold Financing of the First 100 Feet?ÓAvailable online at <http://ksgwww.harvard.edu/iip/doeconf/gabel.html>.Gantz, John. 1999. ÒInternet2 Is on the Way: Watch for It.Ó  ComputerWorld, March 1. Avail-able online at <http://www.computerworld.com/cwi/story/0,1199,NAV47-74_STO34141,00.html>.Garcia, John, and Jon Wilkins. 2001. ÒWhich Broadband Technology Will Win the Race forHomes and Offices?Ó  The McKinsey Quarterly, Number 1. Available online at  <http://
www.mckinseyquarterly.com/article_page.asp?articlename=piwa01>.General Accounting Office (GAO). 2000. Telecommunications:  Technological and Regulatory
Factors Affecting Consumer Choice of Internet Providers (Report to the Subcommittee on
Antitrust, Business Rights and Competition, Committee on the Judiciary, U.S. Senate)[GAO-01-93]. Washington, D.C.:  GAO, October. Available online at <http://www.

gao.gov/new.items/d0193.pdf>.Georgia Municipal Association. 1999. ÇTifton and Thomasville Enter Internet Agreement,ÈOctober 7. Available online at <http://www.gmanet.com/news/1999/1007.
internet.shtml>.Georgia Municipal Association. 2000. ÒLaGrange Internet TVÓ Initiative Provides Free
Internet Access to All Cable TV Households,Ó April. Available online at <http://
www.gmanet.com/research/resources/telecomm.lagrange.shtml>.Gerbrandt, Larry. 2001. ÒThe Kagan Media Index.Ó Paul Kagan Associates. January 31.
Gilder, George, and Bret Swanson. 2001. ÒThe Broadband Economy Needs a Hero.Ó WallStreet Journal. February 23.
Gillet, Sharon, and William Lehr. 1999. ÒAvailability of Broadband Internet Access: Empiri-cal Evidence,Ó prepared for the Telecommunications Policy Research Conference
(sponsored by MIT-ITCC), September 25.Gillis, Justin, and Jackie Spinner. 1999. ÒA Nation Plugged In and Dug Up:  Streets Scarred
in Race to Wire Americe.Ó  Washington Post, July 15, p. A1.Ginty, Maura. 1999. ÒMetromedia Expands in Europe.Ó  ISP News, Nov. 22.Gitlin, Richard D. 2000. ÒNext Generation Networks: The New Public Network.Ó Lucent
Technologies.Glassman, James K. 2001. ÒThe FCCÕs Dangerous Internet Precedent.Ó Wall Street Journal,January 17, p. A26.Goldsborough, Margaret W. 2001. ÒWill Congressional Web Learning Report Gather Mo-mentum or Only Gather Dust?Ó  New York Times, January 3. Available online at <http://www.nytimes.com/2001/01/03/technology/03EDUCATION.html>.Gomes, Lee, and Lisa Bransten. 2000. ÒVenture Capital Loves P-to-P: The Latest TechnologyFad.Ó  Wall Street Journal, July 5, p. B1.Goodman, David J. 2000. ÒThe Wireless Internet: Promises and Challenges.Ó  Computer33(7): 36.Goodman, Peter S. 1999. ÒAT&T Plans a Big Return to Local Service.Ó  Washington Post,Nov. 24.Goodman, Peter S. 1999. ÒOregon Wages a Battle Over Access to Internet.Ó Washington Post,Nov. 1, p. A1.Goodman, Peter S. 2000. ÒDishing Up a New Link to the Internet.Ó  Washington Post, No-vember 6, p. A1.Goodman, Peter S. 2000. ÒFirms Duel Over the Wired West.Ó Washington Post, April 19.
Goodman, Peter S. 2000. ÒRooftops Loom As a Telecom Battleground.Ó  Washington Post,June 12, p. A01.Goodman, Peter S. 2000. ÒTeligent Expands Reach of Wireless.Ó  Washington Post, May 2, p.E01.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.226BROADBANDGoodman, Peter S., and Craig Timberg. 2000. ÒAOL Ends Lobbying for Open Access.ÓWashington Post, February 12.Gotcher, Renee, and Laura Kujubu. 1998. ÒThe Network Comes Home.Ó  IDG, November 5.Available online at <http://www.cnn.com/TECH/computing/9811/05/integr8home.
idg/>.Government of Sweden. 2000. ÒAn Information Society for All:  A Publication About the
Swedish IT Policy,Ó December. Available online at <http://www.naring.
regeringen.se/pressinfo/infomaterial/pdf/n2000_57.pdf>.Government of Sweden. 2000. ÒSummary of the GovernmentÕs Proposal in Government Bill1999/2000:86Ó (fact sheet), Publication No. N2000:018, March. Available online at
<http://www.industry.ministry.se/inenglish/pdf/n2000_18e.pdf >.Green, Paul. 1999. ÒWDM as an Access Technology (CAS-COM).Ó Tellabs, July 28.
Green, Paul. 2001. ÒProgress in Optical Networking.Ó  IEEE Communications 39(1): 54-61.
Greenstein, Shane. 1999. ÒOn the Net: The Recent Commercialization of Access Infrastruc-ture.Ó  iMP, December. Available online at <http://www.cisp.org/imp/december_99/12_99greenstein.htm>.Greenstein,  Shane. 2000. 
ÒCommercialization of the Internet: The Interaction of PublicPolicy and Private ChoicesÓ (working paper), WP-00-11. Evanston, Illinois:  Institute
for Policy Research, Northwestern University. Available online at <http://www.nwu.edu/IPR/publications/wpabstracts00/wp0011.html>.Grenier, Melinda Patterson. 2001. ÒWeb Access Extends to Over 75% of U.S. Public SchoolClassrooms.Ó Wall Street Journal, June 6, p. B2.Grieve, Willie A., and Stanford L. Levin. 1996. ÒCommon Carriers, Public Utilities andCompetition.Ó  Industrial and Corporate Change 5(4): 993-1012.
Gruley, Bryan. 1999. ÒAOL Leads Lobbying Campaign to Gain Access to Broadband Cable-TV Lines for the Internet.Ó  Wall Street Journal, January 26, p. A20.Guernsey, Lisa. 2000. ÒF.C.C. Widens Radio Spectrum for Wireless Networks.Ó New YorkTimes, September 1, p. C2.Guernsey, Lisa. 2000. ÒThe Future Is Here, and ItÕs Ugly: A Spreading Techno-blight ofWires, Cables and Towers Sparks a Revolt.Ó New York Times, September 7, p. G1.Hafner, Katie. 2000. ÒThree Rules of DSL: Location, Location, and Confusion.Ó  New YorkTimes, January 13, p. G1.Hagerty, James. 2000. ÒSunbeam Introduces ÔSmartÕ Appliances in an Effort to Set Industry
Standard.Ó Wall Street Journal, January 14, p. B6.Hales, Linda. 2001. ÒBlobs, Pods and People.Ó  The Washington Post Magazine, March 25, pp.34-39.Hamilton, David. 1999. ÒBroadcom to Buy Epigram to Accelerate Hookup of High-speedData in the Home.Ó  Wall Street Journal, April 26, p. B8.Hansell, Saul. 2000. ÒTime Warner Makes Access Deal with Earthlink.Ó New York Times,November 21, p. C1.Harding, James, and Peter Thal Larsen. 2000. ÒBroadband for All by 2005 Is Aim.Ó  FinancialTimes, August 29, p. 1.Hardy, Quentin, and Scott Thurm. 1999. ÒMotorola, Cisco Jointly Acquire Bosch Telecom.ÓWall Street Journal, June 7, p. B3.Harmon, Amy. 1999. ÒSome Enter the Fast Lane to Get Access to the Web.Ó  New York Times,April 28, p. A1.Harris, Leslie. (Undated). ÒWaiting for Broadband.Ó  Civicnet.org. Available online at <http://www.civicnet.org/comtechreview/cuspofconvergence.htm>.Harris, Nicole. 1999. ÒSprint Pieces Together Wireless Cable for Home Access.Ó  Wall StreetJournal,  May 6.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY227Harris, Nicole. 1999. ÒSprint to Tackle the Broadband Market by Selling Its ION Network toConsumers.Ó  Wall Street Journal, June 21.Harris, Nicole. 2000. ÒAT&TÕs High Wireless Act: Can It Deliver the Web and a Dial Tone?ÓWall Street Journal, March 2, p. B1.Harris, Nicole. 2000. ÒLucent Bets on Fiber Optics, but Faces Hurdles.Ó  Wall Street Journal,February 10, p. B8.Harrison, Jana, et al. 1998. ADSL: Prospects and Possibilities, prepared for the ADSL Forum.Los Angeles:  Center for Telecommunications Management, University of Southern
California, July. Available online at <http://www.adsl.com/mrp_exec_
summary.html>.Harrison, Steve, and Paul Dourish. 1996. ÒRe-Place-ing Space: The Roles of Place and Spacein Collaborative Systems.Ó  Proceedings of the ACM Conference on Computer-SupportedCooperative Work CSCWÕ96 (Boston, Mass.). New York: ACM. Draft version availableonline at <http://www.parc.xerox.com/csl/members/dourish/papers/place-paper.html>.Harroff, Edward. 2000. ÒBredbandsbolaget Brings Broadband Access to Europe.Ó  Lightwave,October 11.Harrow, Jeffrey. 2000. ÒThe Last Mile Rules.Ó  The Rapidly Changing Face of Computing,March 20. Available online at <http://www.compaq.com/rcfoc/20000320.html#_Toc477760970>.Healey, Jon. 1999. ÒVideo Cellular Phones Closer to Reality.Ó  San Jose Mercury News, Au-gust 26.Healey, Jon. 2000. ÒMicrosoft, Partners Introduce ÔUltimateTVÕ.Ó  San Jose Mercury News,June 12.Hecht, Jeff. 2001. ÒBreaking the Metro Bottleneck.Ó  Technology Review 104(5): 48-53. Avail-
able online at <http://www.technologyreview.com/magazine/jun01/hecht.asp>.Hecht, Jeff. 2000. ÒFiber Optics to the Home.Ó  Technology Review 103(2): 48-52. Available
online at <http://www.technologyreview.com/magazine/mar00/hecht.asp>.Hecht, Jeff. 2000. ÒNew Pipelines Promise Unprecedented Speed.Ó  Upside Today, August25. Available online at <http://www.upside.com/texis/mvm/print-it?id=
3999b24a0&t=/texis/mvm/ebiz/story>.Heinzl, Mark. 2000. ÒAs 360networks Readies IPO, Some See Fiber-Capacity Glut.Ó  WallStreet Journal, March 23, p. B6.Heinzl, Mark. 2000. ÒOperators of Fiber-Optic Networks Face Capacity Glut, Falling Prices.ÓWall Street Journal, October 19, p. B1.Heinzl, Mark. 2001. ÒAll-Optical Telecom Network Faces Slowing Economy, Excess Capac-ity.Ó Wall Street Journal, February 23, p. B1.Heinzl, Mark. 2001. ÒBroadband Carriers are Hunting for ÔKiller Apps.ÕÓ Wall Street Journal,June 14, p. B10.Heywood, Peter. 2000. ÒMarconi Launches DSL Killer.Ó  Light Reading, June 5. Availableonline at <http://www.lightreading.com/document.asp?doc_id=832>.Heywood, Peter. 2000. ÒThe Optical Future.Ó  Light Reading, March 29. Available online at<http://www.lightreading.com/document.asp?doc_id=335>.Hogg, Ray. 2000. ÒATM PON Maximizes Bandwidth to Homes and Businesses.Ó  Lightwave16(9), August.Holson, Laura. 1999. ÒThe Battle for US West and Frontier Shows How Difficult the Sectorhas Become to Analyze.Ó  New York Times, June 21.Huber, Peter. 1999. ÒYour Virtual Desktop.Ó  Forbes, March 8, p. 144.Huber, Peter. 2000. ÒThe Death of Old Media.Ó Wall Street Journal, January 11, p. A26.IDC. 2000. ÒEmail Deluge Continues with No End in SightÓ (press release), October 10.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.228BROADBANDIDC. 2000. ÒHome Office Use of the Internet Is Growing DramaticallyÓ (press release), July
24.IDC. 2000. ÒHome Office Households Approach 37 Million in 2000 As Internet Turns ÔWorkAnywhereÕ into 
ÔWork EverywhereÕÓ (press release), September 1.
Isenberg, David S. 2000. ÒYou Think ItÕs DSL vs. Cable? Guess Again.Ó  Fortune 142(8): 64.
(Special Issue: The Future of the Internet).Isenberg, David S. 2001. ÒSMART Letter #56:  Era of Customer-Owned Networks.
Ó  isen.com,June 7. Available online at <http://www.isen.com/archives/010607.html>.Ishida, T., and K. Isbister (eds.). 2000. Digital Cities: Technologies, Experiences, and FuturePerspectives. Springer. Abstracts and chapters available online at <http://link.springer.de/link/service/series/0558/tocs/t1765.htm>.IT Commission, Government of Sweden. 1999. A Future-Proof IT Infrastructure for Sweden:Report by the IT Commission  (SOU 1999:134), Roger Tanner, trans. Stockholm:  Ministry
of Industry. Available online at <http://www.itkommissionen.se/PDF/rapp0026.pdf>.IT Strategy Council (Japan). 2000. ÒBasic IT StrategyÓ (adopted by the IT Strategy Council
on 27 November 2000). Tokyo:  Ministry of Foreign Affairs of Japan. Available online
at <http://www.mofa.go.jp/policy/economy/it/strategy.html>.International Telecommunications Union (ITU). 2001. ÒChairÕs Report,Ó Regulatory Impli-
cations of Broadband Workshop (ITU New Initiatives Programme), Geneva, Switzer-land, May 2-4. Geneva:  ITU, May. Available online at <http://www.itu.int/osg/spu/

ni/broadband/workshop/chairfinal.pdf>.Jander, Mary. 2000. ÒLast Mile Lexicon.Ó  Light Reading, November 20. Available online at<http://www.lightreading.com/document.asp?doc_id=2476>.Jayant, Nikil (ed.). 1999. Signal Compression: Coding of Speech, Audio, Text, Image and Video.Singapore:  World Scientific.
Jesdanum, Anick. 2000. ÒWiring Rural America: Just the Beginning.Ó  Associated Press, Sep-tember 6.Jones, Bill. 2000. ÒA Report on the Feasibility of Internet Voting.Ó California Internet VotingTask Force. January.Joyce, Amy. 1999. ÒBandwidth by Demand: Telecommunications Start-up Streamlines In-ternational Networking.Ó  Washington Post, September 27.Joyce, Amy. 2000. ÒA High-Speed Disconnection.Ó Washington Post, October 5, p. E4.Kelley, Daniel. 1999. ÒDeregulation of Special Access Services: Timing Is Everything.Ó  HAIConsulting. June.Kende, Michael, and Douglas Sicker. 2000. ÒReal-time Services and the Fragmentation ofthe Internet.Ó Proceedings of the 28th Research Conference on Communication, Informationand Internet Policy (TPRC 2000), September 23-25, 2000. Alexandria, Va.:  Telecommu-
nications Policy Research Corporation.Kennard, William. 1999. ÒThe Road Not Taken: Building a Broadband Future for America.ÓRemarks before the National Cable Television Association, Chicago, Illinois, June 15.Available online at <http://www.fcc.gov/Speeches/Kennard/spwek921.html>.Kennard, William. 2000. ÒThe New York Story: ÔAinÕt No Stopping Us Now.ÕÓ Media LawAnd Policy, New York Law School. Spring, Vol. VIII, No. 2.Kennelly, Jim. 1994. Ò9 Ways Going On-Line Can Change Your Life and 6 Ways It CanÕt,ÓThe Washington Post: Fast Forward, September, pp. 9-13.Kettler, David. 1999. ÒLighting Up the Last Mile: FiberÕs Future Is Brightening the LocalLoop.Ó  AmericaÕs Network, July 1. Available online at <http://www.americasnetwork.com/issues/99issues/990701/990701light.htm>.Kirk, Don. 2001. ÒIn Korea, Broadband Is Part of the Culture.Ó New York Times, October 29,p. C3.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY229Kirstein, Mark, Cahners In-Stat. 2000. Entering the Broadband Era (Report No. BB0000CI),
May. Available online at <http://www.instat.com/catalog/downloads/broadbandera8uh.pdf>.Klein, Alec. 2000. ÒAOL Restrictions Alleged.Ó Washington Post, October 10, p. E1.Klein, Alec. 2001. ÒAOL Signs Up 3 More Internet Providers to Use Cable System.Ó Wash-ington Post,  October 6, p. E8.
Klein, Alec. 2001. ÒFCC Clears Way for AOL Time Warner, Inc.Ó Washington Post, January12, p. A1.Kolko, Jed. 2000. ÒBroadband Misses the Market.Ó Forrester Research Brief. September 1.
Kontzer, Tom. 2001. ÒChicagoÕs CivicNet Takes a Step Closer to Reality,ÓInformationWeek.com,  January 4. Available online at <http://www.informationweek.
com/story/IWK20010104S0007>.Kover, Amy. 2000. ÒThe Hot Idea of the Year [peer-to-peer].Ó  Fortune 142(1), June 26.
Krause, Jason. 2000. ÒDSL Upstarts CanÕt Compete With Phone Giants.Ó  Industry Standard,December 22. Available online at <http://www.thestandard.com/article/display/
0,1151,21043,00.html>.Krim, Jonathan. 2001. ÒGates Calls for a Cut in High-Speed Net Costs.Ó Washington Post,September 6, p. E1.Kruger, Lennard G., and Angele A. Gilroy. 2000. ÒIB10045: Broadband Internet Access:Background and IssuesÓ (CRS Issue Brief for Congress), November  28. Available
online at <http://www.cnie.org/nle/st-49.html>.Kruse, Hans, William Yurcik, and Lawrence Lessig. 2000. ÒThe InterNAT: Policy Implica-tions of the Internet Architecture Debate.Ó  Proceedings of the 28th Research Conference onCommunication, Information and Internet Policy (TPRC 2000), September 23-25, 2000. Al-
exandria, Va.:  Telecommunications Policy Research Corporation. Available online at
<http://www.csm.ohiou.edu/kruse/publications/InterNAT_v4.pdf>.Labaton, Stephen. 1999. Ò$72 Billion Deal of Phone Giants Clears Big Hurdle: Ameritech-SBC Would Have to Expand to New Cities and Welcome Competitors.Ó  New YorkTimes, June 30, p. A1.Labaton, Stephen. 1999. ÒFight for Internet Access Creates Unusual Alliances:  Former Foes
Find Profits in AT&T Cable Lines.Ó  New York Times, August 13.Labaton, Stephen. 2000. ÒAn Oops in Time WarnerÕs Battle for Internet.Ó  New York Times,May 24, p. A1.Labaton, Stephen. 2001. ÒSlew of Supreme Court Cases to Focus on Õ96 Telecom Law.ÓNewYork Times, October 1, p. C8.Lacter, Mark. 2000. ÒClick Flicks (Video-on-demand).Ó Forbes. August 7, p. 67.
Lais, Sami. 1999. ÒBuilding Industry Braces For IT, Online Onslaught.Ó  Computerworld,August 23, p. 14.Landers, Peter. 2000. ÒNTT Intends to Link Homes To Web With High-Speed Fiber.Ó  WallStreet Journal, September 27.Larson, Gary, and Jeffrey Chester. 1999. ÒSong of the Open Road:  Building a Broadband
Network for the 21st CenturyÓ (white paper). Washington, D.C.: Center for Media
Education. Available online at <http://www.cme.org/access/broadband/openroad1.html>.Lathen, Deborah. 1999. ÒBroadband Today.Ó Staff Report to William Kennard, Chairman,
Federal Communications Commission. October.Lathen, Deborah. 1999. ÒThe Emergence of ConvergenceÓ [speech], July 22. Available online
at <http://www.fcc.gov/Speeches/misc/spdal901.html>.Latour, Almar. 1999. ÒStandard Connecting Phones to Internet Is Fueling Service Providersin Europe.Ó Dow Jones Newswires, August 9.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.230BROADBANDLatour, Almar. 2001. ÒHow Europe Tripped Over a Wireless Phone Made for the Internet.ÓWall Street Journal, June 5, p. A1.Laubach, Mark. 1999. ÒComments on the Technical Ability to Implement Open Access Pro-visioning via High-Speed Data over Hybrid Fiber-Coaxial Cable Television Systems inthe United States,Ó prepared for the White House National Economic Council, May 30.
Laver, Ross. 1996. ÒPlugging into the Future.Ó  MacleanÕs, January 29, p. 34.Le Blanc,  Jamal. 1999. 
ÒResolving the Digital Divide.Ó Digital Beat 1(19), November 12.
Available online at <http://www.benton.org/DigitalBeat/db111299.html>.LeDuc, Daniel, and Craig Timberg. 2000. ÒBattle Lines Drawn Over Cable: Md., Va. Legisla-tures Confront Issues of Internet Access.Ó  Washington Post, February 7, p. A1.Lee, Chang Hee. 2001. ÒState Regulatory Commission Treatment of Advanced Services:Results of a Survey.Ó National Regulatory Research Institute, February.
Leeper, David.  2001. 
ÒA Long-term View of Short-Range Wireless.Ó  IEEE Computer, June,pp. 39-44.Leibovich, Mark. 1999. ÒFoes Place Ads Hitting AT&T-MediaOne Deal.Ó  Washington Post,May 7, p. E1.Lessig, Lawrence. 2000. ÒClinton Versus the Internet:  End Game.
Ó  New Republic, June 19.Available online at <http://www.thenewrepublic.com/061900/lessig061900.html>.Levey, Collin. 2001. ÒBookshelf: Commuting by Mountain Bike and Modem.Ó Wall StreetJournal, January 4, p. A16.Lewis, Michael. 2000. ÒBoom Box.Ó  New York Times Magazine, August 13, p. 36.Li, Kenneth. 2000. ÒKozmo.com, Media Company.Ó  The Industry Standard, May 1. Availableonline at <http://www.thestandard.com/article/0,1902,14545,00.html>.Lieberman, David. 1999. ÒWeb Growth Will Help Most Media.Ó  USA Today, November 10,p. 1A.Lippman, John, and Andy Pasztor. 2001. ÒHughes ElectronicsÕ DirecTV Reports a Substan-
tial Increase in Its Subscribers.Ó Wall Street Journal, January 17, p. A16.
Loftus, Peter. 2001. ÒData-Equipment Firms Trim Views as Spending Slims.Ó Wall StreetJournal, January 16, p. B6.Lohr, Steve. 1999. ÒIn AT&T Deal, Microsoft Buys Itself a Stake in Post-PC Era.Ó  New YorkTimes, May 7, p. C1.Louderback, Jim. 1999. ÒWireless Strikes Back.Ó ZDNet News, June 25. Available online at<http://www.zdnet.com/zdnn/stories/comment/0,5859,2283013,00.html>.Lu, Kevin. 1997. ÒCost Comparisons of FTTC and FTTH for Various Demands and Densi-ties,Ó published at  the Eighth International Workshop on Optical/Hybrid Access Net-
works. Paper 2.3, Atlanta, Georgia, March 2-5.Mack, Toni, and Mary Summers. 1999. ÒCheap Gamble: Sprint Enters High Stakes Game toWire Up America With Broadband Services.Ó  Forbes, July 5, p. 128.MacKie-Mason, Jeffrey K. 1999. Investment in Cable Broadband Infrastructure:  Open Access Is
Not an Obstacle. Ann Arbor, Mich.:  University of Michigan, November 5. Available
online at <http://www-personal.umich.edu/~jmm/papers/broadband.pdf>.MacMillan, Robert. 2001. ÒAs Free ISPs Fade, Others Raise Rates.Ó Washington Post, January26, p. E1.Mannion, Patrick. 2001. ÒFiber-to-the-Home Advocacy Group Formed.Ó EE Times, July 3.Available online at <http://www.csdmag.com/story/OEG20010703S0028>.Marable, Leslie. 2001. ÒBroadbandÑItÕs a City Thing.Ó The Industry Standard, May 18. Avail-able online at <http://www.thestandard.com/article/0,1902,24626,00.html>.Markoff, John. 1999. ÒMotorola to Offer a Chip That Can Support a Variety of Cell-PhoneStandards.Ó New York Times, November 1, p. C4.
Markoff, John. 2000. ÒEthernet Finds a New Level.Ó  New York Times, June 5, p. C1.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY231Martinez, Barbara. 2000. ÒAn Internet Race Nets Landlords Some Rich Perks.Ó  Wall StreetJournal, March 29, p. B1.Masud, Abdullah, and Brenda Neidigh . 2000. ÒCommonwealth of Virginia Restrictions onMunicipal Telecommunications.Ó June.
Mathews, Anna Wilde. 2001. ÒEchoStarÕs Loss Narrows on Growth in Subscriptions.Ó WallStreet Journal, May 4, p. B6.May, Randolph. 1999. ÒOn Unlevel Playing Fields: The FCCÕs Broadband Schizophrenia.ÓProgress on Point series, Progress and Freedom Foundation, December. Available onlineat <http://www.pff.org/POP_6.11.htm>.McCarthy, Bill. 1999. ÒIntroduction to the Directory of Internet Service Providers.ÓBoardwatch Magazine (Summer).
McClard,  Anne. (Undated). 
ÒUnleashed: Web Tablet Integration into the Home.ÓMediaOne Labs.McDonald, Glenn, and Cameron Crotty. 1999. ÒThe Digital Future.Ó  PCWorld.com, Novem-ber 19. Available online at <http://www.pcworld.com/resource/printable/article.
asp?aid=13926>.McFarland, Henry B. 2000. ÒEconomic Perspectives on Requiring Unbundled Access toCable Broadband Networks.Ó  2000 Annual Meeting Section of Antitrust Law, New
York, July 11.McGee, Art. 1999. ÒCulture, Class and Cyberspace Resources.Ó  Civicnet.org. Available onlineat <http://www.civicnet.org/comtechreview/culture.htm>.McGuire, David. 2001. ÒBells, Rivals Gear Up for Battle.Ó Washington Post, February 28.Available online at <http://www.washtech.com/news/telecom/7915-1.html>.McKay, Jim. 2000. ÒRural Ohio Creates Its Own Wireless Connectivity.Ó  Government Tech-nology (November). Available online at <http://www.govtech.net/publications/gt/
2000/nov/news/index.phtml>.McWilliams, Brian. 1999. Ò@Home Rolls Out Upstream Rate Limit.Ó  InternetNews.com, June24. Available online at <http://www.internetnews.com/isp-news/article/0,,8_144121,00.html>.McWilliams, Gary. 2000. ÒBroadJump Speeds ÔBroadbandÕ Installations.
Ó  Wall Street Jour-nal, February 3, p. B8.Mehta, Stephanie. 1999. ÒAvici Systems Breaks Through Bandwidth Bottleneck.Ó  Wall StreetJournal, May 13, p. B6.Mehta, Stephanie. 2000. ÒU.S. Market for Broadband Is Barely Tapped.Ó  Wall Street Journal,January 12, p. B8.Mehta, Stephanie, and Edward Felsenthal. 1999. ÒSupreme Court Restores Federal RulesAimed at Opening Local-Phone Markets.Ó  Wall Street Journal, Janurary 26, p. A2.Menendez, R.C., et al. 1997. ÒCost Comparisons of FTTC and FTTH for Various Demandsand Densities,Ó Eighth International Workshop on Optical/Hybrid Access Networks,
Atlanta, Georgia, March 2-5.Metropolitan King County Council. 1999. ÒOregon Decision Against AT&T/TCI FavorsCounty Council Demand for Consumer Choice Through Open Access.Ó June 4.
Mick, Collin, Bruce Tolley, and Willem Wery. 1999. ÒRunning 1000BASE-Y Gigabit Ethernetover Copper Cabling.Ó  Gigabit Ethernet Alliance, March 30.
Milgrom, Paul. 1996. ÒProcuring Universal Service: Putting Auction Theory to Work.Ó Lec-
ture at the Royal Swedish Academy of Sciences, December 9.Miller, Peter, Richard Civille, and Dirk Koning. 1999. ÒThe Emergence of Convergence.ÓCommunity Technology Review. Available online at <http://www.civicnet.org/comtechreview/editorintro.htm>.Musgrove, Mike. 1999. ÒThe Broadband Backlog.Ó Washington Post, December 31, p. E1.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.232BROADBANDNamioka, Aki Helen. 1999. ÒNegotiating Open Access with AT&T.Ó  Community TechnologyReview. Available online at <http://www.civicnet.org/comtechreview/seattleatt.htm>.National Association of State Information Resource Executives (NASIRE) and National As-sociation of State Telecommunications Directors (NASTD). 2000. Telecommunications:Closing the Digital Divide with Broadband Internet Access. Lexington, Kentucky:  NASIRE,
October. Available online at <http://www.nascio.org/publications/Telecomm_Report_Oct2000.pdf>.National Cable and Telecommunications Association (NCTA). 2001. Industry Statistics.Washington, D.C.:  NCTA. Available online at <http://www.ncta.com/industry_
overview/indStat.cfm>.National Exchange Carrier Association (NECA). 2000. NECA Rural Broadband Cost Study:Summary of Results. Whippany, N.J.:  NECA. Available online at <http://www.neca.
org/broadban.asp>.National Science Foundation (NSF). 1998. ÒWorkshop on Tetherless T3 Workshop: InterimReport.Ó Washington, D.C.:  NSF, November.
National Science Foundation (NSF). 1999. ÒDraft/Preliminary Report: First/Last Mile Work-shop.Ó  Washington, D.C.:  NSF, April 26.
National Telecommunications and Information Administration (NTIA). 2000. FallingThrough the Net:  Toward Digital Inclusion
. Washington, D.C.: NTIA, October. Availableonline at <http://www.ntia.doc.gov/ntiahome/digitaldivide/index.html>.National Telecommunications and Information Administration (NTIA). 2000. ÒFederal Op-erations in the 1755-1850 MHz Band:  The Potential for Accommodating Third
Generation Mobile Systems,Ó Interim Report (NTIA Special Publication 01-41). Wash-
ington, D.C.:  NTIA, November 15. Available online at <http://www.ntia.doc.gov/
osmhome/reports/imt2000/titlepage.html>.National Telephone Cooperative Association. 1999. ÒDial-tone Is Not Enough: Serving TribalLands.Ó November.
New York Times. 2001. ÒReport Counts Computers in Majority of U.S. Homes.Ó September 7,
p. A15.Nickell, Joe Ashbrook. 2000. ÒHome on the Web.Ó  Industry Standard, October 16. Availableonline at <http://www.thestandard.com/article/display/0,1151,19290,00.html>.Nie, Norman, and Lutz Erbring. 2000. ÒInternet and Society: A Preliminary Report.ÓStanford, Calif.:  Stanford Institute for the Quantitative Study of Society, February 17.
Nielsen/Netratings. 2001. ÒNew York Local Market Dominates Broadband Usage, Accord-ing to Nielsen/NetratingsÓ (press release). New York:  Nielsen/Netratings, May 15.
Norris, Floyd. 2001. ÒItÕs Not Just AT&T: How Telecom Became a Black Hole.Ó Wall StreetJournal, February 16, p. C1.National Telecommunications and Information Administration (NTIA) and Rural UtilitiesService (RUS). 2000. Advanced Telecommunications in Rural America:  The Challenge of
Bringing Broadband Service to All Americans. Washington, D.C.:  NTIA, April. Available
online at <http://www.ntia.doc.gov/reports/ruralbb42600.pdf>.Oakes, Chris. 2000. ÒNapster Not at Home with Cable.Ó  Wired, April 7. Available online at<http://www.wired.com/news/technology/0,1282,35523,00.html>.OÕBrien, Chris. 1999. ÒCable Internet Products Draw Ire of Consumer Groups.Ó  San JoseMercury News, September 29.Odlyzko, Andrew. 2000. ÒThe Current State and Likely Evolution of the Internet.Ó  Proc.Globecom Õ99, IEEE, pp. 1869-1875.Odlyzko, Andrew. 2001. ÒContent Is Not King.Ó  First Monday 6(2). Available online at
<http://www.firstmonday.org/issues/issue6_2/odlyzko/>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY233Omoigui, Sirbu, Eldering, and Himayat. 1996. ÒComparing Integrated Broadband Architec-tures from an Economic and Public Policy Perspective.Ó  Telecommunications and InternetPolicy.Ortiz, Sixto. 2000. ÒBroadband Fixed Wireless Travels the Last Mile.Ó Computer 33(7): 18.
Orwall, Bruce, and Kara Swisher. 1999. ÒDisney Discusses Buying All of Infoseek.Ó  WallStreet Journal, June 8, p. A3.Ota, Kiyohisa. 1999. ÒNTT: Transforming into Information Distributor.Ó  Merrill Lynch In-
Depth Report.Owen, Bruce. 1999. ÒEconomist Says Internet Use Is Limited.Ó  Tech Law Journal, July 9.Available online at <http://www.techlawjournal.com/internet/19990709b.htm>.Pandey, Amit. 1999. ÒCaching 101: WhatÕs the ROI?Ó ISP-Planet, July 5. Available online at<http://www.isp-planet.com/technology/cache101-4.html>.Papadakis, Maria C. 2000. ÒComplex Picture of Computer Use in the Home Emerges.Ó Issue
Brief, National Science Foundation, Directorate for Social, Behavioral, and EconomicSciences. March 31.Parker, Edwin B. 2000. ÒClosing the Digital Divide in Rural America.Ó TelecommunicationsPolicy 24, May. Available online from <http://www.tpeditor.com/contents/2000/
parker.htm>.Parker, Suzi. 2000. ÒNew Economy Recasts the Rural South.Ó Christian Science Monitor, May3, p. 3.Pastore, Michael. 1999. ÒConsumer ISPs Giving Way to Business Providers.ÓInternetnews.com, Nov. 11.Pasztor, Andy. 2000. ÒHughes Electronics Agrees to Provide Satellite-Based Web ServiceAcross India.Ó  Wall Street Journal, March 24, p. B4.Pasztor, Andy. 2000. ÒPanAmSat, Seeking a Niche, Plans Internet Video Service.Ó  WallStreet Journal, March 29, p. B7.Pasztor, Andy. 2001. ÒLoral Scraps Plans to Be Major Operator of Two-Way Satellite Broad-band Systems.Ó Wall Street Journal, February 1, p. A4.Paul Kagan Associates. 2001. The Kagan Media Index, January 31.Pease, Robert. 2000. ÒRural Areas Present Better Business Case for Fiber-to-the-home.ÓLightwave 17 (7): 1. June.
Peterson, Andrea. 2000. ÒTwo Brothers Bet Everything on Free-Broadband  Start-Up.Ó  WallStreet Journal, March 23, p. B8.Pine, David. 1999. ÒLet the Feds Regulate.Ó  iMP, December. Available online at <http://www.cisp.org/imp/december_99/12_99pine.htm>.Piscitello, David M. 2000. ÒThe True Killer Application for Broadband Local Access.Ó  CLEC-Planet. Available online at <http://www.clecplanet.com/business/00072piscitello.htm>.Plotnikoff, David. 2000. ÒWiring the Rural West.Ó  San Jose Mercury News. Available onlineat <http://www0.mercurycenter.com/svtech/news/special/ruralwest/>.Pollack, Andrew. 1999. ÒAmerica Online to Put $1.5 Billion Into a Hughes Alliance.Ó  NewYork Times, June 22, p. C6.Pomerantz, Dorothy. 2001. ÒIf You Overbuild It.Ó Forbes, April 16, p. 144.Poulton, Ken. 1999. ÒThe Palo Alto Fiber to Home TrialÓ (slide presentation), November 24.Available online at <http://alcatraz.labs.agilent.com/Ken_Poulton/ftth/poulton-
v10e/>.Raik-Allen, Georgie. 2000. ÒISky Shoots for the Stars.Ó  Red Herring, January 19. Availableonline at <http://www.redherring.com/vc/2000/0119/vc-isky.html>.Ramstand, Evan, and Dean Takahashi. 1999. ÒSony, TiVo Set Deal on TV-Recording De-vice.Ó  Wall Street Journal, September 9, p. B6.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.234BROADBANDRaymond James and Associates. 1999. ÒHigh Speed Access . . . Working in Real Time,ÓDecember 22.Raymond James and Associates. 2000. ÒOptical Networking: Turn on the Lights,Ó June 13
Reuters. 1999. ÒF.C.C. Approves Line Sharing for Data Carriers.Ó  New York Times, Novem-ber 19, p. C5.Reuters. 1999. ÒReal Estate Companies Offering Data Services.Ó  New York Times, Oct. 6.Reuters.  1999. 
ÒTen Million U.S. Homes Seen Going Digital by 2003.Ó  San Jose MercuryNews, October 20.Reuters. 1999. ÒU.S. Internet Users Surpass 100 Million MarkÑStudy.Ó  San Jose MercuryNews. Available online at <http://www.sjmercury.com/svtech/news/breaking/internet/docs/1065381i.htm>.Reuters. 1999. ÒVictory for Los Angeles Cable Providers.Ó  New York Times, June 19, p. C2.Rich, Motoko. 2001. ÒFirms, Employees Look to Home Offices Again.Ó Wall Street Journal,October 3, p. B8.Richards, Bill. 2001. ÒFor a Montana Utility, a Gamble on Telecom Looks Like a Bad Call.ÓWall Street Journal, August 22, p. A1.Richtel, Matt. 1999. ÒExcite@Home to Separate Cable and Content Divisions.Ó  New YorkTimes, November 22, p. C2.Riley, Jason L. 1999. ÒFaster Web Access Coming (One Day) to a Home Near You.Ó  WallStreet Journal,  July 14, p. A23.
Riley, Patricia, Anu Mandavilli, and Rebecca Heino. 2000. ÒObserving the Impact of Com-munication and Information Technology on ÔNet-WorkÕ.Ó Telework and the New Work-place of the 21st Century
. U.S. Department of Labor, Washington, D.C. Available onlineat <http://www.dol.gov/dol/asp/public/telework/p2_3.htm>.Rohde, David. 1999. ÒDSL Explosion Ready to Rip.Ó  Network World, July 7. Available onlineat <http://www.nwfusion.com/news/1999/0719belldsl.html>.Rohde, David. 1999. ÒMore trouble for AT&T Cable Plan: Big Rivals Enter Fight to OpenCable Nets to All.Ó  Network World, June 28. Available online at <http://www.nwfusion.com/news/1999/0628opencable.html>.Romero, Simon. 2001. ÒShining Future of Fiber Optics Loses Glimmer.Ó  New York Times,June 18, p. A1.Romero, Simon. 2001. ÒWeb Users Left Scrambling as Big D.S.L. Network Shuts Down.ÓNew York Times, March 30, p. C1.Rosenberg, Scott. 2000. ÒGive My Regards to Broadband.Ó  Salon, March 17. Available onlineat <http://www.salon.com/tech/col/rose/2000/03/17/broadband/print.html>.Rosenwein, Rifka. 2000. ÒWhy Media Mergers Matter.Ó BrillÕs Content, December 1999/January.Rowe, Bob. 1999. ÒTelecom and Technology Issues Affecting State Utility CommissionsÓ(presentation given at the  Annual Conference of the Alliance for Public Technology,

March). Available online at <http://www.apt.org/confer/1999/rowe.html>.Rowe, Bob. 2000. ÒImplementing a Cooperative Federalist Approach to Telecom Policy.ÓSpeech presented at Federalist Society, Washington, D.C., September 27.Rowe, Bob. 2000. ÒStrategies to Promote Advanced Telecommunications Capabilities.Ó Fed-eral Communications Law Journal 52(2): 381. Available online at <http://www.law.
indiana.edu/fclj/pubs/v52/no2/rowe.pdf>.Rowe, Bob. 2000. ÒSubstance Plus Process:  Telecom Regulation Reforms to Protect Con-
sumers, Preserve Universal Service, and Promote Competition.Ó University of ColoradoLaw Review 71(4).
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY235Rural Task Force (RTF). 2000. Rural Task Force Recommendation to the Federal-State Joint Boardon Universal Service (before the Federal Communications Commission (FCC)). Wash-
ington, D.C.:  FCC, September 29. Available online at <http://www.wutc.wa.gov/

rtf/rtfpub.nsf/>.Saleh, Adel A.M., and Jane M. Simmons. 1999. ÒArchitectural Principles of Optical Regionaland Metropolitan  Access Networks.
Ó Journal of Lighwave Technology. September.Sandberg, Jared. 2000. ÒAfter 50 Years of Effort, Interactive TV May be Here.Ó Wall StreetJournal, December 7, p. B1.Sandberg, Jared. 2001. ÒBroadbandÕs Chicken-and-Egg Bind.Ó New York Times, April 2, p.B1.Sanford C. Bernstein & Co. and McKinsey & Company. 2000. Broadband!  New York. Janu-
ary.Schement, Jorge. 1999. ÒOf Gaps by Which Democracy We Measure.Ó iMP, December.Schement, Jorge. 1999. ÒOf Nodes and Castles:  The Changing Information Environment of
the Home.Ó Presentation given at 
ÒThe Role of Public Service Media in the DigitalTelecommunications AgeÓ conference, June 21, Bethesda, Maryland. Video archive
available online at <http://nc.psu.edu/archive1.html>.Schiesel, Seth. 1998. ÒPC Companies and Bells to Petition U.S.Ó New York Times, December7, p. C1.Schiesel, Seth. 1999. ÒAT&T Conjures Up Its Vision for Cable, but Can It Deliver?Ó New YorkTimes, May 7, p. A1.Schiesel, Seth. 1999. ÒAT&TÕs Embrace of New Technology Signals Next Era.Ó New YorkTimes, March 8, p. C1.Schiesel, Seth. 1999. ÒBell Atlantic Says Network Is Fully Open.Ó New York Times, April 14,p. C11.Schiesel, Seth. 1999. ÒJumping off the Bandwidth Wagon.Ó New York Times, July 11, p. C1.Schiesel, Seth. 1999. ÒMarket Place:  Notes on Corporate Culture and Possibilities as MCI
Worldcom Meets Two Years After Its Creation.Ó New York Times, June 7, p. C13.Schiesel, Seth. 1999. ÒMerger Deal with Plenty of Intrigue.Ó New York Times, July 22, p. C1.Schiesel, Seth. 1999. ÒStart-Up Leads Phone Cause in Battle for Internet Access.Ó New YorkTimes, May 17, p. C1.Schiesel, Seth. 1999. ÒThe Outlook for Cable Access.Ó New York Times, August 9, p. C1.Schiesel, Seth. 2000. ÒAT&T Takes Full Control of at Home Cable Venture.Ó New York Times,March 30, p. C1.Schiesel, Seth. 2000. ÒFor Most Local Phone Users, Choice Is Not Yet an Option.Ó New YorkTimes, November 21, p. C1.Schiesel, Seth. 2000. ÒU.S. May Pressure Landlords to Allow Digital Competition.Ó NewYork Times, October 12, p. A1.Schiesel, Seth. 2001. ÒHouse to Focus On Net Access and Competition.Ó New York Times,September 3, p. C1.Schiesel, Seth. 2001. ÒSitting Pretty: How Baby Bells May Conquer Their World.Ó New YorkTimes. April 22, p. C1.
Schnurr, Lewis. 2000. ÒMedia and Telecommunications Regulation and the Internet: Regu-late or Strangulate?Ó Media Law and Policy VIII (2).
Schrader, William L. 1999. ÒInternet Access and the Consumer.Ó Testimony of William L.
Schrader, Chairman & CEO PSINet Inc., before the Senate Committee on Commerce,Science and Transportation. April 13.Schwartz, John. 1999. ÒDelivering on Promise of Convergence.Ó  Washington Post, May 7, p.E1.Schwartz, John. 1999. ÒHow Much Room in the Fat Pipe?Ó Washington Post, September 19,p. H1.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.236BROADBANDSchwartz, John. 1999. ÒOpen-Access Online Fight Escalates.Ó Washington Post, July 28, p. E1.Schwartz, John. 2001. ÒWiring the City: Humans WonÕt Do.Ó New York Times, March 8, p.G1.Semon, D. 2001. ÒA Brief History of Data Over Cable.Ó  Time Warner. January.
Shannon, Victoria. 1999. ÒWhy ItÕs Slow Going on the Net,Ó Washington Post, May 24, p. F20.Shin Luh, Shu. 1999. ÒAOL Sees Future in Palms.Ó Washington Post, June 23, p. E1.Shin Luh, Shu. 1999. ÒPhone Companies Reach Pact.Ó Washington Post, August 3, p. E3.Shishkin, Philip. 2000. ÒAOL, Time Warner Offer Open Access for Five Years.Ó Wall StreetJournal, September 25, p. A28.Shishkin, Philip. 2000. ÒEC Scrutinizes MicrosoftÕs Telewest Plan.Ó Wall Street Journal, June13, p. A22.Shumate, Paul W. 1998. ÒComparing the Latest High-Speed Access Technologies: FTTx,HFC, xDSL, and Wireless,Ó presented at IEEE Lasers and Electro-optics Annual Meet-
ing, December 3, Orlando, Fla.Sicker, Douglas, et al. 2000. ÒThe Internet Interconnection Conundrum.Ó  Draft OPP work-
ing paper. April.Siembab, Walter. 1999. ÒPublic Transit for the Information Highway.Ó Available online at
<http://www.civicnet.org/comtechreview/public_transit.htm>.Simon, Greg, and Rich Bond. 1999. ÒFreedom of Choice: Why Local Control Protects Con-sumersÕ Choices.
Ó iMP, December. Available online at <http://www.cisp.org/imp/december_99/12_99simon.htm>.Sliwa, C. 1999. ÒJini: Promising Technology, But Will It Catch On?,Ó Computerworld, March15, p. 76.Smart, Tim. 1999. ÒLockheed, Partners Plan System of Satellites.Ó  Washington Post, May 7,p. E10.SMART Winnipeg. 2000. ÒThe Case for Municipal Fiber White PaperÓ (white paper).
Winnipeg, Manitoba:  SMART Winnipeg, August 15.  Available online at <http://

www.smartwinnipeg.mb.ca/Municipal_Fibre.htm>.Solomon, Deborah. 2000. ÒAmid Steep Business Declines, Phone Giant Calls It Splits; Cut-ting the Prized Dividend.Ó Wall Street Journal, October 26, p. B1.Speta, James. 2000. ÒHandicapping the Race for the Last Mile?: A Critique of Open AccessRules for Broadband Platforms.Ó Yale Journal on Regulation, Winter.Speta, James. 2000. ÒThe Vertical Dimension of Cable Open Access.Ó University of ColoradoLaw Review 71(4), Fall.
Sprint. 2000. ÒMMDSÑBetter Than Sliced BreadÓ (white paper). Available online at <http:
//www.sprintbroadband.com/prsite/articles/MMDS.html>.Staff Report. 1999. ÒPanel Rejects Ordinance in Internet/Cable-TV Case.Ó Wall Street Jour-nal, October 20, p. B11.St. Arnaud, Bill. 2000. ÒGigabit Internet to Every Canadian School by 2005,Ó discussion
paper. Ottawa:  CAnet-3, February 4. Available online at <http://www.canet3.net/
library/papers/GigabittoHomeby2005.html>.Stern, Christopher. 2000. ÒBroadband Market Growth Slows.Ó  Washington Post, August 28,p. E01.Stern, Christopher. 2000. ÒBroadcasterÕs Promise of a Digital TV Age Has Not Been Met,and Now Congress Is Having Second Thoughts About Its Role.Ó Washington Post, De-cember 17, p. H1.Stevenson, Ted. 1999. ÒISP Valuation: From the HorseÕs Mouth.Ó  ISP-Planet.com, November10. Available online at <http://www.isp-planet.com/business/ispcon_valuation.
html>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY237St. Sauver, Joe. 2000. ÒA Fiber Optic Primer and Tutorial: Designing Networks for Opti-mum Performance.Ó Computing News [University of Oregon].  Available online at
<http://cc.uoregon.edu/cnews/summer2000/fiber.html>.Swisher, Kara, and Khanh Tran. 1999. ÒHigh-Stakes Internet Battle Erupts in San Fran-cisco.Ó Wall Street Journal, July 26, p. A24.Taglang, Kevin. 1999. ÒCommunity Technology Centers: Closing the Digital Divide.Ó OMBWatch, September 29.Taschdjian, Martin. 2000. ÒFrom Open Networks to Open Markets: How Public Policy Af-fects Infrastructure Investment Decisions.Ó  Center for Information Policy Research,
Harvard University, Cambridge, Mass. November.Tech Law Journal. (Undated). ÒSummary of Bills Affecting Broadband in the 106th Con-gress.Ó  Available online at <http://techlawjournal.com/cong106/broadband/
Default.htm>.Technology Review. 2001. ÒSpecial Issue: Wired and Wireless.Ó June.
Technology Review. 2001. ÒA Very Long Distance:  A Regulatory Call Put Cell Phones on
Hold.Ó  May, p. 110.
Tedeschi, Bob. 2000. ÒE-Commerce Report: Sites Not Yet Pitching at Full Speed.Ó New YorkTimes, December 4.Telecommunications Reports. 1999. ÒAIG TelecomÕs Bandwidth ÔForwards MarketÕ Looks To-
ward Rapid Growth in Telecom Minutes.Ó August 2.
Telecommunications Reports. 1999. ÒALTS Eyes Strong Enforcement, Service Integration;Kennard Urges Carriers to Go into Residential Markets.Ó May 10.
Telecommunications Reports. 1999. ÒAT&TÕs Plans Are Focus of Senate Hearing.Ó February
19.Telecommunications Reports. 1999. ÒBell Atlantic, IBM Set Home Networking Venture.Ó  Feb-ruary 8.Telecommunications Reports. 1999. ÒBell Atlantic, SBC Form New Broadband Coalition.Ó July5.Telecommunications Reports. 1999. ÒCanadaÕs Teleglobe Unveils $5 Billion Global BroadbandNetwork.Ó  May 17.
Telecommunications Reports. 1999. ÒCanada Takes Hard Line on Cable Modem Access; U.S.Court Adjusts Schedule for Portland Review.Ó July 12.
Telecommunications Reports. 1999. ÒC & W USA to Invest $670 M In Fiber Internet Back-bone.Ó April 19.
Telecommunications Reports. 1999. ÒCompetitive Carriers Set to Unveil Broadband Coali-tion.Ó March 29.
Telecommunications Reports. 1999. ÒCRTC Renounces ÔNew Media ServicesÕ Regulation, Re-
affirms Internet Access Rules.Ó  May 24.
Telecommunications Reports. 1999. ÒDebate over Reallocated DTV Spectrum Exposes Ruts inInformation Superhighway.Ó July 26.
Telecommunications Reports. 1999.  ÒFCCÕs Decision Against Cable Modem Probe Fails toHinder Push for Opening Networks.Ó February 8.
Telecommunications Reports. 1999. ÒGoodlatte Pledges Persistence in Pushing BroadbandBills.Ó May 24.
Telecommuncations Reports. 1999. ÒHome Networking Alliance Eyes Broadband Synergies.ÓAugust 2.Telecommunications Reports. 1999. ÒLong Distance Group Opposes Broadband Service Mea-sures.Ó June 28.
Telecommunications Reports. 1999. ÒNTIA Wants Few Changes to FCC Unbundling Rules.ÓAugust 9.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.238BROADBANDTelecommunications Reports. 1999. ÒOpen Access to Cable Modems Must be National Rule,NACo Says,Ó and 
ÒCable TV Providers Challenge Broward on Open Access.Ó July 26.
Telecommunications Reports. 1999. ÒProgramming ÔLeased-AccessÕ Rules Don
Õt Apply toInternet Services, Cable TV Operators Tell FCC.Ó July 19.
Telecommunications Reports. 1999. ÒRhythmsÕ Hapka Wants ILEC Performance, Not Prom-
ises.Ó June 28.
Telecommunications Reports. 1999. ÒRural Senators Press FCC, NTIA for Internet Access Im-provements.Ó May 24.
Telecommunications Reports. 1999. ÒSatellite Industry Vows to Solve Reliability Puzzle,Launches Itself into Internet, Multimedia Markets.Ó February 8.
Telecommunications Reports. 1999. ÒService Complaints Leveled at AT&T Wireless, FinlandÕsNokia.Ó March 15.
Telecommunications Reports. 1999. ÒUS West Plans to Offer ÔWeb Phone,Õ Cuts DSL Rates.
ÓMay 17.Telecommunications Reports. 2000. ÒNew Senate Broadband Bills Focus on Financial Incen-tives.Ó April 3.
3Com Corporation. 1999. ÒBuilding a Connected Community: A Municipal Blueprint from3Com.Ó  Santa Clara, Calif.:  3Com, August.
Thurm, Scott. 1999. ÒTeledesic ÔSky InternetÕ May Start Sooner.
Ó Wall Street Journal, Septem-ber 27, p. B6.Thurm, Scott. 2000. ÒMcCaw to Fuse Satellite-Phone Systems and Teledesic.Ó Wall StreetJournal, March 2, p. B8.Thurm, Scott, and Jim Carlton. 2000. ÒA Fiber-Optics Powerhouse Is Poised to SpeedTechnologyÕs March.Ó Wall Street Journal, January 20, p. B1.Thurm, Scott, and Mark Heinzl. 2000. ÒFiber Optics Becomes Latest Tech Sector to Crashand Burn.Ó Wall Street Journal. October 26, p. C1.
Thurm, Scott, and Glenn R. Simpson. 2001. ÒTech Industry Seeks Salvation in High-SpeedInternet Connections.Ó Wall Street Journal. June 25, p. B1.Trombly,  Maria. 2000. ÒWireless Data Access Via Cell Phone to Skyrocket This Year, StudySays,Ó Computerworld, April 17. Available online at <http://www.computerworld.com/cwi/story/0,1199,NAV47_STO43885,00.html>.Ungerer, Herbert. 2000. Access Issues Under EU Regulation and Antitrust Law: The Case ofTelecommunications and Internet Markets. Center for Information Policy Research,
Harvard University, July. Available online at <http://www.pirp.harvard.edu/pubs_pdf/ungerer/ungerer_Access_I_00_3.pdf>.U.S. Census Bureau. 2000. Statistical Abstract of the United States. Washington, D.C.:  U.S.
Census Bureau, Department of Commerce. Available online at <http://www.census.gov/prod/2001pubs/statab/sec18.pdf>.U.S. Congress, Office of Technology Assessment. 1991. Rural America at the Crossroads: Net-working for the Future (OTA-TCT-471). Washington, D.C.: U.S. Government Printing
Office, April. Available online at <http://www.wws.princeton.edu/~ota/disk1/1991/9136_n.html>.U.S. Congress, Office of Technology Assessment. 1995. Telecommunications Technology andNative Americans: Opportunities and Challenges, August.U.S. Department of Commerce, NTIA. 2000. ÒFederal Operations in the 1755-1850 MhzBand: The Potential for Accommodating Third Generation Mobile Systems.Ó Interim
Report, November 15 (NTIA Special Publication 01-41). Available online at <http://www.ntia.doc.gov/osmhome/reports/imt2000/titlepage.html>.U.S. House of Representatives (107th Congress). 2001. ÒInternet Freedom and BroadbandDeployment Act of 2001Ó (H.R. 1542). Available online at <http://thomas.loc.gov>.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY239U.S. House of Representatives, Commerce Committee, Subcommittee on Telecommunica-tions, Trade, and Consumer Protection.  2000. 
ÒHearing on the Status of Deploymentof Broadband Technologies. April 11.  Available online at <http://com-

notes.house.gov/media/040112000ttcp.ram>.Van, Jon. 1999. ÒSpeedier Internet Access on Tap: Ameritech Enters Alliance with AOL.ÓChicago Tribune, July 22.
Varian, Hal R. 2000. ÒCool Media: A New Generation Is Turning the Tables on Television.ÓThe Industry Standard, November 20, p. 293. Available online at <http://www.thestandard.com/article/display/0,1151,20004,00.html>.Varian, Hal R. 2000. ÒEstimating the Demand for Bandwidth,Ó technical report. Berkeley,
Calif.:  University of California, Berkeley, August 29. Available online at <http://
www.sims.berkeley.edu/~hal/Papers/wtp/wtp.pdf>.Varian, Hal R. 2000. ÒField of Dreams: What If You Build Broadband and No One Comes?ÓThe Industry Standard, March 20. Available online at <http://www.thestandard.com/article/display/0,1151,12944,00.html>.Verhovek, Sam. 1999. ÒAT&T Fights Push to Open Cable Lines to Its Rivals.Ó WashingtonPost, November 2, p. A20.Veronis Suhler Media Merchant Bank. 2000. ÒCommunications Industry Forecast: Histori-cal and Industry Projections for 12 Industry Segments.Ó July.
Veronis Suhler Media Merchant Bank. 2000. ÒCommunications Industry Forecast: Five-yearHistorical Report of Publicly Reporting Companies.Ó October.
Vogelsang, Ingo, and Bridger M. Mitchell. 1997. Telecommunications Competition: The LastTen Miles. Cambridge, Mass.:  MIT Press.
Vogelsang, Ingo, and Glenn Woroch. 1998. ÒLocal Telephone Service: A Complex Dance ofTechnology, Regulation and CompetitionÓ in Larry L. Deutsch, ed., 
Industry Studies,2nd Edition. Armonk, N.Y.:  M.E. Sharpe. Available online at <http://elsa.berkeley.
edu/~woroch/dance.pdf>.Waddell, Cynthia. 1999. ÒElectronic Curbcuts: Universal Access for Everyone.Ó iMP, De-cember. Available online at <http://www.cisp.org/imp/december_99/12_99waddell.htm>.Walker, Leslie. 1999. ÒClosing the Distance: Instant Messaging Is Talk of Online World.ÓWashington Post, July 6, p. A1.Wallace, Bob. 1999. ÒUUNet to Build, Expand Data Centers for $100M.Ó  Computerworld,August 9, p. 14.Wall Street Journal. 2000. ÒTown Proves Online Access IsnÕt Enough.Ó September 5, p. B13.
Wall Street Journal. 2001. ÒReality Bytes.Ó January 29, p. B8
Washington Post. 2000. ÒDSL Gaining on Cable as the Big Pipe of Choice.Ó Washington Post,February 10, p. E10. Available online at <http://www.washingtonpost.com/wp-srv/WPlate/2000-02/10/204l-021000-idx.html>.Washington Post. 2001. ÒAOLÕs Minutes.Ó  March 8, p. E11.
Weare, Christopher. 1996. ÒInterconnections: A Contractual Analysis of the Regulation ofBottleneck Telephone Monopolies.Ó Annenberg School for Communication, Univer-
sity of Southern California. Oxford University Press.Weber, Thomas. 1999. ÒAOL Deal Envisions Web Surfing via Satellite.Ó Wall Street Journal,May 12, p. B1.Weber, Thomas, and Stephanie N. Mehta. 1999. ÒFast Phone Lines May Help AOL TrumpCable TV.Ó Wall Street Journal, May 7, p. B1.
Weber, Thomas, and Stephanie N. Mehta. 1999. ÒWeb, Telephone Prove No Match for ÔStarWars.ÕÓ Wall Street Journal, May 13, p. B1.Weil, Nancy. 1999. ÒHome Networking Group Picks Next Phoneline Spec.Ó IDG.net, IDGNews Service, Boston Bureau, July 27.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.240BROADBANDWeller, Dennis. 1996. ÒTransition Strategies for Regulation,Ó IDATE, 
Communications & Strat-egies, No. 23, 3rd Quarter, pp. 99-115.Weller, Dennis. 1999. ÒObligations for Universal Service Obligations.Ó GTE, November.
Available online at <http://www.comslaw.org.au/research/Universal/19991101_Weller.html>.Wigfield, Mark. 2000. ÒSchoolsÕ Spectrum Rights Promise a Bonanza, But Can They Cash
In?Ó Wall Street Journal, September 6, p. B1.Wigfield, Mark. 2001. ÒRural Virginia Town Fights for Broadband Access.Ó Wall Street Jour-nal, June 7, p. B6.Wilke, John R. 2000. ÒAOL, Time Warner Pledge Cable Access.Ó Wall Street Journal, Decem-ber 14, p. A3.Williamson, Oliver E. 1975. Markets and Hierarchies. New York:  The Free Press.
Williamson, Richard. 2000. ÒSatellite Net Service Launches.Ó  Interactive Week, November12. Available online at <http://www.zdnet.com/zdnn/stories/news/0,4586,2652654,00.html>.Williamson, Richard. 2001. ÒAT&T Completes First Open Access Cable Trial.Ó ZDNet,June 8. Available online at <http://www.zdnet.com/filters/printerfriendly/0,6061,2770807-3500.html>.Wingfield, Nick. 1999. ÒFree Web Services Challenge AOLÕs Dominance.Ó Wall Street Jour-nal, September 23, p. B8.Wingfield, Nick. 1999. ÒSandpiper Aims to Prevent Event-Driven Web Pileups.Ó  Wall StreetJournal, June 17, p. B10.Wirbel, Laura. 2000. ÒNew Carriers Follow Alternate Broadband Route.Ó  EE Times, Febru-ary 8. Available online at <http://www.eetimes.com/story/OEG20000208S0008>.Witt, Sarah. 1999. ÒBroadbandÕs First Beachhead: High-Speed Internet Service for Multi-Tenant Buildings Leads a Gradual Move to Providing Fast Access for All.Ó  InternetWorld, June 14.
Wolcott, David A. 2001. ÒAn ALTS Analysis: Local Competition Policy & The NewEconomy.Ó ALTS, February 2.
Wolverton, Troy, and Wylie Wong. 2000. ÒInternet World Showcases Broadband Moves.ÓCNET News.com, April 7. Available online at <http://news.cnet.com/news/0-1004-200-1661401.html>.Woolley, Scott. 2000. ÒFast Glass.Ó Forbes, November 13, p. 322.Working Group on Digital Subscriber Line Access (T1E1.4). 2001. American National Stan-dard for TelecommunicationsÑSpectrum Management for Loop Transmission Systems(T1.417-2001). Standards Committee T1. Washington, D.C.:  Alliance for Telecommu-
nications Industry Solutions.Working Party on Telecommunications and Information Services Policies; Committee forInformation, Computer and Communications Policy. 2001. The Development of Broad-band Access in OECD Countries. Paris:  OECD, October.
World Wide Packets. 2000. ÒLast Mile Broadband TechnologiesÓ (white paper). Available
online at <http://www.worldwidepackets.com/solutions/papers/wp_lastmile.jsp>.World Wide Packets. 2000. ÒWorld Wide Packets Deploys First Gigabit Ethernet BroadbandSolution with Grant County Washington PUDÓ (press release), August 7. Available
online at <http://www.wwp.com/news/pressRelease.jsp?id=17>.Woroch, Glenn A. 1998. ÒFacilities Competition and Local Network Investment: Theory,Evidence and Policy Implications.Ó June. Available online at <http://
elsa.berkeley.edu/~woroch/faccomp.pdf>.XDSL Today. 2000. ÒUS West and Consortium of 13 Competitive Local Exchange CarriersSign NationÕs First Region-Wide ÔLine-SharingÕ Agreement.
Ó May 1. Available online
at <http://www.xdsl.com/newsreleases/xdsl/11151.asp>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.BIBLIOGRAPHY241Young, Shawn. 2001. ÒCovad, One of Last DSL Competitors, Blames Troubles on Bell Tac-tics.Ó Wall Street Journal, August 9, p. B1.Young, Shawn. 2001. ÒNorthpoint Communications Files for Chapter 11 Creditor Protec-tion.Ó Wall Street Journal, January 17, p. B10.Young, Shawn. 2001. ÒRhythms Tells Customers It Will Close.Ó  Wall Street Journal, August13, p. B3.Zelnick, Nate. 2000. ÒPackets from Heaven.Ó Internet World, March 30. Available online at<http://www.internetworld.com/news/archive/03302000.jsp#3.30sat>.Zerega, Blaise, and Scott Lajoie. 1999. ÒWill They Come? Builders of High-Bandwidth Net-works May Be Overestimating Their Potential Market.Ó Forbes, November 29.Zerega, Blaise. 2000. ÒCarriers Shift from Voice and Data Transmission to New High-Band-width Services.Ó Red Herring, December 4.Zigmont, Jason. 1999. ÒPricing Your Services.Ó ISP-Planet.com, June 25. Available online at<http://www.isp-planet.com/business/pricing3a.html>.Zona Research. 1999. ÒThe Economic Impacts of Unacceptable Web Site Download Speeds.ÓAvailable online at <http://www.zonaresearch.com/deliverables/white_papers/wp17/>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.245
In the course of its work, the Committee on Broadband Last MileTechnology developed highly detailed material related to various broad-
band technologies. The committee decided that this level of detail was not
appropriate for the main text of its report, but provides the material,
which is not intended to be comprehensive, in this appendix for the reader

interested in learning more about broadband technologies.HYBRID FIBER COAX TECHNOLOGY1Coaxial CableThe foundation upon hybrid fiber coax (HFC) broadband communi-cations networks are based is coaxial cable (Figure A.1), a radio frequency
(RF) transmission line capable of transporting a large number of carriers
(channels). At the head end, or central signal-processing center, each car-
rier is modulated with baseband analog or digital information, and all
carriers are multiplexed together in the frequency domain (Figure A.2).
Spectral separation is accomplished through the use of frequency-selec-
tive diplex filters to allow simultaneous transmission of information in
opposite directions (Figure A.3), commonly called ÒreverseÓ (i.e., from
the home to the head end) and ÒforwardÓ (from the head end to the1Adapted from James Chiddix. 1999. ÒThe Evolution of the U.S. TelecommunicationsInfrastructure Over the Next Decade. TTG2: Hybrid-Fiber-Coax TechnologyÓ (IEEE work-
shop paper).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.246APPENDIX AA, Metallic center conductorB, Dielectric (nonconducting)
C, Metallic outer conductor
D, Plastic jacketed covering (optional)FIGURE A.1Coaxial cable (cut-away view).
Two-Way Radio216 - 470 MHzTV7-13FMTV2-6Two-WayHam79 Analog TV ChannelsRev5-40 MHz54-550 MHzFIGURE A.2Typical RF spectrum for analog cable television.
Reverse carriersForward carriersRF spectrumDiplex filterHead-end equipmentFIGURE A.3Forward and reverse spectra and diplex filter.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A247home). This physical medium provides for the transport of RF energywithin a reasonably secure network with an enormous amount of signal
capacity and flexibility.Conceptually, coaxial cable provides cable operators with a privateconduit through which RF signals are transported; in addition, the me-
dium can support multiple signaling channels without regard to the base-
band signals or modulation scheme that may be employed. This medium
is generally immune to interfering influences that may exist in free space.
From a practical standpoint, coaxial cable supports transmission of sig-
nals at frequencies from baseband to more than 1 GHz.Transmission losses (attenuation) within these cables can be signifi-cant; attenuation increases proportionally with frequency, making it nec-
essary to use RF amplification to cover the long distances encompassed
by the cable plant. Amplifiers may be spaced from a few hundred feet to
one or two thousand feet apart. Although the theoretical frequency limit
of the cable itself is significantly greater than 1 GHz, and cable systems
have been built using upper frequencies in excess of 1 GHz, practical
limitations are set by the frequency responses of active and passive com-
ponents (e.g., amplifiers and filters) used in the network.Tree-and-Branch ArchitectureUntil recently, coaxial cable systems have followed a Òtree-and-branchÓ topology (Figure A.4), delivering the same RF spectrum of sig-HEAD ENDRF amplifierTrunk cable(coax)40+ amplifiercascades werecommonFIGURE A.4Tree-and-branch architecture.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.248APPENDIX Anals to every customer within a particular community. This design servedthe cable industry well, but it did have limitations. The most significant
restriction imposed by this topology was the accumulation of noise and
distortions (Figure A.5) through the extended cascades of broadband RF
amplifiers needed to compensate for transmission losses. This architec-
tural facet affected plant reliability and signal quality at the customerÕs
home. Additionally, for a given design bandwidth, there were practical
and theoretical limits to the number of amplifiers that could be cascaded.
In order to maintain acceptable performance levels, it was necessary to
limit the operational bandwidth of such cable systems to a few hundred
megahertz, far below the potential of the cable alone.Another limitation was imposed by this topology: every customerreceives the same complement of signals. This is generally acceptable for
TV services, but makes the delivery of individually switched or routed
services difficult.Fiber-Optic Transmission TechnologyBy the late 1980s, optical lasers were successfully adapted for use in abroadband environment. Optical transmission had been practical for some
time through the mechanism of turning the transmitting laser ÒonÓ andNoiseCarrier-to-noiseratioCarrier-to-intermodulationratioCarrier (channel)FIGURE A.5Carrier-to-noise and carrier-to-intermodulation distortion.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A249ÒoffÓ in synchronization with the ones and zeros of a digital signal. Abreakthrough came when it was determined that a laser could be left ÒonÓ
and intensity-modulated with the highly complex analog signal repre-
senting the broadband RF spectrum (Figure A.6).Lasers used in this way required characteristics different from theirdigital counterparts. The most critical were very low internal noise and an
extremely linear transfer function. Such devices had been in development
for the digital market in an effort to achieve higher data-transmission
speeds over optical fibers (in contrast to coaxial cable), but further optimi-
zation was required for broadband applications.At the receiving end of an optical link, a relatively simple photo-detector was used to convert the optical signals back into an RF spectrum
essentially identical to the one presented at the input (transmitting) end.
The cable industry quickly adopted this technology for a portion of its
transmission plant, and continues to use it as a way to cost-effectively
transform coaxial tree-and-branch systems into something much more
powerfulÑhybrid fiber coax (HFC) architecture (Figure A.7). In essence,
this approach transforms large systems into highly concentrated collec-
tions of smaller systems. This is a very important characteristic, as dis-
cussed below.Current HFC designs are now providing transmission to and fromneighborhood clusters of a few hundred homes or fewer (Figure A.8).
This arrangement of fiber and coaxial cables allows segmentation of the
traditional coax-only transmission plant into many localized areas (called
nodes), each of which is capable of providing a unique assortment of
information to end users (Figure A.8). The coaxial network that connects
to homes from each optical node remains a small version of the original
tree-and-branch system (more of a bush than a tree).79 Analog TV ChannelsDigital ServicesUHF spectrum470 - 750 MHzTwo-way radio216 - 470 MHz54 - 550 MHzTV7 - 13FMTV2 - 654 - 750 MHz550 - 750 MHzFIGURE A.6750-MHz forward spectrum.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.250APPENDIX AHEAD ENDOptical nodeOptical cable500 homes passedTypically 6 orfewer amplifiersin cascadeMaster headendSecondaryhubPrimaryhubRF ampsCoax500-2,000Home areaOpticalnodeTaps &passivesFiber1,310 nmBaseband digitaltransport1,550  nmHigh powerOpticalnodeFIGURE A.7HFC networks allow smaller serving areas.
FIGURE A.8HFC networks allow narrowcasting of content to the customer.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A251Design ConsiderationsCurrent HFC designs call for fiber nodes serving about 500 homes onaverage, but these nodes can be further segmented into arbitrarily small
coaxial serving areas. Figure A.9 illustrates one way that the spectrum
available within one node may be used.The ability to assign and reassign spectrum to different uses is animportant benefit of HFC architecture, because it allows for advances in
digital services and technologies while continuing to support existing
services. Thus, the architecture can simultaneously support many sepa-
rate virtual networks. This makes the investment to upgrade to HFC a
sustainable one for most cable companies. At least some cable operators
plan to build as many as five separate (virtual) networks on the founda-
tion of their upgraded fiber transport plant (Figure A.10).The HFC architecture enables great flexibility to segment the servicearea. Step-by-step segmentation can match investment with revenues
from new, high-bandwidth services; in the extreme case, fiber can be
extended to the property lines of homes and businesses (not shown in79 Analog TV Channels(NTSC)Rev.QPSK -QAM16Digital Services(QAM64 - QAM256)UHF spectrum470 - 750 MHz2-way radio216 - 470 MHzTV7 - 13FMTV2 - 62-wayham54 - 550 MHz54 - 750 MHz5 - 40MHz550 - 750 MHzSDTVHDTVHigh-speeddataDigital bank (future use)Voice-on-demandVoiceover IPDigitalservices550 - 750 MHzFIGURE A.9Forward and reverse spectra at node.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.252APPENDIX AFigure A.10), or at least to those with the need for services requiringhundreds of megabits per second of connectivity. Only those nodes that
have need of greater data capacity (and the potential for greater revenue)
have to be divided; the rest can remain undisturbed.As nodes are divided and fiber is deployed closer to the customer, thetotal amount of usable bandwidth becomes greater; this makes it possible
for every node division to more than double the available data capacity
while reducing the number of users who share it.2 Similarly, breaking a
500-home node into four parts, each passing an average of 125 homes,
increases the available reverse and forward capacities significantly more
than fourfold and provides more than four times the bandwidth per user.Trials within the industry have made use of the spectrum from 900MHz to 1 GHz (as compared with the traditional use of the 5- to 50-MHz
region) for reverse signals. Because of reduced RF interference at these
higher frequencies and the resulting higher-modulation efficiencies, it is
possible to provide an additional 200 Mbps of transmission capability.
Again, this number can be multiplied through segmentation, as outlined
above.HFCFiberSwitch dataMpeg videoLocated inhead endAnalog videoHUBTransportHFCplantFIGURE A.10Capability to support multiple networks within HFC.
2The accompanying reduction in noise over the coaxial portion of the networkÑin accordwith ShannonÕs lawÑmeans that the usable bandwidth within each subloop also increases
significantly.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A253It is possible to push these numbers even farther. If very high speed,truly symmetric capacity is required, frequencies above 1 GHz can be
used. Some cable plants being constructed today use fiber to feed neigh-
borhoods of 60 homes or fewer with a more-than-commensurate increase
in the per-user capacity for both switched and routed digital services.In 2001, the latest version of the industry standard, DOCSIS 2.0, em-braced two optional refinements that can substantially increase upstream
throughput by using improved modulation in situations where the noise
level permits. One is the use of advanced time-division multiple access
(TDMA), which allows modulations up to 256 quadrature amplitude
modulation (QAM) in upstream bursts (theoretically 8 bits per hertz, real-
world about 6.5), compared with the 16 QAM (4 bits per hertz theoreti-
cally) of the current version. The other is synchronous code-division mul-
tiple access (CDMA), which permits much more robust transmissions in
the presence of certain kinds of interference.Providing Services in Year 2010Information and entertainment services can be classified in two broadcategoriesÑcommon and dedicated. Common services include such pro-
gramming as off-air broadcast, PEG (public, educational, and govern-
ment) channels, basic networks (such as ESPN and CNN), and subscrip-
tion services (such as HBO, Cinemax, and Starz). Dedicated services
include any number of specialized programs that are delivered to the end
user on an individual basis; video-on-demand (VOD) and high-speed
Internet access are examples of this type of service.The cable television (CATV) industry in the United States typicallythinks of a channel as being represented by a contiguous 6-MHz portion
of the available spectrumÑthus, a standard 750-MHz HFC plant has ap-
proximately 112 such ÒchannelsÓ within a total usable spectrum of 672
MHz. Table A.1 provides some details regarding a hypothetical 750-MHz
HFC plantÕs ability to provide almost unlimited service options for cus-
tomers, including the following:¥Standard analog television. The cable television industry will prob-ably always carry some amount of NTSC signals, perhaps 20 or so RF
channels; but it is anticipated that the number of these signals will de-
crease as most of them are incorporated into compressed digital formats.¥Digital standard definition television (SDTV). This will become theÒstandardÓ signal as 256-QAM channels are used to distribute some 200
simultaneous networks (HBO, ESPN, CNN, and so on), including most of
the subscription services.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.254APPENDIX A¥Digital HDTV. These networks will be capable of providing ad-equate bandwidth to support as many as 20 RF channels (each 6 MHz
wide) as the transition to broadcast HDTV services continues.¥Telephony. More than 300 voice channels can be provided within atypical 6-MHz segment of the spectrum, if needed.¥IP data services. This class of service includes voice over IP (VoIP),video telephony over IP (VTIP), streaming video, and high-speed data
services. Higher-data-rate services (100 Mbps) can be provided, as needed,

for work-at-home or commercial uses.¥Video-on-demand. Even with all of the services listed above, enoughbandwidth remains to handle VOD applications in both SDTV and HDTV
formats.Security ConsiderationsSince cable operators have built their plant to provide video and otherservices, and many of those services are available at lower cost, albeit
with lower quality or lacking some other feature, cable operators have
had to find ways to secure their services from unauthorized access. TheTABLE A.1Potential Services That a 750-MHz HFC Cable System
Could ProvideChannels and/orChannels
Services ProvidedBandwidth RequiredRemaining
Common signalsStandard analog television20 channels (120 MHz) for92
NTSC signalsDigital SDTV20 channels (120 MHz) for72
200+ programs of compresseddigital video formatDigital HDTV10 channels for 20 programs62
(60 MHz)Dedicated servicesTelephony1 channel (6 MHz) for 300 DSOs61
(voice channels)IP dataÑstandard service20 channels (120 MHz)Ñ41
10-Mbps data ratesIP dataÑvery high speed3 channels (18 MHz)Ñ38
100-Mbps data ratesVideo-on-demand20 channels (120 MHz) for18
200+ programs of compresseddigital videoFuture18 channels, services as needed0
(108 MHz)Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A255typical solution has been to provide a decoder in the customerÕs home,then to send commands from a head-end controller to the decoder in
order to identify the services for which each subscriber is authorized; this
strategy also permits the operator to capitalize on its economies of scale
and scope by broadcasting all signals simultaneously over the entire tree-
and-branch cable plant.The deployment of HFC networks has complicated the traditionalcontroller-to-decoder scenario. That is, the network architecture and ca-
pacity have both changed, enabling the head-end controller to send a
discrete broadband signalÑcustom-tailored to the consumerÕs require-
ments, preferences, or purchasesÑto each home. In many parts of the
network, the signals for all customers may pass over the bus and to the
home of each customer, so the set-top box would be employed to cull out
for delivery only those signals that are to be received by a specific con-
sumer. When the services are broadcast video programs, there is no in-
teractivity and consequently little need for security beyond the remote
scrambling of the video signal. However, when interactivity is a signifi-
cant portion of the services, the consumer now has access to devices for
both receiving and transmittingÑparticularly with the PC connected to a
cable modem connected to the bus network. The potential exists for both
intentional and accidental spillage of signals, onto and off of the network.ConclusionThe existence of ubiquitous, broadband cable television networks inthis country affords an opportunity to see the rapid realization of ex-
tremely powerful digital networks. The hybrid fiber coax network offers
an excellent high-speed data network solution today and combines that
with a high degree of scalability to adapt to new technologies or services
that may be introduced in the future. The key to the provision of this
capacity is the ability to increase the penetration of optical distribution
equipment as the need arises. This path to progress will eventually lead to
fiber-to-the-curb (FTTC), and even fiber-to-the-home (FTTH). Leading
HFC suppliers drive this technology development and deployment in
response to the cable operatorsÕ customer demand and sustaining rev-
enue sources.DIGITAL SUBSCRIBER LINEIntroductionDigital subscriber line (DSL) service provides high-bit-rate digital ser-
vice over ordinary phone lines, allowing from 100 kbps to tens of mega-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.256APPENDIX Abits per second to reach a telephone company customer. DSL service mayimplement digital telephone service, fast Internet or other data services,
and/or digital video and entertainment services. DSL is the phone com-
panyÕs alternative for broadband access. This section summarizes the ba-
sic concept and architectures of DSL service, provides an overview and
projection of standards and equipment, and envisions DSLÕs future and
ultimate broadband-access capabilities of telephone companies.There are 500 million voiceband modems in existence today, most ofwhich are used at speeds to 56 kbps to provide digital connection be-
tween various service providers and customers or to transfer data and
facsimiles. Voiceband modems are limited in speed because the signals
must traverse telephone company switches that allocate only 64 kbps
maximum (of which 56 kbps are available) to any voice signal, as shown
in Figure A.11. These switches can allow aggregation to higher data rates
of several voice channels, but not over a single voice channel through the
switch. These digital high-speed data must follow an alternative path
through the switch. An additional modem at the telephone company side
of the loop differentiates a DSL connection from a voiceband modem
connection, as in Figure A.12. DSLÕs placement of the extra modem at the
telecommunications company (telco) switch enables the much higher
speeds of DSL to be switched because the switch can now accept that
modemÕs digital output into higher-digital-bandwidth routes through the
switch. Thus, the DSL signal returns to digital format when it enters the
central office, while the voiceband modem signal is effectively embedded
in analog throughout the switch network. The bandwidth of the twisted
pair alone is potentially very high, much higher than the 64/56 kbpsFIGURE A.11Voiceband modem reference model.
TelcoTelcoCOCOTelcoTelcoCOCOtrunkUser 1User 1LocalloopUser 2User 2modem transmission pathmodem transmission pathLocalloopBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A257allowed for digitized voice paths through the switch. However, high digi-tal speed on the copper loop requires sophistication in the design of theDSL modems that attach to the loop. Telephone companies originally did
not appreciate the value of their copper asset and considered replacement
with fiber or coaxial systems, but release of DSL standards and availabil-
ity of low-cost DSL equipment have provided phone companies with an
opportunity to leverage their existing plant.Below are summarized some of the technical challenges of the DSLmodem and the use of existing phone lines for high-speed digital service,
as well as some of the challenges for network design and support of DSL.
Generally, higher DSL data rates occur on shorter phone lines. As phone
companies can afford the time and money to install fiber into more of
their network, copper phone lines reduce in length. Thus, an incremental
migration over the next 50 years to fiber, allowing increasing data rates
for customers and greater and greater connectivity and information age
service, can occur without need for whole-scale network replacement.Figure A.13 depicts the growth to date in digital transmission speedson phone lines. Several types of digital transmission on phone lines are
shown for comparison. Generally, DSL today often really means ADSL,
an asymmetric DSL service that can carry up to 8 Mbps downstream from
a telephone company central office to a customer and up to 1.5 Mbps back
upstream. Approximately 1 million ADSL lines are now deployed, and thenumbers are growing rapidly as early problems and delays with serviceTelcoCOTelcoCOtrunkLocalloopmodem transmission pathmodem transmission pathLocalloopmodem transmission pathmodem transmission pathUser 1User 1User 2User 2modemmodemMo
demModemsplitsplitModemalt broadband pathalt broadband pathFIGURE A.12DSL modem reference model.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.258APPENDIX Aintroduction have begun to abate, and telephone company personnel areincreasingly trained and fluent in this new service. In a short time, tens of
millions of customers will be connected. ADSL service can now be or-
dered in nearly one-third of the United States, and telephone companies
plan ubiquitous coverage in the near future. VDSL, the latest of the DSLs,
can carry up to 60 Mbps on a single phone line and is in early trial and
standardization phases. VDSL presumes some use of fiber to shorten
phone-line lengths, consistent with eventual migration to fiber by phone
companies. These are clearly much faster than voiceband modems. ISDN
and high-bit-rate DSL (HDSL), some phone company early DSL alterna-
tives, are also shown in Figure A.13 for perspective. ADSL deployment,
though, will soon eclipse the number of ISDN and HDSL circuits in ser-
vice.As fiber penetrates and very large scale integrated circuit (VLSI)technology allows yet further sophistication in the design of copper-pair
modems, eventually 100 Mbps plus symmetric connection to individual
customers is possible with DSL, making it by far the broadband access
technology of greatest potential individual bandwidth to the customer.1955                   1970               1981       1986      1992  1993      1996  1997    1999Bell 103modem300 b/sBell 202
modem1,200 b/sV.22bismodem2,400 b/sService  introduction dateBasicRateISDN
144kbpsHDSL1.5or2 MbpsV.34modem28.8
kbpsPCM
modem
56
kbpsADSLup to7MbpsVDSLup to52MbpsT1carrierLocaldigitalswitch;DLCFiber
opticsATMswitchInternet
massmarketFIGURE A.13Data rate increase for phone lines.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A259DSL StandardsTo establish a DSL connection, two modemsÑone owned and oper-ated by a telephone company and the other owned by the customerÑ
must interoperate, thus mandating standardization of the interface. As
described in Cioffi et al.,3 standards committees have charted the course
of DSL technology and the architecture for the associated networks. The
International Telecommunication Union (ITU) has headquarters in
Geneva, Switzerland, and has a major role in standardization. However,
the fundamental DSL standards work has largely been conducted in the
T1E1.4 committee of the American National Standards Institute (ANSI),4the European Telecommunications Standards Institute (ETSI), and the
ADSL Forum. The earliest DSL standards, all adopted internationally af-
ter minor modification, originated in the American group. These stan-
dards groups maintain close cooperation with each other and the ITU.
ITU Study Group 15 (SG15) has recently taken the lead in developing an
offspring of ADSL called G.lite (also known as Universal ADSL) for con-
sumer-oriented use at bit rates of 1.5 Mbps and below. The G.lite standard
was released in 1999 as G.992.2 along with an international version of the
ADSL standard called G.dmt (G.992.1). The main difference in the two
standards is speed, with G.lite at 1.5 Mbps and G.dmt allowing in excess
of 8 Mbps. The industry appears to have turned to use of the latter G.dmt
modems at the lower speeds of G.lite with imbedded potential for future
speed increase as service providers condition and shorten phone lines.
(For more on standards bodies and the relationship of the groups for
DSLs, see Chapter 16 in Cioffi et al.5)DSL ArchitecturesThere are almost 1 billion phone lines worldwide. The telephone linesare twisted pairs of copper wires, with the twisting invented by A.G. Bell
himself, in 1887, along with the phones (1876) to which they are attached.63J. Cioffi, T. Starr, and P. Silverman. 1998. Digital Subscriber Lines. Prentice-Hall, UpperSaddle River, N.J.4See American National Standard T1.601-1992, ÒIntegrated Services Digital Network(ISDN) Ð Basic Access Interface for Use on Metallic Loops for Application on the NetworkSide of the NT (Layer 1 Specification),Ó 1992, New York, N.Y., and ÒVDSL System Require-ments Report,Ó ANSI Document T1E1.4/98-043R2, June 1998, Huntsville, Ala., Rev 14a. See
also ETSI technical specification TS101-270-1 (1998-04), European Telecommunications Stan-dards Institute, Sophia Antipolis, France.5Cioffi et al., Digital Subscriber Lines, 1998.6R.B. Bruce. 1973. A.G. Bell, and the Conquest of Solitude. Cornell University Press, Ithaca,N.Y.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.260APPENDIX AThe phone lines are varied in a great many respects, but the topology ofthe loop plant of a phone company usually follows that of Figure A.14.The phone lines are terminated on central office equipment, wherethe DSL modem can reside. The central office (CO) equipment is con-
nected to phone lines at a main distribution frame (MDF) that essentially
allows physical connection (ÒjumperingÓ) of switch/DSL-modem lines to
customer linesÑas many as 160,000 of which may enter a single central
office. The first segment of the loop plant is typically called the Òfeeder
plant,Ó where hundreds of phone lines may be bundled in a cable that
runs to a smaller distribution point, labeled as SAI in Figure A.14. This
feeder segment is the first that phone companies upgrade to fiber, with
approximately 10 percent of the United States now so upgraded and
smaller percentages in other countries. Such fiber is expensive, but the
cost of labor, digging, and so on can be shared over a greater number of
customers in the feeder segment, making certain upgrades economical.
At the distribution point, splicing and connection to smaller cables con-
taining fewer phone lines occurs, and those cables run through the Òdis-
tribution plantÓ to pedestals or cabinets within a neighborhood whereMaindistributingframeSAIFeederDistributionPedestalsNIDDrop wireInside wireCustomerpremises20,000 to160,0001,500 to 4,000200 to 8004 to 12Number of lines present at a site22,000 ft9,000 ft3,000 ft500 ftWire length to customer (90th percentile) Central office equipmentFIGURE A.14Telephone loop plant topology.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A261connection to the actual twisted pair in a specific customer site (home orbusiness) occurs. Phone lines may thus be several miles in length. Eventu-
ally, fiber can run to the pedestal as demand for high bandwidth becomes
very high, and ultimately to the customerÕs premises as economics allow.Figure A.15 illustrates the distribution of lengths of twisted pairs forthree countries: Italy, the United Kingdom, and the United States. Clearly
the United States has the longest loops, simply because its network was
deployed the earliest, when phone company practice was to use longer
loops. The United Kingdom is intermediate in terms of loop demograph-
ics, while countries that lagged the United States by several decades, such
as Italy, have the shortest loop demographics. One can thus expect the
achievable data rates to be the lowest for DSLs in the United States. Italy,
Germany, and Sweden, for instance, are excellent candidates for higher-
speed DSL service because a large fraction of their loops are within a
kilometer or two of the central office. However, fiber deployment is oc-
curring faster and sooner in the United States in the feeder segment,
which will ultimately reverse the relative lengths shown in Figure A.15.
For instance, the largest U.S. telephone company, Southwest Bell Corpo-
ration, recently announced a $6 billion DSL loop renovation program,
known as Project Pronto, that will bring many loops to less than 4 km01020304050
607080901000.511.522.533.544.555.566.577.58Loop length (km)  {1 km = 3.28 ft}Percentage within lengthFIGURE A.15Cumulative loop distribution for Italy (solid squares), the United
Kingdom (solid circles), and the United States (solid triangles).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.262APPENDIX Awithin a few years. Project Pronto is an example of reversing the trend inFigure A.15. Deregulation and aggressive DSL and Internet use in the
United States have motivated SBC to move quickly, unlike international
operators who still have far less competition because unbundling deregu-
lation has lagged that of the United States by a few years at least.Central OfficeFigure A.16 illustrates the network architecture of DSL. A DSL accessmultiplexer (DSLAM) resides at the telephone company side of the
twisted pair. A splitter circuit may precede the DSLAM termination so
that analog POTS signals can be passively separated from the DSL signals
and conveyed to the voice telephone switches. Splitters are 3-port devices
that ensure that DSL signals above 30 kHz and POTS signals below 4 kHz
are simultaneously passed over the telephone wire without mutual dis-
ruption. The DSLAM houses the modem and processes the customer bit
streams into larger rate fiber transported data streams that usually use
ATM formatting. Various gateway devices can accept the fiber inputs andGATEWAY(s)DSLAMVideoserviceproviderMuxorDemuxADSLmodemADSLmodemADSLmodemInternetserviceprovidersplitPOTSnetworkTelephone company officeDigitalAnalogAnalogDigitalFIGURE A.16Telephone company central office and DSLAM.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A263separate the signals into individual applicationsÕ provider networks, suchas Internet service providers, video and entertainment providers, or voice
service providers. Colocation today involves separate DSLAMs for each
service provider. An alternate service provider must be given fair and
equal access to the phone lines of the service providerÕs customers.Customer PremisesFigure A.17 illustrates the customer premises end of a DSL connec-tion. The customer can be a residential user or a business user. While a
splitter can be used at the customer premises also, the cost of installation
is often perceived as excessive, and so DSL signals typically enter the
customerÕs premises and terminate on application devices. Existing
phones often are augmented by a passive lowpass filter known as a
microfilter, which protects the phone from DSL signals and protects DSL
from ring-voltage transients that otherwise would be disruptive to DSL
service. The DSL modem may be part of a residential or small-business
gateway that either connects to another network in the home or redistrib-
utes digital signals to all application devices at frequencies above 5 MHz.
(ADSL and its latest prot”g”, very-high-data-rate asymmetric DSL
[VADSL or VDSL-lite], exist only below 5 MHz.) The ITU SG15/Q4 group
also standardizes this redistribution system, which is known currently asmicrofilterADSLG.pntmicrofilterG.pntG.pntG.pntVoDSLinterfaceHome/business wiringCustomerpremisesFIGURE A.17Customer premises (residence or small business) DSL interface.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.264APPENDIX AG.pnt. Customer premises wiring alone can carry huge data rates above 5MHz, and sophisticated modem design is less necessary because the ac-
tual redistributed data rates are well below fundamental limits. However,
the DSL signals that traverse the much longer path from central office to
customer need a high degree of sophistication to achieve the data rates
desired in DSL.DSL Transmission EnvironmentThe DSL transmission environment is challenging, and should not beunderestimated. This challenge was the first that had to be addressed in
developing an opportunity for DSL. In fact, in the early days of DSL, there
was little phone company support or interest because it was believed that
this challenge would be insurmountable. Fortunately, an initially small
(but now very large) group of transmission experts worked together
through standards groups to derive practical, high-speed DSL modems.
Challenges continue for yet further increases in DSL speed and capability.
This section discusses the salient characteristics of telephone lines for
digital transmission, with the intent of conveying the difficulty of the
transmission problem for DSLs.The journey of a bit over a phone line is analogous to a long, arduoustrip with several borders to cross, potentially dangerous trip segments,
with various difficulties and costumes imposed upon the traveler, poten-
tially disguising that personÕs appearance to all but those who know well
how to recognize the traveler at the destination. Only the best prepared
travelers (bits) can successfully complete the journey, if the receiver also
knows well how and what to look for. The shorter the journey, the more
successful travelers/bits conveyed to the final destination. Phone lines
typically comprise several segments of wire, characterized by gauges (19,
22, 24, or 26 in the United States and equivalent 0.8-, 0.6-, 0.5-, and 0.4-
millimeter [mm] diameters in the metric system internationally). The
higher the gauge, or more narrow the wire, the more arduous the journey.
At the borders between phone line segments, some energy is reflected,
meaning that a bit may be harder to recognize as a 1 or 0 by the time it
reaches its destination. This energy loss may be equated to an aggressive
customs officer confiscating some identifying documents from the trav-
eler. Some bit energy may also be diverted to unused open-circuited
phone branches (for extension phones or extension phone jacks), further
marring the appearance of the bit; these branches are known as bridged-
taps. The effect of bridged-taps is analogous to unnecessary dead-end
side trips by a traveler to a port that the traveler did not know was closed,
but draining their energy with the wasted round trip, making the ex-
hausted traveler yet more difficult to recognize. Some standardized phoneBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A265line characteristics and behavior appear in the subsection on loop-transfercharacteristics.Phone lines endure a lot of noise, which obscures or disguises the bit.The noise is typically electromagnetically coupled into phone lines. The
external sources of energy that contribute to noise can include signals on
other phone lines (known as crosstalk), radio, and ham broadcasts, and
virtually any type of electrical or mechanical equipment within close
proxmity to the phone line. Such noise can be severely disguising, and
transmitted bits need to be adequately prepared to avert complete loss of
identity if they are to negotiate their journey successfully. The subsection
entitled ÒSources of Noise in DSL SystemsÓ below, overviews several
types of noises.The energy from a bit may also radiate from a phone line, potentiallydisturbing radios within the vicinity of any portion of the phone line. This
is analogous to a boisterous traveler upsetting all the other travelers, thus
running the risk of retribution of some sort. The subsection below entitled
ÒEmission Constraints and PSD MasksÓ describes this problem and the
level of concern.Characterization of Twisted-Pair Telephone LinesChapter 4 of Cioffi et al.7 details the calculation of the frequency-
response of phone lines, which are often described by their Òinsertion
loss.Ó The insertion loss is measured in decibels (10 times the base-10-
logarithm) of the ratio of the power injected into a phone line at any given
frequency to the power emanating at the end of the phone line at that
same frequency. The injected power may be measured without the phone
line present, and then measured again after the phone line is Òinserted,Ó
whence the name Òinsertion loss.Ó Some insertion loss plots versus fre-
quency for American standardized 3- and 4-mile phone lines appear in
Figure A.18. These loops were chosen by ANSI to represent the top 10
percent of worst-case lines in the United States. Loops 1-4 in the left plot
represent simple gauge changes. The usable bandwidth over the lines,
where signals are still distinguishable from noise, may extend to about
600 kHz. Note the large range from as high as Ð20 dB to Ð100 dB in
insertion loss for usable frequencies. This means that the largest signals
on the line may be 100 million times more powerful than the smallest
signals of interest. By contrast, voiceband modems see a range of only a
factor of 100, making DSL transmission a million times more sensitive!7Cioffi et al., Digital Subscriber Lines, 1998.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.266APPENDIX ALoops 5-8 on the right have bridged-taps. Notice the rippling of the inser-tion loss, corresponding to signal energy reflecting from the open-cir-
cuited extensions and returning later in time to the main line to add to the
current signals there. At some frequencies, the reflected signals are 180
degrees out of phase and destroy the current signals, corresponding to
the dips. At other frequencies, energies add, essentially returning the
signal closer to its original unreflected signal level. (A good discussion of
bridged-tap and other effects appears in an article by J.J. Werner.8)Figure A.19 shows insertion loss characteristics of some shorter stan-dardized loops,9 indicative of what might be used with VDSL over a yet
wider bandwidth of 30 MHz. The left plot shows insertion loss for 300-m
and 500-m loops of 26-gauge (TP1) and 24-gauge (TP2) wire, respectively.
As the length increases, the slope also increases. On the right, a short loop
VDSL5 with a bridged-tap has very noticeable rippling, but otherwise is
similar in slope to the insertion loss characteristics on the left. As the
length is increased to 1 km and then to about 1.5 km for VDSL6 and
VDSL7, respectively, the insertion loss decays much more rapidly with
frequency and still exhibits significant rippling because of the bridged-
taps. The same large dynamic range (now because a greater range of
frequencies is used at shorter lengths) is again evident for VDSL.The bridged-tap in VDSL5, 6, and 7 is 10 meters in length, a reason-able and typical number. Thus, the notches are an often-encountered phe-
nomena.012345678910  Frequency (Hz)Frequency (Hz)Line PSD (dB)ADSL Canonical Loops # 1, 2, 3, and 4 Insertion Lossx105x1050-20-40-60-80-100-120-1400-20-40-60-80-100-120-140  ADSL Canonical Loops # 5, 6, 7, and 8 Insertion Loss012345678910  FIGURE A.18ANSI loops 1-4 (at the left) and 5-8 (at the right), insertion loss.
8Werner, J.J. 1991. ÒThe HDSL Environment.Ó IEEE Journal on Selected Areas in Communi-cation 9(6):785-800, August.
9ÒVDSL System Requirements Report,Ó ANSI Document T1E1.4/98-043R2, June 1998,Huntsville, Ala., Rev. 14a. See also ETSI technical specification TS101-270-1 (1998-04), Euro-pean Telecommunication Standards Institute, Sophia Antipolis, France.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.267 Frequency (Hz)Frequency (Hz)0-20-40-60-80-100-120Magnitude (dB)0-20-40-60-80-100-120Insertion loss for "short" VDSL 1, 2, 3Insertion loss for VDSL 5, 6, 7VDSL2 500mVDSL3 500mVDSL5VDSL6VDSL7 00.511.52 2.53 00.511.52 2.53x107x107VDSL1 TP1 300mVDSL1 TP2 500mFIGURE A.19Shorter loops for VDSL systems (TP1 = 26 gauge and TP2 = 24 gauge).
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.268APPENDIX ASources of Noise in DSL SystemsNoise on a twisted-pair transmission system arises from three mecha-nisms:1.The thermal noise of the twisted pair itself,
2.The noise generated internally by the receiving modem, and

3.Signals electromagnetically coupled into the phone line.
Thermal or actual medium noise on a twisted pair is extremely small,near the Boltzman limit of Ð174 decibels per millihertz (db/mHz) at room
temperature, and essentially can be ignored. The noise generated by ter-
minating equipment depends on the design of the receiver electronics.
Standards groups often suggest that this noise level should be about Ð140
dBm/Hz,10 but well-designed modems often generate less, to as low as
Ð160 dBm/Hz. This noise is usually flat in spectrum (i.e., ÒwhiteÓ) and
determines the ultimate frequency limits of a DSL. The insertion loss of a
DSL, as discussed above, and the transmit power-spectral density in
dBm/Hz determine the line output power-spectral density (PSD).
For instance, an ADSL system transmitting at the maximum PSD of Ð40
dBm/Hz can tolerate up to about 85 to 90 dB of insertion loss before
resulting in a channel output PSD of Ð125 to Ð130 dBm/Hz, 10 dB above
Ð140 dBm/Hz (10-dB signal-to-noise ratio) necessary for adequate detec-
tion even in well-coded and designed DSLs). Thus if Ð140 dBm/Hz is the
receiver noise floor, then a DSL using one of the lines on the right in
Figure A.19 would use bandwidths of up to 600 to 700 kHz. ADSL sys-
tems actually allow use of bandwidths up to 1,104 kHz, which would thus
occur on lines that are shorter than those displayed in Figure A.19, thus
having less insertion loss at 1 MHz.Electromagnetically coupled noise occurs because the twisted pair isoften bathed in radiation from a number of electronic sources. The twisted
pair has imperfections that cause this radiation to induce noise voltages
into the differential signal carried between the two wires of a twisted pair.
Figure A.20 shows the twisting of a twisted pair and the opposite spatial
polarity of the voltage at adjacent twists. Theoretically, this twisting intro-
duced by A.G. Bell himself in his 1887 patent should almost cause cance-
lation of induced voltages. This is because impinging radiation would
have different polarities in the adjacent segments and thus cancel itself,
the reason for the twisting. Of course, the twisting is never perfect, nor is
the cancelation, but twisting is better than no twisting. Many phone cus-10American National Standard T1.413-1995, ÒADSL Metallic Interface Specification,Ó 1995,New York, NY. Please see Issue 2, if available, T1.413-1999.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A269tomers are familiar with the Òflat pairÓ they purchase for extending phonelines within their home. This wire is not twisted, and is much more sus-
ceptible to noise pickup; nonetheless, fortunately, this flat pair represents
only a small segment of the total length of the phone line. Category 3
twisted pair, typically used by phone companies, has a few twists per
inch. Category 5 twisted pair is a higher grade, with tighter twisting and
about 100 times better rejection of noise. Category 5 twisted pair finds
increasing use in new buildings (which almost always still use twisted-
pair wiring) and in local area network connection. Flat pair is, of course,
the worst for noise pickup.Crosstalk NoiseFigure A.21 illustrates crosstalk noise, which is the noise produced bysignals on other phone lines. As discussed above, several phone lines
share the same cable. Typically, 25 to 50 twisted pairs are wrapped tightly
in a binder group. Different twisted pairs within the binder group have
different numbers of twists per inch (to prevent radiation patterns from
exactly matching and offsetting the twisting pattern on other twisted+--+FIGURE A.20Twisted-pair voltage polarities.
Pair 2Pair 1f21NEXTNEXTxfH,2xfH,1FEXTFEXTxdfH,1Near-endreceiverFar-endreceiverCrosstalkingtransmitterfS2dxFIGURE A.21Crosstalk illustration.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.270APPENDIX Apairs), and there is some level of rejection caused by twisting. Nonethe-less, a signal launched from a near-end transmitter on the right in Figure
A.21 will enter the cable and begin to couple into the reverse direction on
another twisted pair. This type of opposite-direction crosstalk-noise cou-
pling is known as NEXT, or Near-End CROSSTalk. When the insertion
loss of the segment of wire between the coupling point in both directions
is considered and the noise problem integrated over the total length of
wire, basic physics leads to the standardized crosstalk coupling function
for DSLs ofPSDf
NfPSDf
NEXTnearendxmit
(),
..,Œ
491061513(1)which not coincidentally increases with the 1.5 power of frequency match-ing the decrease in balance of the twisted pair as frequency increases. The
factor of N represents the number of twisted pairs in the binder expected
to carry crosstalking signals. This type of noise often dominates receiver
noise when it exists. For instance, the PSDs of several DSL signals appear
in Figure A.22, where it is clear that the PSD often exceeds Ð140 dBm/Hz,
especially over the frequency range of operation of the offending DSL. 00.10.20.30.40.50.60.70.80.91-140-135-130-125-120-115-110-105-100-95-90Frequency (MHz)ADSL upstream NEXTHDSL NEXTISDN NEXTPSD (dBm/Hz)FIGURE A.22Some worst-case crosstalk spectra for various DSL types.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A271The reader should note that while the crosstalk coupling increases withfrequency, the noises plotted in Figure A.22 combine the coupling with
the transmit power spectral of each of the signals, and if there is no signal
at higher frequencies, then there is no crosstalk. The actual crosstalk into
an individual twisted pair from one of its neighbors is not as bad as the
model at all frequencies. Clearly the coupling is heavily frequency depen-
dent and only at worst case exhibits the behavior of the standards model
above in Equation (1). Nonetheless, this model is heavily used for conser-
vative DSL design.Also in Figure A.21 is the coupling of signals from one phone line toanother in the same direction, which is often called FEXT, for Far-End
CROSSTalk. An exercise similar to the one for NEXT finds a standardized
FEXT coupling function ofPSDf
NdfHfdPSDf
FEXTxmit

49910
62220.,(),
(2)where d is the length of the line in feet and H is the insertion loss of the
twisted pair. The FEXT model is similarly pessimistic and does not in-
clude the highly frequency-dependent nature of real crosstalk when only
one or at best a few other lines interfere in any given frequency band. The
level of FEXT is usually well below NEXT and even below Ð140 dBm/Hz
often, but at higher frequencies above 500 kHz begins to become signifi-
cant and indeed dominant at yet higher frequencies because of the depen-
dency on the square of the frequency. FEXT is usually of strong concern
only in VDSL.Radio NoiseAs Figure A.23 implies, telephone lines are great radio receivers, es-pecially for AM radio broadcasts. Indeed, AM radio signals are delivered
to customers on phone lines in some countries (e.g., Switzerland). AM
radio signals exist in the internationally recognized band from 560 kHz to
1,600 kHz. The double-sideband-with-carrier-modulated AM signals are
10 kHz wide and likely to have PSD levels of Ð100 to Ð120 dBm/Hz on
phone lines, comparable to crosstalk signals and much larger than inter-
nal modem noises. It is common, if not the norm, to see 2 or 3 large AM
radio signals on a phone line in the metropolitan area of any city. Thus,
only a small percentage of the transmit band is disturbed, but in those
bands, the disturbance cannot be ignored. The problem is particularly
evident on elevated phone lines (telephone poles), but not insignificant
even on buried phone lines.AM radio interference is of concern for both ADSL and VDSL butdoes not overlap the transmission bands for high-bit-rate DSL (HDSL) or
ISDN.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.272APPENDIX AHam radio signals are an even greater problem. While smaller poweris transmitted by ham radio operators, the ham antennae are distributed
massively through residential environments, often being only 10 to 100m
away from a phone line. The level of interference is sometimes as large as
Ð35 dBm/Hz, and typically on the order of Ð50 to Ð60 dBm/Hz, well
above the levels of any other noise type. Fortunately, ham radio signals
are typically only 2.5 kHz wide, and there may likely only be one of them
when such interference occurs. Ham radio signals may be transmitted in
internationally recognized narrowbands from 1.8 to 2 MHz, 3.5 to 4 MHz,
7 to 7.1 MHz, 10.1 to 10.15 MHz, 14 to 14.35 MHz, and 18.068 to 18.168
MHz that overlap VDSL transmission, but not other DSLs.Impulse NoiseImpulse noise is nonstationary crosstalk from temporary electromag-netic events in the vicinity of phone lines. Examples of impulse generators
are as diverse as the opening of a refrigerator door (the motor turns on/
off), control voltages to elevators (phone lines in apartment buildings
often run through the elevator shafts), and ringing of phones on lines
sharing the same binder. Each of these effects is temporary and results in
injection of noise into the phone line through the same basic mechanism
as RF noise ingress, but typically at much lower frequencies.Differential (metallic) induced voltages are typically a few millivolts(mV) but can be as high as 100 mV, corresponding to levels of Ð50 to Ð70
dBm/Hz. Typical impulses last tens to hundreds of microseconds (s) butcan span time intervals as long as 3 s.FIGURE A.23Radio interference.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A273Emission Constraints and PSD MasksDSLs need not only be concerned with noises generated by otherelectronic signals, but also with the radiation they create. The concern for
such emission exceeds that normally associated with electronic equip-
ment, where the FCC (in the United States) mandates certain maximum
levels of radiation in various frequency bands. In the case of DSL mo-
dems, the telephone line itself, while not inside the modem, does radiate,
and so this type of radiation is typically limited by limiting the power
spectral density of signals transmitted on phone lines.Unbundling and Standards SolutionsThe American National Standards InstituteÕs T1E1.4 group has takena lead role in discerning problems with crosstalk between various types
of DSLs, standardized and nonstandard. The idea is that if all services
comply with defined spectrum masks, coexistence of different service
providersÕ equipment in the same cable of twisted pairs is possible with-
out the transmission technique itself having to be standardized. A volun-
tary ANSI spectrum management standard was issued in 2001 and of-
fered to the FCC for possible use in future rulemaking.Evolution Possibilities for DSL TechnologyAn enabling event for DSL transmission at high speeds occurred onMarch 10, 1993,11 when ANSI selected the discrete multitone transmission
(DMT) technology for ADSL. The technology offered greater adaptivity
than previous conventional technologies for transmission. The essential
ingredient was an ability of the receiver and transmitter to communicate
through a low-speed overhead back-channel that allowed the transmitterÕs
DSL spectrum and information content to adjust to each and every phone
line in an individually optimized manner. The technology outperformed
even the best-optimized nonadaptive methods in several independent
tests (sometimes showing more than a thousandfold improvement in
noise immunity), and was selected. While early modems were expensive,
the standards groups successfully bet on VLSI improvements eventually
making most of the gains of the DMT technology cost-effective, which has
now happened, and DMT is the basis of all ADSL standards, including
the recently released ITU standards ÒG.liteÓ (G.992.2) and ÒG.dmt DSLÓ
(G.992.1). The additional benefit of standardization allowed economies of11Curiously, the 100th anniversary of the invention of the telephone.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.274APPENDIX Acompetition, as multiple suppliers are assured of interoperable productsthrough the use of and adherence to standards.Good DMT designs gain outstanding performance on telephone lines,and this section enumerates both present performance levels and future
performance levels. This particular technology will allow a number of
solutions to the unbundling and crosstalk problems mentioned above;
these solutions have yet to be implemented but are simulated here to
allow an understanding of future research directions in this DSL area.As phone companies increasingly deploy fiber, telephone line lengthsbecome shorter. It is thus of interest to know the possible data rates versus
line length. Three such plots are presented in the following subsections.
In each, the current state-of-the-art methods are plotted, as well as a num-
ber of potential enhancements that researchers have suggested will fur-
ther DSL performance.ADSL and ProjectionsFigure A.24 lists the first set of curves for DMT ADSL. The verticalaxis plots data rate, while the horizontal axis plots line length in feet. As
line length increases, all data rates decrease. The lowest curve shown is
the performance of a good design that meets current ADSL standardized
performance levels. Most current ADSL modems will not allow more
than 10 Mbps maximum speed, which occurs at about 2,000 feet in the
lowest curve. At about 3 miles, 1.5-Mbps speed is attainable, while a few
hundred kilobits per second are possible beyond that range. ADSL uses
only the lower 1.1 MHz of bandwidth on a twisted pair.A first step in improving these curves is to allow the modems to usesophisticated multiuser information-theory-based detection methods to
eliminate crosstalk effects between lines. The next two curves eliminate
NEXT and NEXT/FEXT, respectively. Note that when crosstalk is re-
moved, a huge jump in data rate is attainedÑby a factor of about 3.
Suddenly, 10 Mbps is possible even to a 2-mile range. A 2-mile range is a
target of projects such as SBCÕs Project Pronto. The so-called bit-cap is
related to ADC (analog-to-digital converter) performance levels, and with
improvements in such technology beyond todayÕs state-of-the-art conver-
sion devices, additional improvement is possible. Finally, a last curve
shows the improvement in performance with some of the most powerful
coding methods yet found (i.e., turbo codes).VADSL and VDSL ProjectionsFigure A.25 lists the first set of curves for what is known recently asDMT VADSL. This extension of ADSL allows up to 5 MHz of bandwidthBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A275to be used on a twisted pair, which allows considerably higher data rateson shorter lines.Data rates jump on lines of a few thousand feet, with 20 Mbps pluspossible on 3,000-ft lines (which characterize the second of the fiber termi-
nation pointsÑthe so-called distribution node) with current methods.
Again, with use of more sophisticated methods, another doubling in the
data rate is feasible.Figure A.26 is for so-called VDSL, which uses up to 20 MHz of band-width on a twisted pair. Here, data rates on 1,000-ft loops, so-called ped-
estal drops, can exceed 250 Mbps with all possible and/or known im-
provements included. A last curve, ÒUltra DSL,Ó allows an increase of
transmit power to 400 milliwatts, perceived as an analog limit for phone
lines with VDSL parameters.Network and Application Interfaces for DSLAs discussed in the introduction to the major section ÒDigital Sub-scriber Line,Ó DSL technologies are able to achieve their high bandwidths02,0004,0006,0008,00010,00012,00014,00016,000Length (ft)CurrentCancel self-xtalkCancel all xtalkIncrease bit capImprove coding 010203040506070Total Rate (Mbps)FIGURE A.24Current ADSL and projections.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.276APPENDIX A02,0004,0006,0008,00010,00012,00014,00016,000Length (ft)CurrentCancel self-xtalkCancel all xtalkIncrease bit capImprove coding 010
20
304050
60Total Rate (Mbps)02,0004,0006,0008,00010,00012,00014,00016,000Length (ft)CurrentCancel self-xtalkCancel all xtalkIncrease bit capImprove codingUltra-DSL 0
50100150
200250300Total Rate (Mbps)FIGURE A.25VADSL and projections for 5 MHz bandwidth use.
FIGURE A.26VDSL performance and projections with 20 MHz of bandwidth.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A277over the copper loop because they avoid the existing telephony networkof switches and transmission channels optimized for voice traffic. In a
sense, the existing non-DSL modem technology Òcreatively abusesÓ the
physical path that is established from point to point for carrying voice
traffic by placing the data on a path designed to carry voice. This has the
advantage of allowing for worldwide switched connectivity of data. How-
ever, it also limits the bandwidth of the connection to, at most, 64 kbps.
This is the rate supported by the digital voice channels within and be-
tween the switches of the worldwide transmission network.Providing a DSL-based physical path on a copper loop will allow auser to transmit at high data rates over that loop. However, DSL will get
the data only to the end of the copper in the central office. To reach
destinations desired by the DSL user, a high-bandwidth data network
must be provided from the CO to these remote sites. Telecommunications
carriers thus face new problems in constructing and managing a network
that is intimately involved in data networking issues.In the current environment, they need only provide the physical-layer connectivity (using either the switched network or a private dedi-
cated line for higher-bandwidth connections). They are isolated from the
details of their usersÕ data networks. In the case of the voice network, it is
as if the telco provides trains from place to place and does not care what
type of car is placed on the trains or what is in the boxcars. In providing
DSL services, the telephone companies must provide a network that in-
teracts directly with their usersÕ networks and protocols. The telco now
needs not only to operate the tracks and trains but also to provide box-
cars, tank cars, and transshipment between trains, ships, and planes.The carrier needs to address the following issues if it is to provideDSL services to its customers:¥It must provide a data network connecting the ADSL terminated
copper loops to the service providers desired by customers. Examples of
service providers include the public Internet, private corporate networks,
interactive video services, or highly interactive games.¥It must provide cost-effective interfaces between its network and
the service providers.¥The data protocols that connect the customer to service providers
over the ADSL network must be compatible with existing technologies
and procedures used by both customers and service providers and must
also support the high-bandwidth services provided by ADSL.¥The carrier must develop methods to manage this new network.
The carrier must be able to add new customers, repair problems, and bill
for the services provided.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.278APPENDIX AAlthough there are many potential implementations that can addressthese issues, a discussion of two contrasting environments and potential
solutions can illustrate the current direction of ADSL end-to-end architec-
tures:1.The large common carrier environment in which a telecommunica-
tions provider offers services to masses of customers and supports many
different service providers;2.Use of DSL in very specialized environments such as college cam-
puses, military bases, or condominium apartments.The Large Common CarrierA large local exchange telephone company may support more than 2million telephone lines in a major metropolitan area. Even a 10 percent
penetration of ADSL results in 200,000 ADSL customers in the area. For
both regulatory and business reasons, the carrier will need to provide
common-carrier access between users and any service provider who pays
to connect to the access network. A user of the ADSL service may wish to
connect to any service provider it chooses. Simultaneous connections from
a user to multiple service providers are likely to be required. Other users
may connect to only one service provider but require that the connection
be physically secure. For example, a remote office might use the ADSL
service to connect to a central corporate LAN.Although large-scale ADSL service has yet to be deployed by anycarrier, many carriers are converging toward a common architecture. Each
central office is served by one or more DSLAMs,12 which terminate the
ADSL line in the central office. POTS voice traffic is also carried on each
loop. Splitters groom the POTS traffic, carried at frequencies below 4 kHz,
before the loop is terminated on a port on the DSLAM. The POTS traffic is
placed on a voice switch in the carrierÕs legacy voice network.The ADSL connection only provides a physical layer between thecustomerÕs ADSL modem and the modem in the CO within the DSLAM.
In this architecture, ATM provides a data link layer end-to-end between
the usersÕ computing environment and the service providerÕs network.
An ATM virtual circuit is established between the userÕs ADSL modem
and the interface between the carrierÕs ATM network and the service
providerÕs network.12DSLAM is an acronym for Digital Subscriber Line Access Multiplexer. The term is nownever translated but has become a generic term for CO-based devices that terminate DSLloops.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A279The DSLAM in the CO terminates many ADSL lines (typically in therange of 200 to 600 ADSL ports per DSLAM) and concentrates the traffic
to and from the customers over DS3 (48-Mbps) or OC3 (155-Mbps) trunks
that connect to ATM switches in the carrierÕs ATM data network. The
service providers are also connected to the carrierÕs ATM network via
similar high-speed trunks. The use of ATM allows for scalability of the
service to support hundreds of thousands of users in a metropolitan area
and a wide range of potential future ADSL services.If the service provider and customer communicate using IP, the use ofPPP (point-to-point protocol) over ATM, as defined in Kwok et al.,13 will
allow both the user and the service provider to operate in an environment
that is similar to that provided by dial-up modems today. In that environ-
ment, the IP is placed in PPP that is carried over the voice network be-
tween the usersÕ and service providersÕ modems. By using PPP over ATM,
the carrier can isolate both the service provider and user from the com-
plexities of both ADSL and ATM.The Specialized CarrierIn contrast to the large public carrier, many specialized deploymentsof ADSL are possible. Any organization that has access to copper loop can
deploy ADSL. For example, the owner of a large rental apartment build-
ing may install an ADSL service to provide high-speed Internet access to
the tenants. A competitive local exchange carrier (CLEC) can, under the
terms of the Telecommunications Act of 1996, lease copper loops from the
incumbent phone company (the incumbent local exchange carrier, or
ILEC) and serve customers with ADSL.The largest CLECs may end up resembling ILECs in both scale andarchitecture of their ADSL services. However, in many cases the deploy-
ment will be small and will have similar requirements to the small ADSL
implementation in the apartment building. Other examples of small ADSL
deployments could include college campuses (which typically own their
own copper loop plant), hotels, or military bases.The requirements for these ÒnicheÓ deployments of ADSL includethese: small scale, that is, from 100 to 1,000 users total; limited need to
support multiple providers; and the service provider and carrier may be
identical. In the case of an ADSL-equipped apartment building, the cus-
tomers are connected directly to the ISP contracted to provide service to13Timothy Kwok et al. 1997. ÒAn Interoperable End-to-End Broadband Service Architec-ture over ADSL Systems (Version 3.0),Ó ADSL Forum Contribution 97-215.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.280APPENDIX Athe building. In the case of a CLEC, the CLEC may itself be an ISP. In thecase of a campus, the users will be connected directly to the university or
companyÕs data network.The DSLAM containing the ATU-Cs is either in close proximity to orintegrated with an IP router. The router is connected directly to the IP
network of the ISP or corporate network. It is managed as an integral part
of that network. The ADSL connections to the user support IP over HDLC
directly on the ADSL physical layer.14 The ADSL user appears as host
directly on the service providerÕs IP network.WIRELESSIntroductionBroadband wireless access is frequently mentioned as an importantalternative to wired technologies, namely, to DSL, cable, and fiber. Wire-
less has always played an important role in telecommunications networks
because of its inherent advantages of modest infrastructure investment
(no wires!), rapid service deployment, and end-user mobility support.
The strategic significance of wireless communication services has in-
creased over the past decade as cellular-telephony subscriber growth con-
tinues to outpace all earlier projections. It is now clear that wireless will
continue to play an important role in emerging telecommunications ser-
vices, including narrowband data and broadband services because of the
same intrinsic advantages. For both Internet and broadband services,
wireless services have experienced a larger-than-expected gestation pe-
riod owing to a combination of factors such as technology cost and perfor-
mance problems, spectrum regulation barriers, and weak standards. How-
ever, wireless data and broadband Internet services seem poised for
technical and market breakthroughs over the next 3 to 5 years, and should
thus provide an important alternative for facilitation of broadband ser-
vices in the United States and other parts of the world.Service ConceptThe concept of a wireless broadband access network is shown in Fig-ure A.27. The basic idea is to provide a high-speed wireless link between
subscriber devices such as PCs, Internet appliances, PDAs, and new per-14ADSL Forum. 1997. Framing and Encapsulation Standards for ADSL: Packet Mode. ADSLForum Technical Recommendation-003, June.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A281sonal multimedia devices (both fixed and mobile). It is expected that ini-tial applications of broadband wireless access will start with fixed devices
such as home PCs connecting to an ISP, with a gradual migration toward
mobile applications as end-user devices become more and more portable.
Thus, the initial impetus for wireless access comes from the need to rap-
idly deploy networks capable of supporting high-speed Internet access.
With increasing investment in next-generation wired networks, it may be
expected that (at least in developed countries), the focus for wireless sys-
tems will shift toward semimobile or mobile services, given that an in-
creasing percentage of computing platforms will become inherently por-
table. It is noted that the wireless access network shown in Figure A.27
may be expected to interface with both the future public telephony net-
work and the Internet, which are themselves experiencing some degree of
convergence as they migrate toward broadband services. This means that
wireless access networks for future broadband systems are likely to be
architecturally aligned with protocols used in fixed networks, rather than
being designed as custom overlay solutions (as is the case with todayÕs
cellular networks). In the long term, this may be expected to drive conver-
gence between fixed and wireless networks further, where the same ser-
vice is offered to both wired and wireless devices in a seamless manner.FIGURE A.27Broadband wireless network service concept.
FutureInternetBroadband WirelessAccess Network Mobile communications devicesFixedPC/WSMobile PDA/PIASemimobilelaptop, etc.Growing proportion ofuser terminals  50% +?Future TelecomNetworkBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.282APPENDIX ATechnology OverviewAs mentioned above, adoption of wireless data services has beeninhibited by a rather slow improvement in wireless technology cost and
performance during the past decade or so. The previous generation of
wireless data technologies (including cellular modems, wide-area data,
satellite data, and wireless LANs) fell far behind MooreÕs law improve-
ments experienced by most computing and telecommunications technolo-
gies. While wireless does pose important technical challenges, there ap-
pears to be no fundamental reason for this discrepancy, which was
probably caused by insufficient R&D and/or venture funding needed to
drive this area. The situation has been largely corrected during the last 2
or 3 years, during which various new broadband wireless technologies
have emerged as competitive options to wired solutions. This is illus-
trated in Figure A.28, which shows the evolution of wireless technology
performance over the last decade. As shown in the figure, newer commer-
cial or precommercial wireless technologies have reached the Mbps+ bit-
rate levels necessary for viable broadband services, either fixed or mobile.Figure A.29 shows the typical bit-rate and mobility regimes for vari-ous broadband wireless networks currently under consideration. The fig-
ure shows the relative roles of fixed wireless access, high-speed wireless
LAN, semimobile broadband PCS, and wideband cellular (IMT-2000).
Although these services are generally viewed as distinct (and may be
worked on by different technical and business communities), changes in
technology are likely to result in new service models that merge one or
more of the existing categories. In the United States, broadband wireless
services are likely to start out with fixed access to residences and gradu-
ally evolve towards portability and mobility. The reverse is likely to hap-
pen in Europe and Japan, where so-called 3G mobile services are expected
to appear on the market within the next few years, and may later be
applied to broadband wireless local loop (WLL) scenarios.The generic architecture of a broadband wireless network consists ofthe following major components: radio modem (physical layer), radio
link protocol (RLP), and fixed infrastructure network with capabilities for
supporting wireless/mobile services. The following subsections summa-
rize key technology issues related to each of these major subsystems.Physical LayerBroadband wireless networks require physical-layer bit rates that areorders of magnitude higher than those for current digital cellular or WLL
systems, i.e., 10 to 100 Mbps versus the current 10 to 100 kbps. The higher
bit rates must be achieved without introducing line-of-sight (LOS) con-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.283FIGURE A.28Evolution of wireless technology performance, 1990-1999.
199019951999CPULAN/WANLocalAccessMemoryWirelessCDPD3G MobileUNIIWLAN, etc.CableModemDSLGbpsRouterATM56K modemSw Ethernet10001000100010001000100100100100100WirelessaccessLocalaccessLAN/WANswitchingCPUspeedMemorysize1010101010kbpskbpsMbpsMHzMB11111Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.284APPENDIX Astraints, thus indicating a need for robust modulation techniques thatwork well for non-LOS channels with fading. At the same time, spectrum
limitations imply the need for significantly higher spectrum usage effi-
ciency (bps/Hz/unit area), that is, 5 to 10 bps/Hz/cell versus the current
0.5 to 1 bps/Hz/cell. Clearly, if broadband wireless services are to reach
significant penetration, cell sizes will have to be relatively small (~1- to 5-
km radius), capable of providing, say, 100 Mbps to 1 Gbps of data through-

put per square kilometer for frequency allocations of a few hundred mega-
hertz.The above order-of-magnitude improvements can indeed be achievedvia a combination of technology improvements, including these:¥High-speed (Mbps+) radio modems based on advanced signal-processingtechniques, such as equalization, spread spectrum, multicarrier modulation, spa-
tial processing, and smart antennas. Examples include equalized QAM, usedin several first-generation fixed wireless systems; equalized VSB in the
U.S. terrestrial HDTV standard; wideband direct-sequence CDMA, under
consideration for the 3G mobile (IMT-2000) standard; and OFDM, pro-
posed for various fixed and semimobile scenarios (including ETSI Hiper-
lan II and several proprietary WLL systems, such as Clarity Wireless/
Cisco). Spatial processing with multiple antennas, mentioned above, is a
new dimension for improving modem performance, and has recently been
proposed by several independent groups (Bell Labs, Stanford University,
Iospan) as a means for dramatically improving both non-LOS coverage
and spectral efficiency. All of these technologies are maturing rapidly,MobilityCellularPCSWirelessLANUMTS/IMT-2000BroadbandPCSHigh-speedWLANLEOS, etc.Application regimefor broadbandwireless10Mbps+ servicesFixed - ModerateMobilityPacket Data +Voice/VideoMicrowaveBroadband10 kbps100 kbps1 Mbps10 Mbps100 MbpsFIGURE A.29Broadband wireless service scenarios in terms of mobility versus
bit rate.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A285and it may be expected that commercial products will soon deliver10 Mps+ services with cellular reuse and spectral efficiency on the order
of 5 bps/Hz/sector. With continuing advances in signal processing,
achievable bit rates should increase to 100 Mbps+ with spectral efficiency
of 10 bps/Hz over the next 5 years.¥Cellular technology capable of scaling to small cells and multiple sectorsnecessary for effective coverage of areas with higher population density. Scaling
of broadband wireless services to small cells is inevitable in areas with
higher population density, where throughputs on the order of 100 Mbps
to 1 Gbps/km2 must be achieved in order to serve even a modest fraction
of the population. Efficient cellular reuse implies the need for modem
technology that can operate at relatively low carrier-to-interference (C/I)
ratios. This can be achieved by a suitable combination of time/frequency/
space processing. For example, spread spectrum achieves high spatial
reuse via time-frequency processing, while multiple antenna spatial pro-
cessing OFDM modems do so using frequency-space processing. Wide-
band CDMA adopted for IMT-2000 radio access achieves a spatial reuse
factor of 1:1 using spread spectrum and interference cancellation tech-
niques. However, net throughput per square kilometer is limited by the
relatively low ~0.5-bps/Hz efficiency of spread spectrum modulation.
Spatial processing techniques mentioned earlier have the potential for
achieving spectral efficiencies on the order of 5 to 10 bps/Hz/cell with
~1:3 spatial reuse. Further gains can be achieved for both CDMA and
spatial processing OFDM with directional remote antennas and base sta-
tion sectorization.¥Spectrum regulation and management policies that facilitate rapid de-ployment of broadband services, while promoting efficient use. The pace of
wireless network deployment is critically dependent on spectrum regula-
tion policies, both international and domestic. Historically, the process of
frequency allocation has been rather slow, with the United States and to
some extent the European Union taking the lead in introducing both spec-
trum auctions and unlicensed bands in order to stimulate efficient eco-
nomic usage. While one-time spectrum auctions in the United States have
had their intended effect (e.g., PCS and MMDS bands), it may be time to
consider introducing more dynamic market mechanisms that allow spec-
trum to change hands in time-constants of minutes or hours rather than
months or years. For example, it may be possible to establish an online
commodity trading system for spectrum that would permit operators
with higher economic utility to bid for their peak usage needs without
having to go through a lengthy procurement process.Rapid deployment of wireless services would be further facilitated bystreamlined approval processes for a wider range of customer equipment,Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.286APPENDIX Aincluding those with higher-powered directive antennas. This wouldprobably require further advances in antenna beam and power control,
but should be technically feasible in the near term. The broadband WLL
business model depends to a large extent on user-installable or self-con-
figuring customer premises equipment (CPE), something that would re-
quire some relaxation of current rules in MMDS and other fixed access
bands. In addition, it may be expected that fixed access will gradually
migrate toward semimobile services as cell sizes become smaller, further
increasing the need for simple approval policies.Unlicensed spectrum, such as the 5-GHz unlicensed national infor-mation infrastructure (U-NII) band in the United States, is an important
facilitator for broadband access. FCCÕs allocation of the U-NII spectrum
has stimulated considerable commercial activity in the high-speed wire-
less LAN area. It is recognized that the same type of technology (perhaps
with somewhat higher power levels and larger coverage areas) could be
used as a broadband PCS access network for public semimobile services
in urban and suburban communities. There is, however, one remaining
technical problemÑthat of spectrum etiquetteÑa decision on which was
deferred by the FCC in its initial U-NII ruling. The problem is that exist-
ing unlicensed band etiquettes such as listen-before-talk (LBT) do not
work well for stream services with quality-of-service (QoS) requirements.
In such cases, the etiquette must be designed for equitable sharing among
contending stream users, without reducing all of them to an unacceptable
QoS level. The FCC has invited the industry to propose a suitable eti-
quette, but a specific scheme has yet to be identified. A possible technical
solution is to introduce a common spectrum coordination channel at the
edge of each unlicensed band and require users to execute mutually
agreed sharing procedures (priority, dynamic auction, and so on) using a
standardized etiquette protocol.Radio Link ProtocolBroadband wireless access requires a new type of radio link protocol(RLP) capable of reliably transporting both packets and media streams
with specified QoS. The broadband RLP itself may be decomposed into a
medium access control (MAC) layer for channel sharing among multiple
subscribers, and a data link control (DLC) protocol for error recovery.
Broadband wireless networks tend to use either a packet CDMA, dy-
namic TDMA type, or an extended 802.11 carrier sense, multiple access/
collision avoidance (CSMA/CA) MAC protocol. CDMA is the basis for
the emerging IMT-2000 wideband CDMA standard for 3G mobile, and is
associated with the choice of spread spectrum modulation believed to be
appropriate for vehicular mobile systems. Dynamic TDMA has generallyBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A287been adopted for broadband applications, as well as for some high-speedLANs (such as wireless ATM and the European Telecommunications Stan-
dards InstituteÕs broadband radio access networks) in view of its ability to
support a combination of packet data and constant bit-rate streams (voice
and video). Extended 802.11 protocols provide streaming extensions for
QoS support, and may be suitable for Ethernet-equivalent WLAN sce-
narios. DOCSIS MAC protocols used in cable networks have also been
modified for WLL applications, but will generally incur a performance
penalty owing to large packet sizes.Data-link-layer retransmission for error recovery is an essential fea-ture for broadband wireless service, since higher-layer protocols are criti-
cally dependent on low packet error rates on each link of the end-to-end
connections. DLC involves fragmentation of data packets into relatively
small units, the optimum for which is typically between 40 and 200 bytes,
depending on the channel and traffic model. Many current implementa-
tions have adopted the ATM cell payload of 48 bytes as the basic unit of
fragmentation on the radio link. This has the advantage of simplifying the
interface to ATM backhaul networks, which are often used in carrier
broadband and DSL networks. Error control on the radio link involves the
addition of a wireless link header containing a sequence number used for
identifying data units to be retransmitted. Implementation results have
shown that significant improvements in end-to-end protocol performance

(typically 2 orders of magnitude in packet error rate) can be achieved with
fragmentation and retransmission on the radio link. This in turn permits
wireless systems to operate in a higher C/I environment, thus increasing
overall capacity of cellular networks.Infrastructure NetworkBroadband wireless access links are being designed as Òplug-insÓ toexisting fixed network architectures based on IP and/or ATM. In order to
facilitate ubiquitous deployment, it is important that both fixed WLL and
mobile access be easily integrated with broadband DSL and cable net-
works currently being deployed. This means that the radio air application
programming interface should be harmonized with both IP and ATM to
the extent possible, particularly in terms of providing generic parameters
for service establishment and QoS control. For fixed wireless access, inter-
face functions specific to the radio link are performed by the base station,
which puts out standard IP and/or ATM data and control into the infra-
structure network.For mobile scenarios, services (such as location management andhandoff) specific to mobile users may be provided either with a mobility
overlay, used in current cellular systems, or by integrating mobility sup-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.288APPENDIX Aport into the core network protocols, such as IP or ATM. The latter method(i.e., support integrated mobility in IP or ATM) is the preferred method
for broadband in view of performance and scalability requirements. More-
over, as an increasing proportion of user devices becomes portable, the
distinction between fixed and mobile user addresses will become more
difficult to administer (the integrated approach does not require a priori
partitioning of mobile and fixed addresses). Protocol specification work
aimed at integrating mobility support into IP and ATM has been done in
both the Internet Engineering Task Force (IETF) (mobile IP) and the ATM
Forum. While much further work remains (3G.IP and so on), it may be
expected that mobility will increasingly be integrated as a standard fea-
ture into fixed network infrastructures. Ultimately, this technical direc-
tion will further accelerate fixed and wireless network convergence, which
has been predicted for some time.MEDIA COMPRESSIONMedia signals include (digital) data as well as analog information andentertainment signals: speech, audio, image, video, graphics, and other
audiovisual signals such as hand gestures and handwriting. These signal
classes are universal and are representative of most if not all information
that needs to traverse the first mile, in either direction.Complementary Roles of Modems andCompression Systems (Codecs)Modem and access technologies have evolved to expand the trans-mission pipe for conveying digital information. In parallel, compression
technology has evolved to compact the amount of digital information that
is needed to convey the information in a signal with a specified level of
fidelity. Access speeds have generally advanced on a faster track than has
compression technology. That said, it is the combination of faster mo-
dems and greater levels of compression that has enabled advances and
revolutions in digital communication. This section focuses on the impact
of media compression as a direct enabler of digital communication over
channels and networks with limited capacity.Computing is an overarching enabler of multimedia communications,whether one is implementing coders or decoders (codecs for short) or is
implementing modulators or demodulators (modems for short). MooreÕs
law has direct implications on the rate at which computing technology
(memory and arithmetic capability) advances as a function of time. In this
view, advances in computing are much more rapid than are advances in
access technologies. That said, advances in computing will only helpBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A289speed up advances in access, but these advances are strictly knowledge-or algorithm-limited, as are the advances in compression.The Dimensions of Performance in Media CompressionThere are four dimensions of performance in a compression system:(1) quality, (2) bit rate, (3) delay, and (4) complexity. ÒQualityÓ refers to
the quality of the signal after compression, measured in absolute terms or
in terms of closeness to the original version of it. The Òbit rateÓ is the data
rate after compression. The ÒdelayÓ is the sum of delays in the encoding
and decoding parts of the system: the compression and decompression
algorithms. (This does not include delay components resulting from spe-
cific implementation details or specific transmission latencies in the com-
munication of the encoder bit stream.) Finally, ÒcomplexityÓ refers to the
computational effort needed to perform the compression and decompres-
sion algorithms, measured for example, in millions of instructions per
second (mips) and kilobytes (the read-only and random-access memories
used in the codec [coder-decoder]). As processing technology improves,
the importance of the complexity parameter tends to diminish, but delay
remains as a fundamental performance metric. Delay is particularly im-
portant in interactive, or two-way, communications.The Fuzzy Fifth Dimension: Richness of ContentIn studies of compression efficiency, where one measures quality deg-radation as a function of increasing levels of compression, one assumes
that the bandwidth, or frequency content in the signal, is a prespecified
characteristic. For example, telephony is always associated with a speech
signal of 4-kHz bandwidth, and television with a signal whose effective
horizontal and vertical resolutions are on the order of a few hundred
pixels in each case (a total number of pixels per frame on the order of
100,000).In Table A.2, the notation of pps refers to pixels per second. It is theproduct [H  V 
 F] of horizontal resolution (H pixels per row), vertical
resolution (V pixels per column), and temporal resolution (F frames per
second).With the evolution of flexible and scalable communications technol-ogy, one often has the option of considering input signals of higher band-
width, as long as the compression is strong enough to delimit the output
data rate to a specified number. Examples are high-bandwidth audio (such
as FM-grade speech with 12- to 15-kHz bandwidth or CD-grade music
with 20-kHz bandwidth, or multichannel sound) and high-definition tele-
vision (a total number of pixels on the order of 2 million, 60 frames per
second).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.290APPENDIX AScalability in bandwidth is a somewhat fuzzy situation in that usersare often not conditioned to the continuum in this parameter between, or
beyond, well-established anchors. For example, wideband speech is a
fuzzy term that implies any bandwidth in the range between well-defined
telephone and CD grades (4 and 20 kHz), and first-generation Internet
video often is understood to mean anything that is usable, albeit below
TV quality (such as 10,000 to 100,000 pixels per frame). The video situa-
tion has the additional dimensions of viewing distance, physical picture
size, and fractional-screen displays, which further control user apprecia-
tion of picture quality or user perception of picture degradation.The Algorithms of Media CompressionThe description of compression algorithms is beyond the scope of thisappendix. It is also not needed for the purposes of this report. What is
important, however, is to note that all compression algorithms are based
on only two basic principles: removal of redundancy in the input signal,
and the reduction of irrelevancy in it. ÒRedundancyÓ is usually character-
ized in a statistical fashion, while ÒirrelevancyÓ is best linked to a percep-
tual criterion. Compression techniques are also usefully classified into
three types: (1) lossy, (2) lossless, and (3) perceptually lossless. Math-
ematically lossless compression is used in some archival, legal, and medi-
cal applications, while perceptual losslessness is a pragmatic criterion for
a large class of applications in transmission and storage. Most compres-
sion standards tend to address this criterion. Other characteristics to keep
in mind are the delay and complexity of the algorithms, and how they areTABLE A.2Multimedia Formats
FormatSampling RateFrequency Band
Telephone8 kHz200-3,400 Hz
Teleconference16 kHz50-7,000 Hz

Compact disk44.1 kHz20-20,000 Hz
Digital audio tape48 kHz20-20,000 Hz
CIF Video3 Mpps [360 
 288 
 30]
CCIR Video12 Mpps [720 
 576 
 30]
HDTV60 Mpps [1,280 
 720 
 60]
NOTE: Mpps = megapixels per second.SOURCE: Nikil Jayant, 1993, ÒHigh Quality Networking of Audio-Visual Information,ÓIEEE Communications Magazine 31(9).
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A291distributed between the compression and decompression parts of the sys-tem. For example, interactive and two-way applications look for low-
delay compression, servers can typically afford high complexity, and cli-
ent systems need to be relatively simple to implement. Implementation
platforms can be ASIC (application-specific integrated circuit), DSP (digi-
tal signal processor), or NSP (native signal processor, as on a Pentium).
As a matter of calibration, a Pentium II (400-MHz) processor can decode
MPEG1 video streams in real time, and a pocket PC in 2001 has a proces-
sor that works at half the speed (about 200 MHz).Compression StandardsTables A.3 and A.4 provide nonexhaustive lists of compression stan-dards for audiovisual signals. In general, results refer to lossy compres-
sion, although these standards include special functions for lossless com-
pression. For example, in JPEG image compression, there is a lossy
(perceptually lossless) version with typical bit rates of 0.5 to 2 bits per
pixel (bpp), while a mathematically lossless version may use a bit rate of
5 to 6 bpp.In Figure A.30, the horizontal axis displays bit rates after compressionfor classes of applications that are arranged in clusters that represent
speech, audio, and image applications. The bit rates range from 1 kbps to
100 Mbps. Interestingly, the geometric mean of this range is 300 kbps, a
number typical of conservative ADSL and cable modem rates in the year
2000. The data rates in Figure A.30 are strict lower bounds in the sense
that in most applications, the compressed information needs to be supple-
mented with ancillary data.Bit Error ProtectionIn a rate k/n error correction code, k information bits are protectedfor transmission over an error-prone channel by adding (n-k) redundant
bits. The fractional overhead is 1-k/n.Sophisticated methods of error protection include these:¥Unequal error protection, in which different parts of the compressoroutput receive different levels of error protection, depending on models
of their relative perceptual importance;¥Joint source and channel coding, in which, for example, the total bitrate available is shared dynamically between source bits and error protec-
tion bits, depending on the model or knowledge of the channel state.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.292APPENDIX ATABLE A.3Standards for Speech Compression
Standard (year)AlgorithmBit RateApplication
G.722 (1988)Subband64, 56, 48 kbpsTeleconferencing
ADPCMMPEG-1 (1992)Musicam384, 256,Two-channel audio
ASPEC128 kbpsw/video on CD
MPEG-2 (1996)PAC320 kbpsFive-channel surround sound
for multimedia recordingDAB (1996)PAC160 kbpsTwo-channel audio for
terrestrial broadcastJBIG (1991)Run length0.05-0.1 bppBinary coded images
coding(half-tone)
JPEG (1991)DCT0.25-8 bppStill continuous-tone images

MPEG-1/2MD-DCT1-8 MbpsAddressable video on CD
(1991, 1994)P  64 (1991)MC-DCT64-1,536 kbpsVideoconferencing
HDTV (1996)MD-DCT17 MbpsAdvanced TV
G.711 (1972)Mu-Law and56-64 kbpsNetwork transmission
A-Law PCMG.721 (1984, 1987)ADPCM32 kbpsBit-rate multiplexers,
undersea cableG.723 (1988)ADPCM24, 40 kbpsOverload on undersea
cable, data modemG.726/G.727ADPCM16, 24, 32,High overload rate for
40 kbpsundersea cable
G.728 (1992)LD-CELP16 kbpsTransmission at low delay

G.729 (1995)ACELP8 kbpsSecond-generation digital
cellularG.723 (1995)ACELP6.3, 5.3 kbpsLow-bit-rate videophone

GSM (1987)RPE-TLP13 kbpsEuropean digital cellular
full-rateIS-54 (1989)VSELP8 kbpsNorth American digital
cellular-TDMAIS-96 (1993)QCELP8.5, 4, 2,North American digital
0.8 kbpscellular-CDMA
GSM-1/2 (1994)VSELP5.6 kbpsEuropean digital cellular
half-rateEVRC (1996)RCELP8.5, 4, 0.8 kbpsNA CDMA, 2nd generation

IS-136 (1995)CELP8 kbpsNA TDMA, 2nd generation
JDC (1989, 1992)VSELP8, 4 kbpsJapanese digital cellularÑ
full and half ratesFS-1016 (1975)CELP4.8 kbpsSecure telephonyÑfull rate
FS-1015 (1975)LPC-10E2.4 kbpsSecure telephonyÑhalf rate
FS-1015 (1996)2.4 kbpsSecure telephonyÑhalf rate,
2nd generationSOURCE: After R.V. Cox. 1999. ÒCurrent Methods of Speech Coding,Ó in N. Jayant (ed.),1999, Signal Compression: Coding of Speech, Audio, Image and Video, World Scientific,
Singapore.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A293TABLE A.4Standards for Audio, Image, and Video Compression
Standard (Year)AlgorithmBit RateApplication
G.722 (1988)Subband ADPCM64, 56, 48 kbpsTeleconferencing
MPEG-1 (1992)Musicam/ASPEC384, 256, 128 kbpsTwo-channel audio w/
video on CDMPEG-2 (1996)PAC320 kbpsFive-channel surround
sound for MM recordingDAB (1996)PAC160 kbpsTwo-channel audio for
terrestrial broadcastJBIG (1991)Run length coding0.05-0.1 bppBinary coded images
(half-tone)JPEG (1991)DCT0.25-8 bppStill continuous-tone
imagesMPEG-1/2(1991, 1994)MC-DCT1-8 MbpsAddressable video on CD
P  64 (1991)MC-DCT64-1,536 kbpsVideoconferencing
HDTV (1996)MC-DCT17 MbpsAdvanced TV
NOTES: kbps = kilobits per second; bpp = bits per pixel.SOURCE: After R.V. Cox. 1999. ÒCurrent Methods of Speech Coding,Ó in N. Jayant (ed.),1999, Signal Compression: Coding of Speech, Audio, Image and Video, World Scientific,
Singapore.FIGURE A.30Data rates in digital representations of signals. Rates are numbers
after compression. SOURCE: After R.V. Cox. 1999. ÒCurrent Methods of SpeechCoding,Ó in N. Jayant (ed.), 1999, Signal Compression: Coding of Speech, Audio, Im-age and Video, World Scientific, Singapore.
HDTVDIGITALTELEVISIONMOVIES ONCOMPACT DISKMUSIC PREVIEWANDBROADCASTAUDIOCONFERENCENETWORKTELEPHONYVIDEO CONFERENCECELLULARRADIOVOICEMAILHIGH-RESOLUTION FACSIMILESECUREVOICEIMAGE-PHONESLIDESHOW 1      2     4      8      16    32    64    128         512     1      2              8             32KILOBITS PER SECONDMEGABITS PER SECONDBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.294APPENDIX AResiliency to Packet LossesPacket networks are often limited by packet losses rather than biterrors. Packet losses can be addressed by retransmission in delay-insensi-
tive applications. In delay-sensitive communications, packet losses can be
anticipated by redundancy in the packet generator.In sophisticated algorithms, such as embedded coding and multipledescription coding, this redundancy is contained by unequal protection
of subpackets, depending on models of perceptual importance of these
subpackets, as in unequal bit error protection.Information Hiding, Steganography, Watermarking,and Multimedia AnnotationsIncreasingly, digital communications will include ancillary informa-tion that may convey a variety of information to the end user that is
related to authentication (information about sender and intended receiver,
for example), and such information is embedded in the main message in
an unobtrusive and imperceptible form. These are the techniques of infor-
mation hiding, with subclasses called steganography and watermarking.
Multimedia annotations also involve additional data, but not necessarily
in imperceptible or hidden form.The overall effect of all of the above processes is that the data rate fordigital communication is strictly higher than the data rates at the output
of the signal compression stage. While there is no rigorous way of mea-
suring the resulting overhead in data rate without regard to the applica-
tion and the needs of it, it is useful to use the following guideline:Typical overall overheads are in the range of 10 to 100 percent, andthe rates on the horizontal axis of the compression chart in Table A.4 need
to be increased by factors as high as 2.0, especially in the case of un-
friendly access methods such as wireless links that are power- and inter-
ference-limited and/or in networks that are operating in situations of
overload.In scalable media communications, the inherent excursions in datarate in the compression algorithm can well exceed the factor of 2 referred
to above. In these cases, the metrics of importance are the average data
rate in the scalable compression algorithm, and, where available and us-
able, more detailed descriptions of the data rate histogram. In fact, assess-
ments of traffic and channel loading depend directly on these difficult
and highly variable characterizations of the information source. The least
complex nontrivial measure of overall data rate is the average data rate
after compression, multiplied by the overhead mentioned in the guide-
line above.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX A295Media-Specific Examples: Access Implications and Questions¥Toll-quality telephony versus Internet or cable modem telephony.Whatare the quality and delay targets in IP-telephony and cable telephony?
What are the consumer expectations? Is there a business case for AM-
radio-grade telephony? What is the competitive landscape?¥Audio/video streaming at lite-ADSL, cable modem, and wireless speeds.Are user expectations going to be tied to television quality? What is the
longevity of partial-screen solutions? What is the competitive landscape?¥Uploading of information from a home.What are the primary casesfor upload-speed on demand? What are the demands of such applications
as telemedicine, teleworking, home publishing? Is there a case for sym-
metric uplink and downlink?Definitive answers to these questions do not exist, but as applicationsmature, it will be possible to understand and quantify them at least im-
plicitly and qualitatively.Research and Technology OutlookAt this time, compression technologies are mature. Although it isdifficult to define the fundamental limits in the game, typical data rates
for specified levels of quality are generally known. Increasing compres-
sion ratios will become the preoccupation of specialists. Likewise, decod-
ers and clients will become pervasive and affordable. New advances in
first mile and first meters multimedia communications will depend in-
creasingly on advances in access speed and on innovations in network-
ing.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.296

A large legacy from past policy, dominated by telecommunicationsregulation, shapes the context for broadband policy. That legacy princi-
pally concerns regulation of wireline communications through common
carriers, but it also includes regulation of cable, broadcasting, other wire-
less communications, and regulations applied to the Internet. The legacyÕs
salient features are briefly reviewed in this appendix.THE LEGACY FROM PAST POLICYCommon Carriers (Telephony)Local and long distance telephone companies operate as commoncarriers, which historically have had close regulatory scrutiny by both
federal and state agencies. The history of common carriage is fundamen-
tal to the baseline for broadband deployment, because it shaped what
exists today in the telephone infrastructure as well as expectations in
numerous industries and locales about the nature of investment and com-
petition in communications and information infrastructure.A telecommunications Òcommon carrierÓ is the term used to describea provider of telecommunications transmission service that offers its ser-
vice to the public for a fee and, in contrast to, for example, a television
station owner or a cable television operator for most of its channels, does
not control the content of the information transmitted by its facilities or
services. Rather, the carrierÕs customer controls the content and the desti-
nation of the transmission. Criminal or civil responsibility for the contentBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX B297rests (for the most part) with the sender, not the carrier. For most of the20th century, federal and state regulation of common carriers has beenconsidered necessary because telecommunications services in any geo-
graphic area have been provided by a single carrier.1 Similar thinking and
tactics have been applied to providers of other kinds of infrastructure
regarded as utilities, such as electric power or water, and historically to
transportation, including rail, toll roads, ferries, and the like.While policy goals are established through laws, regulatory agenciesimplement the laws through rulemaking. The Federal Communications
Commission (FCC) regulates the interstate activities of such carriers,2 and
state commissions regulate their intrastate activities.3 Rulemaking and
other administrative proceedings follow a set of practices that involve
issuing a notice of intent to act, solicitation of comments, and other for-
malities. These processes have given rise to a cadre of in-house and pri-
vate-practice lawyers, economists, and lobbyists seeking to promote or
discourage certain kinds of decisions by regulators. Depending on oneÕsperspective, these processes may reflect an open, fair process for imple-
menting regulations or a drag on the telecommunications marketplace.Regulators were persuaded that local and long distance services werenatural monopolies and, consequently, could be provided at the lowest
cost through a single firm. Economic regulation, not competition, would
constrain the prices and practices of the monopoly carriers. Under this
regulatory regime, the Bell System provided local telephone service in
virtually all urban areas and gradually extended its reach to many rural
areas. Its long distance network interconnected Bell as well as subscribers
of the remaining thousand-plus independent telephone companies (each
a monopoly in its franchise territory), enabling any subscriber to call any
other telephone subscriber. Over time, the Bell System became the envy of
the world because of the breadth, price, and quality of its service offer-
ings.1These monopolies were created initially by AT&TÕs aggressive acquisition of indepen-dent telephone companies in the early 20th century. The regime emerged in the wake of the
1913 agreement between the Bell Telephone system and the U.S. Department of Justice,known as the Kingsbury Commitment. In return for certain concessions, Bell Telephonewas permitted to retain the local telephone companies it had acquired since the turn of the
century and to maintain its monopoly control over long distance.2Under Title II of the Communications Act of 1934, as amended.3Because AT&T and the independent local telephone companies were permitted to oper-ate as government-protected monopolies, the prices and other terms and conditions of theirservice offerings were subject to close scrutiny by federal and state regulators to prevent thetelephone companies from exercising their market power. If a call originates in one state
and terminates in another state or foreign country, that service is subject to the FCCÕsjurisdiction. If a call originates and terminates within the same city or within the same state,that service is subject to the state commissionÕs jurisdiction.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.298APPENDIX BIn the last third of the 20th century, however, technological advancescast increasing doubt on the premise that telephone service, or at least
certain aspects of it, should be provided on a monopoly basis. In the 1960s
and 1970s, the FCC gradually relaxed regulation of telephone terminal
equipment (e.g., telephone handsets, private branch exchanges), known
as customer premises equipment (CPE).4 These actions spawned the emer-
gence of an intensely competitive market for handsets, fax machines, pri-
vate branch exchanges (PBXs), and other terminal equipment.5 In the
1970s and 1980s, the FCC followed a similar pattern of phased regulatory
relaxation in the long distance market. The most significant event in the
introduction of long distance competition involved an antitrust case
spawned by such competition and AT&TÕs response to it. In 1982, AT&Tand the U.S. Department of Justice entered into a consent decree, known
as the ÒModified Final JudgmentÓ (MFJ), that required AT&T to divest its
local operating companies.6 By separating AT&T
Õs monopoly segmentsfrom its more competitive long distance operations, the decree went a
long way toward opening the latter to facilities-based competition, be-
cause it eliminated the incentive of the local telephone companies to dis-
criminate against MCI and other would-be AT&T competitors through
their monopoly control over the local network.The decree removed one of AT&TÕs most substantial competitive ad-vantages by requiring the Bell Operating Companies to provide equal
access to other long distance companies.7 As competition in the long dis-
tance industry matured, additional technical impediments were elimi-
nated (such as the introduction of 800-number portability across long
distance carriers) and new entrants began to make inroads into AT&TÕs4Prior to the FCCÕs action, telephone equipment was part of the service that the localtelephone company provided to its customers. Indeed, customers were prohibited by thecompaniesÕ tariffs from attaching other equipment to the network.
5In deregulating CPE, the FCC also preempted state commissions from continued regula-tion of that equipment. The FCCÕs jurisdiction under the Communications Act of 1934, asamended, in the 1970s was limited to interstate services. The commission recognized, how-
ever, that, as a practical matter, it could not deregulate ÒinterstateÓ CPE, since such equip-
ment is used to place and receive both interstate and intrastate communications. Hence, itbarred state agencies from continuing to regulate the provision of CPE in order to prevent
such policies from frustrating the FCCÕs national deregulation policy. See North CarolinaUtils. Comm. v. FCC I.6See United States v. American Tel. & Tel. Co., 552 F. Supp. 131 (D.D.C. 1982), affÕd, 460 U.S.
1001 (1983).7The operating companies were required to modify their networks to enable a subscriberto these other providers also to use the Ò1+Ó prefix to obtain access. Prior to the implemen-
tation of this Òequal accessÓ requirement, subscribers of long distance companies other than
AT&T were required to dial a seven-digit local number, then dial a multidigit personalidentification number, and then dial the long distance number they were calling.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX B299market share, the FCC gradually relaxed price regulation of AT&T on aservice-by-service basis.8The latter half of the 1980s and first half of the 1990s were marked bythe continued erosion of AT&TÕs long distance dominance, as MCI, Sprint,and scores of other competitors gained significant inroads (although
AT&T remains the largest provider). In light of these changes in the mar-
ketplace, the FCC gradually loosened its controls over different segments
of AT&TÕs long distance business, culminating in a 1995 decision thateliminated the remaining FCC price controls of AT&TÕs basic residentialservices.9 Although AT&T remained subject to price regulation for more
than a decade after it divested its Bell Operating Company subsidiaries,
the prices of interstate services offered by new (and accordingly much
smaller) providers of long distance, such as MCI, were not regulated.10 By
the end of the 1990s, AT&TÕs share of the long-distance market hadslipped below 50 percentIn the late 1980s, federal and state regulators also began to take thefirst steps toward opening local telecommunications markets to competi-
tion. Following several states such as New York and Illinois, the FCC
adopted its Expanded Interconnection rules, which required incumbent
telephone companies to interconnect their networks with new firms that
wished to provide competing local transport services. These develop-
ments raise the possibility of shifts in state regulatory emphasis from
retail rate regulation to wholesale enforcement.11The enactment of the Telecommunications Act of 1996 marked thecommencement of the most concerted effort by state and federal regula-8For example, when 800-number portability made it possible for an 800-number customerto switch long-distance carriers and retain its 800 number (e.g., 1-800-FLOWERS), the FCCremoved its price regulation of AT&TÕs 800 service offerings.9Because the FCCÕs jurisdiction is limited to interstate services, it does not regulate therates that local telephone companies charge for local and intrastate services (such as callsfrom Los Angeles to San Francisco). Local telephone companies, however, provide origina-
tion and termination service to interstate long distance companies. That is, the local tele-phone companies carry an interstate call from the originating end user to the interstatecarrierÕs switch, where it is placed on the long distance carrierÕs network. Local telephonecompanies also carry calls from the long distance companyÕs switch to the called partyÕspremises. This origination and termination service is known as interstate access service andis subject to the FCCÕs jurisdiction.10The FCCÕs theory was that since the new entrants did not possess market power, therewas no need to regulate their rates. If consumers were dissatisfied with an MCI offering,they could always take service from AT&T, whose rates were regulated.11Bob Rowe. 2000. ÒImplementing a Cooperative Federalist Approach to Telecom Policy.ÓSpeech presented at Federalist Society, Washington, D.C., September 27.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.300APPENDIX Btors to dismantle the monopoly control over local telecommunicationsmarkets exercised by the Bell Operating Companies and other incumbent
telephone companies. The results have yet fallen short of the quick move-
ment to ÒderegulationÓ that some had hoped for. Armed with new statu-tory authority, the FCC and state regulatory commissions moved ag-
gressively to require local incumbents to open their markets. Incumbent
telephone companies, called ILECs (incumbent local exchange carriers)
continue to have overwhelming market shares, particularly among resi-
dential customers, thanks to their initial monopoly position and scale and
scope economies that are difficult to overcome. To help overcome these
incumbent advantages, the Telecommunications Act of 1996 mandated
that incumbents offer competitors (CLECs) access to unbundled network
elements at reasonable rates. Because ILECs continue to control well over
90 percent of local market revenues and customers, they remain subject to
comprehensive price regulation at both the federal and state level. CLECs,

lacking market power, generally are not.In 1999, the FCC adopted rules for the gradual deregulation of theincumbent telephone companiesÕ provision of local service used for inter-
state communications. Prices should be deregulated when there was evi-
dence that the incumbent could not exercise market power.12 Meanwhile,
there has been horizontal consolidation among telephone companies plus
vertical integration of such companies (e.g., Qwest acquired USWest;
NYNEX merged with Bell Atlantic, which merged with GTE to become
Verizon; SBC acquired Pacific Telesis and Ameritech; MCI merged with
WorldCom, which also merged with UUNet; and AT&T acquired TCI
and other cable interests). Thus, although the 1996 act eliminated legal
barriers to entry in those states where they persisted, economic and tech-
nical barriers are eroding more slowly. Nevertheless, competitors have
made inroads among business customers in urban markets. Against this
backdrop, issues posed by open access in broadband have prompted FCC
initiatives.CableThe regulatory regime governing cable television systems is entirelydifferent from the common carrier scheme. It has a much shorter history,12What criteria should be applied remains a controversial subject. The incumbents havechafed at delays to their entry into long distance. Competitors to the ILECs have main-tained that the criteria used by the FCC do not provide an accurate picture of the availabil-
ity of alternative providers of local telecommunications services, and that the FCC blue-print would permit the incumbents to preserve their monopoly control over local marketsby granting them substantial pricing flexibility when they continue to wield market power.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX B301and it reflects the fact that following its earliest days, when cable wasused to provide television service in regions not reached by broadcast
television, cable grew by providing an alternative to an existing entertain-
ment and information service (broadcast television) and faced initial de-
ployment challenges. Cable operators do not have to offer their transmis-
sion service to the public on a nondiscriminatory basis, unlike common
carriers. Most important for understanding how regulation was ap-
proached, cable systems maintain considerable control over the content
that is transmitted over their distribution facilities. Unlike common carri-
ers, they have asserted First Amendment rights with regard to the content
they carry, a status upheld by the courts. Cable operators generally are
not required to offer access to their distribution system to enable other
(unaffiliated) content providers to deliver their products to cable sub-
scribers (major multiple system operators that vertically integrate content
production and cable service are required to devote a portion of their
system capacity to unaffiliated networks). Even without any mandate to
do so, however, operators offer unaffiliated content channels for two rea-
sons: (1) no single operator has enough high-quality content to fill all of
its capacity, and (2) operators generally find that customer demand for
these channels exists. Thus, almost every system carries CNN, which is an
AOL Time Warner service, and ESPN, which is owned by Disney-ABC. In
addition, cable operators, under certain circumstances, are required to
offer access to providers of traditional video services under the so-called
leased access provisions of Title VI of the Communications Act of 1934 (as
amended). Also, there have been local content requirements through pub-
lic, education, and government channel provisions of franchises. None-
theless, the contrast between the relative freedom to control content and
the obligations placed on common carriersÑwhich gives rise to expecta-tions of similar behavior in the futureÑis one genesis of todayÕs ÒopenaccessÓ debate,
13 discussed below.
Cable television is subject to limited federal regulation. Under TitleVI of the Communications Act of 1934 (as amended), the Òbasic tierÓ of
services, encompassing mostly local television signals, is subject to rate
regulation. Local authorities could regulate the price of the basic tier,
pursuant to formulas prescribed by the FCC, unless Òeffective competi-tionÓ existed, as defined by the Cable Act of 1992 (such price regulation
expired in 1999). Cable television operators also are limited in their ability
to expand horizontally and vertically with content providers. Devising,13Proponents of open access have argued, among other things, that when a cable systemfurnishes access to an Internet service provider, it is engaged in the provision of a commoncarrier service and, consequently, should be required with the same access obligations thatcharacterize common carriage provided by telephone companies.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.302APPENDIX Bimplementing, and enforcing regulations for the cable industry under the1992 act was difficult and time-consuming. A major complication was
that cable service, like broadband, is multifaceted and varies in capability
from one service area to the next. In the end, it is not clear that the regula-
tion accomplished much in the long run, with the exception of the rules
that made cable network programming available to overbuild competi-
tors and satellite services at ÒreasonableÓ prices, which spurred competi-
tion in video delivery.Cable systems are also subject to local regulationÑthrough the fran-chise agreements that they execute with municipal, county, or, in a few
cases, state authorities. These agreements typically run one or more de-
cades and are a source of revenue for the municipalities that issue them.As franchise agreements have come up for renewal, the new capabili-ties of cable systems to deliver advanced video and data services have
dominated the negotiations. As discussed in Chapter 4 in the report, a key
development beginning in the 1990s was the progressive upgrading of
cable plant to incorporate fiber (hybrid fiber coax), which increased sys-
tem quality and capacity and more recently facilitated use of cable infra-
structure for Internet access. However, cable operators are not under a
legal obligation to upgrade their plant to be able to offer broadband, cable
modem services. Further, if operators complete such an upgrade, they
currently are not (as a class) required to make access to that transmission
service available to unaffiliated providers of broadband services. Open
access requirements (discussed in Chapter 5) have figured heavily in sev-
eral franchise negotiations. Other elements arising in contemporary fran-
chise negotiations include establishment of minimum data bandwidth
and rights-of-way (such as joint trenching rules where there are multiple
entrants). New considerations analogous to the traditional public, educa-
tional, and government (PEG) requirements include extensions to non-
video services and making fiber available to local governments (and pos-
sibly for other customers).InternetFear of regulation has always haunted the Internet, although it isconsidered Òunregulated.Ó Popular misunderstanding has even motivated
the FCC to issue a fact sheet (last revised in January 1998) to dispel myths
about charges and taxes it was alleged to have imposed or to be consider-
ing imposing on the Internet or its use.14 Since the late 1990s, FCC com-
14Federal Communications Commission. 1998. ÒThe FCC, Internet Service Providers, andAccess Charges.Ó Available online at <http://www.fcc.gov/Bureaus/Common_Carrier/
Factsheets/ispfact.html>.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX B303missioners and staff have written and spoken publicly about the benefitsof the commissionÕs hands-off approach to the Internet.15 But the growth
in public interest in the Internet and the businesses behind it continues to
raise questions about prospects for government intervention, including
regulation, whether direct or indirect.The historic interaction of regulation with the Internet was ad hoc,even unintended. Anecdotal evidence suggests that the Internet was not
recognized as a phenomenon or concern by most regulators until the
1990s, when it became commercial, and those circumstances or actions
that can be identified do not seem to have been framed with the Internet
in mind.16 For example, a key enabler, in retrospect, was a series of FCC
decisions that gave customers the right to attach approved devices di-
rectly to the network, which has allowed both ISPs and users to attach
modems to their phone linesÑa necessary precondition for dial-up ac-cess.17 Some observers also point to common carriage regulation as an
important Internet enabler. Entry by ISPs has been facilitated by common
carrier rules which mandate nondiscriminatory access and reasonable
rates apply to both the dial-up lines used by individual customers and the
telephone network dedicated lines used by many ISPs to connect points
of presence to the Internet.Another enabler came in the 1980 second Computer Inquiry, whenthe FCC ruled that firms that use basic telecommunications services to
provide an enhanced service of some kind (such as information delivery)
are not engaged in the provision of a ÒbasicÓ common carrier, telecommu-
nications service (such as local telephone service). Rather, they are pro-
viding an ÒenhancedÓ service and, accordingly, are not subject to the
direct jurisdiction of the FCC or state regulatory commissions. That deci-
sion served to nurture commercial value-added networks, bulletin boards,
database services, and other data communications services in the 1970s15See, for example, Jason Oxman. 1999. ÒThe FCC and the Unregulation of the Internet.ÓOffice of Plans and Policy, Federal Communications Commission, Washington, D.C., July.
Available online at <www.fcc.gov/bureaus/opp/working_papers/oppwp31.pdf>.16The early development of the Internet was motivated in part by a desire to find relieffrom the high costs of dedicated leased line services available from the regulated telecom-
munications industry of the 1960s, which constrained early applications of data communi-cations for government and the research community. The prevailing telecommunicationsenvironment fed the interest and efforts of the researchers supported by the Defense Ad-
vanced Research Projects Agency, who both developed the early technology and were thefirst to benefit from the economies provided through packet-switching.17The certification scheme in 47 C.F.R. Part 68, adopted in the 1970s, enables firms toobtain FCC approval for devices that are attached to the network, permitting third partiesto develop innovative communications equipment while ensuring that attachment of thisequipment does not threaten the integrity of the network.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.304APPENDIX Band 1980s. These proved, in retrospect, to be training grounds for themore open Internet, as well as ISPs, in the 1990s.More recently, through Section 271 of the Telecommunications Act of1996, the former Regional Bell Operating Companies are prohibited from
offering interLATA servicesÑwhich include both long distance telephonyand Internet transmission servicesÑin states in which they provide localtelephone service, until they have satisfied certain market-opening re-
quirements. As a result, while these companies may operate dial-up and
broadband ISPs, customers must obtain connectivity to the rest of the
Internet through a regional or national ISP operated by another company.
Also, although virtually all Internet communications cross state lines, in
1997 the FCC affirmed18 an earlier ruling that the transmission between
an end userÕs premises and an enhanced service providerÕs location in thesame calling area would be treated as a local call, rather than as an inter-
state call, regardless of whether that transmission carries data, an e-mail
message, or even (at least under certain circumstances) a voice call over
the Internet.19 Finally, differences in inter-network traffic flows have fed
debate over so-called reciprocal compensation, a subject of FCC inquiry
in 2000-2001.20The Telecommunications Act of 1966 had another consequence thathas been important for the deployment of broadband Internet access.
Because the act required the ILECs to unbundle their circuits to CLECs, a
class of CLECs came into existence that offered data rather than voice
over these circuits, by means of DSL technology. This investment in DSL
by competitive providers seems to have spurred investment in DSL by
ILECs, and thus to have driven the overall rate of DSL deployment. At the
present time, the market downturn has put many of these competitive
DSL providers in peril, but this should not cause one to dismiss the contri-
bution of competition in this case.When incumbent telecommunications providers offer DSL, this ser-vice comes under the purview of the historical legacy of telecommunica-18Access Reform Order, FCC 97-158, adopted on May 7, 1997.19Precisely which voice transmissions might be subject to access charges is a delicate area.For example, the Federal Communications Commission indicated in a 1998 report to Con-
gress that a handset call to an ISP that terminated at a handset in another state may beclassified as a basic telecommunication service and hence be subject to access charges.20The concern is that different kinds of providers may terminate traffic out of proportionto that which they hand offÑespecially the relative burdens of dial-up Internet traffic. Atpresent, more may be terminated on CLEC than ILEC networks, implying (at least to theILECs) significant reciprocal compensation payments by ILECs to CLECs, but the nature of
potential funds flows depends on actual dial-up use in the future, a subject of disagreement(ÒIn ÔRecip CompÕ Debate, CLECs, Telcos Rely on Varying Projects for Dial-up Internet
Traffic,Ó Telecommunications Reports, January 8, 2001, pp. 9-10).Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX B305tions regulation. When an incumbent telecommunications provider sellsan enhanced service (which is not regulated) over a ÒbasicÓ service, the
incumbent provider must provide the basic service to others. DSL is seen
as a basic service. Thus, at the present time, the ILECs must unbundle
their data services at two levels. They unbundle their physical loops so
competitive DSL providers can implement DSL, and they unbundle their
DSL service so competitive ISPs can sell Internet access over the incum-
bentÕs DSL service.The history presented here, which illustrates indirect regulatory sup-port for the Internet that has been largely inadvertent (at least until the
late 1990s), unfolded without consideration of broadband. It focuses on
the presence or absence of regulatory intervention into pricing and mar-
ket entry. Broadband expands the potential space for intervention in at
least two ways: First, it involves different kinds of industries and tech-
nologies providing Internet access under different regulatory regimes

(e.g., some have expressed concern about the implications for ISP support
of cable-based Internet access in contrast to common carriers). Second,
distinguishing between information services and telecommunications car-
riers blurs when facilities owners integrate carrier and information ser-
vice functions, as is being seen in at least cable- and satellite-based broad-
band offerings.PRESENT: THE 1996 ACTMuch of the current policy framework relates to the Telecommunica-tions Act of 1996, which was framed as a reform effort. Since its enactment
and the unfolding of derivative activities, there is increasing awareness of
what it does and does not accomplish. This piece of legislation, a major
modification to the Communications Act of 1934, was shaped during the
early to mid-1990s. The language of the act indicates that its primary goals
are to promote competition and reduce regulation as a means of increas-
ing growth in telecommunications services and reducing prices.21 It was
enacted shortly after the 1995 commercialization of the Internet backbone
and introduction of the browsers that helped to popularize the World
Wide Web and before such technologies were widely used. Even though
many of the key actors understood that sweeping change was on the
horizon, full appreciation of the key role of the Internet did not exist, in
society or in Washington.21The preamble calls it ÒAn Act to promote competition and reduce regulation in order tosecure lower prices and higher quality services for American telecommunications consum-ers and encourage the rapid growth of new telecommunications technologies.Ó Telecom-
munications Act of 1996, P.L. 104-104, 110 Stat. 56 (1996), Preamble.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.306APPENDIX BThe Telecommunications Act of 1996 adjusted the relative roles offederal and state regulators, increasing that of the states. Whereas the
Communications Act of 1934 preserved state authority over intrastate
rates and services, the 1996 Act specified state roles in interconnection,
incumbent telephone company long distance market entry, and promo-
tion of advanced services. It sent mixed signals on federal preemption of
state regulators, and it reinforced a kind of cooperative federalism.22Most directly relevant to broadband, the Telecommunications Act of1996 calls for the FCC and states to encourage deployment of advanced
technologies for telecommunications to all Americans on a reasonable
and timely basis. But what satisfies Òadvanced,Ó Òall,Ó Òreasonable,Ó and
ÒtimelyÓ? The act, in support of service to ÒallÓ Americans, calls for
access to advanced telecommunications and information services in ru-
ral and high-cost areas to be Òreasonably comparableÓ to that in urban
areas in terms of price and quality. This formulation is interesting be-
cause it joins unregulated information services with regulated telecom-
munications services; what that implies for policy approaches and their
targets is unclear. Specific provisions of the act related to broadband are
summarized in Box 5.1, Chapter 5.24Rowe, ÒImplementing a Cooperative Federalist Approach to Telecom Policy,Ó 2000.
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.307
As input to its ongoing study of broadband last mile technology is-sues and options, the Computer Science and Telecommunications Board
issued a call for white papers in summer 2000. The papers (arranged
alphabetically by authorsÕ last names) are available for download at
CSTBÕs Web site, <www.cstb.org>. Please note that circulation of these
white papers does not constitute endorsement of them by the Committee
on Broadband Last Mile Technology, the Computer Science and Telecom-
munications Board, or the National Academies.ÒFactors Influencing Investment in Residential Broadband Equipment andServicesÑA Venture Capital PerspectiveÓ
George Abe, Palomar VenturesÒBroadband Satellite Networks for Last Mile TechnologyÓIan F. Akyildiz, Georgia Institute of TechnologyÒEthernet Broadband NetworkingÓAndreas Bechtolsheim and David Cheriton, Cisco SystemsÒBroadband Services to Rural Western MassachusettsÓEdward Ciesla, Flack & Kurtz Consulting EngineersBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.308APPENDIX CÒAccess to What? First Mile Issues for Rural BroadbandÓRichard Civille, Richard Civille and Associates; Michael Gurstein,
Michael Gurstein and Associates; Kenneth Pigg, University of Missouri at
ColumbiaÒLast Mile Connectivity Utilizing Fiber Satellite SolutionsÓTom Dennett, Harmonic Data SystemsÒHigh Bandwidth, Applications, and Economic Development: LetÕs Tie ItTogether!ÓSylvie Doucet, Planned Approach, Inc.ÒBroadband Access Over Inverse Multiplexed CopperÓEinar Edvardsen, Telenor R&DÒGetting Tele/Tech on Local Government RadarÓRichard Esposto, Western Integrated NetworksÒTechnology Developments for Quality Multimedia Delivery for Resi-dences: Coupling of the Broadband and Home Network TechnologiesÓAura Ganz, University of MassachusettsÒRegulatory Issues, Pricing, and Access to Public Utility Right-of-WayÓHenry Kilpatrick and Paul Baker, Georgia Institute of TechnologyÒThe Use of Satellite Technology for Last Mile Broadband AccessÓJose-Marie Montpetit and R. DeiningerÒDeployment of Multimedia Services to Residential CustomersÓJose A. Pozas, Telefonica I+DÒResidential Internet Ready Buildings (IRBs)ÓAmnon Ptashek, EDSL Networks, Inc.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.309

Nikil Jayant, Chair, is the John Pippin Chair in Wireless Systems in theElectrical and Computer Engineering Department at Georgia Institute of
Technology, founding director of the Georgia Tech Broadband Institute,
and executive director of GCATT, the Georgia Centers for Advanced Tele-
communications Technology. Earlier at Bell Laboratories, Dr. Jayant
created and managed the Signal Processing Research Department, the
Advanced Audio Technology Department, and the Multimedia Commu-
nications Research Laboratory. Contributions from these organizations
include the definition of unified structures for signal processing and com-
puting, the invention of new technology for high-density magnetic re-
cording, the creation of the 16-kbps CCITT (Consultative Committee on
International Telephony and Telegraphy) international standard for net-
work telephony, channel equalization and data coding technologies for
the IS54 North American Digital Cellular standard, coding and transmis-
sion methodologies for voiceband videotelephony and high-definition
television, the establishment of perceptual coding as a definitive criterion
for low-bit-rate coding of audiovisual signals, and the development of a
digital audio broadcast system as potential future technology for CD-
quality radio broadcasting in the United States. More recent contributions
include software for text-to-speech synthesis, automatic speech recogni-
tion, and natural language dialog; software for Internet communication of
speech, music, and video signals; and multimedia systems for messaging
and the human-computer interface. Dr. Jayant has published more than
100 papers, written a number of books, and has been granted more thanBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.310APPENDIX D20 patents. Businesses created by Dr. JayantÕs research and leadershipspan several segments in audiovisual and data communications. Dr.
Jayant has received several honors, including the Alfred Hay Gold Medal
(for the best student in communication engineering, Indian Institute of
Science, 1965), the IEEE Browder J. Thompson Memorial Prize Award (for
the best IEEE publication by an author under thirty years of age, 1974),
the Industry Paper Award from the Institution of Electrical and Telecom-
munication Engineers (India, 1990), the IEEE Donald G. Fink Prize Paper
Award (for the best tutorial paper in an IEEE publication, 1995), and the
1997 Lucent Patent Recognition Award. Dr. Jayant was inducted into the
New Jersey Inventors Hall of Fame for his contributions to the reduction
of noise in communication systems and is a fellow of the IEEE and a
member of the National Academy of Engineering. Dr. Jayant serves on
the advisory board of NTT-DoCoMo-USA and is a co-founder and chief
scientist of EGTechnology, which creates software solutions for last-mile
multimedia. Dr. Jayant received his PhD in Electrical Communication
Engineering from the Indian Institute of Science, Bangalore, India, in 1970.James A. Chiddix is president of the Interactive Personal Video Group at
AOL Time Warner. The IPV Group is headquartered in New York City
and is chartered with the development of a new broadband video service
to be delivered to the companyÕs millions of digital cable subscribers. The
service will provide an array of server-based products, ranging from ac-
cess to a large library of video on an on-demand basis, to personal video
recorder access and storage of live programming. It also will provide
highly targeted advertising delivery. For the last 15 years, Mr. Chiddix
has served as senior vice president and chief technical officer for Time
Warner Cable, headquartered in Stamford, Connecticut, and its predeces-
sor companies. Mr. Chiddix has been deeply involved in the introduction
of virtually every new cable technology since the mid-seventies. He
played a pioneering role in exploring the use of broadband optical fiber
technology in cable television systems, which led to the universally
adopted Hybrid Fiber Coax network architecture for cable systems. In
1994, he accepted, on behalf of Time Warner Cable, an Engineering Emmy
Award for this work. He led the upgrade of Time WarnerÕs Queens, New
York, system to 150 channels (1-GHz bandwidth), and was the architect of
Time WarnerÕs Full Service Network interactive television trial in Or-
lando, Florida. Mr. Chiddix has been in the cable television business for
30 years. He spent 15 years in a variety of operating positions with two
cable companies in Hawaii. He was also founder and president of CRC
Electronics, Inc., in Honolulu, which manufactured videotape playback,
automated delay, and random-access commercial insertion systems. CRC
was sold to Texscan in 1981. In 1986, he joined Time Warner CableÕsBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX D311corporate office. He also served for 8 years on the board of directors ofCV-21, a cable television company in Fukuoka, Japan. Mr. Chiddix is a
senior member and former director of the Society of Cable Television
Engineers, a senior member of the Institute of Electrical and Electronics
Engineers, and a member of the Cable Pioneers. Mr. Chiddix is a member
of the Computer Science and Telecommunications Board. Mr. Chiddix
currently serves on the committee studying broadband access and helped
produce the CSTB report The Unpredictable Certainty: Information Infra-structure Through 2000.John M. Cioffi, BSEE, 1978, Illinois; PhDEE, 1984, Stanford; Bell Labora-tories, 1978-1984; IBM Research, 1984-1986; EE prof., Stanford, 1986-
present. Cioffi founded Amati Com. Corp. in 1991 (purchased by TI in
1997) and was officer/director from 1991 to 1997. He currently is on the
boards or advisory boards of BigBand Networks, Coppercom, GoDigital,
Ikanos, Ionospan, Ishoni, IteX, Jubilant, Marvell, Kestrel, Charter Ven-
tures, and Portview Ventures and is a member of the U.S. National Re-
search CouncilÕs CSTB. CioffiÕs specific interests are in the area of high-performance digital transmission. He has received various awards:
member, National Academy of Engineering 2001; IEEE Kobayashi Medal
(2001), IEEE Millennium Medal (2000), IEEE fellow (1996), IEE JJ Tomson
Medal (2000), 1999 University of Illinois Oustanding Alumnus, 1991 IEEE
Comm. Mag. best paper; 1995 ANSI T1 Outstanding Achievement Award;
and NSF Presidential Investigator (1987-1992). Cioffi has published over
200 papers and holds over 40 patents, most of which are widely licensed,
including basic patents on DMT, VDSL, and vectored transmission.David D. Clark is a senior research scientist at MIT
Õs Laboratory forComputer Science, where he is currently in charge of the Advanced Net-
work Architecture group. Dr. ClarkÕs research interests include networks,network protocols, operating systems, distributed systems, and computer
and communications security. After receiving his Ph.D., he worked on the
early stages of the ARPANET and on the development of token ring local
area network technology. Since the mid-1970s, Dr. Clark has been in-
volved in the development of the Internet. In the period 1981 to 1989, he
acted as chief protocol architect for this development and chaired the
Internet Activities Board. His current research area is protocols and archi-
tectures for very large and very high speed networks. Specific activities
include extensions to the Internet to support real-time traffic, explicit allo-
cation of service, pricing and new network technologies. In the security
area, Dr. Clark participated in the early development of the multilevel
secure Multics operating system. He developed an information security
model that stresses integrity of data rather than disclosure control.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.312APPENDIX DDr. Clark is a fellow of the ACM and the IEEE and a member of theNational Academy of Engineering. He received the ACM SIGCOMM
award, the IEEE award in international communications, and the IEEE
Hamming Award for his work on the Internet. He is a consultant to a
number of companies and serves on a number of technical advisory
boards. Dr. Clark is currently the chair of the Computer Science and Tele-
communications Board. He chaired the committee that produced the CSTB

report Computers at Risk: Safe Computing in the Information Age. He alsoserved on the committees that produced the CSTB reports Toward a Na-tional Research Network, Realizing the Information Future: The Internet andBeyond, and The Unpredictable Certainty: Information Infrastructure Through2000. Dr. Clark graduated from Swarthmore College in 1966 and receivedhis Ph.D. from the Massachusetts Institute of Technology (MIT) in 1973.Paul Green recently retired as director of Optical Networking Technol-
ogy at Tellabs in Hawthorne, New York. He joined Tellabs in January
1997 after many years at IBM Research, and before that, at MIT Lincoln
Laboratory. At Lincoln he developed the first operational spread spec-
trum system (1953), coinvented the first channel-adaptive receiver (Rake,
1958), invented planetary range-doppler mapping (1960), and worked on
large digital seismic arrays for computerized discrimination between
earthquakes and nuclear explosions. At IBM, his team pioneered peer
networking, which later became standard in IBMÕs System Network Ar-chitecture. He initiated the WDM optical networking program there,
which is credited with the first operational all-optical network (Rainbow-
1 of 1991) and the first commercial WDM product, the IBM Muxmaster
(1995). At Tellabs, his interests center on all-optical crossconnects, the key
building block of all-optical networking. Dr. Green received the IEEE
Simon Ramo Medal in 1991, the Association of Computing MachineryÕsAnnual Communication Award in 1994, and a number of IBM patent
awards. He is a member of the National Academy of Engineering. He has
been president of both the IEEE Information Theory Society and the IEEE
Communication Society.Kevin Kahn is an Intel Fellow, the corporation
Õs highest technical posi-tion, and currently the director of the Wireless Technology Lab, a corpo-
rate advanced development and research lab in IntelÕs Corporate Tech-nology Group. Additionally, he helps drive communications strategies
and policy for the corporation and coordinates a variety of cross-corpo-
rate networking research. Some of his primary current focuses are broad-
band access to the home, home networking, wireless LANs, and Internet
issues bearing on these topics. Throughout his 25-year career with Intel,
he has worked in system software development, operating systems, pro-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX D313cessor architecture, and various strategic planning roles on programs in-volving most of the processors Intel has developed during the period. He
has held both management and senior individual contributor roles. He
was the co-chair of the Universal ADSL Working Group, an industry
alliance dedicated to accelerating the deployment of consumer ADSL ser-
vices for higher speed Internet access, and served as a member of the
Board of Directors of the DSL Forum. He serves on a variety of NSF and
NAS committees and panels, and is a member of the FCC Technical Advi-
sory Committee. He holds a B.Sc. in mathematics from Manhattan Col-
lege, and M.S. and Ph.D. degrees in computer science from Purdue Uni-
versity.Richard Lowenberg is a tele-community planner, environmental de-
signer, media artist, and cultural activist. He has been executive director
of the Davis Community Network and Yolo Area Regional Network in
California since 1996. In this position he has been a consultant to the
California Smart Communities Project and was principal coordinator of
ÒWaterWorks,Ó an online civic decision-support project, funded by the
Corporation for Public Broadcasting (CivNet program), Army Corps of
Engineers, USGS National Spatial Data Infrastructure Program, and ESRI,
Inc. He currently serves on the Board of the Association for Community
Networking, on the Steering Committee of the Global Community Net-
working Congress, and on Computer Professionals for Social Respon-
sibilityÕs DIAC program committee. Mr. Lowenberg was founding direc-tor of the Telluride Institute and its InfoZone Program, in Colorado, from
1985 to 1996. He served on the governing board of the Colorado Ad-
vanced Technology InstituteÕs Rural Telecommunications Project from1994 to 1997; Web authored the 1995 U.S. Economic Development Admin-
istration funded ÒRural Telecommunications Investment Guide,Ó and was
a principal participant on the 1996 NTIA-TIIAP funded ÒMaps for PeopleÓproject. He has been and continues to be a presenter, writer, and consult-
ant on ÒCommunity Networking,Ó ÒTele-Community Development,ÓÒNetworked Economics,Ó and 
ÒInformation EcologyÓ in the United States,
Europe, Latin America, and Japan; and his telecommunications and com-
munity development projects have received federal, state and local gov-
ernment grants; university and corporate support; international media
coverage and recognition. Richard LowenbergÕs media, performance, andinstallation art works have pioneered in the integration of art, science,
technology and ecology, with a primary focus on the social implications
of the ÒInformation Revolutions.Ó He has received numerous grants and
awards, including from the National Endowment for the Arts, and has
presented exhibitions and performances internationally, including at the
Whitney Museum, San Francisco Museum of Modern Arts, KunstmuseumBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.314APPENDIX DDusseldorf, Venice Biennale, and MIT List Center for Visual Arts. Mostrecently he has been ÒArtist in Bioregional Residence,Ó University of Cali-
fornia at Davis.Clifford Lynch has been the director of the Coalition for Networked In-
formation (CNI) since July 1997. CNI, jointly sponsored by the Associa-
tion of Research Libraries and Educause, includes about 200-member or-
ganizations concerned with the use of information technology and
networked information to enhance scholarship and intellectual produc-
tivity. Prior to joining CNI, Dr. Lynch spent 18 years at the University of
California Office of the President, the last 10 as director of Library Auto-
mation. Dr. Lynch, who holds a Ph.D. in computer science from the Uni-
versity of California, Berkeley, is an adjunct professor at BerkeleyÕs Schoolof Information Management and Systems. He is a past president of the
American Society for Information Science and a fellow of the American
Association for the Advancement of Science and the National Information
Standards Organization. Dr. Lynch currently serves on the Internet 2
Applications Council and the National Digital Preservation Strategy Ad-
visory Board of the Library of Congress and was a member of the Na-
tional Research Council committee that recently published The DigitalDilemma: Intellectual Property in the Information Infrastructure.Richard Metzger is partner in the law firm Lawler, Metzger & Milkman
LLC in Washington, D.C. Mr. Metzger brings direct insight into federal
telecommunications regulation and policy making, having served as
deputy chief and subsequently chief, of the Common Carrier Bureau of
the Federal Communications Commission from 1994 to 1998. In these
positions, Mr. Metzger was actively involved in the FCCÕs implementa-tion of the Telecommunications Act of 1996. In particular, during his
tenure in the Bureau, he supervised the preparation of recommendations
to the Commission on a wide range of critical issues, including rules
governing interconnection, access charge reform, and universal service.
Prior to joining the Commission, Mr. Metzger was a member of the law
firm of Rogers and Wells, resident in the Washington, D.C. office. His
areas of emphasis in private practice included telecommunications, anti-
trust, and public utility regulation. Mr. Metzger is a graduate of Williams
College, Phi Beta Kappa. He received a J.D. degree from Georgetown
University Law Center.Elizabeth Mynatt is an assistant professor in the College of Computing at
the Georgia Institute of Technology. There she directs the research pro-
gram in ÒEveryday ComputingÓÑexamining the implications of havingcomputation continuously present in many aspects of everyday life. InBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX D315home environments, Dr. Mynatt aims to enable older adults to continueliving independently, through the use of future home technologies, as
opposed to moving to institutional care settings. Dr. Mynatt is an interna-
tionally recognized expert in the areas of ubiquitous computing and
assistive technologies. Prior to her current position, she worked for 3
years at Xerox PARCÑthe birthplace of ubiquitous computingÑalong-side its inventor, Mark Weiser. Her research explored how to augment
everyday places and objects with computational capabilities. She has

chaired multiple conferences on computer interface technologies and au-
ditory displays, published numerous articles, and is an active leader in
her field. Dr. Mynatt is a Sloan Research Fellow. Her research is sup-
ported by multiple grants from the National Science Foundation includ-
ing a 5-year NSF CAREER award. Dr. Mynatt is the Associate Director of
the Georgia Tech Graphics, Visualization and Usability (GVU) Center,
and is responsible for research and educational objectives in human-com-
puter interaction, including a highly regarded HCI MasterÕs Degree Pro-gram that bridges computing, psychology, design and communication.
Dr. Mynatt received her Ph.D. in computer science at Georgia Tech under
the guidance of Dr. James Foley. Her dissertation work pioneered creat-
ing nonspeech auditory interfaces from graphical interfaces to enable
blind computer users to work with modern computer applications.Eli M. Noam has been a professor of economics and finance at Columbia
Business School since 1976. In 1990, after having served for 3 years as
Commissioner with the New York State Public Service Commission, he
returned to Columbia. He is the director of the Columbia Institute for
Tele-Information. CITI is an independent university-based research cen-
ter focusing on strategy, management, and policy issues in telecommuni-
cations, computing, and electronic mass media. In addition to leading
CITIÕs research activities, Dr. Noam initiated the MBA concentration inthe Management of Entertainment, Communications, and Media at the
Business School and the Virtual Institute of Information, an independent,
Web-based research facility. He has also taught at Columbia Law School
and Princeton UniversityÕs Economics Department and Woodrow WilsonSchool. Noam has published over 19 books and 400 articles in economic
journals, law reviews, and interdisciplinary journals. His books include
the authored, edited, or co-authored volumes Telecommunications in Eu-rope; Television in Europe; Telecommunications Regulation: Today and To-morrow; Video Media Competition; Services in Transition: The Impact of In-formation Technology in the Service Industry; The Law of InternationalTelecommunications in the United States; The International Market in Film andTelevision Programs; Telecommunications in the Pacific Basin; Private Net-works, Public Objectives; Global and Local Networks; Asymmetric Deregula-Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.316APPENDIX Dtion: The Dynamics of Telecommunications Policies in Europe and the UnitedStates; Telecommunications in Western Asia and the Middle East; Telecommu-nications in Latin America; Telecommunications in Africa; The New InvestmentTheory of Real Options and Its Implications for Telecommunications Economics;and Interconnecting the Network of Networks (Spring 2001). His forthcomingbooks include Media Concentration in the United States and 
The Dark Sides ofthe Internet. He has served on the editorial boards of Columbia UniversityPress as well as of several academic journals. He was a member of the
advisory boards for the federal governmentÕs FTS-2000 telecommunica-tions network, the IRSÕs computer system reorganization, and the Na-tional Computer Systems Laboratory. He is a member of the Council on
Foreign Relations. He received an AB (Phi Beta Kappa), M.A., Ph.D. (Eco-nomics), and J.D. from Harvard University.Dipankar Raychaudhuri is currently a professor, Electrical and Com-
puter Engineering Department, and director, WINLAB (Wireless Infor-
mation Network Lab), at Rutgers University. He has previously held pro-
gressively responsible corporate R&D positions in the telecom/
networking area, including chief scientist, Iospan Wireless (2000 to 2001);
assistant general manager and department head, Systems Architecture,
NEC USA C&C Research Laboratories (1993 to 1999); and head, Broad-
band Communications Research, Sarnoff Corp. (1990 to 1992). During the
period from 1995 to 1999, his research group at NEC USA developed one
of the worldÕs first pre-commercial broadband wireless local area net-works (ÒWATMnetÓ) for use in the 5-Ghz band. His research and newtechnology development experience also includes VSAT networks (1984
to 1987), digital TV/HDTV (1988 to 1991), ATM/IP switching and QoS
(1993 to 1997), multimedia network processor (1993 to 1995), and MIMO/
OFDM system (2000 to 2001). Dr. Raychaudhuri obtained his B.Tech
(Hons) from the Indian Institute of Technology, Kharagpur, in 1976 and
the M.S. and Ph.D degrees from SUNY, Stony Brook, in 1978 and 1979. He
is a fellow of the IEEE.Bob Rowe has been a commissioner of the Montana Public Service Com-
mission since 1993. His educational credentials include a B.A. from Lewis
and Clark College; a J.D. from the University of Oregon; and additional
graduate work in public administration and public policy at Harvard
UniversityÕs Kennedy School Executive Program. Mr. Rowe is a past presi-dent of the National Association of Regulatory Utility Commissioners
(NARUC) and a past chair of the NARUC Telecommunications Commit-
tee. He is a member of the National Regulatory Research InstituteÕs boardof directors, the Michigan State University Institute of Public Utilities
Advisory Committee, and the New Mexico State University Center forBroadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX D317Public Utilities Advisory Council. He is also a member of the MontanaFood Bank NetworkÕs board of directors and a member of the State Bar ofMontana Professionalism Committee. He is past chair of the Regional
Oversight Committee for US West. Before election to the Montana Public
Service Commission, he was in public interest practice; was a VISTA
volunteer; and was a public interest lawyer, specializing in utility law and
policy; he also worked for the Montana Legal Service Association, a pri-
vate nonprofit organization, and he represented a variety of community
organizations in rate cases and other utility-related proceedings. He re-
searched and wrote on customer-oriented utility policy for the National
Consumer Center, the National Center for Appropriate Technology, and
other organizations.Steven S. Wildman is director of the James H. and Mary B. Quello Center
for Telecommunication Management and Law and the James H. Quello
Chair of Telecommunications Studies at Michigan State University. The
center, and through it his chair, is endowed, supporting broad-based and
affiliation-dependent research in support of policy making. Previously,
Dr. Wildman was an associate professor at Northwestern University and
director of its Program in Telecommunications Science, Management, and
Policy. His research interests include determinants of market structure
and economic aspects of information and communication. He has served
as a consultant on matters relating to broadcasting, cable television, and
voice and nonvoice telecommunications. His publications include Inter-national Trade in Films and Television Programs (1988), 
Electronic ServicesNetworks: A Business and Public Policy Challenge (1991), 
Video Economics(1992), and Making Universal Service Policy: Enhancing the Process ThroughMultidisciplinary Evaluation (1999). Professor Wildman received his Ph.D.
from Stanford University.Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.318
ADSLasymmetric digital subscriber line
ANSIAmerican National Standards Institute

ASICapplication specific integrated circuit

ATMasynchronous transfer mode

BLECbuilding-focused local exchange carriers

CATVoriginally community antenna television; now synonymous
with cable TVCDMAcode-division multiple access

CDPDcellular digital packet data

CLECcompetitive local exchange carrier

COcentral office

CPEcustomer premises equipment

DARPADefense Advanced Research Projects Agency

DBSdirect broadcast satellite

DHCPdynamic host configuration protocol

DLCdigital loop carrier

DLECdata local exchange carrier

DMTdiscrete multitone transmission

DSLdigital subscriber line

DSLAMDSL access multiplexer

DSPdigital signal processor

ETSIEuropean Telecommunications Standards Institute

FCCFederal Communications Commission

FEXTfar end cross talk

FTTCfiber to the curb
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.APPENDIX E319FTTHfiber to the home
GEOSgeo-synchronous orbit satellites

HDSLhigh-speed digital subscriber line

HDTVhigh definition television

HFChybrid fiber coax

HPNAHome Phone Networking Alliance

IEEEInstitute of Electrical and Electronics Engineers

IETFInternet Engineering Task Force

ILECincumbent local exchange carrier

IPInternet protocol

ISDNintegrated services digital network

ISPInternet service provider

ITUInternational Telecommunication Union

LANlocal area network

LEClocal exchange carrier

LEOSlow earth orbit satellites

LMDSlocal multipoint distribution services

LOSline of sight

MACmedium access control

MDUsmulti-dwelling units

MIMOmultiple in, multiple out

MMDSmultipoint multichannel distribution service

MSOmultiple system operator

NEXTnear end cross talk

NIInational information infrastructure

NSFNational Science Foundation

NSPnative signal processor

NTIANational Telecommunications and Information Administration

OFDMorthogonal frequency division multiplexing

PCSpersonal communications service

PEGpublic, educational, and government

PONpassive optical network

POTSplain old telephone service

PPPpoint-to-point protocol

PSDpower spectral density

QAMquadrature amplitude modulation

QOSquality of service

RADSLrate adaptive digital subscriber line

RFradio frequency

RLPradio link protocol

SDMISecure Digital Music Initiative

SDSLsymmetric digital subscriber line

SDTVstandard definition television
Broadband: Bringing Home the BitsCopyright National Academy of Sciences. All rights reserved.320APPENDIX ESONETsynchronous optical network
TDMtime division multiplexing

TDMAtime division multiple access

UDPuser datagram protocol

USBuniversal serial bus

VADSLvery-high data rate asymmetric DSL

VDSLvery high speed digital subscriber line

VLSIvery large scale integrated circuit

VODvideo on demand

VoDSLvoice over DSL

VoIPvoice over Internet Protocol

VPNvirtual private network

VTIPvideo telephony over Internet Protocol (IP)

W3CWorld Wide Web Consortium

WANwide area network

WDMwavelength-division multiplexing

WLANwireless local area network

WLLwireless local loop
