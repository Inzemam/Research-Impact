DETAILSDistribution, posting, or copying of this PDF is strictly prohibited without written permission of the National Academies Press.  (Request Permission) Unless otherwise indicated, all materials in this PDF are copyrighted by the National Academy of Sciences.Copyright © National Academy of Sciences. All rights reserved.THE NATIONAL ACADEMIES PRESSVisit the National Academies Press at NAP.edu and login or register to get:Œ  
Œ  10% off the price of print titles
Œ  Special offers and discountsGET THIS BOOKFIND RELATED TITLESThis PDF is available at SHARECONTRIBUTORS
http://nap.edu/11106Computer Science: Reflections on the Field, Reflections fromthe Field216 pages | 6 x 9 | PAPERBACKISBN 978-0-309-09301-9 | DOI 10.17226/11106Committee on the Fundamentals of Computer Science: Challenges and Opportunities;Computer Science and Telecommunications Board; Division on Engineering andPhysical Sciences; National Research CouncilComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.




˘
˝˛˛
$
'''''''''''''''Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.THE NATIONAL ACADEMIES PRESS  500 Fifth Street, N.W.  Washington, DC 20001
NOTICE: The project that is the subject of this report was approved by theGoverning Board of the National Research Council, whose members are drawnfrom the councils of the National Academy of Sciences, the National Academy ofEngineering, and the Institute of Medicine. The members of the committee
responsible for the report were chosen for their special competences and withregard for appropriate balance.Support for this project was provided by the National Science Foundation undergrant No. CCR-9981754. Any opinions, findings, conclusions, or recommenda-tions expressed in this publication are those of the authors and do not necessarily
reflect the views of the sponsor.International Standard Book Number 0-309-09301-5 (Book)International Standard Book Number 0-309-54529-3 (PDF)Copies of this report are available from the National Academies Press, 500 FifthStreet, N.W., Lockbox 285, Washington, DC 20055; (800) 624-6242 or (202) 334-3313in the Washington metropolitan area; Internet, http://www.nap.edu.Copyright 2004 by the National Academy of Sciences. All rights reserved.Printed in the United States of AmericaComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.The National Academy of Sciences is a private, nonprofit, self-perpetuating soci-
ety of distinguished scholars engaged in scientific and engineering research, dedi-cated to the furtherance of science and technology and to their use for the general
welfare. Upon the authority of the charter granted to it by the Congress in 1863,the Academy has a mandate that requires it to advise the federal government onscientific and technical matters. Dr. Bruce M. Alberts is president of the National
Academy of Sciences.The National Academy of Engineering was established in 1964, under the charter
of the National Academy of Sciences, as a parallel organization of outstandingengineers. It is autonomous in its administration and in the selection of its mem-bers, sharing with the National Academy of Sciences the responsibility for advis-
ing the federal government. The National Academy of Engineering also sponsorsengineering programs aimed at meeting national needs, encourages educationand research, and recognizes the superior achievements of engineers. Dr. Wm. A.
Wulf is president of the National Academy of Engineering.The Institute of Medicine was established in 1970 by the National Academy of
Sciences to secure the services of eminent members of appropriate professions inthe examination of policy matters pertaining to the health of the public. TheInstitute acts under the responsibility given to the National Academy of Sciences
by its congressional charter to be an adviser to the federal government and, uponits own initiative, to identify issues of medical care, research, and education.Dr.Harvey V. Fineberg is president of the Institute of Medicine.
The National Research Council was organized by the National Academy of Sci-
ences in 1916 to associate the broad community of science and technology with
the Academys purposes of furthering knowledge and advising the federal govern-ment. Functioning in accordance with general policies determined by the Acad-emy, the Council has become the principal operating agency of both the National
Academy of Sciences and the National Academy of Engineering in providingservices to the government, the public, and the scientific and engineering commu-nities. The Council is administered jointly by both Academies and the Institute of
Medicine. Dr. Bruce M. Alberts and Dr. Wm. A. Wulf are chair and vice chair,respectively, of the National Research Council.www.national-academies.orgComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.vCOMMITTEE ON THE FUNDAMENTALS OF COMPUTER SCIENCE:CHALLENGES AND OPPORTUNITIESMARY SHAW, Carnegie Mellon University, ChairALFRED V. AHO, Columbia University
CHARLES H. BENNETT, IBM Research
ALAN BIERMANN, Duke University
EDWARD W. FELTEN, Princeton University
JAMES D. FOLEY, Georgia Institute of Technology
MARK D. HILL, University of Wisconsin at Madison
JON M. KLEINBERG, Cornell University
DAPHNE KOLLER, Stanford University
JAMES R. LARUS, Microsoft Research
TOM M. MITCHELL, Carnegie Mellon University
CHRISTOS H. PAPADIMITRIOU, University of California, Berkeley
LARRY L. PETERSON, Princeton University
MADHU SUDAN, Massachusetts Institute of Technology
KEVIN J. SULLIVAN, University of Virginia
JEFFREY D. ULLMAN, Stanford University and Gradience CorporationStaffJON EISENBERG, Senior Program Officer and Study DirectorLYNETTE I. MILLETT, Program Officer
D.C. DRAKE, Senior Project Assistant (through November 2003)Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.viCOMPUTER SCIENCE AND TELECOMMUNICATIONS BOARDDAVID LIDDLE, U.S. Venture Partners, Co-ChairJEANNETTE M. WING, Carnegie Mellon University, Co-ChairERIC BENHAMOU, 3Com Corporation
DAVID D. CLARK, Massachusetts Institute of Technology, CSTBMember EmeritusWILLIAM DALLY, Stanford University
MARK E. DEAN, IBM Systems Group

DEBORAH L. ESTRIN, University of California, Los Angeles
JOAN FEIGENBAUM, Yale University
HECTOR GARCIA-MOLINA, Stanford University
KEVIN KAHN, Intel Corporation
JAMES KAJIYA, Microsoft Corporation
MICHAEL KATZ, University of California, Berkeley

RANDY H. KATZ, University of California, Berkeley

WENDY A. KELLOGG, IBM T.J. Watson Research Center

SARA KIESLER, Carnegie Mellon University
BUTLER W. LAMPSON, Microsoft Corporation, CSTB Member Emeritus

TERESA H. MENG, Stanford University
TOM M. MITCHELL, Carnegie Mellon University
DANIEL PIKE, GCI Cable and Entertainment

ERIC SCHMIDT, Google Inc.
FRED B. SCHNEIDER, Cornell University
WILLIAM STEAD, Vanderbilt University

ANDREW J. VITERBI, Viterbi Group, LLCCHARLES BROWNSTEIN, DirectorKRISTEN BATCH, Research Associate
JENNIFER M. BISHOP, Program Associate
JANET BRISCOE, Administrative Officer
JON EISENBERG, Senior Program Officer
RENEE HAWKINS, Financial Associate
MARGARET MARSH HUYNH, Senior Project Assistant
HERBERT S. LIN, Senior Scientist
LYNETTE I. MILLETT, Program Officer
JANICE SABUDA, Senior Project Assistant
BRANDYE WILLIAMS, Staff AssistantFor more information on CSTB, see its Web site at <http://www.cstb.org>,write to CSTB, National Research Council, 500 Fifth Street, N.W., Washing-
ton, DC 
20001, call at (202) 334-2605, or e-mail the CSTB at cstb@nas.edu.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Preface
viiThe blossoming of computer science (CS) research is evident in theinformation technology that has migrated from a specialized tool
confined to the laboratory or corporate back office to a ubiquitouspresence in machines and devices that now figure in the lives of virtually
every individual. This widespread diffusion of information technology
can obscure the nature of computer science research underlying the ITfrom the perspective of many outside the field, computer science is seen
not as a basic area of systematic inquiry but as a tool to support other
endeavors.Mindful of these issues, the National Science Foundations Computerand Information Science and Engineering Directorate asked the Com-puter Science and Telecommunications Board of the National
Academies to conduct a study that would improve understanding of CS
research among the scientific community at large, policymakers, and the
general public. By describing in accessible form the fields intellectualcharacter and by conveying a sense of its vibrancy through a set of
examples, the committee also aims to prepare readers for what the future
might hold and inspire CS researchers to help create it.This volume, the product of that study, is divided into two parts thatcontain nine chapters.The volumes prelude, Emily Shops at VirtualEmporia.com, takes a
now-familiar use of computingshopping onlineand illustrates howCS research has made this seemingly simple activity possible.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.viiiPREFACEPart OneChapter 1, The Essential Character of Computer Scienceoffers the committees concise characterization of CS research. Like CSresearchers more generally, the committee members evince a wide range
of perspectives that mirror the broad reach of computation into the very
fabric of our intellectual and physical lives. Recognizing the richness and
diversity of the field, the committee expressly decided not to provide
either a comprehensive list of research topics or a taxonomy of research
areas, nor to develop criteria for what research is inside and outside of CS.
Instead, the committees approach is to describe some key ideas that lie atthe core of CS but not to define boundaries.Part TwoChapters 2 through 9comprises two dozen essays writ-ten by committee members, participants in a June 6-7, 2001, symposium
organized by the committee, and other invited authors. The essays
describe several aspects of CS research and some of the results from the
perspectives of their authors. By providing this diverse set of views on CS
research, the committee aims to express some of the spark that motivates
and excites CS researchers. The essays have a deliberately historical focus,
for three reasons: (1) as described above, the committee decided not to
present a research agenda, either explicit or implicit; (2) other publica-
tions look at current, hot topics in CS and these tend, in any case, to
become dated quickly; and (3) results that have proven durable best illus-
trate the strengths of CS.The prelude and Part One are intended to be accessible to all readers(as are many of the essays). But because this report is also intended to
reach scientists and engineers from a variety of disciplines, a few of the
essays do presume some familiarity with some technical concepts.The committee would like to thank all of the participants in the June2001 symposium; presentations and informal discussions at that event pro-
vided important input to the committee. Julie Sussman, PPA, provided anumber of helpful suggestions concerning the manuscript. The reviewers
listed below provided many valuable suggestions for improvement.Mary Shaw, ChairCommittee on the Fundamentals of Computer Science:
Challenges and OpportunitiesComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Acknowledgment of ReviewersixThis report has been reviewed in draft form by individuals chosenfor their diverse perspectives and technical expertise, in accordance
with procedures approved by the National Research CouncilÕs ReportReview Committee. The purpose of this independent review is to provide
candid and critical comments that will assist the institution in making its
published report as sound as possible and to ensure that the report meets
institutional standards for objectivity, evidence, and responsiveness to
the study charge. The review comments and draft manuscript remain
confidential to protect the integrity of the deliberative process. We wish
to thank the following individuals for their review of this report:David D. Clark, Massachusetts Institute of Technology
Robert L. Constable, Cornell University
Ronald Fedkiw, Stanford University
Joan Feigenbaum, Yale University
Juris Hartmanis, Cornell University
James Jay Horning, Intertrust
Anna R. Karlin, University of Washington
Richard Karp, University of California, Berkeley
Wendy A. Kellogg, IBM Research
Monica S. Lam, Stanford University
Butler W. Lampson, Microsoft Research
Fred B. Schneider, Cornell University
Lynn Andrea Stein, Olin CollegeComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.xACKNOWLEDGMENT OF REVIEWERSGerald Jay Sussman, Massachusetts Institute of TechnologyThomas N. Theis, IBM T.J. Watson Research Center
Jeanette M. Wing, Carnegie Mellon University
Margaret H. Wright, New York UniversityAlthough the reviewers listed above provided many constructivecomments and suggestions, they were not asked to endorse the conclu-
sions or recommendations nor did they see the final draft of the report
before its release. The review of this report was overseen by Lawrence
Snyder, University of Washington. Appointed by the National Research
Council, he was responsible for making certain that an independent
examination of this report was carried out in accordance with institutional
procedures and that all review comments were carefully considered.
Responsibility for the final content of this report rests entirely with the
authoring committee and the institution.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PRELUDEEMILY SHOPS AT VIRTUALEMPORIA.COM1
PART ONETHE ESSENTIAL CHARACTER OF COMPUTER SCIENCE9
1THE ESSENTIAL CHARACTER OF COMPUTER SCIENCE11
What Is Computer Science?, 12
Salient Characteristics of Computer Science Research, 15Computer Science Research Involves Symbols and TheirManipulation, 15Computer Science Research Involves the Creation andManipulation of Abstraction, 17Computer Science Research Creates and StudiesAlgorithms, 19Computer Science Research Creates Artificial Constructs,Notably Unlimited by Physical Laws, 19Computer Science Research Exploits and AddressesExponential Growth, 20Computer Science Research Seeks the Fundamental Limits onWhat Can Be Computed, 21Computer Science Research Often Focuses on the Complex,Analytic, Rational Action That Is Associated with
Human Intelligence, 23xiContentsComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.xiiCONTENTSPART TWOSELECTED PERSPECTIVES ON COMPUTER SCIENCE25
2EXPONENTIAL GROWTH, COMPUTABILITY, AND
COMPLEXITY27

Harnessing Moores Law, 28Mark D. Hill, University of Wisconsin, MadisonComputability and Complexity, 37Jon Kleinberg, Cornell University, and
Christos Papadimitriou, University of California, BerkeleyQuantum Information Processing, 51Charles H. Bennett, IBM Research3SIMULATION57
The Real Scientific Hero of 1953, 58Steven Strogatz, Cornell UniversityMaking a Computational Splash, 61Ronald Fedkiw, Stanford University4ABSTRACTION, REPRESENTATION, AND NOTATIONS65
Abstraction: Imposing Order on Complexity in SoftwareDesign, 66Mary Shaw, Carnegie Mellon UniversityProgramming Languages and Computer Science, 74Alfred V. Aho, Columbia University, and
James Larus, Microsoft Research5DATA, REPRESENTATION, AND INFORMATION79
Database Systems: A Textbook Case of Research Paying Off, 80Jim Gray, Microsoft ResearchComputer Science Is to Information as Chemistry Is toMatter, 88Michael Lesk, Rutgers UniversityHistory and the Fundamentals of Computer Science, 96Edward L. Ayers, University of Virginia6ACHIEVING INTELLIGENCE101
The Experiment-Analyze-Generalize Loop in Computer ScienceResearch: A Case Study, 103Tom Mitchell, Carnegie Mellon UniversityIm Sorry Dave, Im Afraid I Cant Do That: Linguistics,Statistics, and Natural-Language Processing Circa 2001, 111Lillian Lee, Cornell UniversityComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.CONTENTSxiiiComputer Game Playing: Beating Humanity at ItsOwn Game, 119Daphne Koller, Stanford University, and
Alan Biermann, Duke University7BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE127
The Internet: An Experiment That Escaped from the Lab, 129Larry Peterson, Princeton University, and
David Clark, Massachusetts Institute of TechnologyMany-to-Many Communication: A New Medium, 134Amy Bruckman, Georgia Institute of TechnologyCryptography, 144Madhu Sudan, Massachusetts Institute of TechnologyStrategies for Software Engineering Research, 151Mary Shaw, Carnegie Mellon University8RESEARCH BEHIND EVERYDAY COMPUTATION159
How You Got Microsoft Word, 161Jeffrey Ullman, Stanford University and Gradience CorporationVisiCalc, Spreadsheets, and Programming for the Masses,Or How a Killer App Was Born, 167
James D. Foley, Georgia Institute of TechnologyInternet Searching, 174Peter Norvig, Google Inc.9PERSONAL STATEMENTS OF PASSION ABOUT COMPUTER
SCIENCE RESEARCH179

The Legacy of Computer Science, 180Gerald Jay Sussman, Massachusetts Institute of TechnologyFairy Tales, 184Allen Newell, Carnegie Mellon UniversityRevisiting What Is Computer Science, 189
Allen Newell, Carnegie Mellon UniversityAPPENDIXAgenda of July 25-26, 2001, Symposium193
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.1Prelude
Emily Shops at VirtualEmporia.com
Just a decade ago, the Internet was the domain of specialists and technologyaficionados, requiring knowledge of file systems, format compatibilities, and oper-ating system commands. Even the more user-friendly systems such as e-mail andnet news principally served relatively small communities of technically savvypeople.Until recently, the Internet, the World Wide Web, and e-commerce all wouldhave seemed akin to magic to all but the most tech-savvy. Yet despite todayÕs wide-spread acceptance of and familiarity with computer capabilities, the details of howcommonly used computer systems work remains a mystery for non-specialists. It isnot magic, of course, that is at work. Nor did todayÕs system arise as a result of adirect evolution of previous technology.Like many radical innovations, e-commerce, for one, was not planned or evenanticipated by those involved in either research or commerce. Rather, it evolvedfrom a series of technical results that were pursued with other motivationsÑsuchas sharing computer resources or scientific information among researchers.Examining the scientific roots of e-commerce shows how research pursued for itsown sake can enable important, often unanticipated capabilities.We take as our example a hypothetical online retailer, VirtualEmporia.com, and
reveal some of the magicÑthat is, the research foundationsÑbehind the now-simple operation of ordering a book online. Thus it is possible to identify some ofthe computer science (CS) research that enables retailing online and to providepointers to discussions of that research later in this volume. Also noted are someof the ways that a virtual store can provide an intellectual boost over a conventionalstore through its capabilities for searching and indexing, exchanging informationamong customers, and providing an enormous catalog of items.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.2COMPUTER SCIENCE: REFLECTIONSEmily is planning to take atrip next week and sheÕs looking
for something to read on the
airplane. In the past, she would
have gone to a bookstore during
business hours and browsed
through the shelves to select a
book from the limited stock at
hand. Today, Emily has the
option of sitting down at a
computer, at any time of the day
or night, to select and buy a book
or many other types of products.EmilyÕs ComputerEmilyÕs family, like morethan half of the households in the
United States, owns a personal
computer and related software.
Her garden-variety home PC,
available for roughly $600, is able
to run much more sophisticated
programsÑand run them much
fasterÑthan the first computer
her employer bought only 20
years ago. Indeed, the very idea
of a home computer, outside the
professional or aficionado market,
is only about 20 years old.If Emily were to pause andconsider the functionality
available to her, she might marvel
that no other machine is as
flexible, general-purpose, or
malleable as a computer. The idea
that machines can be adapted to
completely new situations for
which they were not originally
designed usually borders on the
farcical. EmilyÕs pencil will not
also serve as a stapler if the need
arises. Computers, though, areAlthough shopping online is now a routineexperience for millions, its familiarity and
simplicity mask the sophisticated eventsbehind the scenes. Indeed, what Emilydoes in the next 5 minutes would have
been impossible without many discoveriesand inventions from computer science.The cost of computing power hasdecreased dramatically. A typical 2003home PC, which had a 2.66 GHz systemclock, 256 Mb of RAM, and a 40 Gb hard
drive, outperformed the IBM/XT PC,released in 1983, which had a 4.77 MHzsystem clock, 640 Kb of RAM, and a 10
Mb hard drive, by a factor of roughly500Ñat one-tenth the cost. Hill (inChapter2) describes the phenomenon of

exponential growth in computing power,and he shows how computer scienceresearch strives to design computers that
sustain this remarkable rate ofimprovement in the cost/performance ratioof computers.EmilyÕs computer and software areremarkable not only for their low cost but
also for their high complexity. Thehardware comprises billions of transistors,and the software installed on the computer
is defined by tens of millions of lines ofcode; hundreds of millions of lines ofadditional software is available. The
capability of the computer is built up fromthese tiny elements.Shaw (in Chapter 4) describes howabstraction hides the complex and often-messy details of a piece of hardware or
software in favor of a simpler, morefocused view of the aspects of immediateComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PRELUDE: EMILY SHOPS AT VIRTUALEMPORIA.COM3universal symbol manipulatorscovering the entire gamut of
information processing. The right
software transforms a computer
from a Web browser to a home
accountant to a photo editor to a
jukebox to a mailbox to a game,
virtually at your whim.Although EmilyÕs computerarrived at her home with a large
amount of software pre-installed
(including the Web browser that
Emily uses to shop at
VirtualEmporia.com), it can also
run tens of thousands of
additional programs. Of course,
Emily will actually use only a
small fraction of those programs,
but she has enormous variety to
choose from. These programs
potentially enable Emily to use
her computer for many different
tasks, ranging from applications
inconceivable before we had
computersÑsuch as e-mail,online messenger services, or chat
roomsÑto computer-basedenhancements to more traditional
tasks like creating and typesetting
documents, organizing a
business, or tracking investments.relevance. This makes it possible to buildenormously complex systems out of a
tower of abstractions, one layer at a time.Systematic research on algorithms anddata structures was also necessary to
build such complex software and hardwaresystems.Nothing elseÑaside from a personÑis auniversal machine that can be taught orprogrammed to accomplish a very wide
range of new tasks. Kleinberg andPapadimitriou (in Chapter 2) show how theidea of universality rests on the notion of
the universal Turing machine and theChurch-Turing hypothesis about theuniversality of computers.The capabilities of EmilyÕs computer canbe improved as current programs are
improved, and even not-yet-conceivedcapabilities can be added as newprograms are written. Software toolsÑprograms that manipulate and transformother programsÑmake it possible tocreate new applications. The most
important of these tools are theprogramming languages that provide thegrammar, syntax, and semantics
programmers use to convey their ideas tocomputers. A wide range of programminglanguages and tools are available today
and new languages and tools are thesubject of computer science research. SeeAho and Larus in Chapter 4.Human-computer interaction research hasled to improved user interfaces that make
it easier for people to work with thissoftware. Foley (in Chapter 8) discusseshow research on user interfaces made
spreadsheet software easier to use.Ullman (in Chapter 8) describes thecomputer science research that led totodayÕs word processors.Foley (in Chapter 8) describes how avariety of CS research results madepossible another kind of computer
program, the spreadsheet.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.4COMPUTER SCIENCE: REFLECTIONSVisiting VirtualEmporia.comEqually remarkably, EmilyÕscomputer is easily connected to
the Internet. This allows her to
obtain information from billions
of Web pages, communicate with
others using e-mail or chat
programs, or use a myriad of
other Internet-delivered services.
Once she is online and has
opened a Web browser, she can
visit VirtualEmporia.com simply
by typing Òhttp://www.VirtualEmporia.comÓ or
selecting a bookmark. Her
computer translates the name of
the destination site into an
Internet address and sends a
message across the Internet to
VirtualEmporia, asking for a Web
page, which contains links to the
rest of VirtualEmporiaÕs network.The Internet, which made data exchangeamong distant computers fast, easy, and
commonplace, marked a striking changein the use of computers. The Internet alsorepresented a striking change in how
communications networks were designed.The Internet is a distributed, fault-tolerantsystem for communicating among
computers. Its design specifies very littleabout the form or content of dataÑthataspect is left to the applications and
systems enabled by the InternetÕs packet-data-transport mechanisms (see Petersonand Clark in Chapter 7). With few changes
to its design or implementation, theInternet grew from approximately 300,000interconnected machines (hosts) in 1990
to over 170 million hosts in 2003.1Although the Internet was originally
constructed to allow researchers to sharedata and remotely access expensivecomputers, users of the early Internet
quickly made e-mail the most popularapplication, and it remains the mostcommon use of the Internet today. Today,
the Internet is opening up many newavenues for communication among people(see Bruckman in Chapter 7).The InternetÕs success derives in largepart from the fact that it provides effective
abstractions to enable computersthroughout the world to find each otherand exchange data. Here, EmilyÕs browserand VirtualEmporia.comÕs Web site use acommunication protocol called http that isbuilt on top of the Internet.The World Wide Web, another of themany uses of the Internet, owes its origins
in part to earlier computer scienceresearch on hypertext, which provides away of navigating among linked
documents.1Internet Systems Consortium (ISC), 2004, ÒInternet Domain Survey,Ó ISC, Redwood City,
Calif., January. Available online at http://www.isc.org/ds/.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PRELUDE: EMILY SHOPS AT VIRTUALEMPORIA.COM5ShoppingWhen Emily visitsVirtualEmporia.comÕs Web site,VirtualEmporia.com recognizes
Emily as an established customer.
It retrieves her records and
produces a customized home
page, based on her past shopping
habits, that suggests a few items
she might want to buy. As she
navigates through the site, the
pages she views are also
customized. VirtualEmporia.com
suggests new books that might
interest her, based on previous
items she has purchased or
searched for. In addition, when
she looks at items or adds them
to her shopping cart,
VirtualEmporia shows her more
items that customers with similar
shopping interests have selected.Emily can also refine herchoices by reading reviews on the
VirtualEmporia site, including
reviews published by recognized
critics and comments from other
customersÑwhich she takes moreor less seriously depending on
the credibility ratings these
comments have accumulated.Emily can browse throughthe items for sale or search the
database of available products.
Emily first enters a search request
by authorÕs name. She receives aresponse in a second or less, even
though VirtualEmporiaÕsdatabase contains information
about millions of books and other
items for sale, has tens of millions
of registered customers, and mayResearch on collaborative filtering led tomachine-learning algorithms that correlate
a new shopperÕs interests with those ofother shoppers in the database, so thatdata from the entire shopping community
can be used to learn EmilyÕs likelyinterests. Mitchell (in Chapter 6) discussessome other applications of machine
learning.Computer science research on reputationsystems allows VirtualEmporia to providesome indications of how much trust one
should place in opinions contributed bystrangers.Like many modern organizations such asairlines, banks, and governments,
VirtualEmporia could not exist in its currentform without database systems. Gray (inChapter 5) describes the research that led
to the relational model for databases andmodern database systems. Building onthis discovery, computer scientists have
developed a rich collection ofrepresentations and algorithms formanipulating data; this makes it feasible to
store, index, search, update, and sortbillions of records in reasonable amountsComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.6COMPUTER SCIENCE: REFLECTIONSreceive queries from hundreds ofusers each second. Emily does not
find the book (she doesnÕt quiteremember the authorÕs name), butshe does remember the name of a
character in the book, which she
uses in a full-content search to
locate the desired book.The online setting enablesbusiness partnerships that were
previously difficult or impossible.
VirtualEmporia also allows Emily
to consider offerings from
multiple booksellers, including
not only a large seller who can
provide almost all books
currently in print, but also
numerous used-book sellers, both
companies and individuals. When
Emily searches for a book, she not
only gets information about how
to order that book and other
editions of that book but also the
opportunity to buy a used copy
from the many booksellers and
individuals who list books at
VirtualEmporia.Paying for the BookAfter some browsing andsearching, Emily finds the books
she wants and goes to the
checkout page, which asks for a
credit card number.EmilyÕs credit cardinformation is automatically
encrypted by her Web browser
before it is sent over the Internet,
making it harder for an
unauthorized person to obtain it,
even though the information isof time, and to ensure their integrity in theface of overlapping queries and updates.The ability to store and rapidly processsuch enormous and growing volumes of
information also depends on work leadingto the ever-increasing performance ofcomputers (see Hill in Chapter 2).Sudan (in Chapter 7) explains how public-key encryption, a technology stemming
from cryptology research, makes itpossible for a business such asVirtualEmporia.com to engage in secure
communications with millions ofindividuals.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PRELUDE: EMILY SHOPS AT VIRTUALEMPORIA.COM7traveling across the InternetÕsshared infrastructure and could
potentially be processed by tens
or hundreds of computers along
the path between her computer
and VirtualEmporia.Shipping the BookVirtualEmporiaÕs shippingsystem makes use of software
algorithms to decide which
warehouse to use for the books
Emily has ordered, whether the
books will all be shipped in one
package or separately to help
speed the books to Emily, which
shipper to select, and so forth.Even though the books arephysical objects that traveled by
airplane and truck, their rapid
journey is assisted by the
shipperÕs computerized logisticssystems that inventory, schedule,
and track the booksÕ journey.
These systems also make it
possible for Emily to track a
package through a Web site and
receive updates on when she can
expect the package to arrive.ConclusionEmilyÕs books will arrive ather home a few days later.
Impatiently awaiting her
purchase, Emily starts to wonder
why the book even had to be a
physical object: why couldnÕt itjust be delivered as a digital
object, transmitted over the
Internet? Indeed, computer
science research has alreadyInformation encoded with a public key canbe decrypted only with the corresponding
private key. VirtualEmporia.com publishesits public key, which anyone can use toencrypt information and securely send it to
VirtualEmporia.com. OnlyVirtualEmporia.com, however, knows theprivate key for decrypting these
messages. This technique can be appliedboth ways: software on EmilyÕs computercan use the secure channel to
VirtualEmporia.com to create a new one inthe reverse direction (fromVirtualEmporia.com to Emily). Therefore
confidential two-way communication canproceed, protected from prying eyes.A special secure version of the WorldWide Web communication protocolprovides a layer of abstraction that makes
it possible for Emily to use securecommunication without knowing about thedetails.Inventory management and routing areboth examples of activities involving
information manipulation. Before computerscience, these processes could beaccomplished only by hand. Computerized
inventory and routing algorithms havemade express shipping much moreefficient. The result has been a reduction
of both the costs and the elapsed time fordelivery.Like shopping, package tracking dependson database systems. It also depends onwireless communications from the delivery
people who carry portable wirelessdevices. These devices owe their originsto research on wireless networks and low-
power devices.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.8COMPUTER SCIENCE: REFLECTIONSprovided many of the necessaryfoundations of electronic books
and has built prototypes of all the
basic components. Electronic
books have just entered the
commercial marketplace and may
become more commonplace once
inexpensive and practical book-
like reading devices become
available.An Òearly adopter,Ó Emily
decides she wants something to
read right away. She goes to
VirtualEmporiaÕs e-booksdepartment, orders and
downloads a book, and starts
reading it within minutes.Perhaps what is most remarkable about EmilyÕs shopping experience is thatitÕs so commonplace today (and electronic books may become commonplace justover the horizon), while just 10 years ago it seemed far-fetchedÑeven as thecomputer science groundwork was being laid. What other stories, which may seemfantastic today even as computer science research is laying their foundations, willwe come to label mundane 10 and 20 years from now?Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Part OneThe Essential Character ofComputer ScienceComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.111The Essential Character ofComputer ScienceComputer science began to emerge as a distinct field in the 1940sand 1950s with the development of the first electronic digital com-
puters. Their creation reflected several coincident factorsÑthedevelopment of computational theory in the 1930s and 1940s, the exist-
ence of compelling computational applications (starting with wartime
needs such as codebreaking and the calculation of artillery trajectories),
and the availability of electronic components with which to implement
computers for those applications. A number of mathematicians, engineers,
economists, and physicists turned their attention to mastering and
enhancing the capabilities of this novel tool. But computers proved so
powerful and absorbing, so interesting and open-ended, and so uniquely
challenging that many of these people realized, a decade or so later, that
they had in fact left their original disciplines and were pioneering a
new field.Computer science embraces questions ranging from the properties ofelectronic devices to the character of human understanding, from indi-
vidual designed components to globally distributed systems, and from
the purely theoretical to the highly pragmatic. Its research methods are
correspondingly inclusive, spanning theory, analysis, experimentation,
construction, and modeling. Computer science encompasses basic research
that seeks fundamental understanding of computational phenomena, as
well as applied research. The two are often coupled; grappling with prac-
tical problems inspires fundamental insights. Given this breadth and
diversity, the discussion that follows does not aim to explicitly or compre-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.12COMPUTER SCIENCE: REFLECTIONShensively define computer science or to catalog all of the research areas.(Indeed, such an effort would inevitably bog down in classifying sub-
disciplines of the field and declaring interdisciplinary activities as ÒinÓ or
Òout.Ó) Instead, the approach is to indicate and illustrate the essentialcharacter of the field through a sampling of representative topics.WHAT IS COMPUTER SCIENCE?Computer science is the study of computers and what they can doÑtheinherent powers and limitations of abstract computers, the design and character-
istics of real computers, and the innumerable applications of computers to solv-
ing problems. Computer scientists seek to understand how to represent
and to reason about processes and information. They create languages for
representing these phenomena and develop methods for analyzing and
creating the phenomena. They create abstractions, including abstractions
that are themselves used to compose, manipulate, and represent other
abstractions. They study the symbolic representation, implementation,
manipulation, and communication of information. They create, study,
experiment on, and improve real-world computational and information
systemsÑthe working hardware and software artifacts that embody thecomputing capabilities. They develop models, methods, and technologies
to help design, realize, and operate these artifacts. They amplify human
intellect through the automation of rote tasks and construction of new
capabilities.Computer hardware and software have been central to computer sci-ence since its origins. However, computer science also encompasses the
study and more general application of principles and theories rooted in or
motivated by hardware and software phenomena. Computer science has

thus come to encompass topics once distinctly part of other disciplines,
such as mathematics, originally motivated by computing and conceptual
questions of information-handling tasks such as natural-language pro-
cessing. Computer science research is often intimately intertwined with

application, as the need to solve practical problems drives new theoretical
breakthroughs.The accompanying essays in this volume elaborate on some impor-tant examples of the results of computer science research. These include:¥The Universal Turing Machine and the Church-Turing thesis, whichprovide a theoretical underpinning for understanding computing (see
Kleinberg and Papadimitriou in Chapter 2);¥Computer programs that achieve, exceed, or augment human per-formance levels in challenging intellectual tasks (see Koller and Bierman
and also Mitchell in Chapter 6);Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.THE ESSENTIAL CHARACTER OF COMPUTER SCIENCE13¥The theory of algorithmsÑformal expressions of proceduresÑwhichseparate algorithmic behavior from the specific code that implements it
(see Kleinberg and Papadimitriou in Chapter 2);¥Programming languages, which are notations specifically designedto represent computational processes, or how things happen (see Aho
and Larus in Chapter 4);¥The relational model of data, which provided a systematic way toexpress complex associations among data and revolutionized the data-
base industry and provided the basis for nearly all business computing
(see Gray in Chapter 5);¥The Internet, a reliable system created from unreliable parts thatdefines a simple, general-purpose abstraction of a packet network on
which a wide range of applications can be constructed (see Peterson and
Clark in Chapter 7);¥Simulation, which permits the study and visualization of both
natural and man-made phenomena (see Fedkiw in Chapter 3); and¥Software systems that allow non-experts to use computers (seeFoley and also Ullman in Chapter 8).Computer scienceÕs striking research advances have touched our livesin profound ways as we work, learn, play, and communicate. Even though
computer science is a relatively young field, born only within the past
seven decades, the pace of innovation in it has been extraordinary. Once
esoteric, expensive, and reserved for specialized tasks, computers are now
seemingly everywhere. Applications and technologies that are now fix-
tures in many peopleÕs lives and work (such as office automation,e-commerce, and search engines) were nonexistent or barely visible just a
decade ago. The personal computer itself was first introduced less then
three decades ago, yet most office workers are now assigned a PC as a
matter of course, and roughly half of all households in the United States
own at least one. Computers are central to the daily operations of banks,
brokerage houses, airlines, telephone systems, and supermarkets. Even
more computers lurk hidden inside handheld cell phones, personal digital
assistants, and automobiles; for example, a typical midmarket automobile
contains a network and dozens of processors. As the size and cost of
computer hardware shrink, computers will continue to proliferate even
more widely (see Hill in Chapter 2). All these computers have provided
society with tremendous social and economic benefits even as they pose
new challenges for public policy and social organizations.Advances in computer science have also led to fundamental changesin many scientific and engineering disciplines, enabling, for example,
complex numerical calculations that would simply be infeasible if
attempted by hand. Computer science has provided highly useful toolsComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.14COMPUTER SCIENCE: REFLECTIONSfor controlling experiments, collecting, exchanging, and analyzing data,modeling and simulation, and for sharing scientific information. Indeed,
finding the right data structure or algorithm can revolutionize the way in
which a scientist thinks about a problem. For example, computer science
algorithms made it possible to put together a vast amount of data from
sequencing machines when the human genome was sequenced. In recent
years, reflecting informationÕs central importance in scholarly work andscience, computing has also taken on new importance in many other dis-
ciplines as well; Ayers (in Chapter 5), for example, discusses ways in
which historians are using computing. Computer scienceÕs computationalparadigm has also shaped new modes of inquiry in other fields, such as
genomics and related areas of biology.One driver of computer science innovation is the doubling of hard-ware performance that we have seen roughly every 11/2 to 2 years (see Hill
in Chapter 2). Another is the invention of myriad new applications of
computers, whose creation is made possible by the tremendous flexibility
of software. Computer applications are largely limited only by human
imagination, although there are fundamental limits on what is comput-
able and there are significant engineering challenges in building complex
systems.This volume explores computer science research, emphasizing howresearch leads both to deeper understanding of computation and to
numerous practical applications. Many others have celebrated the accom-
plishments of computer science or offered predictions about future direc-
tions.1 The emphasis in this volume is on why and how computer
scientists do their research.Part Two of this volume consists of a set of individually authoredessays that provide a sampling of perspectives on several areas of com-
puter science research. These are intended to exemplify some of the
observations made in this chapter and illustrate some of the flavor of
computer science.This chapter broadly considers the essential character of computerscience (what does computer science investigate, design, and create?),
and its methods and modes of research (how do computer scientists1For example, Cathy A. Lazere and Dennis Elliott Shasha, 1998, Out of Their Minds: TheLives and Discoveries of 15 Great Computer Scientists, Copernicus Books, celebrates accomplish-ments of the field. Works describing future research directions include CSTB, NRC, 1992,Computing the Future, National Academy Press; Peter J. Denning and Robert M. Metcalfe,eds., 1997, Beyond Calculation: The Next Fifty Years of Computing, Springer-Verlag; and PeterJ. Denning, ed., 1999, Talking Back to the Machine: Computers and Human Aspiration, Springer-Verlag. Bruce W. Arden, 1980, What Can be Automated: The Computer Science and EngineeringResearch Study, MIT Press, was an attempt to comprehensively survey the field.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.THE ESSENTIAL CHARACTER OF COMPUTER SCIENCE15approach problems? what methods do they use? and what types of resultsemerge?). The discussion below elucidates seven major themes without
attempting to fully enumerate all the research subfields within computer
science, to prescribe a research agenda, or to define the boundaries of
computer science.SALIENT CHARACTERISTICS OFCOMPUTER SCIENCE RESEARCHThe character of a research field arises from the phenomena it seeks tounderstand and manipulate together with the types of questions the dis-
cipline seeks to answer about these phenomena. This section identifies
phenomena and intellectual challenges central to computer science,
describing the key ideas and the identifying work that has helped to
develop those ideas. These broad themes (summarized in Box 1.1), more
timeless than a comprehensive inventory of current topics would be, por-
tray core ideas that computer science is concerned with.Computer Science Research Involves Symbols andTheir ManipulationTwo of the fundamental techniques of computer science research arethe manipulation of discrete information and symbolic representation.
Some information is inherently discrete, such as money. Discrete approxi-
mation enables every kind of information to be represented within the
computer by a sequence of bits (choices of 0 or 1) or the often moreBOX 1.1
Salient Characteristics of Computer Science Research¥Computer science research involves symbols and their manipulation.
¥Computer science research involves the creation and manipulation of
abstractions.¥Computer science research creates and studies algorithms.

¥Computer science research creates artificial constructs, notably unlimited
by physical laws.¥Computer science research exploits and addresses exponential growth.

¥Computer science research seeks the fundamental limits on what can be
computed.¥Computer science research often focuses on the complex, analytic, rational
action that is associated with human intelligence.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.16COMPUTER SCIENCE: REFLECTIONSconvenient bytes (sequences of 8 bits, representing characters such asletters) to which the proper interpretation is applied. A digital image of
any one of Van GoghÕs paintings of sunflowers (call it Sunflowers, forshort) divides the continuous painted canvas into many small rectangular
regions called pixels and gives the (approximate) color at each of these.
The collection of pixels can, in turn, be thought of as a sequence of bits. Bit
sequences, being a ÒdigitalÓ or discrete-valued representation, cannot
fully represent precise, real-valued or ÒanalogÓ information (e.g., the pre-
cise amount of yellow in a sunflower). Practically, though, this apparent
limitation can be overcome by using a sufficiently large enough number
of bits, to, for example, represent the analog information as precisely as
the eye can see or the ear can hear.This sequence of bits can be processed in one way so that a person cansee the Sunflowers image on a display or processed another way for a
printer to print an image. This sequence of bits could be sent in an e-mail
message to a friend or posted to a Web page. In principle, the same
sequence of bits could be passed to an audio interpreter; however, the
audio produced by Sunflowers would not sound very good, since this bit
sequence is unlikely to represent anything reasonable in the symbol sys-
tem used by the audio player. Sunflowers could be executed as a programon the computer, since programs are themselves bit strings; again, how-
ever, the result will probably not produce anything meaningful, since it is
unlikely the paintingÕs representation is a sequence that will do some-thing useful.More subtle than discrete approximation, yet more powerful, is thetechnique of symbolic representation. Here the underlying bits are used
to represent symbols in some notation, and that notation is used to repre-
sent information in a way that permits analysis and further processing.
For example:¥For analysis of differences among sunflowers or between sun-flowers and marigolds, flowers could be described in terms of their genetic
code.¥For graphical animation, a sunflower might be represented by adescription of the color and shape of its parts together with how they are
connected to each other.¥To denote different varieties, sunflowers might be represented bya set of symbols consisting of words in English.The right symbol systems, properly interpreted, allow one to writeprograms that represent and manipulate sounds or images, that simulate
physical phenomena, and even that create artificial systems without an
analog in nature.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.THE ESSENTIAL CHARACTER OF COMPUTER SCIENCE17Several of the essays in this volume deal with symbolic representa-tion. The essay by Kleinberg and Papadimitriou in Chapter 2 discusses
the formal representation of computation itself as symbol strings. Lesk in
Chapter 5 mentions many of the important kinds of representations being
stored in computers as Òdigital libraries.ÓComputer Science Research Involves the Creation andManipulation of AbstractionComputer science often involves formulating and manipulatingabstractions, which are coordinated sets of definitions that capture differ-
ent aspects of a particular entityÑfrom broad concept to its detailedrepresentation in bitsÑand the relations through which some of the defi-nitions refine others or provide additional concepts to help realize others.One aspect of abstraction is that sequences of bits take on specificuseful interpretations that make sense only in particular contexts. For
example, a bit sequence can be thought ofÑin some contextsÑas aninteger in binary notation; using that abstraction, it makes sense to divide
the integer by 3 and get another sequence of bits that is the quotient. But
in a context that abstracts bit sequences as images, it would not be reason-
able to divide Sunflowers by 3 and get something meaningful, nor would it
make sense to divide a DNA sequence by 3. But the abstraction of bits as,
for example, images, should permit operations that make no sense on
integers, such as cropping (removing bits that represent pixels at the edges
of an image) or applying a watercolor filter in an image-manipulation
program. Similarly, the abstraction of bits as DNA sequences should per-
mit analysis of differences among plant species that would make no sense
for integers or images.Abstraction also makes it possible to perceive and manipulate thesame computer-represented ÒobjectÓ at many levels. Objects at one level
make available to higher levels a fixed set of operations, and are per-
ceived by the higher level as if these were the only operations that could
ever be performed on them. For example, the bit sequence representing
Sunflowers and other paintings could be thought of as part of a 
relation(two-dimensional table of data), in which each row contains the bits rep-
resenting an image, another bit sequence representing the name of the
painting, a third bit sequence representing the name of the artist, and so
on. At the lowest level, there are operations that manipulate the indi-
vidual entries in each row; for example, the image bit string could be
converted to a black and white image by manipulating the color informa-
tion. At the next level, one considers the entire relation as an object; opera-
tions on 
the relation, rather than manipulating pixels or displaying images,instead perform such operations as Òfind all the images of paintings byComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.18COMPUTER SCIENCE: REFLECTIONSVan Gogh.Ó If the image abstraction permitted operations like Òtell if thisimage has a region that the typical person would perceive as a sunflower,Óthen the relation abstraction would permit searches like Òfind the namesof all paintings with one or more sunflowers in them.Ó Alas, that sort of
operation on images is beyond the state of the art at the beginning of the
21st century. However, operations at the image-level abstraction can be
used to determine if an image has a large region of yellowish-orange, and
thus to support a question at the level of the table such as Òfind the namesof paintings with large yellow-orange regions.ÓAs alluded to above, abstractions apply to procedures as well as data.Consider a bit sequence representing a piece of computer code that per-
forms a sequence of operations on Sunflowers. One set of bits might pro-vide the (detailed) machine instructions to display the image on a particu-
lar computer. Another set of bits might be the program to animate a
model of a sunflower blowing in the breezeÑwhen interpreted by thecompiler for that language (and, of course, when the object code is then
executed). Yet a third set of bits might be in an animation language that
permits the motion of a sunflower to be described at a high level.The print function common across applications on most systemstoday, which allows a wide range of data objects to be printed on a wide
range of printers, is a powerful example of abstraction. The user need not
know about all the details hiding behind this simple interface
Ñthe ÒprintÓcommand is an abstraction that shows the user only what he or she needs
to see.In each case, the bits are interpreted by a model that abstracts proce-dures above the actual machine instructions that a computer executes.
Observe also that bits can at the same time be both data and procedureÑthe compiler reads a program to produce an output (data) that will later
be executed by a computer (procedure).The Internet works today because of abstractions that were productsof the human imagination. Computer scientists imagined ÒpacketsÓ of
information flowing through pipes, and they (symbolically) worked out
the consequences of that idea to determine the new laws those flows of
information must obey. This conceptualization led to the development of
protocols that govern how data flows through the Internet, what happens
when packets get lost, and so on. The InternetÕs constructs extend wellbeyond mathematics or models to high-level design principles such as
keeping the network core simple and keeping detailed functionality at the
edges. The power of a good abstraction is illustrated by the fact that the
InternetÕs basic protocols have reliably carried traffic on the network sinceits creation, even as this traffic has changed enormously not just in scale
but also in behavior, from e-mail to streaming media and peer-to-peer file
sharing networks.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.THE ESSENTIAL CHARACTER OF COMPUTER SCIENCE19In Part Two, Shaw (in Chapter 4) presents abstractions as a key ideain software design. The essay by Aho and Larus (in Chapter 4) discusses
how the abstractions in computer languages bridge the gap between
computer hardware and humans. Programming languages offer ways to
encapsulate the details of algorithms and define procedural and data
abstractions that allow the algorithms to be used without knowledge of
their details. Peterson and Clark (in Chapter 7) discuss the important
abstractions of the Internet, and Gray (in Chapter 5) covers abstractions
that have proved especially useful for representing data.Computer Science Research Creates and Studies AlgorithmsOften, computing research is less about how to represent static objects(such as an image or a driverÕs-license record) and more about developingand studying algorithms (precise ways to do a particular task) that will
perform operations on objects. With respect to images, such operations
might include cropping an image, finding boundaries between regions of
different color or texture, or telling whether an image has at least 20per-

cent of its colors between yellow and orange. Given a symbolic represen-
tation of a sunflower as a set of measurements and some assumptions
about the strength of the stem and the force of a breeze, a virtual reality
algorithm could display that sunflower swaying in the breeze. Program-
ming languages offer ways to encapsulate the details of these algorithms
and define procedural abstractions that allow the algorithms to be used
without requiring knowledge of their details.Computer science also concerns itself with the amount of time analgorithm takes (its running time), and some computer scientists try tofind algorithms that take less time than others to do similar things, some-
times dramatically reducing the time required. It would not do if, for
example, it took all day to tell if a typical-sized image were 20 percent
yellow. Sometimes, such research yields major breakthroughs that offer
order-of-magnitude improvements in the time required to solve a par-
ticular type of problem.Part Two includes a discussion of programming languages in Ahoand Larus (in Chapter 4) and a treatment of algorithms and their running
time in Kleinberg and Papadimitriou (in Chapter 2). Indeed, essentially
all the essays in this volume mention algorithms and/or programming-
language representations for one or another kind of information.Computer Science Research Creates Artificial Constructs,Notably Unlimited by Physical LawsAnimated sunflowers blowing in the breeze are an example of howthe computational world can mimic, at an extremely accurate level, theComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.20COMPUTER SCIENCE: REFLECTIONSbehavior of the real world. While computer scientists often addresses theworld as it is, computer science also deals with the world as it could be, or
with an entirely invented world behaving under different assumptions.
Computer scientists can, for example, easily change the rules, making
water more viscous or weakening the effect of gravity. For example, video-
game characters often obey physical laws that have never been seen in
nature (ÒRoadrunner physicsÓ). Computational models also describe com-plex natural phenomena that are hard to observe in nature. Such models
can describe both natural and unnatural worlds. For example, it is entirely

possible to make ocean waves a bit more exciting to watch by altering
gravity or the viscosity of waterÑchanges impossible in the laboratorybut routine within the world of computing.Fedkiw (in Chapter 3) describes how computer-generated animationproduces such images as the waves in the movie The Perfect Storm
.Peterson and Clark (in Chapter 7) describe the Internet model. Bruckman
(in Chapter 7) examines online virtual communities.Computer Science Research Exploits andAddresses Exponential GrowthThe speed of light doesnÕt change at all, and DNA strands have grownin length only over geologic time. But computer science must deal with
machines that, by various measures of size and speed (for fixed cost),
double in performance roughly every 11/2 to 2 years (see the essay on
MooreÕs law by Hill in Chapter 2).2 Although these performance improve-
ments make it easier for computer scientists to solve some problems, they
can also magnify computer and system design challenges. Over time, the
critical resource to be optimized changes; designers today must take into
account that obtaining two numbers from a computerÕs main memory cantake a hundred times longer than multiplying them together whereas just
the opposite was once true. Moreover, the improvements create commen-
surate demands that the machines be used to solve ever more complex
problems and larger or harder instances of the same problem and that
ever-larger systems be built.2There are really two related trends that go by the name MooreÕs law. The original formof MooreÕs law states that the number of transistors per chip doubles every 18 months. Thepopular form of MooreÕs law states that as a result of increasing transistor density and othertechnological progress, such as the density of magnetic disk drives, the performance of acomparable-cost computer doubles roughly every 11/2 to 2 years or, alternatively, that the
cost for the same performance halves. This combination of extremely rapid exponentialgrowth and the ability to exploit the improvements in many different combinations of costand performance is unprecedented in the history of technology.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.THE ESSENTIAL CHARACTER OF COMPUTER SCIENCE21Computer scientists have a rule of thumb that every time things get10 times larger or faster a qualitatively different class of research chal-
lenges emerges. To get a sense of this, suppose you are playing bridge,
and you need to examine your hand to see whether you hold no cards of
the suit being played, and therefore are allowed to trump the trick. Since
your hand consists of at most 13 cards at any time, you can usually figure
it out quickly by scanning each of your cards. But suppose bridge were
played with hands of a million cards, with 10,000 suits, each of 100 ranks.
Could you figure out which card to play before your opponents got up to
get a snack? Computers deal with similar situations all the time, and to
avoid scanning all 1,000,000 cards, organizations for data have been
devised that allow us to design algorithms that home in on the desired
card much more quickly than can the obvious Òscan all cardsÓ algorithm.The expectation of rapid improvement in capabilities leads to a formof research, perhaps unique to computer science, sometimes called Òlivingin the future.Ó Although almost every technology goes through some
period of exponential growth, computers are remarkable because the
doubling time is unusually short and the exponential growth period has
been unusually long. As a result, it often makes sense to think about what
the world will be like when computing machines are 10 times faster, or
able to communicate with 100 times the bandwidth. Certain things that
one cannot now do, or cannot do for a reasonable cost, are suddenly going
to become possible. Many research successes that turned into success-
ful products were the result of such confident, forward thinking.In addition to HillÕs, many of the essays in this volume show howcomputer science research has both exploited the exponential improve-
ment in our tools and dealt with the exponential growth in requirements.
The essay by Koller and Biermann (in Chapter 6) examines chess playing,
where the goals of being able to defeat better and better players have
largely been met. Peterson and Clark (in Chapter 7) show how we are
coping with the ever-growing Internet.Computer Science Research Seeks the Fundamental Limits onWhat Can Be ComputedIn addition to developing knowledge that supports practical engi-neering applications, computer science investigates fundamental limits
regarding computation. It has been known since the 1930s that there are
undecidable problems, those that can be stated succinctly yet cannot be
answered. The canonical example of these is, can you write a computer
program that given an arbitrary program P and arbitrary input N to thatprogram, can answer the question, does the program P ever stop runningwhen given the input N? The discovery that the answer to this question isComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.22COMPUTER SCIENCE: REFLECTIONSno is fundamental in the sense that it applies to all possible programsrather than being a statement about a particular piece of programming
code.Perhaps more important is the discovery that not everything that isdecidable (a computer can solve it, somehow) is tractable (solvable in
sufficiently little time that we can expect to get answers to reasonably
large instances of the problem in reasonable time). Some problems, such
as searching for cards described above, are tractable. Even the dumb algo-
rithm of examining each one of n cards in one
Õs hand would only taketime proportional to n. However, there are other problems that are nottractableÑwhere time or computing resources proportional to the size ofthe instance to be solved are insufficient. Instead, they require time or
resources that are exponential in the size of the input nÑthat is, time thatgrows like 2n. This sort of analysis extends more generally to how therequired computing resources relate to the nature and structure of a prob-
lem as well as its size. For some types of problems, the issue is how
accurately something can be computed; here computer science seeks an
understanding of the fundamental limits in the accuracy of what can be
computed and the accuracy of what can be computed quickly (as in
approximation algorithms).An example of a tractability problem is the Traveling Salesman Prob-lem (TSP), where one is given n ÒcitiesÓ (nodes of a graph) with distances
between each pair. The goal is for the salesman (who, following our ear-
lier example, is selling sunflower oil) to visit each city once and return to
the starting city, but minimize the total distance traveled. An obvious
solution, starting from one of the n cities, has 
n Ð 1 choices for the first city,
n Ð 2 choices for the next, and so on, a total of (
n Ð 1)(
n Ð 2) ...(2)(1)
choices. Unfortunately, this number of choices grows faster than 2n. Whatis worse, the theory of intractable problems provides powerful evidence
that there is no way to solve the TSP in substantially less time. As a result,
even the exponential improvement in the speed of computers (ÒMooreÕslaw,Ó as mentioned above) can do almost nothing to increase the size of
problem instance that can be dealt with; perhaps one can handle a few
more cities each year, at best. Of course, even when it is impractical to
solve a problem generally and optimally, the situation is not necessarily
hopeless. In practice, salesmen can make their rounds fairly efficiently
because algorithms that do well enough most of the time have been

discovered.The fundamental limit on our ability to compute applies not only tothe TSP, but also to thousands of problems encountered daily. That is, one
can solve these problems by computer only when the problem instance is
rather small, and the situation can never get much better. Research onComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.THE ESSENTIAL CHARACTER OF COMPUTER SCIENCE23fundamental limits thus informs practical application, by showing thatsome system designs are ultimately a dead end.In Part Two, Kleinberg and Papadimitriou (in Chapter 2) provide adiscussion of the precise implications of the theory of intractable prob-
lems, and Sudan (in Chapter 7) discusses cryptography, a domain where
the intractability of a problem is a help, not a hindrance, because the goal
is assurance that an intruder with a fast computer cannot discover secrets
within any reasonable amount of time.Computer Science Research Often Focuses on the Complex, Analytic,Rational Action That Is Associated with Human IntelligenceOne aspiration of computer science has been to understand and emu-late capabilities that are associated with intelligent human behavior. One
class of these activities is devoted to enabling computers to solve prob-
lems that humans can solve easily, yet that appear very difficult for
machines. A human can easily pick out the presence of a sunflower in an
image, and yet a computer of the early 21st century can do so only with
difficulty and limited accuracy. The problems of image understanding,
language understanding, locomotion, game playing, and problem solving

each provide enormous challenges for the computer scientist. A second
class of intelligence-related research is to understand how the human
mind works by trying to solve problems the way humans do. It turns out,
for example, that the simple Òif A then BÓ logic harking back to Aristotle
does not capture nearly enough of the way people think and make infer-
ences about their environment. A third class of intelligence-related
research is enabling computers to interact with the world by enabling
them to sense the environment, move within it, and manipulate objects.These efforts are elaborated in several of the essays. In Chapter 6,Koller and Biermann discuss game playing by computer as a testbed for
approaches that emulate intelligence. Lee tells about approaches to com-
puter understanding of natural language. Mitchell explores the develop-
ment of machine-learning techniques.Part Two of this volume explores some of the depth and breadth ofcomputer science through essays written by computer scientists. The
essays provide several researchersÕ own views about their research areas
and convey what excites these researchers about computer science.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Part Two
Selected Perspectives onComputer ScienceThe character of computer science research can perhaps best beappreciated by seeing some of the things computer scientists do
and why they choose to do them. In Part Two, computer scientistsexplain not only some of the results achieved in several areas of computer
science research but also what interests and excites them about the research.
The diversity of the topics addressed in these essays reflects the diversity
of the field itself.The essays in Part Two are organized by chapter into several clusters:¥Exponential growth, computability, and complexity. How computerscience research makes possible a sustained growth in computing power
and how theoretical models of computation help us understand intrinsic
limits on what is computable (Chapter 2).¥Simulation. How computer models can be used to simulate aspectsof the physical world (Chapter 3).¥ Abstraction, representation, and notations. How abstraction is usedto express understanding of a problem, manage complexity, and select
the appropriate level of detail and degree of generality (Chapter 4).¥Data, representation, and information. How computer science hasdeveloped new ways of storing, retrieving, and manipulating data, and
how these techniques can profoundly influence the models of a wide
range of professionals (Chapter 5).¥Achieving intelligence. How computer scienceÕs aspiration to emu-late human intelligence has resulted in advances in machine learning,Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.26COMPUTER SCIENCE: REFLECTIONScomputersÕ natural-language understanding, and improved strategies for
game-like situations (Chapter 6).¥Building computing systems of practical scale. How the design, devel-opment, and large-scale deployment of working computing systemsÑnotably, the InternetÑnot only are of great practical value but also consti-tute a diverse and fruitful area of research by which computer scientists
may improve these systems and create new ones (Chapter 7).¥Research behind everyday computation. How computer scientistsÕefforts in the service of human effectiveness have led to such advances as
spreadsheets, text-formatting programs, and information retrieval from
the Internet, and how these and other innovations have had a very broad
impact (Chapter 8).¥Personal passion about computer science research. How several com-puter scientists explain their commitment to computer science research
(Chapter 9).Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.272Exponential Growth, Computability,
and ComplexityThe essay by Hill that follows describes how exponential growth incomputing capability drives technological and intellectual progress and
how computer science research works to sustain this remarkable growth.Next, Kleinberg and Papadimitriou address the intellectual essence ofcomputation. They provide glimpses not only into the foundational
models that define computation but also into theoreticiansÕ thinking about
these modelsÑwhatÕs convincing, whatÕs surprising, whatÕs not.Finally, Bennett describes how quantum computing research seeks tododge a fundamental physical limit of current computing technology and
stretch our conception of computation.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.28COMPUTER SCIENCE: REFLECTIONSHARNESSING MOOREÕS LAWMark D. Hill, University of Wisconsin, MadisonFor most products, the claim Òbetter and cheaperÓ casts suspicion on
the salesperson. For computer-related products, however, Òbetter andcheaperÓ has been wildly true for decades. In this essay, we seek to explain
this success so as to give readers a foundation with which to appreciate
what the future might hold. Specifically, we explain how rapid techno-
logical progress (e.g., the technologistÕs MooreÕs law) has been harnessedto enable better and cheaper computers (the popular mediaÕs MooreÕslaw). We then touch upon future prospects for technological progress,
computer implementation challenges, and potential impacts.How Does Computer Hardware Work?Before delving into our rapid progress in improving computers, it isimportant to reflect on how computers work. As discussed in Chapter 1 of
this volume, computers are not designed to perform a single task. Instead
they are machines that can perform many different computational tasks,
including tasks that are not specified or even conceived until after the
computer is deployed.We enable this flexibility by using software. Software represents acomputational task to hardware as a collection of commands. Each com-
mand is called an instruction and the set of instructions that the hardware
supportsÑits vocabularyÑis its instruction set architecture. Most instruc-tions are simple. An ÒaddÓ instruction adds two numbers and indicates
which instruction is next. A ÒbranchÓ instruction compares two numbersto choose which instruction is next. The instructions manipulate data,such as numbers and characters.Moreover, instructions can manipulate other instructions, since mostmodern computers store instructions just like data. Treating instructions
as data enables programs, such as compilers, that can translate high-levellanguage programs (e.g., written in Java) into machine instructions (see
Aho and Larus in Chapter 4).Computer hardware has three basic components:¥A processor executes instructions. Today, it is most common to
implement a processor on a single silicon chip called a microprocessor.Most computers today employ a single microprocessor, but larger com-
puters employ multiple microprocessors.¥Memory stores instructions and data. Current desktop computer
memories are implemented in several chips and backed up by one orComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY29more magnetic disks. Larger computers can employ hundreds of memorychips and disks.¥Input/output devices connect a computer to both humans (e.g., key-
boards, displays, mice, and speakers) (see Foley in Chapter 8) and to other
computers via networks (see Peterson and Clark in Chapter 7).Hardware designers seek to make processors that execute instruc-tions faster, memory that provides more information, and input/output
devices that communicate more effectively. Furthermore, we can and do
focus on making these primitive elements faster without worrying about
what the software running on the hardware is actually doing.But how do we know this all works? Why is relatively simple hard-ware sufficient for most computing? Which instructions do I need in my
instruction set architecture? Kleinberg and Papadimitriou in this chapter
address these questions using the formal foundations of the Universal
Turing Machine and the Church-Turing hypothesis. These foundations
allow hardware designers to concentrate on the practical questions of
engineering effective hardware.MooreÕs Law and Exponential GrowthThe key enabler of Òbetter and cheaperÓ computers has been rapid
technological progress. Arguably, the most important enabler has been
the progress in the number of transistors (switches) per semiconductor
integrated circuit (chip). In 1965, Gordon Moore used four data points
to predict that the number of transistors per chip would double every

2 years. He was not far off! The trend over the last 35 years has indeed
been exponential, with the number of transistors per chip doubling
approximately every 18 months. Technologists call this trend MooreÕs law.Some commentators have implied that exponential growth, such aswith MooreÕs law, is unique to computer technology. This belief is incor-rect. In fact, exponential growth is common and occurs whenever the rate
of increase of a quantity is proportional to the size of the quantity.
Examples include compound interest and unconstrained biological popu-
lation growth. For example, $100 earning compound interest at a rate of
10 percent will more than double in 8 years: $214 = $100  (1 + 0.10)
8.To understand the implications of rapid exponential growth, con-sider the absurd example of your annual salary starting at a modest $16
but then doubling every 18 months for 36 years. This improvement corre-
sponds to an annual growth rate of 59 percent. In the early years, your
finances would be very tight (e.g., $64 after 3 years). You would have to
live with your parents. With patience, you will eventually be able to buy
a car ($16,000 after 15 years). Then you can move out and buy a houseComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.30COMPUTER SCIENCE: REFLECTIONS($100,000 after 24 years). Eventually you will be very rich and have todream up fundamentally new ways to spend money ($300 million after
36years).
The potency of MooreÕs law is evident when we observe that it hasfollowed the rate and duration of the absurd income example just given.
Sixteen transistors per chip is a mid-1960s number, while 300 million
transistors per chip is an early 21st century count. Of course, MooreÕs lawis not a law of nature. Rather it is a business expectation in the semi-
conductor industry: to stay even with their competitors, technologists
should solve the problems to double the number of transistors per chip
every 18 months.Fortunately, the number of transistors per chip is not the only tech-nological aspect that is achieving rapid, exponential growth rates. The
smaller transistors enabling MooreÕs law also switch much faster. More-over, improvements rivaling (or exceeding) MooreÕs law have occurredinmagnetic disk storage capacity and effective fiber optic network

bandwidth.Unfortunately, some other technologies are improving much moreslowly, notably the round-trip delays to memory chips, to disks, and
across networks. Memory chip delays are improving slowly because
memory chip manufacturers optimize for larger memory capacity instead.
Disk delays seem limited by the inertia of mechanically moving macro-
scopic mass, while network delays are ultimately limited by the speed of
light.How We Have Harnessed Exponential GrowthWhile it is obvious that rapid technological improvements providegreat opportunities for implementing computers, it is also the case that
rapid and differential rates pose great challenges. Rapid change means
that ideas that were too wasteful (e.g., in number of transistors) soon
become appropriate and then become inadequate. The processors in 1960s
computers required hundreds or thousands of chips. It was not until 1970
that is was even possible to implement a primitive processor on a single
chip (and that first so-called microprocessor could only access a memory of
300 bytes, i.e., 0.0003 megabytes!).Subsequently, MooreÕs law enabled microprocessors to use more andfaster transistors. New microprocessor designers exploited this transistor
bonanza to obtain computers that got faster more rapidly than the transis-
tors got faster. Central to this effort are methods of using many transistors
to cooperate side-by-side in what we call parallelism. Not surprisingly,approaches for exploiting transistor parallelism depend on scale or ÒlevelÓ(much as approaches for organizing humans to work in parallel dependComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY31greatly on whether 10, 1000, or 1 million people are available). With tran-sistors in a microprocessor, we have organized our focus on bit and
instruction level parallelism. Near the end of this essay, we discuss how
the currently modest use of thread level parallelism needs to be greatly
expanded.During the 1970s and earlier 1980s, microprocessor developmentfocused on accelerating the execution of each instruction using bit levelparallelism. Designers made changes to enable each instruction to both(a) manipulate a larger range of numbers (and symbols) and (b) perform
those manipulations faster using more transistors side by side. Early
microprocessors, for example, slowly performed manipulations on integers
taking on one of 65,536 (216) values (or fewer). In a single instruction, acurrent microprocessor can rapidly transform data whose values range
through billions (232) or quintrillions (264) of integer and fractional values.Since the mid-1980s, many microprocessor improvements havefocused on parallelism between instructions, not within instructions, with
what is called instruction level parallelism. Thus, instead of executinginstruction A, then instruction B, and then instruction C, we try to do
instructions A, B, and C at the same time. To exploit instruction level
parallelism past a few instructions, however, it is necessary to predict the
outcomes of program decisions (often embodied in branch instructions)
and speculatively execute subsequent instructions. Instruction level par-
allelism techniques have been so successful that modern microprocessors
can have several dozen instructions in execution at any one time! Never-
theless, most microprocessors still appear to execute instructions one at a
time. This illusion allows these microprocessors to run existing software,
unmodified. It enables performance gains without endangering the bil-
lions of dollars invested to develop and deploy existing software.The fact that technologies progress at different rates also poseschallenges to computer implementations. Twenty years ago, the time to
execute a multiply instruction and the time to access a computerÕs mainmemory were comparable. Differential rates of improvement now make a
multiplication more than 100 times faster than accessing main memory.
Computer architects have responded with a plethora of types and layers
of caches. Caches are smaller, faster memories that transparently hold themost-recently accessed subset of the information from a larger, slower
memory. Caches are faster than main memory, because they are smaller
(fewer bits to reach and select among) and can be implemented in tech-
nologies more optimized for speed. Caches often hold a very small frac-
tion of the larger memory (e.g., a 64 kilobyte cache for a 64 megabyte
memory). Nevertheless, they are able to satisfy a substantial fraction of
requests quickly (e.g., 98 percent) due to locality (the property that, at
many sizes and time scales, recently accessed information is highly likelyComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.32COMPUTER SCIENCE: REFLECTIONSto be re-accessed quickly). In some ways, caches work for reasons similarto why your cellular phone can hold many of the numbers you actuallycall. In fact, caches are so effective that current microprocessor designers
spend most of their transistors on caches! More generally, caching 
benefitsmany aspects of computer systems, as locality is common and smaller
memories are faster than larger ones in many technologies.Meeting the above challenges has enabled computers whose perfor-mance has been doubling every 2 years. Ambiguously, this trend is also
called MooreÕs law (e.g., by the popular press). At this point, we have two
MooreÕs laws:¥TechnologistÕs MooreÕs law: number of transistors per chip doublesevery 18 months, and¥Popular MooreÕs law: computer performance doubles every 2 years.
This popular MooreÕs law has provided incredible opportunities forthe rest of computer science. Everyone from researchers to product
designers can dream up many ideas and ask not whether something will
be practical, but when (assuming, of course, one is not trying to solve
problems that cannot be solved or require execution times that defeat
exponential growth with exponential complexityÑsee Kleinberg andPapadimitriou). This performance has facilitated major achievements,

such as beating a chess grandmaster (Koller and Biermann, in Chapter 6),
more realistic computer graphics (Fedkiw, in Chapter 3), better natural-
language processing (Lee, in Chapter 6), and sequencing the human
genome. In these and other cases, however, tremendous algorithmic and
software advances were also necessary to effectively use faster hardware.Many times, however, cost reduction matters more than increasingperformance. In these cases, rather than using more transistors to obtain
more performance at constant cost, it makes more sense to use a constant
number of transistors to obtain the same performance at reduced cost.
Fortuitously, it turns out that every 2 years or so one can obtain the samelevel of performance for half the cost. In a decade, Jim Gray has observed, itwill be possible to buy an equivalent computer for the sales tax on one
today (even if the sales tax is as low as 3 percent, which approximately
equals 1/25). Cost matters because more cost-effective computation caneffectively be more widely applied. This cost reduction has enabled the
rapid spread of inexpensive computers and enabled the explosive growth
of the Internet (Peterson and Clark, in Chapter 7). Once again, creative
innovations, such as word processors (Ullman, in Chapter 8), spread-
sheets (Foley, in Chapter 8), and compelling multi-user environments
(Bruckman, in Chapter 7) are necessary to make cost-effective hardware
useful.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY331See the International Technology Roadmap for Semiconductors Web site at http://public.itrs.net.Future of MooreÕs Law and BeyondRecently, there have been several accounts predicting the end of thetechnologistÕs MooreÕs law. Since at least the early 1970s, there have beennumerous predictions of its demise. However, technologistsÕ creativity
has repeatedly solved the challenges to keep it on track. We are bullish
that MooreÕs law is safe for at least another decade, due to technologiesalready operating in the laboratory, backed by the motivation and vision
of a trillion-dollar industry.1Nevertheless, it seems probable that the doubling time for conven-tional chips will increase and the doubling will eventually halt as atomic
limits are approached. There is already evidence that the doubling time
for memory chips is now closer to every 2 years instead of every 18
months. A contributing factor to this slowdown is the exponentially
increasing cost of building factories for fabricating chips.Taking a longer view, however, innovation beyond the technologistÕsMooreÕs law is likely. Computing has already been implemented by aseries of technologies: mechanical switches, vacuum tubes, discrete tran-
sistors, and now chips driven by MooreÕs law. Eventually, almost all com-puting technologies will be supplanted by newer ones. One emerging
candidate uses synthetic organic molecules to perform switching and stor-
age. Another seeks to exploit quantum superposition to change both the
model and the implementation of some future computers (see Bennett in
this chapter). Both approaches, however, are unproven and may yet be
surpassed by other technologies, some of which are not yet invented.Moreover, we are not yet close to ÒfundamentalÓ limits. We are many
orders of magnitude from subatomic energy and storage limits imposed
by currently understood physics. Furthermore, there is an existence proof
that it is possible to organize computers in a way that is much better for
many tasks: the human brain.As an aside, some argue that we do not need more computing perfor-mance. While it is indeed the case that other constraints, such as low
power, low noise, and low environmental impact, are becoming more
important, we argue for more cost-effective computer performance. First,
all past predictions that there was enough computing performance have
been wrong. Two decades ago, some predicted that the ultimate personal
computer would support three MÕs: one million instructions per second,one megabyte, and one million display elements. TodayÕs personal com-puters routinely exceed the first two attributes by two orders of magni-
tude and still seem inadequate. Second, there are clear opportunities ofComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.34COMPUTER SCIENCE: REFLECTIONSapplying more computing performance (and more algorithms) to makehuman-computer interactions closer to the natural-language exchanges
envisioned in 2001: A Space Odyssey a third of a century ago. Third, as
computing and communication get more cost-effective, surprising new
applications are likely to be invented. Some of us used mainframes for
decades without predicting the spreadsheet, while others used the
Internet for years without predicting the World Wide Web. It will be
surprising if an order-of-magnitude improvement in cost-effective com-
puter performance does not enable a new disruptive application.Harnessing Future Exponential GrowthIn the coming decades, we seek to harness future technology growth,be it slow, fast, or discontinuous. How will we use more transistors (or
more exotic technologies) to enable hardware that will support the cre-
ative applications being forecast in the rest of this volume?How do we exploit billions and trillions of transistors? (A computerwith one gigabyte of memory, for example, has more than 8 billion transistors.)
One known way is to go beyond bit- and instruction-level parallelism to
also exploit thread-level parallelism. When a processor executes a sequence
of instructions, we say it is executing a thread. Thread-level parallelism is
exploited when software specifies multiple threads to execute and hard-
ware is capable of executing the threads concurrently. Today, several
important applications are specified with multiple threads, including
database management systems (Gray, in Chapter 5) and Web crawlers
(Norvig, in Chapter 8); multiple threading is also used to beat human
chess champions (Koller and Biermann, in Chapter 6). Unfortunately, too
many current applications are programmed with a single thread, even if
the problem could be solved in parallel. Much established business soft-
ware, for example, was written for a single thread, even when the prob-
lem was once solved by many clerks operating in parallel. Nevertheless,
creating multi-threaded software has been difficult. In addition, the motiva-
tion to create it has been reduced by the fact that many current computers
execute only one thread at a time. Emerging techniques for supporting
multiple threads on a microprocessor, however, promise to make multi-
threading hardware much more widely available. Moreover, there is also
tremendous additional potential for using threads executing in parallel
on multiple computers that communicate via local- or wide-area net-
works. In the extreme, computers around the world could be harnessed to
solve problems on demand. This vision is now known as grid computing,
since it strives to deliver customers access to computing resources much
as the power grid delivers customers power. We encourage future efforts
to exploit parallel threads in all their forms, because doing so representsComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY35the best-known way to grow computing performance much faster thanMooreÕs law enables for single processors.We also see additional opportunity provided by technology discontinu-ities 
and synergies. First, MooreÕs law will soon enable a complete (albeitsimple) computer on a chip. TodayÕs personal computers, for example,use a complete processor on a chipÑthe microprocessorÑtogether withseveral memory and support chips. Single-chip computers could dramati-
cally 
cut costs and expand the effectiveness of systems. While we haveprimitive single-chip systems today, more powerful ones might unleash
progress in a manner similar to that unleashed by the increasing perfor-
mance of microprocessors over the last three decades. For at least the next
decade, however, single-chip solutions must focus on systems smaller
than personal computers (because personal computers use too much
memory to fit on a chip). Nevertheless, the history of computing has
shown that new smaller systems are great catalysts for change: main-
frames to minicomputers to personal computers to personal digital assis-
tants to cellular phones. Second, technologists are now fabricating sensors
and emitters on chips. This technology holds the promise of systems that
integrate with their environment at unprecedently low cost. A current
success story is an accelerometer for triggering automobile airbag deploy-
ment. Third, the further integration of computers with communication
will make the world even smaller. Communication, with and without
wires, will enable ubiquitous connectivity. The World Wide Web shows
us how communication magnifies the value of computation. Now, imagine
a Web where you are always online everywhere!Each of these trends will further integrate computers into our lives. Inmany cases, integration allows the computers to Òdisappear.Ó When Emily
clicked to buy a book in the prelude to this volume, she was not even
aware of most of the computers that implemented the transaction. Further-

more, she may not recognize her cellular phone, personal digital assistant,
or pacemaker as computers; an integration that is an appropriate and
natural consequence of our abilities to hide complexity from users.Our success in hiding computers when they work, however, bringswith it a responsibility to hide them when they fail. Imagine Web services
as available as telephones and personal computers as dependable as tele-
visions. Numerous solutions will be needed to enable this dependability,
taking into account needs and appropriate costs. Large commercial sys-
tems may seek 10 to 100 times improvements in availability for small
overheads (e.g., 10 percent), while critical functions like pacemakers may
tolerate tripling hardware costs. In many cases, the underlying hardware
may get more unreliable, because transistors are so small (and susceptible
to cosmic rays) and numerous (more chances to fail). While some im-
provements can be done in hardware, transparently to software, otherComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.36COMPUTER SCIENCE: REFLECTIONSsolutions will require hardware and software changes. In many cases, wewill have to design systems assuming that parts will fail. Unlike the
current Web, however, we should seek to ensure that all systems mask
almost all of those failures from users. By laying a more reliable founda-
tion, we can expand the realms in which society can depend on informa-
tion technology.The last half-century has seen substantial computing advances andimpacts on society. We expect the synergies just discussed to provide
plenty of non-technical and technical challenges and opportunities. For
society, the real information revolution may be coming soon. On the tech-
nical side, there is much work to be done. Arthur C. Clarke said, ÒAnysufficiently advanced technology is indistinguishable from magic.Ó Let
Õscreate some more magic!Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY37COMPUTABILITY AND COMPLEXITYJon Kleinberg, Cornell University, andChristos Papadimitriou, University of California, BerkeleyThe Quest for the Quintic FormulaOne of the great obsessions of Renaissance sages was the solutionof polynomial equations: find an 
x that causes a certain polynomial to
evaluate to 0. Today we all learn in school how to solve quadratic
equations (polynomial equations of degree two, such as ax2 + 
bx + 
c = 
0),even though many of us have to look up the formula every time (itÕs  
  xabbac

124
2/). Versions of this formula were known to theBabylonians as early as 2000 BC, and they were rediscovered in manyancient cultures. The discovery of similar but much more complicated
formulas for solving equations of degree three and fourÑthe cubic andquartic formulaeÑhad to wait until the 16th century AD. During the nextthree centuries, the greatest minds in Europe strove unsuccessfully to
discover the quintic formula, cracking equations of degree five, until the
flowering of modern algebra brought the quest to a sudden, surprising
resolution: a proof that there is no quintic formula.This story, on first hearing, can engender a few natural reactions.Among them, surpriseÑwhatÕs the obstacle to a quintic formula? Whywas it so hard to prove it didnÕt exist? And, more subtly, a mild sense ofperplexityÑwhat do we mean by a quintic formula anyway? Why canÕtwe write Òthe largest x such that 
ax5 + 
bx4 + 
cx3 + 
dx2 + 
ex + 
f = 0
Ó and
declare this to be a formula?So we back up. By a ÒformulaÓ in this story, we meant a particular
thing: a finite sequence of steps that begins with the given values of the
coefficients and ends with a root x; each step consists of one of the basicarithmetic operations applied to certain of the quantities already com-
puted, or else it consists of the extraction of a root of one of the quantities
already computed. Now we can assert more precisely, thanks to the work
of the 19th-century mathematicians Abel and Galois: there is no quintic
formula.Viewed from the safe distance of a few centuries, the story is clearlyone about computation, and it contains many of the key ingredients that
arise in later efforts to model computation: We take a computational
process that we understand intuitively (solving an equation, in this case),
formulate a precise model, and from the model derive some highly unex-
pected consequences about the computational power of the process. It is
precisely this approach that we wish to apply to computation in general.
But moving from this example to a fully general model of computationComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.38COMPUTER SCIENCE: REFLECTIONSrequires some further fundamental ideas, because the notion of a Òfor-mulaÓÑa straight-line recipe of arithmetic operationsÑomits two of thecrucial properties of general-purpose computation. First, computation can
be repetitive; we should be able to perform some action over and over
until a certain stopping condition is satisfied. Second, computation should
contain ÒadaptiveÓ steps of the following form: test whether a certain
condition is satisfied; if it is, then perform action A; if it isnÕt, then performaction B. Neither of these is present in straight-line formulas; but a little
reflection convinces one that they are necessary to specify many of the
other activities that we would consider computational.Computation as a Universal TechnologySo, guided by this intuition, let us move beyond stylized forms ofcomputation and seek to understand general-purpose computation in all
its richnessÑfor if we could do this, then we might find similarly surpris-ing consequences that apply much more broadly. Such was the goal of
Alan Turing in the 1930s, and such was also the goal of a host of other
mathematical logicians at that time.TuringÕs entry in this field is particularly compelling, not so muchbecause of its mathematical elegance but because of its basic, common-
sensical motivation and power. He sought a streamlined mathematical
description of what goes on when a person is performing calculations in a
large notebook: he or she writes down and erases symbols, turns the
pages left or right, keeps a limited number of symbols in his or her
memory. The computing device Turing proposedÑthe Turing machineÑhas access to an infinite sequence of Òpages,Ó each of which can hold only
one symbol. At any time, the machine can be in one of a finite set of
possible Òstates of mindÓÑits working memory. The flow of control pro-ceeds simply as follows: based on its current state, and the symbol it is
currently reading, the machine may write a new symbol on the current
page (erasing the existing one), move to the next or preceding page, and
change its state. Subject to these rules, the Turing machine processes the
input it is given and may eventually choose to halt, at which point the
notebook contains its output.Why should we accept this model? First, it accords well with commonsense. It seems to be the way that symbolic computation, as performed
slowly and painfully by humans, proceeds. Indeed, with some practice,
one can implement seemingly any natural symbolic task on a Turing
machine. Second, it is robustÑa version of the model with very small setsof available symbols and states (say, eight of each) is, in a precise sense,
just as powerful as a version with an arbitrary finite set of each, only the
control rules become more complicated. Moreover, it does not matter thatComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY39the ÒpagesÓ on which the computation is performed are arranged in a
linear sequence; it would not add to the power of the model if we arranged
them instead in an arbitrary web of connections. Finally, and most cru-
cially, TuringÕs model is precisely equivalent to the other formalismsproposed in his day, among them, and preceding it, Alonzo ChurchÕslambda calculusÑand it is also equivalent to modern general-purposeprogramming languages such as C and Java (with access to an arbitrary
amount of memory).For the accumulation of these reasons, we are justified in believingthat we have arrived at the ÒrightÓ model of computation; and this is the
content of the Church-Turing thesis: a symbolic function is computable if
and only if it can be computed on a Turing machine (or its equivalents). It
is important to notice what is being claimed: we have not derived the
notion of ÒcomputabilityÓ from a set of more primitive axioms; rather,
after extensive thought experiments, we have asserted that ÒcomputabilityÓcorresponds precisely to what can be computed on a Turing machine.Accepting the Turing machine as the basis for our precise definitionof computability is a momentous step. Its first consequence is that of
universality: there is a Òuniversal Turing machineÓ U that does the follow-
ing. As input, U receives the description of a Turing machine M (theÒcodeÓ of 
M, written in UÕs book) and an input n to 
M (a later chapter in
the same book). As output, U returns the result, if any, of running 
M on 
n.Today, we would think of U simply as an interpreter
Ñit executes a step-by-step simulation of any Turing machine M presented to it. Indeed, our
style of writing programs and then executing them is so ingrained in our
view of computation that it takes a moment to appreciate the conse-
quences that flow from a universal machine. It means that programs and
data are really the same thing: a program is just a sequence of symbols
that looks like any other piece of input; but when fed to a universal
machine, this input wakes up and begins to compute. Think of mobile
code, Java applets, e-mail viruses: your computer downloads them as
data and then runs them as programs.The principle of interchangeable partsÑthat components of a machinecan be mass-produced independently, and a working whole can be
assembled from a random selection of one part from each kindÑwas thedisruptive insight that underpinned the Industrial Revolution. Universal-
ity is perhaps an even more radical approach to assembling systems: a
single computer on your desk can run your word processor, your spread-
sheet, and your online calendar, as well as new applications not yet con-
ceived of or written. And while this may seem completely natural, most
of technology in fact does not work this way at all. In most aspects of
oneÕs technological life, the device is the application; they are one and thesame. If you own a radio and want to watch TV, you must buy a newComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.40COMPUTER SCIENCE: REFLECTIONSdevice. If you want to drive, you use a car; but if you want to fly, you usean airplane. Your car cannot download a new set of instructions and
suddenly be able to fly, or to maneuver underwater. But the computa-
tional world has a flexibility of application that cannot really be imagined
elsewhereÑand that is because the world of computation is powered byuniversal machines.We have all seen the consequences of this flexibility very clearly in thepast decade, as the World Wide Web became a new medium within a
mere 7 years of its introduction. If we look at other mediaÑat the phone,the radio, the televisionÑit took a much longer time from their inceptionsto widespread prominence. What was the difference? Of course there are
many factors that one can point to, but mingled among them is the uni-
versality of the computers on which Web protocols and interfaces run.
People had already bought personal computers for their homes, and built
office information systems around them, before the Web ever existed.
When the Web arrived, it could spread through this infrastructure with
amazing speed. One cannot really imagine an analogue of this process for
the televisionÑit would be as though millions of Americans had beeninduced to buy large inert boxes for their living rooms, and a decade later
someone dreamed up the technology to begin broadcasting pictures to
them. But this is more or less what happened with the Web.The Limits of ComputationComputer science was born knowing its own limitations. For the
strength of the universal machine leads directly to a second, and more
negative, consequenceÑuncomputability, the fact that certain naturalcomputational tasks cannot be carried out by Turing machines or, by
extension, computer programs. The leap from the notion of universality
to this impossibility result is surprisingly effortless, if ingenious. It is
rooted in two basic issuesÑfirst, the surprising difficulty in determiningthe ÒultimateÓ behavior of a program; and second, the self-referential
character of the universal machine U.To appreciate the first of these, recall that our universal machine Usimply performed a step-by-step simulation of a Turing machine M on an
input n. This means that if M computes forever, never halting, then UÕssimulation of M will run forever as well. This is the notion of an 
Òinfiniteloop,Ó familiar to beginning (and experienced) programmers every-
whereÑyour program keeps running with no sign of any output. Do youstop it and see whatÕs wrong, or wait to see if itÕs just taking longer thanexpected to come up with an answer? We might well want something
stronger than the blind simulation that U provides; we might want a
ÒUniversal Termination DetectorÓÑa Turing machine D that behaves as
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY41follows. Given a description of a Turing machine M and an input 
n to 
M,the machine D performs a finite number of steps, and then correctly
reports whether or not M will ever halt with a result when it is run on 
n.(So in particular, the machine D itself halts on every input.)
Could one build such a thing? OneÕs first reaction is to start dreamingup tricks by which one could look at a program and determine whether it
will halt or notÑlooking for obviously repetitive behavior with no stop-ping condition. But gradually the problem begins to look hopelessly difficult.
Maybe the program youÕre analyzing for termination is systematicallyenumerating the natural numbers, searching for a counter-example to a
famous conjecture in mathematics; and it will only stop when it finds one.
So a demonstration that this single program eventually terminates must
implicitly resolve this mathematical conjecture! Could detecting the ter-
mination of programs really be as hard as automating mathematics?This thought experiment raises the suggestion that we should per-haps be considering the problem from the other direction, trying to show
that it is not possible to build a Universal Termination Detector. Another
line of reasoning that might make us start considering such an impossibil-
ity result is, as suggested above, the self-referential nature of the universal
machine U: U is a Turing machine that can simulate the behavior of any
Turing machine. So, in particular, we could run U on a description of
itself; what would happen? When you find yourself asking questions like
this about a mathematical objectÑquestions in which the object refers toitselfÑthere are often explosive consequences lying just ahead. Indeed,the dangerous properties of self-reference appear in ordinary discourse.
From ancient Greece we have EubulidesÕ paradox, which asserts, 
ÒThisstatement is falseÓ: is this a true statement or a false one? Or considerBertrand RussellÕs hypothetical barber, who only shaves the set of allpeople who do not shave themselvesÑwho then shaves the barberhimself?In the case at hand, we can exploit the self-reference inherent in uni-versality to prove that there is no Universal Termination Detector by
showing that there is no Turing machine that correctly implements a
Universal Termination Detector (Box 2.1).This is a first, fundamental impossibility result for computationÑanatural problem that cannot be solved computationally. And starting with
this result, impossibility spreads like a shock wave through the space of
problems. We might want a Universal Equivalence Tester: given two
Turing machines M and M
, are they equivalent? Do they produce thesame result on every input? But it is easy to convince yourself that if we
could build an Equivalence Tester, we could use it to build a Termination
Detector, which we know cannot exist. And so: There is no Universal
Equivalence Tester. We might want a Universal Code Verifier: given aComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.42COMPUTER SCIENCE: REFLECTIONSBOX 2.1
There Is No Universal Termination DetectorWe begin by observing that the set of all Turing machines, while clearlyinfinite, can be enumerated in a list M1; M2; M3, . . . in such a way that each Turingmachine appears once in the list.To do this, we can write a description of each Turing machine as a sequenceof symbols and then order these descriptions in alphabetical order; we first list alldescriptions with one symbol (if there are any), then all descriptions with two
symbols, and so forth.Our impossibility proof proceeds by assuming that there exists a UniversalTermination Detector; we then show how this leads to a contradiction, establishing
that our initial assumption cannot be valid. So to begin, let D be a Turing machinethat is a Universal Termination Detector.We construct, from D, a Turing machine X that will lead to the contradiction.
On input n, here is what X does. It first invokes the Termination Detector D to
determine whether the machine Mn will ever halt when run with input 
n. (This is thecore of the self-reference: we investigate the behavior of Mn on its own position 
nin the alphabetical listing of Turing machines.) If it turns out that Mn will never halton n, then X halts. But if it turns out that 
Mn will halt when run on 
n, then X gratu-
itously throws itself into an infinite loop, never halting.X is not a very useful program; but that is not the point. The point is to noticethat X is itself a Turing machine, and hence is one of the machines from our list; let
us suppose that X is really 
Mk. The self-reference paradoxes we mentionedaboveÑEubulidesÕ and RussellÕsÑwere both triggered by asking a natural ques-tion that exposed the latent contradiction. Our proof here employs such a question,and it is this: does X halt when it is run on input 
k?We consider this question as follows. Suppose that X halts when it is run on
k. Then, since we know X is really 
Mk, it follows that Mk halts on k; and so, by ourconstruction of X, X should not halt when it is run on 
k. On the other hand, supposethat X does not halt when it is run on 
k. Then, again using the fact that X is really
Mk, it follows that Mk does not halt on k; and so X should halt on k. So neitheroutcome is possibleÑX cannot halt on 
k, and it cannot fail to halt on k! This is acontradiction, so there cannot be such a machine X, and hence there cannot be aUniversal Termination Detector D.This style of proof is often referred to as diagonalization, and it was intro-duced by Cantor to show that one cannot put the real numbers in one-to-onecorrespondence with the integers. The term ÒdiagonalizationÓ here comes from thefollowing intuition. We imagine drawing an infinite two-dimensional table whose
rows correspond to the Turing machines M1; M2; M3; . . . and whose columnscorrespond to all the possible inputs 1; 2; 3; . . . . Each entry of this tableÑsay theentry at the meeting of row i and column 
jÑindicates whether or not machine Mihalts when it is run on input j. Viewed in these terms, our supposed machine XÒwalks down the diagonalÓ of this table; on input k, it consults the table entry at themeeting of row k and column 
k, and essentially inverts the answer that it findsthere.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY43Turing machine M and an ÒundesirableÓ output n, is there any input thatwill cause M to produce the output 
n? But again, from a Code Verifier wecould easily build a Termination Detector. No Termination Detector, no
Code Verifier.Suppose you want to verify that the program youÕve just written willnever access a restricted area of memory; or suppose you want to ensure
that a certain revisionÑa transformation of the programÑwill not causeit to change its behavior. Research in the area of programming languages
has developed powerful techniques for program verification and trans-
formation tasks, and they are used effectively to analyze complex pro-
grams in practice (Aho and Larus, in Chapter 4, discuss the transformation
problem in the context of compiler optimization). Such techniques, how-
ever, are developed in a constant struggle against the negative results
discussed above: over the years researchers have carved out broader and
broader tractable special cases of the problem, but to solve these verifica-
tion and transformation tasks in their full generalityÑto perform themcorrectly on all possible programsÑis provably impossible. Such resultsimpose fundamental limitations on our ability to implement and reason
about complex pieces of software; they are among the laws that constrain
our world.When Finite Is Not Good EnoughComputers, as we think of them now, did not exist when Turingcarried out his seminal work. But by the 1950s and 1960s, as truly auto-
mated computation became increasingly available, a growing amount of
attention was devoted to the study and development of algorithmsÑstep-by-step computational procedures, made precise by the notion of
computability. And as this development began to gather force, it became
clear that uncomputability was only one of the laws that constrained our
ability to solve problems. The world abounded in problems whose solv-
ability was not in doubtÑbut for which solving any but the smallestinstances seemed practically infeasible.Some of the most vivid of these problems came from the area ofoperations research, a field that sprang in large part from the epiphanyÑconceived during World War II, and spilling into civilian life ever afterÑthat there was a science to the efficient coordinated movement of armies
and organizations, the efficient allocation of supplies and raw materials.
Thus, we can consider the Traveling Salesman Problem: You are given a
map of N cities and the distances between them, as well as a 
ÒbudgetÓ B;you must visit all the cities via a tour whose total length is at most B. Orconsider the Matching Problem: You must pair up 2N newly admitted
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.44COMPUTER SCIENCE: REFLECTIONScollege studentsÑsome of whom donÕt like one anotherÑinto N pairs of
roommates, so that each pair consists of students who will get along.In the 1960s, Jack Edmonds came up with a beautiful and efficientalgorithm to solve the Matching Problem; and he wrote a paper describ-
ing the method. But how should one describe the result, actually? ÒAcomputational solution to the Matching ProblemÓ?Ñthis is not quite right,since thereÕs an obvious way to solve it: try all possible pairings, and seeif any of them works. There was no question that the Matching Problem
had a computable solution in TuringÕs sense. The crux of the result was inthe efficiency of the solution. Jack Edmonds understood this difficulty
very clearly: ÒI am claiming, as a mathematical result, the existence of agood algorithm for finding a . . . matching in a graph. There is an obvious
finite algorithm, but that algorithm increases in difficulty exponentially
with the size of the graph. It is by no means obvious whether or not there
exists an algorithm whose difficulty increases only algebraically with the
size of the graph.ÓIt is hard to find much to add to this. There is clearly an algorithm thatsolves the Matching Problem in a number of steps that is exponential in
NÑat least N factorial. But try to imagine how long this would take. Even
on the fastest computers we have today the problem of forming 30 pairs
could require an amount of time comparable to the age of the universe.
Yes, the solution is computable; yes, we can even imagine how the whole
computation will proceed; but such a method is of no real value to us at
all if we are seeking a solution to a problem of even moderate size. We
need to find a qualitatively faster method; and this is exactly what Jack
Edmonds had accomplished.EdmondsÕs concern with Ògood algorithmsÓ fit naturally into a
research agenda that was being pursued contemporaneously by Juris
Hartmanis and Richard StearnsÑthat of determining the intrinsic com-putational complexity of natural problems, by determining the smallest
number of computational steps that are required to produce a solution.
And so, following this line of attack, we seek algorithms that require only
Òpolynomial timeÓÑon an input of size N, a ÒgoodÓ algorithm should use
a number of steps that is bounded by a polynomial function of N such as
N2 or 
N5. Clearly polynomial functions grow much more slowly thanexponential ones, and they have a very desirable scaling propertyÑif youincrease your input size by a constant multiplicative factor, the running
time goes up by a predictable constant factor as well. But however much
one tries to justify our interest in polynomial time on theoretical grounds,
its primary justification follows the same lines as the Church-Turing thesis
that we saw earlier: it accords well with our experience from practice.
Problems solvable by polynomial-time algorithms tend overwhelmingly
to be efficiently solvable in practice; and for problems that lack polynomial-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY45time algorithms, one tends to encounter enormously difficult instanceswith some regularity.The choice of polynomial time as a mathematical surrogate for effi-ciency has served computer science very wellÑit has been a powerfulguide to the design of good algorithms. And algorithmic efficiency has
proved to be a far subtler concept than we could have imagined. Consider
again the Traveling Salesman Problem and the Matching Problem. For
each, the Òsearch spaceÓ is enormous: for the Traveling Salesman, any
ordering of the N cities forms a tour that must in principle be considered;
for the Matching Problem, any set of pairs that matches all of them is a
candidate solution. And yet, despite similarities at this level, their
behavior from the point of view of computational difficulty seems to be
utterly divergent. Matching has a polynomial-time algorithm, and very
large problems are solved every day in practice. For the Traveling Sales-
man Problem, on the other hand, we are famously without a polynomial-
time algorithm, and the solution of relatively small instances can still
require a major computational effort.Where does this enormous difference in computational complexitylie? What features of a computational problem determine its underlying
difficulty? The ongoing effort to resolve these questions is a core research
activity in computer science today; it has led to a rich theory of computa-
tional intractabilityÑincluding the notion of NP-completeness, which hasspread from computer science into the physical, natural, and social sci-
ences. It has also led to the celebrated ÒP versus NPÓ question (Box 2.2),
which has drawn the attention of mathematicians as well as computer
scientists and is now featured on several lists of the foremost open ques-
tions in mathematics.Exponential growth is a recurring theme in computer science, and it isrevealing to juxtapose two of its fundamental roles: in MooreÕs law, whichcharts the exponential growth in the power of computing machinery (see
HillÕs essay in this chapter), and in computational complexity, whichasserts that the effort needed to solve certain problems grows exponen-
tially in their size. Do these two principles cancel out? If our computing
power is growing exponentially over time, will we really be bothered by
problems of exponential complexity? The answer is that MooreÕs lawdoes not make our concerns about exponential complexity go away, and
it is important to realize why. The full search space for a 17-city instance
of the Traveling Salesman Problem is 16 times larger than the search
space for a 16-city instance. So if exhaustively searching the space of
solutions for a 16-city problem is at the limit of your current computerÕsabilities, and if computing power doubles every year and a half, then
youÕll need to wait 6 years before your new computer can tackle a 17-cityproblem by brute forceÑ6 years to be able to solve a problem that is onlyComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.46COMPUTER SCIENCE: REFLECTIONSBOX 2.2
Does P Equal NP?We have been concerned with the set of all problems that can be solved by apolynomial-time algorithm; letÕs use P to denote this set of problems.Now, we believe that the Traveling Salesman Problem is very difficult to solvecomputationally; it is likely that this problem does not belong to the set P we havejust defined. But there is at least one good thing we can say about its tractability.
Suppose we are given N cities, the distances between them, and a budget B; andsuppose that in fact there exists a tour through all these cities of length at most B.Then there exists a way for someone to prove this to us fairly easily: he or she
could simply show us the order in which we should visit the cities; we would thentabulate the total distance of this tour and verify that it is at most B.So the Traveling Salesman Problem may not be efficiently solvable, but it is atleast efficiently verifiable: if there is a short tour among the cities we are given, thenthere exists a ÒcertificateÓÑthe tour itselfÑthat enables us to verify this fact inpolynomial time. This is the crux of the Traveling Salesman ProblemÕs complexity,coiled like the ÒtrickÓ that helps you solve a difficult puzzle: it
Õs hard to find a shorttour on your own, but itÕs easy to be convinced when the short tour is actuallyrevealed to you. This notion of a certificateÑthe extra piece of information thatenables you to verify the answerÑcan be formalized for computational problemsin a general way. As a result, we can consider the set of all problems that areefficiently verifiable in this sense. This is the set NPÑthe set of all problems forwhich solutions can be checked (though not necessarily solved) in polynomial time.It is easy to show that any problem in P must also belong to NP; essentially,this is as easy as arguing that if we can solve a problem on our own in polynomial
time, then we can verify any solution in polynomial time as wellÑeven without thehelp of an additional certificate. But what about the other side of the question: isthere a problem that belongs to NP but not to P, a problem for which verifying is
easy but solving is hard? Although there is widespread belief that such problemsmust exist, the issue remains unresolved; this is the famous ÒP versus NPÓ question.
To address this question, it is natural to seek out the ÒhardestÓ problems in
NP, for they are the best candidates for problems that belong to NP but not to P.one city larger! Waiting for MooreÕs law to deliver better computingpower only gets you so far, and it does not beat down the exponential
complexity of a deeply intractable problem. What is needed is not just
better hardware on which to apply brute force, but also a better algorithm
for finding a solutionÑsomething like what Edmonds found for theMatching Problem.The fact that simply-stated problems can have enormous complexity,with solutions that are computationally very difficult to find, has led to
new perspectives on a number of well-studied ideas. Cryptography hasComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY47How can we formalize the notion that one problem is at least as hard as another?The answer lies in reducibility, an idea that came up implicitly when we discussed
computational impossibility. We say that a problem A is 
ÒreducibleÓ to a problem 
Bif, given a Òblack boxÓ capable of solving instances of 
B in polynomial time, we can
design a polynomial-time algorithm for A. In other words, we are able to solve A by
drawing on a solution to B as a 
Òresource.Ó It follows that if we actually had a
polynomial-time algorithm for problem B, we could use this as our Òblack box,Ó and
hence design a polynomial-time algorithm for problem A. Or, simply running thisreasoning backward, if there is no polynomial-time algorithm for A, then there cannotbe a polynomial-time algorithm for B: problem B is at least as hard as problem 
A.So here is a natural thing we might search for: a single problem B in NP withthe property that every problem in NP is reducible to B. Such a problem would,quite conclusively, be among the hardest problems in NPÑa solution to it wouldimply a solution to everything in NP. But do such problems exist? Why should
there be a single problem that is this powerful?In the early 1970s, Steve Cook in North America and Leonid Levin in theSoviet Union independently made the crucial breakthrough, discovering a number
of natural problems in NP with precisely this property: everything in NP can bereduced to them. Today we say that such a problem is ÒNP-complete,Ó and
research over the past decades has led to the discovery that there are literally
thousands of natural NP-complete problems, across all the sciences. For example,determining the winner(s) under a wide variety of election and auction schemes isNP-complete. Optimizing the layout of the gates in a computer chip is NP-
complete. Finding the folding of minimum energy for discrete models of proteins isNP-complete. The Traveling Salesman ProblemÑthe tough nut that started us onthis roadÑis NP-complete. And an important thing to bear in mind is this: becauseevery problem in NP is reducible to any of these, they are all reducible to eachother. There is a polynomial-time algorithm for one if and only if there is a polynomial-time algorithm for all. So we have come to realize that researchers in a host of
different areas, struggling over a spectrum of computationally intractable prob-lems, have in a fairly precise sense all been struggling over the same problem; thisis the great insight that NP-completeness has given us. The original question
remains open.been revolutionized by the theory of complexity, for the design of securecommunication protocols is a field that exists in a mirror-world where
difficult computational problemsÑcodes that are easy to apply and hardto breakÑare resources to be cultivated (see Sudan in Chapter 7). TheRSA public-key cryptosystem was inspired by the presumed difficulty of
factoring large integers, with the prime factors of a number N forming the
hidden ÒkeyÓ whose knowledge allows for easy decryption. The age-old
notion of randomnessÑa concept that is intuitively apparent but notori-ously tricky to defineÑhas been given an appealing formalization basedComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.48COMPUTER SCIENCE: REFLECTIONSon computational complexity: a sequence of digits appears ÒrandomÓ to
an observer if it is computationally difficult for the observer to predict the
next digit with odds significantly better than guessing.For designers of algorithms, we have seen that their struggle with thecomplexity of computation has proceeded at a number of different levels.
One boundary divides the computable from the uncomputableÑit is fea-sible to build a step-by-step interpreter for computer programs, but one
cannot design an algorithm that decides whether arbitrary programs will
terminate. Another boundary divides polynomial-time solvability from
the exponential growth of brute-force search. But while polynomial time
is indeed a good high-level means for gauging computational tractability,
there are an increasing number of applications, typically involving very
large datasets, where simply having a polynomial-time algorithm is far
from adequate. Suppose the size of the input is measured in terabytes
(millions of megabytes); an algorithm that takes a number of steps equal
to the cube of the input size is no more useful in practice than one that
never terminates.None of this is to say that polynomial time has lost its relevance to thedesign of algorithms. But for many large-scale problems, we are faced
with a reprise of the situation in the 1950s and 1960s, when we tumbled
from a concern with computability to a concern with computational com-
plexity: as our real-world computational needs expand, our guidelines for
what constitutes an ÒacceptableÓ algorithm become increasingly stringent.
And this in turn has led to new lines of research, focusing for example on
algorithms that must run in time very close to the size of the input itself;
algorithms that must ÒstreamÓ through the input data in one pass, unable
to store significant parts of it for post-processing.While algorithm design has deepened into the study of increasinglytime-efficient techniques, it has also opened outward, revealing that run-
ning time is just one of many sources of complexity that must be faced. In
many applicationsÑscheduling under real-time conditions, or managinga busy networkÑthe input is not a static object but a dynamic one, withnew data arriving continuously over time. Decisions must be made and
solutions must be constructed adaptively, without knowledge of future
input. In other applications, the computation is distributed over many
processors, and one seeks algorithms that require as little communication,
and synchronization, as possible. And through all these settings, from
NP-complete problems onward, algorithms have been increasingly
designed and analyzed with the understanding that the optimal solution
may be unattainable, and that the optimum may have to serve only as an
implicit benchmark against which the quality of the algorithmÕs solutioncan be measured.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY49The Lens of ComputationOur contemplation of computation has led us quickly to the ÒP versusNPÓ question, now considered among the deepest open problems in math-
ematics and computer science. More recently, our views on complexity
have been influenced by the striking confluence of computation and quan-
tum physics: What happens to our standard notions of running time and
complexity when the computation unfolds according to the principles of
quantum mechanics? It is now known that access to such a hypothetical
Òquantum computerÓ would yield polynomial-time algorithms for cer-
tain problems (including integer factorization and the breaking of the
RSA cryptosystem) that are believed to be intractable on standard com-
puters. What are the ultimate limits of quantum computers? And are
there theoretical obstacles to building them (in addition to the practical
ones currently braved in labs all over the world)? These questions, purely
computational in their origin, present some of the most daunting chal-
lenges facing theoretical physics today.Biology is a field where the synergy with computation seems to goever deeper the more we look. Let us leave aside all the ways in which
sophisticated algorithmic ideas are transforming the practice of biology
with vast genomic and structural databases, massive numerical simulations
of molecules, and the fearsome symbol-crunching of the Human Genome
Project. Instead, consider how we might view molecular biology itself
through a computational lens, with the cell as an information-processing
engine. For fundamentally, a biological system like a cell is simply a
chemical system in which the information content is explicit. The genome
is part of the overall chemical system, but it is not there to take part in the
chemistry itself; rather, it is there as a sophisticated encoding of the chemi-
cal processes that will take place. It is a programming abstractionÑit isthe representation of the real thing, co-existing with the thing itself.Just as computation distinguishes itself from the rest of technology,so are biological systems intrinsically different from all other physical and
chemical systemsÑfor they too have separated the application from thedevice. We can take a cell and change a few symbols in its genomeÑsplicein a new gene or twoÑand we can cause its chemistry to change com-pletely. We have replaced one piece of code with another; the deviceÑthecellular hardwareÑhas been left alone, while we simply changed theapplication running on it. This phenomenon really seems to have no par-
allel in the other sciences. Surely, the non-biological world obeys funda-
mental laws, but it does not containÑand actually implementÑan explicitrepresentation of these laws. Where in the solar system are the few mol-
ecules, encoding the laws of gravity and motion, which we could modify
to cause the planets to follow more eccentric orbits?Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.50COMPUTER SCIENCE: REFLECTIONSComputation as a technology that follows its own laws; computationas the quintessence of universality; computation as a powerful perspec-
tive on the world and on scienceÑthese are issues that still drive ourstudy of the phenomenon today. And the more we grapple with the
underlying principles of computation, the more we see their reflections
and imprints on all disciplinesÑin the way structured tasks can be cast asstylized computational activities; in the surprising complexity of simple
systems; and in the rich and organic interplay between information
and code.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY51QUANTUM INFORMATION PROCESSINGCharles H. Bennett, IBM ResearchComputer science is based on a very fruitful abstraction whose rootsare as old as mathematics but whose power was fully appreciated only in
the 20th century: the notion that information and computation are a
worthwhile object of study in their own right, independent of the physical
apparatus used to carry the information or perform the computation.
While at the most obvious level, MooreÕs law (see Hill in this chapter) is ahardware success story, this success has only been possible because infor-
mation is such an abstract stuff: make a bit a thousand times smaller and
it remains useful for the same purposes as before, unlike a thousand-fold
smaller car or potato.Although MooreÕs law has survived many early predictions of itsdemise, no exponential growth can go on forever. The present few decades
are clearly an exceptional time in the history of computing. Sooner or later
something will have to give, since at the present rate of shrinkage, infor-
mation technology will reach atomic dimensions within 20 years. Accord-
ingly, considerable thought and long-range planning are already being
devoted to the challenges of designing and fabricating devices at the
atomic scale and getting them to work reliably, a field broadly known as
nanotechnology. However, it has long been known that atoms and other
tiny objects obey laws of quantum physics that in many respects defy
common sense. For example, observing an atom disturbs its motion, while
not observing it allows it to spread out and behave as if it were in several
different places at the same time. Until recently, computer designers
considered such quantum effects mostly as a nuisance that would cause
small devices to be less reliable and more error-prone than their larger
cousins.What is new, and what makes quantum informatics a coherent disci-pline, rather than a vexing set of technological problems, is the realization
that quantum effects are not just a nuisance; rather, they offer a new and
more comprehensive way of thinking about information, which can be
exploited to perform important and otherwise impossible information-
processing tasks. Already they have been used to create unconditionally
secure cryptographic key agreement protocols, and in the future, if a
quantum computer can be built, it could easily perform some computa-
tions (most notably the factorization of large numbers) that would take
longer than the age of the universe by the best known algorithms, not
only on todayÕs supercomputers, but also on the supercomputers of 2050(by which time we predict MooreÕs law will have ended).Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.52COMPUTER SCIENCE: REFLECTIONSThe way in which quantum effects can speed up computation is not asimple quantitative improvement, such as would result from using a faster
processor, or some fixed number of parallel processors to speed up com-
putations by some constant factor depending on the hardware. Rather it
is a qualitative improvement in the functional form of the computation
cost, similar to what one typically gets by discovering a smarter algorithm
to solve a problem that previously seemed hard. With quantum informa-
tion processing the physical form of information, for the first time, has a
qualitative bearing on the efficiency with which it can be processed, and
the things that can be done with it. Quantum computers do not speed up
all computations equally: a few, like factoring, are sped up super-
polynomially; general NP search problems like the Traveling Salesman
Problem are sped up quadratically, while other problems are not sped up
at all.But to say quantum computers offer the hope of using physical effectsto dramatically speed up some computations is putting things backwards.
In hindsight, it should rather be said that the laws of quantum physics,
which as far as we know today apply to everything in the universe,

provide a more powerful arsenal of physically performable mathematical
operations than Turing imagined when he formalized the notion of a
computer. Availing ourselves of this more powerful arsenal, although it
does not enlarge the class of computable functions, makes some computa-
tional problems qualitatively easier than they seemed before. Unlike the
former hope of a qualitative speedup from analog processing, which has
largely been dashed by the ability of digital computers, via discrete
approximation to simulate analog processes more accurately than they
can be reproducibly performed in nature, quantum computation offers a
realistic hope of qualitatively enlarging the scope of feasible computation.However, it should be noted that actually building a useful quantumcomputer presents formidable technical challenges, which will probably
be overcome eventually, but not any time soon. The confidence that these
obstacles can ultimately be overcome rests largely on the theory of
quantum error correction and fault tolerance, developed since 1995. This
theory, which is analogous to the classical theory of fault tolerance devel-
oped by von Neumann and others in the days when computers were
made of vacuum tubes and relays, allows arbitrarily large reliable quan-
tum computations to be done on imperfect hardware, provided the hard-
ware exceeds some threshold of reliability. The technical problem is that
the quantum threshold is higher than the classical threshold discovered
by von Neumann, while todayÕs quantum computing hardware processesquantum information far less reliably than vacuum tubes process classical
information, so there remains a gap of several orders of magnitude thatComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY53still needs to be closed. There is every reason to believe it can be closed,but how and when remain to be seen.Just how do quantum information and the hardware used to processit differ from the ordinary classical type of information processing for-
malized by Turing? States of a Turing machine tape, or any other digital
storage medium, are in principle reliably distinguishable, and the tape
can be copied accurately without disturbing it. This is a reasonable ideali-
zation of the behavior of macroscopic information processing hardware
like punch cards, electromechanical relays, and even todayÕs mostadvanced microprocessors and memory chips. But it has been known
since the early 20th century that at an atomic and subatomic scale actual
matter behaves more subtly: not all states are reliably distinguishable
even in principle, and information stored in such states cannot be copied
without disturbing it. Speaking metaphorically, quantum information is
like the information in a dream: attempting to describe your dream to
someone else changes your memory of it, so you begin to forget the dream

and remember only what you said about it.This dreamlike behavior notwithstanding, quantum information obeysexact and well-understood laws. The so-called superposition principle holds
that the possible states of any physical system correspond to directions in
a d-dimensional space (ÒHilbert spaceÓ), where the dimension d is charac-
teristic of the system and represents the systemÕs maximum number ofreliably distinguishable states. Two states are reliably distinguishable if
and only if their Hilbert space directions are orthogonal (as is usually the
case with macroscopic systems). Physically implementable operations on
the system always conserve or reduce distinguishability, corresponding
roughly to rigid rotations and projections in the Hilbert space. In the
simplest nontrivial case d = 2 and the system (e.g., the internal state of anelectron or photon, for example) is called a qubit. If two reliably distin-guishable states of the qubit (e.g., horizontal and vertical polarizations for
a photon) are arbitrarily designated |0> and |1>, a general state may be
expressed as a linear combination |0> +|1>, where  and 
 are com-
plex numbers such that ||2 + ||2 = 1. Another quantum principle, theprojection postulate, holds that if a qubit in this state is subjected to anobservation that would reliably distinguish |0> from |1>, the qubit
behaves like |0> with probability ||2 and like |1> with probability
||2. Observing the system again yields no new information: the systemagain behaves like |0> or |1> according to the result of the first observa-
tion. More generally, observing a quantum system causes it to behave
probabilistically, losing information about its previous state, except when
the system was already in one of the states the observation was designed
to distinguish. The art of quantum computing consists of accurately pre-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.54COMPUTER SCIENCE: REFLECTIONSparing the quantum computer in a desired initial state, performing asequence of accurately controlled manipulations (rotations) of its state
without observing it during the intermediate stages of the computation,and then finally observing the final state to obtain a useful output.This may sound a lot like analog computation, which is not believedto be significantly more powerful than conventional digital computation.
How, one might ask, can a qubitÑsay a photon, which may be polarizedat an arbitrary angle  relative to the horizontal
Ñbe more powerful thanan analog systemÑsay a mechanical wheel oriented at angle  relative tosome standard position? At first sight, the wheel would appear more
powerful. Not only can its orientation be accurately manipulated, but also
the orientation (unlike a photonÕs) can be observed quite precisely with-out significantly disturbing it. The essential difference, which makes quan-
tum computation more powerful than analog computation, comes from
the way individual information-bearing subsystems (e.g., qubits) com-
bine to form a larger system (e.g., a quantum register, or a whole quantum
computer). An n qubit register has 2
n reliably distinguishable states corre-
sponding to the n-bit strings |000É> through |111É1>; more generallythe Hilbert space of a compound quantum system has a dimensionality
equal to the product of the Hilbert space dimensions of its parts. By the
superposition principle, the general state of an n qubit register corre-
sponds to a direction in a 2n dimensional space; and during the computa-
tion the state may undergo controlled rotations in this large space. By
contrast, an n wheel analog computer
Õs state lives in a parameter space ofonly n dimensions; more generally, an analog system
Õs parameter spacehas a dimensionality equal to the sum of the dimensionalities of its parts.
The quantum computerÕs advantage comes from its enormously largerstate space. However, the advantage is rather subtle, because at the end of
a quantum computation, in order to get a classical output, it is necessary
to make an observation, and, by the projection postulate, doing so col-
lapses the 2n parameter quantum state back down to 
n classical bits. This
severe bottleneck at the end of the computation means that an n qubit
quantum computer cannot process any greater volume of information
than an n bit classical computer. However, for some computations, it can
do the processing in far fewer steps because of the extra maneuvering
room the large Hilbert space provides during intermediate stages of the
computation.As noted earlier, the big technical barrier to be overcome in construct-ing a quantum computer is to make the rate of hardware errors, during
the unobserved portion of the computation preceding the final observa-
tion, sufficiently small. This is qualitatively similar to the problem digital
computers faced in the era of vacuum tubes and relays, but quantitatively
worse, because a quantum computer needs to be isolated much moreComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.EXPONENTIAL GROWTH, COMPUTABILITY, AND COMPLEXITY55carefully from its environment to attain a given level of reliability. Inparticular, because of the disturbing effect of observation on quantum
systems, quantum computers must be designed to prevent information
about the data being processed from leaking out of the computer into the
environment before the end of the computation. (If such premature leak-
age took place, the computation would begin to behave like a classical
probabilistic computation instead of a quantum one, and the advantages
of quantum speedup would be lost.) Fortunately the formalism of quan-
tum error correction and fault tolerance allows arbitrarily good protection
against such leakage to be achieved, provided the basic hardware exceeds
some finite threshold of reliability.Aside from computation per se, quantum information science includesthe disciplines of quantum communication and quantum cryptography.
The latter field is at a far more mature stage of development than is
quantum computation per se, with successful laboratory experiments and
even a few startup companies. Quantum cryptography is based on the
fact that eavesdropping on quantum systems disturbs them. In a typical
implementation, a random sequence of N faint polarized light pulses is
sent through an optical fiber, after which the sender and receiver, by
public discussion of the sent and received signals, estimate the amount of
disturbance and hence of potential eavesdropping. If it is too great, they
abort the protocol. Otherwise they can proceed to derive from the sent
and received signals a shorter sequence of random secret key bits on
which the eavesdropper has arbitrarily little information. More precisely
it can be shown that any eavesdropping strategy obeying the laws of
quantum physics, even when assisted by unlimited computing power,
yields only exponentially little expected information on the final key
sequence, if any. The eavesdropper thus faces the dilemma of eavesdrop-
ping gently and learning essentially nothing, or eavesdropping strongly
and causing the protocol to abort. Quantum cryptography is practical
because it does not require a full fledged quantum computer, only classi-
cal computers supplemented by equipment for generating, transporting,
and detecting quantum signals, all of which are available today. Unlike
classical methods of key agreement, it is unconditionally secure, and thus
impervious to future improvements in algorithms or computing power.Although it was inspired by physics, quantum information process-ing is a mathematically coherent and well-characterized extension of clas-
sical information processing. Indeed the latter can now best be viewed as
a useful but limited subset of the larger subject of quantum information
processing, somewhat as the real numbers are a useful but limited subset
of the complex numbers. To continue the analogy, quantum information
processing provides solutions, or improved solutions, to some problems
in classical computation and cryptography, just as the complex planeComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.56COMPUTER SCIENCE: REFLECTIONSprovides solutions and insights into problems in real analysis not explic-itly involving complex variables. For this reason, even aside from its tech-
nological implications, quantum informatics is an intellectually exciting
discipline, with far-reaching implications for the basic mathematical and
physical sciences, both theoretical and experimental. It is already provid-
ing new ways of thinking about a wide variety of scientific and technical
questions, and has begun to affect how science is taught, in a way that will
bring a deeper understanding of the fruitful abstraction that is informa-
tion not only to computer scientists but also to a broad segment of the lay
public.For further information:¥Jozef Gruska, Quantum Computing (McGraw-Hill, 1999, ISBN 007 709503 0)
¥Michael Nielsen and Isaac L. Chuang, Quantum Computation and QuantumInformation (Cambridge University Press, 2000, ISBN 0 0521 63235 8)
¥U.S. National Science Foundation report on quantum information science:
http://www.nsf.gov/pubs/2000/nsf00101/nsf00101.htm¥Online course notes:http://www.theory.caltech.edu/%7Epreskill/ph219/
http://www.cs.berkeley.edu/~vazirani/qc.html¥Other quantum information Web sites:http://www.research.ibm.com/quantuminfo/
http://www.iro.umontreal.ca/labs/theorique/index.html.en
http://www.qubit.org/Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.573SimulationIn Chapter 2, the essay by Kleinberg and Papadimitriou discusses theuniversality of computers. To exploit this universality, we must spe-
cialize the computing engine to a specific task. This specializationultimately takes the form of a program, but the program does not appear
by magicÑits creator needs to understand the task deeply. Further, a
program must handle all variants of the task, not just those that the pro-
grammer can imagine. Usually we address this challenge by creating a
model of the taskÕs problem domain. The model may be expressed in many
different ways, but it can be understood in isolation from any particular
program that implements it.  These models may be designed to match

physical reality, or they may express alternative sets of laws. In this way,
simulation allows computer scientistsÑand othersÑto explain phenomena
that may be difficult, dangerous, or impossible to explore in reality.The use of digital computer simulations for scientific research is half acentury old. Strogatz reflects on the explanatory power of FermiÕs early
simulations and their profound effects. These early models of nonlinear
systems gave better insight into the underlying phenomena than either
the physical experiments (which proceeded too fast) or the math (which
was too hard for the times).Fedkiw describes the modern analog of FermiÕs experimentsÑthe useof simulation to visualize complex phenomena such as turbulent flow. He
shows how this mode of research complements the use of experiments
and closed-form mathematics.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.58COMPUTER SCIENCE: REFLECTIONSTHE REAL SCIENTIFIC HERO OF 1953Steven Strogatz, Cornell UniversityNOTE: Originally published in the New York Times,this op-ed appeared on March 4, 2003.Reprinted by permission of the author.Last week newspapers and magazines devoted tens of thousands ofwords to the 50th anniversary of the discovery of the chemical structure
of DNA. While James D. Watson and Francis Crick certainly deserved a
good party, there was no mention of another scientific feat that also turned
50 this yearÑone whose ramifications may ultimately turn out to be asprofound as those of the double helix.In 1953, Enrico Fermi and two of his colleagues at Los Alamos Scien-tific Laboratory, John Pasta and Stanislaw Ulam, invented the concept of
a Òcomputer experiment.Ó Suddenly the computer became a telescope for
the mind, a way of exploring inaccessible processes like the collision of
black holes or the frenzied dance of subatomic particlesÑphenomenathat are too large or too fast to be visualized by traditional experiments,
and too complex to be handled by pencil-and-paper mathematics. The
computer experiment offered a third way of doing science. Over the past
50 years, it has helped scientists to see the invisible and imagine the
inconceivable.Fermi and his colleagues introduced this revolutionary approach tobetter understand entropy, the tendency of all systems to decay to states
of ever greater disorder. To observe the predicted descent into chaos in
unprecedented detail, Fermi and his team created a virtual world, a simu-
lation taking place inside the circuits of an electronic behemoth known as
Maniac, the most powerful supercomputer of its era. Their test problem
involved a deliberately simplified model of a vibrating atomic lattice,
consisting of 64 identical particles (representing atoms) linked end to end
by springs (representing the chemical bonds between them).This structure was akin to a guitar string, but with an unfamiliarfeature: normally, a guitar string behaves ÒlinearlyÓÑpull it to the sideand it pulls back, pull it twice as far and it pulls back twice as hard. Force
and response are proportional. In the 300 years since Isaac Newton
invented calculus, mathematicians and physicists had mastered the analy-
sis of systems like that, where causes are strictly proportional to effects,
and the whole is exactly equal to the sum of the parts.But thatÕs not how the bonds between real atoms behave. Twice thestretch does not produce exactly twice the force. Fermi suspected that thisComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.SIMULATION59nonlinear character of chemical bonds might be the key to the inevitableincrease of entropy. Unfortunately, it also made the mathematics impen-
etrable. A nonlinear system like this couldnÕt be analyzed by breaking itinto pieces. Indeed, thatÕs the hallmark of a nonlinear system: the partsdonÕt add up to the whole. Understanding a system like this defied allknown methods. It was a mathematical monster.Undaunted, Fermi and his collaborators plucked their virtual stringand let Maniac grind away, calculating hundreds of simultaneous inter-
actions, updating all the forces and positions, marching the virtual string
forward in time in a series of slow-motion snapshots. They expected to
see its shape degenerate into a random vibration, the musical counterpart
of which would be a meaningless hiss, like static on the radio.What the computer revealed was astonishing. Instead of a hiss, thestring played an eerie tune, almost like music from an alien civilization.
Starting from a pure tone, it progressively added a series of overtones,
replacing one with another, gradually changing the timbre. Then it
suddenly reversed direction, deleting overtones in the opposite sequence,
before finally returning almost precisely to the original tone. Even
creepier, it repeated this strange melody again and again, indefinitely, but
always with subtle variations on the theme.Fermi loved this resultÑhe referred to it affectionately as a Òlittlediscovery.Ó He had never guessed that nonlinear systems could harbor
such a penchant for order.In the 50 years since this pioneering study, scientists and engineershave learned to harness nonlinear systems, making use of their capacity
for self-organization. Lasers, now used everywhere from eye surgery to
checkout scanners, rely on trillions of atoms emitting light waves in
unison. Superconductors transmit electrical current without resistance,
the byproduct of billions of pairs of electrons marching in lockstep. The
resulting technology has spawned the worldÕs most sensitive detectors,used by doctors to pinpoint diseased tissues in the brains of epileptics
without the need for invasive surgery, and by geologists to locate oil
buried deep underground.But perhaps the most important lesson of FermiÕs study is how feebleeven the best minds are at grasping the dynamics of large, nonlinear
systems. Faced with a thicket of interlocking feedback loops, where every-
thing affects everything else, our familiar ways of thinking fall apart. To
solve the most important problems of our time, weÕre going to have tochange the way we do science.For example, cancer will not be cured by biologists working alone. Itssolution will require a melding of both great discoveries of 1953. Many
cancers, perhaps most of them, involve the derangement of biochemical
networks that choreograph the activity of thousands of genes and pro-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.60COMPUTER SCIENCE: REFLECTIONSteins. As Fermi and his colleagues taught us, a complex system like thiscanÕt be understood merely by cataloging its parts and the rules govern-ing their interactions. The nonlinear logic of cancer will be fathomed only
through the collaborative efforts of molecular biologistsÑthe heirs toDr.Watson and Dr. Crick
Ñand mathematicians who specialize in com-plex systems, the heirs to Fermi, Pasta, and Ulam.Can such an alliance take place? Well, it can if scientists embrace theexample set by an unstoppable 86-year-old who, following his co-discovery
of the double helix, became increasingly interested in computer simula-
tions of complex systems in the brain.Happy anniversary, Dr. Crick. And a toast to the memory of EnricoFermi.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.SIMULATION61MAKING A COMPUTATIONAL SPLASHRonald Fedkiw, Stanford UniversityHave you ever sat in a movie theater with a box of popcorn and a softdrink watching a movie like The Perfect Storm and wondered where Holly-
wood found a cameraman brave enough to operate a camera under such
dangerous conditions? Well, that particular cameraman was sitting in a
small office north of San Francisco at a company called Industrial Light
and Magic, which was founded in 1975 by George Lucas of Star Warsfame. There, a computer graphics specialist, our Òcameraman,Ó safely
operated the camera with the mouse attached to his computer. In fact, the
camera was little more than a computer program that calculated the rela-
tive positions of boats and waves in order to add captivating imagery to a
tale about fishermen struggling with treacherous waves on rough seas.
Hollywood films are created to captivate and entertain, and thus they
frequently contain exciting scenes with natural phenomena such as water
waves, smoke, tornados, or even lava erupting from volcanoes. Obvi-
ously, weÕre not going to put George Clooney on a boat in the middle ofthe Atlantic Ocean and subsequently pulverize it with waves until it sinks.
In fact, weÕre not going to put anyone on a boat in such a treacherousstorm, assuming we could even find such a storm in the first place. It
turns out to be a lot easier to make waves out of math than out of water.For centuries, applied mathematicians and physicists have derivedmathematical equations describing the behavior of a variety of substances
including water waves in the ocean and the metal hull of a ship (Box 3.1).
These equations are quite complicated and can be solved only in special
situations or with the aid of simplifying assumptions that usually rule out
problems of practical interest. However, in the last half century, the advent

of computer technology has led to a revolution in the study of these types
of equations. Using approximation theory, numerical analysts have
devised a number of algorithms that enable one to program computers to
estimate solutions to many of the equations governing the physical world
to any desired accuracy. Moreover, these numerical solutions provide
useful information for practical problems of interest to both scientists and
engineers.Solving such problems falls into an area of research referred to asÒscientific computing.Ó Scientific computing has become the third branch
of research in many engineering departments, joining theory and experi-
ment as classical approaches to obtaining information about the world
around us. While scientific computing has classically been applied to
physical problems such as those faced in mechanical, aerospace, and struc-
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.62COMPUTER SCIENCE: REFLECTIONSBOX 3.1
The Equations That Describe the Movement of Liquids and GasesThe mathematical equations that describe the movement of liquids and gasesare known as the Navier-Stokes equations. These equations describe how fluid
particles move through space, the effects of internal friction or viscosity, and theway sound waves are transmitted through a fluid. While viscosity is relativelystraightforward to account for, the particle motion and sound wave transmission
can be rather difficult to deal with. Computational methods for approximating theseeffects have to determine which way the particles and the sound waves are moving(and they usually move in different directions) and account for both this direction-
ality and the speed of propagation. When modeling high-speed gas flows contain-ing shock waves as shown in Plate 4, it is important to accurately resolve both theparticle motion and the sound wave transmission effects. On the other hand, when
modeling sloshing water or other liquids as shown in Plates 1 and 2, precise treat-ment of the sound waves is not necessary in order to obtain adequate solutions ofthe equations. Moreover, the treatment of fast-moving sound waves would make
the problem computationally much more expensive to solve. To remedy this diffi-culty, liquids can be assumed to be incompressible; that is, they preserve volume.This assumption removes the directional component and the stiffness of the sound
waves, making the problem computationally tractable. Moreover, this is a physicallyrealistic assumption for liquids, especially when one considers that a liquidÕs resis-tance to compression is responsible for the strong forces produced by hydraulics
devices.tural engineering, the fastest growing application areas may currently bein electrical and computer engineering and in biology and medicine. More
broadly, scientific computing encompasses both computational science
and computational mathematics. We emphasize that mathematics is the
fundamental language for problem solving, and when confronted with a
problem most scientific researchers attempt to formulate a mathematical
description of that problem. Once the mathematical description exists, the
problem is potentially solvable on a computer using either existing algo-
rithmic techniques or newly devised methods. Thus, scientific computing
has become a fundamental requirement for solving problems in signal
processing, image analysis, robotics, computer vision, human computer
interaction, and computer graphics.Returning to our cameraman and his goal of captivating us with dra-matic sequences of waves pounding on a small ship, we now see that
there are a lot of potential resources for creating Òspecial effectsÓ waves
on the computer. In the particular case of The Perfect Storm, IndustrialLight and Magic (ILM) had recently hired a professor of atmosphericComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.SIMULATION63science (who specializes in scientific computing) to use his knowledge ofoceans and waves, especially his algorithmic knowledge, to construct
numerical solutions of large crashing waves on the ILM computers.The Perfect Storm was not the first instance of scientific computing
algorithms being used to make movies of boats and waves. A few years
earlier, a Department of Defense (DOD)-oriented company called Aret”Associates started a small spin-off company called Aret” Entertainment
to create computer graphics software that constructs artificial, but sur-
prisingly realistic, ocean wave models. One can imagine that it could be
particularly useful to be able to reproduce ocean wave models based on,
for example, current wind speeds. If one could measure the wind and
estimate what the ocean wave pattern should look like, this could be
compared to the actual wave patterns in order to ascertain if there have
been any recent outside influences on the wave patterns. That is, one
could subtract the estimated wave pattern from the current wave pattern,
thus revealing the wake of a large ship that passed through the water
even some time ago. This becomes a lot more interesting when one realizes
that underwater ships (submarines) can create surface disturbances as
well. The implications for to the surveillance community are obvious.
Using its knowledge of scientific computing algorithms for studying
waves, Aret” Entertainment developed computer graphics software to
create ocean waves based on wind speeds. This software has won numer-
ous awards and was used to create ocean waves in many films such as
Water World and James Cameron
Õs Titanic. Another recent film, Cast Away,used similar technology to simulate a plane crashing into the ocean,
stranding Tom Hanks on a deserted island.As mentioned earlier, scientific computing algorithms can be used tosimulate a variety of natural phenomena, including the water shown in
Plates 1 and 2, and the smoke and fire shown in Plate 3. While these
everyday events (smoke, fire, and water) are easy to relate to, similar
numerical techniques can also be applied to events that the human eye
will miss completely. For example, Plate 4 shows a computer simulation
of a high-speed shock wave interacting with a bubble of helium. Scientific
computing is having a growing impact in the fields of imaging and data
analysis as well. This is important, for example, in medicine, biology, and
even surveillance. For example, Plate 5 shows several data points obtained
from MRI imaging of a ratÕs brain along with a three-dimensional geo-metric reconstruction of the rat brain obtained by using numerical
methods on a computer.Possibly the most exciting area for future applications of scientificcomputing is the computer simulation and study of humans themselves.
Researchers in biomechanics and medicine are currently working to write
down mathematical equations and numerical models that describe mostComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.64COMPUTER SCIENCE: REFLECTIONSof the human body from the cardiovascular system to muscles, bones, andorgans. As these equations and models are formulated, there is an ever-
growing need for new computational algorithms that can be used for the
computer simulation of biological structures. Plate 6 shows a sample com-
puter simulation of a skeleton running. Geometric models were used for
the bones, mathematical equations were used to describe the limited

motion allowed for by the connective tissue in joints, and special models
for soft tissue were used to simulate the muscles (the red regions in Plate6

represent the biceps muscles). Plate 7 shows 30 muscles of the upper limb
represented as a tetrahedral mesh ready for finite element simulation.
Computer simulation of humans is of interest to a wide variety of com-
mercial industries as well. The entertainment industry would like to simu-
late virtual actors, the textile industry would like to simulate both runway
models and everyday customers trying on virtual clothing, and so on. See
Plate 8 for a computer simulation of a piece of draped cloth.As both everyday personal computers and national laboratory super-computers continue to increase in speed and as better algorithms are
developed, the size, complexity, and realism of the problems that can be
simulated on these computers increase as well. In addition, as researchers
branch out into new and exciting research areas, they will formulate math-
ematical descriptions of their problems that are subsequently amenable to
computer simulation. The future is bright in a number of research areas,
and where researchers go, math and computer algorithms are sure to
follow.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.654Abstraction, Representation, and
NotationsModels capture phenomenaÑof the world or of the imaginationÑ
in such a way that a general-purpose computer can emulate,
simulate, or create the phenomena. But the models are usuallynot obvious. The real world is complex and nonlinear, thereÕs too much
detail to deal with, and relationships among the details are often hidden.
Computer scientists deal with this problem by careful, deliberate creation
of abstractions that express the models. These abstractions are represented
symbolically, in notations appropriate to the phenomena. The design of
languages for these models and for analyzing, processing, and executing
them is a core activity of computer science.Indeed, abstraction is a quintessential activity of computer scienceÑthe intellectual tool that allows computer scientists to express their under-
standing of a problem, manage complexity, and select the level of detail
and degree of generality they need at the moment. Computer scientists
create and discard abstractions as freely as engineers and architects create
and discard design sketches. Shaw describes the role of abstraction in building software, both the
stuff of programsÑalgorithms and representationsÑand the role that
specification and formal reasoning play in developing those abstractions.
Specific software-design techniques such as information hiding and hier-
archical organization provide ways to organize the abstract definitions
and the information they control. Aho and Larus describe how program-
ming languages provide a notation to encode abstractions so as to allow
their direct execution by computer.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.66COMPUTER SCIENCE: REFLECTIONSABSTRACTION: IMPOSING ORDER ON COMPLEXITYIN SOFTWARE DESIGNMary Shaw, Carnegie Mellon UniversityThe success of a complex designed system depends on the correctorganization and interaction of thousands, even millions, of individual
parts. If the designer must reason about all the parts at once, the com-
plexity of the design task often overwhelms human capability. Software
designers, like other designers, manage this complexity by separating the
design task into relatively independent parts. Often, this entails design-
ing large systems as hierarchical collections of subsystems, with the sub-
systems further decomposed into sub-subsystems, and so on until the
individual components are of manageable size.For typical consumer products, the subsystems are physical compo-nents that can be put together on assembly lines. But the principle of
hierarchical system organization does not require an assembly line.
Simon1 tells a parable of two watchmakers, Hora and Tempus. Both made
excellent watches and were often visited by their customers. Their watches
were similar, each with about 1000 parts, but Hora prospered while
Tempus became progressively poorer and eventually lost his shop. Tempus,
it seems, made his watches in such a way that a partially assembled watch
fell apart any time he put it down to deal with an interruption. Hora, on
the other hand, made stable subassemblies of about 10 parts and assembled
these into 10 larger assemblies, then joined these to make each watch. So
any time one of the watchmakers was interrupted by a customer, Tempus
had to restart from scratch on the current watch, but Hora only lost the
work of the current 10-unit assemblyÑa small fraction of TempusÕ loss.
Software systems do not require manual assembly of parts, but theyare large, complex, and amenable to a similar sort of discipline. Software
design benefits from hierarchical system organization based on sub-
systems that are relatively independent and that have known, simple,
interactions. Software designers create conceptual subassemblies with

coherent, comprehensible capabilities, similar to HoraÕs subassemblies.But whereas HoraÕs subassemblies might have been selected for conve-nience and physical organization, computer scientists are more likely to
create structure around concepts and responsibilities. In doing so they
can often state the idea, or abstraction, that is realized by the structure; forexample, the capabilities of a software component are often described in1Herbert A. Simon, 1997, Sciences of the Artificial, 3rd Ed., MIT Press, Cambridge, Mass.,pp. 188ff.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ABSTRACTION, REPRESENTATION, AND NOTATIONS67terms of the componentÕs observable properties, rather than the details ofthe componentÕs implementation. While these abstractions may corre-spond to discrete software components (the analog of physical parts), this
is not necessarily the case. So, for example, a computer scientist might
create an abstraction for the software that computes a satellite trajectory
but might equally well create an abstraction for a communication proto-
col whose implementation is woven through all the separate software
components of a system. Indeed, the abstractions of computer science can
be used in non-hierarchical as well as hierarchical structures. The abstrac-
tions of computer science are not in general the grand theories of the
sciences (though we have those as well; see Kleinberg and Papadimitriou
in Chapter 2), but rather specific conceptual units designed for specific
tasks.We represent these software abstractions in a combination of nota-tionsÑthe descriptive notations of specifications, the imperative notationsof programming, the descriptive notations of diagrams, and even narra-
tive prose. This combination of descriptive and imperative languages
provides separate descriptions of what is to be done (the specification)
and how it is to be done (the implementation). A software component
corresponding to an abstraction has a descriptive (sometimes formal)
specification of its abstract capabilities, an operational (usually impera-
tive) definition of its implementation, and some assuranceÑwith varyingdegrees of rigor and completenessÑthat the specification is consistentwith the implementation. Formal descriptive notations, in particular, have
evolved more or less together with operational notations, and progress
with each depends on progress with the other. The result is that we can
design large-scale systems software purposefully, rather than through
pure virtuosity, craft, or blind luck. We have not achievedÑindeed,may never achieveÑthe goal of complete formal specifications andprogramming-language implementations that are verifiably consistent
with those specifications. Nevertheless, the joint history of these notations
shows how supporting abstractions at one scale enables exploration of
abstractions at a larger scale.Abstractions in Software SystemsIn the beginningÑthat is to say, in the 1950sÑsoftware designersexpressed programs and data directly in the representation provided by
the computer hardware or in somewhat more legible Òassembly lan-guagesÓ that mapped directly to the hardware. This required great con-
ceptual leaps from problem domain to machine primitives, which limited
the sophistication of the results. The late 1950s saw the introduction of
programming languages that allowed the programmer to describe com-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.68COMPUTER SCIENCE: REFLECTIONSputations through formulas that were compiled into the hardware repre-sentation. Similarly, the descriptions of information representation origi-
nally referred directly to hardware memory locations (Òthe flag field isbits 6 to 8 of the third word of the recordÓ). Programming languages ofthe 1960s developed notations for describing information in somewhat
more abstract terms than the machine representation, so that the pro-
grammer could refer directly to ÒflagÓ and have that reference translated
automatically to whichever bits were appropriate. Not only are the more
abstract languages easier to read and write, but they also provide a degree
of decoupling between the program and the underlying hardware repre-
sentation that simplifies modification of the program.In 1967 Knuth2 showed us how to think systematically about the
concept of a data structure (such as a stack, queue, list, tree, graph, matrix,
or set) in isolation from its representation and about the concept of an
algorithm (such as search, sort, traversal, or matrix inversion) in isolation
from the particular program that implements it. This separation liberated
us to think independently about the abstractionÑthe algorithms and datadescriptions that describe a result and its implementationÑthe specific pro-gram and data declarations that implement those ideas on a computer.The next few years saw the development of many elegant and sophis-ticated algorithms with associated data representations. Sometimes the
speed of the algorithm depended on a special trick of representation.
Such was the case with in-place heapsort, a sorting algorithm that begins
by regardingÑabstractingÑthe values to be sorted as a one-dimensionalunsorted array. As the heapsort algorithm runs, it rearranges the values
in a particularly elegant way so that one end of the array can be abstracted
as a progressively growing tree, and when the algorithm terminates, the
entire array has become an abstract tree with the sorted values in a simple-
to-extract order. In most actual programs that implemented heapsort,
though, these abstractions were not described explicitly, so any program-
mer who changed the program had to depend on intuition and sketchy,
often obsolete, prose documentation to determine the original programmerÕsintentions. Further, the program that implemented the algorithms had no
special relation to the data structures. This situation was fraught with
opportunities for confusion and for lapses of discipline, which led to
undocumented (frequently unintended) dependencies on representation
tricks. Unsurprisingly, program errors often occurred when another pro-
grammer subsequently changed the data representation. In response to
this problem, in the 1970s a notion of ÒtypeÓ emerged to help document
2Donald Knuth, 1967, The Art of Computer Programming, Vol. 1, Addison-Wesley, Boston,Mass.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ABSTRACTION, REPRESENTATION, AND NOTATIONS69the intended uses of data. For example, we came to understand thatreferring to record fields abstractlyÑby a symbolic name rather than byabsolute offset from the start of a data blockÑmade programs easier tounderstand as well as to modify, and that this could often be done with-
out making the program run slower.At the same time, the intense interest in algorithms dragged represen-tation along as a poor cousin. In the early 1970s, there was a growing
sense that Ògetting the data structures rightÓ was a key to good software
design. Parnas3 elaborated this idea, arguing that a focus on data struc-
tures should lead to organizing software modules around data structures
rather than around collections of procedures. Further, he advanced the
then-radical proposition that not all information about how data is repre-sented should be shared, because programmers who used the data would
rely on things that might subsequently change. Better, he said, to specify
what a module would accomplish and allow privileged access to the
details only for selected code whose definition was in the same module as
the representation. The abstract description should provide all the
information required to use the component, and the implementer of the
component would only be obligated to keep the promises made in that
description. He elaborated this idea as Òinformation hiding.Ó Parnas sub-sequently spent several years at the Naval Research Laboratory applying
these ideas to the specification of the A7E avionics system, showing that
the idea could scale up to practical real-world systems.This was one of the precursors of object-oriented programming andthe marketplace for independently developed components that can be
used unchanged in larger systems, from components that invoke by pro-
cedure calls from a larger system through java applets that download into
Web browsers and third-party filters for photo-processing programs.
Computer scientists are still working out the consequences of using
abstract descriptions to encapsulate details. Abstractions can, in some
circumstances, be used in many software systems rather than custom-
defined for a specific use. However, the interactions between parts can be
subtleÑincluding not only the syntactic rules for invoking the parts butalso the semantics of their computationsÑand the problems associatedwith making independently developed parts work properly together
remain an active research area.So why isnÕt such a layered abstract description just a house of cards,ready to tumble down in the slightest whiff of wind? Because we partition
our tasks so that we deal with different concerns at different levels of3David L. Parnas, 1972, ÒOn the Criteria to Be Used in Decomposing Systems into Mod-ules,Ó Communications of the ACM 15(2):1053-1058.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.70COMPUTER SCIENCE: REFLECTIONSabstraction; by establishing reasonable confidence in each level of abstrac-tion and understanding the relations between the levels, we build our
confidence in the whole system. Some of our confidence is operational:
we use tools with a demonstrated record of success. Chief among these
tools are the programming languages, supported by compilers that auto-
matically convert the abstractions to code (see Aho and Larus in this
chapter). Other confidence comes from testingÑa kind of end-to-endcheck that the actual software behaves, at least to the extent we can check,
like the system we intended to develop. Deeper confidence is instilled by
formal analysis of the symbolic representation of the software, which
brings us to the second part of the story.Specifications of Software SystemsIn the beginning, programming was an art form and debugging wasvery much ad hoc. In 1967, Floyd4 showed how to reason formally about
the effect a program has on its data. More concretely, he showed that for
each operation a simple program makes, you can state a formal relation
between the previous and following program state; further, you can com-
pose these relations to determine what the program actually computes.
Specifically he showed that given a program, a claim about what that
program computes, and a formal definition of the programming language,

you can derive the starting conditions, if any, for which that claim is true.
Hoare and Dijkstra created similar but different formal rules for reason-
ing about programs in Pascal-like languages in this way.The immediate reaction, that programs could be Òproved correctÓ(actually, that the implementation of a program could be shown to be
consistent with its specification) proved overly optimistic. However, the
possibility of reasoning formally about a program changed the way people
thought about programming and stimulated interest in formal specifica-
tion of components and of programming languagesÑfor precision inexplanation, if not for proof. Formal specifications have now been received
well for making intentions precise and for some specific classes of analysis,

but the original promise remains unfulfilled. For example, there remains
a gap between specifications of practical real-world systems and the com-
plete, static specifications of the dream. Other remaining problems include

effective specifications of properties other than functionality, tractability
of analysis, and scaling to problems of realistic size.4R.W. Floyd, 1967, ÒAssigning Meanings to Programs,Ó Proceedings of Symposia in AppliedMathematics, Vol. 19-32, American Mathematical Society, Providence, R.I.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ABSTRACTION, REPRESENTATION, AND NOTATIONS71In 1972, Hoare5 showed how to extend this formalized reasoning to
encapsulations of the sort Parnas was exploring. This showed how to
formalize the crucial abstraction step that expresses the relation between
the abstraction and its implementation. Later in the 1970s, theoretical
computer scientists linked the pragmatic notion of types that allowed
compilers to do some compile-time checking to a theoretical model of
type theory.One of the obstacles to Òproving programs correctÓ was the difficulty
in creating a correct formal definition of the programming language in
which the programs were written. The first approach was to add formal
specifications to the programming language, as in Alphard, leaving proof
details to the programmer. The formal analysis task was daunting, and it
was rarely carried out. Further, many of the properties of interest about a
particular program do not lend themselves to expression in formal logic.
The second approach was to work hard on a simple common program-
ming language such as Pascal to obtain formal specifications of the lan-
guage semantics with only modest changes to the language, with a result
such as Euclid. This revealed capabilities of programming languages that
do not lend themselves to formalization. The third approach was to design
a family of programming languages such as ML that attempt to include
only constructs that lend themselves to formal analysis (assuming, of
course, a correct implementation of the compiler). These languages require
a style of software development that is an awkward match for many
software problems that involve explicit state and multiple cooperating
threads of execution.Formal specifications have found a home in practice not so much inverification of full programs as in the use of specifications to clarify
requirements and design. The cost of repairing a problem increases dras-
tically the later the problem is discovered, so this clarification is of sub-
stantial practical importance. In addition, specific critical aspects of a
program may be analyzed formally, for example through static analysis
or model checking.The Interaction of Abstraction and SpecificationThis brings us to the third part of our story: the coupling betweenprogress in the operational notations of programming languages and the
descriptive notations of formal specification systems. We can measure5C.A.R. Hoare, 1972, ÒProofs of Correctness of Data Representations,Ó Acta Informatica1:271-281.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.72COMPUTER SCIENCE: REFLECTIONSprogress in programming language abstraction, at least qualitatively, bythe scale of the supported abstractionsÑthe quantity of machine coderepresented by a single abstract construct. We can measure progress in
formal specification, equally qualitatively, by the fraction of a complex
software system that is amenable to formal specification and analysis.
And we see in the history of both, that formal reasoning about programs
has grown hand in hand with the capability of the languages to express
higher-level abstractions about the software. Neither advances very far
without waiting for the other to catch up.We can see this in the development of type systems. One of the earli-est type systems was the Fortran variable naming convention: operations
on variables whose names began with I, J, K, L, or M were compiled with
fixed-point arithmetic, while operations on all other variables were com-
piled with floating-point arithmetic. This approach was primitive, but it
provided immediate benefit to the programmer, namely correct machine
code. A few years later, Algol 60 provided explicit syntax for distinguish-
ing types, but this provided little benefit to the programmer beyond the
fixed/floating point discriminationÑand it was often ignored. Later lan-guages that enforced type checking ran into programmer opposition to
taking the time to write declarations, and the practice became acceptable
only when it became clear that the type declarations enabled analysis that
was immediately useful, namely discovering problems at compile time
rather than execution time.So type systems originally entered programming languages as amechanism for making sure at compile time that the run-time values
supplied for expression evaluation or procedure calls would be legiti-
mate. (Morris later called this ÒNeanderthal verification.Ó) But the nuancesof this determination are subtle and extensive, and type systems soon
found a role in the research area of formal semantics of programming
languages. Here they found a theoretical constituency, spawning their
own problems and solutions.Meanwhile, abstract data types were merging with the inheritancemechanisms of Smalltalk to become object-oriented design and program-
ming models. The inheritance mechanisms provided ways to express com-
plex similarities among types, and the separation of specification from
implementation in abstract data types allowed management of the code
that implemented families of components related by inheritance. Inherit-
ance structures can be complex, and formal analysis techniques for reason-
ing about these structures soon followed.With wider adoption of ML-like languages in the 1990s, the func-tional programming languages began to address practical problems,
thereby drawing increasing attention from software developers for whomComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ABSTRACTION, REPRESENTATION, AND NOTATIONS73correctness is a critical concernÑand for whom the prospect of assur-ances about the software justifies extra investment in analysis.The operational abstraction and symbolic analysis lines of researchmade strong contact again in the development of the Java language, which
incorporates strong assurances about type safety with object-oriented
abstraction.So two facets of programming language designÑlanguage mecha-nisms to support abstraction and incorporation of formal specification
and semantics in languagesÑhave an intertwined history, with advanceson each line stimulated by problems from both lines, and with progress
on one line sometimes stalled until the other line catches up.Additional ObservationsHow are the results of research on languages, models, and formal-isms to be evaluated? For operational abstractions, the models and the
detailed specifications of relevant properties have a utilitarian function,
so appropriate evaluation criteria should reflect the needs of software
developers. Expertise in any field requires not only higher-order reason-
ing skills, but also a large store of facts, together with a certain amount of
context about their implications and appropriate use.6 It follows that mod-
els and tools intended to support experts should support rich bodies of
operational knowledge. Further, they should support large vocabularies
of established knowledge as well as the theoretical base for deriving in-
formation of interest.Contrast this with the criteria against which mathematical systemsare evaluated. Mathematics values elegance and minimality of mecha-
nism; derived results are favored over added content because they are
correct and consistent by their construction. These criteria are appropriate
for languages whose function is to help understand the semantic basis of
programming languages and the possibility of formal reasoning.Given the differences in appropriate base language size that arisefrom the different objectives, it is small wonder that different criteria are
appropriate, or that observers applying such different criteria reach dif-
ferent conclusions about different research results.6This is true across a wide range of problem domains; studies have demonstrated it formedical diagnosis, physics, chess, financial analysis, architecture, scientific research, policydecision making, and others (Raj Reddy, 1988, ÒFoundations and Grand Challenges of Arti-ficial Intelligence,Ó AI Magazine, Winter; Herbert A. Simon, 1989, ÒHuman Experts andKnowledge-based Systems,Ó pp. 1-21 in 
Concepts and Characteristics of Knowledge-based Sys-tems (M. Tokoro, Y. Anzai, and A. Yonezawa, eds.), North-Holland Publishing, Amsterdam).
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.74COMPUTER SCIENCE: REFLECTIONSPROGRAMMING LANGUAGES AND COMPUTER SCIENCEAlfred V. Aho, Columbia University, andJames Larus, Microsoft ResearchSoftware affects virtually every modern personÕs life, often profoundly,but few appreciate the vast size and scope of the worldwide infrastruc-
ture behind it or the ongoing research aimed at improving it. Hundreds of
billions of lines of software code are currently in use, with many more
billions added annually, and they virtually run the gamut of conceivable
applications. It has been possible to build all this software because we
have been successful in inventing a wide spectrum of programming lan-
guages for describing the tasks we want computers to do. But like human
languages, they are sometimes quirky and imperfect. Thus computer sci-
entists are continually evolving more accurate, expressive, and conve-
nient ways in which humans may communicate to computers.Programming languages are different in many respects from humanlanguages. A computer is capable of executing arithmetic or logical
operations at blinding speeds, but it is in fact a device thatÕs frustratinglysimplemindedÑforever fixed in a concrete world of bits, bytes, arith-metic, and logic (see Hill in Chapter 2). Thus a computer must be given
straightforward, unambiguous, step-by-step instructions. Humans, by

contrast, can often solve highly complex problems using their innate
strengths of formulating and employing abstraction.To get a feel for the extent of this Òsemantic gap,Ó imagine explaining
to a young child how to prepare a meal. Given that the child likely has no
experience or context to draw upon, every step must be described clearly
and completely, and omitting even the simplest detail can lead to a messy
failure. Explaining tasks to computers is in many ways more difficult,
because computers not only require far more detail but that detail must
also be expressed in a primitive difficult-to-read notation such as binary
numbers.As an example of how programming languages bridge the gap betweenprogrammers and computers, consider numerical computation, one of
the earliest applications of computers, dating back to World War II. A
common mathematical operation is to multiply two vectors of numbers.
Humans will use a notation such as A*B to indicate the multiplication
(i.e., dot product) of vector A and vector BÑknowing that this is short-hand for all of the individual steps actually needed to perform the multi-
plication. Computers, on the other hand, know nothing about vectors or
the rules for multiplying them. They can only move numbers around;
perform addition, multiplication, and other primitive mathematical opera-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ABSTRACTION, REPRESENTATION, AND NOTATIONS75tions on them; and make simple decisions. Expressed in terms of theseprimitive operations, a simple vector multiplication routine might require
roughly 20 computer instructions, while a more sophisticated version,
which improves performance by using techniques like instruction-level
parallelism and caches (see Hill in Chapter 2), might require a few hun-
dred instructions. Someone looking at this machine-language routine
could easily be excused for not spotting the simple mathematical opera-
tion embodied in the complicated sequence of machine instructions.A high-level programming language addresses this Òsemantic gapÓbetween human and machine in several ways. It can provide operations
specifically designed to help formulate and solve a particular type of
problem. A programming language specifically intended for numeric
computation might use the human-friendly, concise notation A*B. It saves
programmers from repeatedly reimplementing (or mis-implementing) the
same operations. A software tool called a ÒcompilerÓ translates the higher-
level program into instructions executable by a computer.Programmers soon realized that a program written in a high-levellanguage could be run on more than one computer. Because the hardware
peculiarities of a particular computer could be hidden in a compiler, rather
than exposed in a language, programs could often be written in a portable
language that can be run on several computers. This separation of high-
level programs and computers expanded the market for commercial soft-
ware and helped foster the innovative software industry.Another advantage of compilers is that a program written in a high-level language often runs faster. Compilers, as a result of several decades
of fundamental research on program analysis, code generation, and code-
optimization techniques, are generally far better at translating programs
into efficient sequences of computer instructions than are human pro-
grammers. The comparison is interesting and edifying.Programmers can occasionally produce small and ingenious pieces ofmachine code that run much faster than the machine instructions gener-
ated by a compiler. However, as a program grows to thousands of lines or
more, a compilerÕs systematic, analytical approach usually results in higher-quality translations that not only execute far more effectively but also
contain fewer errors.Program optimization is a very fertile area of computer science research.A compiler improves a program by changing the process by which it
computes its result to a slightly different approach that executes faster. A
compiler is allowed to make a change only if it does not affect the result
that the program computes.Interestingly, true optimization is a goal that is provably impossible.An analysis algorithm that predicts if a nontrivial modification affects a
programÕs result can be used to solve the program equivalence problem,Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.76COMPUTER SCIENCE: REFLECTIONSwhich is provably impossible because of TuringÕs result (see Kleinbergand Papadimitriou in Chapter 2). Compilers side-step this conundrum by
modifying a program only when it is possible to demonstrate that the
change leaves the programÕs result unaffected. Otherwise, they assumethe worst and leave alone programs in which there is any doubt about the
consequences of a change. The interplay between TuringÕs fundamentalresult, which predates programming languages and compilers by many
years, and the vast number of practical and effective tools for analyzing
and optimizing programs is emblematic of computer science as a whole,
which continues to make steady progress despite many fundamental limi-
tations on computability.The past half century has seen the development of thousands ofprogramming languages that use many different approaches to writing
programs. For example, some languages, so-called imperative languages,
specify how a computation is to be done, while declarative languages
focus on what the computer is supposed to do. Some languages are
general-purpose, but many others are intended for specific application
domains. For example, the languages C and C++ are commonly used in
systems programming, SQL in writing queries for databases, and PostScript
in describing the layout of printed material. Innovations and new applica-
tions typically produce new languages. For example, the Internet spurred
development of Java for writing client/server applications and JavaScript
and Flash for animating Web pages.One might ask, ÒAre all of these languages necessary?Ó Turing
Õs researchon the nature of computing (see Kleinberg and Papadimitriou in Chapter2)

offers one answer to this question. Since almost every programming lan-
guage is equivalent to TuringÕs universal computing machine, they are allin principle capable of expressing the same algorithms. But the choice of
an inappropriate language can greatly complicate programming. It is not
unlike asking whether a bicycle, car, and airplane are interchangeable
modes of transportation. Just as it would be cumbersome, at best, to fly a
jet to the grocery store to buy milk, so using the wrong programming
language can make a program much longer and much more difficult to
write and execute.Today, most programs are written by teams of programmers. In thisworld, many programming problems and errors arise from misunder-
standings of intent, misinformation, and human shortcomings, so lan-
guage designers have come to recognize that programming languages
convey information among human programmers, as well as to computers.Language designers soon realized that programming languages mustbe extensible as well as computationally universal, as no one language
could provide operations appropriate for all types of problems. Languages
today offer many general mechanisms for programmers to use in address-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ABSTRACTION, REPRESENTATION, AND NOTATIONS77ing their specific problems. One of the early and most fundamental of
these mechanisms introduced into programming languages was the Òpro-cedure,Ó which collects and names the code to perform a particular opera-
tion. So, for example, a programmer who wants to implement operations
that involve multiplying vectors in a language in which this capability is
not built in could create a procedure with a meaningful name, such as
ÒMultiplyVector,Ó and simply cite that name to invoke that procedure
whenever neededÑas opposed to rewriting the same set of instructionseach time. And programmers could then use the procedure in other pro-
grams rather than reinventing the wheel each time. Procedures of this sort
have understandably become the fundamental building blocks of todayÕsprograms.Another early insight is built on the fact that statements in a programtypically execute in one of a small number of different patterns; thus the
patterns themselves could be added to the vocabulary of a language rather
than relying on a programmer to express the patterns with simpler (and a
larger number of) statements. For example, a common idiom is to execute
a group of statements repeatedly while a condition holds true. This is
written:while (condition) dostatementsEarlier languages did not provide this feature and instead relied onprogrammers to construct it, each time it was needed, from simpler state-
ments:test:if (not condition) then goto done;statements
goto test;done:The latter approach has several problems: the program is longer, theprogrammerÕs intent is more difficult to discern, and possibilities forerrors increase. For example, if the first statement said Ògoto testÓinstead of Ògoto done,Ó this piece of code would never terminate.
Incorporation of new constructs to aid in the development of morerobust software systems has been a continuing major trend in program-
ming-language development. In addition to well-structured features for
controlling programs such as the Òwhile loop,Ó other improvements include
features that permit dividing up software into modules, strong type checking
to catch some errors at compile time rather than run time, and incorpora-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.78COMPUTER SCIENCE: REFLECTIONStion of automated memory management that frees the programmer fromworrying about details of allocating and deallocating storage. These fea-
tures not only improve the ability of a programming language to express
a programmerÕs intent but also offer better facilities for detecting incon-sistencies and other errors in programs. Today
Õs huge and ever-growing software infrastructure presents anenormous challenge for programmers, software companies, and society
as whole. Because programs are written by people, they contain defects
known as bugs. Even the best programs, written using the most advanced
software engineering techniques, contain between 10 and 10,000 errors
per million lines of new code. Some defects are minor, while others have
the potential to disrupt society significantly.The constantly evolving programming languages, techniques, andtools have done much to improve the quality of software. But the soft-
ware revolution is always in need of some sweetening. Programming-
language researchers are devoting increasing attention to producing pro-
grams with far fewer defects and systems with much higher levels of fault
tolerance. They are also developing software verification tools of greater
power and rigor that can be used throughout the software development
process. The ultimate research goal is to produce programming languages
and software development tools with which robust software systems can
be created routinely and economically for all of tomorrowÕs applications.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.795Data, Representation, and Information
The preceding two chapters address the creation of models that cap-ture phenomena of interest and the abstractions both for data and
for computation that reduce these models to forms that can beexecuted by computer. We turn now to the ways computer scientists deal
with information, especially in its static form as data that can be manipu-
lated by programs.Gray begins by narrating a long line of research on databasesÑstore-houses of related, structured, and durable data. We see here that the
objects of research are not data per se but rather designs of ÒschemasÓ that
allow deliberate inquiry and manipulation. Gray couples this review with
introspection about the ways in which database researchers approach
these problems.Databases support storage and retrieval of information by definingÑin advanceÑa complex structure for the data that supports the intended
operations. In contrast, Lesk reviews research on retrieving information
from documents that are formatted to meet the needs of applications
rather than predefined schematized formats.Interpretation of information is at the heart of what historians do, andAyers explains how information technology is transforming their para-
digms. He proposes that history is essentially model buildingÑconstruct-
ing explanations based on available informationÑand suggests that the
methods of computer science are influencing this core aspect of historical
analysis.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.80COMPUTER SCIENCE: REFLECTIONSDATABASE SYSTEMS:A TEXTBOOK CASE OF RESEARCH PAYING OFFJim Gray, Microsoft ResearchA small research investment helped produce U.S. market dominancein the $14 billion database industry. Government and industry funding of
a few research projects created the ideas for several generations of
products and trained the people who built those products. Continuing
research is now creating the ideas and training the people for the next
generation of products.Industry ProfileThe database industry generated about $14 billion in revenue in 2002and is growing at 20 percent per year, even though the overall technology
sector is almost static. Among software sectors, the database industry is
second only to operating system software. Database industry leaders are
all U.S.-based corporations: IBM, Microsoft, and Oracle are the three
largest. There are several specialty vendors: Tandem sells over $1 billion/
year of fault-tolerant transaction processing systems, Teradata sells about
$1 billion/year of data-mining systems, and companies like Information
Resources Associates, Verity, Fulcrum, and others sell specialized data
and text-mining software.In addition to these well-established companies, there is a vibrantgroup of small companies specializing in application-specific databasesÑfor text retrieval, spatial and geographical data, scientific data, image
data, and so on. An emerging group of companies offer XML-oriented
databases. Desktop databases are another important market focused on
extreme ease of use, small size, and disconnected (offline) operation.Historical PerspectiveCompanies began automating their back-office bookkeeping in the1960s. The COBOL programming language and its record-oriented file
model were the workhorses of this effort. Typically, a batch of trans-
actions was applied to the old-tape-master, producing a new-tape-master
and printout for the next business day. During that era, there was consid-
erable experimentation with systems to manage an online database that
could capture transactions as they happened. At first these systems were
ad hoc, but late in that decade network and hierarchical database products
emerged. A COBOL subcommittee defined a network data model stan-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION81dard (DBTG) that formed the basis for most systems during the 1970s.Indeed, in 1980 DBTG-based Cullinet was the leading software company.However, there were some problems with DBTG. DBTG uses a low-level, record-at-a-time procedural language to access information. The
programmer has to navigate through the database, following pointers
from record to record. If the database is redesigned, as often happens over
a decade, then all the old programs have to be rewritten.The relational data model, enunciated by IBM researcher Ted Codd ina 1970 Communications of the Association for Computing Machinery article,
1was a major advance over DBTG. The relational model unified data andmetadata so that there was only one form of data representation. It defined
a non-procedural data access language based on algebra or logic. It was
easier for end users to visualize and understand than the pointers-and-
records-based DBTG model.The research community (both industry and university) embracedthe relational data model and extended it during the 1970s. Most signifi-
cantly, researchers showed that a non-procedural language could be com-
piled to give performance comparable to the best record-oriented database
systems. This research produced a generation of systems and people that
formed the basis for products from IBM, Ingres, Oracle, Informix, Sybase,
and others. The SQL relational database language was standardized by
ANSI/ISO between 1982 and 1986. By 1990, virtually all database systems
provided an SQL interface (including network, hierarchical, and object-
oriented systems).Meanwhile the database research agenda moved on to geographi-cally distributed databases and to parallel data access. Theoretical work
on distributed databases led to prototypes that in turn led to products.
Today, all the major database systems offer the ability to distribute and
replicate data among nodes of a computer network. Intense research on
data replication during the late 1980s and early 1990s gave rise to a second
generation of replication products that are now the mainstays of mobile
computing.Research of the 1980s showed how to execute each of the relationaldata operators in parallelÑgiving hundred-fold and thousand-fold speed-ups. The results of this research began to appear in the products of several
major database companies. With the proliferation of data mining in the
1990s, huge databases emerged. Interactive access to these databases
requires that the system use multiple processors and multiple disks to
read all the data in parallel. In addition, these problems require near-1E.F. Codd, 1970, ÒA Relational Model of Data from Large Shared Data Banks,Ó Communica-tions of the ACM 13(6):377-387. Available online at http://www.acm.org/classics/nov95/.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.82COMPUTER SCIENCE: REFLECTIONSlinear time search algorithms. University and industrial research of theprevious decade had solved these problems and forms the basis of the
current VLDB (very large database) data-mining systems.Rollup and drilldown data reporting systems had been a mainstay ofdecision-support systems ever since the 1960s. In the middle 1990s, the
research community really focused on data-mining algorithms. They
invented very efficient data cube and materialized view algorithms that
form the basis for the current generation of business intelligence products.The most recent round of government-sponsored research creating anew industry comes from the National Science FoundationÕs DigitalLibraries program, which spawned Google. It was founded by a group of
ÒdatabaseÓ graduate students who took a fresh look at how information
should be organized and presented in the Internet era.Current Research DirectionsThere continues to be active and valuable research on representingand indexing data, adding inference to data search, compiling queries
more efficiently, executing queries in parallel, integrating data from het-
erogeneous data sources, analyzing performance, and extending the trans-
action model to handle long transactions and workflow (transactions that
involve human as well as computer steps). The availability of huge vol-
umes of data on the Internet has prompted the study of data integration,
mediation, and federation in which a portal system presents a unification
of several data sources by pulling data on demand from different parts of
the Internet.In addition, there is great interest in unifying object-oriented conceptswith the relational model. New data types (image, document, and draw-
ing) are best viewed as the methods that implement them rather than by
the bytes that represent them. By adding procedures to the database
system, one gets active databases, data inference, and data encapsulation.
This object-oriented approach is an area of active research and ferment
both in academe and industry. It seems that in 2003, the research prototypes
are mostly done and this is an area that is rapidly moving into products.The Internet is full of semi-structured dataÑdata that has a bit ofschema and metadata, but is mostly a loose collection of facts. XML has
emerged as the standard representation of semi-structured data, but there
is no consensus on how such data should be stored, indexed, or searched.
There have been intense research efforts to answer these questions. Proto-
types have been built at universities and industrial research labs, and now
products are in development.The database research community now has a major focus on streamdata processing. Traditionally, databases have been stored locally and areComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION83updated by transactions. Sensor networks, financial markets, telephonecalls, credit card transactions, and other data sources present streams of
data rather than a static database. The stream data processing researchers
are exploring languages and algorithms for querying such streams and
providing approximate answers.Now that nearly all information is online, data security and data privacyare extremely serious and important problems. A small, but growing, part of

the database community is looking at ways to protect peopleÕs privacy bylimiting the ways data is used. This work also has implications for pro-
tecting intellectual property (e.g., digital rights management, watermarking)
and protecting data integrity by digitally signing documents and then
replicating them so that the documents cannot be altered or destroyed.Case HistoriesThe U.S. government funded many database research projects from1972 to the present. Projects at the University of California at Los Angeles
gave rise to Teradata and produced many excellent students. Projects at
Computer Corp. of America (SDD-1, Daplex, Multibase, and HiPAC)

pioneered distributed database technology and object-oriented database
technology. Projects at Stanford University fostered deductive database
technology, data integration technology, query optimization technology,
and the popular Yahoo! and Google Internet sites. Work at Carnegie
Mellon University gave rise to general transaction models and ultimately
to the Transarc Corporation. There have been many other successes from
AT&T, the University of Texas at Austin, Brown and Harvard Universities,
the University of Maryland, the University of Michigan, Massachusetts
Institute of Technology, Princeton University, and the University of
Toronto among others. It is not possible to enumerate all the contribu-
tions here, but we highlight three representative research projects that
had a major impact on the industry.Project INGRESProject Ingres started at the University of California at Berkeley in1972. Inspired by CoddÕs paper on relational databases, several facultymembers (Stonebraker, Rowe, Wong, and others) started a project to
design and build a relational system. Incidental to this work, they
invented a query language (QUEL), relational optimization techniques, a
language binding technique, and interesting storage strategies. They also
pioneered work on distributed databases.The Ingres academic system formed the basis for the Ingres productnow owned by Computer Associates. Students trained on Ingres went onComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.84COMPUTER SCIENCE: REFLECTIONSto start or staff all the major database companies (AT&T, Britton Lee, HP,Informix, IBM, Oracle, Tandem, Sybase). The Ingres project went on to
investigate distributed databases, database inference, active databases,
and extensible databases. It was rechristened Postgres, which is now the
basis of the digital library and scientific database efforts within the Uni-
versity of California system. Recently, Postgres spun off to become the
basis for a new object-relational system from the start-up Illustra Informa-
tion Technologies.System RCoddÕs ideas were inspired by seeing the problems IBM and its cus-tomers were having with IBMÕs IMS product and the DBTG network datamodel. His relational model was at first very controversial; people thought

that the model was too simplistic and that it could never give good per-
formance. IBM Research management took a gamble and chartered a small

(10-person) systems effort to prototype a relational system based on CoddÕsideas. That system produced a prototype that eventually grew into the
DB2 product series. Along the way, the IBM team pioneered ideas in
query optimization, data independence (views), transactions (logging and

locking), and security (the grant-revoke model). In addition, the SQL
query language from System R was the basis for the ANSI/ISO standard.The System R group went on to investigate distributed databases(project R*) and object-oriented extensible databases (project Starburst).
These research projects have pioneered new ideas and algorithms. The
results appear in IBMÕs database products and those of other vendors.GammaNot all research ideas work out. During the 1970s there was greatenthusiasm for database machinesÑspecial-purpose computers that wouldbe much faster than general-purpose operating systems running conven-
tional database systems. These research projects were often based on
exotic hardware like bubble memories, head-per-track disks, or associa-
tive RAM. The problem was that general-purpose systems were improv-
ing at 50 percent per year, so it was difficult for exotic systems to compete
with them. By 1980, most researchers realized the futility of special-purpose
approaches and the database-machine community switched to research
on using arrays of general-purpose processors and disks to process data
in parallel.The University of Wisconsin hosted the major proponents of this ideain the United States. Funded by the government and industry, those
researchers prototyped and built a parallel database machine calledComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION85Gamma. That system produced ideas and a generation of students whowent on to staff all the database vendors. Today the parallel systems from
IBM, Tandem, Oracle, Informix, Sybase, and Microsoft all have a direct
lineage from the Wisconsin research on parallel database systems. The
use of parallel database systems for data mining is the fastest-growing
component of the database server industry.The Gamma project evolved into the Exodus project at Wisconsin(focusing on an extensible object-oriented database). Exodus has now
evolved to the Paradise system, which combines object-oriented and
parallel database techniques to represent, store, and quickly process huge
Earth-observing satellite databases.And Then There Is ScienceIn addition to creating a huge industry, database theory, science, andengineering constitute a key part of computer science today. Represent-
ing knowledge within a computer is one of the central challenges of com-
puter science (Box 5.1). Database research has focused primarily on this
fundamental issue. Many universities have faculty investigating these
problems and offer classes that teach the concepts developed by this
research program.BOX 5.1
How Do You Know? A Long-Range View of Database ResearchHow can knowledge be represented so that algorithms can make new infer-ences from the knowledge base? This problem has challenged philosophers for
millennia. There has been progress. Euclid axiomized geometry and proved itsbasic theorems, and in doing so implicitly demonstrated mechanical reasoningfrom first principles. George BooleÕs Laws of Thought created a predicate calculus,
and LaplaceÕs work on probability was a first start on statistical inference.Each of these threadsÑproofs, predicate calculus, and statistical inferenceÑwere major advances; but each requires substantial human creativity to fit new
problems to the solution. WouldnÕt it be nice if we could just put all the books andjournals in a library that would automatically organize them and start producingnew answers?There are huge gaps between our current tools and the goal of a self-organizinglibrary, but computer scientists are trying to fill the gaps with better algorithms andbetter ways of representing knowledge. Databases are one branch of this effort to
represent information and reason about it. The database community has taken abottom-up approach, working with simple data representations and developing acalculus for asking and answering questions about the database.continuedComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.86COMPUTER SCIENCE: REFLECTIONSThe fundamental approach of database researchers is to insist that the infor-mation must be schematizedÑthe information must be represented in a predefinedschema that assigns a meaning to each value. The author-title-subject-abstractschema of a library system is a typical example of this approach. The schema isused both to organize the data and to make it easy to express questions about the
database.Database researchers have labored to make it easy to define the schema,easy to add data to the database, and easy to pose questions to the database.
Early database systems were dreadfully difficult to useÑlargely because welacked the algorithms to automatically index huge databases and lacked powerfulquery tools. Today there are good tools to define schemas, and graphical tools that
make it easy to explore and analyze the contents of a database.This has required invention at all levels of the problem. At the lowest levelswe had to discover efficient algorithms to sort, index, and organize numeric, text,
temporal, and spatial information so that higher-level software could just pick froma wide variety of organizations and algorithms. These low-level algorithms maskdata placement so that it can be spread among hundreds or thousands of disks;
they mask concurrency so that the higher-level software can view a consistentdata snapshot, even though the data is in flux. The low-level software includesenough redundancy so that once data is placed in the database, it is safe to
assume that the data will never be lost. One major advance was the theory andalgorithms to automatically guarantee these concurrency-reliability properties.Text, spatial, and temporal databases have always posed special challenges.Certainly there have been huge advances in indexing these databases, butresearchers still have many more problems to solve. The advent of image, video,and sound databases raises new issues. In particular, we are now able to extract
a huge number of features from images and sounds, but we have no really goodways to index these features. This is just another aspect of the Òcurse of dimen-sionalityÓ faced by database systems in the data-mining and data analysis area.
When each object has more than a dozen attributes, traditional indexing tech-niques give little help in reducing the approximate search space.So, there are still many unsolved research challenges for the low-level data-base Òplumbers.ÓThe higher-level software that uses this plumbing has been a huge success.Early on, the research community embraced the relational data model championed
by Ted Codd. Codd advocated the use of non-procedural set-oriented program-ming to define schemas and to pose queries. After a decade of experimentation,these research ideas evolved into the SQL database language. Having this high-
level non-procedural language was a boon both to application programmers and todatabase implementers. Application programmers could write much simpler pro-grams. The database implementers faced the challenge of optimizing and execut-
ing SQL. Because it is so high level (SQL is a non-procedural functional dataflowlanguage), SQL allows data to be distributed across many computers and disks.Because the programs do not mention any physical structures, the implementer is
free to use whatever ÒplumbingÓ is available. And because the language is func-
tional, it can be executed in parallel.BOX 5.1 Continued
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION87Techniques for implementing the relational data model and algorithms forefficiently executing database queries remain a core part of the database research
agenda. Over the last decade, the traditional database systems have grown toinclude analytics (data cubes), and also data-mining algorithms borrowed from themachine-learning and statistics communities. There is increasing interest in solv-
ing information retrieval and multimedia database issues.Today, there are very good tools for defining and querying traditional data-base systems; but, there are still major research challenges in the traditional data-
base field. The major focus is automating as much of the data administration tasksas possibleÑmaking the database system self-healing and self-managing.We are still far from the goal of building systems that automatically ingestinformation, reason about it, and produce answers on demand. But the goal iscloser, and it seems attainable within this century.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.88COMPUTER SCIENCE: REFLECTIONSCOMPUTER SCIENCE IS TO INFORMATION ASCHEMISTRY IS TO MATTERMichael Lesk, Rutgers UniversityIn other countries computer science is often called ÒinformaticsÓ or
some similar name. Much computer science research derives from the
need to access, process, store, or otherwise exploit some resource of use-
ful information. Just as chemistry is driven to large extent by the need to
understand substances, computing is driven by a need to handle data and
information. As an example of the way chemistry has developed, see
Oliver SacksÕs book Uncle Tungsten: Memories of a Chemical Boyhood(Vintage Books, 2002). He describes his explorations through the different
metals, learning the properties of each, and understanding their applica-
tions. Similarly, in the history of computer science, our information needs
and our information capabilities have driven parts of the research agenda.
Information retrieval systems take some kind of information, such as text
documents or pictures, and try to retrieve topics or concepts based on
words or shapes. Deducing the concept from the bytes can be difficult,
and the way we approach the problem depends on what kind of bytes we
have and how many of them we have.Our experimental method is to see if we can build a system that willprovide some useful access to information or service. If it works, those
algorithms and that kind of data become a new field: look at areas like
geographic information systems. If not, people may abandon the area
until we see a new motivation to exploit that kind of data. For example,
face-recognition algorithms have received a new impetus from security
needs, speeding up progress in the last few years. An effective strategy to
move computer science forward is to provide some new kind of informa-
tion and see if we can make it useful.Chemistry, of course, involves a dichotomy between substances andreactions. Just as we can (and frequently do) think of computer science in
terms of algorithms, we can talk about chemistry in terms of reactions.
However, chemistry has historically focused on substances: the encyclo-
pedias and indexes in chemistry tend to be organized and focused on
compounds, with reaction names and schemes getting less space on the
shelf. Chemistry is becoming more balanced as we understand reactions
better; computer science has always been more heavily oriented toward
algorithms, but we cannot ignore the driving force of new kinds of data.The history of information retrieval, for example, has been driven bythe kinds of information we could store and use. In the 1960s, for example,
storage was extremely expensive. Research projects were limited to textComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION89materials. Even then, storage costs meant that a research project could justbarely manage to have a single ASCII document available for processing.
For example, Gerard SaltonÕs SMART system, one of the leading textretrieval systems for many years (see SaltonÕs book, The SMART Auto-matic Retrieval System, Prentice-Hall, 1971), did most of its processing oncollections of a few hundred abstracts. The only collections of Òfull docu-mentsÓ were a collection of 80 extended abstracts, each a page or two
long, and a collection of under a thousand stories from Time Magazine,each less than a page in length. The biggest collection was 1400 abstracts
in aeronautical engineering. With this data, Salton was able to experiment
on the effectiveness of retrieval methods using suffixing, thesauri, and
simple phrase finding. Salton also laid down the standard methodology
for evaluating retrieval systems, based on Cyril CleverdonÕs measures ofÒrecallÓ (percentage of the relevant material that is retrieved in response
to a query) and ÒprecisionÓ (the percentage of the material retrieved that
is relevant). A system with perfect recall finds all relevant material, making
no errors of omission and leaving out nothing the user wanted. In con-
trast, a system with perfect precision finds only relevant material, making
no errors of commission and not bothering the user with stuff of no
interest. The SMART system produced these measures for many retrieval
experiments and its methodology was widely used, making text retrieval
one of the earliest areas of computer science with agreed-on evaluation
methods. Salton was not able to do anything with image retrieval at the
time; there were no such data available for him.Another idea shaped by the amount of information available wasÒrelevance feedback,Ó the idea of identifying useful documents from a
first retrieval pass in order to improve the results of a later retrieval. With
so few documents, high precision seemed like an unnecessary goal. It was
simply not possible to retrieve more material than somebody could look
at. Thus, the research focused on high recall (also stimulated by the insis-
tence by some users that they had to have every single relevant docu-
ment). Relevance feedback helped recall. By contrast, the use of phrase
searching to improve precision was tried but never got much attention
simply because it did not have the scope to produce much improvement
in the running systems.The basic problem is that we wish to search for concepts, and whatwe have in natural language are words and phrases. When our docu-
ments are few and short, the main problem is not to miss any, and the
research at the time stressed algorithms that found related words via
associations or improved recall with techniques like relevance feedback.Then, of course, several other advancesÑcomputer typesetting andword processing to generate material and cheap disks to hold itÑled tomuch larger text collections. Figure 5.1 shows the decline in the price ofComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.90COMPUTER SCIENCE: REFLECTIONSFIGURE 5.1Decline in the price of disk space, 1950 to 2004.
disk space since the first disks in the mid-1950s, generally following thecost-performance trends of MooreÕs law.Cheaper storage led to larger and larger text collections online. Nowthere are many terabytes of data on the Web. These vastly larger volumes
mean that precision has now become more important, since a common
problem is to wade through vastly too many documents. Not surpris-
ingly, in the mid-1980s efforts started on separating the multiple mean-
ings of words like ÒbankÓ or 
ÒpineÓ and became the research area of
Òsense disambiguation.Ó2 With sense disambiguation, it is possible to
imagine searching for only one meaning of an ambiguous word, thus
avoiding many erroneous retrievals.Large-scale research on text processing took off with the availabilityof the TREC (Text Retrieval Evaluation Conference) data. Thanks to the
National Institute of Standards and Technology, several hundred mega-
bytes of text were provided (in each of several years) for research use.
This stimulated more work on query analysis, text handling, searching2See Michael Lesk, 1986, ÒHow to Tell a Pine Cone from an Ice Cream Cone,Ó ProceedingsSIGDOC, pp. 26-28.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION91algorithms, and related areas; see the series titled TREC Conference Pro-ceedings, edited by Donna Harmon of NIST.
Document clustering appeared as an important way to shorten longsearch results. Clustering enables a system to report not, say, 5000 docu-
ments but rather 10 groups of 500 documents each, and the user can then
explore the group or groups that seem relevant. Salton anticipated the
future possibility of such algorithms, as did others.3 Until we got large
collections, though, clustering did not find application in the document
retrieval world. Now one routinely sees search engines using these tech-
niques, and faster clustering algorithms have been developed.Thus the algorithms explored switched from recall aids to precisionaids as the quantity of available data increased. Manual thesauri, for
example, have dropped out of favor for retrieval, partly because of their
cost but also because their goal is to increase recall, which is not todayÕsproblem. In terms of finding the concepts hinted at by words and phrases,
our goals now are to sharpen rather than broaden these concepts: thus
disambiguation and phrase matching, and not as much work on thesauri
and term associations.Again, multilingual searching started to matter, because multilingualcollections became available. Multilingual research shows a more precise
example of particular information resources driving research. The Cana-
dian government made its Parliamentary proceedings (called Hansard)available in both French and English, with paragraph-by-paragraph trans-
lation. This data stimulated a number of projects looking at how to handle
bilingual material, including work on automatic alignment of the parallel
texts, automatic linking of similar words in the two languages, and so on.4A similar effect was seen with the Brown corpus of tagged Englishtext, where the part of speech of each word (e.g., whether a word is a
noun or a verb) was identified. This produced a few years of work on
algorithms that learned how to assign parts of speech to words in running
text based on statistical techniques, such as the work by Garside.53See, for example, N. Jardine and C.J. van Rijsbergen, 1971, ÒThe Use of HierarchicalClustering in Information Retrieval,Ó Information Storage and Retrieval 7:217-240.
4See, for example, T.K. Landauer and M.L. Littman, 1990, ÒFully Automatic Cross-Language Document Retrieval Using Latent Semantic Indexing,Ó Proceedings of the SixthAnnual Conference of the UW Centre for the New Oxford English Dictionary and Text Research,
pp. 31-38, University of Waterloo Centre for the New OED and Text Research, Waterloo,Ontario, October; or I. Dagan and Ken Church, 1997, ÒTermight: Coordinating Humans andMachines in Bilingual Terminology Acquisition,Ó Machine Translation 12(1/2):89-107.
5Roger Garside, 1987, ÒThe CLAWS Word-tagging System,Ó in R. Garside, G. Leech, and
G. Sampson (eds.), The Computational Analysis of English: A Corpus-Based Approach, Longman,London.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.92COMPUTER SCIENCE: REFLECTIONSOne might see an analogy to various new fields of chemistry. Therecognition that pesticides like DDT were environmental pollutants led to
a new interest in biodegradability, and the Freon propellants used in
aerosol cans stimulated research in reactions in the upper atmosphere.
New substances stimulated a need to study reactions that previously had
not been a top priority for chemistry and chemical engineering.As storage became cheaper, image storage was now as practical astext storage had been a decade earlier. Starting in the 1980s we saw the
IBM QBIC project demonstrating that something could be done to retrieve
images directly, without having to index them by text words first.6 Projects
like this were stimulated by the availability of Òclip artÓ such as the
COREL image disks. Several different projects were driven by the easy
access to images in this way, with technology moving on from color and
texture to more accurate shape processing. At Berkeley, for example, the
ÒBlobworldÓ project made major improvements in shape detection and
recognition, as described in Carson et al.7 These projects demonstrated
that retrieval could be done with images as well as with words, and that
properties of images could be found that were usable as concepts for
searching.Another new kind of data that became feasible to process was sound,in particular human speech. Here it was the Defense Advanced Research
Projects Agency (DARPA) that took the lead, providing the SWITCH-
BOARD corpus of spoken English. Again, the availability of a substantial
file of tagged information helped stimulate many research projects that
used this corpus and developed much of the technology that eventually
went into the commercial speech recognition products we now have. As
with the TREC contests, the competitions run by DARPA based on its
spoken language data pushed the industry and the researchers to new
advances. National needs created a new technology; one is reminded of
the development of synthetic rubber during World War II or the advances
in catalysis needed to make explosives during World War I.Yet another kind of new data was geo-coded data, introducing a newset of conceptual ideas related to place. Geographical data started show-
ing up in machine-readable form during the 1980s, especially with the
release of the Dual Independent Map Encoding (DIME) files after the 19806See, for example, Wayne Niblack, Ron Barber, William Equitz, Myron Flickner, EduardoH. Glasman, Dragutin Petkovic, Peter Yanker, Christos Faloutsos, and Gabriel Taubin, 1993,ÒThe QBIC Project: Querying Images by Content, Using Color, Texture, and Shape,Ó Storageand Retrieval for Image and Video Databases (SPIE), pp. 173-187.7C. Carson, M. Thomas, S. Belongie, J.M. Hellerstein, and J. Malik, 1999, ÒBlobworld: ASystem for Region-based Image Indexing and Retrieval,Ó Proceedings of the Third AnnualConference on Visual Information Systems, Springer-Verlag, Amsterdam, pp. 509-516.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION93census and the Topologically Integrated Geographic Encoding and Refer-encing (TIGER) files from the 1990 census. The availability, free of charge,
of a complete U.S. street map stimulated much research on systems to
display maps, to give driving directions, and the like.8 When aerial photo-
graphs also became available, there was the triumph of MicrosoftÕsÒTerraserver,Ó which made it possible to look at a wide swath of the
world from the sky along with correlated street and topographic maps.9More recently, in the 1990s, we have started to look at video searchand retrieval. After all, if a CD-ROM contains about 300,000 times as
many bytes per pound as a deck of punched cards, and a digitized video
has about 500,000 times as many bytes per second as the ASCII script it
comes from, we should be about where we were in the 1960s with video
today. And indeed there are a few projects, most notably the Informedia
project at Carnegie Mellon University, that experiment with video signals;
they do not yet have ways of searching enormous collections, but they are
developing algorithms that exploit whatever they can find in the video:
scene breaks, closed-captioning, and so on.Again, there is the problem of deducing concepts from a new kind ofinformation. We started with the problem of words in one language need-
ing to be combined when synonymous, picked apart when ambiguous,
and moved on to detecting synonyms across multiple languages and then
to concepts depicted in pictures and sounds. Now we see research such as
that by Jezekiel Ben-Arie associating words like ÒrunÓ or 
ÒhopÓ with
video images of people doing those actions. In the same way we get again
new chemistry when molecules like ÒbuckyballsÓ are created and stimu-
late new theoretical and reaction studies.Defining concepts for search can be extremely difficult. For example,despite our abilities to parse and define every item in a computer lan-
guage, we have made no progress on retrieval of software; people looking
for search or sort routines depend on metadata or comments. Some areas
seem more flexible than others: text and naturalistic photograph process-
ing software tends to be very general, while software to handle CAD
diagrams and maps tends to be more specific. Algorithms are sometimes
portable; both speech processing and image processing need Fourier
transforms, but the literature is less connected than one might like (partly8An early publication was R. Elliott and M. Lesk, 1982, ÒRoute Finding in Street Maps byComputers and People,Ó Proceedings of the AIII-82 National Conference on Artificial Intelli-gence, Pittsburgh, Pa., August, pp. 258-261.9T. Barclay, J. Gray, and D. Slutz, 2000, ÒMicrosoft Terraserver: A Spatial Data Ware-house,Ó Proceedings of ACM SIGMOD, Association for Computing Machinery, New York,pp. 307-318.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.94COMPUTER SCIENCE: REFLECTIONSbecause of the difference between one-dimensional and two-dimensionaltransforms).There are many other examples of interesting computer science researchstimulated by the availability of particular kinds of information. Work on
string matching today is often driven by the need to align sequences in
either protein or DNA data banks. Work on image analysis is heavily
influenced by the need to deal with medical radiographs. And there are
many other interesting projects specifically linked to an individual data
source. Among examples:¥The British Library scanning of the original manuscript of Beowulfin collaboration with the University of Kentucky, working on image
enhancement until the result of the scanning is better than reading the
original;¥The Perseus project, demonstrating the educational applicationspossible because of the earlier Thesaurus Linguae Graecae project, which
digitized all the classical Greek authors;¥The work in astronomical analysis stimulated by the Sloan DigitalSky Survey;¥The creation of the field of Òforensic paleontologyÓ at the Univer-
sity of Texas as a result of doing MRI scans of fossil bones;¥And, of course, the enormous amount of work on search enginesstimulated by the Web.When one of these fields takes off, and we find wide usage of someonline resource, it benefits society. Every university library gained readers
as their catalogs went online and became accessible to students in their
dorm rooms. Third World researchers can now access large amounts of
technical content their libraries could rarely acquire in the past.In computer science, and in chemistry, there is a tension between thealgorithm/reaction and the data/substance. For example, should one look
up an answer or compute it? Once upon a time logarithms were looked
up in tables; today we also compute them on demand. Melting points and
other physical properties of chemical substances are looked up in tables;
perhaps with enough quantum mechanical calculation we could predict
them, but itÕs impractical for most materials. Predicting tomorrowÕsweather might seem a difficult choice. One approach is to measure the
current conditions, take some equations that model the atmosphere, and
calculate forward a day. Another is to measure the current conditions,
look in a big database for the previous day most similar to today, and then
take the day after that one as the best prediction for tomorrow. However,
so far the meteorologists feel that calculation is better. Another compli-
cated example is chess: given the time pressure of chess tournamentsComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION95against speed and storage available in computers, chess programs do theopening and the endgame by looking in tables of old data and calculate
for the middle game.To conclude, a recipe for stimulating advances in computer science isto make some data available and let people experiment with it. With the
incredibly cheap disks and scanners available today, this should be easier
than ever. Unfortunately, what we gain with technology we are losing to
law and economics. Many large databases are protected by copyright; few
motion pictures, for example, are old enough to have gone out of copy-
right. Content owners generally refuse to grant permission for wide use
of their material, whether out of greed or fear: they may have figured out
how to get rich off their files of information or they may be afraid that
somebody else might have. Similarly it is hard to get permission to digitize
in-copyright books, no matter how long they have been out of print. Jim
Gray once said to me, ÒMay all your problems be technical.Ó In the 1960s
I was paying people to key in aeronautical abstracts. It never occurred to
us that we should be asking permission of the journals involved (I think
what we did would qualify as fair use, but we didnÕt even think about it).Today I could scan such things much more easily, but I would not be able
to get permission. Am I better off or worse off?There are now some 22 million chemical substances in the ChemicalAbstracts Service Registry and 7 million reactions. New substances con-
tinue to intrigue chemists and cause research on new reactions, with of
course enormous interest in biochemistry both for medicine and agricul-
ture. Similarly, we keep adding data to the Web, and new kinds of infor-
mation (photographs of dolphins, biological flora, and countless other
things) can push computer scientists to new algorithms. In both cases,
synthesis of specific instances into concepts is a crucial problem. As we
see more and more kinds of data, we learn more about how to extract
meaning from it, and how to present it, and we develop a need for new
algorithms to implement this knowledge. As the data gets bigger, we
learn more about optimization. As it gets more complex, we learn more
about representation. And as it gets more useful, we learn more about
visualization and interfaces, and we provide better service to society.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.96COMPUTER SCIENCE: REFLECTIONSHISTORY AND THE FUNDAMENTALS OF COMPUTER SCIENCEEdward L. Ayers, University of VirginiaWe might begin with a thought experiment: What is history? Manypeople, IÕve discovered, think of it as books and the things in books.ThatÕs certainly the explicit form in which we usually confront history.Others, thinking less literally, might think of history as stories about the
past; that would open us to oral history, family lore, movies, novels, and
the other forms in which we get most of our history.All these images are wrong, of course, in the same way that images ofatoms as little solar systems are wrong, or pictures of evolution as profiles
of ever taller and more upright apes and people are wrong. They are all
models, radically simplified, that allow us to think about such things in
the exceedingly small amounts of time that we allot to these topics.The same is true for history, which is easiest to envision as technologi-cal progress, say, or westward expansion, of the emergence of freedomÑor of increasing alienation, exploitation of the environment, or the growth
of intrusive government.Those of us who think about specific aspects of society or nature for aliving, of course, are never satisfied with the stories that suit the purposes
of everyone else so well.We are troubled by all the things that donÕt fit, all the anomalies, vari-ance, and loose ends. We demand more complex measurement, descrip-
tion, and fewer smoothing metaphors and lowest common denominators.Thus, to scientists, atoms appear as clouds of probability; evolutionappears as a branching, labyrinthine bush in which some branches die out
and others diversify. It can certainly be argued that past human experi-
ence is as complex as anything in nature and likely much more so, if by
complexity we mean numbers of components, variability of possibilities,
and unpredictability of outcomes.Yet our means of conveying that complexity remain distinctly analog:the story, the metaphor, the generalization. Stories can be wonderfully
complex, of course, but they are complex in specific ways: of implication,
suggestion, evocation. ThatÕs what people love and what they remember.But maybe there is a different way of thinking about the past: asinformation. In fact, information is all we have. Studying the past is like
studying scientific processes for which you have the data but cannot run
the experiment again, in which there is no control, and in which you can
never see the actual process you are describing and analyzing. All we
have is information in various forms: words in great abundance, billions
of numbers, millions of images, some sounds and buildings, artifacts.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION97The historianÕs goal, it seems to me, should be to account for as muchof the complexity embedded in that information as we can. That, it
appears, is what scientists do, and it has served them well.And how has science accounted for ever-increasing amounts of com-plexity in the information they use? Through ever more sophisticated
instruments. The connection between computer science and history could
be analogous to that between telescopes and stars, microscopes and cells.
We could be on the cusp of a new understanding of the patterns of com-
plexity in human behavior of the past.The problem may be that there is too much complexity in that past, ortoo much static, or too much silence. In the sciences, weÕve learned how tofilter, infer, use indirect evidence, and fill in the gaps, but we have a much
more literal approach to the human past.We have turned to computer science for tasks of more elaboratedescription, classification, representation. The digital archive my colleagues
and I have built, the Valley of the Shadow Project, permits the manipula-
tion of millions of discrete pieces of evidence about two communities in
the era of the American Civil War. It uses sorting mechanisms, hyper-
textual display, animation, and the like to allow people to handle the
evidence of this part of the past for themselves. This isnÕt cutting-edgecomputer science, of course, but itÕs darned hard and deeply disconcert-ing to some, for it seems to abdicate responsibility, to undermine authority,
to subvert narrative, to challenge story.Now, weÕre trying to take this work to the next stage, to analysis. Wehave composed a journal article that employs an array of technologies,
especially geographic information systems and statistical analysis in the
creation of the evidence. The article presents its argument, evidence, and
historiographical context as a complex textual, tabular, and graphical
representation. XML offers a powerful means to structure text and XSL an
even more powerful means to transform it and manipulate its presenta-
tion. The text is divided into sections called Òstatements,Ó each supported
with Òexplanation.Ó Each explanation, in turn, is supported by evidence
and connected to relevant historiography.Linkages, forward and backward, between evidence and narrativeare central. The historiography can be automatically sorted by author,
date, or title; the evidence can be arranged by date, topic, or type. Both
evidence and historiographical entries are linked to the places in the analy-
sis where they are invoked. The article is meant to be used online, but it
can be printed in a fixed format with all the limitations and advantages
ofprint.
So, what are the implications of thinking of the past in the hard-headed sense of admitting that all we really have of the past is informa-
tion? One implication might be great humility, since all we have for mostComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.98COMPUTER SCIENCE: REFLECTIONSof the past are the fossils of former human experience, words frozen in inkand images frozen in line and color. Another implication might be hubris:
if we suddenly have powerful new instruments, might we be on the
threshold of a revolution in our understanding of the past? WeÕve beenthere before.A connection between history and social science was tried before,during the first days of accessible computers. Historians taught them-
selves statistical methods and even programming languages so that they
could adopt the techniques, models, and insights of sociology and politi-
cal science. In the 1950s and 1960s the creators of the new political history
called on historians to emulate the precision, explicitness, replicability,
and inclusivity of the quantitative social sciences. For two decades that
quantitative history flourished, promising to revolutionize the field. And
to a considerable extent it did: it changed our ideas of social mobility,
political identification, family formation, patterns of crime, economic
growth, and the consequences of ethnic identity. It explicitly linked the
past to the present and held out a history of obvious and immediate use.But that quantitative social science history collapsed suddenly, thevictim of its own inflated claims, limited method and machinery, and
changing academic fashion. By the mid-1980s, history, along with many
of the humanities and social sciences, had taken the linguistic turn. Rather
than software manuals and codebooks, graduate students carried books
of French philosophy and German literary interpretation. The social sci-
ence of choice shifted from sociology to anthropology; texts replaced

tables. A new generation defined itself in opposition to social scientific
methods just as energetically as an earlier generation had seen in those
methods the best means of writing a truly democratic history. The first
computer revolution largely failed.The first effort at that history fell into decline in part because historianscould not abide the distance between their most deeply held beliefs and
what the statistical machinery permitted, the abstraction it imposed. History
has traditionally been built around contingency and particularity, but the
most powerful tools of statistics are built on sampling and extrapolation,
on generalization and tendency. Older forms of social history talked about
vague and sometimes dubious classifications in part because that was
what the older technology of tabulation permitted us to see. It has become
increasingly clear across the social sciences that such flat ways of describ-
ing social life are inadequate; satisfying explanations must be dynamic,
interactive, reflexive, and subtle, refusing to reify structures of social life
or culture. The new technology permits a new cross-fertilization.Ironically, social science history faded just as computers became widelyavailable, just as new kinds of social science history became feasible. No
longer is there any need for white-coated attendants at huge mainframesComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.DATA, REPRESENTATION, AND INFORMATION99and expensive proprietary software. Rather than reducing people to rowsand columns, searchable databases now permit researchers to maintain
the identities of individuals in those databases and to represent entire
populations rather than samples. Moreover, the record can now include
things social science history could only imagine before the Web: com-
pletely indexed newspapers, with the original readable on the screen;
completely searchable letters and diaries by the thousands; and interactive
maps with all property holders identified and linked to other records.
Visualization of patterns in the data, moreover, far outstrips the possibili-
ties of numerical calculation alone. Manipulable histograms, maps, and
time lines promise a social history that is simultaneously sophisticated
and accessible. We have what earlier generations of social science historians
dreamed of: a fast and widely accessible network linked to cheap and
powerful computers running common software with well-established
standards for the handling of numbers, texts, and images. New possibili-
ties of collaboration and cumulative research beckon. Perhaps the time is
right to reclaim a worthy vision of a disciplined and explicit social scien-
tific history that we abandoned too soon.What does this have to do with computer science? Everything, itseems to me. If you want hard problems, historians have them. And
whatÕs the hardest problem of all right now? The capture of the veryinformation that is history. Can computer science imagine ways to cap-ture historical information more efficiently? Can it offer ways to work
with the spotty, broken, dirty, contradictory, nonstandardized informa-
tion we work with?The second hard problem is the integration of this disparate evidencein time and space, offering new precision, clarity, and verifiability, as well
as opening new questions and new ways of answering them.If we can think of these ways, then we face virtually limitless possi-bilities. Is there a more fundamental challenge or opportunity for com-
puter science than helping us to figure out human society over human
time?Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.1016Achieving IntelligenceOne of the great aspirations of computer science has been to under-stand and emulate capabilities that we recognize as expressive of
intelligence in humans. Research has addressed tasks rangingfrom our sensory interactions with the world (vision, speech, locomotion)
to the cognitive (analysis, game playing, problem solving). This quest to
understand human intelligence in all its forms also stimulates research
whose results propagate back into the rest of computer scienceÑfor
example, lists, search, and machine learning.Going beyond simply retrieving information, machine learning drawsinferences from available data. Mitchell describes the application of
classifying text documents automatically and shows how this research
exemplifies the experiment-analyze-generalize style of experimental
research.One of the exemplars of intelligent behavior is natural-language pro-cessing in all its formsÑincluding speech recognition and generation,
natural-language understanding, and machine translation. Lee describes
how, in the area of statistical natural-language understanding, the com-
mitment to an empirical computational perspective draws meaning from
data and brings interdisciplinary contributions together.Games have frequently provided settings for exploring new com-puting techniques. They make excellent testbeds because they are
usually circumscribed in scope, have well-defined rules, employ human-
performance standards for comparison, and are not on the critical path toComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.102COMPUTER SCIENCE: REFLECTIONSmake-or-break projects. In addition, they are engaging and appealing,which makes it easy to recruit early users. Koller and Biermann examine
the history of computer science endeavors in chess and checkers, showing
how success depends both on ÒsmartsÓ (improved representations and
algorithms) and sheer computer power.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE103THE EXPERIMENT-ANALYZE-GENERALIZE LOOP INCOMPUTER SCIENCE RESEARCH: A CASE STUDYTom Mitchell, Carnegie Mellon UniversityMuch research in computer science involves an iterative process ofattacking some new application problem, developing a computer pro-
gram to solve that specific problem, and then stepping back to learn a
general principle or algorithm, along with a precise description of the
general class of problems to which it can be applied. This experiment-
analyze-generalize loop lies at the heart of experimental computer science
research, and it is largely responsible for the continuous growth over
several decades in our knowledge of robust, effective computer algorithms.
Here we illustrate the approach with a case study involving machine-
learning algorithms for automatically classifying text. In particular, we
see how attempts to train a text classifier for classifying Web pages led to

a fundamental insight into a new class of learning algorithms.Automatically classifying text documents such as e-mails, Web pages,
and online memos is a problem of obvious importance. It would clearly
be useful for computers to automatically classify e-mails into categories
such as Òspam,Ó Òmeeting invitations,Ó and so on, or to automatically
classify Web pages into categories such as Òpersonal home page,Ó Òprod-uct announcement,Ó and others. Computer scientists have studied the
problem of automatic text classification for a number of years, over time
developing increasingly effective algorithms that achieve higher classifi-
cation accuracy and accommodate a broader range of text documents.Machine Learning for Text ClassificationOne approach to developing text classification software involvesmachine learning. In most software development, programmers write
detailed algorithms as line-by-line recipes to be executed by the com-
puter. In contrast, machine learning involves training the software by
instead showing it examples of inputs and outputs of the desired program.
The computer then learns (estimates) the general input-output function
from the examples provided. For instance, to train a program to classify
Web pages into categories such as 
Òpersonal home pageÓ or 
Òproductdescription,Ó we would present a set of training examples consisting of
individual Web pages (example inputs) and the correct classification for

each (example outputs). The machine-learning system uses these training
examples to produce a general program that achieves high accuracy on
these examples, and presumably on novel future inputs as well. While itComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.104COMPUTER SCIENCE: REFLECTIONSis unrealistic to expect perfect classification accuracy over novel futureexamples, in fact these accuracies for many text classification problems
are well above 90 percent, and are often higher than those that can be
achieved by manual programming (because humans generally donÕt knowthe general classification rule either!).What kind of machine-learning approach can analyze such trainingexamples to learn the correct classification rule? One popular machine
learning approach is a Bayesian classifier employing a bag-of-words
representation for Web pages. The bag-of-words representation, depicted

in Figure 6.1, describes each text document by the frequency of occurrence
of each word in the document. Although this representation removes
information such as the exact sequence in which words occur, it has been
found to be highly effective for document classification.Once the training-example Web pages are described in terms of their
word frequencies, the classifier can calculate from these training examples
the average frequency for each word, within each different class of Web

pages. A new document can then be automatically classified by first
observing its own word frequencies and then assigning it to the class
whose average frequencies are most similar to its own. The naive Bayes
classifier uses this general approach. More precisely, it uses the training
data to estimate the probability P(wi|cj) that a word drawn at randomfrom a random document from class cj will be the word 
wi (e.g.,
P(ÒphoneÓ|home page) is the probability that a random word found on arandom home page will be the word ÒphoneÓ). Thousands of such prob-ability terms are estimated during training (i.e., if English contains
approximately 105 words, and if we consider only two distinct classes of
Web pages, then the program will estimate such 2 
 10
5 probabilities).
These learned probabilities, along with the estimated class priors, are
then used to classify a new document, d, by calculating the probabilityP(wi|d) that d belongs to the class 
cj based on its observed words.Figure6.2 summarizes the training and classification procedures for the

naive Bayes classifier (this type of Bayes classifier is called ÒnaŁveÓ because
it makes the assumption that words occur independently within docu-
ments of each class, and ÒBayesianÓ because it uses Bayes rules along
with the learned probability terms to classify new documents).Improving Accuracy by Learning from Unlabeled ExamplesAlthough the naive Bayes classifier can often achieve accuracies of90percent or higher when trained to discriminate classes of Web pages

such as Òpersonal home pageÓ versus 
Òacademic course Web page,Ó it
often requires many hundreds or thousands of training examples to reach
this accuracy. Thus, the primary cost in developing the classifier involvesComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.105FIGURE 6.1In the bag-of-words approach, text documents are described solely by the frequencies of the words they contain.
Here, the Web page on the left is represented by the frequencies of each word it contains (shown by the list of words andfrequencies on the right).Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.106COMPUTER SCIENCE: REFLECTIONSFIGURE 6.2Na
Łve Bayes Learner based on the bag-of-words representation fromFigure 6.1.hand-labeling the training examples. This leads to the interesting question:Can we devise learning methods that achieve higher accuracy when given
unlabeled examples (e.g., additional Web pages without their classifica-

tion) in addition to a set of labeled examples? At first it may seem that the
answer must be no, because providing unlabeled examples amounts to
providing an example input to the program without providing the desired
output. Surprisingly, if the text documents we wish to classify are Web
pages, then we shall see that the answer is yes, due to a particular charac-
teristic of Web pages.The characteristic that makes it possible to benefit from unlabeleddata when learning to classify Web pages is illustrated in Figure 6.3. Note
first that Web pages typically appear on the Web along with hyperlinks

that point to them. We can therefore think of each example Web page as

being described by two sets of features: the words occurring within the
page (which we will call X1) and the words occurring on hyperlinks thatpoint to this page (which we will call X2). Furthermore, in many cases theX1 features alone are sufficient to classify the page without 
X2 (i.e., even
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE107FIGURE 6.3Redundantly sufficient features for classifying Web pages. Note that
the class of this Web page (Òfaculty home pageÓ) can be inferred from either (a)the words on the Web page or (b) the words on the hyperlinks that point to the
page. In such cases we say that these two feature sets are Òredundantly suffi-cientÓ to classify the example.
when ignoring the hyperlinks, it is obvious that the Web page of Figure6.3
belongs to the class Òfaculty home pageÓ). Similarly, the X2 features taken
alone may also be sufficient to classify the page (i.e., if the hyperlink
pointing to the page contains the words ÒProfessor Faloutsos,Ó the page is
most probably a Òfaculty home pageÓ). In short, we say in this case thatthe features describing the example Web pages are redundantly sufficientComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.108COMPUTER SCIENCE: REFLECTIONSto perform the classification. Furthermore, notice that the hyperlink wordstend to be quite independent of the exact words on the page, given the
class of the page (in part because the hyperlinks and the pages to which
they point are often written by different authors).This characteristic of Web pages suggests the following training pro-cedure for using a combination of labeled and unlabeled examples: First,
we use the labeled training examples to train two different naive Bayes
classifiers. One of these classifiers uses only the X1 features; the other uses
only the X2 features. The first classifier is then applied to the unlabeled
training examples, and it selects the example d that it is most confident in
classifying (i.e., the example that yields the highest probability P(cj|d)).Itis then allowed to assign that label to this previously unlabeled example,

and the second classifier is now retrained using this new labeled example
along with the original labeled examples. The identical process can be
executed reversing the roles of the two classifiers, using each to train the
other. This process is called co-training. Furthermore, the process can be
repeated many times, each time assigning a few most-confident labels to
the initially unlabeled examples.Does this learning algorithm work in practice? It does. Blum andMitchell,1 for example, describe experiments using co-training to classify
Web pages into the categories Òacademic course home pageÓ or not. Start-
ing with just 12 labeled Web pages, they found that co-training with an
additional 788 unlabeled Web pages reduced the classification error rate
by a factor of two, from 11 percent to 5 percent.Analyze the Specific Solution to Generalize the PrincipleGiven the empirical success of this co-training algorithm for classify-ing Web pages, it is natural to ask: What is the general class of machine-

learning problems for which unlabeled data can be proven to improve
classification accuracy? Intuitively, the reason co-training works when
learning to classify Web pages is that (1) the examples can be described by

two different sets of features (hyperlink words, page words) that are
redundantly sufficient, and (2) the two features are distributed somewhat
independently, so that an example with an easy-to-classify hyperlink is
likely to point to a Web page of average classification difficulty. We can
1A. Blum and T. Mitchell, 1998, ÒCombining Labeled and Unlabeled Data with Co-Training,Ó Proceedings of the 1998 Conference on Computational Learning Theory, Associationfor Computing Machinery, New York.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE109therefore train two classifiers, using each to produce new, high-confidencelabels for training the other.Blum and Mitchell make this intuitive characterization more preciseand formal.2 They prove that for the class of learning problems they
define, one can learn successfully from a small set of labeled examples
and a larger volume of unlabeled examples. The essence of their charac-
terization is as follows. In general, one can view the problem of learning a
classifier as the problem of estimating some unknown classifier function
f:X Y given only a set of labeled input-output examples {xi,f(xi)} anda set of unlabeled examples {xi} with unknown output. The co-trainingproblem setting can then be defined as a special case of learning a
classifier, where (1) the input instances X can be described as 
X1  X2 (i.e.,
X1 = hyperlink words, 
X2 = Web page words), and where (2) one can
compute f  based on either 
X1 or 
X2 (formally, there exist functions 
g1 and 
g2such that f(x) = g1(x1) = g2(x2) for any x = 
x1,x2. They then go on tocharacterize the impact of unlabeled data on learning behavior in several
situations. For example, they show that if one makes the additional assump-
tion 
that X1 and X2 are conditionally independent given the class Y, thenany function that is learnable from noisy labeled data can also be learned
from a small set of labeled data that produces better-than-random accu-
racy, plus unlabeled data.SummaryThis case study shows how the attempt to find more accurate learningalgorithms for Web page classification motivated the development of a

specialized algorithm, which in turn motivated a formal analysis to under-
stand the precise class of problems for which the learning algorithm could
be proven to succeed. In fact, the insights provided by this analysis have,
in turn, led to the development of more accurate learning algorithms for
this class of problems (e.g., Collins and Singer,3 and Muslea et al.
4). Further-2A. Blum and T. Mitchell, 1998, ÒCombining Labeled and Unlabeled Data with Co-Training,Ó Proceedings of the 1998 Conference on Computational Learning Theory, Associationfor Computing Machinery, New York.3M. Collins and Y. Singer, 1999, ÒUnsupervised Models for Named Entity Classification,ÓProceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processingand Very Large Corpora, Association for Computational Linguistics, East Stroudsburg, Pa.,pp. 100-110.4I. Muslea, S. Minton, and C. Knoblock, 2000, ÒSelective Sampling with Redundant Views,ÓProceedings of the Seventeenth National Conference on Artificial Intelligence, AAAI Press, MenloPark, Calif., pp. 621-626.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.110COMPUTER SCIENCE: REFLECTIONSmore, it 
made it apparent that the co-training algorithm published byBlum and Mitchell was in fact similar to an earlier algorithm by Yarowski5for learning to disambiguate word senses (e.g., learning whether ÒbankÓrefers to a financial institution, or a place near a river). In YarowskiÕs case,the features X1 and 
X2 are the linguistic context in which the word occurs,
and the document in which it occurs.This case study illustrates the useful interplay between experimentand theory in advancing computer science. The advance in our under-
standing of the science of computation can be described in this case using
statements of the form Òfor problems that exhibit structure S, algorithm Awill exhibit property P.Ó In some cases we have only experimental evi-
dence to support conjectures of this form, in some cases analytical proofs,
but in many cases a blend of the two, and a family of related statements
rather than a single one.Of course the interplay between experiment and analysis is generallymessy, and not quite as clean as post facto reports would like to make it
appear! In many cases the formal models motivated by specific applica-
tions do not fully capture the complexities of the application. In our own
case study, for instance, the assumption that hyperlink words can be used
to classify the Web page they point to is not quite validÑsome hyperlinkwords such as Òclick hereÓ provide no information at all about the page
they point to! Nevertheless, theoretical characterizations of the problem
are useful even if incomplete and approximate, provided they capture a
significant problem structure that impacts on the design and performance
of algorithms. And the experiment-analyze-generalize cycle of research
often leads to a second and third generation of experiments and of theo-
retical models that better characterize the application problems, just as
current theoretical research on using unlabeled data is now considering
problem formalizations that relax the assumption violated by the ÒclickhereÓ hyperlinks.
5D. Yarowsky, 1995, ÒUnsupervised Word Sense Disambiguation Rivaling SupervisedMethods,Ó Proceedings of the 33rd Annual Meeting of the Association for ComputationalLinguistics, Association for Computational Linguistics, East Stroudsburg, Pa., pp. 189-196.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE111ÒIÕM SORRY DAVE, IÕM AFRAID I CANÕT DO THATÓ:LINGUISTICS, STATISTICS, AND NATURAL-LANGUAGEPROCESSING CIRCA 2001Lillian Lee, Cornell UniversityIts the year 2000, but where are the flying cars? I was promised flying cars.ÑAvery Brooks, IBM commercialAccording to many pop-culture visions of the future, technology willeventually produce the Machine That Can Speak to Us. Examples range

from the False Maria in Fritz LangÕs 1926 film Metropolis to Knight RiderÕsKITT (a talking car) to Star WarsÕ C-3PO (said to have been modeled on
the False Maria). And, of course, there is the HAL 9000 computer from
2001: A Space Odyssey; in one of the filmÕs most famous scenes, the astro-naut Dave asks HAL to open a pod bay door on the spacecraft, to which
HAL responds, ÒIÕm sorry Dave, IÕm afraid I canÕt do that.ÓNatural-language processing, or NLP, is the field of computer sciencedevoted to creating such machinesÑthat is, enabling computers to usehuman languages both as input and as output. The area is quite broad,
encompassing problems ranging from simultaneous multi-language
translation to advanced search engine development to the design of
computer interfaces capable of combining speech, diagrams, and other
modalities simultaneously. A natural consequence of this wide range of
inquiry is the integration of ideas from computer science with work from
many other fields, including linguistics, which provides models of language;
psychology, which provides models of cognitive processes; information
theory, which provides models of communication; and mathematics and
statistics, which provide tools for analyzing and acquiring such models.The interaction of these ideas together with advances in machinelearning (see Mitchell in this chapter) has resulted in concerted research
activity in statistical natural-language processing: making computers
language-enabled by having them acquire linguistic information directly
from samples of language itself. In this essay, we describe the history of
statistical NLP; the twists and turns of the story serve to highlight the
sometimes complex interplay between computer science and other fields.Although currently a major focus of research, the data-driven, com-putational approach to language processing was for some time held in
deep disregard because it directly conflicts with another commonly held
viewpoint: human language is so complex that language samples alone
seemingly cannot yield enough information to understand it. Indeed, it is
often said that NLP is ÒAI-completeÓ (a pun on NP-completeness; see
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.112COMPUTER SCIENCE: REFLECTIONSKleinberg and Papadimitriou in Chapter 2), meaning that the most difficultproblems in artificial intelligence manifest themselves in human language
phenomena. This belief in language use as the touchstone of intelligent
behavior dates back at least to the 1950 proposal of the Turing Test6 as a
way to gauge whether machine intelligence has been achieved; as Turing
wrote, ÒThe question and answer method seems to be suitable for intro-ducing almost any one of the fields of human endeavor that we wish to
include.ÓThe reader might be somewhat surprised to hear that language under-standing is so hard. After all, human children get the hang of it in a few
years, word processing software now corrects (some of) our grammatical
errors, and TV ads show us phones capable of effortless translation. One
might therefore be led to believe that HAL is just around the corner.Such is not the case, however. In order to appreciate this point, wetemporarily divert from describing statistical NLPÕs historyÑwhichtouches upon Hamilton versus Madison, the sleeping habits of colorless
green ideas, and what happens when one fires a linguistÑto examine afew examples illustrating why understanding human language is such a
difficult problem.Ambiguity and Language AnalysisAt last, a computer that understands you like your mother.Ñ1985 McDonnell-Douglas adThe snippet quoted above indicates the early confidence at least onecompany had in the feasibility of getting computers to understand human
language. But in fact, that very sentence is illustrative of the host of diffi-
culties that arise in trying to analyze human utterances, and so, ironically,
it is quite unlikely that the system being promoted would have been up to
the task. A momentÕs reflection reveals that the sentence admits at leastthree different interpretations:1.The computer understands you as well as your mother under-
stands you.2.The computer understands that you like your mother.

3.The computer understands you as well as it understands your
mother.6Roughly speaking, a computer will have passed the Turing Test if it can engage inconversations indistinguishable from those of a human.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE113That is, the sentence is ambiguous; and yet we humans seem toinstantaneously rule out all the alternatives except the first (and presum-
ably the intended) one. We do so based on a great deal of background
knowledge, including understanding what advertisements typically try
to convince us of. How are we to get such information into a computer?A number of other types of ambiguity are also lurking here. For
example, consider the speech recognition problem: how can we distin-
guish between this utterance, when spoken, and Ò. . . a computer thatunderstands your lie cured motherÓ? We also have a word sense ambiguityproblem: how do we know that here ÒmotherÓ means 
Òa female parent,Órather than the Oxford English Dictionary-approved alternative of Òa caskor vat used in vinegar-makingÓ? Again, it is our broad knowledge aboutthe world and the context of the remark that allows us humans to make
these decisions easily.Now, one might be tempted to think that all these ambiguities arisebecause our example sentence is highly unusual (although the ad writers
probably did not set out to craft a strange sentence). Or, one might argue
that these ambiguities are somehow artificial because the alternative inter-
pretations are so unrealistic that an NLP system could easily filter them
out. But ambiguities crop up in many situations. For example, in ÒCopythe local patient files to diskÓ (which seems like a perfectly plausible
command to issue to a computer), is it the patients or the files that are
local?7 Again, we need to know the specifics of the situation in order to
decide. And in multilingual settings, extra ambiguities may arise. Here is
a sequence of seven Japanese kanji characters:Since Japanese doesnÕt have spaces between words, one is faced withthe initial task of deciding what the component words are. In particular,
this character sequence corresponds to at least two possible word
sequences, Òpresident, both, business, general-managerÓ (= 
Òa presidentas well as a general manager of businessÓ) and Òpresident, subsidiary-business, Tsutomu (a name), general-managerÓ (= ?). It requires a fair bit
of linguistic information to choose the correct alternative.87Or, perhaps, the files themselves are patient? But our knowledge about the world rulesthis possibility out.8To take an analogous example in English, consider the non-word-delimited sequence ofletters Òtheyouthevent.Ó This corresponds to the word sequences 
Òthe youth event,Ó Òtheyout he vent,Ó and 
Òthe you the vent.ÓComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.114COMPUTER SCIENCE: REFLECTIONSTo sum up, we see that the NLP task is highly daunting, for to resolvethe many ambiguities that arise in trying to analyze even a single sentence
requires deep knowledge not just about language but also about the world.And so when HAL says, ÒIÕm afraid I canÕt do that,Ó NLP researchers aretempted to respond, ÒIÕm afraid you might be right.ÓFirth Things FirstBut before we assume that the only viable approach to NLP is a mas-sive knowledge-engineering project, let us go back to the early approaches
to the problem. In the 1940s and 1950s, one prominent trend in linguistics
was explicitly empirical and in particular distributional, as exemplified
by the work of Zellig Harris (who started the first linguistics program in
the United States). The idea was that correlations (co-occurrences) found
in language data are important sources of information, or, as the influen-
tial linguist J.R. Firth declared in 1957, ÒYou shall know a word by thecompany it keeps.ÓSuch notions accord quite happily with ideas put forth by ClaudeShannon in his landmark 1948 paper establishing the field of information
theory; speaking from an engineering perspective, he identified the prob-
ability of a messageÕs being chosen from among several alternatives, ratherthan the messageÕs actual content, as its critical characteristic. Influencedby this work, Warren Weaver in 1949 proposed treating the problem of
translating between languages as an application of cryptography (see
Sudan in Chapter 7), with one language viewed as an encrypted form of
another. And Alan TuringÕs work on cracking German codes duringWorld War II led to the development of the Good-Turing formula, an
important tool for computing certain statistical properties of language.In yet a third area, 1941 saw the statisticians Frederick Mosteller andFrederick Williams address the question of whether it was Alexander
Hamilton or James Madison who wrote the various pseudonymous Feder-alist Papers. Unlike previous attempts, which were based on historicaldata and arguments, Mosteller and Williams used the patterns of word
occurrences in the texts as evidence. This work led up to the famed
Mosteller and Wallace statistical study that many consider to have settled
the authorship of the disputed papers.Thus, we see arising independently from a variety of fields the ideathat language can be viewed from a data-driven, empirical perspectiveÑand a data-driven perspective leads naturally to a computational
perspective.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE115A ÒCÓ Change
However, data-driven approaches fell out of favor in the late 1950s.One of the commonly cited factors is a 1957 argument by linguist (and
student of Harris) Noam Chomsky, who believed that language behavior
should be analyzed at a much deeper level than its surface statistics. He
claimed,It is fair to assume that neither sentence (1) [Colorless green ideassleep furiously] nor (2) [Furiously sleep ideas green colorless] . . . has
ever occurred. . . . Hence, in any [computed] statistical model . . . thesesentences will be ruled out on identical grounds as equally ÒremoteÓfrom English. Yet (1), though nonsensical, is grammatical, while (2) is
not.9That is, we humans know that sentence (1), which at least obeys(some) rules of grammar, is indeed more probable than (2), which is just
word salad; but (the claim goes), since both sentences are so rare, they will
have identical statisticsÑi.e., a frequency of zeroÑin any sample ofEnglish. ChomskyÕs criticism is essentially that data-driven approacheswill always suffer from a lack of data, and hence are doomed to failure.This observation turned out to be remarkably prescient: even now,when billions of words of text are available online, perfectly reasonable
phrases are not present. Thus, the so-called sparse data problem con-
tinues to be a serious challenge for statistical NLP even today. And so, the
effect of ChomskyÕs claim, together with some negative results formachine learning and a general lack of computing power at the time, was
to cause researchers to turn away from empirical approaches and toward
knowledge-based approaches where human experts encoded relevant
information in computer-usable form.This change in perspective led to several new lines of fundamental,interdisciplinary research. For example, ChomskyÕs work viewing lan-guage as a formal, mathematically describable object has had a lasting
impact on both linguistics and computer science; indeed, the Chomsky
hierarchy, a sequence of increasingly more powerful classes of grammars,
is a staple of the undergraduate computer science curriculum. Conversely,
the highly influential work of, among others, Kazimierz Adjukiewicz,
Joachim Lambek, David K. Lewis, and Richard Montague adopted the
lambda calculus, a fundamental concept in the study of programming
languages, to model the semantics of natural languages.9Interestingly, this claim has become so famous as to be self-negating, as simple Websearches on ÒColorless green ideas sleep furiouslyÓ and its reversal will show.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.116COMPUTER SCIENCE: REFLECTIONSThe Empiricists Strike BackBy the 1980s, the tide had begun to shift once again, in part because ofthe work done by the speech recognition group at IBM. These researchers,
influenced by ideas from information theory, explored the power of
probabilistic models of language combined with access to much more
sophisticated algorithmic and data resources than had previously been
available. In the realm of speech recognition, their ideas form the core of
the design of modern systems; and given the recent successes of such
softwareÑlarge-vocabulary continuous-speech recognition programs arenow available on the marketÑit behooves us to examine how these sys-tems work.Given some acoustic signal, which we denote by the variable a, wecan think of the speech recognition problem as that of transcription:
determining what sentence is most likely to have produced a. Probabilities
arise because of the ever-present problem of ambiguity: as mentioned
above, several word sequences, such as Òyour lie cured motherÓ versus
Òyou like your mother,Ó can give rise to similar spoken output. Therefore,
modern speech recognition systems incorporate information both about
the acoustic signal and the language behind the signal. More specifically,
they rephrase the problem as determining which sentence s maximizes
the product P(a|s)  P(s). The first term measures how likely the acousticsignal would be if s were actually the sentence being uttered (again, we
use probabilities because humans donÕt pronounce words the same wayall the time). The second term measures the probability of the sentence sitself; for example, as Chomsky noted, Òcolorless green ideas sleep furi-ouslyÓ is intuitively more likely to be uttered than the reversal of the
phrase. It is in computing this second term, P(s), where statistical NLPtechniques come into play, since accurate estimation of these sentence
probabilities requires developing probabilistic models of language. These
models are acquired by processing tens of millions of words or more. This
is by no means a simple procedure; even linguistically naive models
require the use of sophisticated computational and statistical techniques
because of the sparse data problem foreseen by Chomsky. But using
probabilistic models, large datasets, and powerful learning algorithms
(both for P(s) and P(a|s)) has led to our achieving the milestone ofcommercial-grade speech recognition products capable of handling con-
tinuous speech ranging over a large vocabulary.But let us return to our story. Buoyed by the successes in speechrecognition in the 1970s and 1980s (substantial performance gains over
knowledge-based systems were posted), researchers began applying data-

driven approaches to many problems in natural-language processing, in a
turn-around so extreme that it has been deemed a Òrevolution.Ó Indeed,
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE117now empirical methods are used at all levels of language analysis. This isnot just due to increased resources: a succession of breakthroughs in
machine-learning algorithms has allowed us to leverage existing resources
much more effectively. At the same time, evidence from psychology
shows that human learning may be more statistically based than previ-
ously thought; for instance, work by Jenny Saffran, Richard Aslin, and
Elissa Newport reveals that 8-month-old infants can learn to divide con-
tinuous speech into word segments based simply on the statistics of
sounds following one another. Hence, it seems that the ÒrevolutionÓ is
here to stay.Of course, we must not go overboard and mistakenly conclude thatthe successes of statistical NLP render linguistics irrelevant (rash state-
ments to this effect have been made in the past, e.g., the notorious remark,
Òevery time I fire a linguist, my performance goes upÓ). The informationand insight that linguists, psychologists, and others have gathered about
language is invaluable in creating high-performance broad-domain lan-
guage understanding systems; for instance, in the speech recognition set-
ting described above, a better understanding of language structure can
lead to better language models. Moreover, truly interdisciplinary research
has furthered our understanding of the human language faculty. One
important example of this is the development of the head-driven phrase
structure grammar (HPSG) formalismÑthis is a way of analyzing naturallanguage utterances that truly marries deep linguistic information with
computer science mechanisms, such as unification and recursive data-
types, for representing and propagating this information throughout the
utteranceÕs structure. In sum, although many challenges remain (forinstance, while the speech-recognition systems mentioned above are very
good at transcription, they are a long way from engaging in true language
understanding), computational techniques and data-driven methods are
now an integral part both of building systems capable of handling
language in a domain-independent, flexible, and graceful way, and of
improving our understanding of language itself.AcknowledgmentsThanks to the members of and reviewers for the CSTB fundamentalsof computer science study, and especially Alan Biermann, for their help-
ful feedback. Also, thanks to Alex Acero, Takako Aikawa, Mike Bailey,Regina Barzilay, Eric Brill, Chris Brockett, Claire Cardie, Joshua Goodman,
Ed Hovy, Rebecca Hwa, John Lafferty, Bob Moore, Greg Morrisett,
Fernando Pereira, Hisami Suzuki, and many others for stimulating dis-
cussions and very useful comments. Rie Kubota Ando provided the Japanese
example. The use of the term ÒrevolutionÓ to describe the re-ascendance
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.118COMPUTER SCIENCE: REFLECTIONSof statistical methods comes from Julia HirschbergÕs 1998 invited addressto the American Association for Artificial Intelligence. The McDonnell-
Douglas ad and some of its analyses were presented in a lecture by Stuart
Shieber. All errors are mine alone. This paper is based on work supported
in part by the National Science Foundation under ITR/IM grant IIS-
0081334 and a Sloan Research Fellowship. Any opinions, findings, and
conclusions or recommendations expressed above are those of the author
and do not necessarily reflect the views of the National Science Founda-
tion or the Sloan Foundation.BibliographyChomsky, Noam, 1957, ÒSyntactic Structures,Ó Number IV in 
Janua Linguarum. Mouton,The Hague, The Netherlands.Firth, John Rupert, 1957, ÒA Synopsis of Linguistic Theory 1930-1955,Ó pp. 1-32 in the Philo-
logical SocietyÕs Studies in Linguistic Analysis. Blackwell, Oxford. Reprinted in SelectedPapers of J.R. Firth, F. Palmer (ed.), Longman, 1968.Good, Irving J., 1953, ÒThe Population Frequencies of Species and the Estimation of Popula-tion Parameters,Ó Biometrika 40(3,4):237-264.
Harris, Zellig, 1951, Methods in Structural Linguistics, University of Chicago Press. Reprintedby Phoenix Books in 1960 under the title Structural Linguistics.Montague, Richard, 1974, Formal Philosophy: Selected Papers of Richard Montague, RichmondH. Thomason (ed.), Yale University Press, New Haven, Conn.Mosteller, Frederick, and David L. Wallace, 1984, Applied Bayesian and Classical Inference: TheCase of the Federalist Papers, Springer-Verlag. First edition published in 1964 under thetitle Inference and Disputed Authorship: The Federalist.Pollard, Carl, and Ivan Sag, 1994, Head-driven Phrase Structure Grammar, University of
Chicago Press and CSLI Publications.Saffran, Jenny R., Richard N. Aslin, and Elissa L. Newport, 1996, ÒStatistical Learning by8-Month-Old Infants,Ó Science 274(5294):1926-1928, December.
Shannon, Claude E., 1948, ÒA Mathematical Theory of Communication,Ó Bell System Techni-cal Journal 27:379-423 and 623-656.
Turing, Alan M., 1950, ÒComputing Machinery and Intelligence,Ó Mind LIX:433-460.Weaver, Warren, 1949, ÒTranslation,Ó Memorandum. Reprinted in W.N. Locke and A.D.
Booth, eds., Machine Translation of Languages: Fourteen Essays, MIT Press, Cambridge,Mass., 1955.For Further ReadingCharniak, Eugene, 1993, Statistical Language Learning, MIT Press, Cambridge, Mass.
Jurafsky, Daniel, and James H. Martin, 2000, Speech and Language Processing: An Introductionto Natural Language Processing, Computational Linguistics, and Speech Recognition, PrenticeHall. Contributing writers: Andrew Keller, Keith Vander Linden, and Nigel Ward.Manning, Christopher D., and Hinrich Schtze, 1999, Foundations of Statistical Natural Lan-guage Processing, MIT Press, Cambridge, Mass.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE119COMPUTER GAME PLAYING:BEATING HUMANITY AT ITS OWN GAMEDaphne Koller, Stanford University, andAlan Biermann, Duke UniversityThe idea of getting a computer to play a complex game such ascheckers or chess has been present in computer science research from its
earliest days. The earliest effort even predated real computers. In 1769,
Baron Wolfgang von Kempelen displayed a chess-playing automaton
called ÒTurk.Ó It drew a lot of attention, until people realized that the
cabinet of the ÒmachineÓ concealed a human dwarf who was a chess
expert.The first real attempt to show how a computer could play a game wasby Claude Shannon, one of the fathers of information science. The basic
idea is to define a game tree that tells us all of the possible move sequences
in the game. We can then ask, at each point in the tree, what a rational
(selfish) player would do at that point. The answer comes from an analy-
sis of the game tree beginning at the end of the tree (the termination of the
game). For example, assume that one player has black pieces and the
other white pieces. We can mark each game termination point as BÑblackwins, WÑwhite wins, or DÑdraw. Then we can work our way from thetermination points of the game backwards: If the white player, at her turn,
has a move leading to a position marked W, then she can take that move
and guarantee a win; in this case, this position is labeled with W. Other-
wise, if she has a move leading to a position marked D, then she can force
a draw, and the position is labeled with D. If all of her moves lead to
positions marked B, then this position is a guaranteed win for black
(assuming he plays optimally), and it is marked with B. Similar propaga-
tion rules apply to positions controlled by the black player. Thus, assum-
ing perfect play by each player, we can completely understand the win
potential of every board position.This procedure is a great theoretical tool for thinking about a game.For example, it shows that, assuming both players play perfectly, we can
determine without playing a single move which of the players will win,
or if the game has a forced draw. We simply carry out the above proce-
dure and check whether the initial position is marked with a B, a W, or a
D. Unfortunately, for almost all realistic games, this procedure cannot be
carried out because the size of the computation is too large. For example,
the game tree for chess has approximately 10120 trajectories. As Shannon
points out, a computer that evaluated a million positions per second
would require over 1095 years just to decide on its first move!
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.120COMPUTER SCIENCE: REFLECTIONSShannonÕs idea was to explore only part of the game tree. At eachposition, the computer looks forward a certain number of steps, and then
somehow evaluates the positions reached even if they are not wins or
losses. For example, it can give a higher score to positions where it has
more pieces. The computer then selects an optimal move relative to that
myopic perspective about the game.Turing, the inventor of the Turing machine (see ÒComputability andComplexityÓ by Kleinberg and Papadimitriou in Chapter 2) was the first to
try and implement this idea. He wrote the first program capable of playing
a full game of chess. But this program never ran on a computer; it was
hand-simulated against a very weak player, who managed to beat it anyway.The first attempt to get an actual computer to play a full-scale realgame was made by Arthur Samuel. In the mid-1940s, Samuel was a pro-
fessor of electrical engineering at the University of Illinois and became
active in a project to design one of the first electronic computers. It was
there that he conceived the idea of a checkers program that would beat
the world champion and demonstrate the power of electronic computers.
Apparently the program was not finished while he was at the University
of Illinois, perhaps because the computer was not completed in time.In 1949, Samuel joined IBMÕs Poughkeepsie Laboratory and workedon IBMÕs first stored program computer, the 701. SamuelÕs work oncheckers was not part of his job. He did the work in his spare time, with-
out telling his supervisors. He got the computer operators (who had to
authorize and run all computer programs) to run his program by telling
them it was testing the capabilities of the 701. This program was one of
the first programs to run on IBMÕs very first production computer. Thecomputer spent its days being tested for accounting and scientific compu-
tation, and its nights playing checkers.Interestingly, SamuelÕs justification for using the machine was actu-ally valid. Indeed, because his checkers program was one of the earliest
examples of non-numerical computation, Samuel greatly influenced the
instruction set of early IBM computers. The logical instructions of these
computers were put in at his instigation and were quickly adopted by all
computer designers, because they are useful for most non-numerical
computation.SamuelÕs program was the first to play checkers at a reasonable level.It not only implemented ShannonÕs ideas; it also extended them substan-tially by introducing new and important algorithmic ideas. For example,
ShannonÕs original proposal was to search all of the paths in the game upto a given depth. SamuelÕs program used a more sophisticated algorithm,called alpha-beta pruning, that avoided exploring paths that it could prove
were suboptimal. This algorithm allowed Samuel to almost double the
number of steps that it looked into the future before making the decision.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE121FIGURE 6.4The alpha-beta search procedure makes move A without examining
any of the paths marked +.Alpha-beta pruning allowed SamuelÕs program to prune largenumbers of paths in the tree that would never be taken in optimal play.
Consider the example in Figure 6.4. Here, the machine, playing white, has
two moves, leading to positions A and B. The machine examines the paths
that continue beyond position A and determines that the quality (accord-
ing to some measure) of the best position it can reach from A is 10. It then
starts evaluating position B, where the black player moves. The first move
by black leads to position B1; this position is evaluated, by exploring the
paths below it, to have a value of 5 (to white). Now, consider any other
move by black, say to B2. Either B2 is worth more than 5, or less than 5. If
it is worth more than 5, then it is a better position for white, and black,
playing to win, would not take it. If it is worth less than 5, then black will
take it, and the result will only be worse for white. Thus, no matter what,
if the machine moves to position B, it can expect to end up with a position
valued at 5 or less. As it can get 10 by moving to position A, it will never
move to B. And it can determine this without ever exploring B2, B3, . . .,
B12, or any of their descendants. This powerful idea coupled with other
mechanisms enabled the search routines to run hundreds or even thou-
sands of times faster than would have otherwise been possible.Besides having sophisticated search capability, SamuelÕs program wasthe first program that learned by itself how to perform a task better. Samuel
himself was a mediocre checkers player. But he was a very smart com-
puter scientist. He came up with a method by which the computer couldComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.122COMPUTER SCIENCE: REFLECTIONSgradually improve its play as it played more and more games. Recall thatthe computer has to evaluate each non-terminal position. One could, for
example, count the number of pieces of each type on the board and add
them up with appropriate weights. But is a king worth twice as much as a
regular piece, or perhaps five times as much? Samuel came up with the
following idea: letÕs learn these weights by seeing which set of weightsleads to better play. Thus, the computer would play using one set of
weights, and after seeing whether it won or lost the game, it would go and
adjust the weights to get a more correct evaluation of the positions it had
encountered along the way. If it won, it would aim to increase its valua-
tion for these positions, and if it lost, it would decrease them. Although no
single run is reliable in determining the value of a position (a bad position
might, by chance, lead to a win), over time the valuations tended to get
better. Although the computer started out playing very poor checkers, it
ended up playing better than Samuel.SamuelÕs program, even today, is a very impressive achievement,since the 701 had 10 kilobytes of main memory and used a magnetic tape
(and not a disk) for storage. Thus, it had less memory than one of the
musical greeting cards that one can buy at the store for a few dollars.When it was about to be demonstrated, Thomas J. Watson, Sr., thefounder and president of IBM, remarked that the demonstration would
raise the price of IBM stock 15 points. It did. SamuelÕs program and othersgenerated a lot of excitement, and many people were led to believe that
computers would soon be better than any human player. Indeed, in 1957,
Allen Newell and eventual Nobel-prize winner Herbert Simon predicted
that in 10 years, a computer would be world chess champion. Unfortu-
nately, these predictions were premature. Impressive as SamuelÕs achieve-ment was, it was not a very good checkers player. Although it was able to
beat Samuel, most competent checkers players beat it without much strain.Perhaps an early failure was to be expected in this new science, andpeople began to write much better programs. This effort was carried over
to the more popular game of chess, and a number of individuals around
the country began bringing their programs to an annual chess tourna-
ment. It was fun to see computers play against each other, but the nagging
fact remained: against humans these programs did not offer much
competition.These events led to much thought. What was going on here? Theanswer seemed to be in the nature of the games of checkers and chess.
Researchers realized that the game trees were growing in size at an expo-
nential rate as one looks further ahead in the sequences of possible moves.
Computer programs were wasting their time doing a uniform search of
every possible move sequence while humans searched only selected paths.

Humans had knowledge of which paths were likely to yield interestingComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE123results, and they could look much deeper than machines. That is howhumans could win.It seemed obvious that the way to get machines to defeat humans wasto design the programs to play more like people: rather than using a lot of
computer cycles to explore all these irrelevant paths, the computer should
spend more time thinking about which paths to explore. Like people,
machines should invest their resources only in selected paths and they
should look very far down them. During the 1970s, the annual chess
tournament featured many programs that followed this theory: build in a
mechanism that simulates a humanÕs ability to search the interestingpaths, and create an ability in the machine to see very far into the future
moves of the game. It was quite common for program designers to analyze
a clever move by their program and brag about the long search that was
used to find it. Only a fool who did not understand the modern lessons of
game playing would try a uniform search algorithm.But the next surprise came from a chess program developed at North-western University by David Slate, Larry Atkin, and others. They created
a uniform search algorithm despite the common wisdom and won the
annual tournament. At first, people felt it was just luck, but when the
result was repeated a few times, they had to take notice. Why did the
uniform search program defy all reason and defeat selected path pro-
grams that look much deeper? The answer came from a new rationaliza-
tion: a program doing uniform search to a fixed depth plays perfectly to
that depth. It never makes a mistake. Yet a selective search program does
make an occasional mistake within that depth, and when it does the
uniform search program grabs the advantage. Usually the advantage is
enough to win the game. So uniform search programs dominated the
field, and variations on them still are being used.But the question remained: when would these programs finallybecome good enough to defeat humans? Although the Simon-Newell pre-
diction asserted 10 years from 1957, the reality was that it took 40 years. A
computer first became world champion in 1997, when IBMÕs Deep Bluedefeated Garry Kasparov. In a match that involved six games, Deep Blue
won two games, lost one, and tied three. The ultimate goal of a 40-year
quest had been achieved. But examine for a moment the computational
resources that were brought against the human player. Deep Blue ran on
the powerful RS/6000 machine running 32 processors in parallel and also
had special-purpose circuitry to generate chess moves. Deep Blue ben-
efited greatly from harnessing MooreÕs law (see Hill in Chapter 2). Thisgiant machine examined 200 million chess moves per second! But a lot of
computer cycles were not the only factor in Deep BlueÕs victory. The DeepBlue team had spent years building special chess knowledge into the
software and hardware of the system, and the systemÕs play had beenComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.124COMPUTER SCIENCE: REFLECTIONScriticized regularly by chess masters during its development and improvedthrough many redesigns and modifications. Only through this coordi-
nated and long-term effort was the win possible.The years also proved the importance of the learning techniquesdeveloped by Samuel in his checkers program. For example, the worldÕsbest backgammon program, one which plays at world-champion level, is
a program developed by Gerry Tesauro (also at IBM). The main idea in
this program is not search: search does not work well in backgammon,
where even a single play of the game involves thousands of different
possible successor states. The main idea in this program is a learning
algorithm that learns to evaluate the quality of different positions. This
programÕs evaluation was so good that it changed the evaluation of certainpositions, and therefore changed the way in which experts play the game!This story teaches us very much about game playing. But it alsoteaches us about the nature of computation and the nature of human
problem solving. Here are some of the major lessons:¥Our intuitions and thoughtful insights into a process as complicated asplaying one of these board games are very unreliable. We learn things in infor-mation science by writing a program and observing its behavior. We may
theorize or estimate or consult our experts at length on some problems,
but often we cannot find the answer without doing the experiment. On
numerous occasions, we found the experts were wrong and the world of
experiment held an amazing lesson for us.¥The process of decision making in games is vastly more complex than weimagined. It was a combination of increased computer speed combined
with decades of research on search and evaluation methods that eventu-
ally made it possible to defeat a great chess champion. It was not clear in
the early days how much of either of theseÑmachine speed or quality ofsearchÑwould be needed, and it is a profound lesson to observe howmuch of each was required. This provides us with plenty of warning that
when we examine other decision processes such as in economic, political,
or medical diagnosis situations, we may find similar difficulties.¥It is not always the case that to achieve human-level performance, a com-puter should use the same techniques that a human does. The way a computer
does computation is inherently different from the way the brain works,
and different approaches might be suitable for these two Òcomputingarchitectures.Ó However, the performance of Deep Blue also shows that
quantity (a large amount of computer cycles) might occasionally lead to
qualityÑa performance that might be at the level of a human, or indeedindistinguishable from that of a human. (In the match between Deep Blue
and Kasparov, several of KasparovÕs advisors accused IBM of cheating byhaving human players feeding moves to Deep Blue.) But is this muchComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.ACHIEVING INTELLIGENCE125brute-force computation really necessary in order to play high-qualitychess? We have the feeling that there must be a more efficient use of
machines that will do the same job. But we have no idea what it is.
Perhaps, in order to solve that problem, we need to really understand
how intelligence works and how to implement it within a computer.¥Rather than designing a program in its entirety, it may be better to let thecomputer learn for itself. There is a lot of knowledge that people might have
based on their experience but do not know how to make explicit. Some-
times there is simply no substitute for hands-on experience, even for a
computer.¥The research in game playing over the years has had ramifications formany other areas of computing. For example, computer chess research at
IBM demonstrated computing technology that has also been used to attack
problems related to computations on environmental issues, modeling
financial data, the design of automobiles, and the development of innova-
tive drug therapies. SamuelÕs ideas on how to get programs to improvetheir performance by learning have provided a basis for tackling applica-
tions as diverse as learning to fly a helicopter, learning to search the Web,
or learning to plan operations in a large factory.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.1277Building Computing Systems ofPractical ScaleComputer science values not only fundamental knowledge but alsoworking systems that are widely useful. We deliver the benefits of
computer science research through these large-scale, complexcomputing systems, and their design, development, and deployment con-
stitute a fruitful area of research in itself. In doing so, we often raise new
questions about fundamental issues.Started as an attempt to share scarce computing resources, the Internethas become a ubiquitous global utility service, powering personal and
commercial transactions and creating domestic and international policy
challenges. Along the way it has provided a testbed for research that
ranges from high-speed communication to social interactions to new busi-
ness models. The remarkable success of the Internet, including its

scalability and heterogeneity, results from inspired use of engineering-
design principles. Peterson and Clark show how some basic principles of
generality, layers of abstraction, codified interfaces, and virtual resources
led to a system architecture that has survived many orders of magnitude
of growth.The creators of the Internet did not anticipatecouldnÕt have antici-
patedall of its consequences, including the emergence of the WorldWide Web as the principal public-access mechanism for the Internet. The
World Wide Web emerged through the synergy of universal naming,
browsers, widespread convenient Internet access, the Hyper Text Trans-
fer Protocol, a series of markup languages, and the (relative) platform
independence of these mechanisms. The Web has presented new oppor-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.128COMPUTER SCIENCE: REFLECTIONStunitiesincluding support for communication within distributed com-munitiesand it has also led to a number of new problems, not the leastof which are security and privacy. Bruckman assesses the emerging use of
the Internet as a communication medium that links widely dispersed
communities, and she analyzes the factors behind the development of
these communities.Sudan reviews the history of the cryptography and security mechanismsthat underlie secure Web protocols and other forms of secure computer
communication. Also evident is another example of how new opportuni-
ties arise when we find a way to eliminate a significant premise of a
technologyin this case, the advance exchange of decryption informa-tion, or the codebook. Sudan also shows how the computational para-
digm has changed even the basic notion of what constitutes proof in an
authentication system.Software engineering research is concerned with better ways todesign, analyze, develop, evaluate, maintain, and evolve the complex
systems that deliver the computing services described in Peterson and
Clark, Bruckman, and Sudan. Shaw describes how software engineering
researchers formulate and evaluate research of this kind and employ a
variety of approaches to address the subdisciplines different types ofproblems.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE129THE INTERNET: AN EXPERIMENT THAT ESCAPEDFROM THE LABLarry Peterson, Princeton University, andDavid Clark, Massachusetts Institute of TechnologyThe recent explosion of the Internet onto the worlds consciousness isone of the most visible successes of the computer science research com-
munity. The impact of the Internet in enabling commerce, allowing people
to communicate with each other, and connecting us to vast stores of
information and entertainment is undeniable. What is surprising to most
people who now take the Internet for granted is that the underlying archi-
tecture that has allowed the Internet to grow to its current scale was
defined over 25 years ago.This remarkable story began in the late 1970s when a collection ofcomputer science researchers, then numbering less than a hundred, first
deployed an experimental packet-switch network on tens of computers
connected by 56-kbps links. They built the network with the modest goal
of being able to remotely enter jobs on each others computers, but more
importantly, as an experiment to help them better understand the prin-
ciples of network communication and fault-tolerant communication. Only
in their wildest dreams did they imagine that their experiment would
enter the mainstream of society, or that over the next 25 years both the
bandwidth of its underlying links and the number of users it connects
would each grow by six orders of magnitude (to 10-Gbps links and 100
million users, respectively). That a single architecture not only survived
this growth, but also in fact enabled it, is a testament to the soundness of
its design.Layering and AbstractionSeveral design principles, many of them sharpened by years of experi-ence building early operating systems like Multics, helped shape the
Internet architecture.The most important of these was to employ multiple layers of abstrac-tion (see earlier essays) to manage the complexity of the system. Net-
works cannot claim to have invented hierarchical abstraction, but they
have become the most visible application of layering. At the lowest level,
electrical-magnetic signals propagate over some medium, such as a copper
wire or an optical fiber. At the next level, bits are encoded onto these
signals. Groups of bits are then collected together, so abstractly we can
think of machines sending self-contained messages to each other. At theComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.130COMPUTER SCIENCE: REFLECTIONSnext layer, a sequence of machines forwards these messages along a routefrom the original source to the ultimate destination. At a still higher layer,
the source and destination machines accept and deliver these messages
on behalf of application processes that they host. We can think of this
layer as providing an abstract channel over which two (or more) pro-
cesses communicate. Finally, at the highest level, application programs
extract meaning from the messages they receive from their peers.Recognizing that layering is a helpful tool is one thing. Understand-ing the right layers to define is quite another. Here, the architects of the
Internet were guided by another design principle, generalization. Onedimension of generalization is to support as many applications as possible,
including applications that have not yet been imagined. In terms recog-
nized by all computer scientists, the goal was to build a network that
could be programmed for many different purposes. It was not designed
to just carry human voice or TV signals, as were other contemporary
networks. Instead, one of the main characteristics of the Internet is that
through a simple matter of programming, it can support virtually any
type of communication service. The other dimension of generality is to
accommodate as many underlying communication technologies as pos-
sible. This is akin to implementing a universal machine on any number of
different computational elements. Looked at another way, the Internet is
a purely logical network, implemented primarily in software, and running
on top of a wide assortment of physical networks.Next you need to codify the interfaces to the various layers. Here,early Internet researchers recognized the need to keep the common inter-
faces minimal, thereby placing the fewest constraints on the future users
of the Internet, including both the designers of the underlying technolo-
gies upon which it would be built and the programmers that would write
the next generation of applications. This allows for autonomy among the
entities that connect to the Internet: they can run whatever operating
system they want, on whatever hardware they want, as long as they
support the agreed upon interface. In this case, the key interface is between
code modules running on different machines rather than modules running
on the same machine. Such interfaces are commonly called protocols: the
set of rules that define what messages can be sent between a pair of
machines, and under what circumstances.In the early days of network design, it was not clear that we couldactually write protocol specifications with sufficient clarity and precision
that successful communication was practical. In the 1970s it was pre-
dicted that the only way to get different computers to communicate with
each other was to have a single group of people build the code for all the
machines, so that they could take into account all the details that would
never be specified properly in practice. Today, the idea that protocols canComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE131be well specified is accepted, but a great deal of work went into learninghow to do this, including both practical experiments and theoretical work
on automatic checking of specifications.The general idea of abstraction takes many forms in the Internet. Inaddition to using layering as a technique for managing complexity, a
form of abstraction known as hierarchical aggregation is used to manage
the Internets scale. Today, the Internet consists of tens of millions ofmachines, but these machines cannot possibly all know about each other.
How then, can a message be correctly delivered from one machine to
another? The answer is that collections of machines are first aggregated
according to the physical network segment they are attached to, and then
a second time according to the logical segment (autonomous domain) to
which they belong. This means that machines are assigned hierarchical
addresses, such that finding a path from a source machine to a destination
machine reduces to the problem of finding a path to the destination

domain, which is then responsible for delivering the data to the right
physical segment, and finally to the destination machine. Thus, just as
layering involves a high-level protocol hiding the uninteresting details
about a low-level protocol, aggregation involves high levels of the
addressing and routing hierarchy masking the uninteresting details about
lower levels in the hierarchy.Resource SharingNetworks are shared systems. Many users send traffic from manyapplications across the same communication links at the same time. The
goal is the efficient exploitation of expensive resources. Long-distance
communication links are expensive, and if many people can share them,
the cost per user to communicate is greatly reduced.The telephone system is a shared system, but the sharing occurs at thegranularity of a call. When a user attempts to make a call, the network
determines if there is capacity available. If so, that capacity is allocated to
the caller for as long as the call lasts, which might be minutes or hours. If
there is no capacity, the caller is signaled with a busy tone.Allocating communications capacity for a period of minutes or hourswas found to be very inefficient when computer applications communi-
cated. Traffic among computers seems to be very bursty, with short trans-
missions separated by periods of silence. To carry this traffic efficiently, a
much more fine-grained sharing was proposed. The traffic to be sent is
broken into small chunks called packets, which contain both data to be
sent and delivery information. Packets from many users come together
and are transmitted, in turn, across the links in the network from source
toward destination.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.132COMPUTER SCIENCE: REFLECTIONSWhen the concept of packet was first proposed, there was consider-able uncertainty as to whether this degree of multiplexing would work. If
traffic from multiple users arrives to be sent at the same instant, a queue
of packets must form until all can finally be sent. But if the arrival pattern
of packets is unpredictable, is it possible that long, persistent queues will
form? Will the resulting system actually be usable? The mathematics of
queuing theory were developed to try to understand how such systems
might work. Queuing theory, of course, is not restricted to network design.
It applies to checkout lines in stores, hospital emergency rooms, and any
other situation where arrival patterns and service times are predictable
only in a statistical sense. But network design has motivated a great deal
of research that has taught us much about statistical properties of shared
systems. We now know the conditions to build systems like this with
predictable stability, reasonable traffic loads, and support for a wide range
of applications. The concept of the packet has turned out to be a very
robust one that has passed the test of time.More recently, as the Internet has grown larger, and the number ofinteracting traffic flows has grown, a new set of observations have emerged.
The Internet seems to display traffic patterns that are self-similar, which
means that the patterns of bursts that we see in the aggregated traffic have
the same appearance when viewed at different time scales. This hints that
the mathematics of chaos theory may be the tool of choice to increase our
understanding of how these large, shared systems work.Devising techniques to share resources is a recurring problem in com-puter science. In the era of expensive processors, time-sharing systems
were developed to share them. Cheaper processors brought the personal
computer, which attempts to side-step some of the harder sharing prob-
lems by giving each user his own machine. But sharing is a fundamental
aspect of networking, because sharing and communication among people
and the computers that serve them is a fundamental objective. So mastery
of the models, tools, and methods to think about sharing is a fundamental
objective of computer science.Concluding RemarksThe Internet is arguably the largest man-made information systemever deployed, as measured by the number of users and the amount of
data sent over it, as well as in terms of the heterogeneity it accommodates,
the number of state transitions that are possible, and the number of
autonomous domains it permits. Whats more, it is only going to grow insize and coverage as sensors, embedded devices, and consumer electronic
equipment become connected. Although there have certainly been stresses
on the architecture, in every case so far the keepers of the Internet haveComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE133been able to change the implementation while leaving the architectureand interfaces virtually unchanged. This is a testament to the soundness
of the architecture, which at its core defines a universal networkmachine.By locking down the right interfaces, but leaving the rest of therequirements underspecified, the Internet has evolved in ways never
imagined. Certainly this is reflected in the set of applications that run on
the Internet, ranging from video conferencing to e-commerce, but it is
also now the case that the Internet has grown to be so complicated that the
computer scientists that created it can no longer fully explain or predict
its behavior. In effect, the Internet has become like a natural organism that
can only be understood through experimentation, and even though it is a
deterministic system, researchers are forced to create models of its behav-
ior, just as scientists model the physical world. In the end, the Internet
must be viewed as an information phenomenon: one that is capable of
supporting an ever-changing set of applications, and whose behavior can
be understood only through the use of increasingly sophisticated mea-
surement tools and predictive models.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.134COMPUTER SCIENCE: REFLECTIONSMANY-TO-MANY COMMUNICATION: A NEW MEDIUMAmy Bruckman, Georgia Institute of TechnologyIn the early 1990s, computer-mediated communication (CMC) explodedin popularity, moving from a tool used by small groups of engineers and
scientists to a mass phenomenon affecting nearly every aspect of life in
industrialized nations. Even in the developing world, CMC has begun to
play a significant role. Yet we are just at the beginning, not the end, of the
transformations catalyzed by this technology. We can draw an analogy to
an earlier era of intense social change launched by new technology: the
introduction of the car. In the early days of the internal combustion engine,
cars were called horseless carriages: we understood the new technol-ogy in terms of an old, familiar one. At that stage, we could not begin to
imagine the ways that cars would transform the United States and the
world, both for good and for ill. The Internet is in its horseless carriagestage. At this pivotal moment, we have a unique opportunity to shape the
technologys evolution, and the inevitable changes to society that willaccompany it.The key feature of this technology is its support for many-to-manycommunications. This paper will analyze the significance of many-to-
many communications in key relevant application areas.With many-to-many communications, individuals are becomingcreators of content, not merely recipients. For example, we are no longer
restricted to reading journalistic interpretations of current events, but can
now also share our own views with friends and family. Opportunities for
discourse on issues of import are at the foundation of a democratic society.
We are experiencing a renaissance in public debate of serious matters by
citizens.Many-to-many communications are changing the nature of medicine.The new medical consumer arrives at the doctors office better informed.The Pew Center for Internet Life reports that fifty-two million Americanadults, or 55% of those with Internet access, have used the Web to get
health or medical information, and of those, 
70% said the Web informa-tion influenced their decision about how to treat an illness or condition(Fox and Rainie, 2000). Patients can talk online with others with similar
ailments, exchanging not just useful medical information but also emo-
tional support. This emotional support is particularly valuable to care-
givers of patients with serious illnesses, a group whose needs are often
neglected.Many-to-many communications are having a growing impact on busi-ness practices. In the field of retailing, consumers can now easily shareComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE135product recommendations, giving developers of quality products acompetitive advantage. Competitive price information is available with
unprecedented ease of access. The free many-to-many flow of informa-
tion moves us closer to the ideal of an efficient market.New kinds of commerce are emerging. We are no longer bound tohave all purchases of second-hand goods go through middlemen like
consignment shops, but can sell items directly to others. For example, in
areas like antiques, collectibles, and used consumer electronics, for the
first time in history a fair and efficient market has emerged. Items that
would otherwise have been discarded can now find their way to just the
person who needs them, leading to a less wasteful society.The remainder of this paper discusses three application areas wherethe impact of Internet technology merits special attention: the expansion
of scientific knowledge, entertainment, and education.Accelerating the Expansion of KnowledgeThe Internets most obvious capability is to distribute information.The World Wide Web was invented by Tim Berners-Lee and colleagues at
CERN in order to accelerate scientific progress: researchers can exchange
ideas must faster than was formerly possible. This has had particular
impact in the developing world. Researchers in developing nations who
could never afford subscriptions to research journals now have growing
access to current scientific information and indirect participation in the
international community of scientists.Sociologists of science like Bruno Latour teach us that truth is sociallyconstructed. This is true of the most basic hard scientific facts. A new
idea begins attributed to a specific person: Einstein says that E = MC2.As it becomes more accepted, the attribution is dropped to a footnote:
E=MC
2 (Einstein 1905).
 Finally, the attribution is deemed entirely
unnecessary, and one can simply say E = MC2it has become anaccepted scientific fact (Latour et al., 1986). The process of one researchersclaim rising to the level of fact is fundamentally social. Initially, people
are unsurewas the scientists work sound? Do others support this find-ing? As such questions are asked and answered, some claims are rejected
and others become widely accepted. Truth emerges not from the work of
one scientist, but from the community. It is not instantly revealed, but
begins as tentative and solidifies over time. The Internet gets the most
attention for its ability to support the exchange of factual information in
the simple sense, as if it is merely a giant database that is unusually up to
date. However, it is important to understand Latours subtler vision ofhow new knowledge is constructed, and the way that the Internet is

uniquely well suited to accelerating that social process.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.136COMPUTER SCIENCE: REFLECTIONSAs we move forward, we need to find ways to enhance the ability ofnetwork technology to facilitate the free exchange of scientific ideas. Aca-
demic researchers in most fields are still rewarded for presenting ideas in
peer-reviewed journal articles that may take years to appear in print.
They are often reluctant to share ideas before they appear in officially
credited form. Corporate researchers may be reluctant to share findings at
all. Yet the entire endeavor of research can be enhanced through more
immediate sharing of ideas via the Internet. The challenge, then, is to find
ways to give individuals credit for ideas shared rapidly online, while at
the same time maintaining the quality control of peer review. The field of
online community research focuses on these issues, especially, what moti-
vates individuals to contribute and how quality of discourse can be main-
tained (Preece, 2000). The design of our next-generation communication
systems will help to accelerate the pace of discovery in all fields.Online EntertainmentAs we have seen, we can view the Internet as facilitating the exchangeof scientific information; however, it is more far-reaching to see it as sup-
porting the growth of a community of scientists (and information as a key
product of that community). This fundamental insight applies not just to
science, but to most domains. For example, the entertainment industry is
no longer simply delivering content, but is using computer networks to
bring groups of individuals together. New Internet-based forms of enter-
tainment fall into a variety of genres, including bulletin-board systems
(BBSs), chat, and games.Internet-based communication provides opportunities for new kindsof socializing. In chat rooms and on BBSs, people gather together to
discuss hobbies and to meet others. People with an unusual hobby find
they are no longer alone but can meet like-minded others from around the
world. Some of this social activity bridges into face-to-face activity. Hobby-
ists 
from geographically diverse areas may meet face to face at annualconventions and then maintain those ties online. In other cases, the social
activity is local in nature. Computer-mediated communication is used to
schedule face-to-face meetings and to continue discussion between such
meetings. Sociologist Robert Putnam has documented a decrease in
Americans participation in civic groups over the last half-century
(Putnam, 1995). The ease of coordinating social and civic groups with the
aid of new communications technologies has the potential to help begin
to reverse this trend.Popular types of Internet-based games include traditional games (likebridge and chess), fantasy sports, action games, and massively multi-
player games (MMPs). The most important characteristic these gamesComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE137share is that they are social: people play with relatives, old friends, andnew friends met online. For example, the author plays bridge online with
her mother (who lives hundreds of miles away) and action games with
friends from high school and graduate school living all around the country.
Getting together to play online gives us occasions to keep in touch. This
new entertainment form can help to maintain what sociologists call
strong ties over distance and also create new 
weak ties (Wellman and
Gulia, 1999). While one might be inclined to dismiss friendships made
online as trivial, they are often quite meaningful to participants and some-
times have practical value as well. Howard Rheingold recounts how
people who know one another from a California BBS called The WELL
sent hundreds of books to a book-loving group member who lost all his
possessions in a fire. WELL members also collaborated to arrange for the
medical evacuation of a group member who became ill while in the
Himalayas (Rheingold, 1993). These kinds of stories are not unusual.
Every year, students in the Design of Online Communities graduate
class at Georgia Tech are asked to write a short essay on their best and
worst experiences involving Internet-based communications, and similar
stories emerge each time.Its important to note that a number of aspects of online entertainmentare discouraging. In particular, some online games are so compelling for
many players that they may devote extremely large amounts of time to
playing them. For example, as of fall 2001, the most popular MMPEverquest, by Verant Interactivehad 400,000 registered members(Verant, 2001) who spent on average 22.5 hours per week playing (Yee,
2001). That mean figure includes a significant number who hardly partici-
pate at all, so the median is likely substantially higher. In other words,
there are tens and possibly hundreds of thousands of people who devote
all their non-work time to participation in the game. While we must be
careful about passing judgement on how others spend their free time, the
players themselves often find this problematicso much so that the gameis often referred to by the nickname EverCrack. Other games in this
new genre have similar holding power.MMPs are fun for players and profitable for game companies. In addi-tion to charging people to buy the game initially, companies also charge a
monthly fee. This lets companies make more money from a single devel-
opment effort and gives them a more even revenue stream, making them
less dependent on unpredictable seasonal sales and new releases. As a
result, many companies are developing new MMP titles. While tradi-
tional multiplayer games allow a handful of people to interact in the same
game space, MMPs support thousands. Its likely we are just at the begin-ning of their growth in popularity. While they provide an entertainment
offering that is both social and active, they also tend to lead to over-Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.138COMPUTER SCIENCE: REFLECTIONSFIGURE 7.1 
AquaMOOSE 3D: An Internet-based math-learning environment.involvement by some players. This is a key moment to ask: How can weshape this trend? How should we?One constructive course of action is to create game-like environmentsthat have educational content. For example, AquaMOOSE 3D is a three-
dimensional virtual world designed to help high-school students learn
mathematics (Edwards et al., 2001). See Figure 7.1. You are a fish, and you
specify your motion in the graphical world mathematically. For example,
swim in a sine in x and a cosine in 
y, and you move in a spiral and leavea spiral trail behind you. You can also create sets of rings in the water and
challenge others to guess the equation that goes through them. Students
create these mathematical puzzles to challenge their friends. AquaMOOSE
looks much like the purely entertainment environments many students
find so compelling, but time spent there is educationally valuable. We
need to develop more such environments to encourage students to choose
to spend their free time wisely.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE139The Learning Potential of Internet TechnologyEducation is a key area where many-to-many communications havebegun to have a strong positive impact. Many educational applications of
Internet technology focus on information: in distance education informa-
tion is delivered to the student. In online research projects, information is
retrieved. In more innovative work, information is gathered by students
and shared. While information-oriented applications of Internet tech-
nology are useful, the more exciting potential of this new learning medium
is not about information but about community and collaboration. Online,
groups of learners can motivate and support one anothers learningexperiences.Learning from PeersLearning is fundamentally a social process, and the Internet has aunique potential to facilitate new kinds of learning relationships. For

example, in the One Sky, Many Voices project by Nancy Songer at the
University of Michigan (http://www.onesky.umich.edu/), kids can learn
about atmospheric phenomena from scientists working in the field
(Songer, 1996). More importantly, the students also learn from one
another: kids in Montana studying hurricanes can talk online with Florida

students in the midst of one. Learning from peers can be a compelling
experience and is a scalable educational solution. If enough educational
programs try to leverage the skills of adult experts, experts will ultimately
spend all their time in public service. While the supply of experts is
limited, the supply of peers is not.Peers can be a powerful resource for childrens learning, if activitiesare structured to promote productive interactions. MOOSE Crossing is a
text-based virtual world (or MUD) in which kids 8 to 13 years old learncreative writing and object-oriented programming from one another
(http://www.cc.gatech.edu/elc/moose-crossing/). See Figure 7.2. The

specially designed programming language (MOOSE) and environment
(MacMOOSE and WinMOOSE) make it easy for young kids to learn to
program. Members dont just experience the virtual worldthey con-struct it collaboratively. For example, Carrot1 (girl, age 9) created a swim-
ming pool complex. Using lists stored on properties of the pool object, she
keeps track of who is in the pool, sauna, or Jacuzzi, and who has changed
into a bathing suit. You obviously cant jump into the pool if you
re1All real names and online pseudonyms of participants have been changed to protecttheir confidentiality.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.140COMPUTER SCIENCE: REFLECTIONSFIGURE 7.2A text-based virtual world where kids practice creative writing and
learn object-oriented programming.already in the water . . . you need to get out first! This gives Carrotopportunities for comic writing as well as programming. The text-based
nature of the environment is not a technical limitation, but rather a delib-
erate design choice: it gives kids a context for using language playfully
and imaginatively. Carrot enjoys inviting other kids over to the pool.
They in turn learn about programming and writing using her work as a
model (Bruckman, 1998, 2000).The online community provides a ready source of peer support forlearning. Kids learn from one another, and from one anothers projects.That support is not just technical, but also emotional. In answering a
question, one child may tell another, I got confused by that too at first.The online community provides a ready source of role models. If, for
example, girls are inclined to worry that programming might not be a
cool thing for a girl to do, they are surrounded by girls and women
engaging in this activity successfully and enjoying it. Finally, the online
community provides an appreciative audience for completed work. Kids
get excited about being creative in order to share their work with their
peers.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE141Elders as MentorsSocial support for learning online can come not just from peers, teachers,and experts, but also from ordinary members of the general population,
who form a vast potential resource for our childrens education. Retiredpeople in particular have a great deal they can teach kids and free time to
contribute, but they need an easy and well-structured way to do so. In the
Palaver Tree Online project (http://www.cc.gatech.edu/elc/palaver/,
the dissertation research of Georgia Tech PhD student Jason Ellis), middle-
school students learn about history from elders who lived through it.
Teachers begin with literature that is part of their normal curriculum.
Kids brainstorm historical questions based on what theyve learned, inter-view elder mentors about their personal experiences with that time, and
then write research reports about what theyve learned. See Figures 7.3and 7.4. In our studies to date, kids learning about World War II inter-
viewed veterans, and kids learning about the civil rights years interviewed
older African Americans. History learned from real people becomes more
meaningful and relevant (Ellis and Bruckman, 2001).FIGURE 7.3Eighth-grade students interviewing an elder mentor about her expe-
riences growing up during the civil rights years. (All names have been changed.)Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.142COMPUTER SCIENCE: REFLECTIONSFIGURE 7.4The project students created based on their interview.
Of course it would be better for kids to meet with elders face to face,but in practice this rarely if ever happens. In interviews with teachers
who have tried such projects, we found that the logistics are too difficult
to arrange for all involved. Elder volunteers, when asked if they will drive
to an unfamiliar place and commit to multiple visits, often hesitate. How-
ever, when asked, Would you be willing to log on for half an hour a dayfor a few weeks?, they are enthusiastic. The Palaver Tree Online commu-
nity makes this not only possible but also relatively easy for the elders,
students, and teachers. Teachers are already overwhelmed with work,
and any successful school-based learning technology needs to make their
lives easier, not harder.New Social and Technical PossibilitiesCulture and technology co-evolve. The challenge as we move forwardis to develop a vision of what is possibleto understand the more andless desirable outcomes, and try to steer in the right direction. Hardware
and software infrastructure developed over the last 40 years are just nowComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE143becoming widely available and are finding a wide variety of new applica-tions. The wide availability of Internet access has made many-to-many
communications possible, and this capability has a profound impact on
how we conduct business, manage our health, share knowledge, entertain
ourselves and one another, and learn.ReferencesBruckman, A., 1998, Community Support for Constructionist Learning, Computer Sup-ported Cooperative Work 7:47-86.
Bruckman, A., 2000, Situated Support for Learning: Storms Weekend with Rachael,Journal of the Learning Sciences 9(3):329-372.
Edwards, E., J. Elliott, and A. Bruckman, 2001, AquaMOOSE 3D: Math Learning in a 3DMulti-user Virtual World, paper presented at the CHI 2001 Conference on Human
Factors in Computing Systems, Seattle, Wash.Ellis, J., and A.Bruckman, 2001, Palaver Tree Online: Supporting Social Roles in a Commu-nity of Oral History, paper presented at the CHI 2001 Conference on Human Factors
in Computing Systems, Seattle, Wash.Fox, S., and L. Rainie, 2000, The Online Health Care Revolution: How the Web Helps AmericansTake Better Care of Themselves, Pew Internet and American Life Project, Washington,
D.C.Latour, B., S. Woolgar, and J. Salk, 1986, Laboratory Life, Princeton University Press,Princeton, N.J.Preece, J., 2000, Online Communities: Designing Usability, Supporting Sociability, John Wiley &Sons, New York.Putnam, R., 1995, Bowling Alone: Americas Declining Social Capital, Journal of Democracy6(1).Rheingold, H., 1993, The Virtual Community: Homesteading on the Electronic Frontier, Addison-Wesley, Reading, Mass.Songer, N., 1996, Exploring Learning Opportunities in Coordinated Network-EnhancedClassrooms: A Case of Kids as Global Scientists, The Journal of the Learning Sciences5(4):297-327.Verant, 2001, Sony Online Entertainment to Introduce New EverQuest Servers in Euro-pean Markets: Verant Interactive.Wellman, B., and M. Gulia, 1999, Virtual Communities Are Communities: Net SurfersDont Ride Alone, in M.A. Smith and P. Kollock (eds.), 
Communities in Cyberspace,Routledge, New York.Yee, N., 2001, The Norrathian Scrolls: A Study of Everquest (2.5), available at http://
www.nickyee.com/eqt/report.html.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.144COMPUTER SCIENCE: REFLECTIONSCRYPTOGRAPHYMadhu Sudan, Massachusetts Institute of TechnologyConsider the following prototypical scenario in the Internet era: Alicewishes to access her bank account with the Bank of Billionaires (Bob)
through the Internet. She wishes to transmit to Bob her account number
and password and yet does not want her Internet service provider to
know her account number and password. The potential for commerce
over the Internet relies critically on the ability to implement this simple
scenario. Yet when one gets down to formalizing the goals of this scenario
mathematically, one realizes this goal is almost impossible. After all the
Internet service provider has access to every bit of information that enters
or leaves Alices computer, and Bob has only a subset! Fortunately, thereis a tiny crack in any such proof of impossibility (read ComputationalFoundations of Cryptography below for details)
a crack visible onlywhen inspected with a computational lensand from this crack emergescryptography, the science of encrypting and decrypting messages.Cryptography has been practiced for centuries now. Its need becomesevident in any situation involving long-distance communication where
secrecy and (mis)trust are governing factors. Yet, till the advent of the
20th century much of cryptography has been misunderstood and prac-
ticed as black magic rather than as a science. The advent of computers,
and the development of the computational perspective, has changed all
this. Today, one can deal with the subject with all the rigor and precision
associated with all other mathematical subjects. Achieving this progress
has required the formalization of some notionssuch as randomness,knowledge, and proofthat we rely on commonly in our lives but whosemathematical formalization seems very elusive. It turns out that all these
notions are essentially computational, as is cryptography. Furthermore
cryptography is feasible only if some very fundamental computational
hypotheses (such as NP  P; see Kleinberg and Papadimitriou in Chap-
ter2) hold out. This essay describes some of the salient events in the

history of cryptography.Cryptography in the Medieval EraTraditionally, messages were encrypted with codebooks. Roughly, inthis setup Alice and Bob initially share some secret information, called the
codebook. This codebook might be something as simple as a letter-to-letter
substitution rule, or something more complexsuch as a word-to-wordsubstitution rule, and so on. When Alice obtains some new information toComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE145be transmitted secretly to Bob, she uses the codebook to translate themessage and send it (through untrusted couriers) to the receiver. Now,
assuming that the courier does deliver the encrypted message, the receiver
uses his copy of the codebook to translate the messages back. The courier
or any other eavesdropper, however, cannot in theory decipher the message,
since he does not possess the codebook.To compare the above system with some of the more recent themes incryptography, let us compare some of the basic elements of the model and
the associated assumptions. One of the primary features of the model
above is the role of the codebook. It is what distinguishes the receiver
from the eavesdropper (based on information the receiver possesses), and
the initial cryptography protocols assumed (mistakenly, as it turned out)
that the codebook was a necessary component for secret communication.
Over time, the belief took on quantitative dimensionsthe larger the sizeof the codebook, the more secure the encryption. For example, a letter-to-
letter substitution rule applied to the English alphabet requires the testing
of 26! possibilities. But most can be ruled out easily based on frequency
analysis of English text. So letter-to-letter substitution rules, involving
small codebooks, can be broken easily. Word-to-word substitution rules
are harder to break, but it is still feasible to do so with decent computers.The last of these observations, that better computers might lead toloss of secrecy, was worrisome. Maybe the advent of computers would
lead to the ultimate demise of cryptography! In the face of such popular
beliefs, it came as a startling surprise that cryptography could potentially
thrive with advances in computing.Computational Foundations of CryptographyThe foundations of cryptography were laid gradually. First cameinformation-theoretic foundations, starting with Shannon in the 1950s,
and a little later, in the 1970s, came the computational notions of Merkle
(1978), Diffie and Hellman (1976), and Rivest, Shamir, and Adleman (1978).Shannons theory (Shannon, 1949) formally asserted that secret com-munication is possible whenever the communicating parties, Alice and
Bob, share some secret information. Furthermore, this secret information
had to have some randomness associated with it, in order to prove the
security of the transmission. Quantifying this notion (how random is the
shared secret?) led to a quantification of how much information could be
exchanged secretly. In particular, if Alice and Bob got together and picked
a k-bit random string as the secret to share (where every bit is chosenuniformly and independent of other bits), then Alice could encrypt any
k-bit message and send the encrypted message to Bob in the clear, suchthat the eavesdropper could get no information about the message whileComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.146COMPUTER SCIENCE: REFLECTIONSBob, with knowledge of the shared secret, could decrypt the messagefrom the encrypted form. (For example, if the shared secret s is inter-
preted as a k-bit integer and the message m to be exchanged is also a k-bitinteger, then the encrypted text can simply be e = (
m + s) mod 2k. Bob, onreceiving e, can recover m by computing 
e Ð s 
mod 2k).The importance of this result is not so much in the protocol derived asin the notions defined. How do we determine secrecy? Why is the message

m being kept secret in the above exchange? How do we prove it? The
answers all turn out to be quite simple. Message m is secret because its
encryption (which is a random variable dependent on the secret s) isdistributed statistically identically to the encryption of some other
message m. Thus indistinguishability is the basis for secrecy.What happens when Alice tries to transmit a message of more thank-bits to Bob (while they only share a k-bit secret)? Shannons theoryexplained that in this case the eavesdropper can get some information
about the message m from the transmission (no matter what protocol
Alice and Bob adopt). Shannon realized that this information may not
provide any usable information about the message itself, but he was
unable to exploit this lack of usability any further.
How is it possible that one has information about some string m, butis not able to use it? How does one determine usability so as to have a
meaningful sense of this possibility? It turns out that these questions are
essentially computational, and it took the seminal work of Diffie and
Hellman (1976) to realize the computational underpinnings and to exploit
them.Diffie and Hellman noticed that several forms of computation trans-form meaningful information into incomprehensible forms. (As a side
remark they note that small programs written in a high-level language
immediately reveal their purpose, whereas once they are compiled into a
low-level language it is hard to figure out what the program is doing!)
They pointed out a specific algebraic computation that seems to have this
very useful information-hiding feature. They noticed it is very easy to
compute modular exponentiation. In particular, given an n-bit primenumber p, an integer g between 2 and 
p  1, and exponent 
x between 1 and
p  1, it is possible to compute y = gx (mod p) in approximately n2 steps ofcomputation. Furthermore if g is chosen somewhat carefully, then thismapping from x to gx (mod p) is one to one and thus invertible. However,no computationally efficient procedure was known (then or now) to com-
pute, given g, p, and y, an integer x such that y = gx. This task of invertingmodular exponentiation is referred to as the Discrete Logarithm Problem.Relying in part on the seeming hardness of the Discrete Log Problem,Diffie and Hellman suggested the following possibility for Alice and Bob
to exchange secrets: to exchange an n-bit secret Alice picks a prime p and
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE147an integer g as above and sends g and 
p (in the clear!) to Bob. She then
picks a random integer x1 between 1 and 
p  1, computes 
  
  gx1 mod 
p, andsends this string to Bob. Bob responds by picking another random string
x2 and sending to Alice the string 
    gx2 mod 
p. At this point, Alice and Bobcan both compute     gxx12 mod 
p. (Alice computes this as (  
  gx2)    x1, while Bobcomputes this as (    gx1)    x2).What about the eavesdropper? Surprisingly, though all this conversa-tion was totally in the clear, the eavesdropper seems to have no efficient
way to compute     gxx12. She knows     gx1 and 
    gx2 but these do not suffice to
give an efficient way to compute    gxx12. (In all cases we dont know thatthere is no efficient way to compute one of the unobvious casesit is justthat we dont know of any efficient way to compute them and thus conjec-ture that these computations are hard.) Thus Alice and Bob have man-aged to share a random secret by communication in the clear that Alice
can now use to send the real message m to Bob.
The protocol above provides a simple example of the distinction be-tween information and its usability. Together,     gx1 and 
    gx2 specify 
    gxx12but not in any usable way, it seems. The essence of this distinction is acomputational one. And it leads to a very computational framework forcryptography. The protocol can be used to exchange information secretly,
where secrecy is now determined using a computational notion of indis-
tinguishability, where computational indistinguishability suggests that
no efficient algorithm can distinguish between a transcript of a conversa-
tion that exchanges a secret m and one that exchanges a secret 
m. (Givinga precise formulation is slightly out of scope.)And what does one gain from this computational insight? For the firsttime, we have a protocol for exchanging secrets without any prior sharing
of secret information (under some computational hardness assumptions).Lessons Learned from CryptographyThe seminal work of Diffie and Hellman altered fundamental beliefsabout secrecy. The natural guess is that any information that Bob may
possess unknown to Alice would be useless in preserving the secrecy of a
communication from Alice to Bob. A continuation of this line of reasoning
leads to the belief that Alice cant send secret information to Bob unlessthey shared some secrets initially. Yet the above protocol altered this
belief totally. The intractability of reversing some forms of computations
can lead to secret communication. Such intractability itself relies on some
other fundamental questions about computation (and in particular implies
P  NP). In fact, it was the emerging belief in the conjecture 
P  NP
 that
led Diffie and Hellman to propose the possibility of such public-keyComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.148COMPUTER SCIENCE: REFLECTIONSexchange protocols and posit the possibility of other public-key encryp-tion systems.In the numerous years since, cryptography has led to numerous com-putational realizations of conventional wisdom (and computationalrefutations of mathematical truths!). Numerous notions underlying day-
to-day phenomena, for which formalization had earlier proved elusive,
have now been formalized. Two striking examples of such notions are
those of pseudo-randomness and 
proofs. We discuss these below.
Shannons theory had asserted that sharing a secret random string
was necessary for a message to be secure. The Diffie-Hellman protocol
managed to evade this requirement by showing how Alice and Bob could
create a secret that they shared using public conversations only. This
secret was the string     gxx12. How random is this secret? The answer de-pends on your foundations. Information theory would declare this stringto be totally non-random (or deterministic) given 
  
  gx1 and 
    gx2. Compu-tational theory, however, seems to suggest there is some element of ran-
domness to this string. In particular, the triples (    gx1;     gx2;      gx3) and (    gx1;    gx2;     gxx12) seem to contain the same amount of randomness, to anycomputationally bounded program that examines these triples, whenx1; x2; x3 are chosen at random independent of each other. So the compu-tational theory allows certain (distribution on) strings to look morerandom than they are. Such a phenomenon is referred to as pseudo-
randomness and was first formalized by Blum and Micali (1984). Pseudo-
randomness provides a formal basis for a common (and even widely
exploited) belief that simple computational steps can produce a long

sequence of seemingly uncorrelated or random data. It also provided a
fundamental building block that has since been shown to be the crux ofmuch of cryptography.A second example of a computational phenomenon is the age-oldnotion of a proof. What is a proof? Turn-of-the-20th-century logicians had
grappled with this question successfully and emerged with a clean expla-
nation. A proof is a sequence of simple assertions that concludes with the
theorem by which each assertion can be easily verified. The term easilyhere requires a computational formalism, and in fact, this led to the defi-
nition of a Turing machine in the 1940s (see Kleinberg and Papadimitriou
in Chapter 2). The advent of cryptography leads us back to the notion of a
proof and some seemingly impossible tasks. To see the need for this

notion, let us revisit the scenario introduced in the opening paragraph.
The goal of the scenario can be reinterpreted as follows: Bob knows that
Alice is the (only) person who knows a secret password m. So when someuser comes along claiming to be Alice, Bob asks for her password, in effect
saying Prove you are Alice!
 or equivalently 
Prove you know 
m. In
traditional scenarios Alice would have simply typed out her password mComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE149on her keyboard and sent it over the Internet. This would have corre-sponded to our standard intuition of a proof. Unfortunately this stan-
dard notion is a replayable oneany eavesdropper could listen in to theconversation and then also prove that he/she is Alice (or knows m). Butthe interaction above allows Alice to prove to Bob that she knows m(indeed she essentially sends it to him), without revealing m to the eaves-
dropper. So it seems Alice was able to prove her identity without reveal-
ing so much information that others can later prove they are Alice! How
did we manage this? The most significant step here is that we changed
our notion of a proof. Conventional proofs are passive written texts. The
new notion is an interactive randomized conversation. The new notion,
proposed by Goldwasser, Micali, and Rackoff (1989), retains the power of
conviction that conventional proofs carry, but it allows for a greater level
of secrecy. Proofs can no longer be replayed. As subsequent develop-
ments revealed, these proofs also tend to be much shorter and can be
verified much more efficiently. So once again computational perspectives
significantly altered conventional beliefs.The Future of CryptographyCryptography offers a wonderful example of a phenomenon quitecommonplace in the science of computing. The advent of the computer
raises a new challenge. And the science rises to meet the new challenge by
creating a rich mathematical structure to study, analyze, and solve the
new problems. The solutions achieved (and their deployment in almost
every existing Web browser!) as well as the scientific knowledge gained
(proofs, pseudo-randomness, knowledge) testify to the success ofcryptography so far. Going into the future one expects many further
challenges as the scope of cryptography broadens and our desire to goonline increases. One of the biggest challenges thus far has been in creat-
ing large, possibly distributed, systems that address the security of their
contents. Cryptography may be likened to the task of designing secure
locks and keys. No matter how inventive and successful one is with this
aspect, it does not automatically lead to secure houses. Similarly, building
secure computer systems involves many more challenges in terms of
defining goals, making sure they are feasible, and then attaining them
efficiently. Research in this direction is expected to be highly active.To conclude on a somewhat cautious note: Cryptography, like manyother scientific developments, faces the problem of being a double-edged
sword. Just as it can be used to preserve the privacy of honest individuals,
so can it equally well preserve the privacy of the communications of badguys. Indeed, fear of this phenomenon has led to government oversight
on the use and spread of cryptography and has raised a controversialComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.150COMPUTER SCIENCE: REFLECTIONSquestion: Is the negative impact sufficient to start imposing curbs oncryptographic research? Hopefully, the description above is convincing
with respect to two aspects: cryptographic research is essentially just
discovering a natural, though surprising, computational phenomenon.
Curbing cryptographic research will only create a blind spot in our under-
standing of this remarkable phenomenon. And while the tools that the
research invents end up being powerful with some potential for misuse,
knowing the exact potential and limits of these tools is perhaps the best
way to curb their misuse. Keeping this in mind, one hopes that crypto-
graphic research can continue to thrive in the future uninhibited by exter-
nal pressures.REFERENCESBlum, Manuel, and Silvio Micali, 1984, How to Generate Cryptographically StrongSequences of Pseudorandom Bits, SIAM Journal on Computing 13:850-864.Diffie, Whitfield, and Martin E. Hellman, 1976, New Directions in Cryptography, IEEETransactions on Information Theory 22(6):644-654.
Goldwasser, Shafi, Silvio Micali, and Charles Rackoff, 1989, The Knowledge Complexityof Interactive Proof Systems, SIAM Journal on Computing 18(1):186-208.
Merkle, Ralph, 1978, Secure Communications over Insecure Channels, Communications ofthe ACM (April):294-299.
Rivest, Ronald L., Adi Shamir, and Leonard Adleman, 1978, A Method for ObtainingDigital Signatures and Public-key Cryptosystems, Communications of the ACM21(2):120-126.Shannon, Claude E., 1949, Communication Theory of Secrecy Systems, Bell Systems Tech-nical Journal 28(6):656-715.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE151STRATEGIES FOR SOFTWARE ENGINEERING RESEARCHMary Shaw, Carnegie Mellon UniversitySoftware engineering is the branch of computer science that createspractical, cost-effective solutions to computation and information pro-
cessing problems, preferentially applying scientific knowledge, develop-
ing2 software systems in the service of mankind. Like all engineering,
software engineering entails making decisions under constraints of limited
time, knowledge, and resources. The distinctive character of softwarethe form of the engineered artifact is intangible and discreteraises specialissues of the following kind about its engineering:Software is design-intensive; manufacturing costs are a very smallcomponent of product costs.Software is symbolic, abstract, and more constrained by intellectualcomplexity than by fundamental physical laws.Software engineering is particularly concerned with software thatevolves over a long useful lifetime, that serves critical functions, that is
embedded in complex software-intensive systems, or that is otherwise
used by people whose attention lies appropriately with the application
rather than the software itself. These problems are often incompletely
defined, lack clear criteria for success, and interact with other difficult
problemsthe sorts of problems that Rittel and Webber dubbed wickedproblems.3Software engineering rests on three principal intellectual foundations.The principal foundation is a body of core computer science concepts relat-
ing to data structures, algorithms, programming languages and their
semantics, analysis, computability, computational models, and so on; this
is the core content of the discipline. The second is a body of engineeringknowledge related to architecture, the process of engineering, tradeoffs
and costs, conventionalization and standards, quality and assurance, and
others; this provides the approach to design and problem solving that2DevelopSoftware engineering lacks a verb that covers all the activities associatedwith a software product, from conception through client negotiation, design, implementa-tion, validation, operation, evolution, and other maintenance. Here, develop refers inclu-
sively to all those activities. This is less than wholly satisfactory, but it isnt as bad as listingseveral verbs at every occurrence.3Horst Rittel and Melvin Webber, 1973, Dilemmas in a General Theory of Planning,Policy Sciences 4:155-169, Elsevier Scientific Publishing, Amsterdam.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.152COMPUTER SCIENCE: REFLECTIONSrespects the pragmatic issues of the applications. The third is the humanand social context of the engineering effort, which includes the process of
creating and evolving artifacts, as well as issues related to policy, markets,
usability, and socio-economic impacts; this context provides a basis for
shaping the engineered artifacts to be fit for their intended use.Software engineering is ofteninappropriatelyconfused with mereprogramming or with software management. Both associations are
inappropriate, as the responsibilities of an engineer are aimed at the pur-
poseful creation and evolution of software that satisfies a wide range of
technical, business, and regulatory requirementsnot simply the abilityto create code that satisfies these criteria or to manage a project in an
orderly, predictable fashion.Software EngineeringA physicist approaches problems (not just physical problems) by try-ing to identify masses and forces. A mathematician approaches problems
(even the same problems) by trying to identify functional elements and
relations. An electrical engineer approaches problems by trying to identify
the linearly independent underlying components that can be composed
to solve the problem. A programmer views problems operationally, look-
ing for state, sequence, and processes. Here we try to capture the charac-
teristic mind-set of a software engineer.Computer Science FundamentalsThe core body of systematic knowledge that supports software engi-neering is the algorithmic, representational, symbol-processing knowledge
of computer science, together with specific knowledge about software
and hardware systems.Symbolic representations are necessary and sufficient for solving informa-tion-based problems. Control and data are both represented symbolically.As a result, for example, an analysis program can produce a symbolic
description of the path for a machine tool; another program can take this
symbolic description as input and produce a symbolic result that is the
binary machine code for a cutting tool; and that symbolic representation
can be the direct control program for the cutting tool. Notations for sym-
bolic description of control and data enable the definition of software,
both the calculations to be performed and the algorithms and data struc-
tures. This task is the bread and butter of software implementation, and
the existence of symbol strings as a uniform underlying representation of
code, data, specification, analysis, and other descriptions simplifies both
software design and tool support for software development activities.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE153Abstraction enables the control of complexity.
 Abstraction allows the
introduction of task-specific concepts and vocabulary, as well as selective
control of detail. This in turn allows separation of concerns and a crisp
focus on design decisions. A designer of mechanical systems might work
with (and expand) a set of abstractions having to do with shapes, weights,
and strengths, whereas a designer of accounting systems might work
with a set of abstractions having to do with customers, vendors, transac-
tions, inventory, and currency balances. The ability to introduce problem-
specific definitions that can, in most respects, be treated as part of the
original design language allows software design to be carried out in
problem-specific terms, separating the implementation of these abstrac-
tions as an independent problem. An additional benefit is that this leads
to models and simulations that are selective about the respects in which
they are faithful to reality. Some levels of design abstraction, character-
ized by common phenomena, notations, and concerns, occur repeatedly
and independent of underlying technology. The most familiar of these is
the programming language, such as Java. The recent emergence of UML
has provided a set of diagrammatic4 design vocabularies that address
specific aspects of design, such as the sequence of operations or the allow-
able transitions between system states. More specialized abstractions are
now being used to define software product families, or design spaces
that allow multiple similar software systems to be produced systemati-
cally and predictably.Imposing structure on problems often makes them more tractable, and anumber of common structures are available. Designing systems as related setsof independent components allows separation of independent concerns;
hierarchy and other relations help explain the relations among the com-
ponents. In practice, independence is impractical, but software designers
can reduce the uncertainty by using well-understood patterns of software
organization, called software architectures. An architecture such as a pipe-
and filter system, a client-server system, or an application-and-plugin
organization provides guidance drawn from prior experience about the
kinds of responsibilities to assign to each component and the rules that
govern component interaction.Precise models support analysis and prediction. These models may be
formal or empirical. Formal and empirical models are subject to different
standards of proof and provide different levels of assurance in their
results. For example, a formal model of an interaction protocol can reveal4Diagrams are symbolic representations, just as text strings are. The grammars for dia-grammatic notations may be more complex than those for textual symbolic representations,
but the essential properties are shared.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.154COMPUTER SCIENCE: REFLECTIONSthat implementations will have internal inconsistencies or the possibilityof starvation or deadlock. The results support software design by provid-
ing predictions of properties of a system early in the system design, when
repair is less expensive. Software systems are sufficiently complex that
they exhibit emergent properties that do not derive in obvious ways from
the properties of the components. Models that support analysis or simula-
tion can reveal these properties early in design, as well.Engineering FundamentalsThe systematic method and attention to pragmatic solutions thatshapes software engineering practice is the practical, goal-directed
method of engineering, together with specific knowledge about design
and evaluation techniques.Engineering quality resides in engineering judgment. Tools, techniques,
methods, models, and processes are means that support this end. The
history of software development is peppered with methodologies for
designing software and tools for creating and managing code. To the
extent that these methods and tools relieve the designer of tedious, error-
prone details, they can be very useful. They can enhance sound judgment,
and they may make activities more accurate and efficient, but they cannot
replace sound judgment and a primary commitment to understanding
and satisfying clients needs.
Engineering requires reconciling conflicting constraints and managinguncertainty. These constraints arise from requirements, from implementa-
tion considerations, and from the environment in which the software
system will operate. They typically overconstrain the system, so the engi-
neer must find reasonable compromises that reflect the clients priorities.Moreover, the requirements, the available resources, and the operating
environment are most often not completely known in advance, and they
most often evolve as the software and system are designed. Engineers
generate and compare alternative designs, predict the properties of the
resulting systems, and choose the most promising alternatives for further
refinement and exploration. Finding sufficiently good cost-effective solu-
tions is usually preferable to optimization.Engineering skills improve as a result of careful systematic reflection onexperience. A normal part of any project should be critical evaluation of the
work. Critical evaluation of prior and competing work is also important,
especially as it informs current design decisions. One of the products of
systematic reflection is codified experience, for example in the form of a
vocabulary of solution structures and the situations in which they are
useful. The designs known as software product lines or software product
families define frameworks for collections of related software systems;Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE155these are often created within a company to unify a set of existing products
or to guide the development of a next-generation product.Human, Social, and Economic FundamentalsThe commitment to satisfying clients needs and managing effective
development organizations that guides software engineering business
decisions is the organizational and cognitive knowledge about the human
and social context, together with specific knowledge about human-
computer interaction techniques.Technology improves exponentially, but human capability does not. The
Moores-law improvements in cost and power of computation (see Hill inChapter 2) have enabled an unprecedented rate of improvement in technical
capability. Unfortunately, the result has often been software products 
thatconfuse and frustrate their users rather than providing corresponding
improvements in their efficiency or satisfaction. Software developers are
increasingly aware of the need to dedicate part of the increase in comput-
ing capability to simplifying the use of the more-capable software by
adapting systems to the needs of their users.Cost, time, and business constraints matter, not just capability. Much of
computer science focuses on the functionality and performance proper-
ties of software, including not only functional correctness but also, for
example, speed, reliability, and security. Software engineering must also
address other concerns of the client for the software, including the cost of
development and ownership, time to delivery, compliance with standards
and regulations, contributions to policy objectives, and compatibility with
existing software and business processes. These factors affect the system
design as well as the project organization.Software development for practical software-intensive systems usually dependson teamwork by creative people. Both the scale and the diversity of knowl-
edge involved in many modern software applications require the effort
and expertise of numerous people. They must combine software design
skills and knowledge of the problem domain with business objectives,
client needs, and the factors that make creative people effective. As a
result, the technical substance of software engineering needs an organiza-
tional setting that coordinates their efforts. Software development methods
provide guidance about project structure, management procedures, and
information structures for tracking the software and related documents.Software Engineering ResearchSoftware engineering researchers seek better ways to develop practicalsoftware, especially software that controls large-scale software-intensiveComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.156COMPUTER SCIENCE: REFLECTIONSsystems that must be highly dependable. They are often motivated by theprospect of affecting the practice of software development, by finding
simpler ways to deal with the uncertainties of wicked problems, and by
improving the body of codified or scientific knowledge that can be applied
to software development.Scientific and engineering research fields can be characterized byidentifying what they value:What kinds of questions are interesting?What kinds of results help to answer these questions, and whatresearch methods can produce these results?What kinds of evidence can demonstrate the validity of a result,and how are good results distinguished from bad ones?Software engineering research exhibits considerable diversity alongthese dimensions. Understanding the widely followed research strategies
helps explain the character of this research area and the reasons software
engineering researchers do the kinds of research that they do.Physics, biology, and medicine have well-refined public explanationsof their research processes. Even in simplified form, these provide guid-
ance about what counts as good research both inside and outside the
field. For example, the experimental model of physics and the double-
blind studies of medicine are understood, at least in broad outline, not
only by the research community but also by the public at large. In addi-
tion to providing guidance for the design of research in a discipline, these
paradigms establish the scope of scientific disciplines through a social
and political process of boundary setting.Software engineering, however, is still in the process of articulatingthis sort of commonly understood guidance. One way to identify the
common research strategies is to observe the types of research that are
accepted in major conferences and journals. These observations here are
based specifically on the papers submitted to and accepted by the Inter-
national Conference on Software Engineering;5 they are generally repre-
sentative of the field, though there is some dissonance between research
approaches that are advocated publicly and those that are accepted in
practice. Another current activity, the Impact Project,6 seeks to trace the
5Mary Shaw, 2003, Writing Good Software Engineering Research Papers, Proceedings ofthe 25th International Conference on Software Engineering (ICSE 2003), IEEE Computer Society,pp. 726-736.6Impact Project Panel, 2001, Determining the Impact of Software Engineering ResearchUpon Practice, Panel Summary, Proceedings of the 23rd International Conference on SoftwareEngineering (ICSE 2001), IEEE Computer Society, p. 697.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.BUILDING COMPUTING SYSTEMS OF PRACTICAL SCALE157influence of software engineering research on practice; the emphasis thereis on the dissemination of research rather than the research strategies
themselves.Questions Software Engineering Researchers Care AboutGenerally speaking, software engineering researchers seek better waysto develop and evaluate software. Development includes all the synthetic
activities that involve creating and modifying the software, including the
code, design documents, documentation, and so on. Evaluation includes
all the analytic activities associated with predicting, determining, and
estimating properties of the software systems, including both functionality

and extra-functional properties such as performance or reliability.Software engineering research answers questions about methods ofdevelopment or analysis, about details of designing or evaluating a par-
ticular instance, about generalizations over whole classes of systems or
techniques, or about exploratory issues concerning existence or feasibility.The most common software engineering research seeks an improvedmethod or means of developing softwarethat is, of designing, imple-menting, evolving, maintaining, or otherwise operating on the software
system itself. Research about methods for reasoning about software sys-
tems, principally analysis of correctness (testing and verification), is also
fairly common.Results Software Engineering Researchers RespectThe tangible contributions of software engineering research may beprocedures or techniques for development or analysis; they may be
models that generalize from specific examples, or they may be specific
tools, solutions, or results about particular systems.By far the most common kind of software engineering research resultis a new procedure or technique for development or analysis. Models of
various degrees of precision and formality are also common, with better
success rates for quantitative than for qualitative models. Tools and nota-
tions are well represented, usually as auxiliary results in combination
with a procedure or technique.Evidence Software Engineering Researchers AcceptSoftware engineers offer several kinds of evidence in support of theirresearch results. It is essential to select a form of validation that is appro-
priate for the type of research result and the method used to obtain the
result. As an obvious example, a formal model should be supported byComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.158COMPUTER SCIENCE: REFLECTIONSrigorous derivation and proof, not by one or two simple examples. Yet, asimple example derived from a practical system may play a major role in
validating a new type of development method.The most commonly successful kinds of validation are based on analysisand real-world experience. Well-chosen examples are also successful.Additional ObservationsAs in other areas of computer science, maturation of software engi-neering as a research area has brought more focused, and increasingly
explicit, expectations for the quality of researchcare in framing ques-tions, quality of evidence, reasoning behind conclusions.Software engineering remains committed to developing ways tocreate useful solutions to practical problems. This commitment to dealing
with the real world, warts and all, means that software engineering
researchers will often have to contend with impure data and under-con-
trolled observations. Most computer science researchers aspire to results
that are both theoretically well grounded and practical. Unfortunately,
practical problems often require either the simplification of the problem
in order to achieve theoretically sound conclusions or else the sacrifice of
certainty in the results in favor of results that address the practical aspects
of the problem. Software engineering researchers tend to choose the latter
course more often than the former.The community of computer users seems to have a boundless appe-tite for information-processing capability. Fueled by our collective imagi-
nation, this appetite seems to grow even faster than Moores-law technol-ogy growth. This demand for larger scale and complexity, coupled with
an increasing emphasis on dependability and ease of useespecially forusers with little computer traininggenerates new problems, and evennew classes of problems for software engineering.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.1598Research Behind
Everyday ComputationComputer science research has led to the emergence of entirely newcapabilities used by millions of ordinary people today. Using
computers to typeset text was probably foreseeable, but the easewith which anyone can become a small-scale publisher by using the Web
was harder to envision. Automating accountantsÕ ledger paper was
perhaps natural, but the ability to disintermediate the financial-analysis
functionÑmoving control from a central data-processing department to a
spreadsheet on an executiveÕs deskÑcould not have been. Creating an
index of documents stored at various Internet locations so that they could
be shared by a community of physics researchers was, perhaps, not
astounding, but leveraging the power of distributed access, the universal
name-space of the uniform resource locator (URL), and easily usable

browsers together with new algorithms for searching has led to an explo-
sion of information-retrieval opportunities that has changed forever the
way we do business.Computers now perform most of the document-preparation tasks thatused to be handled by secretaries: typing drafts, correcting drafts, posi-
tioning figures, formatting final copy, and the like. Ullman traces the
30-year evolution of text-formatting programs from quick-and-dirty type-
setters created by graduate students to avoid typing their theses to the
powerful document-formatters of the present day.Similarly, Foley shows how todayÕs spreadsheets, which began as aprogram to help accountants manage ledger sheets, astonished theComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.160COMPUTER SCIENCE: REFLECTIONScomputer-science world by becoming the Òkiller applicationÓ that trans-
ferred effective control of computing to non-programmers in all disciplines.One of the principal personal uses of computers today is searchingthe InternetÕs wealth of online information. The idea of informationretrieval is far from new, but the ability to dedicate computing power to
amplifying human effort has led to new wrinkles, such as attempts to
establish the relevance of information based on the number of people
referring to it. Norvig explains the technology behind modern Internet
searches.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.RESEARCH BEHIND EVERYDAY COMPUTATION161HOW YOU GOT MICROSOFT WORDJeffrey Ullman, Stanford University and Gradience CorporationThose born after about 1975 cannot imagine the cumbersome processby which formal documents, ranging from business letters to books, were
produced. Drafts were hand-written and then typed by a secretary using
a typewriter. If corrections were needed, small errors could be handled by
erasing or by applying whiteout, followed by typing of the correct words.
But length-changing errors required that the entire page be retyped and
the error-checking process be repeated. When computers first became
widespread in businesses and schools, many people started typing their
documents on punch cards. Similar to the cards that were used in the
famous Florida vote of 2000, the cards represent letters when you punch
out certain holes, creating Òchad.ÓA document such as a thesis could be typed on cards, fed to thecomputer, and printed line-for-line on a printer. Early printers were like
typewriters, but faster. This arrangement solved the problem of handling
small errors, since only one or a few cards would have to be repunched.
Several early computer-science students saw the potential for doing better,
especially as they confronted the daunting task of typing their PhD theses.
In 1964, Jerry Saltzer at the Massachusetts Institute of Technology created
for this purpose a pair of programs: Typeset, which was an early form of
a text editor, and Runoff, which was an improved formatting system. Bob
Balzer, at Carnegie Mellon University, created software similar to Runoff,
called LEAD (List, Edit, and Display), at about the same time. Programs
like Runoff and LEAD not only reproduced what was on punch cards, but
also formatted the document by placing on one line as many words as
would fit, typically a maximum of 80 characters per line. This advance
solved the problem of having to retype large amounts of text when words
were inserted or deleted. Special commands, which were not part of the
text, could be inserted to control matters such as justification, that is,
alignment of text on the right, as in a book, as well as on the left.Word-Processing Software at Bell LabsThe Typeset/Runoff system inspired a group of researchers at BellLaboratories, leading to Joe OssannaÕs NROFF (new runoff) program. AÒmacroÓ capability was added to allow repetitive formatting concepts,
such as section headers or indented paragraphs, to be defined once and
used easily many times. The ÒMSÓ macro package by Mike Lesk was
widely used as a standard for formatting of text. But the printed outputComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.162COMPUTER SCIENCE: REFLECTIONSdevice was still a souped-up typewriter, with its single size and font ofletters.In the early 1970s, work on typesetting at Bell Labs had progressed tothe point where the labs purchased a CAT phototypesetting machine, of
the kind used at the time to produce newspapers, for example. This device
allowed printing to be done in several fonts and font sizes. Unlike todayÕslaser printers, it printed only on photographic paper, which was then
reproduced by one of several processes, such as a ÒXerox machine.ÓNROFF evolved into TROFF (typesetter runoff) to allow documents to be
created that were then typeset on film. For the first time, it became possible
for casual authors to produce a letter or report that looked as if it were
part of a book.However, TROFF was not up to the requirement faced by many sci-entists and engineers to set mathematical text easily. While the CAT
printer could, for example, print a subscript in the correct (smaller) size
and below the line of text, there was no convenient way to tell it to do so.
EQN, a program written by Brian Kernighan, solved that problem by
taking expressions that represented how the equation or formula shouldlook (e.g., ÒX sub 1
Ó for an 
X with a subscript 1, 
X1) and turning them intoTROFF, while leaving everything that wasnÕt equations intact, for laterprocessing by TROFF. EQN is in effect an atypical programming lan-
guage, since it does not let you write general-purpose algorithms, as the
best-known programming languages do, but it helps you deal with a
particular, difficult problem, that of describing how mathematical expres-sions should look on the page. It is an excellent example of how theeffective design of a language or notation for a problem leads to tools that
people find useful and powerful. A key borrowing of EQN from the more
traditional programming languages is recursion, one of the central themes
of computing, where things are defined partially in terms of themselves.
For example, EQN allows one to say not only ÒX sub 1
Ó but 
ÒX sub
anythingÓ or even 
Òanything sub anything,Ó where the 
ÒanythingsÓ can
themselves have subscripts or any of the other operations whereby math-
ematical expressions are built up, such as by horizontal lines for division.
Thus, one can say things like ÒX sub {
n sub 
i} Ó to represent an 
X whose
subscript is itself a subscripted Òn sub 
iÓ (  xni).Several other components of modern word processors got their startin the same Bell Labs group. The first spell-checkers were developed to
compare words in the document with a list of ÒacceptableÕÕ words, modi-fied by rules for plurals, tense modifications, and so on. Also, Lorinda
Cherry developed the first grammar-checker (DICT, for ÒdictionÓ) byapplying a table of rules to the document.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.RESEARCH BEHIND EVERYDAY COMPUTATION163Typesetting Research at Xerox PARCIn the mid-1970s, a team of researchers at Xerox PARC (Palo AltoResearch Center) made several important contributions toward the way
we now create documents. One was the development of the laser printer.
While the Xerox PARC researchers could and did build a laser printer,
they could not do so at a price people would pay. They estimated that it
would cost over $100,000 at that time for the printer we now buy for a few
hundred dollars. Nevertheless, in order to verify their conjecture that the
existence of these devices would change the way people dealt with docu-
ments, they built prototypes of a laser printer, called Dover, and gave
them to several universities. As envisioned, the Dover changed markedly
the way students and faculty prepared papers. Also as envisioned, the
cost for building such devices has dropped dramatically over the years,
and the dream of a laser printer on every desk has become real.A second innovation from the PARC group was the WYSIWYG(wizzy-wig, or 
Òwhat you see is what you getÓ) editor. A prototype texteditor called Bravo allowed users to see the document they were creating.
In one sense, the differences between Bravo and TROFF were small. For
example, each allowed you to specify that certain text should be italics. In
Bravo, as in MSWord and other text-processing systems today, one could
change fonts, say to italics, as one typed. In contrast, TROFF required you
to type a command (Ò.itÓ) to say Òchange to italics.Ó Bravo allowed you to
see that you were really typing italic text (and would also let you see if
you forgot to return to roman text when you should), while with TROFF,
you could only tell whether you got it right when you printed your docu-
ment later. On the other hand, Bravo was less adept at setting complex
mathematical formulas, since it did not possess the recursive description
capabilities of EQN, and in fact, the successors of Bravo up to this day
have not recaptured the power of EQN in WYSIWYG mode. While it may
seem obvious that for non-mathematical typesetting, WYSIWYG editors
are a wonderful tool, the existence of such editors depends on develop-
ments in a number of different areas. Of course, processors had to become
fast enough that it became economical to devote a processor to a single
task like editing. Computer graphics technology needed to advance to a
state where it was possible to offer the user a video terminal as a display
unit. Operating systems needed to incorporate windows as a primitive
concept and manage rapid communication and drawing of characters,
between keyboard, processor, and display.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.164COMPUTER SCIENCE: REFLECTIONSThe TeX ProjectAt about the same time as the Xerox activities, Don Knuth at Stanfordbegan a broad study of how computers can improve the preparation and
typesetting of documents. By this time, it was clear that the font was a
critical computer object. Descriptions of the letters in a font have to be
developed so the same look can be displayed on a video terminal and also
printed, perhaps at a different size, on one of many different printing
devices. For this purpose, Knuth developed a system called Metafont for
describing the shapes of letters and other characters in a way that allows
easy generation of the font in different sizes and slants. Knuth also devel-
oped TeX, a unified system for typesetting that incorporates the capabili-
ties of TROFF and several specialized systems such as EQN. In addition,
TeX increases the care with which paragraphs and pages are laid out.
TeXÕs paragraphing algorithm looks at the words of an entire paragraphbefore deciding on line-breaks, and thereby improves the look of the text
when compared with ÒgreedyÓ algorithms that look at text a line at a time
and fit whatever they can on each line in succession. The TeX paragraphing
algorithm is an excellent example of a general computational approach
called Òdynamic programming.Ó It works roughly as follows. First, we
need a measure of how well words fit on a line. A typical approach, even
for greedy algorithms, is to decide on the optimum space between words
and then assign a ÒbadnessÓ to a line proportional to the square of the
deviations of the spaces from the optimal. The objective then becomes to
minimize the total badness of all the lines in a paragraph.Now the number of ways to break a paragraph of, say, 100 words into10 lines is astronomical; it is the number of ways to pick 9 line breaks
among the 99 positions between the words, which is Ò99 choose 9,Ó or
about 1.7 trillion. It is clearly not feasible to consider all possible ways to
break paragraphs. Fortunately, as is often the case in computer science,
the obvious way to do something is neither the best way nor the only
way. In this case, dynamic programming let Knuth find an algorithm that
takes time proportional to the length of the paragraph, rather than to
some exponential in the size of the paragraph.The dynamic programming algorithm fills out a table of least bad-nesses, not just for the paragraph itself, but for all paragraphs that could
be formed from a tail or suffix of the sequence of words in the paragraph.
That is, for each i, starting at 1 and going up to the number of words in theparagraph, the entry for i is the least badness of any division of the last 
iwords into lines. Suppose we have computed this value for 1, 2, . . . up to
i Ð 1. To decide on the best line breaks for the last 
i words, we consider, forall k small enough that 
k words can fit on one line, the cost of placing the
first k of the 
i words on one line (using the formula for the ÒbadnessÓ of
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.RESEARCH BEHIND EVERYDAY COMPUTATION165any particular line), plus the badness of the best breaking for the remain-ing i Ð k words (as given by the table). As soon as 
i reaches the total
number of words in the paragraph, we know the cost of the best line
breaking, and we can easily figure out what that breaking is, by storing in
the table, as we go, the winning value of k for each 
i.In addition, one of KnuthÕs students, Frank Liang, invented an elegantalgorithm for choosing the points at which words should be hyphenated.
The dictionary tells us how to hyphenate in a straghtforward way: it lists
every word it knows and shows where the hyphens may go. In addition
to using a lot of space, that approach is of little use if youÕve just inventeda word like Òcyberpunk,Ó or you need to hyphenate a proper noun. Liang
Õsapproach was to summarize the rules of hyphenation, using a simple
language for expressing those rules and their priorities.Imagine a collection of rulesÑitÕs good to hyphenate here; itÕs notgood to hyphenate there. For instance, it is generally a bad idea to hyphenate
between the ÒaÓ and ÒtÓ in Ò. . . at . . . .Ó But if the word happens to fit thepattern Ò. . . ation . . .,Ó then it is actually a good idea to hyphenate
between the ÒaÓ and 
ÒtÓ if the word has to be hyphenated. Each rule has
a number associated with it, and this number is given to those points
between letters to which the rule applies. Thus, a point might acquire
several different numbers, from different rules. If so, take the largest of
the numbers and ignore the rest. The magic of LiangÕs algorithm is this: ifthe number associated with a point is odd, then you may hyphenate
there; if it is even, you may not. For example, the rule about Ò. . . at . . .Ómight receive a low, even number, like 2. That number suggests that in
the absence of any more specific pattern, letÕs not hyphenate here. Therule about Ò. . . ation . . . ,Ó on the other hand, would have a high, odd
number, such as 9. Thus, the rule strongly suggests Òa-tionÓ is a good
hyphenation, and overrules the more general idea that Òa-tÓ is bad. Werewe to have a specific word in mind with pattern Ò. . . ation . . .Ó where we
did not want the hyphen between the ÒaÓ and 
ÒtÓ (there are no such
examples in common English), we could make that word a pattern with a
still higher, even number, like 24.Word Processing TodayIf you are familiar with MSWord or a similar application such asWordPerfect, you will know that many of the ideas described here are
available to you. The application breaks paragraphs into lines in a way
that allows alignment at both left and right (although it does not use the
TeX algorithm for doing so). It allows changes of font at the press of a
button on the screen. It allows global changes in the way elements such as
sections are displayed, just as the early Bell Labs macro packages did. ItComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.166COMPUTER SCIENCE: REFLECTIONShas a rule-based system to catch many grammatical errors, like DICT did,and catches spelling errors in a similar way. It has a WYSIWYG interface
like the old Bravo editor, and it easily passes its document to a laser
printer, a descendant of the Dover printers of 25 years ago. The system
provides a virtually unlimited number of fonts.Perhaps as a reflection on how prevalent word processing has become
in ordinary discourse, neither Microsoft nor other manufacturers of word-
processing applications have felt the need to integrate mathematical type-
setting nearly as closely as did EQN. Ironically, many scientists and engi-
neers still prefer to write using TeX (which has all the power of EQN and
more), or its variant LaTeX, a system developed by Leslie Lamport.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.RESEARCH BEHIND EVERYDAY COMPUTATION167VISICALC, SPREADSHEETS, AND PROGRAMMINGFOR THE MASSES, OR ÒHOW A KILLER APP WAS BORNÓJames D. Foley, Georgia Institute of TechnologyAn important part of computing is the study of human computerinteractionÑHCI. Individuals and organizations generally buy computerhardware and software expecting that the computer will allow them to do
something entirely new, or more accurately or completely or quickly or
economically or with more enjoyment than without the computer. The
role of HCI is to develop computer capabilities that match what people want
to do, so that the computer can be useful to individuals and organizations.1At least three important software innovations in the last 30 years havebeen HCI tours de force:¥The development of window managers at SRI and PARC, whichwere precursors to the Macintosh and Microsoft window manager soft-
ware that allowed millions of people to easily use personal computers.¥The development of the first Web browser by Tim Berners-Lee in1991;2 the development of Mosaic (the first widely available browser) at
the University of Illinois in 1993, and their subsequent progeny Netscape
Navigator and Internet Explorer, which made the World Wide Web
accessible to millions of people as opposed to the thousands who had
been using it originally.¥VisiCalc, developed by Dan Bricklin and Bob Frankston in 1979.Prior to VisiCalc, personal computers were bought mostly by hobbyists,
game players, and to teach programming. The VisiCalc spreadsheet pro-
gram (whose commercial successors include MicrosoftÕs Excel) causedmany financial analysts, business people, accountants, and students to
buy personal computers (first the Apple II and later the IBM PC). As such,
VisiCalc was the Òkiller appÓ that dramatically increased sales of these
computers.VisiCalcIn this essay we focus on VisiCalc, for several reasons. First, VisiCalcdid spark the sales of personal computers. Second, VisiCalc introduced1See, for example, Brad A. Myers, 1998, ÒA Brief History of Human Computer InteractionTechnology,Ó ACM Interactions 5(2):44-54. Available online at http://www-2.cs.cmu.edu/~ mulet/papers/uihistory.tr.html.2See http://www.w3.org/History.html.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.168COMPUTER SCIENCE: REFLECTIONSmany of its users to computer programming without their ever realizingthey were doing computer programming, thereby providing a powerful
tool in an easy-to-use package. And finally, as with window managers
and Mosaic, VisiCalc could not have happened without a considerable
body of prior computer science research.Why did VisiCalc spark PC sales? Why did people rush to buy acomputer in order to use VisiCalc? Simply because VisiCalc met a market
need (a human need) to organize and calculate numbers more rapidly
using an electronic spreadsheet than one could do by hand with a paper-
based spreadsheet and an adding machine or an electronic calculator.
There was a pent-up demand, and VisiCalc together with the PC met that
demand. As time went on, other uses for VisiCalc developedÑmany of usorganize lists of address and other information in the convenient row and
column format of our favorite spreadsheet, perhaps never calculating a
single number. These uses may not have been what Bricklin and Frankston
envisioned, but are typical of the way in which tools are adapted by their
users to meet needs not envisioned by the toolsÕ designers.
What about this notion that VisiCalc users are actually programming?Well, the ÒequationsÓ of VisiCalc, by which one states that a particular
cell of the spreadsheet is to have a value computed from other cells, are
essentially the same as the assignment statements and expressions used
in all modern programming languages. The VisiCalc equation Ò= (B6 +B7)/(C4 + C5) Ð D9
Ó placed in cell B9 has the same effect
3 as the C pro-
gramming language statement B9 = (B6 + B7)/(C4 + C5) Ð D9 or the Pascal
statement ÒB9 := (B6 + B7)/(C4 + C5) Ð D9
Ó or the Java statement 
ÒB9 =(B6+B7)/(C4 + C5) 
Ð D9.
Ó But, referring back to the concept of the uni-
versal machine (see Kleinberg and Papadimitriou in Chapter 2), it is not
the case that this limited form of programming in VisiCalc is the equiva-
lent of a general programming capability.VisiCalc allowed and encouraged its users to program without realizingthat they were programming, using the simple-to-understand formulae
that could either be typed into a spreadsheet cell or be partially or in some
cases completely entered simply by pointing to the cells in the spread-
sheet that appear in the equation. Hence, a reduction in the Òfear of pro-grammingÓ that often discouraged people from putting computers to use.
How did VisiCalc draw on computer science research? In multipleways:3Strictly speaking, as soon as any of the variables such as B6 or C5 change, the equation isre-evaluated and the new value is placed in cell B9, whereas with the programming lan-
guages the assignment statement is executed only when the program flow of control comesto the statement. This means that the VisiCalc equation is a more powerful construct thanthe programming language assignment statement.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.RESEARCH BEHIND EVERYDAY COMPUTATION1691. By using a visual Òwhat you see is what you getÓ (WYSIWYG) user
interface, in which one sees the spreadsheet and can directly manipulate cells in
the spreadsheet by pointing at them.Dan Bricklin states in his Web pages4 that he was aware of and influ-enced by the early research work of Doug Engelbart on text editors using
a mouse, and that he had probably seen a demonstration of Xerox PARCÕsAlto computer system, which was in turn also influenced by Engelbart.
Engelbart and PARC are the critical early developers of the key elements
of contemporary window-oriented user interfaces found in the Macintosh
and Microsoft operating systems.EngelbartÕs passion was to augment the human intellect by providingcomputer tools to help organize information, compose and modify docu-
ments, and work with others at a distance while doing this. With this
vision, he and a group (up to 17 researchers) developed NLS (oN-Line
System) between 1962 and 1969 at the Stanford Research Institute.Along the way, they invented the mouse as a way to interact with thecomputer by pointing rather than by the much slower process of moving
a cursor with key strokes; developed tiled windows (non-overlapping, as
opposed to the overlapping windows of Microsoft Windows and the
Apple Macintosh operating system); developed a text editor with com-
mands to move, copy, and delete individual characters, words, or blocks
of text (see Ullman in Chapter 8); and provided hyperlinks (just like in the
World Wide Web) and key-word searches (similar to the search-engine
concept of Google and Alta Vista).EnglebartÕs research style is not unusual; set a big, hard-to-achievegoal, and create multiple tools needed to achieve that goal. The same
thing happened at Xerox PARC. The Alto workstation software devel-
oped at PARC starting in the early 1970s was the prototype for the Apple
Macintosh and Microsoft Windows user interfaces. Alto had many of the
features seen in these and other contemporary window interfaces: windows,
icons, menus, copy and paste commands, and direct-manipulation text
and graphics editors.2. By using Òprogramming by exampleÓ to simplify and speed up the process
of entering equations.VisiCalc was the first widely used instance of Òprogramming byexample,Ó in which the user does programming by demonstrating opera-
tions to the computer rather than by specifying what is to be done via4See http://www.bricklin.com/visicalc.htm.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.170COMPUTER SCIENCE: REFLECTIONSsome programming language. For example, to indicate that a cell shouldalways have in it the sum of several other cells, one would point at the cell
that has the sum, and then successively to the cells that are to be summed.The idea of programming by example was developed in a slightlydifferent form by Moshe Zloof of IBM research a few years earlier. Zloof
wanted to allow users to specify database queries without having to learn
a query programming language (such as SQL). His insight was to recog-
nize that if a user gave just an example of the query results such as a list of
part numbers, descriptions, inventory quantity, and selling price, then the
query language statement(s) to obtain all of the results could be generated
from the example.VisiCalc applied the concept in a slightly different way than did Zloof,thus both drawing on and contributing to the storehouse of computer
science knowledge (a typical pattern for CS and other research). Specifi-
cally, VisiCalc allows the user to enter a formula (such as given above) by
pointing at the cells that occur in the formula. So to enter the formula
B2+C5 in cell B1, the user points at cell B1, types = to indicate that a

formula is being specified, then points at cell B2, then points at cell C5,
and ends by typing the enter key. The + in the formula is assumed and
entered automatically, as the most common choice. If the product is
desired rather than the sum, the user types Ò*Óafter pointing at cell B2 andbefore pointing at cell C5.This seemingly simple idea greatly simplifies the process of enteringformulae, and it corresponds nicely to the intuition that, given a choice
between pointing at something and typing the name of something (in the
case at hand, the spreadsheet cell), we humans will tend to point rather
than name, as the easier of the two alternatives.3. By applying finite state machine notation as a tool for designing theprogramÑwhat inputs were valid in each Òstate,Ó what response the computer
would make to each input, and what new program ÒstateÓ would result.
The understanding of how to use state diagrams for specifying thebehavior of interactive programs was first developed by William Newman
in 1968 as a researcher at Imperial College, London. He, in turn, drew on
the fundamental notion of finite state machines that had been developed
as yet another computer science concept. The idea as applied to VisiCalc
is that the program can be in one of a finite number of states. In each state,
only certain user actions (such as entering information into a cell, or
selecting a command) are possible. Each such action takes the program to
another state (or back to the same state) and at the same time causes some
change in what the user sees on the display.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.RESEARCH BEHIND EVERYDAY COMPUTATION1714. By using language parsing techniques.Computer scientists have developed techniques for taking expressionssuch as the earlier example of the expression (B6 + B7)/(C4 + C5) Ð D9
stored in cell B9 and actually performing the calculations in the appropriate
sequence. With the example expression, the actual sequence of arithmetic
operations would be:Add cells B6 and B7, saving the result in a place called TEMP1.Add cells C4 and C5, saving the result in a place called TEMP2.
Add TEMP1 and TEMP2, saving the results in TEMP1.
Add TEMP1 and cell D9, saving the results in cell B9.This may seem simple, but try writing out a general procedure thatwill work with an arbitrary expression, with many parentheses and divi-
sions and multiplications! Not so easy, is it?The Next ÒKiller AppÓWhat will be the successor to VisiCalc, to windowing systems, to Webbrowsers that will provide new capabilities to millions and tens of millions
of computer users? There are many possibilities; I believe that whatever
the next major development, the next Òkiller app,Ó might be, it will:
¥Meet an individual or organizational need.¥Draw on the research of many, many computer scientists.¥Leverage the existing hardware and software infrastructure, andaccelerate their growth (just) as VisiCalc leveraged and accelerated the
availability of PCs and e-mail leveraged the Internet and Web browsers
leveraged the World Wide Web protocols.We also note that only Web browsing was well anticipated as a killerappÑanticipated by Vannevar Bush in the 1940s and researched by anumber of prominent computer scientists from the late 1960s into the
1980s.Many candidates for the next Òkiller appÓ recognize that the now-
common use of computers by people sitting at a desk may not be the
major way of using computers in the future. A fundamentally new
direction for computing is evolving: I call this direction off-the-desk-top
computing, in the sense that it will not be desk-top computers but other
forms of computers that will create the next revolution. Others call it
ubiquitous or embedded computing, in the sense that computing will be
everywhere (i.e., ubiquitous) and embedded in all manner of devices andComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.172COMPUTER SCIENCE: REFLECTIONSequipment. This is already happening. Contemporary cell phones have acomputer that is as powerful as desk-top computers of 10 years ago. TV
set-top boxes have as much computing power as powerful engineering
workstations of 5 years ago. The typical automobile has 10 to 20 com-
puters with aggregate power comparable to a contemporary desk-top PC.The most widespread hardware and software infrastructure thatmight be leveraged is the wireless phone system. It is already pervasive,
and it is computer intensive. It is already heavily used for short text
messages, for games, and to obtain information. And, with the small size
of wireless phones and their keypads, and the integration of wireless
functionality into personal digital assistants and with the clear benefit of
voice recognition in using small devices, a trend can surely be predicted.
More generally, voice recognition will become more and more pervasive
as algorithms improve and as computing power and memory become
ever more available.Another hardware and software infrastructure that will be leveragedis the World Wide Web itself. With vast amounts of information online
and more and more of the world citizenry connected, the use of intelligent
assistants to find information, to make sense of information, and to use
information will surely expand. Current examples include comparison
shopping, money management, and travel arrangements. Life has become
more complex and fast-moving; perhaps computers can help simplify life
in some ways.Automobiles already have dozens of computers, many networkedtogether. They serve just one of two purposesÑoperating the car, orentertaining/communicating with the driver and passengers. Many cars
already have built-in wireless phones, global positioning systems, limited
voice recognition, and navigation aids. Many people spend tens of hours
a week in a car, and there are significant personal and societal benefits to
further leveraging the automotive computing infrastructure to make driv-
ing safer, to connect us with the outside world, and to entertain us.We spend significant amounts of time at home. Many predictions aremade for computer-based home entertainment systems and the broader
Òwired home,Ó but the home has a very weak hardware and software
infrastructureÑnothing like that of the car or the typical office workingenvironment or the wireless phone. I believe that homes will ultimately
have networked appliances, switches, lights, motion sensors, cameras,
microphones, and so on. While we do not yet have a killer app, we have
candidates such as the use of computers to allow older people to live
alone at home for more years before having to live with their children or
in a nursing home; energy management; and home security.We should not neglect new uses of the Internet and the Web. AmyBruckman, in her essay in Chapter 7, nicely likens our use of the Web toComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.RESEARCH BEHIND EVERYDAY COMPUTATION173the early days when the automobile was still known as the Òhorselessbuggy.Ó At that time, nearly a century ago, one could not imagine the cars
and highways of today.While we can and should be proactive in exploring these possibilitiesand their implications for our lives, it is also true that only time will tell.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.174COMPUTER SCIENCE: REFLECTIONSINTERNET SEARCHINGPeter Norvig, Google Inc.In 300 BC, the Library of Alexandria held some half million scrollsand served as a cultural center for the world, uniting the thoughts of
Greek, Egyptian, Macedonian, and Babylonian culture. According to the
Letter of Aristeas, the library had Òa large budget in order to collect, ifpossible, all the books in the world.Ó Whole fields of study such as
geometry and grammar grew from the scholars who had the fortune to
travel to and study at Alexandria.In 2004 AD, the Internet forms a distributed library of billions ofpages, one that is accessible to anyone, anywhere in the world, at the click
of a mouse. Every day hundreds of millions of ÒtripsÓ to the library start
with a query to an Internet search engine. If I want to research a topic such
as ÒLibrary of Alexandria,Ó I can type those words to a search engine and
in less than a second have access to a list of 31,000 pages, sorted by their
usefulness to the query. This unprecedented ease of access to information
has revolutionized the way research is done by students, scientists,
journalists, shoppers, and others. It opens up an online marketplace of
products, services, and ideas that benefits both information providers
and seekers; sellers and buyers; consumers and advertisers.How is it that an Internet search engine can find the answers to aquery so quickly? It is a four-step process:1.Crawling the Web, following links to find pages;
2.Indexing the pages to create an index from every word to every
place it occurs;3.Ranking the pages so the best ones show up first; and
4.Displaying the results in a way that is easy for the user to understand.
Crawling is conceptually quite simple: starting at some well-known
sites on the Web, recursively follow every hypertext link, recording the
pages encountered along the way. In computer science this is called the
transitive closure of the link relation. However, the conceptual simplicity
hides a large number of practical complications: sites may be busy or
down at one point and come back to life later; pages may be duplicated at
multiple sites (or with different URLs at the same site) and must be dealt
with accordingly; many pages have text that does not conform to the
standards for HTML, HTTP redirection, robot exclusion, or other proto-
cols; some information is hard to access because it is hidden behind a
form, Flash animation, or Javascript program. Finally, the necessity ofComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.RESEARCH BEHIND EVERYDAY COMPUTATION175crawling 100 million pages a day means that building a crawler is anexercise in distributed computing, requiring many computers that must
work together and schedule their actions so as to get to all the pages
without overwhelming any one site with too many requests at once.A search engineÕs index is similar to the index in the back of a book: it
is used to find the pages on which a word occurs. There are two main
differences: the search engineÕs index lists every occurrence of every word,not just the important concepts, and the number of pages is in the billions,
not hundreds. Various techniques of compression and clever representa-
tion are used to keep the index Òsmall,Ó but it is still measured in terabytes
(millions of megabytes), which again means that distributed computing is
required. Most modern search engines index link data as well as word
data. It is useful to know how many pages link to a given page, and what
the quality of those pages is. This kind of analysis is similar to citation
analysis in bibliographic work and helps establish which pages are
authoritative. Algorithms such as PageRank and HITS are used to assign
a numeric measure of authority to each page. For example, the PageRank
algorithm says that the rank of a page is a function of the sum of the ranks
of the pages that link to the page. If we let PR(p) be the PageRank of page
p, Out(p) be the number of outgoing links from page p, Links(p) be the set
of pages that link to page p, and N be the total number of pages in the
index, then we can define PageRank by    PR(p)NPR(i)/Out(i)
Links(p)
rri/()
1where r is a parameter that indicates the probability that a user will choose
not to follow a link, but will instead restart at some other page. The r/Nterm means that each of the N pages is equally likely to be the restart
point, although it is also possible to use a smaller subset of well-known
pages as the restart candidates. Note that the formula for PageRank is
recursiveÑPR appears on both the right- and left-hand sides of the equa-tion. The equation can be solved by iterating several times, or by employ-
ing algorithms that compute the eigenvalues of a (4-billion-by-4-billion)
matrix.The two steps above are query independentÑthey do not depend onthe userÕs query and thus can be done before a query is issued, with thecost shared among all users. This is why a search takes a second or less,
rather than the days it would take if a search engine had to crawl the Web
anew for each query. We now consider what happens when a user types
a query.Consider the query [ÒNational AcademiesÓ computer science], where
the square brackets denote the beginning and end of the query, and theComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.176COMPUTER SCIENCE: REFLECTIONSquotation marks indicate that the enclosed words must be found as anexact phrase match. The first step in responding to this query is to look in
the index for the hit lists corresponding to each of the four words
ÒNational,Ó ÒAcademies,Ó Òcomputer,Ó and 
Òscience.Ó These four lists are
then intersected to yield the set of pages that mention all four words.
Because ÒNational AcademiesÓ was entered as a phrase, only hits where
these two words appear adjacent and in that order are counted. The result
is a list of 19,000 or so pages.The next step is ranking these 19,000 pages to decide which ones are
most relevant. In traditional information retrieval this is done by counting
the number of occurrences of each word, weighing rare words more
heavily than frequent words, and normalizing for the length of the page.
A number of refinements on this scheme have been developed, so it is
common to give more credit for pages where the words occur near each
other, where the words are in bold or large font, or in a title, or where the
words occur in the anchor text of a link that points to the page. In addition
the query-independent authority of each page is factored in. The result is
a numeric score for each page that can be used to sort them best-first. For our
four-word query, most search engines agree that the Computer Science and
Telecommunications Board home page at www7.nationalacademies.org/
cstb/ is 
the best result, although one preferred the National Academiesnews page at www.nas.edu/topnews/ and one inexplicably chose a year-
old news story that mentioned the Academies.The final step is displaying the results. Traditionally this is done by
listing a short description of each result in rank-sorted order. The descrip-
tion will include the title of the page and may include additional informa-
tion such as a short abstract or excerpt from the page. Some search engines
generate query-independent abstracts while others customize each
excerpt to show at least some of the words from the query. Displaying this
kind of query-dependent excerpt means that the search engine must keep
a copy of the full text of the pages (in addition to the index) at a cost of
several more terabytes. Some search engines attempt to cluster the result
pages into coherent categories or folders, although this technology is not
yet mature.Studies have shown that the most popular uses of computers are e-mail,word processing, and Internet searching. Of the three, Internet searching
is by far the most sophisticated example of computer science technology.
Building a high-quality search engine requires extensive knowledge and
experience in information retrieval, data structure design, user interfaces,
and distributed systems implementation.Future advances in searching will increasingly depend on statisticalnatural-language processing (see Lee in Chapter 6) and machine-learning
(see Mitchell in Chapter 6) techniques. With so much dataÑbillions ofComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.RESEARCH BEHIND EVERYDAY COMPUTATION177pages, tens of billions of links, and hundreds of millions of queries perdayÑit makes sense to use data-mining approaches to automaticallyimprove the system. For example, several search engines now do spelling
correction of user queries. It turns out that the vast amount of correctly
and incorrectly spelled text available to a search engine makes it easier to
create a good spelling corrector than traditional techniques based on dic-
tionaries. It is likely that there will be other examples of text understand-
ing that can be accomplished better with a data-oriented approach; this is
an area that search engines are just beginning to explore.Recommended ReadingChakrabarti, S., B. Dom, D. Gibson, J. Kleinberg, S.R. Kumar, P. Raghavan, S. Rajagopalan,and A. Tomkins, 1999, ÒHypersearching the Web,Ó Scientific American, June, pp. 54-60.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.1799Personal Statements of PassionAbout Computer Science Research
We close with some reflections by computer scientists on thenature of the field and the sources of their passion in their ownwork.Sussman identifies a distinctive characteristic of computer science asÒprocedural epistemologyÓÑthe representation of imperative knowledge
that allows us to treat a symbolic expression as data for purposes of
analysis and as procedure for purposes of dynamic interpretation. The
ability to represent data and procedures in symbolic form provides the
enormous power of precise expression and reasoning.Newell writing in 1976 is enchanted by the notion that computertechnology may incorporate intelligent behavior into objects. We can
create Òfrozen action to be thawed when needed,Ó and the action can be
conditional on the state of the world.We close with one of the oldest attempts among computer scientiststo define computer science. In a reprinted letter first published in 1967,
Newell, Perlis, and Simon characterize computer science broadly as thestudy of the phenomena surrounding computers.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.180COMPUTER SCIENCE: REFLECTIONSTHE LEGACY OF COMPUTER SCIENCEGerald Jay Sussman, Massachusetts Institute of TechnologyWe have witnessed and participated in great advances, in transporta-tion, in computation, in communication, and in biotechnology. But theadvances that look like giant steps to us will pale into insignificance by
contrast with the even bigger steps in the future. Sometimes I try to imag-
ine what we, the technologists of the second half of the 20th century, will
be remembered for, if anything, hundreds of years from now.In the distant past there were people who lived on the banks of theNile River. Each year the Nile overflowed its banks, wiping out land
boundaries but providing fertile soil for growing crops. As a matter of
economic necessity the Egyptians invented ways of surveying the land.
They also invented ways of measuring time, to help predict the yearly
deluge. Similar discoveries were made in many places in the world. Holders
of this practical knowledge were held in high esteem, and the knowledge
was transferred to future generations through secret cults. These early
surveyors laid the foundation for the development of geometry (Òearth
measurementÓ in Greek) by Pythagoras and Euclid and their colleagues
around 350 BC. Geometry is a precise language for talking about space. It
can be taught to children. (EuclidÕs Elements has been used in this way formore than 2000 years.) It makes the children smarter, by giving them
ways of expressing knowledge about arrangements in space and time. It
is because of these Greeks that we can tell a child, ÒIf you build it out of
triangles it will not collapse the way it does when you build it out of
rectangles.ÓThe Rhind Papyrus from Egypt (c. 1650 BC) is the earliest documentthat we have that discusses what we now think of as algebra problems.
Diophantus, another Greek, wrote a book about these ideas in the third
century A.D. Algebra was further developed by Abu Abd-Allah ibn Musa
Al-Khwarizmi (c. 780Ðc. 850) and others. (Note: ÒalgebraÓ = alÕjabr is an
Arabic word meaning Òthe recombining of broken parts.Ó) Algebra is also
a precise language that gives us the ability to express knowledge about
the relationships among quantities, and to make deductions from that
knowledge, without necessarily knowing the values of those quantities.For a long time people were able to predict the motions of some of theheavenly bodies using ad hoc theories derived from observation and
philosophical considerations. Claudius Ptolemy wrote the Almagest, afamous compendium of this knowledge, in the second century. About 350
years ago Descartes, Galileo, Newton, Leibnitz, Euler, and their contem-
poraries turned mechanics into a formal science. In the process theyComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PERSONAL PASSION ABOUT COMPUTER SCIENCE RESEARCH181invented continuous variables, coordinate geometry, and calculus. Wenow can talk about motion precisely. This achievement gives us the words
to say such sentences as, ÒWhen the car struck the tree it was going
50km/hour.Ó Now every child can understand this sentence and know

what is meant by it.In each of these cases there was an advance in human intelligence,ultimately available to ordinary children, that was precipitated by an
advance in mathematics, the precise means of expression. Such advances
are preceded by a long history of informal development of practical tech-
nique. We are now in the midst of an intellectual revolution that promises
to have as much impact on human culture as the cases I have just
described.We have been programming universal computers for about 50 years.The practice of computation arose from military, scientific, business, and
accounting applications. Just as the early Egyptian surveyors probably
thought of themselves as experts in the development and application of
surveying instruments, so have we developed a priestly cult of Òcom-
puter scientists.Ó But, as I have pointed out (H. Abelson, G.J. Sussman,
and J. Sussman, Structure and Interpretation of Computer Programs, 2ndEdition, MIT Press, Cambridge, Mass., 1996):Computer Science is not a science, and its ultimate significance haslittle to do with computers. The computer revolution is a revolution inthe way we think and in the way we express what we think. The essence
of this change is the emergence of what might best be called proceduralepistemologyÑthe study of the structure of knowledge from an impera-tive point of view, as opposed to the more declarative point of view
taken by classical mathematical subjects. Traditional mathematicsprovides a framework for dealing precisely with notions of Òwhat is.ÓComputation provides a framework for dealing precisely with notions
of Òhow to.ÓComputation provides us with new tools to express ourselves. Thishas already had an impact on the way we teach other engineering sub-jects. For example, one often hears a student or teacher complain that the
student knows the ÒtheoryÓ of the material but cannot effectively solve
problems. We should not be surprised: the student has no formal way to
learn technique. We expect the student to learn to solve problems by an
inefficient process: the student watches the teacher solve a few problems,
hoping to abstract the general procedures from the teacherÕs behavior
with particular examples. The student is never given any instructions on
how to abstract from examples, nor is the student given any language for
expressing what has been learned. It is hard to learn what one cannot
express.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.182COMPUTER SCIENCE: REFLECTIONSIn particular, in an introductory subject on electrical circuits we showstudents the mathematical descriptions of the behaviors of idealized circuitelements such as resistors, capacitors, inductors, diodes, and transistors.
We also show them the formulation of KirchoffÕs laws, which describe the
behaviors of interconnections. From these facts it is possible, in principle,
to deduce the behavior of an interconnected combination of components.
However, it is not easy to teach the techniques of circuit analysis. The
problem is that for most interesting circuits there are many equations and
the equations are quite complicated. So it takes organizational skills and
judgment to effectively formulate the useful equations and to deduce the
interesting behaviors from those equations.Traditionally, we try to communicate these skills by carefully solvingselected problems on a blackboard, explaining our reasoning and
organization. We hope that the students can learn by emulation, from our
examples. However, the process of induction of a general plan from
specific examples does not work very well, so it takes many examples and
much hard work on the part of the faculty and students to transfer the
skills.However, if I can assume that my students are literate in a computerprogramming language, then I can use programs to communicate ideas
about how to solve problems: I can write programs that describe the gen-eral technique of solving a class of problems and give that program to the
students to read. Such a program is precise and unambiguousÑit can be
executed by a dumb computer! In a nicely designed computer language a
well-written program can be read by students, who will then have a pre-
cise description of the general method to guide their understanding. With
a readable program and a few well-chosen examples it is much easier to
learn the skills. Such intellectual skills are very hard to transfer without
the medium of computer programming. Indeed, Òa computer language is
not just a way of getting a computer to perform operations but rather it is
a novel formal medium for expressing ideas about methodology. Thus
programs must be written for people to read, and only incidentally for
machines to executeÓ (Abelson et al., Structure and Interpretation of Com-puter Programs, 1996).I have used computational descriptions to communicate methodologicalideas in teaching subjects in electrical circuits and in signals and systems.
Jack Wisdom and I have written a book and are teaching a class that uses
computational techniques to communicate a deeper understanding of
classical mechanics. Our class is targeted for advanced undergraduates
and graduate students in physics and engineering. In our class computa-
tional algorithms are used to express the methods used in the analysis of
dynamical phenomena. Expressing the methods in a computer language
forces them to be unambiguous and computationally effective. StudentsComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PERSONAL PASSION ABOUT COMPUTER SCIENCE RESEARCH183are expected to read our programs and to extend them and to write newones. The task of formulating a method as a computer-executable pro-
gram and debugging that program is a powerful exercise in the learning
process. Also, once formalized procedurally, a mathematical idea becomes
a tool that can be used directly to compute results.We may think that teaching engineering and science is quite removedfrom daily culture, but this is wrong. Back in 1980 (a long time ago!) I was
walking around an exhibit of primitive personal computers at a trade
show. I passed a station where a small girl (perhaps 9 years old) was
typing furiously at a computer. While I watched, she reached over to a
man standing nearby and pulled on his sleeve and said: ÒDaddy! Daddy!
This computer is very smart. Its BASIC knows about recursive defini-
tions!Ó I am sure that her father had no idea what she was talking about.
But notice: the idea of a recursive definition was only a mathematicianÕs
dream in the 1930s. It was advanced computer science in the 1950s and
1960s. By 1980 a little girl had a deep enough operational understanding
of the idea to construct an effective test and to appreciate its significance.At this moment in history we are only at the beginning of an intellec-tual revolution based on the assimilation of computational ideas. The
previous revolutions took a long time for the consequences to actualize. It
is hard to predict where this one will lead. I see one of the deepest conse-
quences of computational thinking entering our society in the transforma-
tion of our view of ourselves. Previous revolutions have entered culture
by affecting the way we think and the way we talk: we discuss economic
phenomena in terms of Òmarket forces.Ó We talk about geopolitical devel-
opments as having Òmomentum.Ó We think it is hard to accomplish an
organizational change because of Òinertia.Ó In exactly the same way we
will find computational metaphors sneaking into our vocabulary. We
already hear ourselves describing some social interactions as Ònetwork-
ing.Ó We may ÒpingÓ a friend to see if he Òacks,Ó indicating that he is
available. But these are still rather superficial. More telling is the fact that
we can describe people and organizations as having Òbugs,Ó and that
these can be Òpatched.Ó Perhaps the most important consequence of com-
putational thinking will be in the development of an understanding of
ourselves as computational beings. Indeed, my personal experience as a
computer programmer has made me aware that many of my own prob-
lems are bugs that can be analyzed and debugged, often with great effort,
and sometimes patched.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.184COMPUTER SCIENCE: REFLECTIONSFAIRY TALESAllen Newell, Carnegie Mellon UniversityNOTE:  This essay is reproduced by permission ofAllen Newell Archives, Carnegie Mellon University,in the print (non-electronic) form of this reportand can be read there on pages 184 through 188.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PERSONAL PASSION ABOUT COMPUTER SCIENCE RESEARCH185NOTE:  See page 184.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.186COMPUTER SCIENCE: REFLECTIONSNOTE:  See page 184.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PERSONAL PASSION ABOUT COMPUTER SCIENCE RESEARCH187NOTE:  See page 184.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.188COMPUTER SCIENCE: REFLECTIONSNOTE:  See page 184.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PERSONAL PASSION ABOUT COMPUTER SCIENCE RESEARCH189REVISITING ÒWHAT IS COMPUTER SCIENCEÓAllen Newell, Carnegie Mellon UniversityNOTE:  This essay is reproduced by permission ofAllen Newell Archives, Carnegie Mellon University,in the print (non-electronic) form of this reportand can be read there on pages 189 through 192.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.190COMPUTER SCIENCE: REFLECTIONSNOTE:  See page 189.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PERSONAL PASSION ABOUT COMPUTER SCIENCE RESEARCH191NOTE:  See page 189.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.192COMPUTER SCIENCE: REFLECTIONSNOTE:  See page 189.Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.193AppendixAgenda of July 25-26, 2001, SymposiumWEDNESDAY, JULY 25, 20011:30 p.m.Opening RemarksMary Shaw, Carnegie Mellon University, and Chair, Com-mittee on the Fundamentals of Computer Science1:45 - 3:15Session 1:  Impacts of Computer Science
Edward L. Ayers, University of VirginiaÑUnderstandingthe Past as Information
Susan Landau, Sun MicrosystemsÑThe Profound Effect ofCS on the Practice and Teaching of Mathematics
Michael Lesk, National Science FoundationÑComputerScience Is to Information as Chemistry Is to Matter3:15 - 3:30Break3:30 - 4:00Guest SpeakerWilliam A. Wulf, National Academy of EngineeringÑTheEngineering and Science Fundamentals of Computer ScienceComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.194APPENDIX4:00 - 5:30Session 2:  Sampling of Hard Research Questions in
Computer ScienceSriram Rajamani, Microsoft ResearchÑSpecifying and Check-ing Properties of Programs

Lillian Lee, Cornell UniversityÑÓIÕm Sorry Dave, IÕm AfraidI CanÕt Do ThatÓ: Linguistics, Statistics, and Natural Language
Processing in 2001
Chee Yap, New York UniversityÑToward Robust GeometricComputation5:30Reception6:30 p.m.DinnerTHURSDAY, JULY 26, 20017:30 a.m.Continental Breakfast8:30 - 10:30Session 3:  CS Research:  Content and Character
Ursula Martin, University of St. AndrewsÑWhat Is Com-puter Science?ÑThe European Perspective
Neil Immerman, University of Massachusetts, AmherstÑOn the Unusual Effectiveness of Logic in Computer Science
Amy Bruckman, Georgia Institute of TechnologyÑSynergiesBetween Educational Theory and Computer Science
Gerald Sussman, Massachusetts Institute of TechnologyÑThe Legacy of Computer Science10:30 - 10:45Break10:45 - 12:00Wrap-up DiscussionÑWhat Makes Computer ScienceVital and Exciting?All-participant discussion, moderated by Jim Foley, GeorgiaInstitute of TechnologyComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PLATE 1Computer-generated water being poured into a glass.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.2COMPUTER SCIENCE: REFLECTIONSPLATE 2A ball making a splash in a tank of computer-generated water.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PLATES3PLATE 3Computer-generated smoke rolls past a sphere (a) and a computer-
generated candle flame (b).ABComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.4COMPUTER SCIENCE: REFLECTIONSPLATE 4Computer simulation of a shock wave impinging on a Helium bubble.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PLATES5PLATE 5(a) MRI data points from a ratÕs brain and (b) computer reconstruction
of the brain geometry.ABComputer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.6COMPUTER SCIENCE: REFLECTIONSPLATE 6Computer simulation of a running skeleton with biceps.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.PLATES7PLATE 7A tetrahedral muscle mesh ready for finite element simulation.
Computer Science: Reflections on the Field, Reflections from the FieldCopyright National Academy of Sciences. All rights reserved.8COMPUTER SCIENCE: REFLECTIONSPLATE 8Computer simulation of a piece of draped cloth.
