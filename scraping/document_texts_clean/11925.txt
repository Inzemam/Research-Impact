detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/11925toward a safer and more secure cyberspace328 pages | 6 x 9 | paperbackisbn 9780309103954 | doi 10.17226/11925seymour e. goodman and herbert s. lin, editors; committee on improvingcybersecurity research in the united states; computer science andtelecommunications board; division on engineering and physical sciences;national research council; national academy of engineeringtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.seymour e. goodman and herbert s. lin, editorscommittee on improving cybersecurity research in the united statescomputer science and telecommunications boarddivision on engineering and physical sciencestoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.the national academies press 500 fifth street, n.w. washington, dc 20001notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn from the councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsible for the report were chosen for their special competences and with regard for appropriate balance.support for this project was provided by the defense advanced research projects agency (award number n0017403c0074), the national science foundation (award number cns0221722), the national institute of standards and technology (contract number sb134103c0028), the department of homeland security through the national science foundation (award number cns0344585), the national academy of engineering, the national research council fund (no award number), and f. thomas leighton and bonnie berger leighton. any opinions, ndings, conclusions, or recommendations expressed in this publication are those of the author(s) and do not necessarily re˚ect the views of the organizations, agencies, or individuals that provided support for the project.back cover: summarized in the righthand column of the chart is the new mindset advocated in this report as essential to achieving a more generally secure cyberspace.library of congress cataloginginpublication datatoward a safer and more secure cyberspace / committee on improving cybersecurity research in the united states, computer science and telecommunications board, division on engineering and physical sciences, national research council of the national academies ; seymour e. goodman and herbert s. lin, editors. p. cm. includes bibliographical references. isbn 9780309103954 (pbk.)  isbn 9780309667418 (pdf) 1. computer security. 2. computer networkssecurity measures. 3. cyberterrorismprevention. i. goodman, seymour e. ii. lin, herbert. iii. national research council (u.s.). committee on improving cybersecurity research in the united states. qa76.9.a25t695 2007005.8dc22 2007037982this report is available fromcomputer science and telecommunications boardnational research council500 fifth street, n.w.washington, dc 20001additional copies of this report are available from the national academies press, 500 fifth street, n.w., lockbox 285, washington, dc 20055; (800) 6246242 or (202) 3343313 (in the washington metropolitan area); internet, http://www.nap.edu.copyright 2007 by the national academy of sciences. all rights reserved.printed in the united states of americatoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprot, selfperpetuating society of distinguished scholars engaged in scientic and engineering research, dedicated to the furtherance of science and technology and to their use for the general welfare. upon the authority of the charter granted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientic and technical matters. dr. ralph j. cicerone is president of the national academy of sciences.the national academy of engineering was established in 1964, under the charter of the national academy of sciences, as a parallel organization of outstanding engineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsors engineering programs aimed at meeting national needs, encourages education and research, and recognizes the superior achievements of engineers. dr. charles m. vest is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy of sciences to secure the services of eminent members of appropriate professions in the examination of policy matters pertaining to the health of the public. the institute acts under the responsibility given to the national academy of sciences by its congressional charter to be an adviser to the federal government and, upon its own initiative, to identify issues of medical care, research, and education. dr. harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology with the academy™s purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both the national academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientic and engineering communities. the council is administered jointly by both academies and the institute of medicine. dr. ralph j. cicerone and dr. charles m. vest are chair and vice chair, respectively, of the national research council.www.nationalacademies.orgtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.ivcommittee on improving cybersecurity research in the united statesseymour (sy) e. goodman, georgia institute of technology,  chair (from august 2006) joel s. birnbaum, hewlettpackard company, chair (until  august 2006) david aucsmith, microsoft corporationsteven m. bellovin, columbia universityanjan bose, washington state universitybarbara fraser, cisco systems, inc.james gosler, sandia national laboratorieswilliam guttman, carnegie mellon universityruby b. lee, princeton universityfernando (fred) luiz, hewlettpackard company (retired)teresa f. lunt, palo alto research centerpeter g. neumann, sri internationalstefan savage, university of california, san diegowilliam l. scherlis, carnegie mellon universityfred b. schneider, cornell universityalfred z. spector, independent consultantjohn wankmueller, mastercard internationaljay warrior, agilent laboratoriesstaffherbert s. lin, senior scientist and study director (from  september 2005)charles n. brownstein, study director (until september 2005)kristen batch, associate program ofcerjennifer m. bishop, program associate (until november 2006)janice m. sabuda, senior program assistantted schmitt, consultanttoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.vcomputer science and telecommunications boardjoseph f. traub, columbia university, chaireric benhamou, benhamou global ventures, llcfrederick r. chang, university of texas, austinwilliam dally, stanford universitymark e. dean, ibm almaden research centerdeborah estrin, university of california, los angelesjoan feigenbaum, yale universitykevin kahn, intel corporationjames kajiya, microsoft corporationmichael katz, university of california, berkeleyrandy h. katz, university of california, berkeleysara kiesler, carnegie mellon universityteresa h. meng, stanford universityprabhakar raghavan, yahoo! researchfred b. schneider, cornell universityalfred z. spector, independent consultantwilliam stead, vanderbilt universityandrew j. viterbi, viterbi group, llcpeter weinberger, google, inc.jeannette m. wing, carnegie mellon universitystaffjon eisenberg, directorkristen batch, associate program ofcerradhika chari, administrative coordinatorrenee hawkins, financial associatemargaret marsh huynh, senior program assistantherbert s. lin, senior scientistlynette i. millett, senior program ofcerdavid padgham, associate program ofcerjanice m. sabuda, senior program assistantted schmitt, consultantbrandye williams, program assistantjoan d. winston, program ofcerfor more information on cstb, see its web site at http://www.cstb.org, write to cstb, national research council, 500 fifth street, n.w.,  washington, dc 20001, call (202) 3342605, or email the cstb at cstb@nas.edu.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.viiprefacein the past several years, cybersecurity has been transformed from a concern chie˚y of computer scientists and information system managers to an issue of pressing national importance. the nation™s critical infrastructure, such as the electric power grid, air trafc control system, nancial system, and communication networks, depends extensively on information technology (it) for its operation. concerns about the vulnerability of this infrastructure have heightened in the securityconscious environment after the september 11, 2001, attacks. national policy makers have become increasingly concerned that adversaries backed by substantial resources will attempt to exploit the cybervulnerabilities in the critical infrastructure, thereby in˚icting substantial harm on the nation. today, there is an inadequate understanding of what makes it systems vulnerable to attack, how best to reduce these vulnerabilities, and how to transfer cybersecurity knowledge to actual practice. for these reasons, and in response to both legislative and executive branch interest, the national research council (nrc) established the committee on improving cybersecurity research in the united states (see appendix a for biographies of the committee members). the committee was charged with developing a strategy for cybersecurity research in the 21st century. to develop this strategy, the committee built on a number of previous nrc reports in this area, notably, computers at risk (1991), trust in cyberspace (1998), and information technology for counterterrorism (2003).1 although 1 national research council, 1991, computers at risk, national academy press, washington, d.c.; national research council, 1998, trust in cyberspace, national academy press, washington, d.c.; national research council, 2003, information technology for counterterrorism: immediate actions and future possibilities, the national academies press, washington, d.c.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.viii toward a safer and more secure cyberspacethese reports were issued some years ago, the committee found that they contained valuable points of departure for the present effort. in addition, the committee undertook a set of hearings and briengs that provided information about presentday concerns and responses to those concerns. the report of the president™s information technology advisory committee on cybersecurityšcyber security: a crisis of prioritizationšwhich lays out a research agenda and makes recommendations on how to implement it, provided a useful point of departure as well.2box p.1 contains the full charge to the committee. the committee™s survey of the current cybersecurity research landscape is described in appendix b. as requested in the charge, section b.5 contains a survey of the research effort in cybersecurity and trustworthiness to assess the current mix of topics; sections b.4 and b.6 address level of effort, division of labor, and sources of funding; section b.3 addresses quality. the issue related to the timescales of cybersecurity research is addressed in section 10.2.2. structural dimensions of a program for cybersecurity research are addressed in section 3.3.two elements in the committee™s statement of task were not fully addressed. first, although part ii provides general guidance regarding appropriate areas of programmatic focus, this report does not provide a detailed explication of research priorities within or among these areas (that is, the research areas meriting federal funding). the reason, explained at greater length in section 3.4.4, is that in the course of its deliberations, the committee concluded that the nation™s cybersecurity research agenda should be broad and that any attempt to specify research priorities in a topdown manner would be counterproductive. second, the study™s statement of task calls for it to address appropriate levels of federal funding for cybersecurity research. as discussed in section 10.2.2, the committee articulates a specic principle for determining the appropriate level of budgets for cybersecurity research: namely, that such budgets should be adequate to ensure that a large fraction of good ideas for cybersecurity research can be explored. it further notes that the threat is likely to grow at a rate faster than the present federal cybersecurity research program will enable us to respond to, and thus that in order to execute fully the broad strategy articulated in this report, a substantial increase in federal budgetary resources devoted to cybersecurity research will be needed.it is important to delineate the scope of what this report does and to 2 president™s information technology advisory committee. february 2005. cyber security: a crisis of prioritization, national coordination ofce for information technology research and development, washington, d.c.; available at www.nitrd.gov/pitac/reports/20050301cybersecurity/cybersecurity.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.preface ixspecify what it does not do. the committee recognizes that cybersecurity is only one element of trustworthiness, which can be dened as the property of a system whereby it does what is required and expected of itšdespite environmental disruption, human user and operator errors, and attacks by hostile partiesšand that it does not do other things. trustbox p.1 statement of taskthis project will involve a survey of the research effort in cybersecurity and trustworthiness to assess the current mix of topics, level of effort, division of labor, sources of funding, and quality; describe those research areas that merit federal funding, considering short, medium, and longterm emphases; and recommend the necessary level for federal funding in cybersecurity research. technologies and approaches conventionally associated with cybersecurity and trustworthiness will be examined to identify those areas most deserving of attention in the future and to understand the research baseline. in addition, this project will also seek to identify and explore models and technologies not traditionally considered to be within cybersecurity and trustworthiness in an effort to generate ideas for revolutionary advances in cybersecurity. structural alternatives for the oversight and allocation of funding (how to best allocate existing funds and how best to program new funds that may be made available) will be considered and the project committee will provide corresponding recommendations. finally, the committee will offer some guidance on the shape of grantmaking research programs.consistent with legislative language, the committee will consider:1. identication of the topics in cybersecurity research that deserve emphasis for the future. as discussed with congressional staff, this analysis will build on past work within cstb [computer science and telecommunications board] and elsewhere, which has identied many important and often enduring topics. 2. the distribution of effort among cybersecurity researchers. the emphasis will be on universities, in part to address the link between the conduct of researchers and the education and training of cybersecurity experts, to ensure that there are enough researchers to perform the needed work. comparisons between academic and industry activities will be made.3. identication and assessment of the gaps in technical capability for critical infrastructure network security, including security of industrial process controls. 4. the distribution, range, and stability of support programs among federal funding organizations. 5. issues regarding research priorities, resource requirements, and options for improving coordination and efcacy in the national pursuit of cybersecurity research. opportunities for crosssector (and intrasector) coordination and collaboration will be consideredtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.x toward a safer and more secure cyberspaceworthiness has many dimensions, including correctness, reliability, safety, and survivability, in addition to security. nevertheless, the charge of this report is to focus on security, and other issues are addressed only to the extent that they relate to security.this report is not conned to technical topics alone. a number of policy issues related to cybersecurity are discussed. these policy issues provide an overarching context for understanding why greater use has not been made of cybersecurity research to date. in addition, because the report concludes that cybersecurity research should not be undertaken entirely in a domainindependent manner, the report also discusses brie˚y a number of problem domains to which cybersecurity research is applicable. the committee assembled for this project included individuals with expertise in the various specialties within computer security and other aspects of trustworthiness, computer networks, systems architecture, software engineering, process control systems, humancomputer interaction, and information technology research and development (r&d) programs in the federal government, academia, and industry. in addition, the committee involved individuals with experience in industrial research. the committee met rst in july 2004 and four times subsequently. it held several plenary sessions to gather input from a broad range of experts in cybersecurity. particular areas of focus included thencurrent federal research activity, the state of the art in usable security, and current vendor activity related to advancing the state of cybersecurity. the committee did its work through its own expert deliberations and by soliciting input from key ofcials at sponsoring agencies, numerous experts at federal agencies, academic researchers, and hardware and software vendors (see appendix c). additional input included perspectives from professional conferences, the technical literature, and government reports studied by committee members and staff (see appendix b). the committee appreciates the support of its sponsoring agencies and especially the numerous inputs and responses to requests for information provided by jaynarayan lala and lee badger at the defense advanced research projects agency (darpa), carl landwehr and karl levitt at the national science foundation (nsf), edward roback at the national institute of standards and technology (nist), douglas maughan at the department of homeland security (dhs), and robert herklotz at the air force ofce of scientic research (afosr).personal note from the chaira large fraction of the american population now spends a great deal of time in cyberspace. we work and shop there. we are educated and entertained there. we socialize with family, friends, and strangers in cybertoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.preface xispace. we are paid and we pay others through this medium. millions of commercial enterprises and local, state, and federal government agencies do their business there. it has become a critical infrastructure in its own right, and it is embedded in almost all other critical infrastructures. we rely on cyberspace to help keep electricity ˚owing, public transportation running, and many other basic services working at levels that we have come to regard as essential elements of our society. these functions, expectations, and resulting dependencies are with us now, have been growing rapidly, and are expected to continue to grow well into the future.the people, businesses, and governments of the rest of the world are following suit. on a per capita basis, some are even more committed to this infrastructure than the united states is. the internet alone is now used by about a billion people and comes to ground in about 200 countries. and they are all connected to us and to one another.it is thus very much in the public interest to have a safe and secure cyberspace. yet cyberspace in general, and the internet in particular, are notoriously vulnerable to a frightening and expanding range of accidents and attacks by a spectrum of hackers, criminals, terrorists, and state actors who have been empowered by unprecedented access to more people and organizations than has ever been the case with any infrastructure in history. most of the people and organizations that increasingly depend on cyberspace are unaware of how vulnerable and defenseless they are, and all too many users and operators are poorly trained and equipped. many learn only after suffering attacks. these people, and the nation as a whole, are paying enormous costs for relying on such an insecure infrastructure.the committee on improving cybersecurity research in the united states was established by the national research council of the national academies with the nancial support of nsf, darpa, nist, dhs, the national academy of engineering, and f. thomas and bonnie berger leighton. the basic premise underlying the committee™s task is that research can produce a better understanding of why cyberspace is as vulnerable as it is and that it can lead to new technologies and policies and their effective implementation to make things better.cybersecurity is not a topic that is new to the national agenda. indeed, a number of earlier reports have addressed this subject from different perspectives. many of these reports have been concerned with specic threats (e.g., terrorism), missions (e.g., critical infrastructure protection), government agencies (e.g., how they might better protect themselves), or specic sectors (e.g., banking and nance). this study tackles the problem from the perspective of protecting all legitimate users of cyberspace, including the individual citizens, small commercial concerns, and government agencies that are particularly vulnerable to harassment and injury every toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.xii toward a safer and more secure cyberspacetime they use the internet or connect to other networks. the committee strongly believes that a more generally secure cyberspace would go a long way toward protecting critical infrastructure and national security.what would a safer and more secure cyberspace look like? to address this question, the committee has formulated a cyberspace bill of rights (cbor). it consists of 10 basic provisions that the committee believes users should have as reasonable expectations for their online safety and security. the cbor articulated in this report is distinctly usercentric, enabling individuals to draw for themselves the contrast between that vision and their own personal cyberspace experiences. unfortunately, the state of cyberspace today is such that it is much easier to state these provisions than it is to achieve them. no simple research project will lead to the widespread reality of any of these provisions. indeed, even achieving something that sounds as simple as eliminating spam will require a complex, crosscutting technical and nontechnical r&d agenda. accordingly, this report goes on to propose a comprehensive r&d agenda and to show how that agenda would help realize the provisions of the cbor. the report also warns that there will be no shortcuts and that realizing the cbor vision will take a long, sustained, and determined effort. there is much to accomplish.many of this report™s technical r&d recommendations build on and support those of earlier reports. however, they give particular emphasis to problems that have handicapped the more extensive practice of cybersecurity in the past. thus, the report focuses substantial attention on the very real challenges of incentives, usability, and embedding advances in cybersecurity into realworld products, practices, and services.on behalf of the committee, i would like to thank those who took the time and trouble to contribute to our deliberations by brieng the committee. this group of individuals is listed in appendix c. in addition, those who reviewed this report in draft form played a critical and indispensable role in helping to improve the report (see ﬁacknowledgment of reviewersﬂ on page xiii). on the computer science and telecommunications board (cstb), ted schmitt™s work as program ofcer on his rst nrc project was exemplary, and janice sabuda provided administrative and logistical support beyond compare. special recognition is due to herbert s. lin, who became the cstb study director about halfway through the committee™s lifetime, and who worked so hard to pull this report together. his tenacity, determination, and expertise were indispensable. seymour e. goodman, chaircommittee on improving cybersecurity research in the united statestoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.xiii acknowledgment of reviewersthis report has been reviewed in draft form by individuals chosen for their diverse perspectives and technical expertise, in accordance with procedures approved by the national research council™s report review committee. the purpose of this independent review is to provide candid and critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meets institutional standards for objectivity, evidence, and responsiveness to the study charge. the review comments and draft manuscript remain condential to protect the integrity of the deliberative process. we wish to thank the following individuals for their review of this report:eric benhamou, benhamou global ventures, llc,earl boebert, sandia national laboratories (retired),william r. cheswick, at&t research,david d. clark, massachusetts institute of technology,richard a. demillo, georgia institute of technology,samuel h. fuller, analog devices, inc.,paul a. karger, ibm thomas j. watson research center,pradeep khosla, carnegie mellon university,butler lampson, microsoft corporation,brian lopez, lawrence livermore national laboratory,william lucyshyn, university of maryland,clifford neuman, university of southern california,eugene spafford, purdue university,toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.xiv acknowledgment of reviewersphilip venables, goldman sachs, jesse walker, intel corporation, andjeannette m. wing, carnegie mellon university.although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the nal draft of the report before its release. the review of this report was overseen by lewis branscomb and brian snow. appointed by the national research council, they were responsible for making certain that an independent examination of this report was carried out in accordance with institutional procedures and that all review comments were carefully considered. responsibility for the nal content of this report rests entirely with the authoring committee and the institution.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.xvcontentsexecutive summary 1part i setting the stage1 introduction 151.1 the report in brief, 151.2 background of the study, 162 what is at stake? 192.1 interconnected information technology everywhere,  all the time, 192.2 the nature of cybersecurity vulnerabilities, 202.3 systems and networks at risk, 222.3.1 attacks on the internet, 232.3.2 attacks on embedded/realtime computing  and control systems, 252.3.3 attacks on dedicated computing facilities, 262.4 potential consequences of exploits, 272.5 the magnitude of the threat against today™s technologies, 322.6 an ominous future, 352.6.1 the evolution of the threat, 382.6.2 the broad range of capabilities and goals of cyberattackers, 42toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.xvi contents3 improving the nation™s cybersecurity posture 513.1 the cybersecurity bill of rights, 513.1.1 introduction to the cybersecurity bill of rights, 523.1.2 the provisions of the cybersecurity bill of rights, 533.1.3 concluding comments, 573.2 realizing the vision, 583.3 the necessity of research, 583.4 principles to shape the research agenda, 613.4.1 principle 1: conduct cybersecurity research as though its application will be important, 623.4.2 principle 2: hedge against uncertainty in the nature of the future threat, 693.4.3 principle 3: ensure programmatic continuity in the research agenda, 703.4.4 principle 4: respect the need for breadth in the  research agenda, 723.4.5 principle 5: disseminate new knowledge and artifacts, 74part ii an illustrative research agenda4 category 1šblocking and limiting the impact of compromise 834.1 secure design, development, and testing, 834.1.1 research to support design, 844.1.2 research to support development, 914.1.3 research to support testing and evaluation, 1034.2 graceful degradation and recovery, 1074.2.1 containment, 1074.2.2 recovery, 1094.3 software and systems assurance, 1105 category 2šenabling accountability 1135.1 attribution, 1135.2 misuse and anomaly detection systems, 1185.3 digital rights management, 1216 category 3špromoting deployment 1246.1 usable security, 1246.2 exploitation of previous work, 1316.3 cybersecurity metrics, 133toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.contents xvii6.4 the economics of cybersecurity, 1426.4.1 conflicting interests and incentives among the actors in cybersecurity, 1446.4.2 risk assessment in cybersecurity, 1476.4.3 the nature and extent of market failure (if any) in cybersecurity, 1526.4.4 changing business cases and altering the market calculus, 1536.5 security policies, 1667 category 4šdeterring wouldbe attackers and penalizing attackers 1697.1 legal issues related to cybersecurity, 1707.2 honeypots, 1717.3 forensics, 1738 category 5šillustrative crosscutting problemfocused research areas 1818.1 security for legacy systems, 1818.2 the role of secrecy in cyberdefense, 1848.3 insider threats, 1858.4 security in nontraditional computing environments  and in the context of use, 1918.4.1 health information technology, 1918.4.2 the electric power grid, 1938.4.3 web services, 1968.4.4 pervasive and embedded systems, 1978.5 secure network architectures, 1998.6 attack characterization, 2008.7 coping with denialofservice attacks, 2018.7.1  the nature of denialofservice attacks, 2018.7.2  responding to distributed denialofservice attacks, 2028.7.3 research challenges, 2058.8 dealing with spam, 2089 category 6šspeculative research 2149.1 a cyberattack research activity, 2159.2 biological approaches to security, 2169.3 using attack techniques for defensive purposes, 2189.4 cyberretaliation, 219toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.xviii contentspart iii conclusion10 looking to the future 22310.1 why has little action occurred?, 22310.2 priorities for action, 22910.2.1 item 1: create a sense of urgency about the  cybersecurity problem commensurate with the risks, 23010.2.2 item 2: commensurate with a rapidly growing cybersecurity threat, support a robust and sustained research agenda at levels which ensure that a large fraction of good ideas for cybersecurity research can be explored, 23310.2.3 item 3: establish a mechanism for continuing followup on a research agenda, 23710.2.4 item 4: support infrastructure for cybersecurity  research, 24110.2.5 item 5: sustain and grow the human resource base, 24210.3 concluding comments, 248appendixes a  committee and staff biographies 251 b  cybersecurity reports and policy: the recent past 264b.1 introduction, 264b.2 cybersecurity policy activity since 2001, 266b.3 identifying exposures, best practices, and  procedures, 269b.4 publicprivate collaboration, coordination, and cooperation, 275b.4.1 information sharing and analysis centers, 276b.4.2 alliances and partnerships, 276b.4.3 privatesector support for cybersecurity research in academia, 279b.5 notable recent efforts at identifying a research  agenda, 280toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.contents xixb.6 the current federal research and development landscape, 290b.6.1 the nature of supported activity in cybersecurity, 290b.6.2 interagency cooperation and coordination, 292b.6.3 research focus areas, 292b.6.4 agency specifics, 293c  contributors to the study 306toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.xxp.1 statement of task, ix2.1 lack of exploitation does not indicate nonvulnerability, 302.2 major sources of data characterizing the cyberthreat, 362.3 on botnets, 402.4 possible points of vulnerability in information technology systems and networks, 442.5 foreign sourcing of information technology used in the united states, 472.6 the silence of a successful cyberattack, 483.1 what firewalls and antivirus products protect against, 593.2 lessons learned from the technologytransfer effort associated with microsoft™s static driver verier, 644.1 the saltzerschroeder principles of secure system design and development, 866.1 fluency with information technology (and cybersecurity), 1266.2 bug bounties and whistleblowers, 1568.1 issues in system migration, 1838.2 secrecy of design, 1868.3 attack diffusion, 20410.1 a model categorization for understanding budgets, 240boxestoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.1executive summarybackgroundgiven the growing importance of cyberspace to nearly all aspects of national life, a secure cyberspace is vitally important to the nation, but cyberspace is far from secure today. the united states faces real risks that adversaries will exploit vulnerabilities in the nation™s critical information systems, thereby causing considerable suffering and damage. in this context and in response to a congressional request, the national research council (nrc) established the committee on improving cybersecurity research in the united states. the committee was charged with developing a strategy for cybersecurity research at the start of the 21st century. the basic premise underlying this report is that research can produce a better understanding of why cyberspace is as vulnerable as it is and that such research can lead to new technologies and policies and their effective implementation, making cyberspace safer and more secure. the report also addresses the nature of the cybersecurity threat, explores some of the reasons that previous cybersecurity research efforts and agendas have had less impact on the nation™s cybersecurity posture than desired, and considers the human resource base needed to advance the cybersecurity research agenda. society ultimately expects computer systems to be trustworthyšthat is, that they do what is required and expected of them despite environmental disruption, human user and operator errors, and attacks by hostile parties, and that they not do other things. trustworthiness has many toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.2 toward a safer and more secure cyberspacedimensions, including correctness, reliability, safety, and survivability, in addition to security. however, the scope of this report, consistent with the committee™s charge, is somewhat narrower: it focuses on security and addresses other trustworthiness issues only to the extent that they relate to security.what is at stakeinformation technology (it) is essential to the daytoday operations of companies, organizations, and government. people™s personal lives also involve computing in areas ranging from communication with family and friends to online banking and other household and nancial management activities. companies large and small are ever more reliant on it to support diverse business processes, ranging from payroll and accounting, to tracking of inventory, operation of sales, and support for research and development (r&d)šthat is, it systems are increasingly needed for companies to be able to operate at all. critical national infrastructuresšsuch as those associated with energy, banking and nance, defense, law enforcement, transportation, water systems, and governmentšand private emergency services also depend on itbased systems and networks; of course, the telecommunications system itself is a critical infrastructure for the nation.such dependence on it will grow. but in the future, computing and communications technologies will also be embedded in applications in which they are essentially invisible to their users. a future of ﬁpervasive computingﬂ will see it ubiquitously integrated into everyday objects in order to enhance their usefulness, and these objects will be interconnected in ways that further multiply their usefulness. in addition, a growing focus on innovation in the future will require the automation and integration of various services to provide rapid response tailored to the needs of users across the entire economy.the ability to fully realize the benets of it depends on these systems being securešand yet nearly all indications of the size of the threat, whether associated with losses or damage, type of attack, or presence of vulnerability, indicate a continuously worsening problem. moreover, it is almost certainly the case that reports understate the actual scope of the threat, since some successful attacks are not noticed and others noticed but not reported.the gaps between commercial practice and vulnerabilities in critical infrastructure are still wide. meanwhile, the ability of individuals, organizations, or even state actors to attack the nation™s institutions, its people™s identities, and their online lives in cyberspace has grown substantially. industry trends toward commoditization have resulted in clear targets for toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.executive summary 3focused attacks, making coordinated attacks by hundreds of thousands of coopted cooperating agents practical for the rst time in history.the potential consequences of a lack of security in cyberspace fall into three broad categories. first is the threat of catastropheša cyberattack, especially in conjunction with a physical attack, could result in thousands of deaths and many billions of dollars of damage in a very short time. second is frictional drag on important economic and securityrelated processes. today, insecurities in cyberspace systems and networks allow adversaries (in particular, criminals) to extract billions of dollars in fraud and extortionšand force businesses to expend additional resources to defend themselves against these threats. if cyberspace does not become more secure, the citizens, businesses, and governments of tomorrow will continue to face similar pressures, and most likely on a greater scale. third, concerns about insecurity may inhibit the use of it in the future and thus lead to a selfdenial of the benets that it brings, benets that will be needed for the national competitiveness of the united states as well as for national and homeland security.the broad range of capabilities and goals of cyberattackersa very broad spectrum of actors, ranging from lone hackers to major nationstates, poses security risks to the nation™s it infrastructure. organized crime (e.g., drug cartels) and transnational terrorists (and terrorist organizations, perhaps statesponsored) occupy a region in between these two extremes, but they are more similar to the nationstate than to the lone hacker.highend attackers are qualitatively different from others by virtue of their greater resourcesšmoney, talent, time, organizational support and commitment, and goals. these adversaries can thus target vulnerabilities at any point in the it supply chain from hardware fabrication to end uses. furthermore, they are usually highly capable of exploiting human or organizational weaknesses over extended periods of time. the bottom line is that the threat is growing in sophistication as well as in magnitude, and against the highend attacker, many current best practices and security technologies amount to little more than speed bumpsšthus requiring additional fundamental research and new approaches, such as a greater emphasis on mitigation and recovery.the cybersecurity bill of rightsthe committee believes that individual users, organizations, and society at large are entitled to use and rely on information technologies whose toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.4 toward a safer and more secure cyberspacefunctionality does not diminish even when they are under attack. this vision for a safe and secure cyberspace can be expressed as the committee™s cybersecurity bill of rights (cbor). following is a list of the 10 provisions in this cbor. explanations and additional discussion of each provision are presented in the main body of the report.the rst three provisions relate to properties of holistic systems, including availability, recoverability, and control of systems: i. availability of system and network resources to legitimate users. ii. easy and convenient recovery from successful attacks. iii. control over and knowledge of one™s own computing environment.the next three provisions relate to the traditional security properties of condentiality, authentication (and its extension, provenance), and authorization: iv. condentiality of stored information and information exchange.  v. authentication and provenance.  vi. the technological capability to exercise negrained control over the ˚ow of information in and through systems.the next three provisions relate to crosscutting properties of systems: vii. security in using computing directly or indirectly in important applications, including nancial, health care, and electoral transactions and realtime remote control of devices that interact with physical processes. viii. the ability to access any source of information (e.g., email, web page, le) safely. ix. awareness of what security is actually being delivered by a system or component.the last provision relates to justice: x. justice for security problems caused by another party.how are the goals of the cbor to be achieved? as the discussion in the remainder of this report indicates, a different way of thinking about cybersecurity will be necessary regarding the ways in which secure systoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.executive summary 5tems are designed, developed, procured, operated, and used. in the long run, this different way of thinking will entail new directions in education, training, development practice, operational practice, oversight, liability laws, government regulation, and so on.realizing the visioncompared with what exists today, this vision of a secure cyberspace is compelling. however, for two distinct but related reasons, the nation is a long way from meeting this goal. the rst reason is that much about cybersecurity technologies and practices is known but not put into practice. even the deployment of cybersecurity measures that are quite unsophisticated can make a difference against casual attackers. thus, the cybersecurity posture of the nation could be strengthened substantially if individuals and organizations collectively adopted current best practices and existing security technologies that are known to improve cybersecurity. the second reason is that, even assuming that everything known today was immediately put into practice, the resulting cybersecurity posturešthough it would be stronger and more resilient than it is nowšwould still be inadequate against today™s threat, let alone tomorrow™s. closing this gapša gap of knowledgešwill require both traditional and unorthodox approaches to research.traditional research is problemspecic, and there are many cybersecurity problems for which good solutions are not known. (a good solution to a cybersecurity problem is one that is effective, is robust against a variety of attack types, is inexpensive and easy to deploy, is easy to use, and does not signicantly reduce or cripple other functionality in the system of which it is made a part.) research will be needed to address these problems.but problembyproblem solutions, or even problemclass by  problemclass solutions, are highly unlikely to be sufcient to close the gap by themselves. unorthodox, cleanslate approaches will also be needed to deal with what might be called a structural problem in cybersecurity research now, and these approaches will entail the development of new ideas and new points of view that revisit the basic foundations and implicit assumptions of security research. addressing both of these reasons for the lack of security in cyberspace is important, but it is the second goalšclosing the knowledge gapšthat is the primary goal of cybersecurity research and the primary focus of this report. research is needed both to develop new knowledge and to make such knowledge more usable and transferable to the eld. furthermore, cybersecurity will be a continuing issue: threats evolve (both on their own toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.6 toward a safer and more secure cyberspaceand as defenses against them are discovered), and new vulnerabilities often emerge as innovation changes underlying system architectures, implementation, or basic assumptions. and, because there are growing incentives to compromise the security of deployed it systems, research will always be needed. personal gain, organized crime, terrorism, and national interests are superseding (and, in the eyes of many, have superseded) personal fame and curiosity as incentives.principles to drive the ongoing research agendathe committee identied several principles that should shape the cybersecurity research agenda:conduct cybersecurity research as though its application will be important. the scope of cybersecurity research must extend to understanding how cybersecurity technologies and practice can be applied in reallife contexts. consequently, fundamental research in cybersecurity will embrace organizational, sociological, economic, legal, and psychological factors as well as technological ones.hedge against uncertainty in the nature and severity of the future cybersecurity threat. it seems prudent to take a balanced approach that hedges against the eventuality that a highend cybersecurity threat emerges and becomes manifestly obvious to all. that hedge is an r&d agenda in cybersecurity that is both broader and deeper than might be required if only lowend threats were at issue. (because of the long lead time for largescale deployments of any measure, part of the research agenda must include research directed at reducing those long lead times.)ensure programmatic continuity. a sound research program should also support a substantial effort in research areas with a long time horizon for payoff. this is not to say that longterm research cannot have intermediate milestones, although such milestones should be treated as midcourse corrections rather than ﬁgo/nogoﬂ decisions that demoralize and make researchers overly conservative. longterm research should engage both academic and industrial actors, and it can involve collaboration early and often with technologytransition stakeholders, even in the basic science stages.respect the need for breadth in the research agenda. cybersecurity risks will be on the rise for the foreseeable future, but few specics about those risks can be known with high condence. thus, it is not realistic to imagine that one or even a few promising approaches will prevent or even substantially mitigate cybersecurity risks in the future, and cybersecurity research must be conducted across toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.executive summary 7a broad front. in addition, because qualitatively new attacks can appear with little warning, a broad research agenda is likely to decrease signicantly the time needed to develop countermeasures against these new attacks when they appear. priorities are still important, but they should be determined by those in a position to respond most quickly to the changing environmentšnamely, the research constituencies that provide peer review and the program managers of the various researchsupporting agencies. notions of breadth and diversity in the cybersecurity research agenda should themselves be interpreted broadly as well, and might well be integrated into other research programs such as software and systems engineering, operating systems, programming languages, networks, web applications, and so on. disseminate new knowledge and artifacts (e.g., software and hardware prototypes) to the research community. dissemination of research results beyond one™s own laboratory is necessary if those results are to have a wide impactša point that argues for cybersecurity research to be conducted on an unclassied basis as much as possible. other information to be shared as widely as possible includes threat and incident information that can help guide future research.important categories of research focusa research agenda can be laid out to make progress toward the vision embedded in the cybersecurity bill of rights. this agenda has six primary areas of focus. although these categories identify important areas of focus, they are broad in scope. this breadth re˚ects a recognition of the holistic nature of cybersecurityšattackers will attack at any technological or procedural weak point, so no single or even small number of silver bullets can ﬁsolve the cybersecurity problem.ﬂ a good cybersecurity research portfolio recognizes the importance of diversity in an uncertain threat environment, which is true even if several areas of focus warrant emphasis. 1. category 1šblocking and limiting the impact of compromise. this category includes secure information systems and networks that resist technical compromise; convenient and ubiquitous encryption that can prevent unauthorized parties from obtaining sensitive or condential data; containment, backup, mitigation, and recovery; and system lockdowns under attack.one illustrative example of research in this category is secure design, development, and testing. research is needed that will facilitate the design of systems that are ﬁsecure by design.ﬂ research is also needed for security evaluation, for good implementation practoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.8 toward a safer and more secure cyberspacetices and tools that reduce the likelihood of program ˚aws (bugs) and make it easier for developers to implement secure systems, and for improved testing and evaluation for functionality that has not been included in the specication of a system™s requirements and that may result in security vulnerabilities. 2. category 2šenabling accountability. this category includes matters such as remote authentication, access control and policy management, auditing and traceability, maintenance of provenance, secure associations between system components, intrusion detection, and so on. in general, the objective is to hold anyone or anything that has access to a system componentša computing device, a sensor, an actuator, a networkšaccountable for the results of such access.one illustrative example of research in this category is attribution. anonymous attackers cannot be held responsible for their actions and do not suffer any consequences for the harmful actions that they may initiate. but many computer operations are inherently anonymous, which means that associating actors with actions must be done explicitly. attribution technology enables such associations to be easily ascertained, captured, and preserved. at the same time, attribution mechanisms do not solve the important problem of the unwittingly compromised or duped user, although these mechanisms may be necessary in conducting forensic investigations that lead to such a user. 3. category 3špromoting deployment. this category is focused on ensuring that the technologies and procedures in categories 1 and 2 are actually used to promote and enhance security. category 3 includes technologies that facilitate ease of use by both end users and system implementers, incentives that promote the use of security technologies in the relevant contexts, and the removal of barriers that impede the use of security technologies.one illustrative example of research in this category is usable security. security functionality is often turned off, disabled, bypassed, and not deployed because it is too complex for individuals and enterprise organizations to manage effectively or to use conveniently. thus, an effort to develop more usable security mechanisms and approaches would have substantial payoff. usable security has social and organizational dimensions as well as technological and psychological ones. other illustrations are provided in the main text of this report.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.executive summary 94. category 4šdeterring wouldbe attackers and penalizing attackers. this category includes legal and policy measures that could be employed to penalize or impose consequences on cyberattackers, and technologies that support such measures. in principle, this category could also include technical measures to retaliate against a cyberattacker.one illustrative example of research in this category would facilitate the prosecution of cybercriminals across international borders. many cybercrime perpetrators are outside of u.s. jurisdiction, and the applicable laws may not criminalize the particulars of the crime perpetrated. even if they do, logistical difculties in identifying a perpetrator across national boundaries may render him or her practically immune to prosecution. research is needed to further harmonize laws across many national boundaries to enable international prosecutions and to reduce the logistical difculties involved in such activities. other illustrations are provided in the main text of the report.5. category 5šillustrative crosscutting problemfocused research areas. this category focuses elements of research in categories 1 through 4 onto specic important problems in cybersecurity. these include security for legacy systems, the role of secrecy in cyberdefense, coping with the insider threat, and security for new computing environments and in application domains.6. category 6šspeculative research. this category focuses on admittedly speculative approaches to cybersecurity that are unorthodox, ﬁoutofthebox,ﬂ and also that arguably have some potential for revolutionary and nonincremental gains in cybersecurity. the areas described in this report are merely illustrative of such ideasšof primary importance is the idea that speculative ideas are worth some investment in any broad research portfolio.why has cybersecurity action taken  to date been insufficient?the committee believes that the cybersecurity threat is ominous. moreover, as one of the most itdependent nations in the world, the united states has much to lose from the materialization of this threat. but this committee is not the rst committeešand this report is not the rst reportšto make this claim. after more than 15 years of reports pointing to an ominous threat, and in fact more than 15 years in which the threat has objectively grown, why is there not a national sense of urgency about toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.10 toward a safer and more secure cyberspacecybersecurity? why has action not been taken to close the gap between the nation™s cybersecurity posture and the cyberthreat?the notion that no action to promote cybersecurity has been taken in the past 15 years is somewhat unfair. in recent years, most major it vendors have undertaken signicant efforts to improve the security of their products in response to enduser concerns over security, and many of today™s products are by many measures more secure than those that preceded these efforts. in addition, the sentinel events of september 11, 2001, spurred public concerns about security, and some of that concern has spilled over into the cybersecurity domain.nevertheless, these changes in the environment, important though they are, do not change the fact that the degree of awareness and action taken in the past 15 years is nowhere near what is necessary to achieve a robust cybersecurity posture.the committee believes that the lack of adequate action in the cybersecurity space can be largely explained by three factors: past reports have not provided the sufciently compelling information needed to make the case for dramatic and urgent action. if so, perhaps it is possible to paint a sufciently ominous picture of the threat in terms that would inspire decision makers to take action. detailed and specic information is usually more convincing than information couched in very general terms, but unfortunately, detailed and specic information in the open literature about the scope and nature of the cyberthreat is lacking. many corporate victims of cyberattack, for example, are reluctant to identify themselves as being victims for fear of being cast in a bad light relative to their competitors. even with the relevant information in hand, decision makers discount future possibilities so much that they do not see the need for presentday action. that being the case, nothing short of a highly visible and perhaps ongoing cyberdisaster will motivate actions. decision makers weigh the immediate costs of putting into place adequate cybersecurity measures, both technical and procedural, against the potential future benets (actually, avoided costs) of preventing cyberdisaster in the futurešand systematically discount the latter as uncertain and vague. the costs of inaction are not borne by the relevant decision makers. the bulk of the nation™s critical infrastructure is owned and operated by privatesector companies. to the extent that these companies respond to security issues, they generally do so as one of the risks of doing business. but they do much less to respond to the toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.executive summary 11threat of lowprobability, highimpact (i.e., catastrophic) threats, although all of society at large has a large stake in their actions. the rst factor above suggests the necessity of undertaking a truly authoritative assessment of the cybersecurity threat that draws on the best industry and intelligence data available and that is made public for all to see. the second and third factors suggest that the cybersecurity problem results not from a failure to recognize the threat but from a failure to respond sufciently to it. (in other words, awareness is not enoughšthere are potential solutions that have not been deployed widely and many problems for which practical solutions are not known today.) these factors suggest the need for putting into place mechanisms that change the calculus used to make decisions about cybersecurity. as for the impact of research on the nation™s cybersecurity posture, it is not reasonable to expect that research alone will make any substantial difference at all. indeed, there is a very large gap between a successful ﬁin principleﬂ result or demonstration and its widespread deployment and use; closing this gap is the focus of research in category 3špromoting deployment, above. but many other factors must also be aligned if research is to have a signicant impact. specically, it vendors must be willing to regard security as a product attribute that is coequal with performance and cost; it researchers must be willing to value cybersecurity research as much as they value research into highperformance or costeffective computing; and it purchasers must be willing to incur presentday costs in order to obtain future benets.priorities for action todaythe committee has identied the following ve action items for policy makers as warranting the highest priority:ł create a sense of urgency about the cybersecurity problem. one element will be to provide as much information as possible about the scope and nature of the threat. a second element will be to change the decisionmaking calculus that excessively focuses vendor and enduser attention on shortterm costs of improving their cybersecurity postures.commensurate with a rapidly growing cybersecurity threat, support a broad, robust, and sustained research agenda at levels which ensure that a large fraction of good ideas for cybersecurity research can be explored. discretionary budgets for the foreseeable future will be very tight, but even in such times, program growth is possible if the political will is present to designate these directions as priorities. both the toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.12 toward a safer and more secure cyberspacescope and scale of federally funded cybersecurity research are seriously inadequate. to execute fully the broad strategy articulated in this report, a substantial increase in federal budgetary resources devoted to cybersecurity research will be needed. nor should cybersecurity research remain in the computer science domain alone, and additional funding might well be used to support the pursuit of cybersecurity considerations in other closely related research endeavors, such as those related to creating highassurance systems and the engineering of secure systems and software across entire system life cycles.establish a mechanism for continuing followup on a research agenda. today, the scope and nature of cybersecurity research across the federal government are not well understood, least of all by government decision makers. an important rst step would be for the government to build on the efforts of the national coordination ofce for networking and information technology research and development to develop a reasonably complete picture of the cybersecurity research efforts that the government supports from year to year. to the best of the committee™s knowledge, no such coordinated picture exists.support research infrastructure. making progress on any cybersecurity research agenda requires substantial attention to infrastructural issues. in this context, a cybersecurity research infrastructure refers to the collection of open testbeds, tools, data sets, and other things that enable research to progress and which allow research results to be implemented in actual it products and services. without an adequate research infrastructure, there is little hope for realizing the full potential of any research agenda.sustain and grow the human resource base. when new ideas are needed, human capital is particularly important. for the pool of cybersecurity researchers to expand to a sufciently large level, wouldbe researchers must believe that there is a future to working in this eld, a point suggesting the importance of adequate and stable research support for the eld. increasing the number of researchers in a eld necessarily entails increased support for that eld, since no amount of prioritization within a xed budget will result in signicantly more researchers. in addition, potential graduate students see stable or growing levels of funding as a signal about the importance of the eld and the potential for professional advancement.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.13part isetting the stagepart i of this report consists of three chapters. chapter 1, ﬁintroduction,ﬂ provides a brief overview of the report and describes how this study came into being.chapter 2, ﬁwhat is at stake?,ﬂ describes what is at stake in realizing (or failing to realize) a more secure cyberspace. specically, it notes today™s dependence on computing and communications technologies for myriad applications, and it projects a future of ﬁpervasive computingﬂ in which information technology will be ubiquitously integrated into everyday objects in order to enhance their usefulness and in which these ﬁsmart objectsﬂ will be interconnected in ways that further multiply their usefulness. in this context, the chapter addresses the nature of cybersecurity vulnerabilities, explores some of their consequences, and characterizes various parties that pose a threat to cybersecurity.chapter 3, ﬁimproving the nation™s cybersecurity posture,ﬂ characterizes the vision of the national research council™s committee on improving cybersecurity research in the united statesšembodied in the cybersecurity bill of rightsšof what a more secure cyberspace would look like, and it underscores the key role that research will necessarily play in achieving such a vision. most importantly, chapter 3 lays out a set of principles driving an ongoing research agenda.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.151.1 the report in briefgiven the growing importance of cyberspace to nearly all aspects of national life, a secure cyberspace is vitally important to the nation, but cyberspace is far from secure today. the united states faces real risks that adversaries will exploit vulnerabilities in the nation™s critical information systems. the basic premise underlying this report is that research can produce a better understanding of why cyberspace is as vulnerable as it is, and that such research can lead to new technologies and policies and their effective implementation to make cyberspace safer and more secure.cybersecurity is not a topic new to the national agenda. but previous efforts to examine cybersecurity have addressed the subject from the standpoint of dealing with specic threats (e.g., terrorism), missions (e.g., critical infrastructure protection), government agencies (e.g., how they might better protect themselves), or specic sectors (e.g., banking and nance). this report focuses on the value of addressing cybersecurity from the perspective of protecting all legitimate users of cyberspace, including individual citizens and small commercial establishments and government agencies, which are particularly vulnerable to harassment and injury every time they log on to the internet or use some other commercial network. the committee on improving cybersecurity research in the united states believes that a more generally secure cyberspace will go a long way toward protecting critical infrastructure and national security.1 introductiontoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.16 toward a safer and more secure cyberspacethe committee™s vision for a safer and more secure cyberspace is re˚ected in a ﬁcybersecurity bill of rightsﬂ (cbor), consisting of 10 basic provisions that users should have as reasonable expectations for their safety and security in cyberspace. the cbor articulated in this report is usercentric, enabling individuals to draw for themselves the contrast between the vision contained in the cbor and their own personal cyberspace experiences. unfortunately, the state of cyberspace today is such that it is much easier to state these provisions than it is to achieve them. no simple research project, no silver bullet, no specic critical cybersecurity research topic will lead to the widespread reality of any of these provisions. indeed, even achieving something that sounds as simple as eliminating spam will require a complex, crosscutting technical and nontechnical research and development (r&d) agenda. the committee™s proposal for action focuses attention on a number of research areas identied as important in earlier reports (appen dix b, section b.5). it also focuses on understanding why important and helpful cybersecurity innovations developed in the past have not been more widely deployed in today™s information technology (it) products and services, thus bringing the very real challenges of incentives, usability, and embedding advances in cybersecurity squarely into the research domain.the committee™s action agenda for policy makers has ve elements. the rst is to create a sense of urgency about the cybersecurity problem, as the cybersecurity policy failure is not so much one of awareness as of action. the second, commensurate with a rapidly growing cybersecurity threat, is to support a broad, robust, and sustained research agenda at levels which ensure that a large fraction of good ideas for cybersecurity research can be explored. the third is to establish a mechanism for continuing followup on a research agenda that will provide a coordinated picture of the government™s cybersecurity research activities across the entire federal government, including both classied and unclassied research. the fourth is to support research infrastructure, recognizing that such infrastructure is a critical enabler for allowing research results to be implemented in actual it products and services. the fth is to sustain and grow the human resource base, which will be a critical element in ensuring a robust research agenda in the future.1.2 background of the studypolicy makers, and to a lesser extent, the public, have given attention to cybersecurity issues for some time now, but cybersecurity problems have continued to fester. for example, in 1997, the president™s commission on critical infrastructure protection noted the importance of toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.introduction 17cybersecurity for the systems that operate the nation™s critical infrastructure, such as the electric power grid and the air trafc control system as well as the communications and processing backbones that are increasingly essential to the operation of the entire economy, including distribution, nance, and manufacturing. in the wake of the attacks of september 11, 2001, there is a rising concern that adversaries, backed by substantial resources, will attempt to exploit the vulnerabilities in the information systems of the nation, both private and public. it is a long way between knowing that there are vulnerabilities and xing them. first and foremost, the will to x them must be presentša will that has been all too often absent in the committee™s judgment. presuming the will to do so, more and better application of existing knowledge and cybersecurity technologies and practices to information system vulnerabilities would help to mitigate many of them. in some cases, such application is straightforward. in other cases, the understanding of the vulnerabilities or of how to deal with them is incomplete or inadequate. and in still other cases, as with cybersecurity in the power grid and in health care, the specic applications context frames how such existing knowledge can be helpful, even when that knowledge is very relevant. against this backdrop, the national research council established the committee on improving cybersecurity research in the united states, charged with developing a coherent strategy for cybersecurity research at the start of the 21st century. the committee™s strategy is laid out in this report. to frame this strategy in an appropriate context, this report also considers the nature of the cybersecurity threat, reasons why previous cybersecurity research efforts and agendas have had less impact than hoped for on the nation™s cybersecurity posture, and the human resource base needed to advance the cybersecurity research agenda. to put this report into context, it is helpful to consider the ndings and conclusions from a number of other reports and activities on cybersecurity from the past several years. described in greater detail in appen dix b, these reports and activities have made a number of points that will be reprised in this report. the following are key conclusions that can be drawn from past studies.first, there are no silver bullets for ﬁxingﬂ cybersecurity. the threats are evolving and will continue to grow, meaning that gaining ground requires a broad and ongoing societywide effort that focuses on cybersecurity vulnerabilities. a culture of security must pervade the entire life cycle of it systems operations, from initial architecture, to design, development, testing, deployment, maintenance, and use. a number of focus areas are particularly important to achieving such a culture: collaboration among researchers; effective coordination and information sharing between the public and private sector; the creation of a sufcient toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.18 toward a safer and more secure cyberspacecore of research specialists necessary to advance the state of the art; the broadbased education of developers, administrators, and users, making securityconscious practices second nature just as optimizing for performance or functionality is; making it easy and intuitive for users to ﬁdo the right thingﬂ; the employment of business drivers and policy mechanisms to facilitate security technology transfer and diffusion of r&d into commercial products and services; and the promotion of riskbased decision making (and metrics to support this effort). second, the earlier reports have identied as meriting research investment a number of important areas that are consistent with those identied in this report, including authentication, identity management, secure software engineering, modeling and testbeds, usability, privacy, and benchmarking and best practices. understanding the intersection between critical infrastructure systems and the it systems increasingly used to control them is another common theme for research needs. third, taken together the activities reviewed give an overall sense thatšunless we as a society make cybersecurity a priorityšit systems are likely to become overwhelmed by cyberthreats of all kinds and eventually to be limited in their ability to serve society. this future is avoidable, but precluding it requires the effective coordination and collaboration of private and public sector; continuous, comprehensive, and coordinated research; and appropriate policies to promote security and deter attackers.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.192.1 interconnected information technology everywhere, all the timefor many people today, the information revolution is represented by the most visible and salient interactions they have with information technology (it)štyping at the keyboard of their computers at work or at home or talking on their cellular telephones. people™s personal lives also involve computing through social networking, home management, communication with family and friends, and management of personal affairs. but a much larger collection of information technology embodied in computing, software, and networking deployments is instrumental to the daytoday operations of companies, organizations, and government. companies large and small rely on computers for diverse business processes, ranging from payroll and accounting to the tracking of inventory and sales, to support for research and development (r&d). the distribution of food and energy from producer to retail consumer relies on computers and networks at every stage. nearly everyone (in everyday society, business, government, and the military services) relies on wireless and wired communications systems. information technology is used to execute the principal business processes both in government and in many of the largest sectors of the economy, including nancial services, health care, utilities, transportation, and services. indeed, the architecture of today™s enterprise it systems is the very embodiment of the critical business logic in complex enterprises. it is impossible to imagine the walmarts, the fedexes, and the amazons of today without information 2 what is at stake?toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.20 toward a safer and more secure cyberspacetechnology. in short, many computing and communications systems are themselves infrastructure and serve as components of the infrastructure of other organizations.in the future, computing and communications technologies (collectively, information technologies) are likely to be found in places where they are essentially invisible to everyday view: in cars, wallets, clothing, refrigerators, keys, cabinets, watches, doorbells, medicine bottles, walls, paint, structural beams, roads, dishwashers, identication (id) cards, telephones, and medical devices (including some embedded in human beings). computing will be embedded in myriad places and things or will be easily transported in pockets or on wrists. computing devices will be coupled to multiple sensors and effectors. computing and communications will be seamless, enabling the tight integration of personal, family, and business systems. sensors, effectors, and computing will be networked together so that they pass relevant information to one another automatically.in this vision of truly pervasive computing, the ubiquitous integration of computing and communications technologies into common everyday objects enhances their usefulness and makes life easier and more convenient. understanding context, personal information appliances will make appropriate information available on demand, enabling users to be more productive in both their personal and professional lives. and, as has been true with today™s desktops and mainframes, interconnections among all of these nowsmart objects and appliances will multiply their usefulness many times over.2.2 the nature of cybersecurity vulnerabilitiesa security vulnerability in an it artifact (e.g., a part, hardware component, software module, data structure, system, and so on) exists if there is a way to manipulate the artifact to cause it to act in a way that results in a loss of condentiality, integrity, and availability.condentiality. a secure system will keep protected information away from those who should not have access to it. examples of failures that affect condentiality include the interception of a wireless signal and identity theft. integrity. a secure system produces the same results or information whether or not the system has been attacked. when integrity is violated, the system may continue to operate, but under some circumstances of operation, it does not provide accurate results or information that one would normally expect. the alteration of data toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 21in a database or in a sensor data stream or an instruction stream to a mechanical effector, for example, could have this effect.  availability. a secure system is available for normal use even in the face of an attack. a failure of availability may mean that the email does not go through, or the computer simply freezes, or response time becomes intolerably long (possibly leading to catastrophe if a physical process is being controlled by the system).these types of damage may be in˚icted without the victim even being aware of the attack. for example, a system may be compromised by the obtaining of information ostensibly protected by that system (e.g., encrypted information may be intercepted and decrypted without the owner realizing it). or, an attack may be used to support a selective denial of services (i.e., the allowing of access for most connections, but denying or corrupting some particular critical connections). if improper alteration occurs in small amounts in large, seldomreferenced databases, the fact of such corruption may never be discovered.note also the impact of any such damage on the user™s psychology. a single database that is found to be corrupted, even when controls are in place to prevent such corruption, may throw into question the integrity of all of the databases in a system. a single data stream that is compromised by an eavesdropper may lead system operators and those who depend on the system to be concerned that all data streams are potentially compromised. in such cases, the potential harm from any of these incidents goes far beyond the actual corrupted database or compromised data stream, since enormous amounts of effort need to be made to ensure that other databases or data streams have not been corrupted or compromised. those other databases may be perfectly good, but may not be considered reliable under such circumstances.denial of service, corruption, and compromise are not independentšfor example, an attacker could render a system unavailable by compromising it. an attacker could seek to in˚ict such damage in several  ways.  an attack can be remotešone that comes in ﬁthrough the wires,ﬂ for example, as a virus or a trojan horse program introduced via email or other communication or as a denialofservice attack over a network connection. as a general rule, remote attacks are much less expensive, much less risky, and much easier to conduct than are the second and third types listed below.  some it element may be physically destroyed (e.g., a critical data center or communications link could be blown up) or compromised (e.g., it hardware could be surreptitiously modied in the toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.22 toward a safer and more secure cyberspacedistribution chain). such attacks generally require close access (i.e., requiring physical proximity).  a trusted insider may be compromised or may be untrustworthy in the rst place (such a person, for instance, may sell passwords that permit outsiders to gain entry); such insiders may also be conduits for hostile software or hardware modications that can be inserted at any point in the supply chain, from initial fabrication, to delivery to the end user. compromising a trusted insider can be accomplished remotely or locally. not all compromises are the result of insider malice; phishing attacks are one example of how a trusted insider can be tricked into providing sensitive information.of course, these three ways of causing damage are not mutually exclusive, and in practice they can be combined to produce even more destructive effects than any one way alone. additionally, attackers can easily ﬁprepositionﬂ vulnerabilities to facilitate the timing of later attacks. this prepositioning could be in the form of trap doors left behind from previous virus infections, unintentional design vulnerabilities,1 or compromised code left by a compromised staff member or by a breakin to the developer™s site.22.3 systems and networks at riskwhat it systems and networks are at risk? key elements of information technology fall into three major categories: the internet; embedded/realtime computing (e.g., avionics systems for aircraft control; air trafc control; supervisory control and data acquisition [scada] systems controlling the distribution of electricity, gas, and water; the switching systems of the conventional telecommunications infrastructure; bank teller machine networks; ˚oodgates); and dedicated computing devices (e.g., desktop computers). each of these elements plays a different role in national life, and each is subject to different kinds of attack. 1 an example is the recent episode during which sony™s bmg music entertainment surreptitiously distributed software on audio compact discs (cds) that was automatically installed on any computers that played the cds. this software was intended to block the copying of the cd, but it had the unintentional side effect of opening security vulnerabilities that could be exploited by other malicious software such as worms or viruses. see iain thomson and tom sanders, ﬁvirus writers exploit sony drm,ﬂ vnunet.com, november 10, 2005; available at http://www.vnunet.com/vnunet/news/2145874/viruswritersexploitsonydrm.2 p.a. karger and r.r. schell, multics security evaluation: vulnerability analysis, esdtr74193, vol. ii, june 1974, hq electronic systems division, hanscom air force base; available at http://csrc.nist.gov/publications/history/karg74.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 232.3.1 attacks on the internetthe infrastructure of the internet is a possible target, and given the internet™s public prominence and ubiquity, it may appeal to terrorists or criminals as an attractive target. the internet can be attacked in two (not mutually exclusive) waysšphysically or ﬁthrough the wires.ﬂphysical attacks might destroy one or a few parts of the internet in frastructure. but the internet is a densely connected network of networks that automatically routes around portions that become unavailable,3 which means that a large number of important nodes would have to be destroyed simultaneously to bring it down for an extended period of time. destruction of some key internet nodes could result in reduced network capacity and slow trafc across the internet, but the ease with which internet communications can be rerouted would minimize the longterm damage.4an attack that comes through the wires rather than via physical attack can have much higher leverage. the internet crosses borders and its reach is extended throughout the globe. but the global internet was not designed to operate in a hostile environment where information systems and networks can be attacked from inside. indeed, it is an unfortunate result of internet history that the protocols used by the internet today are derived from the protocols that were developed in the early days of the advanced research projects agency network, where there were only a few wellrespected researchers using the infrastructure, and they were trusted to do no harm. consequently, security considerations were not built in to the internet, which means that all cybersecurity measures taken today to protect the internet are addon measures that do not remedy the underlying security deciencies.one type of attack is directed against internet operations. such attacks are often based on selfreplicating programs (worms and viruses) that are transmitted from system to system, consuming prodigious amounts of router processing time and network channel bandwidth. in recent years, some of these worms and viruses have been transmitted without explicitly destructive payloads and yet have been able to disrupt key internet backbone subnetworks for several days. another kind of attack on inter3 national research council. 2001. the internet™s coming of age. national academy press, washington, d.c. note, however, that the amount of redundancy is limited primarily by economic factors.4 this comment applies largely to u.s. use of the internet. it is entirely possible that other nationsšwhose trafc is often physically routed through one or two locations in the united statesšwould fare much worse in this scenario. see national research council. 2003. the internet under crisis conditions: learning from september 11. the national academies press, washington, d.c.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.24 toward a safer and more secure cyberspacenet operations seeks to corrupt the routing tables that determine how a packet should travel through the internet. in both cases, the intent of the attack is to reduce the normally expected functionality of the internet for some signicant portion of its usersšthat is, it is a denialofservice attack in intent, although not one necessarily based on ˚ooding trafc.an attacker might also target the internet™s domain name system (dns), which translates domain names (e.g., ﬁexample.comﬂ) to specic internet protocol (ip) addresses (e.g., 123.231.0.67) denoting specic internet nodes. a relatively small number of ﬁroot name serversﬂ underpins the dns. although the dns is designed to provide redundancy in case of accidental failure, it has some vulnerability to an attack that might target all name servers simultaneously. although internet operations would not halt instantly, an increasing number of sites would, over a period of time measured in hours to days, become inaccessible without root name servers to provide authoritative translation information. physical replacement of damaged servers would be achievable in a matter of days, but changing the ip addresses of the root name servers and promulgating the new ip addresses throughout the internetša likely necessary step if the name servers are being attacked repetitively in an automated fashionšwould be much more problematic.5a throughthewires attack is possible because of internetenabled interconnection. thus, a hostile party using an internetconnected computer 10,000 miles away can launch an attack against an internet connected computer in the united states just as easily as if the attacker were next door. criminals and adversaries located all over the globe may nonetheless communicate and partly coordinate their activities through the network, without ever having to meet or cross national boundaries, especially in countries were they can operate without a serious fear  of surveillance or aided by insider accomplices. by contrast, the planet is a world of sovereign nationstates, with different laws and regula tions governing computer activitiesša point that makes traditional responses of military retaliation or criminal prosecution much more problematic.dependence on the internet for the performance of core business functions is increasingly a fact of life for a growing number of businesses and government agencies, as well as citizens in private life. it is obvious that a disruption to the internet would be a major disruption to an electronic commerce company such as amazon.com. but what is less obvious is that in the last couple of years, many large companies have come to depend on the internet and other networks running internet protocols 5 national research council. 2005. signposts in cyberspace: the domain name system and internet navigation. the national academies press, washington, d.c.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 25for internal voice and data communications and other key functionsšand these trends will only accelerate in the future as pressures for cost reduction grow. a good example is the fact that voiceoverip (voip) connections are increasingly replacing conventional telephony. thus, it is only a matter of a relatively short time before today™s independence of voice communications from the internet no longer exists to any signicant degreešand this will be true for business, government, and the general civilian population.finally, it is an unfortunate fact of life today that in many cases, when a system or a network connected to the internet is under attack, the only feasible protective action is to disconnect from the internet. such an action may eliminate the attack (unless a rogue program has been successfully inserted into the targeted system or network before the connection is cut), but it also renders the attack maximally successful in a certain sense, since now for all practical purposes the disconnected system or network does not exist on the internet.2.3.2 attacks on embedded/realtime  computing and control systemsembedded/realtime computing in specic systems could also be attacked. for example, many embedded computing systems could be corrupted over time or be deployed with hidden vulnerabilities.6 of particular concern could be avionics in airplanes, collisionavoidance systems in automobiles, and other transportation systems. such attacks would require a signicant insider presence in technically responsible positions in key sectors of the economy, likely but not necessarily over long periods of time. another example is that sensors, which can be important elements of counterterrorism or anticrime precautions, could be the target of an attack or, more likely, precursor targets of a terrorist or criminal attack.another possible attack on embedded/realtime computing would be an attack on the systems controlling elements of the nation™s critical infrastructurešfor example, the electric power grid, the air trafc control system, the railroad infrastructure, water purication and delivery, or telephony. for example, attacks on the systems and networks that control and manage elements of the nation™s transportation infrastructure could introduce chaos and disruption on a large scale that could drastically reduce the capability of transporting people and/or freight (including food and fuel).6 an inadvertent demonstration of this possibility was illustrated with the year2000 (y2k) problem that was overlooked in many embedded/realtime systems designed in the 1980s and earlier.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.26 toward a safer and more secure cyberspaceto illustrate, electric generation plants are controlled by a variety of itbased scada systems. attacks on these scada systems could obviously result in local disruptions in the supply of electrical power. but two other scenarios are more problematic. the electric power distribution grid, also controlled by itbased scada systems and being necessary for electric power generated in one location to be useful in another location hundreds of miles away, is also a conduit through which a failure in one location can cascade to catastrophic proportions before the local failure can be dealt with.7 (in this context, the distribution grid includes both the transmission lines that carry electricity and their control channels.) in addition, because scada systems are used to control physical elements of the grid, attacks on scada systems can also result in irreversible physical damage to unique equipment that may require many months to replace. although causing such consequences requires inside or expert knowledge rather than just random attacks, the consequences are severe in terms of economic damage to the country.similar concerns arise with conventional telecommunications and the nancial system (including the federal reserve banking system, which is a system for handling largevalue nancial transactions, and a second system for handling smallvalue retail transactions [including the automated clearing house, the creditcard system, and paper checks]). although these systems are also largely independent of the public internet, they are utterly dependent on computers, and thus they are subject to a variety of security vulnerabilities that do not depend on internet connectivity.2.3.3 attacks on dedicated computing facilitiesin many of the same ways that embedded computing could be attacked, dedicated computers such as desktop computers could also be corrupted in ways that are hard to detect. one possible channel comes from the use of untrustworthy it talent by software vendors.8 the con7 for example, the cause of the blackout of august 2003šlasting 4 days and affecting 50 million people in large portions of the midwestern and northeastern united states and ontario, canadašwas traced to a sequence of cascading failures initiated by the shutdown of a single 345 kv transmission line. admittedly, the grid was in a stressed state in northeastern ohio when this occurred, but the grid often faces such stress during heat waves and storms. see u.s.canada power system outage task force, final report on the august 14, 2003 blackout in the united states and canada: causes and recommendations, april 2004; available at https://reports.energy.gov/blackoutfinalweb.pdf. 8 although security concerns are often raised about the offshoring of it development, untrustworthy talent may be foreign or domestic in origin. foreign it workersšwhether working in the united states (e.g., under an h1b visa or a green card) or offshore on outsourced workšare generally not subject to thorough background investigations; therefore, an obvious route is available through which foreign terrorist organizations can gain insider toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 27cern is that once working on the inside, these individuals would be able to introduce additional but unauthorized functionality into systems that are widely used. under such circumstances, the target might not be just any desktop computer (e.g., any computer used in the ofces around the country) but rather the desktop computers in particular sensitive ofces or in critical operational software used in corporate or government computer centers (e.g., a major bank or the classied and unclassied systems of the department of defense). another possible channel for attacking dedicated computing facilities results from the connection of computers through the internet; such connections provide a potential route through which terrorists or criminal organizations might attack computer systems that do provide important functionality for many sectors of the economy. examples of widely used internetbased vectors that, if compromised, would have a largescale effect in a short time include appealing web pages and certain shareware programs, such as those for sharing music les. an appealing web page might attract many viewers in a short period of time, and viewers could be compromised simply by viewing the page. shareware programs might contain viruses or other ﬁmalware.ﬂ in principle, channels for distributing operating systems upgrades could be corrupted as well, but because of their critical nature, these channels are in general much more resistant to security compromise. it is likely that internetconnected computer systems that provide critical functionality to companies and organizations are better protected through rewalls and other security measures than is the average system on the internet. nevertheless, as press reports in recent years make clear, such measures do not guarantee that these large systems are immune to the hostile actions of outsiders.9 2.4 potential consequences of exploitsthe possible consequences of successful exploits of cyber vulnerabilities cover a broad spectrum, from causing annoyance to an individual to causing catastrophic consequences for society. it is, of course, possible that the existence of a vulnerabilityševen if widespreadšwill not lead to access. reports of american citizens having been successfully recruited by foreign terrorist organizations add a degree of believability to the scenario of domestic it talent™s being used to compromise systems for terrorist purposes.9 for example, the slammer worm attack reportedly resulted in a severe degradation of the bank of america™s automatic teller machine network in january 2003. see aaron davis, ﬁcomputer worm snarls web: electronic attack also affects phone service, bofa™s atm network,ﬂ san jose mercury news, january 26, 2003; available at http://www.bayarea.com/mld/mercurynews/5034748.htm+atm+slammer+virus&hl=en.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.28 toward a safer and more secure cyberspacedisaster (see box 2.1), but making this possibility the basis for an effective cybersecurity response is clearly not a sensible thing to do today.if a virus attacks a home computer and erases all of the les on it, the consequences range from mere annoyance to emotional trauma (e.g., if irreplaceable pictures were stored). if the user had made a recent backup, the hassle factor involved in recovering the les may be only a matter of an hour or twošthough removing the virus may be more involved than that. if the ﬁhomeﬂ computer involved belongs to a small business, critical business records could be lost.if a cybersecurity breach enables a hostile party to impersonate an individual, the result may be highly problematic for the individual. victims of identity theft suffer for years under a cloud of uncertainty about their nances and credit records even as they try to clear their records.10 no one dies because someone has impersonated him or her, although the compromise of personal information such as home addresses can certainly lead to serious harm.11 if the identities of many individuals are compromised and identity theft results, serious economic losses to nancial institutions may occur.12if consumers are not condent of online security, they will be more reluctant to engage in online activities and electronic commerce. for example, the gartner group estimated that $1.9 billion in ecommerce sales would not occur in 2006 because of consumer concerns about the security of the internet.13if a company™s trade secrets or condential business plans are compromised, its viability as a business entity may be placed at risk (most likely if it is a small company) or its competitiveness in the 10 the term ﬁidentity,ﬂ as used in ﬁidentity theft,ﬂ is somewhat misleading in this context. some observers point out that in a deep philosophical sense, an individual™s identity is inextricably associated with that individual. they thus suggest that a more precise term may be ﬁcredential theftﬂ or ﬁtheft of personal information,ﬂ either of which allows the possessor of the credential or personal information to impersonate the individual to whom that credential refers or with whom that personal information is associated. however, customary usage refers to ﬁidentity theft,ﬂ and in the interests of clarity for the reader, this report continues that usage. 11 in 1989, actress rebecca schaeffer was stalked and murdered by a fan who allegedly retrieved her name and address from the california motor vehicle department. her death inspired the passage of the federal driver™s privacy protection act of 1994, 18 u.s.c. 2721.12 gartner press release, ﬁgartner says number of phishing emails sent to u.s. adults nearly doubles in just two years,ﬂ november 9, 2006; available at http://www.gartner.com/it/page.jsp?id=498245.13 gartner press release, ﬁgartner says nearly $2 billion lost in ecommerce sales in 2006 due to security concerns of u.s. adults,ﬂ november 27, 2006; available at http://www.gartner.com/it/page.jsp?id=498974.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 29marketplace reduced. millions of dollars might be lost, but people rarely die from the theft of trade secrets.if the ˚ybywire controls of a modern passenger airplane are compromised, the pilot might lose control and be unable to land safely. hundreds of lives aboard the plane may be placed at risk.if the computer systems controlling the operation of a railroad are compromised, extensive physical damage may be caused in train crashes.if electronic medical records are compromised by the unauthorized alteration of data, medical and pharmaceutical decisions that rely on the integrity of those data are placed at risk, and improper treatment may result. if these alterations are not detected, thousands of lives may be placed at risk.if the department of defense™s logistics systems are compromised, largescale military deployments could become quite difcult or impossible to conduct in a timely manner.if the communications systems used by emergency responders in a city are compromised so that communications capabilities are greatly diminished, police, re, and medical personnel would be crippled in responding to emergencies.if the computerized controls for an industrial plant are compromised, an adversary might be able to cause a major industrial accident. for example, if a chemical plant near a major metropolitan area were involved, a bhopallike accident might occur.if the electric power grid is compromised and attackers are able to cause blackouts over a wide area, public safety may be endangered through collateral consequences, such as rioting and looting. widespread blackouts that last for more than a few daysšentirely possible if the appropriate attack strategy is usedšgo beyond mere nuisance and begin to threaten economic livelihoods and personal health and safety on a large scale.even worse, the latter scenarios cannot be considered in isolation. indeed, if launched as part of a broader terrorist attack, they might be accompanied by physical ﬁkineticﬂ attacks on vital national interests, either domestically or abroad. cyberattacks conducted as part of a multipronged attack scenario that also includes physical attacks, rather than cyberattacks alone, could have the most catastrophic consequences.14 for example, cyberattacks conducted as part of a larger scenario could result in greater opportunity to widen the damage of a physical attack (e.g., by providing false information that drives people toward, rather than away 14 national research council. 2003. information technology for counterterrorism: immediate actions and future possibilities. the national academies press, washington, d.c.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.30 toward a safer and more secure cyberspacebox 2.1 lack of exploitation does not indicate nonvulnerabilityskeptics have often asked the following question: if information technology is so vulnerable, why hasn™t there been a ﬁdigital pearl harborﬂ yet? the rhetori cal logic is that since a digital pearl harbor hasn™t happened yet, the nation™s  cybersecurity posture must not be as bad as is claimed. in the view of the committee on improving cybersecurity research in the united states, the premise could reasonably be questioned, but stipulating the premise for the moment, such rhetoric does raise an interesting question: how might an observer distinguish which of the following statements is true: ﬁthere are no serious vulnerabilities in today™s information technologyﬂ or ﬁthere are serious but unseen vulnerabilitiesﬂ?a story from the early days of computer security is a good place to begin. an experimental timesharing system at a major university, to which users could connect using dialup modems, was subject to attack by hackers who would try to bring the system down. using these dialup connections, the hackers were successful from time to time. the system administrators responded to this threat by changing the system command structure. in particular, they added a command, called crash, that any user could invoke. the command was documented as follows: ﬁif you use this command, you will crash the system. everyone will lose their work, and be really mad at you. please don™t do this.ﬂ this security innovation turned out to be successful, because the existence of the crash command took all the intellectual challenge out of crashing the system, and the system administratorsšthemselves of a hacker mindsetšunderstood the motivations of their adversaries very, very well. obviously, such an approach would not work today. but this story illustrates the point that nondisaster does not necessarily mean that no vulnerabilities are present. given the existence of systemic vulnerabilities and the capability to exploit them, which essentially every cybersecurity expert recognizes, the question necessarily turns to one of motivation. why might a hostile party with the capability to exploit a vulnerability not do so?it is instructive to consider an analogous situation in the intelligence community. sensitive and important information about nation a may be gathered by (adversary) nation b from a wellplaced but covert source. under what circumstances might nation b refrain from using that information against nation a? the answer depends on the value that nation b places on protecting the source of the information versus the value that it places on using the information at that time. protecting sources and methods is a task of paramount importance in the intelligence community, because many sources and methods of collecting intelligence would be difcult to replace if their existence became knownšand thus, certain types of information are not used simply because their use would inevitably disclose the source.similarly, in the shadowy world of cyberthreat and cybersecurity, a hostile party with the capability to exploit a vulnerability would be welladvised to wait until the time was advantageous for it to launch an attack. in fact, one might well imagine that such a party would conduct exercises to probe weaknesses and lay the groundwork for an attack without actually taking overly hostile action. for example, such a party might use a virus that simply replicated itself but did not carry a payload that did any damage at all to prove to itself that such an attack was possible in principle. the cybersecurity community knows of incidents (such as rapidly propagating viruses without destructive payloads and the active compromise of many networkconnected computers that can be used to launch a variety of distributed attacks) that are consistent with the likely tactics of intelligent hostile parties. and it knows of intelligent parties whose intentions toward the united states are hostile. these factors do not constitute a logical proof of extensive cyberthreat, but they do underlie the committee™s judgment that the vulnerabilities with which it is concerned are not merely theoretical.from, the point of attack); interfering with timely responses to an attack (e.g., by disrupting the communications systems of rst responders); or increasing terror in the population through misinformation (e.g., by providing false information about the nature of a threat). and, of course, it is possible for information technology controlling the operation of physical systems to cause physical damage to those systems.note also that the nation™s information technology might be either a target of an attacker or a weapon for an attacker to use. in the rst case, an element of the it infrastructure itself (e.g., the means for people to communicate or to engage in nancial transactions) might be a target to be destroyed. in the second case, the target of an adversary might be another kind of critical infrastructure (e.g., the electric power grid), and the adversary could either launch or exacerbate the attack by exploiting the it infrastructure. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 31box 2.1 lack of exploitation does not indicate nonvulnerabilityskeptics have often asked the following question: if information technology is so vulnerable, why hasn™t there been a ﬁdigital pearl harborﬂ yet? the rhetori cal logic is that since a digital pearl harbor hasn™t happened yet, the nation™s  cybersecurity posture must not be as bad as is claimed. in the view of the committee on improving cybersecurity research in the united states, the premise could reasonably be questioned, but stipulating the premise for the moment, such rhetoric does raise an interesting question: how might an observer distinguish which of the following statements is true: ﬁthere are no serious vulnerabilities in today™s information technologyﬂ or ﬁthere are serious but unseen vulnerabilitiesﬂ?a story from the early days of computer security is a good place to begin. an experimental timesharing system at a major university, to which users could connect using dialup modems, was subject to attack by hackers who would try to bring the system down. using these dialup connections, the hackers were successful from time to time. the system administrators responded to this threat by changing the system command structure. in particular, they added a command, called crash, that any user could invoke. the command was documented as follows: ﬁif you use this command, you will crash the system. everyone will lose their work, and be really mad at you. please don™t do this.ﬂ this security innovation turned out to be successful, because the existence of the crash command took all the intellectual challenge out of crashing the system, and the system administratorsšthemselves of a hacker mindsetšunderstood the motivations of their adversaries very, very well. obviously, such an approach would not work today. but this story illustrates the point that nondisaster does not necessarily mean that no vulnerabilities are present. given the existence of systemic vulnerabilities and the capability to exploit them, which essentially every cybersecurity expert recognizes, the question necessarily turns to one of motivation. why might a hostile party with the capability to exploit a vulnerability not do so?it is instructive to consider an analogous situation in the intelligence community. sensitive and important information about nation a may be gathered by (adversary) nation b from a wellplaced but covert source. under what circumstances might nation b refrain from using that information against nation a? the answer depends on the value that nation b places on protecting the source of the information versus the value that it places on using the information at that time. protecting sources and methods is a task of paramount importance in the intelligence community, because many sources and methods of collecting intelligence would be difcult to replace if their existence became knownšand thus, certain types of information are not used simply because their use would inevitably disclose the source.similarly, in the shadowy world of cyberthreat and cybersecurity, a hostile party with the capability to exploit a vulnerability would be welladvised to wait until the time was advantageous for it to launch an attack. in fact, one might well imagine that such a party would conduct exercises to probe weaknesses and lay the groundwork for an attack without actually taking overly hostile action. for example, such a party might use a virus that simply replicated itself but did not carry a payload that did any damage at all to prove to itself that such an attack was possible in principle. the cybersecurity community knows of incidents (such as rapidly propagating viruses without destructive payloads and the active compromise of many networkconnected computers that can be used to launch a variety of distributed attacks) that are consistent with the likely tactics of intelligent hostile parties. and it knows of intelligent parties whose intentions toward the united states are hostile. these factors do not constitute a logical proof of extensive cyberthreat, but they do underlie the committee™s judgment that the vulnerabilities with which it is concerned are not merely theoretical.taken together, these scenarios suggest that a lack of security in cyberspace has three potential consequences. first is the threat of catastropheša cyberattack, especially in conjunction with a physical attack, could result in thousands of deaths and many billions of dollars of damage in a very short time. second is frictional drag on important economic and securityrelated processes. today, insecurities in cyberspace systems and networks allow adversaries (in particular, criminals) to extract enormous sums of money in fraud and extortionšand force businesses to expend additional resources to defend themselves against these threats. if cyberspace does not become more secure, tomorrow™s businesses will continue to face similar pressures, and most likely on a greater scale. third, concerns about insecurity may inhibit the use of information technologies in the future and thus lead to selfdenial of the benets they bring, benets toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.32 toward a safer and more secure cyberspacethat will be needed for the national competitiveness of the united states as well as for national and homeland security.2.5 the magnitude of the threat against today™s technologiesthe previous sections in this chapter describe what might be possible through a cyberattack. in the absence of quantitative threat information, these possibilities might well be regarded as speculative or isolated instances. but nearly all indicators of frequency, impact, scope, and cost of cybersecurity incidents show a continuously worsening picture. this is true whether one considers the losses due to itbased fraud and theft, identity theft and attacks on personal information, incidence of viruses and malicious code, number of compromised systems, or other types of impact. the discussion below reviews some of the publicly available evidence about the impacts of cyberattacks.in february 2005, the president™s information technology advisory committee (pitac) released a report entitled cybersecurity: a crisis of prioritization containing several data points indicating the size and scope of the threat, drawn from various sources.15 reexamining those data points and a number of others 2 years later offers a point of direct comparison for measuring recent trends in cybersecurity:the pitac report noted that in the deloitte 2004 global security survey, 83 percent of nancial service organizations experienced compromised systems in 2004. this compares with 28 percent in 2005 and 82 percent in 2006. in 2003, the gure was 39 percent.16 the pitac report noted that the 9th annual computer virus prevalence survey 2003 of icsa labs (formerly known as the international computer security association) reports that the monthly percentage of personal computers infected by a virus grew from  1 percent in 1996 to over 10 percent in 2003. the 10th annual computer virus prevalence survey 2004 reports a continued increase of 0.8 percent, approaching 12 percent.17 15 president™s information technology advisory committee. february 2005. cyber security: a crisis of prioritization, national coordination ofce for information technology research and development, washington, d.c.; available at www.nitrd.gov/pitac/reports/20050301cybersecurity/cybersecurity.pdf.16 deloitte, global security survey, annual reports on the global nancial services industry, 2002 to 2006. the 2006 report explained the huge differences as resulting from changes in the respondent pool, specically their size and geographic distribution; see deloitte, 2006, 2006 global security survey, deloitte touche tohmatsu, p. 26; available at http://www.deloitte.com/dtt/cda/doc/content/usfsi150606globalsecuritysurvey(1).pdf.17 icsa labs, 9th annual computer virus prevalence survey 2003 (2004); and icsa labs, 10th annual computer virus prevalence survey 2004 (2005); see http://www.icsalabs.com/icsa/ toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 33the pitac report noted that the january to june 2004 symantec internet security threat report showed that the rate of computers incorporated into bot armies rose from under 2,000 per day to over 30,000. symantec™s january to june 2006 report shows a rising rate of compromised computers, from over 40,000 to over 60,000, with an average over the period of 57,717.18the 2003 icsa labs report noted that 92 of 300 respondents (31 percent) reported virus disasters. the 2004 icsa labs report shows an increase of 6 percent over 2003, from 92 of 300 to 112 of 300 respondents.19the pitac report noted that the icsa labs surveys show an upward trend for each of the past 9 years for cost, downtime, and days to recover from signicant virus events. this trend continued in 2004, with a 25 percent increase in recovery time over the 2003 gure and a signicant jump in cost related to recovery.new vulnerabilities reported to the computer emergency response team coordination center (cert/cc) more than doubled again from the 3,780 recorded in 2004 to 8,064 recorded in 2006.20the symantec report noted that in the rst half of 2004, the average time between the public disclosure of a vulnerability and the release of an associated exploit was 5.8 days. the report showed that in the rst half of 2006, an average exploit time was 3 days, continuing the trend of quicker exploitation and cutting exploit time by almost half.21since the release of the pitac cybersecurity report, a number of other reports have highlighted the increasing sophistication of attacks. overall, these reports suggest that lesssophisticated attacks are now being icsahome.php. the 2003 rate is 108/1,000, or 10.8 percent. the 2004 rate is 116/1,000, or 11.6 percent. 18 symantec corporation, symantec internet security threat report: trends for january 06œ june 06, vol. x, september 2006. the report warns that new methodologies were implemented to obtain and record attack data, including bot activity. it says that as a consequence of these changes ﬁany comparison with the attack data gathered in previous periods would be invalid.ﬂ see p. 40. 19 the icsa labs report denes a virus disaster as an incident in which 25 or more personal computers or servers are infected at the same time with the same virus, or an incident causing signicant damage or monetary loss to the organization. see icsa labs, 10th annual computer virus prevalence survey 2004 (2005), p. 1.20 computer emergency response team coordination center, cert statistics; available at http://www.cert.org/stats/. 21 the symantec report for januaryjune 2006 (vol. x) also notes that vendors are dramatically reducing the patch development and release time, so that the overall window of exposure fell from 60 days in january 2006 to 28 days in june 2006. see symantec corporation, symantec internet security threat report: trends for january 06œjune 06, vol. x, september 2006, pp. 5859.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.34 toward a safer and more secure cyberspacethwarted by the increased use of virus protection software, spyware, and spam lters and other security products, but the attacks that are succeeding have greater impactšand are more difcult to protect against. for example, the deloitte 2006 global security survey noted the ﬁexponential increase in the sophistication of threats and their potential impact across an organization.ﬂ22 the 2006 ecrime watch survey found that 55 percent of all organizations in the survey had at least one incident of an insider attack, up from 39 percent the previous year.23 the symantec internet security threat report, volume x, published in september 2006, concludes that ﬁthe threat environment continues to be populated by lowerprole, targeted attacks as cyber criminals identify new ways to steal information or provide remote access to user systems. the attacks propagate at a slower rate in order to avoid detection and increase the likelihood of successful compromise before security measures can be put in place.ﬂ24 the documentation of the nature of cybersecurity incidents provided in these reports is fragmented and incomplete. for example, the department of justice notes that there is ﬁcurrently [in february 2006] no national baseline measure . . . on the extent of cybercrime.ﬂ25 yet, the available data are sufcient to make assertions about the seriousness of the threat that are more than just statements to be taken on faith. (box 2.2 lists some of more signicant sources.) some efforts focus on counting the frequency, nature, and trends of attacks. others focus on measuring the impacts and costs of incidents by surveying organizations and individuals. taken together, they paint a clear picture of growing impacts, including lost production, operational disruptions, and direct economic costs from fraud and lost business, measured on the scale of several billions of dollars annually.26 the impact is already very large and is growing, and the threat is expanding. it is also likely that the reported level of security incidents understates 22 deloitte, 2006 global security survey (2006), p. 13.23 cso magazine, u.s. secret service, cert coordination center, microsoft corp., 2006 ecrime watch survey; available at http://www2.csoonline.com/info/release.html?cid=24531. 24 symantec corporation, symantec internet security threat report: trends for january 06œ june 06, vol. x, september 2006, p. 4.25 department of justice, bureau of justice statistics, national computer security survey announced, february 9, 2006; available at http://www.ojp.usdoj.gov/bjs/pub/press/ncsspr.htm. the survey is also supported by a number of trade associations and industry groups.26 for example, the 2006 javelin strategy and research report on identity fraud estimated the total cost of id fraud in 2004 at $56.6 billion. approximately 9 percent of these cases were attributable to phishing, hacking, computer viruses, or spyware on home computers; another 6 percent resulted from data breaches at businesses holding personal information. assuming that the average cost of an incident of computerbased id fraud is comparable with the cost of other kinds of id fraud (an assumption that seems roughly consistent with other data presented in the report), these cases account for $8 billion to $9 billion in losses. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 35the actual level. for example, the 2006 csi/fbi computer crime and security survey found that the negative publicity from reporting incidents to law enforcement is a major concern of many organizations, noting that only 25 percent of rms report incidents to authorities.27 some incidents would routinely go unreported for benign reasons (e.g., they were not severe enough). but there is also a systematic bias against reporting, because targets of cyberattacks such as government agencies and large corporations are often concerned that widespread disclosure of their victimization would shake public condence in their operations and integrity. whether they are concerned about embarrassment, loss of condence, giving competitors an advertising advantage over them, or drops in market share, agencies and corporations have few incentives to report these events in a public forum. in some cases, successful cyberattacks may never be noticed at all (as might be the case if valuable secrets were stolen).how signicant is the underreporting? this magnitude is hard to estimate, but one widely cited article from 2002 claims that ﬁonly about 10% of all cybercrimes committed are actually reported and fewer than 2% result in a conviction.ﬂ the article offers two reasons for this: institutions feel that they have more to lose by reporting computer security breaches, and they assume that law enforcement will provide little or no assistance.28 2.6 an ominous futurethe committee believes that security will be a continuing issue because there will always be incentives to compromise the security of deployed systems, and that these incentives will only increase over time as organizations and individuals increasingly depend on information technology. personal gain, organized crime, terrorism, and national interests are superseding personal fame and curiosity as incentives for cyberattacks, and thus the threat picture is coming to include increasingly sophisticated actors who possess signicant resources to execute attacks. moreover, threats evolve (both on their own and as defenses against them are discovered), and new vulnerabilities often emerge as innovation changes underlying system architectures, implementation, or basic assumptions. see javelin strategy and research, identity fraud survey report, consumer version, january 2006; available at www.javelinstrategy.com/products/ad35ba/27/delivery.pdf.27 lawrence a. gordon, martin p. loeb, william lucyshyn, and robert richardson, 2006 csi/fbi computer crime and security survey, computer security institute, 2006; available at http://i.cmpnet.com/gocsi/dbarea/pdfs/fbi/fbi2006.pdf.28 chris hale, ﬁcybercrime: facts and figures concerning the global dilemma,ﬂ crime and justice international, 18(65): 56, 2426, september 2002.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.36 toward a safer and more secure cyberspacebox 2.2 major sources of data characterizing the cyberthreatthere are many sources of data characterizing the nature of the cybersecurity threat. the sources of data and analysis described in this box are (or are planned to be) updated on an ongoing (e.g., annual) basis. (in a few instances reports have been issued consistently for more than 10 years.) sponsoring organizations include academic institutions, federal agencies, and a range of privatesector companies working either alone or in collaboration. the rst two sources listed here focus on the frequency of incidents and the type of attacks observable through the monitoring of internet trafc. the others are surveys measuring the scope, impact, and cost of incidents to organizations and rms, although the purpose, scope, and methods of these surveys vary considerably. cert/cc statistics: the computer emergency response team coordination center (cert/cc) has collected statistics on vulnerabilities and incidents since 1988. cert is a center of internet security expertise located at the software engineering institute, a federally funded research and development center operated by carnegie mellon university. in addition to maintaining incident and vulnerability statistics, cert/cc works with uscert to coordinate defense against and response to cyberattacks. further information is available at http://www.cert.org/stats/certstats.html. symantec internet security threat report: first published in january 2002 by riptech, inc. (acquired by symantec in july 2002), this report has been published twice annually since 2002, for a total of 10 reports. using network data collected by sensors monitoring network activity globally, these reports summarize and analyze network attack trends, vulnerability trends, and malicious code trends. metrics used to measure the ﬁthreat landscapeﬂ have continued to evolve along with the types of attacks. all of the reports are available at http://www.symantec.com/enterprise/threatreport/index.jsp.ecrime watch survey: this annual survey, started in 2004, is conducted by cso (chief security ofcer) magazine in cooperation with the u.s. secret service™s electronic crimes task force, cert/cc, and microsoft corporation. the purpose of the survey is to identify electroniccrime trends and techniques and to gather data on their impact. the 2006 report is available at http://www.cert.org/archive/pdf/ecrimesurvey06.pdf.fbi computer crime survey: conducted in 2005, the purpose of this survey is to ﬁgain an accurate understanding of what computer security incidents are being experienced by the full spectrum of sizes and types of organizations within the united states.ﬂ1 internet fraud crime report: prepared by the national white collar crime center and the federal bureau of investigation (fbi), the 2005 edition is the fth annual compilation of ﬁinformation on complaints received and referred by the internet crime complaint center (ic3) to law enforcement or regulatory agencies for appropriate action.ﬂ2 the report outlines many of the current trends and patterns in internet crime; it is available at http://www.ic3.gov/media/annualreport/2005ic3report.pdf. ł csi/fbi computer crime and security survey: conducted by the computer security institute (csi) with the participation of the san francisco, california, fbi computer intrusion squad, this survey is now in its 11th year, having produced a report every year since 1996. its primary focus is on the economic impacts of incidents, the economic decisions that organizations make regarding computer security, and how they manage risk associated with security breaches. see http://www.gocsi.com/.deloitte™s global security survey: published annually since 2003, this survey reports on the outcome of focused discussions with information technology executives from the global nancial services institutions designed to identify perceived levels of risks, the types of risks that are the focus of concern, the resources being used to mitigate these risks, the security technologies being employed, and the value gained from the security investments made. the 2006 report is available at http://www.deloitte.com/dtt/cda/doc/content/deloitte%202006%20global%20security%20survey(2).pdf. icsa (formerly known as the international computer security association) labs annual computer virus prevalence survey: conducted every year from 1996 through 2004, the objectives of this survey are ﬁto examine the prevalence of computer viruses in mid and largesized organizations; describe the computer virus problem in computer networks, including desktop computers; application and le servers; and perimeter devices such as rewalls, gateways, and proxy servers; and observe trends in computer virus growth, infection methodologies, and attack vectors.ﬂ3 the 10th annual report, published in 2005, is available at http://www.icsalabs.com/icsa/docs/html/library/whitepapers/vps2004.pdf.1federal bureau of investigation, 2005 fbi computer crime survey, washington, d.c., p. 1. key ndings of this report may be found at http://www.fbi.gov/page2/jan06/computercrimesurvey011806.htm; the entire report is available at http://www.digitalriver.com/v2.0img/ operations/naievigi/site/media/pdf/fbiccs2005.pdf.2national white collar crime center, federal bureau of investigation, the internet crime complaint center 2005 internet crime report: january 1, 2005œdecember 31, 2005, washington, d.c., p. 3.3icsa labs, 10th annual computer virus prevalence survey 2004, 2005, p. 3.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 37box 2.2 major sources of data characterizing the cyberthreatthere are many sources of data characterizing the nature of the cybersecurity threat. the sources of data and analysis described in this box are (or are planned to be) updated on an ongoing (e.g., annual) basis. (in a few instances reports have been issued consistently for more than 10 years.) sponsoring organizations include academic institutions, federal agencies, and a range of privatesector companies working either alone or in collaboration. the rst two sources listed here focus on the frequency of incidents and the type of attacks observable through the monitoring of internet trafc. the others are surveys measuring the scope, impact, and cost of incidents to organizations and rms, although the purpose, scope, and methods of these surveys vary considerably. cert/cc statistics: the computer emergency response team coordination center (cert/cc) has collected statistics on vulnerabilities and incidents since 1988. cert is a center of internet security expertise located at the software engineering institute, a federally funded research and development center operated by carnegie mellon university. in addition to maintaining incident and vulnerability statistics, cert/cc works with uscert to coordinate defense against and response to cyberattacks. further information is available at http://www.cert.org/stats/certstats.html. symantec internet security threat report: first published in january 2002 by riptech, inc. (acquired by symantec in july 2002), this report has been published twice annually since 2002, for a total of 10 reports. using network data collected by sensors monitoring network activity globally, these reports summarize and analyze network attack trends, vulnerability trends, and malicious code trends. metrics used to measure the ﬁthreat landscapeﬂ have continued to evolve along with the types of attacks. all of the reports are available at http://www.symantec.com/enterprise/threatreport/index.jsp.ecrime watch survey: this annual survey, started in 2004, is conducted by cso (chief security ofcer) magazine in cooperation with the u.s. secret service™s electronic crimes task force, cert/cc, and microsoft corporation. the purpose of the survey is to identify electroniccrime trends and techniques and to gather data on their impact. the 2006 report is available at http://www.cert.org/archive/pdf/ecrimesurvey06.pdf.fbi computer crime survey: conducted in 2005, the purpose of this survey is to ﬁgain an accurate understanding of what computer security incidents are being experienced by the full spectrum of sizes and types of organizations within the united states.ﬂ1 internet fraud crime report: prepared by the national white collar crime center and the federal bureau of investigation (fbi), the 2005 edition is the fth annual compilation of ﬁinformation on complaints received and referred by the internet crime complaint center (ic3) to law enforcement or regulatory agencies for appropriate action.ﬂ2 the report outlines many of the current trends and patterns in internet crime; it is available at http://www.ic3.gov/media/annualreport/2005ic3report.pdf. ł csi/fbi computer crime and security survey: conducted by the computer security institute (csi) with the participation of the san francisco, california, fbi computer intrusion squad, this survey is now in its 11th year, having produced a report every year since 1996. its primary focus is on the economic impacts of incidents, the economic decisions that organizations make regarding computer security, and how they manage risk associated with security breaches. see http://www.gocsi.com/.deloitte™s global security survey: published annually since 2003, this survey reports on the outcome of focused discussions with information technology executives from the global nancial services institutions designed to identify perceived levels of risks, the types of risks that are the focus of concern, the resources being used to mitigate these risks, the security technologies being employed, and the value gained from the security investments made. the 2006 report is available at http://www.deloitte.com/dtt/cda/doc/content/deloitte%202006%20global%20security%20survey(2).pdf. icsa (formerly known as the international computer security association) labs annual computer virus prevalence survey: conducted every year from 1996 through 2004, the objectives of this survey are ﬁto examine the prevalence of computer viruses in mid and largesized organizations; describe the computer virus problem in computer networks, including desktop computers; application and le servers; and perimeter devices such as rewalls, gateways, and proxy servers; and observe trends in computer virus growth, infection methodologies, and attack vectors.ﬂ3 the 10th annual report, published in 2005, is available at http://www.icsalabs.com/icsa/docs/html/library/whitepapers/vps2004.pdf.1federal bureau of investigation, 2005 fbi computer crime survey, washington, d.c., p. 1. key ndings of this report may be found at http://www.fbi.gov/page2/jan06/computercrimesurvey011806.htm; the entire report is available at http://www.digitalriver.com/v2.0img/ operations/naievigi/site/media/pdf/fbiccs2005.pdf.2national white collar crime center, federal bureau of investigation, the internet crime complaint center 2005 internet crime report: january 1, 2005œdecember 31, 2005, washington, d.c., p. 3.3icsa labs, 10th annual computer virus prevalence survey 2004, 2005, p. 3.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.38 toward a safer and more secure cyberspace2.6.1 the evolution of the threatin 1992, the world wide web had not yet been invented. cybersecurity efforts were focused primarily on enhancing the security of individual, unnetworked systems. even then, security had been raised as an important issue (as discussed in section 10.1). but 15 years later, information technology has advanced dramatically in almost all eldsšexcept for cybersecurity. consider that in the past 15 years:the increasingly ubiquitous interconnection of the world™s computers provides many avenues for cyberattackers to exploit, and these will only proliferate.increasing standardization and homogeneity of communications protocols, programming interfaces, operating systems, computing hardware, and routers allow for a single developed attack to be used against vast numbers of systems.distinctions between data and program have been eroded. ﬁactive contentﬂ is now quite common in programming paradigms; pictures, word processing les, and spreadsheets can and often do contain programs embedded within them in order to increase their functionality. (for example, a spreadsheet can contain macros that are integral to the use of that spreadsheet.) the consequence is that the computing environment is no longer under the complete control of the user of these les.as systems evolve they tend to become more complex. the greater the complexity, the more difcult it is to verify the operation of the system before it is put into use, and the more difcult it may be to detect that the system™s defenses have been penetrated. dramatic increases in complexity make the jobs of both attacker and defender more difcult, but the increase in difculty affects the defender much more than the attacker.user demands for backward compatibility often mean that older and less secure components cannot be replaced with newer components that reduce or mitigate the old vulnerabilities. furthermore, the complexities of the ensuing extra software to accommodate compatibility tend to introduce further ˚aws.use of webbased services (see section 8.4.3) proliferates the opportunities for adversaries to attack important service providers. web services may depend on other web services, so the ability to predict, or even comprehend, the impact of attacks may be very low.the great difculties of associating individuals with specic destructive or hostile actions, coupled with an uncertain and ambiguous legal and policy framework for dealing with such incidents (especially when they involve communications and information passed across national boundaries), make it highly unlikely that toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 39adversaries will suffer signicant negative consequences for their actions, thus increasing the likelihood that others will take actions with similar intent.widespread networking of computers was a signal event in the evolution of information technology, with signicant implications for cybersecurity. as one example, consider the problem of botnets. a botnet (also known as a zombienet) is a collection of computers on a network that are under the remote control of an unauthorized party, often obtained through the use of a worm or a trojan horse that exploits some system vulnerability. (box 2.3 describes botnets in greater detail.) botnets are one of the most pernicious internet security problems today (that is, in mid2007). for example, symantec reported that in the rst 6 months of 2006, it identied 6,337 commandandcontrol servers (i.e., botnet controllers) and 4,696,903 individual computers that had been compromised (ﬁzombiedﬂ) at some point during that time period.29 some reports indicate that approximately 250,000 new compromises occur daily, although this gure includes a large number of compromises occurring on previously compromised systems (i.e., a vulnerable computer is likely compromised by multiple botnets).30 david dagon of the georgia institute of technology has reported that the total number of compromised computers is in the tens or hundreds of millions,31 and the messaging antiabuse working group estimated that in 2006, about 7 percent of all internetconnected computers (some 47 million) had been compromised.32 the size of individual botnets has grown as well, with some reports suggesting the existence of botnets with as many as hundreds of thousands or even 1.5 million zombies.33 a similarly profound shift is likely as computing becomes increas29 symantec corporation, symantec internet security threat report: trends for january 06œjune 06, vol. x, september 2006; available at http://www.symantec.com/specprog/threatre port/entwhitepapersymantecinternetsecuritythreatreportx092006.enus.pdf.30 rick wesson, ﬁabuse and the global infection rate,ﬂ presentation at defcon, au gust 14, 2006; more information is available at http://www.defcon.org/html/defcon14/ dc14speakers.html.31 david dagon, ﬁthe network is the infection,ﬂ available at http://www.caida.org/ projects/oarc/200507/slides/oarc0507dagon.pdf.32 byron acohido and jon swartz, ﬁmalicioussoftware spreaders get sneakier, more prevalent,ﬂ usa today, april 23, 2006; available at http://www.usatoday.com/tech/news/ computersecurity/infotheft/20060423botherdersx.htm.33 in late 2005, a man was indicted by a federal grand jury on charges that he had compromised nearly 400,000 windows computers (see robert lemos, ﬁsuspected bot master busted,ﬂ securityfocus, november 3, 2005; available at http://www.securityfocus.com/news/11353). also in late 2005, dutch prosecutors alleged that three suspects had compromised 1.5 million computers as part of a worldwide botnet (see toby sterling, ﬁdutch say suspects hacked 1.5m computers,ﬂ associated press newswire, october 20, 2005; available at http://www.usatoday.com/tech/news/computersecurity/20051020dutchhackx.htm).toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.40 toward a safer and more secure cyberspacebox 2.3 on botnetsbotnets (also known as zombienets) are collections of compromised computers that are remotely controlled by a malevolent party. a compromised computer is connected to the internet, usually with an ﬁalwaysonﬂ broadband connection, and is running software introduced by the malevolent party. malevolent software can be introduced through a number of channels; they include clicking on a link that takes the user to a certain web page, downloading an attachment that executes a program, forcing entry into a computer through an unprotected port (e.g., one typically used for le sharing across the internet), and so on. using uptodate security software such as antivirus programs and rewalls helps to reduce the threat of such ﬁmalware,ﬂ but today most personal computersševen protected onesšare at least somewhat vulnerable to such threats.an individual compromised computer (a zombie or a bot) can be used for many purposes, but the threat from botnets arises from the sheer number of computers that a single malevolent party can controlšoften tens of thousands and as many as a million. (note also that an individual unprotected computer may be part of multiple botnets as the result of multiple compromises.) when the zombied computers are connected to the internet through broadband connections, the aggregate bandwidth of the botnets is enormous (e.g., a small botnet of 1,000 zombies times a 300 kilobit digital subscriber line connection is 300 megabits per second). a further property of botnets is that they can be controlled remotely by an adversary, which means that the apparent perpetrator of a hostile act is a zombie computeršmaking it difcult to trace a hostile act to its initiator. indeed, an adversary may be located in a nation other than the home country of the zombies.typically, an adversary builds a botnet by nding a few machines to compromise. the rst hostile action that these initial zombies take is to nd other machines to compromiseša task that can be undertaken in an automatic manner. but botnets are capable of undertaking a variety of other actions that have signicant impact on the botnet operator™s target(s). for example, botnets can be used to conduct the following actions:distributed denialofservice attacks. a denialofservice attack on a target renders the target™s computer resources unavailable to service legitimate requests by requesting service itself and blocking others from using those resources. but if these requests for service come from a single source, it is easy to simply drop all service requests from that source. however, a distributed denialofservice attack can ˚ood the target with multiple requests from many different machines, each of which might, in principle, be a legitimate requester of service. spam attacks. botnets can be used to send enormous amounts of spam  email. since spam is illegal in many venues and is regarded as antisocial by most, it is in a spammer™s interest to hide his or her identity. some botnets also search for email addresses in many different locations.trafcsnifng attacks and keylogging. a zombie can examine cleartext data passing by or through it. such data might be sensitive information such as usernames and passwords, and it might be contained in data packets or in various input channels, such as the keyboard channel.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 41ingly pervasive and embedded in all manners of devices. these embedded computers are themselves likely to be in communication with one another when they are in range (with all of the security issues that such communication implies). they are also likely to be much larger in number: an ordinary room at home could conceivably contain tens or hundreds of such devices. these developmentsšpervasive computing and adaptive (dynamic) ubiquitous networked systemsšwill call for the development of new security models and architectures. if continued expansion of the use and benets of it is to be realized, the information technology systems and networks must be adequately protected. otherwise, individuals and organizations throughout society click fraud. a great deal of advertising revenue comes from individuals clicking on ads. a botnet can easily be used to generate a large volume of clicks on ads that do not correspond to any individual™s legitimate interest in those ads. further, because each zombie appears to be legitimate, it is difcult for the party being defrauded to know that a botnet is being used to perpetrate click fraud.probes. it is widely reported that only a few minutes elapse between the instant that a computer attaches to the internet and the time that it is probed for vulnerabilities and possibly compromised itself. without botnets in operation, nding open and vulnerable machines would be a much more difcult process.acting as hosts for information exltration. botnets could be used as recipients of clandestinely gathered informationša kind of ﬁdead dropﬂ for trojan horses planted to gather information secretly that mask the ultimate destination of such information.botnets would be (and are) a logical vehicle of choice for many malevolent parties. botnets can be dormant for a long time before being activated. once activated, the botnet owner or operator can stay in the background, unidentied and far away from any action, while the individual botsšmostly belonging to innocent partiesšare the ones that are visible to the party under attack. and botnets are highly ˚exible, capable of being upgraded on the ˚y just like any other piece of software.thus, it is not surprising to see that botnets can be used as the basis of an underground service to unethical end users. a botnet owner could rent the botnet to party a to send spam, party b to extort money from an online business, and party c to sniff trafc and collect online identication credentials. a typical price might be ﬁ$0.50 per zombie per hour of use.ﬂ today, it is known that botnets are used for criminal purposes such as cyberextortion, but the extent to which they are used by terrorists or adversary nations is unknown.source: adapted in part from honeynet project and research alliance, ﬁknow your enemy: tracking botnets,ﬂ march 13, 2005; available at http://www.honeynet.org.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.42 toward a safer and more secure cyberspacewill deem it unacceptably risky to increase their reliance on insecure technologies. even today, cybersecurity issues have not been addressed adequately, and individuals and organizations throughout society nd themselves under an increasingly dark and threatening cloud. in short, cybersecurity is increasingly important, both as a pillar of today™s critical computing and communications applications and as an enabler of future advances in computing and information technology. 2.6.2 the broad range of capabilities and goals of cyberattackersthe committee believes that a very broad spectrum of actors, ranging from lone hackers at one extreme to major nationstates at the other, pose security risks to the nation™s information technology infrastructure. organized crime (e.g., drug cartels) and transnational terrorists (and terrorist organizations, some of them statesponsored) occupy a region between these two extremes, but they are closer to the nationstate than to the lone hacker.34attackers have a range of motivations. some are motivated by curiosity. some are motivated by the desire to penetrate or vandalize for the thrill of it, others by the desire to steal or prot from their actions. and still others are motivated by ideological or nationalistic reasons. today, the most salient cybersecurity threat emanates from hackers and criminals, although there is growing realization that organized crime is seeing increasing value in exploiting and targeting cyberspace. thus, most cybersecurity efforts taken across the nation in all sectorsšboth in research and in deploymentšare oriented toward defending against these low and midlevel threats.much more work remains to be done to address even these lowerlevel threats. the state of security practice today is such that even casual attackers can nd many vulnerabilities to exploit. the deployment of even quite unsophisticated cybersecurity measures can make a difference against casual attackers. thus, the cybersecurity posture of the nation could be strengthened if individuals and organizations collectively adopted ﬁbest practicesﬂ that are known to improve cybersecurity. the research and development (r&d) activities addressed in much of this report will ultimately lead to signicant progress against these low to midlevel threats. however, against the highend attacker, efforts oriented 34 in certain ways, it could be argued that organized crime constitutes a more potent threat than many nationstates do. one reason is that the resources available to organized crime syndicates for supporting cyberthreat activities may exceed those available to a nationstate. a second reason is that the operations of nationstates are often constrained within a bureaucratic context that may be more cumbersome than in a syndicate.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 43toward countering the casual attacker or even the common cybercriminal amount to little more than speed bumps. the reason is that the highend cyberthreat, as described below, is qualitatively different from other threats. first and foremost, highend actors usually have enormous resources. major nationstates, for example, are nanced by national treasuries; they can exploit the talents of some of the smartest and most motivated individuals in their national populations; they often have the luxury of time to plan and execute attacks; and they can draw on all of the other resources available to the national government, such as national intelligence, military, and law enforcement services. organized crime syndicates, such as drug cartels, may operate hand in hand with some governments; when operating without government cooperation, their human and nancial resources may not be at the level available to governments, but they are nevertheless quite formidable. statesponsored terrorist groups by denition obtain signicant resources from their state sponsors.as a result, the highend cyberattacker can be relatively pro˚igate in executing its attack and in particular can target vulnerabilities at any point in the it supply chain from hardware fabrication to user actions (box 2.4). in particular, the resources of the highend cyberattacker facilitate attacks that require physical proximity. for example, a major nationstate threat raises questions about the nations in which it is safe to design software or to manufacture chips.35the availability of such resources widens the possible target set of highend attackers. low and midlevel attackers often benet from the ability to gain a small prot from each of many targets. spammers and bot harvesters are the best examples of this phenomenonšan individual user or computer is vulnerable in some way to a spammer or a bot harvester, but the spammer or bot harvester prots because many such users or computers are present on the internet. however, because of the resources available to them, highend attackers may also be able to target a specic computer or user whose individual compromise would have enormous value (ﬁgoing after the crown jewelsﬂ). in the former case, an attacker confronted with an adequately defended system simply moves on to another system that is not so well defended. in the latter case, the attacker has the resources to escalate the attack to a very high degreešperhaps overwhelmingly so.it is also the case that the resources available to an adversaryš especially highend adversariesšare not static. this means that for a sufciently valuable target, a highend adversary may well be able to deploy 35 defense science board. 2005. high performance microchip supply, ofce of the under secretary of defense for acquisition, technology, and logistics, washington, d.c., february; available at http://www.acq.osd.mil/dsb/reports/200502hpmsreportfinal.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.44 toward a safer and more secure cyberspacebox 2.4 possible points of vulnerability in information  technology systems and networksan information technology system or network has many places where an operationally exploitable vulnerability can be found; in principle, a completely justiable trust in the system can be found only in environments that are completely under the control of the party who cares most about the security of the system. as discussed here, the environment consists of many thingsšall of which must be under the interested party™s control.the software is the most obvious set of vulnerabilities. in a running operating system or application, exploitable vulnerabilities may be present as the result of faulty program design or implementation, and viruses or worms may be introduced when the system or network comes in electronic contact with a hostile source. but there are more subtle paths by which vulnerabilities can be introduced as well. for example, compilers are used to generate object code from source code. the compiler itself must be secure, for it could introduce object code that subversively and subtly modies the functionality represented in the source code. a particular sequence of instructions could exploit an obscure and poorly known characteristic of hardware functioning, which means that programmers well versed in minute behavioral details of the machine on which the code will be running could introduce functionality that would likely go undetected in any review of the code.the hardware constitutes another set of vulnerabilities, although less attention is usually paid to hardware in this regard. hardware includes microprocessors, microcontrollers, rmware, circuit boards, power supplies, peripherals such as printers or scanners, storage devices, and communications equipment such as network cards. on the one hand, hardware is physical, so tampering with these components requires physical access at some point in the hardware™s life cycle, which may be difcult to obtain. on the other hand, hardware is difcult to inspect, so hardware compromises are hard to detect. consider, for example, that graphics display cards often have onboard processors and memory that can support an execution stream entirely separate from that running on a system™s ﬁmainﬂ processor. also, peripheral devices, often with their own microprocessor controllers and programs, can engage in bidirectional communications with their hosts, providing a possible vector for outside in˚uence. and, of course, many systems rely on a eldupgradable readonly memory (rom) chip to support a boot sequencešand corrupted or compromised roms could prove harmful in many situations.the communications channels between the system or network and the ﬁoutsideﬂ world present another set of vulnerabilities. in general, a system that does not interact with anyone is secure, but it is also largely useless. thus, communications of some sort must be established, and those channels can be compromisedšfor example, by spoong (an adversary pretends to be the ﬁauthorizedﬂ system), by jamming (an adversary denies access to anyone else), or by eavesdropping (an adversary obtains information intended to be condential).operators and users present a particularly challenging set of vulnerabilities. both can be compromised through blackmail or extortion. or, untrustworthy operators and users can be planted as spies. but users can also be tricked into actions that compromise security. for example, in one recent exploit, a red team used inexpensive universal serial bus (usb) ˚ash drives to penetrate an organization™s toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 45additional resources in its continuing attack if its initial attacks fail. in other words, capabilities that are infeasible for an adversary today may become feasible tomorrow. this point suggests that systems in actual deployment must continually evolve and upgrade their security.a corollary issue is the value of risk management in such an environment. if indeed an adversary has the resources to increase the sophisticasecurity. the red team scattered usb drives in parking lots, smoking areas, and other areas of high trafc. in addition to some innocuous images, each drive was preprogrammed with software that would collect passwords, logins, and machinespecic information from the user™s computer, and then email the ndings to the red team. because many systems support an ﬁautorunﬂ feature for insertable media (i.e., when the medium is inserted, the system automatically runs a program named ﬁautorun.exeﬂ on the medium) and the feature is often turned on, the red team was notied as soon as the drive was inserted. the result: 75 percent of the usb drives distributed were inserted into a computer.given the holistic nature of security, it is also worth noting that vulnerabilities can be introduced at every point in the supply chain: that is, systems (and their components) can be attacked in design, development, testing, production, distribution, installation, conguration, maintenance, and operation. on the way to a customer, a set of cdroms may be intercepted and a different set introduced in its place; extra functionality might be introduced during chip fabrication or motherboard assembly; a default security conguration might be left in an insecure statešand the list goes on.given the dependence of security on all of these elements in the supply chain, it is not unreasonable to think of security as an emergent property of a system, as its architecture is implemented, its code instantiated, and as the system itself is embedded in a human and an organizational context. in practice, this means that the actual vulnerabilities that a system must resist are specic to that particular system embedded in its particular context. this fact should not discourage the development of generic building blocks for security that might be assembled in a systemspecic way, but it does mean that an adversary could attack many possible targets in its quest to compromise a system or a network.sources:  information on compilers based on ken thompson, ﬁre˚ections on trusting trust,ﬂ communications of the acm, 27(8): 761763, august 1984. see also p.a. karger and r.r. schell, ﬁthirty years later: lessons from the multics security evaluation,ﬂ pp. 119126 in proceedings of the 18th annual computer security applications conference, december 913, 2002, las vegas, nev.: ieee computer society. available at http://www.acsaadmin.org/2002/papers/classicmultics.pdf. information on usb drive: see steve stasiukonis, ﬁsocial engineering, the usb way,ﬂ dark reading, june 7, 2006. available at http://www.darkreading.com/document.asp?docid=95556&wt.svl=column11. information on chip fabrication based on defense science board, high performance microchip supply, department of defense, february 2005; available at http://www.acq.osd.mil/dsb/reports/200502hpmsreportfinal.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.46 toward a safer and more secure cyberspacetion of its attack and the motivation to keep trying even after many initial attempts fail, it raises the question of whether anything less than perfect security will sufce. this question in turn raises understandable doubts about the philosophy of managing cybersecurity risks that is increasingly prevalent in the commercial world. yet, doing nothing until perfect security can be deployed is surely a recipe for inaction that leaves one vulnerable to many lowerlevel threats.highend cyberattackersšand especially major nationstate adversariesšare also likely to have the resources that allow them to obtain detailed information about the target system, such as knowledge gained by having access to the source code of the software running on the target or the schematics of the target device or through reverseengineering. success in obtaining such information is not guaranteed, of course, but the likelihood of success is clearly an increasing function of the availability of resources. for instance, a country may obtain source code and schematics of a certain vendor™s product because it can require that the vendor make those available to its intelligence agencies as a condition of permitting the vendor to sell products within its borders.concerns about a highend cyberattacker surfaced publicly in congressional concerns about the department of state™s use of computers manufactured in china (box 2.5). although there is no public evidence that the nondomestic origin of it components has ever compromised u.s. interests in any way, there is concern that it might in the future, or that such compromises in the past may have gone undetected.second, highend attackers sometimes do not wish their actions to be discovered. for example, they may hope that their adversaries do not gain a full picture of their own capabilities or do not take defensive actions that might reduce their capabilities in the future.36 (see box 2.6.) in such situations, and unlike a successful hacker who seeks glory and fame in the eyes of his or her peers, the successes of highend cyberattackers may well never be known outside a very small circle of individuals. a related point is that sophisticated attackers are very well capable of appearing to be less skilled hobbyisthackers, when in fact they are actually laying the groundwork for future attacks. put differently, under such circumstances, it might well be surprising to see actual direct evidence of the highend attacker, since such evidence would likely be masked. indirect evidence and inference thus become necessary to make the case that such an attacker even exists, even though such a case is necessarily weaker from an evidentiary standpoint.36 this is not to say that a highend attacker would never want to be discovered. in some cases, an attacker may nd it desirable to leave some evidence behind so that the damage that an attack causes cannot be attributed to an error or a glitch but instead points to the fact that the attacker is present and is a force to be reckoned with.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 47box 2.5 foreign sourcing of information technology  used in the united statesin march 2006, the u.s. department of state announced that it would purchase 16,000 lenovo computers and related equipment for use throughout the department. (lenovo, inc., is the chinese company to which ibm sold its laptop and desktop personal computer [pc] business in 2005. lenovo was incorporated in hong kong but is currently headquartered in the united states, and is reported to have ties to the chinese government as well.) about 900 of the 16,000 pcs were designated for use in the network connecting u.s. embassies and consulates. in may 2006, and after objections had been raised in the u.s. congress concerning the use of computers made by lenovo in a classied network, the state department agreed not to use lenovo computers for such classied work.the use of computers made by a chinese company for classied work was bound to raise a number of security concerns. but the state departmentœlenovo incident is symptomatic of a much larger issue. as computers and other information technology (it) systems are assembled with components manufactured or provided by vendors in many nations, even an ﬁamericanﬂ computer is not necessarily ﬁmade in the usaﬂ in anything but name. similar concerns arise with software components or applications that have been designed or coded or are maintained overseas but are being used in the united states.the nations that supply it components include manyšnot just chinašthat might well have an interest in information on u.s. national security or economic matters. in addition, as ﬁamericanﬂ companies increasingly send some of their work offshore or use foreign citizens in the united states to work on it, it is easy to see many possible avenues of foreign threat to the integrity of the security of information technology used in the united states.of course, the committee also recognizes that threats to the integrity of information technology used by the united states do not emanate from foreign sources alone, and there is no evidence known today that the nondomestic origin of it components has compromised u.s. interests in any way. but there is concern that compromises might occur in the future, or that such compromises in the past may have gone undetected. (as a saying in the intelligence community goes, ﬁwe have never found anything that an adversary has successfully hidden.ﬂ)third, the highend cyberattacker is generally indifferent to the form that its path to success takes, as long as that path meets various constraints such as affordability and secrecy. in particular, the highend cyberattacker will compromise or blackmail a trusted insider to do its bidding or inltrate a target organization with a trained agent rather than crack a security system if the former is easier to do than the latter. many hackers are motivated by the fame that they gain from defeating technological security mechanisms (sometimes by social engineering means rather than by technology exploitation). fourth, the motivation of a highend cyberattacker is unambiguously toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.48 toward a safer and more secure cyberspaceand seriously hostile. for example, a highend cyberattacker may use it in an attack as a means to an end and not as an end itself for a highimpact attack, much as the terrorists on september 11, 2001 (9/11), commandeered four airplanes to use as weapons. that is, for a highend adversary, a cyberattack may be most effective as an amplier of a physical attack.37 fifth, as a military strategy (a point relevant mostly to nationstates), 37 national research council. 2003. information technology for counterterrorism: immediate actions and future possibilities. the national academies press, washington, d.c.box 2.6 the silence of a successful cyberattackgiven the existence of systemic vulnerabilities and a party with the capability and intent to exploit them, it is important to consider the motivations of such a party. in particular, it is important to ask why a hostile party with the capability to exploit a vulnerability would not do so.consider rst an analogous situation in the intelligence community. say that sensitive and important information about nation a is gathered by (adversary) nation b from a wellplaced but covert source. under what circumstances might nation b refrain from using that information against nation a? the answer depends on the value that nation b places on protecting the source of the information versus the value it places on using the information at that time. ﬁprotecting sources and methodsﬂ is a task of paramount importance in the intelligence community, because many sources and methods of collecting intelligence would be difcult to replace if their existence became knownšand thus, certain types of information are not used simply because their use would inevitably disclose the source.similarly, in the shadowy world of cyberthreat and cybersecurity, a hostile party with the capability to exploit a vulnerability might be well advised to wait until the time is right for it to launch an attack. in fact, one might well imagine that such a party would conduct exercises to probe weaknesses and lay the groundwork for an attack, without actually taking overly hostile action. for example, such a party might use a virus that simply replicated itself but did not carry a payload that did any damage at all in order to prove to itself that such an attack is possible in principle. the cybersecurity community knows of incidents (such as rapidly propagating viruses without destructive payloads and the active compromise of many networkconnected computers that can be used to launch a variety of distributed attacks) that are consistent with the likely tactics of intelligent hostile parties. and it knows of intelligent parties whose intentions toward the united states are hostile. these factors do not constitute a logical proof of a highend cyberthreat, but they do underlie the committee™s judgment that the vulnerabilities with which it is concerned are not merely theoretical.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.what is at stake? 49offensive operations in cyberspacešespecially against u.s. national interestsšmay offer considerable advantages for adversaries.38 the united states is, as a nation, far more dependent on information technology than its potential adversaries are, and thus a hostile nationstate might well seek to exploit this asymmetry. preparations for conducting cyberwarfare can be undertaken with minimal visibility, thus complicating the efforts of the united states to gather intelligence on the scope and nature of potential threats. finally, in cyberwarfare, the advantages tend to favor attackers over defenders. for these reasons, adversary nationstates are likely to have strong incentives for developing capabilities to exploit weaknesses in the u.s. cybersecurity posture.how likely is it that a highend cyberthreat will emerge? today, it is primarily knowledge of the threat emanating from hobbyists and sophisticated hackers that is widespread and that largely drives present cybersecurity efforts. losses from these threats are known, though not with any kind of precision, and widespread reallife experience demonstrates their signicance to business operations. by contrast, information about the highend threat emanating from organized crime and hostile nationstates is not easily available. with a lack of specic information, the highend threat can be easily dismissed by systems owners and operators as one that is hypothetical and undocumented (at least in a public sense); such owners and operators thus might contend that there is an inadequate business case for the further investments that would be needed to counter the highend threat. however, some analysts, notably those with access to classied information, assert in the strongest possible terms that the highend cyberthreat is here today, that it is growing, and that the incidents reported publicly only hint at the severity and magnitude of that threat.39 although the committee on improving cybersecurity research in the united states itself contained members with varying views on the seriousness or immediacy of the nationstate threat, the committee as a whole concluded that highlevel threatsšspawned by motivated, sophisticated, and wellresourced adversariesšcould increase very quickly on a very 38 military analysts in the people™s republic of china are known to be considering such matters. see, for example, l. qiao and x. wang, unrestricted warfare, 1999, pla literature and arts publishing house, beijing, people™s republic of china; available at http://www.terrorism.com/documents/trcanalysis/unrestricted.pdf.39 see, for instance, bill gertz, ﬁchinese hackers prompt nave college site closure,ﬂ the washington times, november 30, 2006, available at http://www.washtimes.com/ national/200611301030495042r.htm; dawn s. onley and patience wait, ﬁred storm rising: dod™s efforts to stave off nationstate cyberattacks begin with china,ﬂ government computer news, august 21, 2006, available at http://www.gcn.com/print/2525/417161.html; and nathan thornburgh, ﬁinside the chinese hack attack,ﬂ time, august 25, 2005, available at http://www.time.com/time/nation/article/0,8599,1098371,00.html.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.50 toward a safer and more secure cyberspaceshort timescale, potentially leading to what some dub a ﬁdigital pearl harborﬂ (that is, a catastrophic event whose occurrence can be unambiguously traced to ˚aws in cybersecurity)šand that the nation™s it vendors and users (both individual and corporate) would have to respond very quickly if and when such threats emerged. therefore, a robust research program that addresses both current and future possible threats driven by the highend threat is necessary to provide the technological underpinnings of such a response. moreover, it suggests a research agenda that is necessarily broader and deeper than would otherwise be the case if the threat were known with high condence to be limited to that posed by hackers and ordinary criminals. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.513 improving the nation™s  cybersecurity posturegiven the scope and nature of the cybersecurity threat as discussed in chapter 2, what should the nation do about it? this chapter begins with a committeedeveloped ﬁcybersecurity bill of rightsﬂ (section 3.1) that characterizes what it would mean for cyberspace to be safe and secure. building on this characterization, section 3.2 describes the information technology (it) landscape into which cybersecurity research ˚ows. it describes the twin needs for research that would lead to improved deployment of today™s cybersecurity technologies and the emergence of new cybersecurity technologies in the future. section 3.3 explains the rationale for cybersecurity research, placing such research in the larger context of the cybersecurity problem, and section 3.4 concludes the chapter with ve principles that should guide that research. 3.1 the cybersecurity bill of rightsthe cybersecurity bill of rights (cbor) describes a vision for a safe and more secure cyberspace. in the most general sense, individual users, organizations, and society at large are entitled to use and rely on information technologies whose functionality does not diminish even when these technologies are under attack. although there are 10 provisions in the cbor that articulate desirable security properties of information technology writ large, it is likely that as information technology evolves, other provisions will need to be added and the existing ones modied.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.52 toward a safer and more secure cyberspace3.1.1 introduction to the cybersecurity bill of rightsthe cybersecurity bill of rights is a statement of security goals or expectationsšwhat is it that society should reasonably expect in the way of security in its information technologies, and what should technologists and organizations strive to achieve? since many or most of today™s information technologies are not designed or implemented with the goals of the cbor in mind, the cybersecurity bill of rights also illustrates the enormous gap between what information technologies should do and what they now do. serious efforts directed at achieving these goals would greatly decreasešbut never eliminatešthe security risks associated with using information technology. as importantly, the availability of information technologies designed and implemented with these goals in mind would expand the policy choices available to society about the functionality that it deserves and should expect from its technologies.as a statement of expectations, the security provisions of the cbor are neither absolute nor unconditional. when an information technology system or component does not embed a provision that should be provided, users have a right to know that the technology they are using does not meet that expectation so that they can act accordingly. moreover, the way in which the provisions of the cbor are realized for any given system will depend on many contextual factors. for example, the cybersecurity needs of an individual end user are different from those of a bank or the electric power grid. in constructing the cbor, the committee derived the provisions by considering four categories that are important to cybersecurity. these categories involve the following: (1) holistic systems properties relating to availability, recoverability, and control of systems; (2) traditional security properties relating to condentiality, authentication, and authorization; (3) crosscutting properties such as safe access to information, condent invocation of important transactions, including those that will control physical devices, and knowledge of what security will be available; and (4) matters relating to jurisprudence: that is, appropriate justice for victims of cyberattack. (some of the categories and provisions within them overlap.)finally, the cbor is usercentric, but ﬁuserﬂ should be interpreted broadly. users include individual end users, organizations, andšmost importantlyšprograms and system components that use (invoke or call on) other information technology systems or components. but taken together and viewed overall, the cbor should be seen as a societal bill of rights, because the use of information technology in society has ramications reaching far beyond a single individual or organization. because critical societal functions depend on information technology, the security toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 53of the information technologies involved in those functions is of paramount importance.3.1.2 the provisions of the cybersecurity bill of rightsthe rst three provisions relate to holistic systems properties including availability, recoverability, and control of systems:i.  availability of system and network resources to legitimate users.users of information technology systems (from individuals to groups to society, and including programs and applications1) should be able to use the computational resources to which they are entitled and systems that depend on those resources. attacks intended to deny, seriously degrade, or reduce the timeliness of information technologybased services should not succeed.ii. easy and convenient recovery from successful attacks.because cybersecurity measures will sometimes fail, recovery from a security compromise will be necessary from time to time. when necessary, such recovery should be easy and convenient for individual users, systems administrators, and other operators. recovery is also an essential element of survivability and fault tolerance. recovery should be construed broadly to include issues related to longterm availability in the face of ﬁbit rotﬂ and incompatible upgrades.2iii.  control over and knowledge of one™s own computing environment.users expect to be in control of events and actions in their own immediate environment, where control refers to taking actions that in˚uence what happens in that environment. knowledge refers to knowing how things that are happening compare to user expectations about what is happening. to the extent that events and actions are occurring that are not initiated by the user, a breach in security may be occurring. 1 groups and societies are effectively aggregations of users, and computer programs and applications are proxies of users.2 ﬁbit rotﬂ refers to the phenomenon in which a program (or features of a program) will suddenly stop working after a long time, even though ﬁnothing has changedﬂ in the environment. in fact, the environment has changed, although perhaps in subtle and unnoticed ways.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.54 toward a safer and more secure cyberspacethe next three provisions relate to the traditional security properties of condentiality, authentication (and its extension, provenance), and authorization:iv.  condentiality of stored information and information exchange. one central function of information technology is the communication and storage of information. just as most people engage in telephone conversations and store paper les with some reasonable assurance that the content will remain private even without their taking explicit action, users should expect electronic systems to communicate and store information in accordance with clear condentiality policies and with reasonable and comprehensible default behavior. systems for application in a particular problem domain should be able to support the range of privacy policies relevant to that domain.as for systems that communicate with one another, some or all of the information that they pass among themselves belongs to someone, at least in the sense that someone has a condentiality interest in it. in other cases, the information may not be particularly sensitive, but there is almost never any afrmative reason for that information to be shared with other parties unbeknownst to the owneršsuggesting that external access to normally condential data should normally be done with explicit permission. as a particularly important way of ensuring condentiality, responsible parties should have the technical capability to delete or expunge selected information that should not be permanently stored. this is important in the context of removing erroneous personal information from cyberspace. today, electronically recorded information can be difcult to remove from the databases in which it is stored. for example, ﬁdeletedﬂ information may be retained in a backupšand it should be possible to delete information from backups as well as from the original recording medium.whether or notšin a particular situationšit is appropriate to delete all instances of a given datum is a policy issue. but even if a policy choice were made that asserted that such deletions were appropriate, the technology of today is largely incapable of supporting that choice.v. authentication and provenance. mutual authentication of the senders and receivers involved in an information exchange is an essential part of maintaining contoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 55dentiality, since passing information to the wrong party or device is an obvious way in which condentiality might be violated. as an extension of traditional authentication, users should have access to reliable and relevant provenance (that is, knowledge of the responsible parties) for any electronic information or electronic event, commensurate with their need for security and assurance.provision v does not rule out anonymous speech, for examplešbut it does mean that any given user should be able to refuse to accept information from or participate in events initiated by anonymous parties. information originating from untrustworthy sources should not be able to masquerade as information originating from known trustworthy sources. when information has no explicit provenance, users and their software agents should be able to determine this fact and make decisions regarding trust accordingly. information sources and events in cyberspace should be construed broadly, so that deliberately hostile or antisocial sources and actions should have provenance as well. provenance should be reliable and nonrepudiable.vi.  the technological capability to exercise negrained control over the ˚ow of information in and through systems.authorized parties should be technically able to exercise negrained control over ˚ows of information. for example, it should be technologically possible for an individual to conduct certain online transactions with technologically guaranteed anonymity, and for putative partners in such transactions to decline to participate if anonymity is offered. it should also be technologically possible for individuals to know who collects what information about them. and, they should have the technical ability to restrict the types, amounts, and recipients of personal information. access privileges determine the functionality that an information technology system or network offers to a user or other entity. circumstances may change in such a way that privileges need to be revokedšfor example, when a user is terminated or determined to be a threat, or when a service has been compromised. revocation of privileges at various granularities is a necessary security capability.whether or not individuals should have legal rights to exercise negrained control over the ˚ow of information in and through systems is a policy issue. but even if a policy choice were made that asserted the propriety of such legal rights, the technology of today is largely incapable of supporting that choice.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.56 toward a safer and more secure cyberspacethe next three provisions relate to crosscutting properties of systems such as safe access to information, condent invocation of important transactions, including those that will control physical devices, and knowledge of what security will be available:vii.  security in using computing directly or indirectly in important applications, including nancial, health care, and electoral transactions and realtime remote control of devices that interact with physical processes.security is especially important in certain kinds of transactions, such as those involving nancial, medical, or electoral matters. further, computational devices increasingly control physical processes as well as information processes, and such devices may have the potential to act dangerously in the physical world. it is thus especially important that cyberattackers be precluded from impairing the safe operation of physical devices.in this context, security refers to the availability, integrity, appropriate privacy controls on information, sufcient guarantees about the identities of involved parties to prevent masquerading and other attack, and nonrepudiation guarantees so that parties can be assured of their interactions.viii.  the ability to access any source of information (e.g., email, web page, le) safely.today, many security vulnerabilities are exploited as the result of some user action in accessing some source of information. in this context, safe access means that nothing unexpected happens and that nothing happens to compromise the expected condentiality, integrity, and availability of the user™s information or computational resources. safety cannot be assured with 100 percent certainty under any circumstances (for example, a user may take an allowed but unintended action that results in compromised condentiality), but with proper attention to technology and to usability, the accessing of information can be made much less risky than it is today.ix.  awareness of what security is actually being delivered by a system or component.users generally have expectations about the securityrelevant behavior of a system, even if these expectations are implicit, unstated, or unfounded. system behavior that violates these expectations is often responsible for security problems. thus, users have a right to know what security policies and assurances are actually toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 57being delivered by a system or component so that they can adjust their own expectations and subsequent behavior accordingly. as an illustration, nonexpert users need to know how security settings map onto policies being enforced, as well as how settings need to be specied in order to achieve a particular policy.such awareness also implies the ability to make informed judgments about the degree of security that different systems provide. if individuals and organizations are to improve their cybersecurity postures, they need to know how to compare the security of different systems and the impact of changes on those systems. to a great degree, quantitative risk assessments, rational investment strategies, and cybersecurity insurance all depend on the ability to characterize the security of systems. the last provision relates to justice:x. justice for security problems caused by another party.in most of society, there is an expectation that victims of harm are entitled to some kind of justicešsuch as appropriate punishment of the perpetrator of harm. but today in cyberspace, there is no such expectation owing largely to the difculty of identifying perpetrators and the lack of a legal structure for pursuing perpetrators. in addition, individuals who are victimized or improperly implicated because of cybersecurity problems should have access to due process that would make them whole. society in its entirety should also have the ability to impose legal penalties on cyberattackers regardless of where they are located. 3.1.3 concluding commentsevery set of rights has responsibilities associated with it. because the cbor denes a set of security expectations for information technology, it has implications for every party that creates or uses information technology. designers and developers of information technologies for end users will have obligations to produce systems whose security behavior is consistent with the cbor unless otherwise explicitly noted to be inconsistent. designers and developers of information technology systems and components on which other systems depend are also affected, because the cbor denes for system designers and developers a set of expectations for what can happen on either side of an interface between two components. that is, because information technology systems today are crafted and deployed in a modular fashion, the cbor also has design and implementation implications for the functionality of toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.58 toward a safer and more secure cyberspacethose two components, regardless of the side of the interface on which each resides. to the extent that the cbor can be relied on to set security expectations for components developed by different parties, the result will be a more orderly world that supports composability of the building blocks in the it infrastructure. the cbor would also require end users to be sufciently knowledgable to ascertain whether and to what extent the information technology that they use in fact delivers on the cbor™s security obligations.how should the goals of the cbor be achieved? as the discussion in the remainder of this report indicates, a new way of thinking about securityša drastic cultural shiftšwill be necessary regarding the ways in which secure systems are designed, developed, procured, operated, and used. in the long run, such a shift will entail new directions in education, training, development practice, operational practice, oversight, liability laws, and government regulation. 3.2 realizing the visioncompared to what is available today, the foregoing vision of a secure cyberspace is quite compelling. however, for two distinct though related reasons, we are a long way away from meeting this goal. the rst reason is that there is much about cybersecurity technologies and practices that is known but not put into practice. as an example, according to the senior information security ofcer at a major nancial institution, the codication and dissemination of best practices in cybersecurity policy at the level of the chief executive ofcer or the chief information ofcer have been particularly challenging, because incentives and rewards for adopting best practices are few. box 3.1 indicates the limited scope of threats against which certain common commercial products defend.the second reason is that even assuming that everything known today was immediately put into practice, the resulting cybersecurity posturešthough it would be stronger and more resilient than it is todayšwould still be inadequate against today™s threats, let alone tomorrow™s. closing this gapša gap of knowledgešwill require research, as discussed below.3.3 the necessity of researchframing the issue of necessary research requires understanding the larger context of which such research is a part. today, the vast majority of actual cybersecurity efforts is devoted to a reactive catchup game that xes problems as they are discovered (either in anticipation of attack as toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 59the good guys nd them or in response as the bad guys nd them). moreover, end users often do not avail themselves of known cybersecurity technologies and practices that could signicantly improve their individual resistance to cyberattack of various kinds. for example, they often do not install patches to systems that could close known security holes in their design, implementation, or conguration. vendors of it products and services often do not use technologies and development practices that could reduce the number of security vulnerabilities embedded in them. for example, they do not use known technologies that might prevent the buffer over˚ows that continue to account for roughly half of all box 3.1 what firewalls and antivirus products protect againstfirewallsšwhether implemented with hardware or softwarešare used to prevent malicious or unwanted trafc from reaching protected resources or to allow only authorized trafc (e.g., from specic network addresses). antivirus products generally scan les or le systems looking for known computer viruses or malicious code, usually relying on a frequently updated virus denition le.below is a short list of some of the vulnerabilities that rewalls and antivirus products attempt to address:worms. both rewalls and antivirus products can be used to identify and slow (or halt) the propagation of computer worms, which, unlike viruses, can act independently once released. viruses. antivirus products can scan for, remove, and often repair damage done by viruses obtained from opening infected emails or other means.trojans. antivirus products can identify and remove trojan horse software (i.e., malicious software that masquerades as legitimate software), while rewalls can be used to spot and prevent network trafc associated with trojan horse software.vulnerability scans. firewalls can be used to prevent automated port scanning tools from outside the rewall from uncovering open ports on (or otherwise learning about) potentially vulnerable machines behind the rewall.denialofservice attacks. firewalls can often assist in mitigating denialofservice attacks by blocking trafc from offending network addresses.insider misbehavior. firewalls are often used to block specic kinds of network trafc (or requests) from those inside the rewall as wellšfor example, by not allowing trafc over specic ports used by applications deemed inappropriate for a given setting (e.g., p2p lesharing applications in an ofce setting) or by blocking access to specic web sites that an organization has deemed inappropriate for a given setting.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.60 toward a safer and more secure cyberspacecomputer emergency response team coordination center (cert/cc) advisories.3reactive efforts are essential because it is impossible to replace the existing it infrastructure in one fell swoop (and even if it were possible, we would not know what to replace it with) and because the security of any given system will require upgrading throughout its life cycle as new threats emerge and new vulnerabilities are found. still, continuously reacting to cybersecurity problemsšwithout new approaches to developing and deploying a stronger and more secure technological foundationšis a poor way to make progress against escalating or new threats. by their very nature, reactive efforts are incremental; vulnerabilities that ˚ow from basic system design and architectural concepts cannot be xed by such means, and often patching introduces additional security ˚aws. a focus on patching also tends to draw interest and attention away from more fundamental architectural problems that cannot be simply xed with a patch.security addons will always be necessary to x individual security problems as they arise, and r&d is needed to develop improved tools and techniques for dealing with nearterm xes (e.g., conguration management, audit, patch management), but ultimately there is no substitute for system or networkwide security that is architected from initial design through deployment, easy to use, and minimally intrusive from the user™s standpoint.furthermore, for all practical purposes, the cybersecurity risks (the combination of adversary threats and technical or procedural vulnerabilities) of the future are impossible to predict in any but the most general terms. because it is difcult to anticipate innovation (which changes the architecture or implementation underlying specic systems) and to comprehend complex systems (which makes understanding the systems in place today very hard), it is almost guaranteed that unforeseen applications will result in unforeseen security concerns and human beings will be unable to anticipate all of the security issues that accompany complex systems. in short, in many ways security is an emergent property of a complex it system that depends on both the underlying system architecture and its implementation. consider, for example, the relatively common practice of building an application on top of an offtheshelf operating system. although the applications builder can in principle know all there is to know about the application, its relationship to the operating system is known only through the various application programming interfaces (apis) of the operating system. but since the inputoutput behavior of 3 for more on the cert/cc advisories, see http://www.cert.org/advisories/.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 61these apis is usually incompletely specied (e.g., it may not be documented how the system responds when inputs are provided that are not of the expected variety), the overall relationship between application and operating system cannot be known completely. much research is needed on the properties, practices, and disciplines to drive this emergencešjust as research in the nascent complexity sciences is addressing similar problems of understanding emergence in other problem domains characterized by sensitive dependence on initial conditions.this does not mean that it is impossible to identify areas of focus, but it does imply that within those areas of focus the nation™s research strategy should seek to develop a broad and diverse technological foundation that would enable more rapid responses to new and currently unforeseen threats as they emerge as well as to yield unanticipated advances.as for the character of the research needed, both traditional and unorthodox approaches will be necessary. traditional research is problemspecic, and there are many cybersecurity problems for which good solutions are not known. (a good solution to a cybersecurity problem is one that is effective, is robust against a variety of attack types, is inexpensive and easy to deploy, is easy to use, and does not signicantly reduce or cripple other functionality in the system of which it is made a part.) research is and will be needed to address these problems.but problembyproblem solutions, or even problemclass by problemclass solutions, are highly unlikely to be sufcient to close the gap by themselves. unorthodox, cleanslate approaches will also be needed to deal with what might be called a structural problem in cybersecurity research now, and these approaches will entail the development of new ideas and new points of view that revisit the basic foundations and implicit assumptions of security research. addressing both of these reasons for the lack of security in cyberspace is important, but it is the secondšclosing the knowledge gapšthat is the primary goal of cybersecurity research and the primary focus of this report. 3.4 principles to shape the research agendathis section describes a set of interrelated principles that the committee believes should shape the research agenda. some are principles intended to drive specic components of the research agenda, while others are intended to change the mindset with which the agenda is carried out. individually, none of these principles is new, but in toto they represent the committee™s best understanding of what should constitute a sound philosophical foundation for cybersecurity research.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.62 toward a safer and more secure cyberspace3.4.1 principle 1: conduct cybersecurity research as though its application will be important.3.4.1.1 the rationale the committee™s view on conducting cybersecurity research is shaped by two essential points. first, much of today™s cybersecurity research is limited to creating ﬁbuilding blocksﬂ for security that could be incorporated into various applications. today™s dominant perspective is that basic research entails the creation or inprinciple demonstration of a new cybersecurity concept or mechanism, and that bringing this concept or mechanism into realworld use is somehow less demanding or intellectually less worthy than the ﬁbasicﬂ or ﬁfundamentalﬂ research that led to the innovative concept or mechanism.but research that results only in a proof of concept or a feasibility demonstration is often far from practical application, and an innovation, original though it may be, is not a tool or a system. indeed, there is an enormous distance between the development of a good idea and its widespread use (whether by end users or by system designers and developers), and traversing that distance often entails additional research activity that is signicant in its own right. for example, the committee believes that the likelihood of a good idea succeeding in the marketplace is enhanced if it is scalable, adoptable, and composable.a scalable idea works on realworld problems of reasonable size in reasonable time.an adoptable idea is one whose benets can easily be seen by its potential users, and it can be easily used by parties other than its creator.a composable idea can be integrated into a system without necessitating fullscale reanalysis and retesting. composability is desirable because any system of signicant size is usually developed in pieces by separate groups and at separate times, and is complicated by the fact that users may congure a system so that different components are active. without composability, the ﬁcompleteﬂ system must be tested as one big and maximally complex lump. much additional research may be necessary to make a given concept scalable, composable, and adoptable. however, such considerations are often not taken seriously in the basic science stage, as many researchers believe they can defer such issues until the technology is ready for delivery. this attitude has inhibited the development of practical tools even though the underlying science had promise.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 63formal verication methods provide an example. formal methods such as model checking have been successfully applied to hardware on an economically signicant scale. nonetheless, much of the early work on formal verication methods for software resulted in technologies that required large amounts of training or radical changes to engineering practice, or that were based on unrealistic ideas about requirements gathering, or that were too costly and unable to interoperate, or that required hardware capabilities for undertaking verication that were not easily available. in many cases, these methods could operate only when the entire program to be veried was available, and could not operate on welldened subunits. researchers on formal methods did not have the benet of effective metrics for assessing the benets that might ˚ow from adopting these methods. in recent years, some of these problems have been overcome, with the result that formal methods do have some genuine utility in software development, and the use of formal methods is a hotbed of activity in research and in companies like microsoft. one example is microsoft™s static driver verier (sdv) tool. the sdv is a static codeanalysis tool for formally verifying that device drivers comply with various application programming interface rules about how the driver interfaces with an operating system. box 3.2 provides more details. second, the committee believes that a view of cybersecurity research as being devoted only to the creation of building blocks is far too narrow, and is one of the primary reasons that the benets of past cybersecurity research have not been fully realized. while the creation of new cybersecurity building blocks is an essential and primary component of any research agenda in cybersecurity, the span of cybersecurity research must be broadened in several interrelated dimensions to encompassšindeed, embracešthe application of known and future approaches to specic application domains, development of cybersecurity tools for every part of the it life cycle, and multidisciplinary approaches to cybersecurity problems.a related point is that focusing research attention on questions of deployment will help to reduce the time needed to deploy innovations. largescale deployments of any kind inevitably take a long time, and even small reductions in lead time could make a big difference should the need arise for the deployment of cybersecurity measures in an emergency.in addition, it is important for research to consider and decision makers to take into account the enormous political pressures to ﬁdo somethingﬂ in the wake of a catastrophe. indeed, it is not unknown that measures hastily put into place after a disaster have subsequently proven to be ineffective, or even worse, harmful. it is thus appropriate to focus some research attention on how to sensibly deploy emergency measures toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.64 toward a safer and more secure cyberspaceunder such circumstances. in addition, because postcatastrophe deployments often change the boundaries of what is politically feasible, research should also consider what sensible things might be done if and when such opportunities arise.3.4.1.2 new computing paradigms and applications domainscybersecurity problems in an environment of largescale distributed computing, embedded computing, batch processing and mainframe combox 3.2 lessons learned from the technologytransfer effort  associated with microsoft™s static driver verifierthe static driver verier (sdv) systematically analyzes windows device drivers against a set of rules that dene what it means for a device driver to properly interact with the windows operation system kernel. the sdv is based on a codeanalysis engine known as slam, which incorporates type checking, model checking, program analysis, and automated deduction. slam was the result of research to create methodologies and tools to check the correctness of partial specication of program behavioršspecically the use of the device driver interface to the windows kernel. the sdv provides an automated environment for running slam that incorporates rules for the windows driver model; a wellarticulated environment model of the windows kernel and other drivers; scripts to congure the sdv with driverspecic information; and a graphical user interface to present results. intellectually, the primary lesson learned in the transition from the slam research to the working sdv tool is to focus on problems rather than technology. the problem must be recognized as critical by product developers and end users, and not just technically interesting to researchers. it must also be bounded sufciently to provide a tangible solution with measurable success criteria. all parties involved, including product developers, end users, and researchers, must see clearly the link between the problem at hand and the solutionšwhich is what the implementation of the sdv framework made clear in the case of the slam research.from an organizational point of view, the primary lesson is that leaving the scaling up of a prototype research as an exercise for the development group is likely to result in lack of acceptance and adoption, since the development group will not necessarily make the ﬁobviousﬂ leap from technology solution to useful and viable product. successful technology transfer is, at least in part, a research team responsibility, and involves considerable effort on the part of researchers to understand how product teams operate, how they allocate resources, how they make decisions, and what it takes to turn a prototype into a product.source: adapted from thomas ball, byron cook, vladimir levin, and sriram k. rajamani, slam and static driver verier: technology transfer of formal methods inside microsoft, microsoft research technical report, msrtr200408, january 2004.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 65puting, desktop computing, web services (see section 8.4.3), and pervasive computing (see section 8.4.4) may be different from one another, even when meaningful analogs among these paradigms can be identied. contexts of use matter as well: internet services support http web browsing and remote login, but the security issues associated with web browsing are far greater than those associated with remote login simply because the former is used far more than the latter. at a deep technical level, the types of attacks that may be launched in these different environments are not so different from one another, and the fundamental research issues needed to address these attacks were identied in the early 1970s and have not changed signicantly since then. but these environments do differ signicantly in their exposure to a wide range of anonymous attackers. as a result, the opportunities for launching different types of attack do vary signicantly, suggesting the need for research on the scope and nature of those opportunities in the different environments and how those opportunities might be limited or circumscribed.but what is less well appreciated is that similar issues apply in applications domains, and understanding how a particular cybersecurity approach is relevant to a particular application domain can be and often is as challenging as developing that approach in the rst place. cybersecurity research is most likely to be relevant to an application domain if it is conducted with deep knowledge of and insight into the issues that arise in that domain. an explicit consideration of the application domain serves both to inspire cybersecurity research based on the security problems associated with the domain and to increase the likelihood that the research will be used to solve real problems in the application domain. examples of such application domains include cybersecurity for health care applications (see section 8.4.1) and for the electric power grid (see section 8.4.2).since most cybersecurity researchers do not have domainspecic expertise, collaboration with others who do becomes a sine qua non for success in this kind of research. moreover, these collaborations must be undertaken as enterprises among coequalsšand in particular the computer scientist as cybersecurity researcher cannot view the problem domain as ﬁmerelyﬂ the applications domain, must refrain from jumping to conclusions about the problem domain, must be willing to learn the facts and contemplate realities and paradigms in the problem domain seriously, and must not work solely on the rened abstract problem that characterizes much of computer science research. similarly, applications experts cannot view security as a mere annoyance to be brushed aside as quickly as possible, must refrain from jumping to conclusions about cybersecurity, must be willing to learn the facts and contemplate realities toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.66 toward a safer and more secure cyberspaceand paradigms in cybersecurity seriously, and must not work in complete isolation from the abstractions of computer science research.the need for collaboration between domain experts and cybersecurity specialists can also be seen in the issue of how to make security functionality more usable by nonspecialists. addressed at greater length in section 6.1, the research area of usable security entails the development of security technologies that can be integrated seamlessly into how people already do their work, thereby increasing the likelihood that they will actually be used in everyday life.3.4.1.3 attending to security throughout a system™s life cyclefor many years, tensions between security and other desirable system attributes or functionality have generally not been resolved in ways that have improved security. while these kinds of tension may never disappear, and indeed in some cases (e.g., in the absence of a serious observed threats) it can make good economic and business sense to resolve these tensions in such a manner, the committee believes strongly that cybersecurity must be regarded as an essential element throughout the entire life cycle of an it product or service and that cybersecurity efforts should focus much more on creating inherently secure products. security products that retroactively attempt to apply security to systems will always be needed, and securityrelated afterthoughts will always be necessary (simply because the good guys cannot anticipate every possible move by the bad guys), but the reality of security is that it is important in every phase of a system™s life cycle, including requirements specication, design, development and implementation, testing and evaluation, operations, maintenance, upgrade, and even retirement. whether different foci of research are needed to address security issues in each of these phases is an open question, but it is clear that the needs for security are not identical in each phasešand so researchers and funders should be open to the idea of phasespecic cybersecurity research. as an example of thinking implied by this principle, consider a search for alternatives to the notion of perimeter defense, which has been a common approach to security for many years. under perimeter defense, what is ﬁinsideﬂ a vital information system or network is protected from an outside ﬁattackerﬂ who may try to ﬁpenetrateﬂ the system to gain access to or acquire control over data and system resources on the inside. perimeter defense has the major advantage of being scalable. that is, defensive perimeters such as rewalls are deployed because it is much easier to secure one machine than several thousand. scalability comes from the fact that adding a machine inside the perimeter imposes little if any additional burden on the defense. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 67however, in practice, perimeter defense is often implemented in ways that require no changes to systems on the inside of the perimeter. that is, defensive efforts are focused primarily on one perimeteršthe perimeter that encompasses the entire systemšwith little defensive attention to components inside. (one familiar example of this is a rewall that protects all of the computers on a local area networkšwith the result that an attacker who compromises the rewall has rendered all of the computers on that network vulnerable.) the mindset of perimeter defense is that ﬁthose inside the perimeter need not be concerned about security in any signicant way.ﬂin a world of increasingly interconnected and numerous computers and networks, this notion of perimeter defense is no longer realistic (if it ever was). denitions of ﬁinsideﬂ and ﬁoutsideﬂ change ˚uidly with business strategy and partnerships, and yesterday™s business partner may be tomorrow™s insider threat. in coalition operations involving u.s. military forces, an ally today may be an adversary tomorrowšimplying that the implementation of security policies must be continually updated, since the categories of friend and foe are essentially arbitrary. the growing proliferation of wireless technologies and the reliance on employees working from home or while traveling makes the notion of ﬁoutsideﬂ a slippery concept. trusted insiders may also be compromised. most importantly, when the perimeter is breached (whether by virtue of a technical weakness such as buffer over˚ow or an operational weakness such as an employee being bribed to reveal a password), the attacker has entirely free rein inside.3.4.1.4 engaging a multidisciplinary approach to cybersecurityany meaningful cybersecurity research program should be understood as a highly multidisciplinary enterprise for two related reasons. first, adversaries can focus their efforts on any weak point in a system, whether that weak point is technological, organizational, sociological, or psychological. interactions related to these factors may in˚uence the technical agenda (e.g., consideration of how to make audit trails valuable evidence in court proceedings), but a technical agendašthat is, one limited to technology alonešwill almost certainly be insufcient to solve realworld problems. put differently, cybersecurity must be regarded holistically if realworld security is to be improved. second, solutions to cybersecurity problems may also have some relationship to law enforcement authorities, insurance companies, customers, users, international governments, and so on. solutions developed without recognizing these relationships may prove to be unusable for practical purposes in the face of realworld deployment problems. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.68 toward a safer and more secure cyberspaceunderstanding why certain ﬁtechnically promisingﬂ research may be inadequate or unusable is necessarily multidisciplinary, involving matters of economics, law and regulation, organization theory, psychology, and sociology, as well as deep insights into technology. to illustrate, consider that applicationsinpractice require attention to a range of nontechnical issues: persuading operators and developers to adopt best practices in areas such as patch management, conguration management, audit and logging, and organizational and management processes. also in scope are software engineering techniques, architecture, and network conguration through awareness, codication of those practices, and education programs.developing the value proposition and business case for the deployment of security, which includes economic models and measurement techniques to facilitate models for estimating costs and benets, testbeds, eld trials, and case studies to demonstrate and assess value when in situ. this point is discussed further in section 6.4.easing changes to established business and engineering practices that may be associated with the introduction of cybersecurity functionality.ensuring that the applicationinpractice is organizationally scalable. for example, a small pilot program to test the suitability of a security application may not reveal the range of exceptional cases that must be handled when the application is deployed throughout the organization. largescale deployments are almost always organizationally stressful, and procedures tested in a smallscale environment often need debugging and optimization when an application is scaled up.providing incremental benet for incremental deployment. it is difcult to adopt cybersecurity solutions that provide benet only when they are widely deployed, if only because the burden of proof is large under these circumstances. conversely, ﬁearly graticationﬂšthat is, when an increment of additional work or attention to cybersecurity resulting in some relatively immediate reward that relates to the current ongoing development activityšcan obviate or dramatically reduce the need to use a managerimposed ﬁforce majeureﬂ that coerces the development team into adopting a security measure or technology.ensuring robustness against changing attacks. a specic cybersecurity solution may protect against the exploitation of a particular vulnerability, but be rendered ineffective by a small change in the nature of that exploit. unless the nature of that change can be kept secret (a very hard condition to meet), such ﬁsolutionsﬂ will be rendered ineffective very quickly as attackers seek to counter it.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 69managing tensions between security and operational resilience. although certain tensions between security and other desirable properties have often been noted (e.g., tensions between security and ease of use), the connection between security and organizational resilience has often been overlooked. for example, operational compliance with any given organizational security policy is facilitated by standardization, but standardization often increases the risk of commonmode failures. security is often enhanced by physical securityšsensitive activities being undertaken in protected locationsšbut organizational resilience in crisis often relies on distribution of processing and mobile access to information. security is enhanced by encryption and tight access controls, but in crisis or emergency, decryption keys and the small number of individuals with the necessary access are often unavailable.these points suggest a need for problemoriented research in addition to traditional disciplineoriented research. the latter tends to characterize research in most computer science academic departments and universities. problemoriented research, on the other hand, will require close collaboration among cybersecurity researchers and experts from other disciplines, and as suggested in section 3.4.1.2, collaborations with application domain experts as well.because of the stovepiped nature of many academic disciplines, including computer science, special efforts will be needed to nurture problem interdisciplinary efforts that will encourage and incentivize the interaction of academic cybersecurity researchers with researchers with other specialties, both in university departments and nonacademic research institutes.3.4.2 principle 2: hedge against uncertainty  in the nature of the future threat.it is unknown if a signicant highend cyberthreat will in fact emerge into public view, and judgments about the likelihood of such an emergence vary. but given the potential damage that such an adversary could in˚ict, it seems prudent to take a balanced approach that provides a hedge against that possibility. in the absence of substantial evidence about the existence of a highend threat, a ﬁmanhattan projectﬂ approach to strengthening the nation™s cybersecurity posture is likely unwarranted because of the enormous cost of such an effort, to say nothing of how one would know if such an effort had been successful. at the same time, it is reasonable to construct a research agenda in cybersecurity that is both broader and deeper than might be required if toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.70 toward a safer and more secure cyberspaceonly lowend threats were at issue. the development of stronger technological foundations for computer and network security is, of course, highly relevant to threats across the entire spectrum, but because a highend threat may well be capable of undertaking more sophisticated or more subtle technical attacks, the technological research agenda must be correspondingly deeper. because highend adversaries would be perfectly happy to target nontechnological elements of a system, a broader research agenda will be needed to develop approaches to defending those elements as well.note that this hedge against uncertainty refers to r&d rather than deployment. that is, deployment costs are often largešand organizations may have sound reasons for not deploying various cybersecurity measures if a threat has not obviously manifested itself. whatever the downside of a reactive approach, decision makers are often reactive because they do not see the value of certain proactive measures in the absence of a manifestly obvious threat. but it is undeniable that should a threat become manifestly obvious, decision makers will want to have options ﬁoff the shelfﬂ that can be deployed in a short time so as to minimize the possible damagešand the very purpose of r&d is to expand the number of options available should highend threats materialize.of course, the term ﬁshortﬂ is a relative onešand the time in question is ﬁshorter than would be possible if r&d had not been conducted.ﬂ research results cannot be deployed instantaneously, nor on a wide scale in less than a few years. in the face of the sudden emergence of a manifestly obvious highend threat, it might be possible to deploy research prototypes on a scale of a few weeks or months for critical systems (and the likelihood of being able to do so would be higher if research had been conducted in accordance with principle 1). for the majority of other systems, an emergency response might well be to put into place draconian procedural and technical measures that would mitigate the highend attack but also would have the effect of drastically reducing the operational utility of those systems. as relevant research results were deployed to protect these systems, the original mitigation measures could be scaled back and the original operational utility of these systems gradually returned to normal.3.4.3 principle 3: ensure programmatic  continuity in the research agenda.a research program should support a substantial effort in areas with a long time horizon for payoff. such support would necessarily extend for timescales long enough to make meaningful progress on hard problems (5 years to investigate a promising technology is not unreasonable, toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 71for example) and in sufcient amounts that new technologies might be developed and tested in reasonably realistic operating environments.4 historically, such investigations have been housed most often in academia, which can conduct research with fewer pressures for immediate delivery on a bottom line.this is not to say that longterm research cannot have intermediate milestones, though the purpose of such milestones should be to make midcourse corrections rather than go/nogo decisions that can demoralize researchers and make them overly conservative. longterm research can also involve collaboration early and often with technology transition stakeholders and can engage both academic and industrial actors, even in the basic science stages. those stakeholders get an early planning view and an opportunity to in˚uence the course of research and development. private industry has important roles to play as well. today, industrial research and development in cybersecurity is a signicant component of the nation™s cybersecurity r&d efforts, and meaningful cybersecurity results emerge from this effort. in addition, industrial participation, or at least the involvement of product developers, is essential for developing prototypes and mounting eld demonstrations. thus, it is highly appropriate to support academic/industrial cooperation in efforts oriented toward development. possible synergies between government and academia/private industry deserve support as well. for example, both the national institute of standards and technology and the national security agency (nsa) have very deep expertise regarding certain aspects of cybersecurity that could be valuable in the conduct of even unclassied research undertaken in the civilian sector. finally, program managersšand more importantly, fundersšof such research must be tolerant of research directions that do not appear to promise immediate applicability. research programs, especially in it, are oftenševen generallyšmore ﬁmessyﬂ than research managers would like. the desire to terminate unproductive lines of inquiry is understandable, and sometimes entirely necessary, in a constrained budget environment. on the other hand, it is frequently very hard to distinguish between (a) a line of inquiry that will never be productive and (b) one that may take some time and determined effort to be productive. while an intel4 note, however, that it is a long way from a prototype or conceptual proofofprinciple that is usable only by its creator to a tool that might be tested or deployed in such environments. in his classic text the mythical manmonth, frederick p. brooks, jr. (reading, mass.: addisonwesley, 1995) estimates that the effort necessary to create a programming systems product from a program is an order of magnitude larger than for creating the program itself.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.72 toward a safer and more secure cyberspacelectually robust research program must be expected to go down some blind alleys occasionally (indeed, even frequently), the current political environment punishes such blind alleys as being of type a, with little apparent regard for the possibility that they might be type b.5most researchers, regardless of eld, would argue that programmatic continuity is needed in any research program. but such continuity is particularly relevant to cybersecurity. as noted in section 2.6, cybersecurity problems will endure as long as bad guys have incentives to compromise the security of itbased systems and networks, and thus cybersecurity research will always be needed to deal with some new and unanticipated exploit. moreover, because the underlying technology evolves (quite rapidly, in fact), solutions crafted in one it environment may well no longer be useful in a different one. 3.4.4 principle 4: respect the need for breadth in the research agenda.one of the most frequent complaints from federal policy makers regarding reports that lay out research agendas is that such reports do not set priorities. policy makers argue that in an environment of limited nancial resources, they look to the research community to set priorities so that limited dollars can be spent most effectively. the committee understands the persuasiveness of and rationale for this perspective, and for this reason it has identied important areas of research focus (grouped into six categories and explored in detail in chapters 4 through 9). nevertheless, the committee is still quite concerned that an excessively narrow focus on priority areas would result in other important topics or promising avenues being neglected and that such a focus would run signicant risks of leaving the nation unprepared for a rapidly changing cybersecurity environment.broad research agendas are often regarded as ﬁpeanut butter spreadﬂša pejorative term used among policy makers to refer to spreading resources more or less evenly among a large number of programs or efforts. it is pejorative because the implication is that no thought has gone into deciding whether these efforts are necessary at all, and that the ﬁspreadﬂ simply re˚ects the unwillingness of the agenda™s creators to set priorities. but the need for breadth in this case re˚ects the simple reality that there is no silver bullet, or even a small number of silver bullets, that will solve ﬁthe cybersecurity problem,ﬂ and a broad research agenda helps to ensure that good ideas are not overlooked.5 national research council. 2003. information technology for counterterrorism: immediate actions and future possibilities. the national academies press, washington, d.c.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 73the basic canon of priority setting is that one identies the most important problems and allocates resources preferentially to solve those problems. ﬁimportanceﬂ is related both to frequency of occurrence and by severity of the impact of any given occurrence. but severity is very difcult to ascertain in general, as it depends on the details and the signicance of particular systems attacked. as for frequency, the deployment of a defense that addresses the threat of a highly likely attack a may well lead to a subsequent increase in the likelihood of a previously less likely attack b. in short, adversaries may not behave in accordance with expectations that are based on static probability distributions, and thus it is very difcult to prioritize a research program for countering terrorism in the same way that one might, for example, prioritize a program for dealing with natural disasters. (section 6.4.2 describes some of the issues related to quantitative risk assessment.)the fundamental asymmetry between attacker and defender also affects the research agenda. the cyberdefender must be successful at every point in the defense, whereas the cyberattacker must succeed only once. even if one vulnerability is closed, a serious attacker will seek another vulnerability to exploit. this search will cost the attacker some time, and this other vulnerability may be more difcult to exploitšthese factors make it worthwhile to close the original vulnerability. but there is no sense in which closing the original vulnerability can be said to be a nal solution.consequently, new exploitations of vulnerabilities can appear with very little warning. in many cases, these new exploitations are merely variations on a theme, and the defense can easily adjust to the new attack. but in other cases, these new exploitations are qualitatively different, of a nature and character not seen before. although such cases are hopefully rare, it is safe to bet that the rate at which they appear will not be zero. if qualitatively new attacks suddenly manifest themselves, considerable time will elapse before techniques and technologies can be developed to handle them. conducting a broad research agenda is likely to decrease signicantly the time needed to develop countermeasures against these new attacks when they appear.cybersecurity is analogous to developing a defense against con men and fraudsters, who are innitely creative or at least very clever in adapting old attacks to new technologies. there are, of course, basic highend principles that enable one to guard against con men and fraudsters. but it is not realistic to imagine that there is one or even a few promising approaches that will prevent or even substantially mitigate fraud in the future. rather, a good cybersecurity research agenda is more like a good strategy for investing in the stock market, both of which are driven by a multitude of unpredictable factors. although there are basic principles toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.74 toward a safer and more secure cyberspaceof investment about which any investor should be cognizant, ultimately a diversied portfolio of investments is a foundational element of any good overall strategyševen if one is willing to place bets on a few very promising stocks.these comments should not be taken to mean that all topics are equally important in an absolute sensešonly that the committee believes that any topdown articulation of research priorities is bound to be overtaken by events (e.g., new technologies, new threats, new kinds of exploits) very rapidly. rather, decisions about what areas or topics should be supported should be made by those in a position to respond most quickly to  the changing environmentšnamely, the research constituencies that provide peer review and the program managers of the various research supporting agencies.finally, notions of breadth and diversity in the cybersecurity research agenda should themselves be interpreted broadly. a great deal of experience suggests that cybersecurity considerations are not easily separated from other engineering issues, and in particular go handinhand with the design and engineering of secure systems. cybersecurity is relevant to research, education, and practice for every component of the it system™s development life cycle, and research focused on these components should itself embrace a cybersecurity aspect to such work. by tacitly accepting the current practice of fencing off ﬁcybersecurity researchﬂ into separate programs, research programs have a tendency to focus primarily on those areas that are more ﬁpurely cybersecurityﬂ such as crypto protocols and other aspects of cybersecurity that are easily separable from basic system design and implementation and to neglect those areas where integration is a principal concern, principally the engineering of software and cyberphysical systems. integrating cybsersecurity considerations into related programs (software and systems engineering, operating systems, programming languages, networks, web applications, and so on) will help program managers in these areas to better integrate cybsersecurity into the overall engineering context. because of the inability to achieve perfection in our engineering practices, it is necessary to pursuešsimultaneouslyša wide variety of kinds of interventions across a broad front. section 4.3 (software and systems assurance) explores these comments in somewhat greater depth.3.4.5 principle 5: disseminate new knowledge and artifacts.university research activities are an important crucible in which new ideas are discovered, invented, and explored. but publication or other dissemination of research results is also a sine qua non for progress, and it is necessary to disseminate results to a community broader than one™s toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.improving the nation™s cybersecurity posture 75own research laboratory for research to have a wide impact, a point that argues for cybersecurity research to be conducted on an unclassied basis as much as possible. as argued in the 2005 cybersecurity report of the president™s information technology advisory committee, ﬁthe vast majority of the nation™s academic researchers do not hold the security clearances needed to undertake classied work [and furthermore] many research universities regard classied research as incompatible with their role as producers of knowledge beneting society as a whole.ﬂ6 almost by denition, broad dissemination is incompatible with classied research. (see also the discussion in section b.6.4.2.)as a logical point, it would be possible to expand the number of researchers with clearances or to make more research unclassied. although the committee acknowledges that there are some circumstances in which cybersecurity research should be classied, it also believes that these circumstances are narrow. furthermore, a signicant expansion in the number of cybersecurity researchers with security clearances does not seem feasible in the present political environment. thus, the committee believes that as a general rule, the nation would be better served by the latter course.a related point is that the cybersecurity expertise and talent developed in the classied world are likely to be quite relevant to the civilian world, and mechanisms to share ideas about technology and training with the public, and in particular with students in the eld, should be encouraged. a notable example of such technology sharing is the national security agency™s domestic technology transfer program, established for the purpose of openly sharing nsadeveloped technologies with the nonnsa community.7 nsa has also worked with at least one major it vendor to enhance the security of its products.8 it is also worth noting that the declassifying of cybersecurity research has some parallels with the 1990s debatešsince resolvedšover restricting the export of strong cryptography.9 under the restrictions in effect at the time, the export of products embedding strong cryptography and 6 president™s information technology advisory committee, cyber security: a crisis of prioritization, national coordination ofce for information technology research and development, washington, d.c., february 2005; available at www.nitrd.gov/pitac/ reports/20050301cybersecurity/cybersecurity.pdf.7 for more information on this program, see http://www.nsa.gov/techtrans/index.cfm for a description of the program and http://www.nsa.gov/techtrans/techt00004.cfm for a description of tools and technologies related to cybersecurity.8 alec klein and ellen nakashima, ﬁfor windows vista security, microsoft called in pros,ﬂ washington post, january 9, 2007; available at http://www.washingtonpost.com/wpdyn/content/article/2007/01/08/ar2007010801352.html.9 national research council. 1996. cryptography™s role in securing the information society, kenneth w. dam and herbert s. lin (eds.). national academy press, washington, d.c.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.76 toward a safer and more secure cyberspaceeven basic knowledge about cryptography was regulated as part of the munitions trade. at the time, the rationales on export related to the undesirability of allowing strong cryptography to be used by adversaries, both nationstates and criminals. but ultimately, decision makers realized that national security and economic security needs could not be easily disentangled, and that in an increasingly globalized economic environment, the ability of commercial rms to keep information condential was important indeed. beginning in the late 1990s, export controls on cryptography were gradually relaxed. finally, in many elds of scientic research, the primary means of disseminating discoveries is through presentations at conferences or publication in refereed journals. however, in much of computer science, important research knowledge and insight are conveyed through the dissemination and use of software and/or hardware artifacts. because cybersecurity has experimental dimensions, those responsible for academic human resource decisions should expect that signicant research results in cybersecurity will be broadly disseminated through software downloads at least as much as through published papers or conference proceedings.1010 national research council. 1994. academic careers for experimental computer scientists and engineers. national academy press, washington, d.c. this report addresses the con˚ict between standard academic metrics of merit (i.e., published papers) and the practice of disseminating artifacts as is done in experimental computer science.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.77part iian illustrative research agendapart ii presents one illustrative research agenda that might be constructed to further the goals described in part i. the rst four categories of the agenda (chapters 4 through 7) constitute what might be regarded as primary areas of programmatic focus. the fth category (chapter 8) is a broad, crosscutting category that draws on parts of the rst four categories but focuses on bringing them together in the context of specic cybersecurity problems. the sixth category (chapter 9) contains what might be regarded as speculative ideas that are worth some effort to investigate. table ii.1 maps the topics described in this research agenda to the provisions of the cybersecurity bill of rights described in chapter 3.the areas of programmatic focus were selected on the basis of their high importance. (here, ﬁimportanceﬂ is characterized by the enormous benets that would ˚ow from progress in those domains.) fruitful results in these areas would signicantly increase the security of the technology base on which information technology (it) applications are built and increase the likelihood of incorporating those results into these applications. such incorporation, on a large scale, would in turn signicantly improve the nation™s cybersecurity posture. at the same time, the research described within each area of programmatic focus is fairly broad. this breadth is based on the committee™s belief that excessive priority setting in the cybersecurity research eld runs signicant risks of leaving the nation unprepared for a rapidly changing cybersecurity environment. the committee cautions policy makers strongly against neglecting potentially important topics in their quest to prioritize research. moreover, because there will always be incentives and opportunities to attack itbased systems in the future, it would be a profound mistake to believe that the committee™s specic research agendašor any other one that any other group might createšcan ﬁsolve the problemﬂ of cybersecurity once and for all. the committee emphasizes that the specic topics covered in part ii constitute representative examples of possible research within the four areas of programmatic focus and not specic priorities within those areas.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.78 toward a safer and more secure cyberspacetable ii.1 mapping research topics to the 10 provisions of  the committee™s cybersecurity bill of rightsresearch topicsaiavailabilityiirecoveryiiicontrolivconfidentialityvauthenticationviflow controlviiapplicationviiiaccessixawarenessxjusticecategory 1šblocking and limiting the impact of compromise4.1secure design, development, and testingxxxxxxxxxx4.2graceful degradation and recoveryxxxxx4.3software and systems assurancexxxxxxxcategory 2šenabling accountability5.1attributionxxxxxx5.2misuse and anomaly detection systemsxxxx5.3digital rights managementxxxcategory 3špromoting deployment6.1usable security xxxxx6.2exploitation of previous workxxxxxxxxxx6.3cybersecurity metricsxxx6.4the economics of cybersecurityxxxxxxxxx6.5security policiesxxxxxxxxcategory 4šdeterring wouldbe attackers and penalizing attackers7.1legal issues related to cybersecurityxxxxxxxxxx7.2honeypotsxxx7.3forensicsxxxtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.an illustrative research agenda  79table ii.1 mapping research topics to the 10 provisions of  the committee™s cybersecurity bill of rightsresearch topicsaiavailabilityiirecoveryiiicontrolivconfidentialityvauthenticationviflow controlviiapplicationviiiaccessixawarenessxjusticecategory 1šblocking and limiting the impact of compromise4.1secure design, development, and testingxxxxxxxxxx4.2graceful degradation and recoveryxxxxx4.3software and systems assurancexxxxxxxcategory 2šenabling accountability5.1attributionxxxxxx5.2misuse and anomaly detection systemsxxxx5.3digital rights managementxxxcategory 3špromoting deployment6.1usable security xxxxx6.2exploitation of previous workxxxxxxxxxx6.3cybersecurity metricsxxx6.4the economics of cybersecurityxxxxxxxxx6.5security policiesxxxxxxxxcategory 4šdeterring wouldbe attackers and penalizing attackers7.1legal issues related to cybersecurityxxxxxxxxxx7.2honeypotsxxx7.3forensicsxxxtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.80 toward a safer and more secure cyberspaceresearch topicsaiavailabilityiirecoveryiiicontrolivconfidentialityvauthenticationviflow controlviiapplicationviiiaccessixawarenessxjusticecategory 5šillustrative crosscutting problemfocused research areas8.1security for legacy systemsxxxxxxxxx8.2the role of secrecy in cyberdefensexxxxxxxxx8.3insider threatsxxxx8.4security in nontraditional computing environments and in the context of usexxxxxxxxxx8.5secure network architecturesxxxxxxxx8.6attack characterizationxxxxx8.7coping with denialofservice attacksxxxx8.8dealing with spamxxxxcategory 6šspeculative research9.1a cyberattack research activityxxxxxxxxxx9.2biological approaches to securityxxxxxxxxx9.3using attack techniques for defensive purposesxxxxxxxxx9.4cyberretaliationxxxxxxxxxxtable ii.1 continuednote: some imprecision in this mapping is freely acknowledged, in the sense that a number of the specic mappings mentioned are the result of judgment calls that might be different if a different set of individuals were to make those judgments. as presented in chapter 3 of this report, the 10 provisions of the cybersecurity bill of rights are as follows: i. availability of system and network resources to legitimate users. ii. easy and convenient recovery from successful attacks. iii. control over and knowledge of one™s own computing environment. iv. condentiality of stored information and information exchange.  v. authentication and provenance.  vi. the technological capability to exercise negrained control over the ˚ow of information in and through systems.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.an illustrative research agenda  81research topicsaiavailabilityiirecoveryiiicontrolivconfidentialityvauthenticationviflow controlviiapplicationviiiaccessixawarenessxjusticecategory 5šillustrative crosscutting problemfocused research areas8.1security for legacy systemsxxxxxxxxx8.2the role of secrecy in cyberdefensexxxxxxxxx8.3insider threatsxxxx8.4security in nontraditional computing environments and in the context of usexxxxxxxxxx8.5secure network architecturesxxxxxxxx8.6attack characterizationxxxxx8.7coping with denialofservice attacksxxxx8.8dealing with spamxxxxcategory 6šspeculative research9.1a cyberattack research activityxxxxxxxxxx9.2biological approaches to securityxxxxxxxxx9.3using attack techniques for defensive purposesxxxxxxxxx9.4cyberretaliationxxxxxxxxxx vii. security in using computing directly or indirectly in important applications, including nancial, health care, and electoral transactions, and realtime remote control of devices that interact with physical processes. viii. the ability to access any source of information (e.g., email, web page, le) safely. ix. awareness of what security is actually being delivered by a system or component. x. justice for security problems caused by another party.athe numbering of each research topic corresponds with the numbering of the section on that topic in chapter 4 through chapter 9.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.83the goal of requirements in category 1 of the committee™s illustrative research agenda is that of ensuring that the impact of compromises in accountability or system security is limited. this broad categoryšblocking and limiting the impact of compromisešincludes secure information systems and networks that resist technical compromise; technological and organizational approaches that reveal attempts to compromise information technology (it) components, systems, or networks; containment of breaches; backup and recovery; convenient and ubiquitous encryption that can prevent unauthorized parties from obtaining sensitive or condential data; system lockdowns under attack; and so on.a basic principle underlying category 1 is that of defense in depth. a great deal of experience in dealing with cybersecurity issues suggests that no individual defensive measure is impossible to circumvent. thus, it makes sense to consider defense in depth, which places in the way of a cyberattacker a set of varied hurdles, all of which must be penetrated or circumvented if the cyberattacker is to achieve its goal. when different hurdles are involved, an attacker must have access to a wider range of expertise to achieve its goal and also must have the increased time and resources needed to penetrate all of the defenses.4.1 secure design, development, and testingthe principle that security must be a core attribute of system design, development, and testing simply re˚ects the point that it is more effective 4category 1šblocking and limiting  the impact of compromisetoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.84 toward a safer and more secure cyberspaceto reduce vulnerabilities by not embedding them in a system than to x the problems that these vulnerabilities cause as they appear in operation.1 vulnerabilities can result from design, as when system architects embed security ˚aws in the structure of a system. vulnerabilities also result from ˚aws in developmentšgood designs can be compromised because they are poorly implemented. testing for security ˚aws is necessary because designers and implementers inevitably make mistakes or because they have been compromised and have deliberately introduced such ˚aws. 4.1.1 research to support design4.1.1.1 principles of sound and secure designin the past 40+ years, a substantial amount of effort has been expended in the (relatively small) security community to articulate principles of sound design and to meet the goal of systems that are ﬁsecure by design.ﬂ on the basis of examinations of a variety of systems, researchers have found that the use of these principles by systems designers and architects correlates highly to the security and reliability of a system. box 4.1 summarizes the classic saltzerschroeder principles, rst published in 1975, that have been widely embraced by cybersecurity researchers. systems not built in accord with such principles will almost certainly exhibit inherent vulnerabilities that are difcult or impossible to address. these principles, although well known in the research community and available in the public literature, have not been widely adopted in the mainstream computer hardware and software design and development community. there have been efforts to develop systems following these principles, but observable longterm progress relating specically to the multitude of requirements for security is limited. for example, research in programming languages has resulted in advances that can obviate whole classes of errorsšbuffer over˚ows, race conditions, offbyone errors, format string attacks, mismatched types, dividebyzero crashes, and unchecked procedurecall arguments. but these advances, important though they are, have not been adopted on a sufcient scale to make these kinds of error uncommon.nonetheless, the principles remain validšso why have they had so little impact in the design and development process? in the committee™s 1 for example, soo hoo et al. determined empirically that xing security defects after deployment cost almost seven times as much as xing them before deployment. furthermore, security investments made in the design stage are 40 percent more costeffective than similar investments in the development stage. see k. soo hoo, a. sudbury, and a. jaquith, ﬁtangible roi through secure software engineering,ﬂ secure business quarterly, quar ter 4, 2001. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 85view, three primary reasons account for the lack of such impact: the mismatch between these principles and realworld software development environments, shortterm expenses associated with serious adherence to these principles, and potential con˚icts with performance.4.1.1.1.1 the mismatch with current development methodologiesone reason for the lack of impact is the deep mismatch between the principles of system design in box 4.1 and realworld software development environments. even a cursory examination of the principles discussed in box 4.1 suggests that their serious application is predicated on a thorough and deep understanding of what the software designers and architects are trying to do. to apply these principles, software designers and architects have to know very well and in some considerable detail just what the ultimate artifact is supposed to do.the software development model most relevant to this state of affairs is often called the waterfall model, explicated in considerable detail by boehm.2 this model presumes a linear development process that proceeds from requirements specication, to design, to implementation/coding, to integration, to testing/debugging, to installation, to maintenance, although modied versions of the model acknowledge some role for feedback between each of these stages and preceding ones. but despite its common use in many software development projects (especially large ones), the waterfall model is widely viewed as inadequate for realworld software development. the reason is that manyšperhaps even mostšsoftware artifacts grow organically. the practical reality is that large software systems emerge from incremental additions to small software systems in ways entirely unanticipated by the designers of the original system. if the original system is successful, users will almost certainly want to add new functionality. the new functionality desired is by denition unanticipatedšif the designers had known that it would be useful, they would have included it in the rst place.indeed, it is essentially impossible in practice for even the most operationally experienced it applications developers to be able to anticipate in detail and in advance all of a system™s requirements and specications. (sometimes users change their minds about the features they want, or even worse, want contradictory features! and, of course, it is difcult indeed to anticipate all potential uses.) thus, system requirements and specications are always inherently incomplete, even though they underlie and drive the relationships among various modules and their inter2 barry boehm, software engineering economics, prenticehall, englewood cliffs, n.j., 1981.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.86 toward a safer and more secure cyberspacebox 4.1 the saltzerschroeder principles of secure  system design and developmentsaltzer and schroeder articulate eight design principles that can guide system design and contribute to an implementation without security ˚aws:economy of mechanism: the design should be kept as simple and small as possible. design and implementation errors that result in unwanted access paths will not be noticed during normal use (since normal use usually does not include attempts to exercise improper access paths). as a result, techniques such as linebyline inspection of software and physical examination of hardware that implements protection mechanisms are necessary. for such techniques to be successful, a small and simple design is essential. failsafe defaults: access decisions should be based on permission rather than exclusion. the default situation is lack of access, and the protection scheme identies conditions under which access is permitted. the alternative, in which mechanisms attempt to identify conditions under which access should be refused, presents the wrong psychological base for secure system design. this principle applies both to the outward appearance of the protection mechanism and to its underlying implementation. complete mediation: every access to every object must be checked for authority. this principle, when systematically applied, is the primary underpinning of the protection system. it forces a systemwide view of access control, which, in addition to normal operation, includes initialization, recovery, shutdown, and maintenance. it implies that a foolproof method of identifying the source of every request must be devised. it also requires that proposals to gain performance by remembering the result of an authority check be examined skeptically. if a change in authority occurs, such remembered results must be systematically updated. open design: the design should not be secret. the mechanisms should not depend on the ignorance of potential attackers, but rather on the possession of specic, more easily protected, keys or passwords. this decoupling of protection mechanisms from protection keys permits the mechanisms to be examined by many reviewers without concern that the review may itself compromise the safeguards. in addition, any skeptical users may be allowed to convince themselves that the system they are about to use is adequate for their individual purposes. finally, it is simply not realistic to attempt to maintain secrecy for any system that receives wide distribution. separation of privilege: where feasible, a protection mechanism that requires two keys to unlock it is more robust and ˚exible than one that allows access to the presenter of only a single key. the reason for this greater robustness and ˚exibility is that, once the mechanism is locked, the two keys can be physically separated and distinct programs, organizations, or individuals can be made responsible for them. from then on, no single accident, deception, or breach of trust is sufcient to compromise the protected information. least privilege: every program and every user of the system should operate using the least set of privileges necessary to complete the job. this principle reduces the number of potential interactions among privileged programs to the minimum for correct operation, so that unintentional, unwanted, or improper uses of privilege are less likely to occur. thus, if a question arises related to the possible misuse of a privilege, the number of programs that must be audited is minimized. least common mechanism: the amount of mechanism common to more than one user and depended on by all users should be minimized. every shared mechanism (especially one involving shared variables) represents a potential information path between users and must be designed with great care to ensure that it does not unintentionally compromise security. further, any mechanism serving all users must be certied to the satisfaction of every user, a job presumably harder than satisfying only one or a few users. psychological acceptability: it is essential that the human interface be designed for ease of use, so that users routinely and automatically apply the protection mechanisms correctly. more generally, the use of protection mechanisms should not impose burdens on users that might lead users to avoid or circumvent themšwhen possible, the use of such mechanisms should confer a benet that makes users want to use them. thus, if the protection mechanisms make the system slower or cause the user to do more workševen if that extra work is ﬁeasyﬂšthey are arguably ˚awed.source: adapted from j.h. saltzer and m.d. schroeder, ﬁthe protection of information in faces, inputs, state transitions, internal state information, outputs, and exception conditions.put differently, the paradox is that successful principled development requires a nontrivial understanding of the entire system in its ultimate form before the system can be successfully developed. systems designers need experience to understand the implications of their design choices. but experience can be gained only by making mistakes and learning from them. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 87box 4.1 the saltzerschroeder principles of secure  system design and developmentsaltzer and schroeder articulate eight design principles that can guide system design and contribute to an implementation without security ˚aws:economy of mechanism: the design should be kept as simple and small as possible. design and implementation errors that result in unwanted access paths will not be noticed during normal use (since normal use usually does not include attempts to exercise improper access paths). as a result, techniques such as linebyline inspection of software and physical examination of hardware that implements protection mechanisms are necessary. for such techniques to be successful, a small and simple design is essential. failsafe defaults: access decisions should be based on permission rather than exclusion. the default situation is lack of access, and the protection scheme identies conditions under which access is permitted. the alternative, in which mechanisms attempt to identify conditions under which access should be refused, presents the wrong psychological base for secure system design. this principle applies both to the outward appearance of the protection mechanism and to its underlying implementation. complete mediation: every access to every object must be checked for authority. this principle, when systematically applied, is the primary underpinning of the protection system. it forces a systemwide view of access control, which, in addition to normal operation, includes initialization, recovery, shutdown, and maintenance. it implies that a foolproof method of identifying the source of every request must be devised. it also requires that proposals to gain performance by remembering the result of an authority check be examined skeptically. if a change in authority occurs, such remembered results must be systematically updated. open design: the design should not be secret. the mechanisms should not depend on the ignorance of potential attackers, but rather on the possession of specic, more easily protected, keys or passwords. this decoupling of protection mechanisms from protection keys permits the mechanisms to be examined by many reviewers without concern that the review may itself compromise the safeguards. in addition, any skeptical users may be allowed to convince themselves that the system they are about to use is adequate for their individual purposes. finally, it is simply not realistic to attempt to maintain secrecy for any system that receives wide distribution. separation of privilege: where feasible, a protection mechanism that requires two keys to unlock it is more robust and ˚exible than one that allows access to the presenter of only a single key. the reason for this greater robustness and ˚exibility is that, once the mechanism is locked, the two keys can be physically separated and distinct programs, organizations, or individuals can be made responsible for them. from then on, no single accident, deception, or breach of trust is sufcient to compromise the protected information. least privilege: every program and every user of the system should operate using the least set of privileges necessary to complete the job. this principle reduces the number of potential interactions among privileged programs to the minimum for correct operation, so that unintentional, unwanted, or improper uses of privilege are less likely to occur. thus, if a question arises related to the possible misuse of a privilege, the number of programs that must be audited is minimized. least common mechanism: the amount of mechanism common to more than one user and depended on by all users should be minimized. every shared mechanism (especially one involving shared variables) represents a potential information path between users and must be designed with great care to ensure that it does not unintentionally compromise security. further, any mechanism serving all users must be certied to the satisfaction of every user, a job presumably harder than satisfying only one or a few users. psychological acceptability: it is essential that the human interface be designed for ease of use, so that users routinely and automatically apply the protection mechanisms correctly. more generally, the use of protection mechanisms should not impose burdens on users that might lead users to avoid or circumvent themšwhen possible, the use of such mechanisms should confer a benet that makes users want to use them. thus, if the protection mechanisms make the system slower or cause the user to do more workševen if that extra work is ﬁeasyﬂšthey are arguably ˚awed.source: adapted from j.h. saltzer and m.d. schroeder, ﬁthe protection of information in for these reasons, software development methodologies such as incremental development, spiral development, and rapid prototyping have been created that presume an iterative approach to building systems based on extensive prototyping and strong user feedback. doing so increases the chances that what is ultimately delivered to the end users meets their needs, but entails a great deal of instability in ﬁthe requirements.ﬂ moreover, when such ﬁdesign for evolvabilityﬂ methodologies are used with modularity, encapsulation, abstraction, and welldened toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.88 toward a safer and more secure cyberspaceinterfaces, development and implementation even in the face of uncertain requirements are much easier to undertake. the intellectual challengešand thus the research questionšis how to fold security principles into these kinds of software development processes. 4.1.1.1.2 the shortterm expensea second reason that adherence to the principles listed in box 4.1 is relatively rare is that such adherence isšin the short termšalmost always more expensive than ignoring the principles. if only shortterm costs and effort are taken into account, it isštodayšsignicantly more expensive and timeconsuming to integrate security from the beginning of a system™s life cycle, compared with doing nothing about security and giving in to the pressures of shorttimeline deliverables. this reality arises from a realworld environment in which software developers often experience false starts, and there is a substantial amount of ﬁplaying aroundﬂ that helps to educate and orient developers to the task at hand. in such an environment, when many artifacts are thrown away, it makes very little sense to invest up front in that kind of adherence unless such adherence is relatively inexpensive. the problem is further compounded by the fact that the transition from the ﬁplaying aroundﬂ environment to the ﬁserious developmentﬂ environment (when it makes more sense to adhere to these principles) is often unclear.an example is the design of interfaces between components. highly constrained interfaces increase the stability of a system incorporating such components. at the same time, that kind of constraining effort is inevitably more expensive than the effort involved when an interface is only lightly policed. in this context, a constrained interface is one in which calling sequences and protocols are guaranteed to be valid, meaningful, and appropriate. guarantees must be provided that malformed sequences and protocols will be excluded. providing such guarantees requires resources and programming that are unnecessary if the sequences and protocols are simply assumed to be valid.a second example arises from cooperative development arrangements. in practice, system components are often developed by different parties. with different parties involved, especially in different organizations, communications difculties are inevitable, and they often include incompatibilities among interface assumptions, the existence of proprietary internal and external interfaces, and performance degradations resulting from the inability to optimize across components. this point suggests the need for welldened and carefully analyzed specications for the constituent components, but it is obviously easier and less expensive to simply assume that specications are unambiguous.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 89in both of these examples, an unstructured and sloppy design and implementation effort is likely to ﬁworkﬂ some of the time. although such an effort can provide insight to designers and offer an opportunity for them to learn about the nature of the problem at hand, transitioning successfully to a serious production environment generally requires starting over from scratch rather than attempting to evolve an unstructured system into the production system. but in practice, organizations pressed by resources and schedule often believešincorrectly and without foundationšthat evolving an unstructured system into the production system will be less expensive. later, they pay the price, and dearly.4.1.1.1.3 the potential con˚ict with functionality and ease of usea third important reason that adherence to the principles in box 4.1 is relatively rare is the potential con˚ict with functionality. in many cases, introducing cybersecurity to a system™s design slows it down or makes it harder to use. implementing the checking, monitoring, and recovery needed for secure operation requires a lot of computation and does not come for free. at the same time, commodity productsšout of which many critical operational systems are builtšare often constrained by limited resources and cost, even while the market demands everhigher performance and functionality. 4.1.1.2 the relevant researchin light of the issues above and the historically wellknown difculties in conventional computer system development (and especially the software), research and development (r&d) should be undertaken aimed at adapting the design principles of box 4.1 for use in realistic and common software development environments that also do not make excessive sacrices for performance or cost. today, there are well established methodologies for designtocost and designforperformance but no comparable methodologies for designing systems in such a way that security functionality can be implemented systematically or even that the security properties of a system can be easily understood. indeed, security reviews are generally laborious and timeconsuming, a fact that reduces the attention that can be paid to security in the design process. in general, the design process needs to consider security along with performance and cost. one essential element of a ﬁdesignforsecurity evaluationﬂ will be approaches for dealing with system complexity, so that genuinely modular system construction is possible and the number of unanticipated interactions between system components is kept to a bare toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.90 toward a safer and more secure cyberspaceminimum, as discussed in box 4.1. in any given case, the right balance will need to be determined between reducing the intrinsic complexity of a system (e.g., as expressed in the realistic requirements for security, reliability, availability, survivability, human safety, and so on) and using architectural means that simplify the interfaces and maintainability (e.g., through abstraction, encapsulation, clean interface design, and design tools that identify and enable the removal of undesired interactions and incompatibilities and hindrances to composability). this point also illustrates the need to address security issues in the overall architecture of applications and not just as addedon security appliances or components to protect an intrinsically unsafe design. another important element is the tracing of requirements to design decisions through implementation. that is, from a security standpoint (as well as for other purposes, such as system maintenance), it is important to know what code (or circuitry) in the nal artifact corresponds to what requirements in the system™s specication. any code or circuitry that does not correspond to something in the system specication is inherently suspect. (see also section 4.1.3.1.) today, this problem is largely unsolved, and such documentationšin those rare instances when it does existšis generated manually. apart from the laborintensiveness of the manual generation of such documentation, a manual approach applied to a complex system virtually guarantees that some parts of the code or circuitry will remain untraced to any requirement, simply because it has been overlooked. moreover, for all practical purposes, a manual process requires that the original designers and implementers be intimately involved, since the connections between requirement and code or circuitry must be documented in near real time. once these individuals are no longer available for consultation, these connections are inevitably lost.with respect to the issue of shortterm expense, r&d might develop both technical and organizational approaches to reducing shortterm costs. from a technical perspective, it would be desirable to have tools that facilitate the reuse of existing design work. from an organizational perspective, different ways of structuring design and development teams might enable a more costeffective way of exploiting and leveraging existing knowledge and good judgment.finally, it is worth developing design methods that proactively anticipate potential attacks. threatbased design is one possible approach that requires the identication and characterization of the threats and potential attacks, nding mechanisms that hostile parties may employ to attack or gain entry to a computing system, and redesigning these mechanisms to eliminate or mitigate these potential security vulnerabilities. a further challenge is that of undertaking such design in a way that does not comtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 91promise designtocost and designforperformance goals, such as high performance, low cost, small footprint, low energy consumption, and ease of use. 4.1.2 research to support development4.1.2.1 hardware support for securitytoday, systems developers embody most of the security functionality in software. but hardware and computer architecture can also support more secure systems. in the past two to three decades, computer and microprocessor architects have focused on improving the performance of computers. however, in the same way that processing capability has been used in recent years to improve the user experience (e.g., through the use of computeintensive graphics), additional increases in hardware performance (e.g., faster processors, larger memories, higher bandwidth connections) may well be usable for improving security. compared with softwarebased security functionality, hardwarebased support for security has two primary advantages. one advantage is that new hardware primitives can be used to make security operations fast and easily accessible, thus eliminating the performance penalty often seen when the same functionality is based in software and increasing the likelihood that this functionality will be used. a second advantage is that it tends to be more trustworthy, because it is much harder for an attacker to corrupt hardware than to corrupt software. some critics of implementing security in hardware believe that security is in˚exible and cannot adapt to changes in the environment or in attacker patterns. but hardware support for security need not imply that the entire security function desired must be implemented in hardware. research is needed to determine the fundamental hardware primitives or features that should be added to allow ˚exible use by software to construct more secure systems.hardware support can be leveraged in several ways. first, faster computing allows software to do more checking and to do more encrypting. increases in raw processing performance can be large enough to allow more modular, more trustworthy software to run at acceptable speedsšthat is, specialpurpose software tricks used to enhance performance that also violated canons of secure program construction are much less necessary than they were in the past. second, specic checking capability can be added to the processor itself, supporting a kind of ﬁhardware reference monitor.ﬂ this is especially easy to contemplate at the moment, given the current trend to multicore architecturesšsome cores can be used for checking other cores. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.92 toward a safer and more secure cyberspacethe checks possible can be quite sophisticated, monitoring not only what actions are being requested but checking those actions in the context of past execution.3 such checking can be used to ensure that applications, middleware, and even privileged operating system software do not perform actions that violate security policies. hardware can also provide a safety net for potentially harmful actions taken by software, such as executing code that should be considered data. since the hardware processor executes all software code, it can provide valuable ﬁdefenseindepthﬂ support in preventing software from compromising system security and integrity.third, securityspecic operations can be added into hardware. for example, processors can be designed in which data that are written to memory are encrypted leaving the processor and decrypted when they return to the processor. or, instructions can be stored in memory in encrypted form and then decrypted by the hardware just prior to execution. some proposals for hardwareimplemented security operations even go so far as to make the operations of these special operations invisible to other computations that occur on that processor.hardware can also implement a trustworthy and protected memory for storing secrets (typically, a small number). these secrets cannot be retrieved by software (so they are guaranteed to remain secret no matter what software is running); rather, they are usedšfor example, to encrypt datašby invoking hardware primitives that use those secrets and return the result. this approach was rst implemented in smart cards some years ago, but smart cards have often proved slow and inconvenient to use. smart cards were followed by a succession of other positionings of the functionality, including outboard secure coprocessors and modied microprocessors. the desirability of any given positioning depends, at least in part, on the nature of the threat. for example, if the hardware support for security appears on additional chips elsewhere on a board, then an attacker with physical access to the computer board might succeed without very sophisticated equipment. placing the support on the microprocessor chip itself signicantly complicates such attacks.an example of embedding securityspecic features into hardware to protect a user™s information is provided by lee et al.,4 who have developed a secretprotected (sp) architecture that enables the secure and con3 paul williams and eugene h. spafford, ﬁcupids: an exploration of highly focused, coprocessorbased information system protection,ﬂ computer networks, 51(5): 12841298, april 2007.4 r. lee, p. kwan, j.p. mcgregor, j. dwoskin, and z. wang, ﬁarchitecture for protecting critical secrets in microprocessors,ﬂ proceedings of the 32nd international symposium on computer architecture, ieee computer society, washington, d.c., pp. 213, june 2005.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 93venient protection of a user™s sensitive information stored in an online environment, by providing hardware protection of critical secrets such as cryptographic keys belonging to a given user. in the sp architecture, keys follow their users and are not associated with any particular device. thus, a given user can securely employ his or her keys on multiple devices, and a given device can be used by different users. the sp architecture is based on several elements. one element is the existence of a concealed execution mode in an spenhanced microprocessor, which allows a process to execute without its state being tampered with or observed by other processes, including the main operating system running on the processor. it includes a very efcient mechanism for runtime attestation of trusted code. a second element is a trusted software module running in concealed execution mode that performs the necessary protected computations on users™ secret keys, thus protecting all key information (the keys themselves, the computations, and intermediate states) from observation and tampering by adversaries. a third element is a chain of user cryptographic keys that are needed for accessing, and the protecting by encryption of any amount of sensitive information. this chain is stored in encrypted form (and thus can be resident anywhere), but it can be decrypted with a master key known only to the user. similarly, user data, programs, and les encrypted by these keys can be stored safely in public online storage and accessed over public networks. a fourth element is a secure input/output (i/o) channel that enables the user to pass the master key to the sp hardware and the trusted software module without the risk that other modules may intercept the master key. (sp architecture also requires a variety of specic hardware and operating system enhancements for implementing these elements.)lee et al. suggest that sp architecture may be valuable for applications other than protecting cryptographic keysšapplications such as digital rights management and privacy protection systems. also, different scenarios, such as those requiring ﬁtransient trustﬂ in providing protected data to crisis responders, can be supported with small extensions to the sp architecture. lee et al. also note that while various proposals exist for secure i/o and secure bootstrapping, more research is needed to study alternatives that can be integrated into splike architectures for commodity computing and communications devices. sp architecture demonstrates that securityenhancing hardware features can be easily added to microprocessors and ˚exibly employed by software applications without degrading a system™s performance, cost, or ease of use.another example of recent work in this area is the new generation of hardware being shipped with secure coprocessors that can store encryption keys and can perform encryption and hash functions. specically, the trusted computing group is an industry consortium that has proposed toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.94 toward a safer and more secure cyberspacea trusted platform module (tpm) that is added to the i/o bus of a computing device to enable the measurement of the bits of the software stack that is installed, in order to detect changes in the software.5 it can provide useful security functionality that can be leveraged by many applications. tpm is a step forward in hardwarebased security, but there are some limitations, such as the fact that the tpm denition of ﬁremote attestationﬂ enables checking the integrity of the bits on the entire software stack on program launch, but it does not do any checks after that for dynamic hostile code insertion and modication. tpm also has a threat model limited to software attacks and does not provide any coverage for even simple physical attacks like bus or memory probing; these probably should be considered because of the easy theft or loss of mobile or personal computing devices. tpm is available in some personal computers.a system with tamperproof hardware, or with hardware features that support the tamperproong of software, has the potential to radically change the way that operating systems enforce security. in particular, such a system provides a basis for doing secure attestation of programs and datašboth locally and remotely. for example, a program might be accompanied by an attestation that describes its hash, thereby preventing modied programs (with the same name) from being executed. (in general, an attestation can refer to almost any property of a program and not just to the specic machine code realization of a program.) to ensure that a given software module is unaltered, one might digitally sign itšhowever, maintaining the binding between the hash and the software can be problematic without hardware support. in the longer run, operating systems might support programs accompanied by attestations which assert that some analyzer has checked the program (along with attestations that give a basis for trusting the analyzer and trusting the environment in which it executed) or asserting that some program has been ﬁwrappedﬂ in a reference monitor which ensures that certain policies are enforced.6much fundamental research remains to be done to determine what kinds of attestations will be useful to users and how difcult it will be for such attestations to be developed. there are also new legal issues to be addressed, since basic questions of ownership and control over computational resources come to the fore. (for example, the notion of  hardwarebased restrictions on certain uses of programs and data stored on one™s computer is inconsistent with the tradition that one has unlim5 trusted computing group, ﬁtrusted platform module (tpm) specications,ﬂ april 2006; available at https://www.trustedcomputinggroup.org/specs/tpm.6 alan shieh, dan williams, emin gun sirer, and fred b. schneider, ﬁnexus: a new operating system for trustworthy computing,ﬂ work in progress session, 20th symposium on operating system principles, october 2005; available at http://www.cs.cornell.edu/fbs/ publications/nexussospwip.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 95ited technical freedom to do as one pleases with programs and data on one™s computer.)another example is the recent introduction of multicore processors. these processors allow security checking to be done in parallel with other instruction processing, but the dominant application is support of code safety rather than checking accesscontrol privileges. today, it is not known how best to use multicore processors, and devoting some of their resources to security checking may have signicant security advantages. new architectures in operating systems will be necessary to fully leverage the potential for such hardware. still another security function that may be more appropriately implemented in hardware is the generation of random numbers, which can be used for cryptographic keys or for nonces.7 random numbers generated through software are much more guessable by an opponent, since the opponent must be presumed to have access to the same software. thus, since poor choice of random numbers leads to vulnerabilities, hardware implementation of random number generatorsšstrictly speaking, generators for random seeds to be used as inputs into (pseudo) random number generatorsšallows for the continuing injection of randomness into the pool. protection of the random seed generator and the pseudorandom number generator is more effectively accomplished in hardware.finally, the processor is not the only hardware element in a computing system. how other hardware elements might contribute to security is as yet almost entirely unexplored.4.1.2.2 tamper resistancethe tamper resistance of an it artifact (which includes resistance to inspection and to alteration) is also an important property. improving the tamper resistance of hardware can increase the robustness of a system, because security functionality implemented at a high level of abstraction (in software) can often be subverted by tampering at lower levels (in hardware). improving the tamper resistance of such artifacts is especially important in a world of pervasive computing, in which hardware devices with networked connectivity will proliferate in an unconstrained manner and thus may well be available for adversaries to examine and modify. 7 a nonce is a number that is used in a protocol only once. for example, it can be used in an authentication protocol to ensure that an old message cannot be reused in a replay attack. since an authentication protocol will typically require a nonce as an input variable, a replay attack is virtually impossible because the innitesimally small likelihood that any given nonce will be identical to a previous one.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.96 toward a safer and more secure cyberspaceresearch in both the creation of tamperresistant components and how they can be effectively exploited is valuable. for example, lie et al. have developed a hardware implementation of a form of executeonly memory that allows instructions stored in memory to be executed but not otherwise manipulated.8 in particular, software cannot be copied or modied without detection. a machine supporting internal compartments is required, in which a process in one compartment cannot read data from another compartment. all data that leave the machine are encrypted, since it must be assumed that external memory is not secure. there are tradeoffs among security, efciency, and ˚exibility, but the analysis of lie et al. indicates that it is possible to create a normal multitasking machine in which nearly all applications can be run in an executeonly mode.a second dimension of tamper resistance is that of increasing the difculty of reverseengineering a given object code. this can be problematic, as the object code must ultimately be read in its original form to be executed. one might encrypt object code, and decrypt it only when necessary for execution. however, in the absence of specialpurpose hardware to carry out such decryption,9 it might be possible for an adversary to intercept the code as it is being decrypted and run.another class of techniques is known as code obfuscation, which refers to processes through which object code can be rewritten and/or stored in forms that are hard to transform into meaningful source code.10 code obfuscation is intended to transform the object program in ways that do not alter its function but make it more difcult to understand. the new transformed program may have slower execution times or exhibit behavior not found in the original program, and managing this tradeoff between undesirable behavior and degree of obfuscation remains a key challenge in developing codeobfuscation techniques.finally, a degree of tamper resistance can be obtained by adding code (ﬁguardsﬂ) that monitor for changes to the code and take action if tamper8 d. lie, c. thekkath, m. mitchell, p. lincoln, d. boneh, j. mitchell, and m. horowitz, ﬁarchitectural support for copy and tamper resistant software,ﬂ proceedings of the 9th international conference on architectural support for programming languages and operating systems, pp. 168177, 2000.9 see, for example, amir herzberg and shlomit s. pinter, ﬁpublic protection of software,ﬂ acm transactions on computer systems, 5(4): 371393, november 1987.10 boaz barak, ﬁcan we obfuscate programs?,ﬂ available at http://www.math.ias.edu/~boaz/papers/obfinformal.html#obfpaper; douglas low, ﬁprotecting java code via code obfuscation,ﬂ available at http://www.cs.arizona.edu/~collberg/research/students/douglaslow/obfuscation.html.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 97ing is detected.11 such an approach is the foundation behind at least one commercial enterprise.12 4.1.2.3 process isolationa third interesting area is that of process isolation and separation. the ability to virtualize multiple processes running on the same processor has been in hand since the early 1960s on the pdp1 and in the mid1960s on ibm mainframe computers. in more recent times, early microprocessors such as the intel 8086 lacked an instruction set architecture that could support virtualization, and this deciency persisted through the instruction set architecture of the pentium.13 as the instruction set evolved to be more capable and processor speeds rose, virtualization of these microprocessors became feasiblešand was useful as well, because of the increasing needs for isolation in a changing threat environment.the basic requirements for virtualization were described in 1974 by popek and goldberg.14 the basic work on virtualization to run multiple operating systems was done at ibm for the 7044,15 the 360/40,16 and the rst product cp/67 for the 360/67.17 virtualization makes it possible to run multiple operating systems (and their applications) on a single server, reducing overall hardware costs. production and test systems can run at the same time in the same hardware, and different operating systems such as windows and linux can share the same server. virtualization may also have particular relevance to improving security in operating systems that are designed to be backward compatible with earlier versions. virtualization can increase the load factor on servers and other systems, thus 11 see hoi chang, 2003, ﬁbuilding selfprotecting software with active and passive defenses,ﬂ ph.d. dissertation, department of computer science, purdue university. 12 for an example of a commercial enterprise based on products using this approach, see http://www.arxan.com.13 j.s. robin and c.e. irvine, ﬁanalysis of the intel pentium™s ability to support a secure virtual machine monitor,ﬂ 9th usenix security symposium, august 1417, 2000, denver, colo.: usenix, the advanced computing systems association, pp. 129144; available at http://www.usenix.org/events/sec2000/robin.html.14 g.j. popek and r.p. goldberg, ﬁformal requirements for virtualizable third generation architectures,ﬂ communications of the acm, 17(7): 412421, july 1974.15 r.w. o™neill, ﬁexperience using a timeshared multiprogramming system with dynamic address relocation hardware,ﬂ pp. 611621 in vol. 30, proceedings of the 1967 spring joint computer conference, april 1820, 1967, atlantic city, n.j.: thompson books.16 a.b. lindquist, r.r. seeber, and l.w. comeau, ﬁa timesharing system using an associative memory,ﬂ proceedings of the ieee, 54(12): 17741779, december 1966.17 r.a. meyer and l.h. seawright, ﬁa virtual machine timesharing system,ﬂ ibm systems journal, 9(3): 199218, 1970; available at http://www.research.ibm.com/journal/sj/093/ ibmsj0903d.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.98 toward a safer and more secure cyberspaceutilizing central processing unit cycles that would otherwise be wasted unproductively.the major challenge today in process separation is that of achieving the capability to allow selected interactions between processes (that is, in dening and enforcing policies for information ˚ow), and of course interactions between processes mean that independence and separation can no longer be guaranteed. consider, for example, that a mailer and a web browser might run on separate virtual machines. that would prevent downloaded malware from a web site from having a harmful effect on the mailer. but what should be done if the user wants to mail a web page? or if the user wants to view the web page corresponding to a url in a received email? the general problem, not solvable in the abstract, is in deciding whether any proposed interaction between processes will be harmful or not. put differently, the issue is unanticipated consequences of interactions that are allowed and designed into the system, rather than failures in the isolation of a virtual machine in the rst place. note also that when largescale storage devices must also be shared between processes for storing the data associated with each process, these processes must interact implicitly as they seek and obtain access to such devices, even if such interactions are not explicitly allowed by whatever security policy is in place.finally, the integration of higherlevel components that have not been optimized for use in a secure kernel environment remains a challenge. isolation is a relatively easily exploitable benet, in that a component should be able to run in a virtual environment just as easily as in a real one. but other services can exploit the services provided by secure kernels as well. for example, security services can benet from isolation because they are less easily subverted in that conguration and have greater tamper resistance. in addition, because they are isolated, they are likely to have different failure modes than if they were run in the main system. some examples include the following: antivirus services that depend on trustworthy databases to identify viruses, provenance services that securely store the provenance of every le out of reach of the main operating system, network services that check provenance metadata prior to forwarding real data to applications, eventmonitoring and logging services for detecting problems or to support subsequent forensic investigation, and automated recovery services that enable recovery to a system state captured at some point prior to some security failure. a different approach to process separation is to isolate functionality on multiple processors. the theory underlying this approach is that processing power is increasingly inexpensive, thus putting a lower premium on maximizing the efciency of computational capability. especially with multicore processors available, it becomes possible in principle for one toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 99processor to run a single application, thus increasing its immunity from ˚aws in other applications. the operating system for that application can thus be written in a way that supports only that application, which implies that it can be made much simpler than an operating system designed for generalpurpose use. further, from a security standpoint, the behavior of a simpler and more specialized system is easier to specify, and hence deviations from normal behavior are easier to detect.184.1.2.4 languagebased securitylanguagebased security is an approach to security that is based on techniques developed in the programminglanguage community to ensure that programs can be relied on not to violate some policy of interest.19 the techniques involved include analysis and transformation. one wellknown form of analysis is ﬁtype checking,ﬂ whereby the fact that a program does certain unsafe things is detected before the program is run. one wellknown form of program transformation is the addition of runtime checks to a program, whereby a program is instrumented in a way that prevents the (instrumented) program from making a problematic (i.e., policyviolating) transformation.20these techniques are applicable to a wide variety of systems: systems written in highend languages, legacy systems, and systems whose code is represented only as machine language today. these techniques also have special relevance to writing systems that enforce information ˚ow and integrity policies, which are ﬁend to endﬂ and far more general than the usual ﬁaccesscontrol policiesﬂ that today™s operating systems enforce, and for creating ﬁarticial diversityﬂ (by program rewriting) so that different instances of a program are not subject to common attacks.4.1.2.5 component interfacessound interface design must be integrated into system architecture. a basic goal of interface design should be to encourage the development and analysis of system requirements, policies, architectures, and interfaces that will greatly enhance the understandability of computer 18 eric bryant et al., ﬁpoly2 paradigm: a secure network service architectureﬂ; available at http://www.acsac.org/2003/abstracts/72.html.19 fred b. schneider, greg morrisett, and robert harper, ﬁa languagebased approach to security,ﬂ pp. 86101 in informatics: 10 years back, 10 years ahead, lecture notes in computer science, vol. 2000, reihnard wilhelm (ed.), springerverlag, heidelberg, 2000.20 fred b. schneider, ﬁenforceable security policies,ﬂ acm transactions on information and system security 3(1): 3050, february 2000.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.100 toward a safer and more secure cyberspacesystems and their behavior as observed by application developers, system administrators, and users. the achievement of sound interfaces can have enormous benets in the development, procurement, operation, and use of those computer systems and associated networks. this effort has user and systemoriented aspects, particularly in trying to reduce the semantic gap between what can be derived from specic interfaces and what can be obtained by detailed examination of source code, libraries, compilers, interpreters, operating system environments, networking, and system administration tools.particular emphasis is also needed on the use of analysis techniques for dening and analyzing system interfaces so that the desired behavior that they represent and the dependencies among different interfaces can be more easily understood and controlled. the approach should be both constructive (in terms of developing or modifying systems to achieve more understandable behavior) and analytic (in terms of trying to gure out what is happening dynamically, especially when something unusual occurs), and it should be applicable to interfaces for operating systems, applications, and system administration.as an illustration, consider what it means to specify a component interface. these interfaces typically describe how a component is supposed to respond to certain inputs (or a range of inputs). but many component designers fail to specify the behavior for other inputs, and this is exactly the space within which attackers search for inputs that will make the component act outside its specication.composability is particularly relevant in the design of interfaces. for example, combining two components with welldesigned interfaces may introduce unwanted side effects that are not evident from either interface. this is clearly undesirable and needs to be avoided through sound interface and system design.research and development areas specically oriented to interface design might include the following:the development of models and staticanalysis tools for evaluating interface specications and determining their composability, interdependencies, and ability to enforce security requirements. of considerable interest to the development of secure systems would be the following: š the ability to analyze individual interfaces for logical consistency, completeness with respect to functionality that must be included, uniformity of interface conventions, consistency with documentation, understandability, and ease of use; š the ability to analyze the interactions among different interfaces, as part of the ability to create systems as predictable compositoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 101tions of carefully analyzed components, with analysis of how the properties of the individual interfaces are affected; and š the ability to determine the minimal subsets of systems whose functionality is sufcient to satisfy the given requirements, and to identify any hidden dependencies on unvalidated functionality.  in addition, extensive guidelines should be developed for perspicuous interfaces, for use with various software development methodologies and programming languages.the establishment of systematic approaches for handling exception conditions, concurrency, and remediation under adverse conditions. for example, it is important to avoid bad system behavior where possible and to be able to respond rapidly to potentially complex system misbehavior or attacks, and to ensure that appropriate handles are accessible in the visible interfaces without cluttering up normal use and creating more opportunities for human error.the development and constructive use of metrics for usability, particularly with respect to security issues such as access controls, authentication protocols, system administration, and so on. usability metrics for visible interfaces must be an integral part of the development process. they must also be incorporated into any evaluation processes, such as those built into the common criteria process.21the supplementing of the design and development process with assurance techniques specically relevant to the interfaces, including the ability to identify additional hidden and detrimental functionality that can be accessed through the interface in undocumented or unspecied ways. for example, an interface might include a test function inserted during debugging that exposes cryptographic keys. although such a function should be removed before release, its actual removal may be overlooked.note that these areas may require semantic knowledge of the underlying components (such as specications or implementations) and cannot be based solely on the interfaces themselves.4.1.2.6 cryptologytoday, with many advances already made in cryptography, it is tempting to believe that cryptography is well enough understood that it does not warrant further research. nevertheless, as the recent success in break21 for more information on the common criteria process, see http://www.commoncriteria portal.org/.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.102 toward a safer and more secure cyberspaceing the sha1 hash algorithm suggests,22 the intellectual infrastructure of cryptography for commercial and other nonmilitary/nondiplomatic use is not as secure as one might believe. growing computational power (which led to the vulnerability of the data encryption standard to bruteforce decryption) and increasingly sophisticated cryptanalytic tools mean that the study of even these very basic cryptographic primitives (encryption and hash algorithms) has continuing value. moreover, what had been viewed as esoteric cryptographic primitives and methods of mostly theoretical interestšthreshold cryptography, proactive security, and multiparty computationšare now being seen as exactly the right primitives for building distributed systems that are more secure.nor are interesting areas in cryptology restricted to cryptography. for example, the development of secure protocols is today more of an art than a science, at least in the public literature, and further research on the theory of secure protocols is needed. a related point is that realworld cryptosystems or components can be implemented in such a way that the security which they allegedly provide can be compromised through unanticipated information ﬁleakagesﬂ that adversaries can exploit or cause.23 in addition, despite the widespread availability of encryption tools, most electronic communications and data are still unencryptedša point suggesting that the infrastructure of cryptology remains illsuited for widespread and routine use. many practical problems, such as the deployment of usable publickey infrastructures, continue to lack scalable solutions. the conceptual complexity of employing encryption and the potential exposures that come 22 more precisely, an attack against the sha1 algorithm has been developed that re duces its known runtime collision resistance by a factor of 211 (from 280 to 269) (xiaoyun wang, yiqun lisa yin, and hongbo yu, ﬁfinding collisions in the full sha1,ﬂ advances in cryptologyšcrypto™05; available at http://www.infosec.sdu.edu.cn/paper/sha1 cryptoauthnew2yao.pdf). in addition, adi shamir announced during the rump session at crypto™05 (on august 15, 2005) that wang and other collaborators had demonstrated the possibility of nding a collision in sha1 in 263 operations, although no actual collisions had been found. this result applies only to collision resistance, which means that digital signatures are placed at risk, but the result does not affect constructions for key derivation, message authentication codes, or random function behavior (i.e., it does not affect any construction in which specic content may be at issue).23 for example, paul kocher has developed attacks on certain realworld systems that can reveal secret keys in much less time than would be required by bruteforce techniques, even though the cryptography in these systems has been implemented perfectly. kocher™s attacks are based on timing and/or power measurements of the systems involved. see, for example, paul kocher et al., ﬁtiming attacks on implementations of difehellman, rsa, dss, and other systems,ﬂ december 1995, available at http://www.cryptography.com/resources/whitepapers/timingattacks.pdf; and paul kocher et al., ﬁintroduction to differential power analysis and related attacks,ﬂ 1998, available at http://www.crypto graphy.com/dpa/technical/.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 103with doing it wrong strongly suggest the need for research to understand where, how, and when it ts into security architecture. as an example of bringing cryptographic theory into practice, consider multiparty computations. here, a collection of parties engages in computing some function of the values that each has, but no party learns values that the others have. moreover, some protocols defend against having a fraction of the participants be compromised.threshold digital signatures are a simple example of a multiparty computation. this functionality is useful (though it has not yet enjoyed widespread practical use) when a service is implemented by a replicated set of servers. (any majority of the servers can together create a signature for responses from the service, but no individual server is capable of impersonating the service.) however, more sophisticated multiparty computation algorithms have not yet made the transition from theory to practice. socalled proactive cryptographic protocols are another area of interest. these protocols call for the periodic changing of secrets so that information that an attacker gleans from successfully compromising a host is shortlived. effecting the transition of this cryptographically supported functionality from theory to practice will change the toolbox that systems builders use and could well enable systems that are more secure through the clever deployment of these new cryptographic primitives.finally, as new mathematical methods are discovered and as new computing technology becomes available, what is unbreakable today may be penetrable next week. as one example, consider that quantum computing, if made practical, would invalidate several existing methods thought to be unbreakable. likewise, it has not yet been proven that prime factorization is an np problem, and that np is not reducible to p. thus, it is possible that future discoveries could change a number of the current assumptions about systems such as the rsa algorithmšsuggesting that work on developing new basic cryptographic primitives is useful as a hedge against such possibilities.4.1.3 research to support testing and evaluationtesting and evaluation (t&e) are necessary because of the nature of information technology artifacts as things designed and implemented by people, who make mistakes. t&e generally consumes half or more of the overall cost for a software system. t&e occurs at every level of granularity in a system (unit to subassembly, to overall system, to deployed system in situ), and at all process phases, starting with requirements. traditional testing involves issues of coverage. testing every statement may not be enough, but it may nonetheless be difcult to achieve. testing every branch and path is even harder, since there is generally a toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.104 toward a safer and more secure cyberspacecombinatorially large number of paths. how much coverage is needed, and what are the metrics of coverage?4.1.3.1 finding unintended functionalityone of the most challenging problems in testing and evaluation is that of auditing a complex artifact for functionality that has not been included in the specication of requirements and that may result in security vulnerabilities. in a world of outsourced and offshore chip fabrication and/or code development and given the possibilities that trusted designers or programmers might not be so trustworthy, it is an important task to ensure that functionality has not been added to a hardware or software system that is not consistent with the system™s specications. however, the complexity of today™s it artifacts is such that this task is virtually impossible to accomplish for any real system, and the problem will only get worse in the future. today, the best testing methodologies can be divided into two types: (1) efforts to nd the problems whose presence is a priori known, and (2) directed but random testing of everything else that might reveal an ﬁunknown unknown.ﬂ formal methods may also offer some promise for nding unintended functionality, although their ability to handle large systems is still quite limited.these considerations suggest that comprehensive cybersecurity involves both secure hardware and secure software at every level of the protocol stack, from the physical layer up. this is not to say that every it application must be run on hardware or software that has been designed and fabricated by trustworthy partiesšonly that the sensitivity of the application should determine what level of concern should be raised about possible cybersecurity ˚aws that may have been deliberately embedded in hardware or software.4.1.3.2 test case generationa second dimension of testing is to ensure that testing is based on a ﬁgoodﬂ set of test cases. for example, it is well known that test cases should include some malformed inputs and some that are formally derived from specications and from code, and in particular, cases that go outside the specication and break the assumptions of the specication. such cases will often reveal security vulnerabilities if they do exist.testing can focus on particular attributes beyond just functional behavior. for example, a security test might focus on behavior with outofspecication inputs, or it might occur when the system is under load beyond its declared range, and so on. similarly, unit or subsystem testing could focus on the ﬁrobustnessﬂ of internal interfaces as a way to assess toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 105how an overall system might contain an error, keeping an error within the connes of a subsystem by tolerating and recovering.a related point is the development of test suites for commonly used software for which there are multiple implementations. for example, chen et al. documented the existence of different semantics in three different versions of unix (linux, solaris, and freebsd) for system calls (the uidsetting system calls) that manage system privileges afforded to users.24 their conclusion was that these different semantics were responsible for many security vulnerabilities. appropriate test suites would help to verify the semantics and standards compliance of system calls, library routines, compilers, and so on.4.1.3.3 tools for testing and evaluationa third important dimension of testing and evaluation is the realworld usability of tools and approaches for t&e, many of which suffer from realworld problems of scalability, adoptability, and cost. for example: tools for static code analysis are often clumsy to use and sometimes ˚ag an enormous number of issues that must be ignored because they are not prioritized in any way and because resources are not available to address all of them. dynamic behavior analysis, especially in distributed asynchronous systems, is poorly developed. for example, race conditionsšthe underlying cause of a number of major vulnerabilitiesšare difcult to nd, and tools oriented toward their discovery are largely absent.model checking, code and program analysis, formal verication, and other ﬁsemanticsbasedﬂ techniques are becoming practical only for modestly sized realsystem software components. considerable further work is needed to extend the existing theory of formal verication to the compositions of subsystems.all of these t&e techniques require some kind of specication of what is intended. with testing, the test cases themselves form a specication, and indeed agile techniques rely on testing for this purpose. inspection allows more informal descriptions. analysis and semanticsbased 24 hao chen, david wagner, and drew dean, ﬁsetuid demystied,ﬂ proceedings of the 11th usenix security symposium, pp. 171190, 2002; available at http://www.cs.berkeley.edu/~daw/papers/setuidusenix02.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.106 toward a safer and more secure cyberspacetechniques rely on various focused ﬁattributespecicﬂ specications of intent. inspection is another important technique related to testing and evaluation. inspection underlies the common criteria (iso 15408), but it relies on subjective human judgment in the sense that the attention of the human inspectors may be guided through the use of tools and agreed frameworks for inspection. moreover, the use of human inspectors is expensive, suggesting that inspection as a technique for testing and evaluation does not easily scale to large projects. 4.1.3.4 threat modeling today, most security certication and testing are based on a ﬁtest to the specicationﬂ process. that is, the process begins with an understanding of the threats against which defenses are needed.  defenses against those threats are re˚ected as system specications that are included in the overall specication process for a system. testing is then performed against those specications. while this process is reasonably effective in nding functionality that is absent from the system as implemented (this is known because that functionality is re˚ected in the specication), it has two major weaknesses.the rst weakness of the testtothespecication process is that it requires a set of clear and complete specications that can be used to drive the specics of the testing procedure. however, as noted in section 4.1.1, a great deal of realworld software development makes use of methodologies based on spiral and incremental development in which the software ﬁevolvesﬂ to meet the new needs that users have expressed as they learn and use the software. this means that it is an essentially impossible task to specify complex software on an a priori basis. thus, specications used for testing are generally written after the software has been written. this means that the implemented functionality determines the specications, and consequently the specications themselves are no better than the understanding of the system on the part of the developers and implementers. that understanding is necessarily informal  (and hence incomplete), because it is, by assumption, not based on any kind of formal methodology. (the fact that these specications are developed after the fact also makes them late and not very relevant to the software development process, but those are beyond the scope of this report.)the second weakness, related to the rst, is that this methodology is not particularly good at nding additional functionality that goes beyond what is formally specied. (section 4.1.3.1 addresses some of the difculties in nding such problems.)toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 107weaknesses in a testtothespecication approach suggest that complementary approaches are needed. in particular, threat modeling and threatbased testing are becoming increasingly important. in these approaches, a set of threats is characterized, and testing activities include testing defenses against those threats. (this is the complement to threatbased design, described in section 4.1.1.2.) this approach can be characterized as, ﬁtell me the threats that you are defending against and prove to me that you have done so.ﬂ research in this domain involves the development of techniques to characterize broader categories of threat and more formal methods to determine the adequacy of defenses against those threats. for those situations in which a threat is known and a vulnerability is present but no defense is available, developing instrumentation to monitor the vulnerability for information on the threat may be a useful thing to do as well. research is also needed for enabling spiral methodologies to take into account new threats as a system ﬁevolvesﬂ to have new features. 4.2 graceful degradation and recoveryif the principle of defense in depth is taken seriously, system architects and designers must account for the possibility that defenses will be breached, in which case it is necessary to contain the damage that a breach might cause and/or to recover from the damage that was caused. although security efforts should focus on reducing vulnerabilities proactively where possible, it is important that a system provide containment to limit the damage that a security breach can cause and recovery to maximize the ease with which a system or network can recover from an exploitation. progress in this area most directly supports provision ii and provision iii of the cybersecurity bill of rights, and indirectly supports provision vii. 4.2.1 containmentthere are many approaches to containing damage: engineered heterogeneity. in agriculture, monocultures are known to be highly vulnerable to blight. in a computer security context, a population of millions of identically programmed digital objects is systematically vulnerable to an exploit that targets a specic security defect, especially if all of those objects are attached to the toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.108 toward a safer and more secure cyberspaceinternet.25 if it is the specics of a given object code that result in a particular vulnerability, a different object code rewritten automatically to preserve the original object code™s highend functionality may eliminate that vulnerability. (of course, it is a requirement of such rewriting that it not introduce another vulnerability. moreover, such methods can interfere with efforts to debug software undertaken at the object code level, as well as with legitimate thirdparty software addons and enhancements, suggesting that there are tradeoffs to be analyzed concerning whether or not automatic rewriting is appropriate or not in any given situation.)disposable computing. an attacker who compromises or corrupts a system designed to be disposablešthat is, a computing environment whose corruption or compromise does not matter much to the useršis unlikely to gain much in the way of additional resources or privileges.26 a disposable computing environment can thus be seen as a buffer between the outside world and the ﬁrealﬂ computing environment in which serious business can be undertaken. when the outside world manifests a presence in the buffer zone, the resulting behavior is observed, thus providing an empirical basis for deciding whether and/or in what form to allow that presence to be passed through to the ﬁrealﬂ environment. as in the case of process isolation, the challenge in disposable computing is to develop methods for safe interaction between the buffer and the ﬁrealﬂ environment.one classic example of disposable computing is java, which was widely adopted because its sandboxing technology created a perimeter around the execution context of the applet code. that is, an applet could do anything inside the sandbox but was constrained from affecting anything outside the sandbox. virtualization and isolation. as discussed in section 4.1.2.3, isolation is one way of conning the reach of an application or a software module.25 monocultures in information technology also have an impact on the economics of insuring against cyberdisasters. because the existence of a monoculture means that risks to systems in that monoculture are not independent, insurers face a much larger upper bound on their liability than if these risks were independent, since they might be required to pay off a large number of claims at once.26 perhaps the most important gain from such an attack is knowledge and insight into the structure of that computing environmentšwhich may be useful in conducting another attack against another similarly constructed system.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 1094.2.2 recoverya second key element of a sound defensive strategy is the ability to recover quickly from the effects of a security breach, should one occur. indeed, in the limiting case and when information leakage is not the threat of concern, allowing corruption or compromise of a computer system may be acceptable if that system can be (almost) instantaneously restored to its correct previous state. that is, recovery can itself be regarded as a mechanism of cyberdefense when foiling an attack is not possible or feasible. recent work in embedding transaction and journaling capabilities into basic le system structures in operating systems suggests that there is some commercial demand for this approach.because of the difculty of highcondence prevention of system compromise against highend threats, recovery is likely to be a key element of defending against such threats. illustrative research topics within this domain include the following:rebooting. rebooting a system is a step taken that resets the system state to a known initial conguration; it is a necessary step in many computer operations. for example, rebooting is often necessary when a resident system le is updated. rebooting is also often necessary when an attack has wreaked havoc on the system state. however, rebooting is normally a timeconsuming activity that results in the loss of a great deal of system state that is perfectly ﬁhealthy.ﬂ rebooting is particularly difcult when a largescale distributed system is involved. microrebooting (an instantiation of a more general approach to recovery known as software rejuvenation27) is a technique that reboots only the parts of the system  that are failing rather than the entire system. research in microrebooting includes, among other things, the development of techniques to identify components in need of rebooting and ways to reduce further the duration of outage associated with rebooting. such considerations are particularly important in environments that require extremely high availability.27 software rejuvenation is a technique proposed to deal with the phenomenon of software aging, one in which the performance of a software system degrades with time as the result of factors such as exhaustion of operating system resources and data corruption. in general terms, software rejuvenation calls for occasionally terminating an application or a system, cleaning its internal state and/or its environment, and restarting it. see, for example, kalyanaraman vaidyanathan and kishor s. trivedi, ﬁa comprehensive model for software rejuvenation,ﬂ ieee transactions on dependable and secure computing, 2 (2, apriljune): 124137, 2005. see also http://srejuv.ee.duke.edu.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.110 toward a safer and more secure cyberspaceonline production testing. an essential element of recovery is fault identication. one approach to facilitate such identication is online testing, in which test inputs (and sometimes deliberately faulty inputs) are inserted into running production systems to verify their proper operation. in addition, modules in the system are designed to be selftesting to verify the behavior of all other modules with which they interact.largescale undo capabilities. an undo capability enables system operators to roll back a system to an earlier state, and multiple layers of undo capability enable correspondingly longer rollback periods. if a successful cyberattack occurs at a given time, rolling back the system™s state to before that time is one way of recovering from the attackšand it does not depend on knowing anything about the specic nature of the attack.28 4.3 software and systems assurancesoftware and systems assurance is focused on two related but logically distinct goals: the creation of systems that will do the right thing under the range of possible operating conditions, and human condence that the system will indeed do the right thing. for much of computing™s history, highassurance computing has been most relevant to systems such as realtime avionics, nuclear command and control, and so on. but in recent years, the issue of electronic voting has brought questions related to highassurance computing squarely into the public eye. at its roots, the debate is an issue of assurance: how does (or should) the voting public become convinced that the voting process has not been compromised? in such a context, it is not enough that a system has not been compromised; it must be known not to have been compromised. this issue has elements of traditional highassurance concerns (e.g., does the program meet its specications?) but also has broader questions concerning support for recounts, making sure the larger context cannot be used for corruption (e.g., conguration management). a variety of techniques have been developed to promote software and 28 aaron b. brown, a recoveryoriented approach to dependable services: repairing past errors with systemwide undo, university of california, berkeley, computer science division technical report ucb//csd041304, december 2003, available at http://roc.cs.berkeley.edu/projects/undo/index.html; a. brown and d. patterson, ﬁundo for operators: building an undoable email store,ﬂ in proceedings of the 2003 usenix annual technical conference, san antonio, tex., june 2003, available at http://roc.cs.berkeley.edu/papers/brownemailundo usenix03.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 1šblocking and limiting the impact of compromise 111systems assurance, including formal requirements analysis, architectural reviews, and the testing and verication of the properties of components, compositions, and entire systems. it makes intuitive sense that developing secure systems would be subsumed under systems assurancešby denition, secure systems are systems that function predictably even when they are under attack.29 an additional challenge is how to design a system and prove assurance to a general (lay) audience. in the example above, it is the general voting publicšnot simply the computer science communityšthat is the ultimate judge of whether or not it is ﬁsufciently assuredﬂ that electronic voting systems are acceptably secure.some techniques used to enhance reliability are relevant to cybersecurityšmuch of software engineering research is oriented toward learning how to decide on and formulate system requirements (including tradeoffs between functionality, complexity, schedule, and cost); developing methods and tools for specifying systems, languages, and tools for programming systems (especially systems involving concurrent and distributed processing); middleware to provide common services for software systems; and so on. testing procedures and practices (section 4.1.3) are also intimately connected with assurance. all of these areas are relevant to the design and implementation of more secure systems, although attention to these issues can result in common solutions that address reliability, survivability, and evolvability as well.software engineering advances also leverage basic research in areas that seem distant from system building per se. success in developing tools for program analysis, in developing languages for specications, and in developing new programming languages and computational models typically leverages more foundational workšin applied logic, in algorithms, in computational complexity, in programminglanguage design, and in compilers. at the same time, assurance and security are not identical, and they often seek different goals. consider the issue of system reliability, usually regarded as a key dimension of assurance. in contrast with threats to security, threats to system reliability are nondirected and in some sense are more related to robustness against chance events such as power outages or uninformed users doing surprising or unexpected things. by contrast, threats to security are usually deliberate, involving a human adversary who has the intention to do damage and who takes actions that are decid29 for more discussion of this point, see national research council, trust in cyberspace, national academy press, washington, d.c., 1999.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.112 toward a safer and more secure cyberspaceedly not random. a test and evaluation regime oriented toward reliability will not necessarily be informative about security. the same is true about using redundancy as a solution to reliability, since redundancy can be at odds with heterogeneity in designing for security. thus, it would be a mistake to conclude that focusing solely on reliability will automatically lead to high levels of cybersecurity. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.1135category 2šenabling accountabilitythe goal of requirements in category 2 of the committee™s illustrative research agenda is that of ensuring that anyone or anything that has access to a system componentša computing device, a sensor, an actuator, a networkšcan be held accountable for the results of such access. enabling accountability refers to the ability to hold a party responsible for the consequences of its actions, and in particular that a consequence can be associated with appropriate parties if those actions cause harm. in this broad category are matters such as remote authentication, access control and policy management, auditing and traceability, maintenance of provenance, secure associations between system components, and so on. 5.1 attributioncomputer operations are inherently anonymous, a fact that presents many problems in cybersecurity. when a system is under remote attack, the attacker is generally unknown to the targeted system. when an attack has occurred, anonymous individuals cannot subsequently be held responsible and do not suffer any consequences for the harmful actions that they initiated. and, if all users of a system are anonymous, there is no way to differentiate between authorized and unauthorized actions on a system.attribution is the ability to associate an actor with an action. (by contrast, authentication refers to establishing the truth of some claim of toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.114 toward a safer and more secure cyberspaceidentity.) the actor is characterized by some attribute(s), such as the name of a user, the serial number of a machine on a network, or some other distinguishing property of the actor. attribution requires technology that is less inherently anonymous so that association between action and actor is easily ascertained, captured, and preserved.attribution should be conceptualized with respect to ve important characteristics:precision. a single attribute may uniquely characterize an actor, as might be the case with the complete genome sequence corresponding to a specic human being or the manufacturer™s serial number on a given machine. but such attributes are by far the exception. individuals may have the same name; the media access control (mac) address of a specic network device may not be unique, and even a human being may have an identical twin (whose genomic sequence will be identical in all respects to that of the rst human being). accuracy. a characteristic related to precision is accuracy, a measure of the quality of attribution, such as the probability that the attribution is correct (i.e., that the value of the attribute is indeed associated with the actor in question). accuracy is a key issue in legal standards for evidence and in the extent to which it is reasonable to develop linkages and inferences based on those attributes.lifetime/duration. as a rule, an association (which generally consists of the actor™s attribute, the action, the object acted on, and other relevant data such as the time of the action) need not be preserved forever. for example, a statute of limitations applies to many associations, after which the association can often be discarded. but this example also points out that the duration of preservation depends on the purpose being served. from a legal standpoint, it may be safe to discard the association. but what may be safe from a legal standpoint may not make sense for business reasons (e.g., a business may need to reconstruct what happened in a project long ago), and conversely as well.granularity. as a general rule, an action consists of a number of components in a certain sequence. for some purposes, it may be sufcient to make attributions about the action at the highest level (that is, at the level of complete transaction). for example, it may be necessary to determine that an operating system patch came from the operating system manufacturer. however, there may be times when an entity contemplating accepting or executing an action may want to make attributions on individual components of a transaction. perhaps, in a nancial transaction, a gross total would toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 2šenabling accountability 115be attributed to a valid counterparty, but the tax implications might be attributed to a tax lawyer. for instance, one could research the possibility of having different attributions associated with the various results of network service invocations. while complex, this is related to the large body of work on transitive, or delegated, trust. in the rst instance, the operating system manufacturer trusts its employees and the operating system patch installer trusts the manufacturer. in the example of the nancial transaction, the trust relationship is explicitly broken out among the individual components of the transaction.security (specically, resistance of an attribution to attack and spoofing). attribution depends on the inability to break the association between action and actor, because in its absence, impersonation can easily occur.these ve characteristics vary depending on the application. for example, for operational defense, duration may be very short, measured in seconds or minutes; for forensics investigation, duration may be measured in years.there are also a number of systemslevel issues for the implementers and/or the operators of attributioncapable systems. for example, where should be the locus of responsibility for the implementation of attribution mechanisms? an operator of a system or network may expect that attribution will be built in to system or network actions. but in a decentralized environment in which many vendors are responsible for providing one component service or another, the party responsible for implementing attribution mechanisms may be difcult to identify (or to hold accountable for such implementation). note that attribution may be an issue at all levels of a system design (the individual and organization at high levels, the computers or applications at low levels).another systemslevel issue is the privacy of attribution information. attribution information can be very sensitive, and thus must be protected against unauthorized or improper disclosure. similar considerations apply to parties that are allowed to request that attribution be obtained in the rst place.1the most important cybersecurity issue associated with attribution is a problem that attribution mechanisms cannot solvešthe unwittingly 1 this point raises the issue of how attribution is designed into a system. under some designs and for some applications, all actions might routinely be attributed and the information stored in a secure database, to be divulged only to parties that provide proper authorization. under other applications (perhaps applications that are more privacysensitive), actions might be attributed only under explicit authorization.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.116 toward a safer and more secure cyberspacecompromised or duped user. as the existence of botnets illustrates, a cyberattacker has many incentives to compromise others into doing his or her dirty work. even in the instances when attribution mechanisms operate perfectly, they may well identify a cyberattack as originating from a computer belonging to an innocent little old lady from pasadena. put differently, there is a big difference between identifying the source or sources of a cyberattack and associating with that attack the name of a human being or beings responsible for launching it.this is not to say that making such an identication is uselessšindeed, it may be an essential step in a forensic investigationšand it is worthwhile to make such steps as easy as possible. and, the widespread deployment of attribution mechanisms may increase the likelihood that the perpetrator of any given attack can be identied.assuming that identifying the launch point of an attack is possible, such identication could be used in operational defense to identify the source of a remote attack. such identication is a necessary (though not sufcient) condition for being able to shut off or block the attack in real time at the source. two such attacks are a distributed denialofservice attack and the theftšwhile it is happeningšof a large proprietary (or ﬁtradesecretﬂ) digital object. in this case, the objective is to block the compromise in real time, and false positives (that misidentify the attacker) are of less consequence than failure to identify the attack at all.an area related to attribution that warrants further exploration is the automated capture, maintenance, and use of ﬁinformation provenance.ﬂ provenance is a sequence of attributes that in some way species trustworthy information relating to the initial creation and every subsequent modication of some information unit or collection of information units (e.g., a le, an email, and so on). an important characteristic of provenance is that it would be maintained on information across distributed systems; for example, it would ˚ow with an object. there are many possible uses of provenance. for example:a computer program may possess a provenance that in some ways species who was involved in its creation. this could solve many problemsšfor example, nding out which programs may have been written or modied by an individual who is later found out to be untrustworthy. today, some aspects of provenance may be maintained in a source control system, but usually not in a highly trustworthy fashion.just as with antiques, provenance would tend to provide a greater ability to interpret where information came from, and this may shed light on the value of the information. with the proliferation of information of all types including images, it is increasingly diftoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 2šenabling accountability 117cult to separate fact from ction. for example, a picture with provenance indicating that there has been no modication beyond its initial imaging and also its association with the new york times newsroom might well be more trustworthy than a picture that has been postprocessed and associated with a tabloid.email with provenance may enable increased trust of that email. while provenance will by no means prevent the transmission of spam or viruses, the knowledge of the provenance of a forwarded email note (some attributes of the author, his or her computer, any modiers in a forwarding path, and so on) would provide some condence to the recipient and would certainly provide forensic benets in tracking down cyberattackers. provenance for email could also help to address today™s problems of anonymous harassing emails, since a sender could be more readily identied. databases implementing provenance could provide a user with the ability to easily determine the data elements that contributed to a given result. this ability might well contribute to the condence that the user has in that result or might suggest new and fruitful lines of inquiry.there would seem to be signicant research related to utilizing provenance to make systems and information more secure, as one element of security (or more precisely, condence in security) is knowing the detailed lineage of any given system and its components.there are also complex and highly interesting questions relating to the implementation of provenance. for example, there are questions as to how one can provide systems support for an extensible set of attributes, how those attributes can be associated reliably and immutably with their corresponding information, how performance issues associated with a large list of attributes can be contained, how to surface provenance information via programmatic interfaces, and how one can handle the coalescing of attributes so that the attribute lists do not grow without bound. it seems likely that storage of attributes would be beneted by the existence of a trusted computing base that would use virtualization to ensure sufcient isolation.finally, there are fascinating questions as to how to make provenance valuable to users. given the massive increase in the amount of attribute data available, there are interesting questions as to how to surface it in ways so that the valuable provenance stands out. there is the possibility that signicantly useful, applicationspecic heuristics will be created that can monitor provenance and detect potential problems. analysis must also be done on the impact of provenance on privacy.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.118 toward a safer and more secure cyberspaceas an example of research in data provenance, margo seltzer has undertaken work on provenanceaware storage systems (pass).2 seltzer points out that although the chain of ownership and the transformations that a document has undergone can be important, most computer systems today implement provenancerelated features as an afterthought, usually through an auxiliary indexing structure parallel to the actual data. she argues that provenance is merely a particular type of metadata, and thus that the operating system itself should be responsible for the automatic collection and management of provenancerelevant metadata just as it maintains conventional le system metadata. and, it should support queries about that metadata. an extension of a provenanceaware system, more difcult to implement, would enable queries to be made about entities smaller than a le, such as the individual cells of a spreadsheet or particular paragraphs in a document. progress in attribution research increases the ability to provide provenance for electronic information or events (cybersecurity bill of rights provision v), is an integral element of expunging information (provision iv), inhibits an attacker™s ability to perform denialofservice attacks (provision i), and improves the ability to audit systems performing certain critical functions (provision vii).5.2 misuse and anomaly detection systemsmisuse and anomaly detection (mad) systems refer to a fairly wide range of systems and techniques for detecting suspicious or anomalous activity on (or intrusion into) computers, servers, or networks.3 intrusions are most often classied either as misuse (i.e., an attack) or as an anomaly. in general, there are two primary types of mad systems in use today in organizations large and small:hostbased mad systems. these systems operate on a specic host or computer to detect suspicious activity on that particular hostšfor example, malicious connection attempts or applications doing things that they should not be doing (e.g., a word processor  2 see http://www.eecs.harvard.edu/~margo/research.html.3 for more detailed information on id systems and related issues, see rebecca bace, undated, ﬁan introduction to intrusion detection and assessment for system and network security management,ﬂ icsa labs white paper, available at http://www.icsa.net/icsa/docs/html/communities/ids/whitepaper/intrusion1.pdf; and karen kent and peter mell, 2006, ﬁguide to intrusion detection and prevention (idp) systems (draft), recommendations of the national institute of standards and technologyﬂ (nist special publication 80094), national institute of standards and technology, gaithersburg, md., available at http://csrc.nist.gov/publications/drafts/draftsp80094.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 2šenabling accountability 119trying to modify key operating system or conguration les); andnetworkbased mad systems. these systems focus on network data ˚ows, looking for suspicious packets or trafc.often these two types of systems are used together to create a hybrid solution for misuse or anomaly detection. indeed, each by itself is quite limited.mad systems are potentially valuable in that they seek to detect the early stages of an attack (e.g., an attacker™s probing of a machine or network for specic vulnerabilities) and can then aid in protecting a machine from (or even preventing) the subsequent stages of the attack. mad systems also seek to detect telltale signs of suspicious activity or patterns of behavior (whether by a user, an application, or a piece of malicious code) that rewalls or other tools might miss or ignore.mad systems are generally quite complex and require signicant effort to manage properly. they are not a xall solution for computer or network security; mad systems cannot compensate or account for weaknesses such as design ˚aws and software bugs, and cannot compensate or account for weaknesses in organizational authentication policies, data management practices, or network protocols themselves. from a technical standpoint, one of the most signicant difculties of developing usable mad systems is the fact that the behavior of an intruder may be nearly indistinguishable from that of a legitimate user; intruders often take great care to make their behavior look innocuous. for instance, mad systems are ﬁtrainableﬂ by attackers. a patient attacker can gradually increase the incidence of events to be later associated with an attack to the point where the mad system ranks them as ﬁnormal,ﬂ whereas springing the specic events on the system would cause it to alarm.as a result, when mad systems are made very sensitive, they are notorious for generating many false positives (sounding alarms when none are warranted) and thereby inconveniencing legitimate users; when they are made less sensitive in order to avoid inconveniencing legitimate users, they are notorious for failing to sound alarms when intruders or misuse is in fact present. an aggravating factor is that attackers are constantly at work devising and rening ways to elude known mad systemsšfor example, using socalled ﬁstealthyﬂ scans to avoid the notice of some mad systems. reconciling the tension between false positives and false negatives is thus a central area of mad system research.another challenge in the development of mad systems is that of nding methods that function efciently in large systems. many approaches to misuse and anomaly detection generate enormous amounts of data, which must subsequently be analyzed. (in the extreme case, an audit toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.120 toward a safer and more secure cyberspacelog that allows the reconstruction of a user™s activities is a mad system that only collects data; automated tools for log analysis that search for suspicious patterns of behavior can then be regarded as a kind of post hoc mad system.) moreover, the collection and analysis of such large amounts of data may degrade performance to unacceptable levels, suggesting that a hierarchical abstraction process may be needed for more efcient performance.4 related is the challenge of integrating mad systems with network infrastructure itself, making mad a standard feature in some deployments. in addition, mad systems must address the very difcult problem of uncovering possible patterns of misuse or anomalies that may occur in a distributed manner across the systems of a large network. that is, certain behavior may not be suspicious if and when it occurs in isolation, but the identical behavior may well be suspicious if it occurs on multiple systems at the same time. today, understanding how to correlate behavior that is nonanomalous in the small to infer an indication of anomalous behavior in the large is quite problematic. the problems are even more severe in an environment in which qualitatively different exploitations might be occurring in different systems orchestrated by a single hostile actor. despite more than two decades of research in this area, signicant problems remain concerning the interpretation of the audit and network packet data, in particular, involving the early recognition of patterns of multiple simultaneous attacks or outages, identifying the sources and identities of attackers, and discerning the intent of the attacks.5 privacy problems must also be addressed, because the audit and network packet data can contain sensitive information.6progress in mad system research supports provision i, provision iii, provision ix, and provision x of the cybersecurity bill of rights.4 p.a. porras and p.g. neumann, ﬁemerald: event monitoring enabling responses to anomalous live disturbances,ﬂ in proceedings of the nineteenth national computer security conference, nist/ncsc, baltimore, md., pp. 353365, october 2225, 1997; and p.g. neumann and p.a. porras, ﬁexperience with emerald to date,ﬂ in proceedings of the first usenix workshop on intrusion detection and network monitoring, usenix, santa clara, calif., pp. 7380, april 1999, available at http://www.csl.sri.com/neumann/det99.html.5 p.a. porras and p.g. neumann, ﬁemerald: event monitoring enabling responses to anomalous live disturbances,ﬂ in proceedings of the nineteenth national computer security conference, nist/ncsc, baltimore, md., pp. 353365, october 2225, 1997; and p.g. neumann and p.a. porras, ﬁexperience with emerald to date,ﬂ in proceedings of the first usenix workshop on intrusion detection and network monitoring, usenix, santa clara, calif., pp. 7380, april 1999, available at http://www.csl.sri.com/neumann/det99.html.6 phillip a. porras, ﬁprivacyenabled global threat monitoring,ﬂ ieee security and privacy, novemberdecember 2006, pp. 6063.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 2šenabling accountability 1215.3 digital rights managementdigital rights management (drm) refers to the granting of various privileges depending on the identity of the party who will use those privileges. a common example is the management of privileges for protected contentša publisher may choose to sell the right for an individual to watch a (digital) movie once or an unlimited number of times, but in any case, only to watch it and not to forward or copy it. unlike physical objects, if a computer can read some bits (as would be necessary to convert those bits into a humansensible form like music or pictures), then that computer will also be able to copy those bits an unlimited number of times. providers want recipients to abide by certain terms of use specied in a contract and want technical assurances that the contract will be enforced. moreover, permission to copy the bits of a protected work is unlikely to be part of a contract that restricts the use of those bits, since the copies can be used or further distributed for use in ways that do not comply with the contract terms. thus, a means of enforcement is needed to constrain what is done with the bits. such enforcement requires software that can be trusted by the provider even though it is executed on a machine that is not similarly trusted.since computers are universalšand therefore a computer can simulate any otheršthe trusted software could well be running in a software simulator rather than directly on the hardware (unless specialpurpose hardware is being used). universality of digital computers is thus problematic, because when the trusted software is run in a simulator, the simulator could make illicit copies of an electronic copy without the trusted software™s knowledge of this copying; the illicit copies can then be subsequently used to violate the terms of the use agreement.thus, solving the drm problem is more than a problem of ensuring condentiality for the content in questionšthe problem is bigger than how to transmit the electronic content from the owner to the customer in a way that prevents interception by third parties. it is also a problem of (what has come to be known as) trusted computing: how to build a computing environment in which the user is not trusted to control certain aspects of its conguration and operation but rather a programmer is trusted to do this. recent hardware extensions, such as the trusted platform module (tpm) (see section 4.1.2.1), can be seen as providing support for exactly this trust and execution model. but tpm and such solutions are not a panaceašmany consumers would nd it unacceptable to own a generalpurpose computer over which they themselves do not have complete control (having ceded some control to the programmers of certain trusted software). so there is a tension between computer owners who feel that toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.122 toward a safer and more secure cyberspacethey have lost control over their computers and the desire of content providers to enforce their contentusage contracts.moreover, drm schemes may enforce the rights of content owners at the expense of eroding the rights of content users. the most salient example of such erosion is the impact of drm on fair use, which is the principle allowing the smallscale use of limited amounts of copyrighted materials for certain limited purposes.7 some drm implementations eliminate fair use because of the difculty in algorithmically distinguishing between fair use and illegal copying. another problem is that drm schemes often force the user into using the content on only one devicešuse on a second device requires a second copy. the overall effect of such implementations, especially in the long run, has important public policy implications that are as yet poorly understood.8the economic model for drm rests on the premise that illegal copies of a work deprive the content owner of the revenues that would be associated with the legal sale of those copies. there is some merit to this claim, and yet it is not the only factor in play. for example, estimating lost revenues in this fashion surely overstates the revenue loss, since some of the copies distributed illegally would be acquired by parties who would not have paid for legal copies in the absence of the illegal copies. also, by some accounts, unprotected digital content can spur rather than impede sales of that content. these points suggest that the net outcome of widespread drm implementation is uncertain, and thus the longterm economic rationale for these drm schemes is poorly understood. still another issue with drm is that drm technology is usually designed with a failure mode that defaults to ﬁdeny access.ﬂ that is, because drm technology generally serves the interests of content owners rather than of content users, the operating principle for drm is to deny access to the content unless the user can provide appropriate authorization for access. thus, drm itself introduces a potential security vulnerability to a denialofservice attack that can be exploited by an adversary clever enough to interfere with the authorization mechanisms involved. 7 fair use is dened by statute in sections 107 through 118 of title 17 of the u.s. code. see http://www.copyright.gov/title17/92chap1.html.8 a hardwarebased approach is not the only possible approach to digital rights management. another approach is based on accountability. a contentusage contract could be enforced legally by embedding into every legitimate copy of electronic content a unique identier (known as a watermark). if an illegal copy is discovered, the embedded identier can be used to identify the original owner, who has presumably allowed the original version to be copied in violation of the contentusage contract. however, this approach fails if the user can remove the watermark before copying occurs, and there is no reason to believe that it is possible to develop an unremovable watermark. in addition, the identied user could claim that the content was stolen. finally, this approach requires individual prosecution for every illegal copy foundša major disadvantage when widespread copying is at issue.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 2šenabling accountability 123although the most common use today of drm is the protection of copyrighted works that are sold for prot, the philosophy underlying drmšthat content providers should have the ability to exercise negrained control over how their content is usedšcan be used to support individuals in protecting their own documents and other intellectual property in precisely the same ways. for example, a may wish to send a sensitive email to b, but also to insist that b not print it or forward it to anyone else. some drm systems are available today that seek to provide controls of this nature within the boundaries of an enterprise.this kind of drm application operates in an environment very different from a copyrightenforcement regime. in a copyrightenforcement regime, the primary concern is preventing the improper largescale distribution of copyrighted works, whereas the concerns in an enterprise drm regime are more varied (e.g., individuals may have more concerns about the time periods during which content may be available). because the particular set of rights relevant to any given recipient is more varied, users must specify in detail the rights they wish to grant to content recipients. although default settings ease the burden, many users still nd enterprise drm systems cumbersome and clumsy from a usability standpoint. in addition, because the scale of rights enforcement is necessarily much more negrained (one improperly forwarded email can become very problematic), there are higher premiums and greater needs for protections against actions such as ﬁscreen scrapingﬂ as a way of obtaining machinereadable content in violation of the rights mechanism. finally, both sender and recipient must generally operate within the same enterprisešusually, a sender who wants to engage a recipient outside the enterprise does not have the functionality afforded by the drm system.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.124the goal of requirements in category 3špromoting deployment, is that of ensuring that the technologies and procedures in categories 1 and 2 of the committee™s illustrative research agenda are actually used to promote and enhance security. this broad category includes technologies that facilitate ease of use, by both end users and system implementers; incentives that promote the use of security technologies in the relevant contexts; and removal of barriers that impede the use of security technologies. 6.1 usable securityit is axiomatic that security functionality that is turned off or disabled or bypassed or not deployed by users serves no protective function. the same is true for security practices or procedures that are promulgated but not followed in practice. (this section uses the term ﬁsecurityﬂ in its broadest sense to include both technology and practices and procedures.) yet, even in an age of increasing cyberthreat, security features are often turned off and security practices are often not followed. today, security is often too complex for individuals and enterprise organizations to manage effectively or to use conveniently. security is hard for users, administrators, and developers to understand; clumsy and awkward to use; obstructs all of these parties in getting real work done; and does not scale easily to large numbers of users or devices to be protected. thus, many cybersecurity measures are circumvented by the users they are intended 6category 3špromoting deploymenttoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 125to protect, not because these users are lazy but because these users are well motivated and trying to do their jobs. when security gets in the way, users switch it off and work around it, designers avoid strong security, and administrators make mistakes in using it.it is true that in the design of any computer system, there are inevitable tradeoffs among various system characteristics: better or less costly administration, trustworthiness or security, ease of use, and so on. because the intent of security is to make a system completely unusable to an unauthorized party but completely usable to an authorized one, there are inherent tradeoffs between security and convenience or ease of access.one element of usable security is better education. that is, administrators and developersšand even end usersšwould benet from greater attention to security in their information technology (it) education, so that the concepts of and the need for security are familiar to them in actual working environments (box 6.1). in addition, some aspects of security are necessarily left for users to decide (e.g., who should have access to some resource), and users must know enough to make such decisions sensibly.the tradeoff between security and usability need not be as stark as many people believe, however, and there is no a priori reason why a system designed to be highly secure against unauthorized access cannot also be userfriendly. an example case in which security and usability have enhanced each other in a noncybersecurity context is that of modern hotel room keys. key cards are lighter and more versatile than the old metal keys were. they are easier for the guests to use (except when the magnetic strip is accidentally erased), and the system provides the hotels with useful security information, such as who visited the room and whether the door was left ajar. modern car keys are arguably more secure and more convenient as well.the committee believes that efforts to increase security and usability can proceed simultaneously for a long time, even if they may collide at some point after attempts at better design or better engineering have been exhausted. many of the usability problems of today have occurred because designers have simply given up too soon, before serious efforts have been made to reconcile the tension. all too often, the existence of undeniable tensions between security and access is used as an excuse for not addressing usability problems in security. one part of the problem is that the interfaces are often designed by programmers who are familiar with the technology and often have a level of literacy (both absolute and technical) well above that of the average end user. the result is interfaces that are generally obvious and well understood by the programmers but not by the end users. few programmers even have awareness of interface issues, and fewer still have useful traintoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.126 toward a safer and more secure cyberspaceing and background in this subeld. for example, security understandings are often based on physicalworld metaphors, such as locking doors and obscuring sensitive information. these metaphors have some utility, and yet considerable education is needed to teach users the limitations of the metaphors. (consider that in a world of powerful search tools [e.g., google™s desktop, and spotlight on mac computers], it is not realistic for those in possession of sensitive information to rely on ﬁtrusting other people not to look for sensitive informationﬂ or ﬁburying information in box 6.1 fluency with information technology (and cybersecurity)a report entitled being fluent with information technology published several years ago by the national research council (nrc) sought to identify what everyoneševery useršought to know about information technology.1 written in 1999, that report mentioned security issues in passing as one subtopic within the general area of information systems. subsequently, lawrence snyder, chair of the nrc committee on information technology literacy responsible for the 1999 report, wrote fluency with information technology: skills, concepts, and capabilities.2 the university of washington course for 2006 based on this book (http://www.cs.washington.edu/education/courses/100/06wi/labs/lab11/lab11.html) addresses security issues in greater detail by setting forth the following objectives for the security unit:learn to create strong passwords set up junk email ltering use windows update to keep your system up to date update mcafee virusscan so that you can detect viruses use windows defender to locate and remove spywareanother nrc report, ict fluency and high schools: a workshop summary,3 released in 2006, suggested that security issues were one possible update to the ˚uency framework described in the 1999 nrc report.taken together, these reports indicate that in the 8 years since being fluent with information technology was released, issues related to cybersecurity have begun to become important even to the most basic it education efforts.1national research council. 1999. being fluent with information technology. national academy press, washington, d.c.2lawrence snyder. 2002. fluency with information technology; skills, concepts, and capabilities. addisonwesley, lebanon, ind.3national research council. 2006. ict [information and communications technology] fluency and high schools: a workshop summary. the national academies press, washington, d.c.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 127subsubsubsub directories,ﬂ whereas in the absence of such tools, such actions might well have considerable protective value.) the difculty of overcoming such limitations suggests that it is simply unrealistic to expect that security should depend primarily on security education and training. in addition, the extra training and education for security simply do not match the market, with the predictable result that users don™t spend much time learning about security. users want to be able to buy and use it without any additional training. vendors want to sell to customers without extra barriers. couple these realities with the projection that the internet user population will double in the next decade, with hundreds of millions of new users, and it is clear that we cannot depend on extra education and training to improve security signicantly.if user education is not the answer to security, the only other possibility is to develop more usable security mechanisms and approaches. as a starting point, consider the following example. individuals in a company may need to share les with one another. when these persons are in different work units, collaboration is often a hassle. using today™s security mechanisms, it is likely that these people would have to go through an extended multistep process to designate le directories that they want to share with one anotheršmanaging accesscontrol lists, giving specic permissions, and so on. depending on the level of inconvenience entailed, these individuals may simply elect to email their les to one another, thus circumventing entirely the difculties of inhouse collaborationšbut also making their les vulnerable to all of the security issues associated with the open internet. it would be much more preferable to have mechanisms in place that aggregate and automatically perform lowlevel security actions under an abstraction that allows each user to designate another person as a collaborator on a given project and have the system select the relevant les to make available to that person and to no others.usable security would thus reduce the cognitive load needed by an authorized user to navigate security and the ﬁhassle factor,ﬂ thus increasing the likelihood that users would refrain from simply bypassing security measures or would never implement them in the rst place. such issues go far beyond the notion of ﬁwizards,ﬂ which all too often simply mask an underlying complexity that is inherently difcult to understand. system administrators are also an important focal point for usable security. because system administrators address lowlevel system issues much more often than end users do, they are usually more knowledgeable about security matters and are usually the ones to whom end users turn when security issues arise. but many users (e.g., those in small businesses) must perform their own system administrationša point suggesting that remote security administration, provided as a service, has an toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.128 toward a safer and more secure cyberspaceimportant role to play while more usable security mechanisms are not widely deployed.in addition, the fact that system administrators are more knowledgeable than end users about lowlevel security issues does not mean that they do not nd administering those issues to be a burden. for example, system administrators rather than vendors must make decisions about access controlšwho should have what privileges on a systemšsimply because the vendor does not and cannot know to whom any particular user is willing to grant access to a resource. however, this fact does not mean that it should be difcult to specify an accesscontrol list. many computer security problems result from a mismatch between a security policy and the way that the policy is or is not implemented, and system administrators would benet greatly from automated tools that would indicate how their systems are actually congured and whether an actual conguration is consistent with their security policy. for example, administrators need to be able to set appropriate levels of privilege for different users, but they also need to be able to generate lists of all users with a given level of privilege. some tools and products offer some capability for comparing installed congurations with dened security policies, but more work needs to be done on tools that enable security policies to be described more clearly, more unambiguously, and more easily. such tools are needed, for example, when security policies change often. a related though separate point is the extent to which new systems and networks can or should include ideas that involve signicant changes from current practice. though end users are the limiting case of this issue (e.g., ﬁhow can you deploy systems that require the habits of 200 million internet users to change and a whole industry to support them?ﬂ), the issue of requiring signicant change is also relevant to system administrators, who are fewer in number but may well be as resistant to change as end users are.in some cases, issues may arise that fundamentally require end users to alter their ways of doing business. consider the question of whether the end user should or should not make a personal choice about whether or not to trust a certicate authority. one line of argument suggests that such a question is too important to handle automatically. if so, users may indeed be required to change their habits and learn about certicate authorities. but the countering line of argument is that systems that require users to make such decisions will never be deployed on a large scale, regardless of their technical merits, and there is ample evidence that most users are not going to make sensible choices about trusting certicate authorities. one way of addressing such differences is to develop technology that by default shields users from having to make such choices toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 129but nevertheless provides those who wish to do so with the ability to make their own choices.the quest for usable security has social and organizational dimensions as well as technological and psychological ones. researchers have found that the development of usable security requires deep insight into the humaninteraction dimensions of the application for which security is being developed and of the alignment of technical protocols for security and of the social/organizational protocols that surround such security. only with such insight is it possible to design and develop security functionality that does not interfere with what legitimate workers must do in the ordinary course of their regular work. (that is, such functionality would not depend on taking explicit steps related only to security and nothing else.) for example:individuals generally have multiple cyberidentities. for example, a person may have a dozen different login names to different systems, each of which demands its own password to access. different identities often mean that the associated roles differ, for example, by machine, by user identities, by privilege, and so on. it is hard enough to remember different login names, which may be necessitated because the user™s preferred login name is already in use (the login name johnsmith is almost certainly already in use in most largescale systems, and any given john smith may use johnsmithamex or johnsmithcitibank or johnsmithphone as his login name, depending on the system he needs to access). but what about passwords? in order to minimize the cognitive load on the user, he or she will often use the same password for every sitešand in particular will not tailor the strength of the password to the importance or the sensitivity of the site. alternatively, users may plead for ﬁsinglesignonﬂ capability. being required to present authentication credentials only once is certainly simpler for the user but is risky when different levels of trust or security are involved.individuals usually don™t know what they don™t know. a common approach to security is to hide objects from people who do not have explicit authorization to access them, and to make these objects visible to people who do have explicit authorization. from a business process standpoint, there is an important category that this approach to security does not recognizešindividuals who should have explicit authorization for access but do not. authorization is granted in one of two ways: the individual receives authority unbidden (e.g., a new hire is automatically granted access to his toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.130 toward a safer and more secure cyberspaceor her unit™s server), and/or the individual requests authorization from some authority who then decides whether or not to grant that authority. the latter approach, most common when some ad hoc collaborative arrangement is made, presumes that the individual knows enough to request access. but if the necessary objects are hidden from the individual, how does he or she know that it is necessary to request access to those specic objects? such issues often arise in an environment dealing with classied information in which, because of secrecy and compartmentalization, one party does not know what information another party has. individuals function in a social and organizational context, and processes for determining access rights are inherently social and organizational. when necessary accesses are blocked in the name of security, individuals must often expend considerable effort in untangling the web of confusion that is the ultimate cause of the denial of access. individuals with less aggressive personalities, or newly hired individuals who do not want to ﬁmake troubleﬂ may well be more reluctant to take such actionšwith the result that security policies and practices have kept employees from doing their work. addressing these social and organizational dimensions of security requires asking questions of a different sort than those that technologists usually ask. technologists usually seek to develop solutions or applications that generalize across organizational settingsšand users must adapt to the requirements of the technology. focusing on the social and organizational dimension implies developing understandings of what end users are trying to accomplish, with whom, and in what settings. what is the organization trying to achieve? what are the daytoday security practices of effective employees? what are the greatest security threats? what information must be protected? what workplace practices are functional and effective and should be preserved in security redesigns? these understandings then support and may even drive design innovation at the network, infrastructure, and applications interface levels. a social and organizational understanding of security is based on posing questions at several distinct levels. in an organization, senior management determines security policy and establishes the nature and scope of its security concerns. but management also shapes a much larger social context that includes matters such as expectations for cooperative work, the nature of relationships between subordinates and superiors, and relationships between support and business units. at the same time, individuals and groups in the organization must interpret managementdetermined security concerns and implement managementdetermined policyšand these individuals and groups generally have considerable toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 131latitude in doing so. most importantly, individuals and groups must get their primary work done, and security is by denition peripheral to doing the primary work of the organization. thus, because there is often con˚ict, or at least tension, between security and getting work done, workers must make judgments about what risks are worth taking in order to get their work done and how to bypass security measures if that is necessary in order to do so.it is against this backdrop that the technology infrastructure must be assessed. at the applications and task levels, it is important to understand how datasharing practices are managed and what interorganizational and intraorganizational information ˚ows must be in place for people to work effectively with others. a key dimension of datasharing practices is access privilegesšhow are they determined, and how is knowledge of these privileges promulgated? (this includes, of course, knowing of the privileges themselves as well as their settings.) technology development so assessed implies not only good technology, but extensive tools that facilitate organizational customization and that help end users identify what needs to be communicated and to whom.6.2 exploitation of previous workthere is a long history of advances in cybersecurity research that are not re˚ected in today™s practice and products. in many cases, the failure to adopt such advances is explained at least in part by a mismatch between market demands and the products making use of such research. for example, secure architectures often resulted in systems that were too slow, too costly, too late, and/or too hard to use. nevertheless, the committee believes that some security innovations from the past are worth renewed attention today in light of a new underlying technological substrate with which to implement these innovations and a realization that inattention to nontechnical factors may have contributed to their nonuse (section 3.4.1.4). these previous innovations include, but are not limited to the following:virtual machine architectures that enable strict partitions and suitable isolation among different users, as discussed in section 4.1.2.3 (process isolation);multilevel security and multilevel integrity that enable the simultaneous processing of information with different classication levels;with the exception of the as/400, system 38 (now the ibm iseries), capability architectures that have not traditionally been successful but could prove to have valuable lessons to teach; andtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.132 toward a safer and more secure cyberspacesoftware engineering practices and programming tools for developing secure and reliable systems.ﬁoldﬂ but unadopted innovations that solved real cybersecurity problems are often plausible as points of departure for new research that addresses these same problems. as an example of early work that may be relevant today, consider what might be called a ﬁsmallprocess/messagepassingﬂ model for computation, in which a user™s work is performed using multiple loci of control (generally called threads), which communicate with one another by means of signals and messages. exemplied by unix, this model has a demonstrated ability to optimize machine resources, especially processor utilization; while one thread may be blocked waiting on, say, disk access, other threads can be performing useful tasks.the smallprocess/messagepassing model does, however, have some disadvantages for security. a secure machine must map some set of external attributes, such as user identity, role, and/or clearance into the internal workings of the machine and use those attributes to enforce limits on access to resources or invocation of services. the internal data structures used to enforce these limits is often called the ﬁsecurity state.ﬂ the security state of a smallprocess/messagepassing structure is diffuse, dynamic, and spread throughout a large number of processes. furthermore, its relationship to the hardware is tenuous. it is therefore hard to analyze and verify.an alternative structure is the ﬁlargeprocessﬂ model of computation, an example of which was multics. in the largeprocess model, the work being done for a user is tied to a single locus of control, and the security state is mostly embodied in a hardwareenforced structure. this model relies on multiplexing between users to gain efciency (as opposed to the smallprocess model, which multiplexes between threads working for a single user) and is efcient only when large numbers of users are sharing a single body of hardware, such as a server. from a security perspective, the advantage of the largeprocess structure is that the security features of the system are easier to understand, analyze, and verify.because hardware resources are increasingly inexpensive, efcient use of hardware is no longer as important as it once was. designs based on the need to use hardware efciently have also had undesirable security consequences, and with the dropping cost of hardware, it may make sense to revisit some of those designs in certain circumstances. for example, the multicore processor (discussed brie˚y in section 4.1.2.1) holds some promise for mitigating the performance penalties of the largeprocess model, and permitting the security and verication advantages to be exploited in certain contexts. although a smallprocess/messagepassing model is sensible for distributed computing (e.g., for web services) in which toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 133administrative control is decentralized, the largeprocess model makes sense in applications such as a public utility or central server in which security requirements are under centralized administrative control.6.3 cybersecurity metricscybersecurity is a quality that has long resistedšand continues to resistšprecise numerical classication. today, there are few good ways to determine the efcacy or operational utility of any given security measure. thus, individuals and companies are unable to make rational decisions about whether or not they have ﬁdone enoughﬂ with respect to cybersecurity. in the absence of good cybersecurity metrics, it is largely impossible to quantify costbenet tradeoffs in implementing security features. even worse, it is very difcult if not impossible to determine if system a is more secure than system b. good metrics would also be one element supporting a more robust insurance market in cybersecurity founded on sound actuarial principles and knowledge.1one view of security is that it is a binary and negative propertyšsecure is simply dened as the opposite of being insecure. under this ﬁabsolutistﬂ model, it is easy to demonstrate the insecurity of a system via an effective attack, but demonstrating security requires proving that no effective attack exists. an additional complicating factor is that once an attacker nds a vulnerability, it must be assumed that such knowledge will propagate rapidly, thus enabling previously stymied attackers to launch successful attacks.there are some limited domains, such as the proof of privacy in shannon™s foundational work on perfect ciphers2 and the proof of safety properties guaranteed by the type systems of many modern programming languages that are successful applications of this approach. but on the whole, only relatively small programs, let alone systems of any complexity, can be evaluated to such a standard in their entirety.if security is binary, then a system with any vulnerability is insecurešand metrics are not needed to indicate that one system is ﬁmoreﬂ secure than another. but this absolutist view has both theoretical and practical difculties. one theoretical difculty is that the difference between 1 it is also helpful to distinguish between a metric (which measures some quantity or phenomenon in a reasonably repeatable way) and risk assessment (which generally involves an aggregation of metrics according to a model that provides some degree of predictive power). for example, in the nancial industry, risk assessment depends on a number of metrics relevant to a person™s nancial history (e.g., income, debt, number of years in the same residence, and so on).2 claude shannon, ﬁcommunication theory of secrecy systems,ﬂ bell system technical journal, 28: 656715, october 1949.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.134 toward a safer and more secure cyberspacea secure and a vulnerable software artifact can be as small as one bit, and it is hard to imagine a process that is sensitive enough to determining if the artifact is or is not secure.a practical difculty is that staticcode analysisšpredicting the behavior of code without actually executing itšremains a daunting challenge in the general case. one aspect of the difculty is that of determining if the code in question behaves in accordance with its specications. usually the domain of formal proofs of correctness, this approach presumes that the specications themselves are correctšbut in fact vulnerabilities are sometimes traced to incorrect or inappropriate specications. moreover, the size of systems amenable to such formal proofs remains small compared to the size of many systems in use today. a second aspect of this difculty is in nding functionality that should not be present according to the specications (as discussed in section 4.1.3.1).outside the absolutist model, security is inherently a synthetic propertyšit no longer re˚ects some innate quality of the system, but rather how well a given system with a given set of security policies (section 6.5) can resist the activities of a given adversary. thus, the security of a system can be as much a property of the adversary being considered as it is of the system™s construction itself. that is, measuring the security of a system must be qualied by asking, against what kind of threat? under what circumstances? for what purpose? and under what security policy?in this context, the term ﬁmetricﬂ is not binary. it must be, at the very least, ordinal, so that metrics can be used to rankorder a system along some securityrelevant dimension. in addition, the term ﬁmetricﬂ assumes that one or more outcomes of interest can be measured in an unambiguous wayšthat one can recognize a good outcome or a bad outcome when it occurs. furthermore, it assumes that an improvement in the metric actually corresponds to an improvement in outcome. yet another complicating factor is that an adversary may offer unforeseen threats whose impact on the system cannot be anticipated or measured in advance. while the absolutist modelšwhich depends a great deal on formal proofšpresumes that all security properties can be specied a priori, in practice it is common that a system™s security requirements are not understood until well after its deployment (if even then!). moreover, if a threat (or even a benign event) is unforeseen, a response tailored to that threat (or event) cannot be specied (although a highly general response, such as ﬁabort,ﬂ may be possible, and certain other responses may be known to be categorically undesirable). for example, the cryptography community has had some success in formalizing the security of its systems. proving cryptographic security calls for dening an abstract model of an adversary and then using reductions to prove that key security properties have equivalent computational toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 135hardness to certain wellknown difcult problems. thus, the strength of a cipher can be parameterized as a function of the adversary™s qualitative capabilities (e.g., the ability to inject known plaintext messages into the channel) and quantitative capabilities (e.g., the ability to perform  n computations in time m). however, outside this raried environment, real attackers bypass these limitations simply by working outside the model™s assumptions (e.g., side channel attacks, protocol engineering interactions, and so on). and, sometimes cryptographic primitives can fail, invalidating the model™s assumptions, as illustrated by recently discovered problems in the sha1 hash algorithm.3finally, the security of a system tends to be tightly coupled with the particulars of its conguration, which suggests that security can be a highly fragile property. the same software system may be considerably more secure under the care of one administrator than under the care of another.these challenges suggest that the search for an overall cybersecurity metricšone that would be applicable to all systems and in all environmentsšis a largely fruitless quest. rather, cybersecurity must be conceptualized in multidimensional terms, and metrics for cybersecurity must, for example, take into account the nature of the threat and how a system is operated in practice. users and researchers thus must be clear about the limitations of a given metric (e.g., the metric only applies under the following set of assumptions) and/or create tests that anticipate various classes of adversaries. nevertheless, we have strong intuitions that some systems are in fact more secure than others. while security may always be too complex to submit to a precise analysis, it seems likely that even imperfect approaches may provide useful insights for evaluating current and future systems, provided that the necessary qualiers are taken into account.to date, most attempts to dene security metrics have fallen into one of several broad categories. the rst category is operational metrics. this approach, typied by the security metrics guide for information technology systems from the national institute of standards and technology,4 focuses on measurements of the behavior of an it organization. thus, at the highest level of abstraction, one might measure the fraction of systems that have certain security controls in place, the number of systems operators with security accreditations, the number of organizational components with incident response plans, and so on. enterprise it executives might 3 xiaoyun wang, yiqun lisa yin, and hongbo yu, ﬁfinding collisions in the full sha1,ﬂ advances in cryptologyšcrypto™05; available at http://www.infosec.sdu.edu.cn/paper/sha1cryptoauthnew2yao.pdf.4see  http://csrc.nist.gov/publications/nistpubs/80055/sp80055.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.136 toward a safer and more secure cyberspacealso track outcome data (e.g., number of viruses detected inside the organization, number of intrusions from the outside) and control data (number of machines with antivirus software, number of services exposed by rewall, and so on). operational metrics can be valuable for tracking overall compliance with a security policy and trends in wellestablished problem classes, but they seem unlikely to be useful in providing nergranularity insight about software security.related to operational metrics are what might be called process metrics; these indicate the extent to which an organization follows some best practice or practices. an example of a process metric is the capability maturity model (cmm), which is intended to measure the quality of an organization™s software development processes. in the cmm, organizations are measured from level 1 (corresponding to a development process that is ad hoc and chaotic) to level 5 (corresponding to a development process that is repeatable, welldened, and institutionalized; managed with quantiable objectives and minimal variation in performing tasks; and optimized to produce continuous process improvement).5 process metrics must be correlated with outcome metrics in order to be regarded as successful, and the extent of such correlation is an open question today.a second broad category of metrics is that of product evaluations. this approach focuses on a thirdparty evaluation process for products rather than for organizations. these evaluation processes are typically structured around certications of product security that place a product™s security in a categorical ranking based on its passing certain process benchmarks. for example, the common criteria specify distinct evaluation assurance levels, which require successfully passing a variety of test regimes ranging from functional system testing to formal design verication. typically these certications are based on some combination of software process measures (e.g., what design practices were used in the design of the software) and testing (e.g., validating that unacceptable test inputs are not accepted).the strongest ratings may require a formal analysis of security for a system™s design. however, there are real limits to such metrics for the security eld. first, they are largely disconnected from the software artifact itself and can make few statements about the weaknesses of a particular implementation. second, certication levels are sufciently coarse that most products can only be successfully evaluated within the same narrow range. finally, certication is humanintensive and thus can be 5 the original cmm for software is no longer supported by the software engineering institute. in 2000, the swcmm was upgraded to cmmi® (capability maturity model integration).toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 137very expensive and slow. under the regime of the orange book, many software artifacts were no longer marketed or supported by the vendors by the time the certication had been completed. under the current common criteria regime, many small companies cannot afford to get their products certied, thus creating a potential bias that may inhibit a fully open market in secure and security products.a third category of metrics is post hoc, or outcome, metrics. this is the most datarich category of security metrics because it is driven by  post hoc analysis and characterization of discovered security vulnerabilities or active attacks. examples of an outcome metric might be the following: the rate (number per unit time) of successful penetration attempts of a system when a given cybersecurity action is in place. in this example, a lower value is better (assuming that the threat environment remained the same) but is meaningful only for this particular cybersecurity measure. the fraction of known vulnerabilities that a given cybersecurity measure eliminates or mitigates (cowan™s relative vulnerability metric).6 in this example, a larger fraction is better, subject to the same qualiers. (note that any metric involving the tracking of vulnerabilities over time requires a list of standardized names for vulnerabilities and other information security exposures. developing and maintaining this list are the purposes of the mitre common vulnerabilities and exposures effort and have enabled longitudinal vulnerability analyses and a reduction in confusion when communicating about particular problems.) the cert coordination center (cert/cc) also maintains vulnerability lists that provide common vocabulary, data for classication, and so on.7the time that it takes for a particular kind of worm (e.g., a scanner that chooses a target at random once it has been implanted) to infect a certain fraction of the vulnerable population of internet sites. defenses against this kind of worm can then be characterized in terms of their effect on this time (longer times would indicate defenses of greater effectiveness). staniford et al. present a model of internet worms that parameterizes worm outbreaks in terms of their spreading 6 crispin cowan, ﬁrelative vulnerability: an empirical assurance metric,ﬂ presentation at the workshop on measuring assurance in cyberspace, 44th ifp working group, june 2003; available at http://www2.laas.fr/ifipwg/workshops&meetings/44/.7 for more information on the cert coordination center, see http://www.cert.org/certcc.html.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.138 toward a safer and more secure cyberspacerate.8 following the model of moore et al.,9 defenses can then be evaluated quantitatively as the fraction of susceptible hosts that are protected over a given period of time for a given deployment. in general, this approach is only well suited for evaluating the relative strength of security technologies, and then only when attacks can be abstracted and homogenized. the nancial impact of security penetrations when losses are incurred.  firms cannot make reasonable investment decisions unless they understand the implicit and explicit impact of their security investment decisions. this is a challenging task, but currently the only data available are anecdotal, making the decision to invest difcult to evaluate and compare with other security/nonsecurity investment options. software vulnerabilities are widely reported on public mailing lists and archived in both public and private databases (the national vulnerability database is one such wellknown collection). each vulnerability is typically tagged with its source and the particular systems impacted and the source of the vulnerability. attacks are typically gathered from intrusiondetection system logs and honeypot systems designed to detect new attacks (e.g., symantec™s deepsight and dshield.org are wellknown examples of attackmonitoring systems). such data can be used in a number of ways:relative assessments based on counts. different systems or versions of systems may be compared on the basis of the number of vulnerabilities or attacks they experienced. this is one of the most problematic use of post hoc data, since it presumes that the vulnerabilitydiscovery process and the targetselection process are random and uniform. in fact, both are unlikely to be true. particular systems are likely to be targeted more than others owing to popularity (i.e., because the system provides a wider base to attack), owing to familiarity (i.e., there are fewer people with knowledge of unusual systems), or owing to the particular goals of the attacker (i.e., its intended victim makes extensive use of a particular system). similarly, vulnerability discovery is driven by the same motives as those of attackers as well as by an additional bias from thirdparty 8 stuart staniford et al., ﬁthe top speed of flash worms,ﬂ presented at the acm workshop on rapid malcode (worm), october 29, 2004, washington, d.c.; available at www.icir.org/vern/papers/topspeedworm04.pdf.9 david moore, colleen shannon, and k claffy, ﬁcode red: a case study on the spread and victims of an internet worm,ﬂ pp. 273284 in proceedings of the 2nd acm sigcomm workshop on internet measurement, asm press, new york, 2002.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 139security assessment companies that actively search for new vulnerabilities to enhance their offerings and marketing to potential customers. vulnerability origin studies. rescorla rst synchronized vulnerability data with particular software versions to analyze the time origin of vulnerabilities in popular opensource operating systems and their ﬁlifetimeﬂ distribution.10 ozment and schechter provided a more detailed analysis showing that, at least for the openbsd system, most newly discovered vulnerabilities are not in ﬁnewﬂ code and have existed for long periods of time.11 moreover, they attempt to use reliability growth models to infer changes in the rate of new vulnerabilities being introduced and in the rate of overall vulnerabilities being discovered. while these techniques are necessarily limited (they are inherently ﬁrightcensored,ﬂ since the future is unknown), they suggest a mechanism to identify real trends. this is a nascent area, and there is little doubt that it could be extended to the analysis of particular subsystems, changes in software process, and so on.defense evaluation studies. cowan has argued for using future vulnerability data as a mechanism for evaluating defense approaches.12 his ﬁrelative vulnerabilityﬂ metric would thus provide a means for comparing different hardening approaches, based on the fraction of subsequent vulnerabilities that were blocked. while this approach cannot predict the impact of completely new attacks, it seems well posed to measure the breadth of defenses intended to address particular classes of vulnerabilities. at the same time, there is a natural symbiosis between attacker and defender, and thus popular defenses will be more likely to induce the creation of attacks that work around them.reactivity. moore et al. rst used attack data to infer the rate at which administrators patched systems that were vulnerable to the code red v2 worm.13 rescorla used a more sophisticated version 10 e. rescorla, ﬁis finding security holes a good idea?,ﬂ presentation at the workshop on economics and information security 2004, may 2004; available at http://www.dtc.umn.edu/weis2004/rescorla.pdf.11 andy ozment and stuart e. schechter, ﬁmilk or wine: does software security improve with age?,ﬂ usenix security 2006, 2006; available at http://www.eecs.harvard.edu/~stuart/papers/usenix06.pdf.12 crispin cowan, ﬁrelative vulnerability: an empirical assurance metric,ﬂ presentation at the workshop on measuring assurance in cyberspace, 44th ifp working group, june 2003; available at http://www2.laas.fr/ifipwg/workshops&meetings/44/.13 david moore, colleen shannon, and k claffy, ﬁcode red: a case study on the spread and victims of an internet worm,ﬂ pp. 273284 in proceedings of the 2nd acm sigcomm workshop on internet measurement, asm press, new york, 2002.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.140 toward a safer and more secure cyberspaceof this analysis to analyze patching behavior for vulnerabilities in popular implementations of secure sockets layer (ssl). finally, beattie et al. use patch update data to extrapolate an optimal time to patch (for the purpose of maximizing availability) based on honeypot measures of attack incidence.14 in general, the effects of software maintenance on security is understudied (indeed, rescorla provides an argument that patches can harm security15), and yet considerable empirical data are available on this topic.threat assessments. different vulnerabilities engender different risks. in particular, some vulnerabilities are easier to exploit than others, some have more signicant consequences, some transition more quickly into attacks in the wild, and some persist for longer periods of time. today threat assessments are largely performed on an ad hoc basis, but there is reason to hope that at least some of this activity could be automated and objectied.finally, there are predictive metrics that measure something intrinsic about a given information technology artifact and that are intended to provide an a priori indication of how secure a system is before it is deployed. an example is vulnerability testing/checking metrics that have emerged from recent work enabling the automated detection of classes of security vulnerabilities in software. as opposed to manual penetration testing, automated methods are by design testerindependent and repeatable. staticanalysis approaches include the detection techniques of wagner et al. for buffer over˚ows and format string vulnerabilities16 and the automated analysis and model checking of whole operating system kernels of engler et al.17 while these techniques are neither complete nor accurate (they produce false positives), they are able to consume large software systems and identify potential security vulnerabilities. some systems, exemplied by ganapathy et al., are even able to analyze binary 14 steve beattie et al., ﬁtiming the application of security patches for optimal uptime,ﬂ usenix lisa, 2002; available at http://www.homeport.org/~adam/timetopatch usenixlisa02.pdf.15 e. rescorla, ﬁis finding security holes a good idea?,ﬂ presentation at the workshop on economics and information security 2004, may 2004; available at http://www.dtc.umn.edu/weis2004/rescorla.pdf.16 david wagner, jeffrey s. foster, eric a. brewer, and alexander aiken, ﬁa first step towards automated detection of buffer overrun vulnerabilities,ﬂ network and distributed system security 2000; available at http://www.cs.berkeley.edu/~daw/papers/overrunsndss00.ps.17 dawson engler, david yu chen, seth hallem, andy chou, and benjamin chelf, ﬁbugs as deviant behavior: a general approach to inferring errors in systems code,ﬂ in proceedings of the eighteenth acm symposium on operating systems principles, 2001; available at http://www.stanford.edu/~engler/deviantsosp01.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 141programs, discover new vulnerabilities, and identify precise test cases (i.e., exploits).18 dynamic testing, via fuzz testers, can manipulate both input and environment to test corner cases known to be a source of security vulnerabilities in the past.the most sophisticated of these systems can also triage their own output and determine which vulnerabilities are most likely to be exploitable. using such tools, one can compare this aspect of security across different versions of a software system and evaluate trends in how new detectable vulnerabilities emerge. however, if successful, these tools will become less useful over time as they are introduced into the normal qualityassurance process and the vulnerabilities that they detect are weeded out before deployment. a similar methodology is possible for detecting condentiality violations, using static information ˚ow analysis and dynamic taint checking; however, this particular approach has not been explored as a security metric per se (although garnkel uses one such technique to demonstrate the presence of information leakage in a commodity operating system19). another type of predictive metric addresses the attackability of a system. howard and leblanc developed the notion of an attack surface,20 which is dened in terms of externally visible and accessible system resources that can be used to mount an attack on the system and subsequently weighted according to the potential damage that could be caused by any given exploitation of a vulnerability. larger attack surfaces indicate a larger extent of potential vulnerability, and vulnerabilities in a system can be reduced by reducing the attack surface. attack surface measures potential rather than actual aggregate vulnerability. the presumption, supported in part with post hoc data, is that smaller attack surfaces are likely to host fewer exploitable vulnerabilities and will be easier to secure. while howard and leblanc measure the number of potential ﬁattack vectorsﬂ in a given system and conguration, manadhata and wing have formalized ﬁattack surfaceﬂ without reference to howard and leblanc™s attack vectors.21 the attacksurface metric appears to have promise, but as of yet it is still largely a manual enterprise.22 18 vinod ganapathy et al., ﬁautomatic discovery of apilevel exploits,ﬂ in proceedings of the 27th international conference on software engineering, st. louis, mo., pp. 312321, 2005.19 simson l. garnkel, information leakage and computer forensics, center for research on computation and society, harvard university, february 17, 2006.20 michael howard and david leblanc, writing secure code, second edition, microsoft press, seattle, wash., 2002.21 p. manadhata and j.m. wing, an attack surface metric, cmucs05155, technical report, pittsburgh, pa., july 2005.22 manadhata and wing also have made progress on a more semiautomated process for analyzing source code. see p.k. manadhata, j.m. wing, m.a. flynn, and m.a. mcqueen, toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.142 toward a safer and more secure cyberspaceresearch to further develop the types of metrics described above is needed. outcome metrics would have high utility for characterizing the impact of some cybersecurity measures, whether technical or procedural. because predictive metrics seek to characterize artifacts themselves, they would facilitate comparative assessments among different software options and congurations. generalizing across these different types of metrics, the committee believes that some of the most promising lines of research involve the simultaneous use of different combinations of metrics. for example, an automated analysis of attacksurface metrics might be designed so that the resulting data could direct vulnerability testing, or post hoc metrics might be used to create quantitatively driven threat assessments. in addition, it would be enormously valuable if metrics useful for understanding security behavior and phenomena in detail could be composed into metrics relevant to aspects of overall system behavior. today, little is known about how to combine metrics of detailed behavior into metrics of larger scope, and research will be needed to advance this goal. finally, metrics ought to be subject to a continuing validation process in which various metrics are assessed against incidents as they become known, in order to determine what such metrics might predict about the character of such incidents.a note of caution is also appropriate in the search for cybersecurity metrics. researchers have sought good metrics for many years, and though many benets would ˚ow from the invention of good metrics, the challenge in this cybersecurity research area is particularly great, and some very new ideas will be needed if cybersecurity metricians are to make more progress. 6.4 the economics of cybersecuritythis section provides an economic perspective on why cybersecurity is hard and on why (if at all) there is underinvestment in cybersecurity.23 determining the right amount to spend on information security activities in total is linked to efciently allocating such resources to specic organizational it activities. for example, organizations need to determine how much to spend on hardware, software, stafng, and personnel training. ﬁmeasuring the attack surfaces of two ftp daemons,ﬂ quality of protection workshop, alexandria, va., october 30, 2006.23 ross anderson, ﬁwhy information security is hardšan economic perspective,ﬂ proceedings of the 17th annual computer security applications conference, ieee computer society, new orleans, la., 2001, pp. 358365.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 143the committee believes that insight into many problems of cybersecurity can be gained by exploiting the perspective of economics: network externalities, asymmetric information, moral hazard, adverse selection, liability dumping, risk dumping, regulatory frameworks, and tragedy of the commons.24 as this list implies, the breadth of economic barriers to improving cybersecurity is extensive and nontrivial. these economic factors can result in a potential for market failureša lessthanoptimal allocation of resources. taken together, their presence creates a complex and interrelated set of perverse incentives for economic actors. these economic factors go a long way toward explaining why, beyond any technical solutions, the provision of cybersecurity is and will be a hard problemšone requiring research and policy solutions beyond funding technology researchšto ameliorate. in contrast to the large body of technical research on cybersecurity, research related to the economics of cybersecurity is still nascent.25 however, a small but growing body of literature is beginning to provide insights into the necessary elements of the economic analysis essential for addressing policy aspects of cybersecurity. for example, alderson and soo hoo note that most of the public policy initiatives to address the safety and security of the u.s. national information infrastructure have ignored the stakeholder incentives to adopt and to spur the development of security technologies and processes. they suggest that continuing insecurities in cyberspace are in large part the direct result of a public policy failure to recognize and address those incentives and the technological, economic, social, and legal factors underlying them, and argue that the deployment of a more secure cyber infrastructure could be accelerated by careful consideration of stakeholder incentives.26 solutions that emerge from such research are likely to be subtle and partial, requiring the cooperation and coordination of technology researchers, engineers, economists, lawyers, and policy makers. any combination of solutions needs to incorporate a fundamental principle of economic analysis: assign responsibility to parties in proportion to their capabilities for managing the risk.2724 ross anderson, ﬁwhy information security is hardšan economic perspective,ﬂ proceedings of the 17th annual computer security applications conference, ieee computer society, new orleans, la., 2001, pp. 358365.25 lawrence a. gordon and martin p. loeb, ﬁbudgeting process for information security expenditures,ﬂ communications of the acm, january 2006, vol. 49, no. 1, p. 121.26 david alderson and kevin soo hoo, ﬁthe role of economic incentives in securing cyberspaceﬂ; available at http://iisdb.stanford.edu/pubs/20765/aldersonsoo hoocisacrpt1.pdf.27 hal varian, ﬁmanaging online security risks,ﬂ economic science column, new york times, june 1, 2000; ross anderson and tyler moore, ﬁthe economics of information security,ﬂ science, 314(5799): 610613, october 27, 2006.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.144 toward a safer and more secure cyberspace6.4.1 con˚icting interests and incentives  among the actors in cybersecuritythere are a number of different actors whose decisions affect the cybersecurity posture of the nation and various entities within the nation: technology vendors, technology service providers, consumers, rms, law enforcement, the intelligence community, attackers, and governments (both as technology users and as guardians of the larger social good). each of these actors gets plenty of blame for being the ﬁproblemﬂ: if technology vendors would just properly engineer their products, if end users would just use the technology available to them and learn safe behavior, if companies would just invest more in cybersecurity or take it more seriously, if law enforcement would just pursue attackers more aggressively, if policy makers would just do a better job of regulation or legislation, if attackers could just be deterred from launching attacks. . . .there is some truth to such statements, and yet merely to state them does not advance the cause of better understanding and solutions. in particular, knowing why various actors behave as they do is the rst step toward changing their behavior. indeed, one could easily argue that from an economic perspective, each of these actors is behaving largely as might be anticipated on the basis of their interests and incentives and that the reasons underlying their behavior are perfectly reasonable from an economic standpoint, despite the negative impacts on cybersecurity.28 consider rst the incentives of the attacker. partly because the incentive structure of the attacker is undesirable from a societal perspective and partly because there is clear moral high ground in going after the bad guy, most regulatory and legislative activity has thus far focused on changing the incentive structure of the attacker to make it more dangerous to conduct an attack.29 for example, laws have been passed criminalizing certain kinds of activity and increasing the penalties for such activity. rewards have been offered for information leading to the arrest and conviction of cyberattackers. on the other hand, jurisdictional issues and the anonymity offered by the intrinsically international nature of cyberspace have served to prevent or at least to greatly impede and increase the cost of identifying and prosecuting cyberattackers. in other words, in practice, 28 see, for instance, hal varian, ﬁmanaging online security risks,ﬂ economic science column, new york times, june 1, 2000; alfredo garcia and barry horowitz, ﬁthe potential for underinvestment in internet security: implications for regulatory policy,ﬂ journal of regulatory economics, 31(1): 3755, february 2007, available at http://ssrn.com/abstract=889071; tyler moore, ﬁthe economics of digital forensics,ﬂ presented at the fifth annual workshop on the economics and information security, june 2628, 2006, cambridge, england; ross anderson and tyler moore, ﬁthe economics of information security,ﬂ science, 314(5799): 610613, october 27, 2006.29 douglas a. barnes, ﬁdeworming the internet,ﬂ texas law review, 83: 279329, 2004.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 145the disincentives for an attacker are minimal, since the likelihood of punishment for an attack is quite low. the attacker™s incentives are part of a larger underground economy. broadly speaking, the actors in this economy are those selling attack services (e.g., use of a botnet, stolen credit card numbers); those with the direct malevolent intent paying to use those services (e.g., those who wish to conduct a denialofservice attack on a site for extortion purposes, those who wish to commit actual fraud); and the victims of the resulting cyberattacks (e.g., the operators of the web site being attacked, those whose credit card numbers are used for fraudulent purposes [or the banks that absorb the fraudulent charges]). the existence of this economy makes manifest a decoupling between adversarial or criminal intent and the expertise needed to follow through on that intent, thus expanding enormously the universe of possible malefactors. in other words, attack services (e.g., botnets as described in box 2.3 in chapter 2) can be regarded as an economic commodity. for example, if someone needs a botnet for some purpose, that party can obtain the use of a botnet in the appropriate market.insight into the underground cybereconomy of attackers potentially yields pressure points on which to focus security efforts. for example, the sellers of attack services must publicize the availability of their services in an appropriate marketplace, and it may be possible to target the sellers themselves. it may also be possible to interfere with the operation of the marketplace itself, by shutting down the various marketplace venues or by poisoning them so that buyers and sellers cannot trust each other.in addition, many of the constraints on digital forensics practices, essential to law enforcement, are due to con˚icting incentives of technology vendors, service providers, consumers, and law enforcement.30 for example, technology vendors have economic incentives to differentiate their products by making them proprietaryšbut in a regime in which there are many proprietary products on the market, law enforcement ofcials must have at the ready a range of forensic tools that together can operate on a wide range of products embedding multiple standards.technology vendors have signicant nancial incentives to gain a rstmover or a rsttomarket advantage. they are driven by important features of the information technology market: the number of other people using a product, the high xed costs and low marginal costs, and the cost to customers of switching to another product (i.e., lockin).31 30 tyler moore, ﬁthe economics of digital forensics,ﬂ fifth annual workshop on the economics of information security, university of cambridge, england, june 2628, 2006.31 carl shapiro and hal r. varian, information rules: a strategic guide to the network economy, harvard business school press, boston, mass., 1998. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.146 toward a safer and more secure cyberspacethese network effects have signicant consequences for engineering an information system for security.32 timetomarketša key dimension of competitiveness in the industryšis adversely affected when vendors must pay attention to ﬁsuper˚uousﬂ functionality or system characteristics, and functionality or system characteristics that customers do not demand are by denition super˚uous. the logic of getting to market quickly runs counter, however, to adding security features, which add complexity, time, and cost in design and testing while being hard to value by customers. in addition, there is often an operational tension between security and other functionality that customers demand explicitly, such as ease of use, interoperability, and backward compatibilityšconsider, for example, security measures that may make it difcult or cumbersome to respond quickly in an emergency situation.information technology purchasers (whether individuals or rms) largely make product choices based on features, ease of use, performance, and dominance in a market,33 although in recent years the criteria for product selection have broadened to include security to some extent in some business domains. but even to the extent that consumers do consider security, there is an information asymmetry that makes it difcult or impossible for them to distinguish between products that are secure and ones that are not. this leads to the ﬁmarket for lemonsﬂ problem described by akerlof 34šbuyers are unwilling to pay for something (in this case security) that they cannot measure, so leading vendors to avoid the extra costs of providing something they cannot recover. evaluation systems, such as the common criteria, have been attempts to remedy this problem. common criteria and the european information technology security evaluation criteria (itsec) require evaluations to be paid for by the vendor seeking evaluation. this introduces the perverse incentive that motivates vendors to shop around for an evaluation contractor with whom a ﬁsweetheart dealﬂ can be negotiated, leading to the potential for suspect certications.35 certication systems may even have the perverse effect of encouraging those most motivated to transfer liability, 32 ross anderson, ﬁwhy information security is hardšan economic perspective,ﬂ proceedings of the 17th annual computer security applications conference, ieee computer society, 2001, p. 359.33 ross anderson and tyler moore, ﬁthe economics of information security,ﬂ science, 314 (5799): 610613, october 27, 2006.34 george a. akerlof, ﬁthe market for ‚lemons™: quality, uncertainty and the market mechanism,ﬂ quarterly journal of economics, 84: 488500, 1970.35 ross anderson, ﬁwhy information security is hardšan economic perspective,ﬂ proceedings of the 17th annual computer security applications conference, ieee computer society, 2001, pp. 358365. note that while the meaning of such a certication from a technical perspective may also be suspect, it is beside the point made here. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 147meet ﬁdue diligenceﬂ requirements, and take advantage of naïve customers to seek certication. mechanisms such as online ﬁtrustﬂ certications meant to help users determine the safety of their online activities appear to result in adverse selection that undermines that safety, where untrustworthy sites are signicantly more likely than trustworthy ones to seek certication.36 end users improve their own cybersecurity postures when they act to protect their systems, for instance by maintaining antivirus software. but if the tasks required to protect their systems are complex or costly and their own risk of a security compromise is minimal, a user has little motivation to spend time or money preventing others from using their systems for nefarious purposes (e.g., as part of a botnet). for example, universities with relatively unprotected networks were used to attack major commercial web sites but bore only a small amount of the cost (as a nuisance in lost performance).37 while ﬁconcentratedbenetﬂ users, such as large commercial web sites, may suffer serious loss, the harm to ordinary users is diffuse and offset by the costs required to take mitigating action.38 these cases can be recognized as instances of the classic ﬁtragedy of the commonsﬂ problem.39 furthermore, from the standpoint of operators, the benets of successful security can be seen only in events that do not happen, so it is easy to regard resources devoted to security as ﬁwasted.ﬂ the issue of spending money on insurance premiums is similar, but for the conventional losses against which insurance usually protects, there are at least reasonable risk metrics that make quantitative decisions about insurance spending possible. research is needed to accurately characterize the scope and nature of the incentives of these various actors. in addition, understanding the relationships among these actorsšthat is, the marketšis key to nding ways to intervene in the market in order to shape the behavior of its actors.6.4.2 risk assessment in cybersecurityeven if the incentive structures for the various actors could be changed, issues of how much to invest in security and what to invest in 36 benjamin edelman, ﬁadverse selection in online ‚trust™ certications,ﬂ harvard university, cambridge, mass., 2006, draft working paper, available at http://www.benedelman.org/publications/advseltrustdraft.pdf.37 hal varian, ﬁmanaging online security risks,ﬂ economic science column, new york times, june 1, 2000.38 douglas a. barnes, ﬁdeworming the internet,ﬂ texas law review, 83: 279329, 2004.39 ross anderson, ﬁwhy information security is hardšan economic perspective,ﬂ proceedings of the 17th annual computer security applications conference, ieee computer society, 2001, pp. 358365. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.148 toward a safer and more secure cyberspacewould remain. this requires the ability to make sound investments in cybersecurity based on reasonable assessments of the risks. individuals and companies do spend large amounts on security. roughly $100 billion is spent annually on it security worldwide.40 but there are few ways to know how much is enough. indeed, technology solutions can create a false sense of security.41 some models for determining appropriate levels of investment at the rm level have been developed,42 but budgeting for it security is often driven by such things as the past year™s budget, best industry practices, and a list of mustdo items, rather than any sound economic principles. while costbenet approaches appear to be useful for properly determining levels of investment, they are predicated on an ability to estimate benets, which requires understanding the risk prole.43 firms also excessively discount future costs (see the discussion on behavioral economics below in this section) and costs borne by others (section 6.4.3), and to the extent that they optimize their operations and investments at all, they do so on a narrow and shortterm basis.a necessary condition for investing rationally in cybersecurity depends on being able to assess the risks of cyberattack and the benets of countermeasures taken to defend against such attack. section 6.3 addresses the difculties in assessing benets of cybersecurity measures. but assessing risks is also a difcult challenge, especially in a risk environment inhabited at least partly by lowprobability, highimpact events. attempts to construct a business case for cybersecurity often founder because of the unavailability of actuarial data that might help predict in quantitative terms the likelihood of a specic type of attack, and, as discussed below, attacks can change on a short timescale and thereby reduce the utility of such data. in general, such data that are available are not specic enough to drive organizational change, since victims of 40 kenneth cukier, ﬁprotecting our future: shaping publicprivate cooperation to secure critical information infrastructures,ﬂ the rueschlikon conference report of a roundtable of experts and policy makers, washington, d.c., may 2006, p. 12. 41 kenneth cukier, ﬁprotecting our future: shaping publicprivate cooperation to secure critical information infrastructures,ﬂ the rueschlikon conference report of a roundtable of experts and policy makers, washington, d.c., may 2006, p. 12. 42 see for instance, lawrence a. gordon and martin p. loeb, ﬁthe economics of information security investment,ﬂ acm transactions on information and systems security, 5(4, november): 438457, 2002; soumyo d. moitra and suresh l. konda, the survivability of network systems: an empirical analysis, cmu/sei2000tr021, esctr2000021, december 2000, available at http://www.cert.org/archive/pdf/00tr021.pdf.43 lawrence a. gordon and martin p. loeb, ﬁbudgeting process for information security expenditures,ﬂ communications of the acm, 49(1, january): 121, 2006. see also, kenneth cukier, ﬁensuring (and insuring?) critical information infrastructure protection,ﬂ a report of the 2005 rueschlikon conference on information policy, switzerland, june 1618, 2005, p. 7.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 149various attacks are usually quite reluctant to share information on attacks, concerned about drawing public attention to limitations or deciencies in their security posture and/or being placed at a subsequent competitive disadvantage in the marketplace.a major impediment in data collection is the reluctance on the part of owners and operators of it to collect and share the data necessary for companies to know their risk or for the insurance industry to create a viable market.44 indeed, rms have good reasons to avoid disclosing breaches. while economic consequences vary, rms can suffer signicant costs.45 potential negative impacts from public disclosures of information security breaches include lost market value and competitive disadvantage. that is, if one company releases information about an incident and other companies do not release information about their own incidents, the releasing company may well be disadvantaged by its candor in the marketplace as its competitors call attention to its failings. firms also fear legal liability and government nes. indeed, gordon et al. argue that, absent appropriate economic incentives, it is in a rm™s selfinterest to renege on previously agreedon arrangements to share cybersecurityrelated information, even though information sharing among a group of rms lowers the cost of each rm™s attaining any given level of information security and thus yields potential benets both for individual rms and for society at large.46 thus, one research question suggested by the above discussion is the development of incentives that would promote greater information sharing. possible incentives that warrant research include providing public subsidies to informationsharing rms that vary according to the level of information sharing that takes place; governmentsubsidized insurance; and other forms of government regulation. research would entail an examination of how such incentives should be constructed and evaluated and how to prevent the creation of perverse economic incentives that actually discourage information sharing and/or better cybersecurity.44 kenneth cukier, ﬁensuring (and insuring?) critical information infrastructure protection,ﬂ a report of the 2005 rueschlikon conference on information policy, switzerland, june 1618, 2005, p. 22.45 katherine campbell, lawrence a. gordon, martin p. loeb, and lei zhou, ﬁthe economic cost of publicly announced information security breaches: empirical evidence from the stock market,ﬂ journal of computer security, 11: 431448, 2003. this paper examines just one element of potential costsšstock market valuation.46 l.a. gordon, m.p. loeb, and w. lucyshyn, ﬁsharing information on computer systems security: an economic analysis,ﬂ journal of accounting and public policy, 22(6): 461485, 2003. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.150 toward a safer and more secure cyberspacean example of a quantitative costbenet analysis was offered by wei et al. in 2001.47 wei and his colleagues developed a methodology, built a model based on cost factors associated with various intrusion categories, and applied the model to investigating the costs and benets of deploying and using a cooperative intrusiondetection system known as hummer. the model addressed questions such as ﬁwhat is the cost of not detecting an intrusion?ﬂ and ﬁwhat does it cost to detect an intrusion?ﬂ to address the allimportant question of likelihood, wei et al. used empirical data relating to the frequency with which different categories of intrusion occurred in order to calculate the annual loss expectancy (ale) (that is, an attack™s damage multiplied by its empirically estimated frequency in 365 days of system operation). if a security mechanism prevents a certain kind of attack with probability p, the loss thereby avoided is p times ale. the net benet is calculated by subtracting security investment from the sum of all avoided losses over the operational lifetime of the security mechanism installed.another reason for the difculty of risk assessment is that the ﬁlikelihoodﬂ of a particular attack is a reactive quantity. for example, imagine that the historical record shows that a certain type of attack (attack a) has accounted for 50 percent of the attacks against a particular operating system recorded in the past year, while another type of attack (attack b) accounted for only 10 percent of the attacks. now, imagine that resources have been made available to develop a defense against attack a and that now such a defense is available and is being deployed. this deployment will have two resultsšincidents of attack a will almost certainly be reduced (because adversaries will not waste their time conducting ineffective attacks), and incidents of attack b will increase, perhaps absolutely or perhaps only relative to the frequency of attack a. (it is also likely that attacks of still another type, attack c, will emerge, and attacks of this type will never before have been seen. indeed, one might well argue that the ability to create attacks of a type never before seen is part of the denition of a skilled attacker.)more generally, decision makers have few ways to understand and quantitatively characterize the space of possible attacks and the evolution of a threat. since the space of possible attacks is so large, sampling that space is an essential element of tractability. but what are the rules that should govern such sampling? at what level of granularity should attacks be characterized? thus, an important research area is to nd an approach 47 huaqiang wei, deb frinke, olivia carter, and chris ritter, ﬁcostbenet analysis for network intrusion detection systems,ﬂ csi 28th annual computer security conference, october 2931, 2001, washington, d.c.; available at www.csds.uidaho.edu/deb/costbenet.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 151to the calculus of decision making in cyberspace that does not depend as heavily on actuarial data as do current methods. in addition, this research area would seek to develop more usable characterizations of attacks.behavioral economics might suggest research on topics in which human psychological limitations and complications are operative,48 and consequently how actual human behavior in economic matters deviates, often substantially, from that of the rational actor postulated in neoclassical economic theory. in particular, tversky and kahneman have described a mental process known as the availability heuristic, in which individuals assess the magnitude of the risk associated with some harmful event based on whether they can bring examples of harm readily to mind.49 if people can easily think of such examples, their assessment of risk increases (e.g., their judgments about the likelihood go up).in the noncyber domain, slovic found that people are much more likely to buy insurance for natural disasters if they can recall such disasters in their personal histories.50 indeed, policy makers are not immune to the availability heuristicša great deal of experience in national responses to catastrophic events suggests that such events do much more to force policy makers to pay attention to problems than all the reports in the world. applying the availability heuristic to cybersecurity would suggest that if users cannot see a direct and signicant impact on themselves from a cybersecurity problem, their awareness and concern about cybersecurity will be relatively low. the converse would also be true: in the aftermath of a ﬁdigital pearl harbor,ﬂ public attention to cybersecurity would rise dramatically. consider, for example, the security of air transport before and after september 11, 2001 (9/11). prior to the 9/11 attacks, many reports had drawn attention to the weaknesses in ˚ight securityšbut few changes had been made. after the attacks, airport security was dramatically increased, but in ways that many analysts argue provide only a few genuine enhancements in actual security. similarly, in the cybersecurity domain, a very important and relevant research question is how research results and best practices in cybersecurity should be disseminated in an 48 sendhil mullainathan and richard h. thaler, ﬁbehavioral economics,ﬂ international encyclopedia of the social and behavioral sciences; available at www.iies.su.se/nobel/papers/ encyclopedia%202.0.pdf.49 see, for example, a. tversky and d. kahneman, ﬁjudgment under uncertainty: heuristics and biases,ﬂ pp. 322 in d. kahneman, p. slovic, and a. tversky (eds.), judgment under uncertainty: heuristics and biases, cambridge university press, cambridge and new york, 2002.50 p. slovic, the perception of risk, earthscan publications ltd., london and sterling, va., 2000.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.152 toward a safer and more secure cyberspaceatmosphere of sudden enthusiasm that would be inevitable after a digital pearl harbor. gordon et al. go even farther, suggesting that a reactive approach toward the deployment of measures to strengthen cybersecurity beyond some basic minimum may be consistent with an entirely rational (nonbehavioral) economic perspective.51 the essence of the argument is that, given a xed amount to spend on cybersecurity measures, it may make sense to hold a portion of the budget in reserve and wait for a security breach to occur before spending the reserve. by deferring the decision on spending the reserve, managers may obtain a clearer picture about whether or not such spending is warranted. in a waitandsee scenario, actual losses do occur if and when a breach occurs, but the magnitude of those losses may be lower than the expected benets of waiting, and so on balance, it may well pay to wait. for any given company, the implications of this model depend on the specics regarding the costs of security breaches, the costs of various cybersecurity measures to be put into place, the likelihood that specic security breaches will occur, and the magnitude of the budget available. thus, one research theme associated with this perspective would be the development of tools and analytical techniques that would enable reasonable and defensible estimates of all of these various parameters in any given instance.6.4.3 the nature and extent of market failure  (if any) in cybersecurityas noted in section 6.4.1, the various actors in the cybersecurity domain may well be acting just as a rationalactor economic model might predict. in this view, users, vendors, customers, and so on are concerned with security at a level commensurate with the risk they perceive: although cybersecurity problems occur, users of information technology learn to adjust their behavior, expectations, and economic models to take into account these problems, and business decisions are being made appropriately for the level of threat that currently exists. in this view, there is no market failure, and allowing the free market in cybersecurity to work its will is the preferred course of action.to the extent that decision makers do take cybersecurity into account, the natural inclinationšindeed, scal responsibilityšof organizational decision makers is to take only those measures that mitigate the secu51 l.a. gordon, m.p. loeb, and w. lucyshyn, ﬁinformation security expenditures and real options: a waitandsee approach,ﬂ computer security journal, 19(2): 17, 2003. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 153rity problem for their own organizations rather than for society as a whole. (for example, businesses are not required to consider the downside impact of compromising customer privacyšsuch impact results in costs to the customers rather than to the business.) that is, they must make a business case for their security investments, and any investment in security beyond thatšby denitionšcannot be justied on business grounds. thus, beyond a certain level, society rather than the company will benet, and so security at or beyond that level is a public good in which individual organizations have little incentive to invest. in short, incentives for deploying a level of security higher than what today™s business cases will bear are thus nearly nonexistent. accordingly, if the nation™s cybersecurity posture is to be improved to a level that is higher than the level to which today™s market will drive it, the market calculus that motivates organizations to pay attention to cybersecurity must be altered in some ways, and the business cases for the security of these organizations must change.it is a differentšand researchablešquestion about whether the national cybersecurity posture resulting from the investment decisions of many individual rms acting in their own selfinterest is adequate from a societal perspective. this question becomes especially interesting if data and information become available to support business cases for greater cybersecurity investments by individual rms.6.4.4 changing business cases and altering the market calculusthe business case for undertaking any action is based on a comparison of incremental costs and benets. thus, the likelihood of undertaking an action increases if the costs of undertaking it are lower and/or if the benets of taking it are higher. in the cybersecurity domain, for example, efforts to develop and promote usable security (section 6.1) can be fairly regarded as efforts both to avoid lower costs (with security measures many of the benefts will come in the form of cost avoidance) and to reduce disincentives to deploying security functionality. in general, the central element of the economic research agenda for cybersecurity is to identify actions that lower barriers and eliminate disincentives; to create incentives to boost the economic benets that ˚ow from attention to cybersecurity; and to penalize a lack of attention to cybersecurity or actions that cause harm in cyberspace.the discussions below focus on two complementary approaches to changing business casesšapproaches for increasing the ˚ow of relevant information to cybersecurity decision makers and approaches for incentivizing actual change in the behavior of those decision makers.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.154 toward a safer and more secure cyberspace6.4.4.1 letting current threat trends take their courseone approach to increasing the ˚ow of information to decision makers is to wait for the threat environment to change. in this approach, individual organizations monitor their cybersecurity environment and alter their approaches to cybersecurity as changes in their environment occur (e.g., as certain kinds of threats manifest themselves in the future). that is, as the threat changes, so too will customer behavior and vendor business cases. indeed, recent announcements and activities of a number of software vendors indicate that markets have been changing in directions that call for more robust cybersecurity functionality.nevertheless, from a public policy perspective, this approach leaves open the possibility of cyberattacks with consequences that ripple and reverberate far beyond individual organizations and affect important societal functions. the reason is that current cybersecurity efforts respond to the current perception of risk, which is driven by the most visible threats of today. history and intelligence information suggest that vastly more sophisticated threats against a wider variety of targets are likely to be in the ofng, but that these threats will present little overt evidence to motivate further defensive action on the part of most private organizations and individuals.moreover, this approach presumes that organizations can respond to changes in the threat on the necessary timescale. because new kinds of death emerge relatively infrequently, life insurance companies can adjust their actuarial models and develop new rate structures when new threats emerge. but it is not at all clear that changes in the cyberthreat environment will emerge slowly, and indeed considerable evidence exists that it can change quickly. 6.4.4.2 use of existing market mechanisms to improve the flow of information rational investment in security depends on the availability of accurate information about vulnerabilities, and a number of market mechanisms have been developed (though not all have been deployed) to increase the availability of such information. 52 the availability of information about vulnerabilities depends on two factors. one factor is the identication of vulnerabilities; a second factor is the sharing of information about vulnerabilities once identied.52 the discussion of this section is based largely on rainer böhme, ﬁvulnerability markets: what is the economic value of a zeroday exploit?,ﬂ proceedings of 22c3, berlin, germany, december 2730, 2005. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 155one market mechanism that has been used to identify vulnerabilities is the bug challenge or bug bounty.53 bug challenges and bounties are offered by producers who pay a monetary reward for reporting security problems that someone nds. they require the value of the reward to be greater than the amount that the identier might realize by exploiting or selling the vulnerability elsewhere. however, the underlying market mechanism suffers a number of imperfections, particularly in the ability for pricing signals to work efciently, that make it impractical on a large scale.54 (see box 6.2.) bug auctions based on vendor participation have also been considered.55 they are similar in concept to bug challenges, although they are based on different theoretical framework. of course bug auctions could be held independent of vendors, but essentially they act as blackmail for vendors and honest users while providing no useful information about security when no vulnerability is for sale.56 market mechanisms for sharing vulnerability information have also been developed. for example, vulnerability information brokers act as intermediaries among benign identiers of vulnerabilities, users, and vendors.57 because they provide a mechanism for reporting vulnerability information, the u.s. computer emergency response team (cert) acts as vulnerability brokers, although it does not prot from reporting vulnerabilities. some rms have monetized this process by buying information about vulnerabilities and creating business models that offer an advantage of advance knowledge about vulnerabilities to their customers.58 however, these marketbased mechanisms for vulnerability disclosure carry incentives for manipulation (by leaking information) and have been shown to underperform certlike mechanisms.59 53 see for instance, the mozilla security bug bounty program, at http://www.mozilla.org/security/bugbounty.html.54 rainer böhme, ﬁvulnerability markets: what is the economic value of a zeroday exploit?,ﬂ proceedings of 22c3, berlin, germany, december 2730, 2005, p. 2.55 andy ozment, ﬁbug auctions: vulnerability markets reconsidered,ﬂ workshop of economics and information security, minneapolis, minn., 2004.56 rainer böhme, ﬁvulnerability markets: what is the economic value of a zeroday exploit?,ﬂ proceedings of 22c3, berlin, germany, december 2730, 2005, p. 2. see footnote 2 therein.57 karthik kannan and rahul telang, ﬁmarket for software vulnerabilities? think again,ﬂ management science, 51(5, may): 726740, 2005.58 see for instance, idefense quarterly challenge, at http://labs.idefense.com/vcp/ challenge.php#moreq4+2006%3a+%2410%2c000+vulnerability+challenge.59 karthik kannan and rahul telang, ﬁmarket for software vulnerabilities? think again,ﬂ management science, 51(5, may): 726740, 2005; ross anderson and tyler moore, ﬁthe economics of information security,ﬂ science 314(5799): 610613, 2006.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.156 toward a safer and more secure cyberspaceanother asyet untried mechanism for sharing information is based on derivative contracts, by which an underwriter issues a pair of contracts: contract a pays its owner $100 if on a specic date there exists a certain wellspecied vulnerability x for a certain system. the complementary contract b pays $100 if on that date x does not exist. these contracts are then sold on the open market. the issuer of these contracts breaks even, by assumption. if the system in question is regarded as highly secure by market participants, then the trading price for contract a will dropšit is unlikely that x will be found on that date, and so only speculators betting against the odds will buy contract a (and will likely lose their [small] investment). by contrast, the trading price for contract b will remain near $100, so investors playing the odds will prot only minimally but with high probability. the trading prices of contracts a and b thus re˚ect box 6.2 bug bounties and whistleblowersthe bug bountyšpaying for information about systems problemsšstands in marked contrast to the more common practice of discouraging or dissuading whistleblowers (dened in this context as one who launches an attack without malicious intent), especially those from outside the organization that would be responsible for xing those problems. yet the putative intent of the whistleblower and the bug bounty hunter is the samešto bring information about system vulnerabilities to the attention of responsible management. (this presumes that the whistleblower™s actions have not resulted in the public release of an attack™s actual methodology or other information that would allow someone else with genuine malicious intent to launch such an attack.) whether prosecution or reward is the correct response to such an individual has long been the subject of debate in the information technology community.consider, for example, the story of robert morris, jr., the creator of the rst internet worm in 1988. morris released a selfreplicating, selfpropagating program onto the internet. this programša wormšreplicated itself much faster than morris had expected, with the result that computers at many sites, including universities, military sites, and medical research facilities, were affected. he was subsequently convicted of violating section 2(d) of the computer fraud and abuse act of 1986, 18 u.s.c. §1030(a)(5)(a) (1988), which punishes anyone who intentionally accesses without authorization a category of computers known as ﬁ[f]ederal interest computersﬂ and damages or prevents authorized use of information in such computers, causing the loss of $1,000 or more. however, at the time, a number of commentators argued for leniency in morris™s sentencing on grounds that he had not anticipated the results of his experiment, and further that his actions had brought an important vulnerability into wide public view and thus he had provided a valuable public service. it is not known if these arguments swayed the sentenctoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 157the probability of occurrence of the underlying event at any time.60 the derivatives approach requires a trusted third party. this approach shares with insurance underwriters the need to pay upon the occurrence of a breach in order to hedge the risk to which they are exposed. 60 found in rainer böhme, ﬁvulnerability markets: what is the economic value of a zeroday exploit?,ﬂ the concept of the value of derivative contracts re˚ecting the market™s judgment about the security of a system is taken from lawrence a. gordon, martin p. loeb, and tashfeen sohail, ﬁa framework for using insurance for cyberrisk management,ﬂ communications of the acm, 46(3): 8185, 2003; proceedings of 22c3, berlin, germany, december 2730, 2005, p. 3, available at http://events.ccc.de/congress/2005/fahrplan/attachments/542boehme200522c3vulnerabilitymarkets.pdf.ing court, but morris™s sentence did not re˚ect the maximum penalty that he could have received.those who put on public demonstrations of system vulnerabilities have often said that they did so only after they informed responsible management of their ndings and management failed to take remedial action on a sufciently rapid timescale. thus, they argue, public pressure informed and generated by such demonstrations is the only way to force management to address the problems identied. however, these individuals are usually (though not always) outsiders to the responsible organization, and in particular they do not have responsibility for overall management. inside the organization, management may well have evaluated the information provided by the demonstration and judged its operational signicance to be less important than is alleged by the demonstrators. that is, responsible management is likely to have (at least in principle) more information about the relevant operational context, and to have decided that the vulnerability is not worth xing (especially because all attempts at xing vulnerabilities run the risk of introducing additional problems).a further concern is the fear of setting bad precedents. imagine that an individual launches a cyberattack against some organization and causes damage. when caught, the person asserts that his or her intent was to test the defenses of the organization and so he or she deserves a reward for revealing vulnerabilities rather than prosecution. if the individual could cite precedents for such an argument, his or her own defense case would be much stronger.one of the most signicant differences between the bug bounty and the unauthorized public demonstration of system vulnerability is that in the case of the former, the party paying the bountyšusually the vendoršhas demonstrated a receptiveness to receiving the information. but whether other, more controversial mechanisms have value in conveying such information is an open and researchable question.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.158 toward a safer and more secure cyberspace6.4.4.3 privatesector mechanisms to incentivize behavioral changeprivatesector mechanisms to incentivize organizations and individuals to improve their cybersecurity postures do not entail the difculties of promulgating government regulation, and a number of attempts in the private sector have been made for this purpose. research is needed to understand how these attempts have fared, to understand how they could be improved if they have not worked well, and to understand how they could be more widely promulgated and their scope extended if they have.6.4.4.3.1 insurance historically, the insurance industry has played a key role in many markets as an agent for creating incentives for good practices (e.g., in health care and in re and auto safety). thus, the possibility arises that it might be able to play a similar role in incentivizing better cybersecurity.consumers (individuals and organizations) buy insurance so as to protect themselves against loss. strictly speaking, insurance does not itself protect against lossšit provides compensation to the holder of an insurance policy in the event that the consumer suffers a loss. insurance companies sell those policies to consumers and prot to the extent that policyholders do not le claims. thus, it is in the insurance company™s interest to reduce the likelihood that the policyholder suffers a loss. moreover, the insurance company will charge a higher premium if it judges that the policyholder is likely to suffer a loss. particularizing this reasoning to the cybersecurity context, consumers will buy a policy to insure themselves against the possibility of a successful exploitation by some adversary. the insurance company will charge a higher premium if it judges that the policyholder™s cybersecurity posture is weak and a lower premium if the posture is strong. this gives the user a nancial incentive to strengthen his or her posture. users would pay for poor cybersecurity practices and insecure it products with higher premiums, and so the differential pricing of business disasterrecovery insurance based in part on quality/assurance/security would bring market pressure to bear in this area. indeed, cyberinsurance has frequently been proposed as a marketbased mechanism for overcoming security market failure,61 and the importance of an insurance industry role in promoting 61 see, for instance, lawrence a. gordon, martin p. loeb, and tashfeen sohail, ﬁa framework for using insurance for cyberrisk management,ﬂ communications of the acm, 46(3): 8185, 2003; jay p. kesan, ruperto p. majuca, and william j. yurcik, ﬁthe economic case for cyberinsurance,ﬂ workshop on the economics of information security, cambridge, mass., 2005; toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 159cybersecurity was recently noted at the 2005 rueschlikon conference on information policy.62 of course, how such a market actually works depends on the specics of how premiums are set and how a policyholder™s cybersecurity posture can be assessed. (for example, one possible method for setting premiums for the cybersecurity insurance of a large rm might be based in part on the results of an independently conducted red team attack.) furthermore, there are a number of other reasons that stand in the way of establishing a viable cyberinsurance market: the highly correlated nature of losses from outbreaks (e.g., from viruses) in a largely homogenous monoculture environment, the difculty in substantiating claims, the intangible nature of losses and assets, and unclear legal grounds.63 6.4.4.3.2 the credit card industry a prime target of cybercriminals is personal information such as credit card numbers, social security numbers, and other consumer information. because many participants in the credit card industry (e.g., banks and merchants) obtain such information in the course of their routine business activities, these participants are likely to be targeted by cybercriminals seeking such information. to reduce the likelihood of success of such criminal activities, the credit card industry has established the payment card industry (pci) data security standard, which establishes a set of requirements for enhancing payment account data security.64 these requirements include the following:  1. install and maintain a rewall conguration to protect cardholder data. 2. do not use vendorsupplied defaults for system passwords and other security parameters. 3. protect stored cardholder data. 4. encrypt transmission of cardholder data across open, public networks.william yurcik and david doss, ﬁcyberinsurance: a market solution to the internet security market failure,ﬂ workshop on economics and information security, berkeley, calif., 2002.62 kenneth cukier, ﬁensuring (and insuring?) critical information infrastructure protection,ﬂ a report of the 2005 rueschlikon conference on information policy, switzerland, june 1618, 2005.63 rainer böhme, ﬁvulnerability markets: what is the economic value of a zeroday exploit?,ﬂ proceedings of 22c3, berlin, germany, december 2730, 2005, p. 4.64 an extended description of these requirements can be found at http://usa.visa.com/download/business/acceptingvisa/opsriskmanagement/cisppcidatasecurity standard.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.160 toward a safer and more secure cyberspace 5. use and regularly update antivirus software. 6. develop and maintain secure systems and applications. 7. restrict access to cardholder data by business need to know. 8. assign a unique identier to each person with computer access. 9. restrict physical access to cardholder data.10. track and monitor all access to network resources and cardholder data.11. regularly test security systems and processes.12. maintain a policy that addresses information security.organizations (e.g., merchants) that handle credit cards must conform to this standard and follow certain leveled requirements for testing and reporting. compliance with these standards is enforced by the banks, which have the authority to penalize noncompliant organizations and data disclosures caused by noncompliance.6.4.4.3.3 standardssetting processesfor certain specialized applications, compliance with appropriate security standards are almost a sine qua non for their success. for example, for electronic voting applications, security standards are clearly necessary, and indeed the national institute of standards and technology has developed security standardsšor more precisely, voluntary guidelinesšfor electronic voting systems. (these guidelines are voluntary in the sense that federal law does not require that electronic voting systems conform to themšbut many states do have such requirements.)in a broader context, the international organization for standardization (iso) standards process is intended to develop standards that specify requirements for various products, services, processes, materials, and systems and for good managerial and organizational practice. many rms nd value in compliance with an iso standard and seek a public acknowledgment of such compliance (that is, seek certication) in order to improve their competitive position in the marketplace.in the cybersecurity domain, the iso (and its partner organization, the international electrotechnical commission [iec]) has developed iso/iec 17799:2005, which is a code of practice for information security management that establishes guidelines and general principles for initiating, implementing, maintaining, and improving information security management in an organization. iso/iec 17799:2005 contains best practices of control objectives and controls in certain areas of information security management, including security policy; organization of information security; information systems acquisition, development, and maintenance; and information security incident management. although iso/iec toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 16117799:2005 is not a certication standard, the complementary specication standard iso/iec 27001 addresses information security management system requirements and can be used for certication.65 as for the putative value of iso/iec 17799:2005, the convener of the working group that developed iso/iec 17799:2005 argued that ﬁusers of this standard can also demonstrate to business partners, customers and suppliers that they are t enough and secure enough to do business with, providing the chance for them to turn their investment in information security into businessenabling opportunities.ﬂ666.4.4.4 nonregulatory publicsector mechanisms a variety of nonregulatory publicsector mechanisms are available to promote greater attention to and action on cybersecurity, including the following:government procurement. the federal government is a large consumer of information technology goods and services, a fact that provides some leverage in its interactions with technology vendors. such leverage could be used to encourage vendors to provide the government with it systems that are more secure (e.g., with security defaults turned on rather than off). with such systems thus available, vendors might be able to offer them to other customers as well.government cybersecurity practices. the government is an important player in information technology. thus, the federal government itself might seek to improve its own cybersecurity practices and offer itself as an example for the rest of the nation. tax policy. a variety of tax incentives might be offered to stimulate greater investment in cybersecurity.public recognition. public recognition often provides ﬁbragging rightsﬂ for a rm that translate into competitive advantages; cybersecurity could be a candidate area for such recognition. one possible model for such recognition is the malcolm baldrige national quality award, given to rms judged to be outstanding in a number of important business quality areas. the award was established to mark a standard of excellence that would help u.s. organizations achieve worldclass quality.65 see http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber= 39612.66 see http://www.iso.org/iso/en/commcentre/pressreleases/archives/2005/ref963.html.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.162 toward a safer and more secure cyberspacethe desirability and feasibility of these mechanisms and others are topics warranting investigation and research.6.4.4.5 direct regulation (and penalties)still another approach to changing business cases is the direct regulation of technology and usersšlegally enforceable mandates requiring that certain technologies must contain certain functionality or that certain users must behave in certain ways. this is an extreme form of changing the business casesšthat is: comply or face a penalty. the regulatory approach has been taken in certain sectors of the economy: nancial services, health care, utilities such as electricity and gas, and transportation are among the obvious examples of sectors or industries that are subject to ongoing regulation. for many products in common use today, vendors are required by law to comply with various safety standardsšseat belts in cars are an obvious example. but there are few mandatory standards relating to cybersecurity for it products. indeed, in many cases the contracts and terms of service that bind users to it vendors often oblige the users to waive any rights with respect to the provision of security; this is especially true when the user is an individual retail consumer. in such situations, the buyer in essence assumes all security risks inherent in the use of the it product or service in question. (note here the contrast to the guarantees made by many credit card companiesšthe fair credit reporting act sets a ceiling of $50 on the nancial liability of a credit card holder for an unauthorized transaction providing proper notications have been given, and many credit card issuers have contractually waived such liability entirely if the loss results from an online transactions. these assurances have had an important impact on consumer willingness to engage in electronic commerce.)such contracts notwithstanding, direct regulation might call for all regulated institutions to adopt certain kinds of standards relating to cybersecurity ﬁbest practicesﬂ regarding the services they provide to consumers or their own internal practices. for example, in an attempt to increase security for customers, the federal financial institutions examination council (ffiec) has directed covered nancial institutions to implement twofactor authentication for customers using online banking.67 another 67 twofactor authentication refers to the use of two independent factors to authenticate one™s identity. an authentication factor could be something that one knows (e.g., a password), something that one has (e.g., a hardware token), or something that one is (e.g., a ngerprint). so, one twofactor authentication scheme calls for a user to insert a smart card into a reader and then to enter a password; neither one alone provides sufcient authentication, but the combination is supposed to do so.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 163ﬁbest practiceﬂ might be the use of tiger teams (red teams) to test an organization™s security on an ongoing basis. (the committee is not endorsing either of these items as a best practicešthey are provided as illustrations only of possible best practices.)however, regulation is difcult to get right under the best of circumstances, as a good balance of ˚exibility and in˚exibility must be found. regulation so ˚exible that organizations need not change their practices at all is not particularly effective in driving change, and regulation so in˚exible that compliance would require organizations to change in ways that materially harm their core capabilities will meet with enormous resistance and will likely be ignored in practice or not adopted at all.several factors would make it especially difcult to determine satisfactory regulations for cybersecurity.68 attack vectors are numerous and new ones continue to emerge, meaning that regulations based on addressing specic ills would necessarily provide only partial solutions. costs of implementation would be highly variable and dependent on a number of factors beyond the control of the regulated party. risks vary greatly from system to system. there is wide variation in the technical and nancial ability of rms to support security measures. in addition, certain regulatory mechanisms have been used for publicly traded companies to ensure that important information is ˚owing to investors and that these companies follow certain accounting practices in their nances. for example, publicly traded companies must issue annual reports on a u.s. securities and exchange commission (sec) form 10k; these documents provide a comprehensive overview of the company™s business and nancial condition and include audited nancial statements. in addition, publicly traded companies must issue annual reports to shareholders, providing nancial data, results of continuing operations, market segment information, new product plans, subsidiary activities, and research and development activities on future programs. audits of company nances must be undertaken by independent accounting rms and must follow generally accepted accounting practices. intrusive auditing and reporting practices have some precedent in certain sectors that are already heavily regulated by federal and state authoritiesšthese sectors include nance, energy, telecommunications, and transportation.research is needed to investigate the feasibility of using these mechanisms, possibly in a modied form, for collecting information on security breaches and developing a picture of a company™s cybersecurity posture. as an illustration of the value of regulation, consider that in 68 alfredo garcia and barry horowitz, ﬁthe potential for underinvestment in internet security: implications for regulatory policy,ﬂ journal of regulatory economics, vol. 31, no. 1, february 2007; available at http://ssrn.com/abstract=889071.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.164 toward a safer and more secure cyberspace2002, california passed the rst state law to require public disclosure of any breach in the security of certain personal information. a number of states followed suit, and the california law is widely credited with drawing public attention to the problem of identity theft and its relationship to breaches in the security of personal information. an empirical study by gordon et al. found that the sarbanesoxley act of 2002 (p.l. no. 107204, 116 stat. 745) had a positive impact on the voluntary disclosure of information security activities by corporations, a nding providing strong indirect evidence that the passage of this act has led to an increase in the focus of corporations on information security activities.69 but such regulatorydriven focus is not without cost and may have unintended consequences, including decreased competition, distortions in cybersecurity investments and internal controls, and lost productivity from increased risk aversion.70 thus, research is needed to better understand the tradeoffs involved in implementing informationdisclosure regulations. what might be included under such a rubric? one possibility is that a publicly traded company might be required to disclose all cybersecurity breaches in a year above a certain level of severityša breach could be dened by recovery costs exceeding a certain dollar threshold. as part of its audit of the rm™s books, an accounting rm could be required to assess company records on such matters. a metric such as the number of such breaches divided by the company™s revenues would help to normalize the severity of the cybersecurity problem for the company™s size. another possibility is that a publicly traded company might be required to test its cybersecurity posture against a red team, and a sanitized report of the test™s outcome or an independent assessment of the test™s results included in the rm™s sec form 10k report. with more information about a rm™s track record and cybersecurity posture on the public record, consumers and investors would be able to take such information into account in making buying and investment decisions, and a rm would have incentives to improve in the ways re˚ected in such information. (these possibilities should not be construed as policy recommendations of the committee, but rather as some topics among others that are worth researching for feasibility and desirability.)69 lawrence a. gordon, martin p. loeb, william lucyshyn, and tashfeen sohail, ﬁimpact of sarbanesoxley act on information security activities,ﬂ journal of accounting and public policy, 25(5): 503530, 2006. 70 anindya ghose and uday rajan, ﬁthe economic impact of regulatory information disclosure on information security investments, competition, and social welfare,ﬂ 2006 workshop on economics of information security, cambridge, england, march 2006.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 1656.4.4.6 use of liabilityliability is based on the notion of holding vendors and/or system operators nancially responsible through the courts for harms that result from cybersecurity breaches. according to this theory, vendors and operators, knowing that they could be held liable for cybersecurity breaches that result from product design or system operation, would be forced to make greater efforts than they do today to reduce the likelihood of such breaches. courts in the legal system would also dene obligations that users have regarding security.some analysts (often from the academic sector or from industries that already experience considerable government regulation) argue that the nation™s cybersecurity posture will improve only if liability forces users and/or vendors to increase the attention they pay to security matters. opponents argue that the threat of liability would sti˚e technological innovation, potentially compromise trade secrets, and reduce the competitiveness of products subject to such forces. moreover, they argue that there are no reasonable objective metrics to which products or operations can be held responsible, especially in an environment in which cybersecurity breaches can result from factors that are not under the control of a vendor or an operator.an intermediate position connes explicit liability to a limited domain. in this view, regulation or liability or some other extrinsic driver can help to bootstrap a more marketdriven approach. believers in this view assert that new metrics, lampposts, criteria, and so on can be integrated with established processes for engineering or acceptance evaluation. updating the common criteria or the federal information security management act (fisma) to include these mandated elements would enable the injection of the new ideas into the marketplace, and their demonstrated value and utility may persuade others not subject to regulation or liability to adopt them anyway.all of these views on liability were present within the committee, and the committee did not attempt to reconcile them. but it found value in separating the issue into three components. the rst is the putative effectiveness of an approach based on liability or direct regulation in strengthening the nation™s cybersecurity posture. the second is the character of the actual link between regulation or liability and technological innovation and trade secret protection. the third is the public policy choice about any tradeoffs that such a link might imply.regarding the rst and the second, the committee found mostly a set of assertions but exceedingly little analytical work. advocates of regulation or liability to strengthen cybersecurity have not made the case that any regulatory apparatus or case law on liability can move quickly toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.166 toward a safer and more secure cyberspaceenough as new threats and vulnerabilities emerge, while critics of regulation or liability have not addressed the claim that regulation and liability have a proven record of improving security in other elds, nor have they yet convincingly shown why the information technology eld is different. nor is there a body of research that either proves or disproves an inverse link between regulation or liability and innovation or trade secret protection. substantial research on this point would help to inform the public debate over regulation by identifying the strengths and weaknesses of regulation or liability for cybersecurity and the points (if any) at which a reconciliation of the tensions is in fact not possible. regarding the third, and presuming the existence of irreconcilable tensions, it then becomes a public policy choice about how much and what kind of innovation must be traded off in order to obtain greater cybersecurity. 6.5 security policieswith the increasing sophistication and wide reach of computer systems, many organizations are now approaching computer security using more proactive and methodical strategies than in the past. central to many of these strategies are formal, highend policies designed to address an organization™s overall effort for keeping its computers, systems, it resources, and users secure. while access control is a large component of most security policies, the policies themselves go far beyond merely controlling who has access to what data. indeed, as guel points out, security policies communicate a consensus on what is appropriate behavior for a given system or organization.71basically, developing a security policy requires making many decisions about such things as which people and which resources to trust and how much and when to trust them. the policy development process comprises a number of distinct considerations:72developing requirements involves the oftendifcult process of determining just how much security attention to pay to a given set of data, resources, or users. human resources information, for example, or critical proprietary data about a company™s product, might require signicantly stronger protections than, say, general information documents on an organization™s intranet. a biological research facility might wish to encrypt genomic databases that 71 michele d. guel, ﬁa short primer for developing security policies,ﬂ sans institute, 2002; available at http://www.sans.org/resources/policies/policyprimer.pdf.72 more perspective on developing security policies can be found in matt bishop, ﬁwhat is computer security?ﬂ ieee security and privacy, 1(1): 6769, 2003. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 3špromoting deployment 167contain sequence information of pandemic viruses, allowing access only to vetted requestors.setting a policy entails translating security requirements into a formal document or statement setting the bounds of permissible and impermissible behavior and establishing clear lines of accountability. implementing a policy can be accomplished using any of a range of technical mechanisms (e.g., a rewall or setting a user™s system permissions) or procedural mechanisms (e.g., requiring users to change passwords on a monthly basis, reviewing accesscontrol lists periodically).assessing the effectiveness of mechanisms for implementing a policy and assessing the effectiveness of a policy in meeting the original set of requirements are ongoing activities. organizations often choose to create a number of distinct policies (or subpolicies) to address specic contexts. for example, most organizations now provide employees with acceptableuse policies that specify what types of behavior are permissible with company computer equipment and network access. other prevalent policies include wireless network, remote access, and databackup policies. having multiple security policies allows organizations to focus specic attention on important contexts (for example, consider the efciency of having an organizationwide password policy), although harmonizing multiple policies across an organization can often be a challenge.determining just how to set one™s security policy is a critical and often difcult process for organizations. after all, long before any security policy is ever drafted, an organization must rst get a good sense for its security landscapešfor example, what things need what level of protection, which users require what level of access to what different resources, and so on. however, in the beginning of such a process, many organizations may not even know what questions need to be asked to begin developing a coherent policy or what options are open to them for addressing a given concern. one major open issue and area for research, therefore, is how to assist with this early, though allimportant, stage of developing requirements and setting a security policy, as well as how to assist in evaluating existing policies.73one approach to the problem of establishing appropriate policies in large organizations is the use of rolebased access control, a practice that 73 one interesting framework for developing and assessing security policies can be found in jackie rees, subhajyoti bandyopadhyay, and eugene h. spafford, ﬁpfires: a policy framework for information security,ﬂ communications of the acm, 46(7): 101106, 2003.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.168 toward a safer and more secure cyberspacedetermines the security policy appropriate for the roles in an organization rather than the individuals (a role can be established for a class of individuals, such as doctors in a hospital, or for a class of devices, such as all wireless devices). however, since individuals may have multiple roles, reconciling con˚icting privileges can be problematic.other major open issues and research areas include the enforcement of security policies (as discussed in section 6.1) and the determination of how effective a given security policy is in regulating desirable and undesirable behavior. these two areas (that is, enforcement and auditability) have been made more signicant in recent years by an evolving regulatory framework that has placed new compliance responsibilities on organizations (e.g., sarbanesoxley act of 2002 [p.l. no. 107204, 116 stat. 745]; grammleachbliley act [15 u.s.c., subchapter i, sec. 68016809, disclosure of nonpublic personal information]; the health insurance portability and accountability act (hipaa) of 1996; and so on). another open question in this space involves the effectiveness of using outsourced rms to audit security policies.additional areas for research include ways to simulate the effects and feasibility of security policies; how to keep policies aligned with organizational goals (especially in multipolicy environments); methods for automating security policies or making them usable by machines; how to apply and manage security policies with respect to evolving technology such as distributed systems, handheld devices, electronic services (or web services), and so on; and ways to reconcile security policies of different organizations that might decide to communicate or share information or resources.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.169the goal of requirements in category 4šdeterring wouldbe attackers and penalizing attackers, is that of deterring wouldbe attackers from taking actions that could result in the compromise of a system or network and penalizing attackers who do take such actions. this broad category in the committee™s illustrative research agenda includes legal and policy measures that could be taken to penalize or impose consequences on cyberattackers and technologies that support such measures. in principle, this category could also include technical measures to retaliate against a cyberattacker.the rationale for this category is that in the absence of legal, technical, economic, or other punitive measures against attackers, wouldbe attackers have few incentives to refrain from launching attacks. (the same rationale applies, of course, in the physical world, where wouldbe criminals are deterred from criminal activity by the threat of punishment and consequence.) in a penaltyfree world, an attacker pays no penalty for failed attacks and can therefore continue attacking until he or she succeeds or quits. research in this category thus serves two important but complementary goals. first, such research seeks to develop more effective methods for imposing some kind of penalty on attackers, whether or not they have been successful in their attacks. second, the availability of such methods increases the likelihood that an attacker will in fact suffer a penalty for hostile actions, and thus the availability of these methods presumably decreases the likelihood that a wouldbe attacker will initiate such 7category 4šdeterring wouldbe attackers and penalizing attackerstoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.170 toward a safer and more secure cyberspaceactions. with fewer attackers, the cybersecurity task becomes easier to undertake.a key characteristic of deterrence is that penalties can be directed at the proper party. category 2 (enabling accountability) research supports this goal by focusing on ways to ensure that actions in cyberspace can be associated with specic actors, but that research does not presume that actors will seek to conceal their actions. malefactors in cyberspace will usually seek to do so, and thus investigators and other interested parties will need forensic tools that allow them to reestablish any deliberately broken bindings between actions and identity.the following discussion presents illustrative topics within this category.7.1 legal issues related to cybersecurityas noted above, cybersecurity is not just a technical domain. in cybersecurity, as in other areas of life in which security concerns arise, it is not unreasonable to conclude that the tools available to promote and enhance cybersecurity should include a legal dimension. for example, consider the notion of recourse for victims of cybercrime. in most areas other than those involving cyberspace, individuals who are victims of criminal activity can appeal to law enforcement and the courts to punish the perpetrators. but a victim of cybercrimešwhether a private citizen, a business, or an organizationšoften or even usually has little practical recourse.in principle, of course, cyberattackers can be held accountable for actions that cause harm in cyberspace through criminal or civil penalties. such action requires a good characterization of what constitutes behavior that warrants criminal penalties, as well as the ability to identify the party responsible (see section 5.1) and a legal framework that enables prosecutions to take place across all of the political boundaries that may have been crossed in the course of the punishable misbehavior. many cybercrime perpetrators are outside of u.s. jurisdiction, and the applicable laws may not criminalize the particulars of the crime perpetrated. even if they do, logistical difculties in identifying the perpetrator across national boundaries may render him or her practically immune to prosecutions. harmonization of national laws (as provided for in the 2001 council of europe convention on cybercrime) is a good first step toward ensuring the availability of recourse, but there remains substantial legal and policy research to further the cause of harmonization more broadly and to reduce the logistical difficulties entailed in tracking, identifying, and prosecuting cybercriminals across national boundaries. considerable efforts are underway today at the regional intergovtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 4šdeterring and penalizing attackers 171ernmental and international governmental level, as discussed in ﬁthe international landscape of cyber security.ﬂ1a second example involves relationships between law enforcement and technology/service vendors. internet service providers (isps) are used by cybercriminals as conduits of their crimes (and sometimes isps are willing accomplices). however, law enforcement authorities often have little leverage to persuade or compel isps to cut off access to suspicious users or to supply provenance or to trace data for forensics examination. from a law enforcement perspective, dataretention practices for most isps are inadequate to support investigative needs. however, providing additional authorities to law enforcement to compel various kinds of cooperation from isps (e.g., to enforce longer dataretention periods) has implications for civil liberties and is thus controversial. legal, policy, and technical research is needed to nd ways to protect due process and civil liberties without placing undue barriers in the way of legitimate law enforcement activities.7.2 honeypotsthe term honeypot in computer security jargon refers to a machine, a virtual machine, or other network resource that is intended to act as a decoy or diversion for wouldbe attackers. a honeynet refers to a collection of honeypots on a network. honeypots or honeynets intentionally contain no real or valuable data (and hence receive no legitimate trafc) and are kept separate from an organization™s production systems. indeed, in most cases, systems administrators want attackers to succeed in compromising or breaching the security of honeypots to a certain extent so that they can log all the activity and learn from the techniques and methods used by the attacker. this process allows administrators to be better prepared for attacks on their real production systems. honeypots are very useful for gathering information about new types of attacks, new techniques, and information on how things like worms or malicious code propagate through systems, and they are used as much by security researchers as by network security administrators. honeypots are usually of two main types: (1) a more basic, ﬁlow interactionﬂ implementation that emulates or gives the appearance of a real system or real machines in place; or (2) a more complex, ﬁhigh interactionﬂ system containing real tools and applications designed to 1 delphine nain, neal donaghy, and seymour goodman, ﬁthe international landscape of cyber security,ﬂ chapter 9 in detmar w. straub, seymour goodman, and richard baskerville (eds.), information security: policies, processes, and practices, m.e. sharpe, new york, forthcoming 2008.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.172 toward a safer and more secure cyberspacegather as much information about attacker activity as possible.2 honeypots of the rst type can be quite simple to install and manage, although the information they provide on attackers may be limited, and the nature of the honeypot itself may be more susceptible to discovery by a skilled attacker. honeypots of the second type are considerably more complicated, requiring much more skill to set up and manage, although the richness of information that they are capable of gleaning about attackers and techniques also increases, while the true nature of these honeypots may also be more difcult for attackers to discover.there are also other, more focused types of honeypots. for example, spam honeypotsšbasically, vulnerable mail servers set up to attract the notice of those sending out illegitimate emailšhave been quite useful in helping administrators generate spam ﬁblacklistsﬂ for their own real mail servers. wireless honeypots have also proven useful in detecting and learning from how attackers exploit wireless resources. another useful tool along these lines is the honeytoken. a honeytoken, like a honeypot, has no legitimate purpose other than to uncover illegitimate activity, so any use or access of a honeytoken can be considered suspicious. for example, consider the following scenario:a bogus medical record called ﬁjohn f. kennedyﬂ is created and loaded into the database. this medical record has no true value because there is no real patient with that name. instead, the record is a honeytoken. . . . if any employee is looking for interesting patient data, this record will denitely stand out. if the employee attempts to access this record, you most likely have an employee violating patient privacy [policies].3in any case, just as systems administrators and researchers learn about attackers from honeypots, attackers themselves can learn how to detect honeypots and honeynets as well, thereby avoiding them and maintaining some secrecy regarding the techniques they use. indeed, one recent paper on the subject likens the relationship between attackers and honeypot administrators to a continual arms race.4 as one can imagine, as soon as an attacker determines that he or she is actually working with a honeypot, useful interactions are likely to cease. however, even then, researchers and administrators can learn things about how the attacker 2 for additional information on the variety of honeypots in use today and related issues, see the honeynet project™s home page at http://www.honeynet.org/.3 lance spitzner, ﬁhoneytokens: the other honeypot,ﬂ securityfocus, july 7, 2003; available at http://www.securityfocus.com/infocus/1713.4 thorsten holz and frederic raynal, ﬁdetecting honeypots and other suspicious environments,ﬂ proceedings of the 2005 ieee workshop on information assurance and security, united states military academy, west point, n.y., june 1517, 2005.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 4šdeterring and penalizing attackers 173discovered the nature of the honeypot and how the attacker might try to hide his or her tracks (e.g., altering log les, attempting to damage or crash the honeypot, and so on).one signicant open question with honeypots and honeynets (indeed, this is a broader question within cybersecurity itself) is whether or not one should use honeypottype resources to strike back at or otherwise affect the resources of an attacker.5 (this point is discussed further in section 9.4, cyberretaliation.) in many cases, administrators could use information learned through an attacker™s interaction with a honeypot to lessen the danger that the attacker poses to real systems or other machines in the future (e.g., either by ﬁhacking backﬂ at the attacker or even removing or crippling zombie software from the attacking machine). another question for some in the computing community involves the ethics of deploying and using honeypotsšsome consider it a form of entrapment (although u.s. law would seem to argue otherwise).6 7.3 forensicscyberforensics involves the science and technology of acquiring, preserving, retrieving, and presenting data that have been processed electronically or have been stored in electronic form.7 forensic identication is a necessary (though not sufcient) condition for prosecution or of retaliation against parties that take harmful actions. (an essential complement to forensic identication is the existence of a legal framework than allows actions to be taken against cyberattackers; both are foundational elements in a strategy of deterrence that complements defense in supporting cybersecurity.) forensics is necessary because, among other things, attackers often seek to cover their tracks. for example, mechanisms for providing provenance (see chapter 5, ﬁcategory 2šenabling accountabilityﬂ) are unlikely to work perfectly, suggesting that afterthefact identication of a perpetrator may be necessary (and may in fact be a somewhat easier task than undertaking realtime identication).5 for more perspective on passive versus active defense, see national research council, realizing the potential of c4i: fundamental challenges, national academy press, washington, d.c., 1999, p. 143; available at http://newton.nap.edu/html/c4i/.6 see michelle delio, ﬁhoneypots: bait for the cracker,ﬂ wired news, march 7, 2001; available at http://www.wired.com/news/culture/0,1284,42233,00.html.7 michael g. noblett, mark m. pollitt, and lawrence a. presley, ﬁrecovering and examining computer forensic evidence,ﬂ forensic science communications, october 2000, vol. 2,  no. 4; available at http://www.fbi.gov/hq/lab/fsc/backissu/oct2000/computer.htm.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.174 toward a safer and more secure cyberspacemuch of the cyberforensics eld has developed largely in response to a demand for service from the law enforcement community to help it deal with the reality that criminals are making more effective and more extensive use of information technology just like the rest of society. indeed, greater societal use of information technology has expanded the scope of possible opportunities for criminals.in 1984, the federal bureau of investigation established its computer analysis and response team to address the needs of investigators and prosecutors to examine computer evidence in a structured and programmatic manner. what was then called computer forensics has evolved to include any evidence in digital form (e.g., audio, video, and data) from digital sources (e.g., computers, faxes, cellular telephones, and so on).8 digital forensics is now an integral part of legal investigations, with widespread recognition of its growing importance occurring during the 1990s.9the support for forensic analysis provided by federal agencies such as the department of justice and the national institute of standards and technology (nist) is further recognition of its growing importance. for instance, nist now maintains the national software reference library, which consists of a collection of digital signatures of known, traceable software applications. by comparing any given le™s signature to this collection, investigators can determine if that le is already knownšif so, it need not be collected as evidence.10 nist™s computer forensics tool testing program seeks to ensure the reliability of computer forensic tools produce consistent, accurate, and objective results.11cyberforensics research has moved beyond the initial focus on law enforcement and digital evidence for use in criminal prosecution to include military and business operations. for instance, business needs include forensics for purposes of the investigation of employee wrongdoing and the protection of intellectual property. practitioners in these areas have different primary objectives (although they may share prosecution as a secondary objective), which affect their analysis and decisionmaking processes and also affect their perspectives about requirements 8 carrie morgan whitcomb, ﬁan historical perspective of digital evidence: a forensic scientist™s view,ﬂ international journal of digital evidence, spring 2002, vol. 1, no. 1.9 george mohay, ﬁtechnical challenges and directions for digital forensics,ﬂ proceedings of the first international workshop on systematic approaches to digital forensic engineering (sadfe™05), ieee computer society, 2005.10 a description of the national software reference library is available at the program web site: http://www.nsrl.nist.gov/.11 see the computer forensics tool testing program web site for details: http://www.cftt.nist.gov.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 4šdeterring and penalizing attackers 175for digital forensic research.12 meeting statutory standards for evidence creates criteria different from those for producing results in the shortest possible time so that they can be acted on to maintain operations and availability of service, and to protect assets. moreover, cyberforensics requirements will likely evolve over time, along with the increasingly pervasive use of it. one recent example of new forensic requirements is in corporate governance to meet regulatory requirements such as those imposed by the sarbanesoxley act of 2002.13 another factor affecting research requirements is the temporal environment required for forensic analysisšwhereas law enforcement™s primary focus is on afterthefact forensics, military and business operations often need realtime or nearrealtime forensics. cyberforensics research must necessarily cover the broad scope of problems that arise from this wide range of requirements.one working denition of digital forensic science, which re˚ects this broad scope, was offered by the 2001 digital forensic research workshop: ﬁthe use of scientically derived and proven methods toward the preservation, collection, validation, identication, analysis, interpretation, documentation and presentation of digital evidence derived from digital sources for the purpose of facilitating or furthering the reconstruction of events found to be criminal, or helping to anticipate unauthorized actions shown to be disruptive to planned operations.ﬂ14 formalization of the eld as the scientic discipline of digital forensic science is still in the early stages, with one of the rst formal research papers in the eld appearing in 1992.15 a recent needs analysis survey that focused on law enforcement requirements notes that the national and international judiciary has begun to question the scientic validity of the ad hoc procedures and methodologies applied to digital forensics and is increasingly demanding proof of theoretical foundation and scientic 12 gary palmer (ed.), ﬁa road map for digital forensic research: report from the first digital forensic research workshop (dfrws),ﬂ dtrt00101 final, november 6, 2001, p. 3. table 1, suitability guidelines for digital forensic research, captures differences in these areas.13 george mohay, ﬁtechnical challenges and directions for digital forensics,ﬂ proceedings of the first international workshop on systematic approaches to digital forensic engineering (sadfe™05), ieee computer society, 2005.14 gary palmer (ed.), ﬁa road map for digital forensic research: report from the first digital forensic research workshop (dfrws),ﬂ dtrt00101 final, november 6, 2001,  p. 16. 15 eugene h. spafford and stephen a. weeber, ﬁsoftware forensics: can we track code to its authors?,ﬂ 15th national computer security conference, pp. 641650, october 1992. a more recent paper that outlines some of the scientic issues in the eld is eugene h. spafford, ﬁsome challenges in digital forensics,ﬂ in research advances in digital forensicsšii, m. olivier and s. shenoi (eds.), springer, 2006.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.176 toward a safer and more secure cyberspacerigor.16 this foundation is required in order to mandate and interpret the standards applied to digital evidence and to establish the qualications of digital forensics professionals through a certication process.17 military and business forensics needs range across a broad spectrum, from trafc analysis tools and instrumentation of embedded systems to handling massive data volume and network monitoring, and they require a similar foundation to deal with increasing complexity and broader application.18 the embedding of computational resources in other devices, for instance, seems likely to increase the complexity of digital forensics and the extent of its usefulness. two examples are the recovering and reconstructing of detail from global positioning system units built into cars to determine recent movements of a suspect auto, and the recovery of phone books, notes, and call information from cellular telephones. accordingly, a number of research areas within this expansive view of digital forensics have been identied:19building a framework for digital forensic science. this research area includes three elements: denitional work to provide a lexicon with clear terminology, a useful process model for the digital investigation process, and the development of an understanding of the academic and vocational expertise necessary, followed by curriculum development. for example, several models have been developed with increasing levels of abstraction and generalization of the digital investigation process.20 denitional work has progressed in the form of ontological models for dening layers of specialization across the areas employing forensic analysis, identifying the necessary elements of a certication process, and domainspecic educational requirements.2116 marcus k. rogers and kate seigfried, ﬁthe future of computer forensics: a needs analysis survey,ﬂ computers and security, 23: 1216, 2004.17 matthew meyers and marc rogers, ﬁcomputer forensics: the need for standardization and certication,ﬂ international journal of digital evidence, vol. 3, no. 2, 2004.18 george mohay, ﬁtechnical challenges and directions for digital forensics,ﬂ proceedings of the first international workshop on systematic approaches to digital forensic engineering (sadfe™05), ieee computer society, 2005.19 gary palmer (ed.), ﬁa road map for digital forensic research: report from the first digital forensic research workshop (dfrws),ﬂ dtrt00101 final, november 6, 2001, pp. 3339. the categories and specic research areas noted are drawn from this paper.20 cf. mark reith, clint carr, and gregg gunsch, ﬁan examination of digital forensic models,ﬂ international journal of digital evidence, vol. 1, no. 3, fall 2002; brian carrier and eugene h. spafford, ﬁgetting physical with the digital investigation process,ﬂ international journal of digital evidence, vol. 2, no. 2, 2003.21 cf. ashley brinson, abigail robinson, and marcus rogers, ﬁa cyber forensics ontology: creating a new approach to studying cyber forensics,ﬂ digital investigation, 3s: 3743, 2006.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 4šdeterring and penalizing attackers 177issues of integrity in digital evidence. this research would address the need to ensure the integrity of digital evidence, which is inherently fragile and almost always suspect. several important legal issues arise when seeking to submit digital evidence, affecting whether and what is admissible in court.22 these include establishing the authenticity, lack of tampering in all of the systems through which the evidence has passed, reliability of computergenerated records (e.g., the possibility that the same digital signature could have resulted from different texts), and authorship. legal distinctions also arise with differences between humanentered data and computergenerated data. specic research areas include the development of antitampering methods, the creation of baseline standards of correctness in digital transform technology, and procedural standards for proper laboratory protocols. for example, several methods are in use todayšchecksum, oneway hash algorithms, and digital signaturesšto help to demonstrate that the integrity of evidence has been preserved.23 each of these has advantages and drawbacks, ranging from the ease with which they can be applied and maintained to the level of condence in them and what they prove (i.e., who, when, what). some work has also been done to understand what requirements cyberforensic analysis tools must meet in order to establish and maintain evidentiary trust: usability by the human investigator (abstracting data to a level that can be analyzed), comprehensiveness (inculpatory and exculpatory evidence), accuracy, determinism, and veriablility.24detection and recovery of hidden data. this research area would focus on creating discovery mechanisms that detect and extract digital evidence in all its forms. specic research areas include the categorization of places and mechanisms for hiding data, mechanisms for the detection of original material, and methods for extracting and recovering hidden data.25 this line of research would search for ways to identify the who, what, when, where, and how for digital evidence. merely obtaining data poses a wide variety of technical challenges. for example, the diversity of devices on which 22 orin s. kerr, ﬁcomputer records and the federal rules of evidence,ﬂ united states usa bulletin, vol. 49, no. 2, u.s. department of justice, march 2001.23 chet hosmer, ﬁproving the integrity of digital evidence with time,ﬂ international journal of digital evidence, vol. 1, no. 1, 2002.24 brian carrier, ﬁdening digital forensic examination and analysis tools using abstraction layers,ﬂ international journal of digital evidence, vol. 1, no. 4, 2003.25 one description of the challenges involved in this area can be found in paul a. henry, ﬁantiforensics,ﬂ april 2006; available at http://layerone.info/2006/presentations/antiforensicslayeronepaulhenry.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.178 toward a safer and more secure cyberspacepotentially relevant information may be stored means that new protocols and tools must be developed for each device. relevant information may be buried amidst large volumes of other irrelevant information and may be distributed across many different devices or locations. information may not even be stored on persistent media (for example, it might be stored in dynamic random access memory [dram] and disappear when the system on which it is stored is powered down). the recovery of encrypted data has been a particular concern of both practitioners and researchers.26 in addition, systems can be designed to support forensic investigation and thereby increase the quantity and quality of forensic information available.27 automating the collection process and performing targeted searches using techniques such as data mining could also improve the detection and recovery of useful data.28 these are aspects of what has been termed ﬁforensic readiness,ﬂ the extent to which activities and data are recorded in a manner sufcient for forensic purposes.29 another aspect of the detection and recovery of data addresses the science and technology of acquiring, preserving, retrieving, and presenting data that have been processed electronically or have been stored in electronic form but in a nonevidentiary context. outside of this context, the evidentiary requirements of forensic investigation are relaxed. thus, for example, statistical likelihood, indirect evidence, and hearsay fall within the scope of nonevidentiary forensics.digital forensic science in networked environments (network forensics). this research area focuses on the need to expand digital forensics beyond its roots in computer forensics, which focused heavily on standalone, mediaintensive sources. specic research areas include understanding the similarities and relationships between computer and network forensics, methods for applying digital forensic analysis in real time, and the development of trusted collection processes and criteria for trusted agents outside of law 26 eoghan casey, ﬁpractical approaches to recovering encrypted digital evidence,ﬂ international journal of digital evidence, vol. 1, no. 3, 2002.27 florian buchholz and eugene spafford, ﬁon the role of file system metadata in digital forensics,ﬂ digital investigation, 1(4): 297308, december 2004.28 brian d. carrier and eugene h. spafford, ﬁautomated digital evidence target denitions using outlier analysis and existing evidence,ﬂ 2005 digital forensic research workshop (dfrws), new orleans, la., august 1719, 2005.29 george mohay, ﬁtechnical challenges and directions for digital forensics,ﬂ proceedings of the first international workshop on systematic approaches to digital forensic engineering (sadfe™05), ieee computer society, 2005; eugene h. spafford, ﬁsome challenges in digital forensics,ﬂ in research advances in digital forensicšii, m. olivier and s. shenoi (eds.), springer, 2006.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 4šdeterring and penalizing attackers 179enforcement (e.g., intelligence, network operators) to collect forensic evidence. for example, network geolocation technology would provide a means for determining the physical location of a logical network address. tools for monitoring and mapping network trafc would allow realtime network management.30 related is trafc analysis, which calls for understanding the source and nature of certain kinds of attack and requires techniques, equipment, and legal tools to characterize the huge trafc ˚ows on public and private networks that accompany those kinds of attack. extracting information about interconnections (e.g., trafc volume, communicating pairs, and network topology as functions of time) can help hunt down enemies and understand interrelationships. finally, research is needed on the formalization of policies to support network forensics, including systematic application and data retention, logging of system and network information, attack response planning, and network forensic training.31while this and other research marks a clear beginning toward the goal of establishing a discipline of digital forensic science, further progress is possible in all of the areas. much of the required research is technical in nature, and in many cases the techniques and problems are similar to other technical research areas (e.g., software debugging, data provenance,  intrusiondetection, and malware analysis), although such synergies remain largely unexplored. however, there are also legal, economic, and policy research issues. for instance, there are likely economic constraints owing to the lack of incentives for both technology vendors and users related to improving forensic readiness.32the international aspects of digital forensic investigation in a world of global highspeed networks mean that there are some signicant legal issues related to the quality, provenance, analysis, and maintenance of data in different legal jurisdictions that have yet to be fully understood and addressed.30 see, for instance, ﬁnetwork geolocation technologyﬂ and ﬁatm mapping and monitoring toolﬂ at the national security agency™s domestic technology transfer program web site: http://www.nas.gov/techtrans/index.cfm.31 cf. srinivas mukkamala and andrew h. sung, ﬁidentifying signicant features for network forensic analysis using articial intelligent techniques,ﬂ international journal of digital evidence, vol. 1, no. 4, 2003; alec yasinsac and yanet manzano, ﬁpolicies to enhance computer and network forensics,ﬂ presentation at the workshop on information assurance and security, united states military academy, west point, n.y., june 2001.32 tyler moore, ﬁthe economics of digital forensics,ﬂ presented at the fifth annual workshop on the economics and information security, cambridge, england, june 2628, 2006.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.180 toward a safer and more secure cyberspaceone example of a signicant policy issue is that of addressing the tension between forensics and privacy. concerns about privacy have motivated the development of counterforensic tools. some initial work has been done to evaluate the effectiveness of existing commercial counterforensic tools and the operational implications for digital forensic analysis.33 yet, policy questions such as understanding and managing the boundary between the legitimate collection and use of digital forensic evidence and the illegitimate monitoring of behavior and activities have barely been asked, let alone answered. indeed, the question of what is and is not legitimate has still to be answered.3433 matthew geiger, ﬁevaluating commercial counterforensic tools,ﬂ 2005 digital forensic workshop, new orleans, la., august 1719, 2005.34 eugene h. spafford, ﬁsome challenges in digital forensics,ﬂ research advances in digital forensicsšii, m. olivier and s. shenoi (eds.), springer, 2006.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.181while chapters 4, 5, 6, and 7 address specic focus areas, this chapter presents a number of problems whose solutions will involve research described in all of those chapters.8.1 security for legacy systemsorganizations make large investments in making systems work properly for their business needs. if system deployment is complex or widespread, many organizations are highly reluctant to move to systems based on newer or more current technologies because of the (often quite considerable) work that would inevitably be required to get the new systems to work as well as the older systems worked. however, because legacy systemsšby denitionšembody design and architectural decisions made before the emergence of the current threat environment, they pose special challenges for security. that is, when new and unanticipated threats emerge, legacy systems must be retrotted to improve securityšand this is true even when careful design and attention to security have reduced the number of potential security vulnerabilities in the original legacy system. in this context, the challenge is to add security without making existing software products, information assets, and hardware devices any more obsolete than is necessary. research to support this goal has three components: 8category 5šillustrative crosscutting problemfocused research areastoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.182 toward a safer and more secure cyberspace1. research is needed to address the relatively immediate security needs of legacy systems, as these systems will be with us for a long time to come. 2. it is worthwhile to expend some signicant effort to create new systems and networks that are explicitly designed to be secure, at least for critical systems whose compromise would have high consequences. research on cleanslate designs for secure and attackresilient architectures will show what can be achieved when these efforts are relieved of the need to t into an insecure existing framework, and it may be that new design approaches will make it possible to achieve performance, cost, and security goals simultaneously.3. research effort should be explicitly focused on easing the transition path for users of today™s information technology applications to migrate to securebydesign systems in the futureša path that is likely to take years or decades to accomplish even after such ﬁfromthestart secureﬂ systems are designed and initially deployed. (box 8.1 presents further discussion of this point.)one key issue in the security of legacy systems is patch management. tinkering with existing legacy systemsšfor whatever reasonšcan result in severe operational problems that take a great deal of time and effort to resolve, but xing security problems almost always requires tinkering. therefore, operational managers are often faced with choosing between the risk of installing a x to some vulnerability (that is, the installation of the patch may disrupt operations or even introduce a new vulnerability) and the risk of not installing it (that is, attackers might be able to exploit the vulnerability). further, the installation of a patch generally necessitates a set of new tests to ensure both that the vulnerability has been repaired and that critical operational functionality has not been lost. if it has been lost, a new cycle of patchandtest is needed. these cycles are both costly and inherently timeconsuming, and consequently many systems managers avoid them if at all possible. such dilemmas are exacerbated by the fact that it is often the very release of a x that prompts an attack.1 one area of research thus suggested is the development of a methodology that will help operational managers decide how to resolve this dilemma.1 this paradoxical situation results from the fact that the release of a x is publicized so that it can be disseminated as widely as possible. the publicity about the x can alert wouldbe attackers to the existence of the vulnerability in the rst place, and the x itself can usually be ﬁdisassembledﬂ in order to reveal the nature of the original vulnerability. because some installations will not install the x, wouldbe attackers gain opportunities that would not otherwise become available.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 183a second area of research relevant to the security of legacy systems is that of program understanding. programunderstanding tools are essential for addressing security issues that arise in legacy systems for which documentation is poor and original expertise is scarce. the reason is that legacy systems continue to play essential operational roles long after their technological foundations are obsolete and after the departure of the individuals who best understand the systems. but as new security issues arise in these legacy systems, a detailed understanding of their internal operation and of how actual system behavior differs from intended behavior is necessary in order to address these issues. tools that help new analysts box 8.1 issues in system migrationone important dimension of security for legacy systems involves strategies for migrating to systems that are more inherently secure. in this context, it is often the case that a migration strategy needs only to preserve existing assets. for example, a user may have a large investment in data les of a given format that are required for a given version of a program. a new version that is more inherently secure may well require les of a different format. one strategy to preserve assets may be to require the new version to open all les in the old format. a different strategy may call for a conversion utility to convert old les to the new format. the rst strategy might be deemed a requirement for backward compatibilityšthat is, the new system should operate as the old one did in a manner that is as transparent as possible to the user. but all too often, the requirement for full backward compatibility complicates the security problemšbackward compatibility may, explicitly or implicitly, call for building in the same security vulnerabilities in an attempt to preserve the same functional behavior. (for example, a large fraction of the windows xp system code base is included for backward compatibility with windows 98 and windows 2000ša fact that is well recognized as being responsible for many vulnerabilities in xp.)in the second approach, the migration to a more secure system is made easier by the weaker requirement that only the data assets of the earlier generation be preserved (or made usable) for the new system. the duplication of all functional behavior is explicitly not a requirement for this approach, although it remains a signicant intellectual challenge to determine what functional behavior must and must not carry over to the new system.another fact about system migration is that with distributed systems in place, it is very difcult, from both a cost and a deployment standpoint, to replace all the legacy equipment at once. this means that for practical purposes, an organization may well be operating with a heterogeneous information technology environmentšwhich means that the parts that have not been replaced are likely still vulnerable, and their interconnection to the parts that have been replaced may make even the new components vulnerable. the result of this tension is often that no meaningful action for security improvement takes place.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.184 toward a safer and more secure cyberspaceunderstand ˚ows of control and data can facilitate such understanding and the ﬁreverseengineeringﬂ of legacy systems.8.2 the role of secrecy in cyberdefenseshould the inner operations of security mechanisms be kept secret or not? it is widely assumed in much of the unclassied research communityšespecially the community associated with opensource softwarešthat the correct answer to this question is ﬁno.ﬂ this answer is based on the idea that secrecy prevents the security community from examining the mechanism in question and in so doing eliminates the opportunity for a rigorous peer review (e.g., nding ˚aws in results, verifying results independently, and providing [open] building blocks that others can build on [thereby fostering research progress]).2 there is a further belief in this community that a weak system can usually be compromised without knowledge of what is purportedly secret.3in the classied cybersecurity community, the opposite view is much more prominent. in this view, secrecy of mechanism throws up an additional barrier that an adversary must penetrate or circumvent in order to mount a successful attack, but in no event is secrecy the only or even the primary barrier that should be established. vendors, even of products for civilian use, also have an interest in keeping implementations secret (under existing trade secret law).both points of view have merit under some circumstances, and a number of researchers have sought to reconcile them. for example, spafford argued in 1996 that unless an exploit is actually being used in a widespread manner, it is better not to publish details of a ˚aw, because to do so would result in a much larger risk of exposure.4 this is true even if a x is available, since the mere availability of a x does not guaranteešnor even nearly guaranteešthat the x will be installed. some will not hear of the x; some will not be able to install it because of certication requirements; some will not have the expertise to install it; some will fear the subsequent breakage of some essential element of system functionality. more recently, swire has argued that secrecy is most useful to the defense on the rst 2 spafford goes so far as to argue that opensource development is an issue that is orthogonal to security. see http://homes.cerias.purdue.edu/~spaf/openvsclosed.html.3 a related argument applies to data and history. whether data and development history are protected by national security classications or trade secrets, their unavailability to the community at large prevents the community from using that data and history to understand why systems fail or the origins of a particular kind of bug or ˚aw. 4 eugene spafford, ﬁcost benet analyses and best practices,ﬂ practical unix and internet security, simson garnkel and eugene spafford (eds.), o™reilly press, cambridge, mass., 2003.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 185occasion of an attack on a computer system but that it is far less effective if an adversary can probe the defenses repeatedly and learn from those probes.5 the national research council itself commented on this tension in 1998 (box 8.2). additional research should be done to shed more light on appropriate uses of secrecy in cybersecurity.presuming that there are some circumstances in which secrecy is an asset to cyberdefense, an additional research question arises: to what extent is it possible to keep any mechanism secret when it is widely deployed? what technological approaches can be used to increase the likelihood that a widely deployed mechanism can be kept secret?8.3 insider threatsthe majority of cybersecurity research efforts are focused on making it more difcult for ﬁoutsideﬂ adversaries to compromise information systems. but, as the cases of robert hanssen and aldrich ames suggest, insiders can pose a considerable security risk as well. indeed, much of the past 10 to 15 years of u.s. counterintelligence history suggests that the threat to national security emanating from the trusted insider is at least as serious as the threat from the outsider.6 insiders can be in a position to do more harm to services and resources to which they have authorized access than can outsiders lacking such access; these concerns are particularly important in contexts in which safe operation depends on good decisions being made by systems operators. insiders can also leverage their authorized access to obtain information to extend their access. the compromised insider presents a more difcult security challenge than that posed by hostile outsiders. the rst rule about security is to keep hostile parties away, and the insider, by denition, has bypassed many of the barriers erected to keep him or her away. moreover, a compromised insider may work with outsiders (e.g., passing along information that identies weak points in an organization™s cybersecurity posture). compromised insiders fall into two categoriesšknowing and unknowing. knowingly compromised insidersšthose that know they are 5 peter swire, ﬁa model for when disclosure helps security: what is different about computer and network security?,ﬂ journal on telecommunications and high technology law, vol. 2, 2004. 6 for this report, the term ﬁinsiderﬂ is used to denote an individual in an authorized position whose actions can materially affect the operation of the information technology systems and networks associated with critical infrastructure in a negative way. since not all ﬁinsidersﬂ pose a threat, the terms ﬁinappropriately trusted insiderﬂ or ﬁcompromised insiderﬂ are used to mean an insider with the willingness and motivation to act improperly with respect to critical infrastructure. the term ﬁoutsiderﬂ refers to an individual who is not in the position of an ﬁinsider.ﬂtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.186 toward a safer and more secure cyberspaceacting on behalf of an adversaryšare most likely associated with a highend threat, such as a hostile major nationstate, and their motivations also vary widely and include the desire for recognition for hacking skills, ideological convictions, and monetary incentives. knowingly compromised insiders may become compromised because of bribery, blackmail, ideological or psychological predisposition, or successful inltration, among other reasons. by contrast, unknowingly compromised insiders are those that are the victims of manipulation and social engineering. in essence, unknowingly compromised insiders are tricked into using their special knowledge and position to assist an adversary. regarding the knowingly compromised insider, a substantial body of experience suggests that it ranges from very difcult to impossible to identify with reasonable reliability and precision individuals who will box 8.2 secrecy of designsecrecy of design is often deprecated with the phrase ﬁsecurity through obscurity,ﬂ and one often hears arguments that securitycritical systems or elements should be developed in an open environment that encourages peer review by the general community. evidence is readily available about systems that were developed in secret only to be reverseengineered and to have their details published on the internet and their ˚aws pointed out for all to see. but opensource software has often contained security ˚aws that have remained for years as well.1the argument for open development rests on certain assumptions, including these: the open community will have individuals with the necessary tools and expertise, they will devote adequate effort to locate vulnerabilities, they will come forth with vulnerabilities that they nd, and vulnerabilities, once discovered, can be closedševen after the system is deployed.there are environments, such as military and diplomatic settings, in which these assumptions do not necessarily hold. groups interested in nding vulnerabilities here will mount longterm and wellfunded analysis effortsšefforts that are likely to dwarf those that might be launched by individuals or organizations in the open community. further, these wellfunded groups will take great care to ensure that any vulnerabilities they discover are kept secret, so that they may be exploited (in secret) for as long as possible.special problems arise when partial public knowledge about the nature of the security mechanisms is necessary, such as when a military security module is designed for integration into commercial offtheshelf equipment. residual vulnerabilities are inevitable, and the discovery and publication of even one such vulnerability may, in certain circumstances, render the system defenseless. it is, in general, not sufcient to protect only the exact nature of a vulnerability. the precursor information from which the vulnerability could be readily discovered must also be protected, and that requires an exactness of judgment not often found in group endeavors. when public knowledge of aspects of a military system is required, the most prudent course is to conduct the entire development process under cover of secrecy. only after the entire assurance and evaluation process has been completedšand the known residual vulnerabilities identiedšshould a decision be made about what portions of the system description are safe to release.any imposition of secrecy, about either part or all of the design, carries two risks: that a residual vulnerability could have been discovered by a friendly peer reviewer in time to be xed, and that the secret parts of the system will be reverseengineered and made public, leading to the further discovery, publication, and exploitation of vulnerabilities. the rst risk has historically been mitigated by devoting substantial resources to analysis and assurance. (evaluation efforts that exceed the design effort by an order of magnitude or more are not unheard of in certain environments.) the second risk is addressed with a combination of technology aimed at defeating reverseengineering and strict procedural controls on the storage, transport, and use of the devices in question. these controls are difcult to impose in a military environment and effectively impossible in a commercial or consumer one.finally, there is sometimes a tension between security and exploitation that arises in government. intelligence agencies have a stake in concealing vulnerabilities that they discover in systems that an adversary uses, because disclosure of such a vulnerability may lead the adversary to x it and thus render it useless for intelligencegathering purposes. if the vulnerability also affects ﬁfriendlyﬂ systems, a con˚ict arises about whether the benets of exploitation do or do not outweigh the benets of disclosure. 1see for example, steve lodin, bryn dole, and eugene h. spafford, ﬁmisplaced trust: kerberos 4 random session keys,ﬂ proceedings of internet society symposium on network and distributed system security, pp. 6070, february 1997. source: adapted largely from national research council, trust in cyberspace, national academy press, washington, d.c., 1998.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 187box 8.2 secrecy of designsecrecy of design is often deprecated with the phrase ﬁsecurity through obscurity,ﬂ and one often hears arguments that securitycritical systems or elements should be developed in an open environment that encourages peer review by the general community. evidence is readily available about systems that were developed in secret only to be reverseengineered and to have their details published on the internet and their ˚aws pointed out for all to see. but opensource software has often contained security ˚aws that have remained for years as well.1the argument for open development rests on certain assumptions, including these: the open community will have individuals with the necessary tools and expertise, they will devote adequate effort to locate vulnerabilities, they will come forth with vulnerabilities that they nd, and vulnerabilities, once discovered, can be closedševen after the system is deployed.there are environments, such as military and diplomatic settings, in which these assumptions do not necessarily hold. groups interested in nding vulnerabilities here will mount longterm and wellfunded analysis effortsšefforts that are likely to dwarf those that might be launched by individuals or organizations in the open community. further, these wellfunded groups will take great care to ensure that any vulnerabilities they discover are kept secret, so that they may be exploited (in secret) for as long as possible.special problems arise when partial public knowledge about the nature of the security mechanisms is necessary, such as when a military security module is designed for integration into commercial offtheshelf equipment. residual vulnerabilities are inevitable, and the discovery and publication of even one such vulnerability may, in certain circumstances, render the system defenseless. it is, in general, not sufcient to protect only the exact nature of a vulnerability. the precursor information from which the vulnerability could be readily discovered must also be protected, and that requires an exactness of judgment not often found in group endeavors. when public knowledge of aspects of a military system is required, the most prudent course is to conduct the entire development process under cover of secrecy. only after the entire assurance and evaluation process has been completedšand the known residual vulnerabilities identiedšshould a decision be made about what portions of the system description are safe to release.any imposition of secrecy, about either part or all of the design, carries two risks: that a residual vulnerability could have been discovered by a friendly peer reviewer in time to be xed, and that the secret parts of the system will be reverseengineered and made public, leading to the further discovery, publication, and exploitation of vulnerabilities. the rst risk has historically been mitigated by devoting substantial resources to analysis and assurance. (evaluation efforts that exceed the design effort by an order of magnitude or more are not unheard of in certain environments.) the second risk is addressed with a combination of technology aimed at defeating reverseengineering and strict procedural controls on the storage, transport, and use of the devices in question. these controls are difcult to impose in a military environment and effectively impossible in a commercial or consumer one.finally, there is sometimes a tension between security and exploitation that arises in government. intelligence agencies have a stake in concealing vulnerabilities that they discover in systems that an adversary uses, because disclosure of such a vulnerability may lead the adversary to x it and thus render it useless for intelligencegathering purposes. if the vulnerability also affects ﬁfriendlyﬂ systems, a con˚ict arises about whether the benets of exploitation do or do not outweigh the benets of disclosure. 1see for example, steve lodin, bryn dole, and eugene h. spafford, ﬁmisplaced trust: kerberos 4 random session keys,ﬂ proceedings of internet society symposium on network and distributed system security, pp. 6070, february 1997. source: adapted largely from national research council, trust in cyberspace, national academy press, washington, d.c., 1998.actually take hostile actions on the basis of their proles or personal histories. (for example, it is often hard to distinguish merely quirky employees from potentially dangerous individuals, and there is considerable anecdotal evidence that some system administrators have connections to the criminal hacker underground.) thus, the identication of compromised insiders must rely on analyses of past and present behavior.7 (that is, it may be possible to infer intent and future behavior from usage signatures, 7 more precisely, the identication of a compromised insider depends rst on identifying behavior or actions that are anomalous or improper, and then on associating an individual with that behavior or those actions. an intrusiondetection system typically ˚ags anomalous behavior, and association of that behavior with an individual depends on higherlevel systems issues, such as policies, radiofrequency indentication proximity sensors to autolock machines, authenticated systems logs, and so on.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.188 toward a safer and more secure cyberspacealthough the consequences of false positives here may be quite high.) in other words, it is highly unlikely that general means for detecting potential spies and saboteurs will be developed; therefore, barriers to particular acts are necessary instead. the knowledge base about how to defend against compromised insiders is not extensive, at least by comparison with the literature on defending against ﬁoutsiders.ﬂ still, there is general agreement that a multifaceted defensive strategy is more likely to succeed than is an approach based on any one element. some of the relevant elements include the following:technology. authentication and access control are two wellknown technologies that can help to prevent an insider from doing damage. strong authentication and access controls can be used together to ensure that only authorized individuals gain access to a system or a network and that these authorized individuals have only the set of access privileges to which they are entitled and no more. as noted in section 6.5, tools to manage and implement accesscontrol policies are an important area of relevant research; with such tools available to and used by systems administrators, the damage that can be caused by someone untrustworthy and unaccountable can be limited, even if he or she has improper access to certain system components.forensic measures (section 7.3) and mad systems (section 5.2) can also play an important role in deterring the hostile activity of a compromised insider. for example, audit trails can monitor and record access to online les containing sensitive information or execution of certain system functions, and contemporaneous analysis may help to detect hostile activity as it is happening. however, audit trails must be kept for all of the users of a system, and the volume of data generally preclude comprehensive analysis on a routine basis. thus, automated audit trail analyzers could help to identify suspicious patterns of behavior that may indicate the presence of a compromised insider. in addition, it may be more or less important to audit the records of an individual, depending on the criticality of the resources available to that person; automated tools to decide on appropriate audit targets would be helpful to develop. note also that maintaining extensive logs may in itself pose a security risk, as they may be used to help recreate otherwise condential or classied material that is in otherwise restricted data les. for instance, keystroke logs may contain passwords or formulae, and logs of references consulted may be used to reverseengineer toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 189a secret process. thus, logs may need to be protected to a level as high as (or higher than) anything else on the system.organizations. in an environment in which most employees are indeed trustworthy, what policies and practices can actually be implemented that will help to cope effectively with the insider threat? known organizational principles to deal with a lack of trust include separation of duties and mandatory job rotation and vacations, and are often used in the nancial industry. such principles often generate specic technical security requirements that are often not considered explicitly in technical discussions of security. (for example, separation of duties requires that one person not play two rolesša fact that requires that an organization™s security architecture to enforce a single identity for an individual rather than multiple ones.) research is needed in how to dene, describe, manage, and manipulate security policies. systems can be abused through both bad policy and bad enforcement. tools are needed to make setting and enforcing policy easier. for example, a particularly useful area of investigation would be to gain a more complete understanding of what sophisticated and successful systems administrators do to protect their systems. encapsulating that knowledge and codifying it somehow would provide insight into what the best kinds of defense are. management. recent movements toward moreopen architectures along with more collaboration and teamwork within and across institutions present management challenges. for example, certain information may be intended for distribution on a needtoknow basis, but given a shift toward morecollaborative exercises, determining who needs to know what and constraining the sharing of information to that end is difcult. in both business and government, there has been a signicant movement toward embracing cooperation across organizations and sectors, but this, of course, introduces security problems. legal and ethical issues. many privacy and workplace surveillance issues need to be addressed when an organization determines how to implement tools to decrease the possibility of insider malfeasance. for example, many anomalydetection systems require the collection of large amounts of data about the activities of individuals in order to establish a baseline from which deviations might detect anomalous behavior. both the fact of such collection and how those data are handled have serious privacy implications, from both a legal and an ethical standpoint. one of the most important of these issues is that it is all too easy for an organization to be both very securityaware and toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.190 toward a safer and more secure cyberspaceemployeeunfriendly at the same time. that is, even if draconian security measures are legal (and they may be of questionable legality), the result may be an environment in which employees feel that they are not trusted, with a concomitant lowering of morale and productivity and perhaps higher turnover. for example, an environment in which employees police one another for violations of security practice may breed distrust and unease among colleagues. conversely, an environment that provides trusted mechanisms for dispute resolution and justice can promote a greater sense of camaraderie. the interplay between employment laws and the need for system security is also a concern. for example, the termination of suspected individuals may not occur immediately, and thus such people may maintain access while the necessary paperwork goes through channels.research is also needed to understand the circumstances under which an insider threat is (or is not) a concern serious enough to warrant substantial attention. systems are often designed embedding unrealistic assumptions about insiders. for instance, it is common in networked enterprises to assume that one cannot and should not worry about insider attacks, meaning that nothing is done about insiders who might abuse the network. this approach leaves major security vulnerabilities in new networking paradigms in which individual user devices participate in the routing protocol. but in more traditional networking paradigms, individual user devices do not participate in the routing protocol, and thus this particular security vulnerability is of less concern. as for the unknowingly compromised insider, effective defenses against trickery are very difcult to deploy.8 adversaries who engage in such trickery are experts at exploiting the willingness of people to be helpfulša process often known as ﬁsocial engineering.ﬂ these adversaries use people to provide inside information, and they use people by taking advantage of situations that cause breakdowns in normal procedures. in short, they help human error to occur. for example, badges are often required for entry into a secure facility, and passwords are required to access the computer network. however, entry and access can often be obtained in the following manner: walk up to the door carrying an armload of computers, parts, and dangling cords. ask someone to hold the door open, and thank them. carry the junk over to an empty cubicle, look for the password and login name that will be on 8 this discussion of social engineering is drawn largely from national research council, information technology for counterterrorism: immediate actions and future possibilities, the national academies press, washington, d.c., 2003.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 191a postit note somewhere, and log in. if you cannot log in, ask someone for help. as one guide for hackers puts it, just shout, ﬁdoes anyone remember the password for this terminal? . . . you would be surprised how many people will tell you.ﬂ9 the reason that social engineering succeeds is that, in general, people (e.g., employees of an organization) want to be helpful. it is important to counter social engineering if cybersecurity is to be achieved, but whatever that entails, the solution must not be based on extinguishing the tendencies of people to be helpful. the reason is that helpful people play a key role in getting any work done at allšand thus the research challenge is to develop effective techniques for countering social engineering that do not require wholesale attacks on tendencies to be helpful.some of the approaches described above for dealing with the knowingly compromised insider are relevant. for example, compartmentalization or a twoperson rule might be useful in combating social engineering. but as a general principle, approaches based on deterrence will not workšsimply because deterrence presumes that the party being deterred knows that he or she is taking an action that may result in a penalty, and most people who are trying to be helpful don™t expect to be punished for doing so.8.4 security in nontraditional computing environments and in the context of useas noted in section 3.4.1.2, cybersecurity research that is situated in the context of use has a greater likelihood of being adopted to solve security problems that occur in that context. this section provides several illustrative examples.8.4.1 health information technologyhealthrelated information spans a broad range and includes the medical records of individual patients, laboratory tests, the published medical literature, treatment protocols, and drug interactions, as well as nancial and billing records and other administrative information. the deciencies relate to not having the relevant information (even though it may be available somewhere) at the right time and in the right place to support good decision making. the intensive use of information technology (it) to acquire, manage, analyze, and disseminate health care information holds great potential for reducing or eliminating these information 9 see ﬁthe complete social engineering faqﬂ; available at http://morehouse.org/hin/blccrwl/hack/soceng.txt.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.192 toward a safer and more secure cyberspacedeciencies, and a variety of reports clearly document the benets of electronic medical records and computerbased clinical decisionsupport tools for health care workers.at the same time, it is also broadly understood that ensuring the privacy and security of personal healthrelated information is a precondition for the widespread acceptance of health information technologies into clinical practice. security requirements for such systems span a very large range, including both recordkeeping systems and embedded systems that improve or enable the performance of many medical devices and procedures. security issues of special importance to health it systems include the following:conditional condentiality. in general, only preauthorized individuals should have access to personal health information. however, in emergency situations in which the patient is unable to give explicit consent, medical personnel without previous authorization may need access.secure diagnostic and treatment systems. medical technology (e.g., radiation devices for treating cancer, scanners, pacemakers) are increasingly controlled by computer. software for these systems must be especially resistant to hostile compromise if their safety is to be ensured.usability. health care providers are particularly sensitive to workplace demands that reduce the amount of time they can spend in actual patient care, and a matter of a few seconds of additional unproductive time per patient can mean the difference between an acceptable system and an unacceptable one. security functionality, in particular, is notorious for wasting users™ timešand thus special attention to user needs in a health care environment is warranted.record integrity. users and patients must be condent that the contents of a medical record are not altered undetectably and that data in transmission are not changed or corrupted.auditability. this function ensures that all medical interventions and diagnoses are recorded and associated with a responsible individual, and also that all parties viewing a record can subsequently be audited for having an appropriate need to know. nonrepudiation is an essential part of auditability for ensuring that a responsible individual cannot plausibly deny responsibility for a decision.in general, these security and privacy functions do not require technical advances beyond what is known today. nevertheless, the integration of known security and privacy techniques with the particulars of a very toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 193demanding health care environment is an exemplar of the importance of situated research and development.8.4.2 the electric power gridthe electric power grid is a national infrastructure that links generating stations through transmission lines and distribution lines to the customer loads. highvoltage transmission lines connected in a mesh network bring the power from generating stations to lowervoltage distribution lines that connect to customer loads in a radial topology. the ownership of these elements (generation, transmission, and distribution facilities) in a geographical area may not be sharedšin many states, generation has been deregulated, meaning that generators compete with each other in power markets to sell their power. the hundreds of organizations that own portions of the power grid, and the even more entities (vendors, contractors, market players, and so on) that interact with it, use very large numbers of computers. some parts of the grid™s cyberinfrastructure operate, control, or otherwise directly or indirectly modify the workings of the grid.the monitoring and control of the power grid are done by computerized control centers. the grid is divided into ﬁcontrol areasﬂ; a control center monitors and controls that portion of the grid using a supervisory control and data acquisition (scada) system. quite often, the realtime data gathered by the scada systems can be analyzed to predict the effects of contingencies (e.g., short circuits that may cause outages of lines or generators, thus overloading other lines or causing other limit violations) and possible remedial actions to guard against such contingencies. the computer systems used to conduct such analysis are known as energy management systems (ems), and these control centers are often called scadaems (or simply ems).the scada systems are connected by communications channels (usually microwave today) to all the substations and generating stations in the control area, and the realtime data are gathered by the scada system polling the remote terminal units (rtus) at the substations. that scada system may have communications with other scada systems in neighboring control areas or with other control centers in the same area.in recent years, intelligent electronic devices (ieds) have proliferated in the substations and generating stations. these microprocessorbased devices perform the usual local functions of control, protection, and switching, but they can also perform other enhanced functions, including the gathering and storage of data at much faster rates. these ieds are usually accessible remotely, and many utilities use internet connectivity to conduct normal engineering functions on such substation equipment.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.194 toward a safer and more secure cyberspacegiven the increasing demand for electric power, it is inevitable that the electric power industry will continue to seek everhigher efciencies in the existing grid, so as to minimize the expense of constructing new grid elements. thus, interconnections within the various control centers of the grid must be taken as a given, with all of the vulnerabilities that such extensive interconnections imply. there is broad agreement that the communications infrastructure that connects the substations to the control area scada systems, developed in the 1960s and 1970s, is too slow for today™s purposes.10 faster communications will allow more widearea (rather than local) and distributed (rather than central) control, which in turn may require distributed bases of realtime data that are gathered and stored using publishersubscriber methods and middleware that monitors the quality of service (qos).an approach based on deploying a faster but isolated cyber infrastructure for the power grid is conceptually the simplest. but in addition to its high cost, this approach, at least when taken to its logical extremes, also results in a loss of ˚exibility and convenience from the standpoint of many engineering and market functions, especially regarding intercommunications, interoperability, and rapid response. an alternative is to develop design guidelines for the evolving cyberinfrastructure that will allow the ˚exibility of interconnectivity but with controlled and managed risks of penetration. while this approach preserves the lower expenses associated with ﬁpiggybackingﬂ on existing infrastructure, it has the major drawback that commercially available computer and communications infrastructures are neither secure enough nor robust enough to support such use.the new cyberinfrastructure must be able to withstand various contingencies such as malicious threats, human errors, and environmental hazards. (note that malicious threats may come from disgruntled employees and former employees who have detailed insider knowledge or from enemy nations or terrorists with access to expert knowledge.) although the power grid must be able to withstand the threat of physical attack on generators and transmission lines, another security concern arises if an adversary can attack the power grid remotely. in addition, the surprisingly large number of very large scale outages in the united states in the past 40 years raises the question of whether the infrastructure is reliable enough even in the absence of malicious misuse. indeed, many of those outages could have been triggered maliciously or intentionally, exploiting exactly the same vulnerabilities that were the 10 united states department of energy, ofce of electric transmission and distribution, national electric delivery technologies roadmap, january 2004; available at http://www. electricdistribution.ctc.com/pdfs/techroadmap.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 195cause of the accidental outages. (some of these outages occurred even though operators had previously insisted that various improvements that had been made in the grid technology would prevent such occurrences in the future.)the main technical and administrative challenge for the future is not merely to secure the cyberinfrastructure of the grid today, but to guide the evolution of the cyberinfrastructure so that the grid is not vulnerable to cyberattacks and the propagating of accidental effects. as the main purpose of the cyberinfrastructure is to operate the grid reliably, securely, and economically, the advances in communications, computation, and control technologies will continue to push the cyberinfrastructure in directions that accommodate this improved control. a major task is then to determine design factors that meet the cybersecurity and reliability objectives in ways that are consistent with the control and economic objectives of the grid. the entirety of an interconnected grid must be considered as a single system, and developed and analyzed accordingly. this is difcult because of the extent to which the providers are independent and disjoint private entities. however, neither total deregulation nor complete government regulation is compatible with the needs stated above.some of the important cybersecurity issues for the grid include the following:developing lightweight cybersecurity mechanisms. computers used for operational control generally run at high duty cycle because of premiums on efciency and on controlling many systems, and thus there is often little capacity for undertaking activities such as anomaly detection, virus updates, or penetration testing. although advances in hardware capability could, in principle, mitigate this problem, historically utility operators have adopted a relatively slow refresh rate for technology. lightweight mechanisms and testing practices that consume minimal system resources while being used on an operational system would be more likely to be used in practice.developing better forensics for scada systems and programmable logic controllers. for example, logs for these systems generally record physical parameters but not the inbound commands or communications or the originator of those commands. anomaly detection is also uncommon in these systems, although the highly structured and stylized nature of commands to these systems should make it easier to detect anomalies.implementing cybersecurity measures that can operate in an interruptheavy realtime environment. because programmable logic controllers operate multiple devices, the timing of interruptions from toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.196 toward a safer and more secure cyberspacevarious devices can make program ˚ow highly unpredictable and can thus complicate any security analysis that may be performed.in general, cybersecurity issues for the electric power grid include (but are not limited to) the possibility of electronically compromising substations operated remotely, tricking operators of control centers into doing harmful things with false or delayed data, managing the high cost of falsely identifying an authorized party as an unauthorized one, and modeling the electric grid in order to understand its vulnerabilities. 8.4.3 web servicesweb services provide application components and attendant it resources with dened interfaces that interact over the web. any given web service is also frequently used by multiple organizations.the commercial objectives are rapid deployment of business offerings, shorter process cycles, synergy between businesses, and customer benets through integration. one example of web services is the programmatic interfaces made available through the world wide web (www) that serve the function of applicationtoapplication communication. these web services provide a standard means of interoperating between different software applications, running on a variety of platforms and/or frameworks. www services are characterized by their interoperability and extensibility, as well as by their xmlbased machineprocessable descriptions. a second example of web services is the universal description, discovery and integration (uddi) specication, which denes a registry service for other web services; this registry service manages information about service providers, service implementations, and service metadata. a third web service is online storage and distributed data repositories that applications developers can exploit. web services in general can be chained together in a loosely coupled way to create complex and sophisticated valueadded services.many of the security issues that arise in webbased computing are similar to those for local applications, but web services have a number of additional security concerns that involve networking in an open environment. for example, web services are loosely coupled in a more or less ad hoc manner. thus, a dynamically established security model is necessaryšthat is, the security model is necessarily contextualšand thus requires an integration of intent over all of the components. how should such models be created? what does trust mean in such an environment? what security functionality is required of each component? how is such functionality asserted and substantiated by the application? how are toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 197authentication information and storage access rights passed from service to service in a dynamically assembled application? what is the functionality needed in tools for the analysis and specication of security policies for distributed storage?8.4.4 pervasive and embedded systemspervasive computing devices include sensor networks, ad hoc networks (e.g., cartocar), and humanembedded processors, as well as the devices described in section 2.1 (interconnected information technology everywhere, all the time). because pervasive computing systems will have programmable hardware processors and will be interconnected, they are subject to all the software and networkbased security vulnerabilities that can affect other computing devices (e.g., dedicated computing systems). furthermore, it is likely that linking together pervasive computing devices will result in the accessibility of signicant amounts of potentially sensitive information, personal and otherwise. such concentration poses both technical risk, because the information can be stolen or corrupted, and social/organizational risk, because the information can be misused by its custodians. the need to protect this information against these risks thus raises the level of security robustness that one might require of the information technology storing this information.as in many of today™s computing devices, the vulnerabilities in pervasive computing will include those that arise from the complexity of the software likely to be used, the likely extensibility of the software built into these systems, and the connectivity of these devices. however, pervasive computing will call for security solutions and approaches to scale upward by many orders of magnitudešto accommodate many more components, many more systems, many more naïve users, many more deployment locations. pervasive computing systems will also differ from today™s systems in several other ways: they may be signicantly resourceconstrained. for example, the battery energy or computing capability may be limited, implying potentially undesirable tradeoffs between security and cost or security and performance, as the implementation of security may be costly in computational capability.they will be used by people with little knowledge of computing in any form, and thus cannot require a signicant degree of attention to the details of security at all. such users should be, at most, required only to specify the parameters of a desired security policy. authentication of a person should be handled easily and naturally, without much cognitive effort, and the strength of the authenticatoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.198 toward a safer and more secure cyberspacetion should be matched automatically to the sensitivity of the application. see section 6.1 (usable security) for more on this point.they will be smaller in size, which may mean increased difculty in creating and implementing good human interfaces for security. they are far more subject to physical compromise (e.g., they may be unattended) and thus more susceptible to adversarial takeovers in hostile environments, destruction, theft, and loss.system architectures for embedded systems need to be ˚exible enough to support the rapid evolution of security mechanisms and standards and need to provide in situ capabilities for remote upgrade.one illustrative vulnerability in pervasive and embedded systems (and personal computers [pcs] as well!) arises from the fact that the programming of many such systems depends on the availability of a readonly memory (rom) chip whose program contents assume control of the system upon powerup. in earlier days, a rom chip could not be upgraded without the physical access to remove and replace the chip itself. but today, most systems use flash rom chips that can be rewritten from softwareša feature that greatly facilitates and reduces the cost of upgrades.a device with a flash rom is thus potentially subject to compromise. for example, in 1999, the chernobyl virus attacked the bios chip in many pccompatible computers, with the result that the program stored in the bios memory chip of approximately 300,000 computers was corrupted. once the programming in flash rom has been corrupted, its contents remain even after system restarts, poweroffandon sequences, and system reinstallation. in other words, flash rom corruption defeats many commonly used recovery techniques.what kinds of problems could be caused by a flash rom corruption? kocher et al. use the example of an antiaircraft radar with an embedded realtime operating system.11 within the system are several flash rom chips, and a corruption is introduced into one of them. because the rom programming is loaded into the system kernel on bootup, it has trusted access to the entire busšand its purpose is to cause the radar to ignore certain types of radar signatures. physical and sidechannel attacks are also possible in systems in which an adversary cannot be denied physical access. such attacks can be invasive or noninvasive attacks. invasive attacks against integrated 11 paul kocher et al., ﬁsecurity as a new dimension in embedded system design,ﬂ design automation conference, june 711, 2004, san diego, calif.; available at http://palms.ee.princeton.edu/palmsopen/lee41stdac461.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 199circuits usually require expensive equipment. examples include probing and reverseengineering of the chip. in such attacks, the chip is depackaged and the chip layout is reconstructed through microscopy and the removal of the covering layers. noninvasive attacks do not require the device to be opened; they include timing attacks, power analysis attacks, fault induction techniques, and electromagnetic analysis attacks. 8.5 secure network architecturesit is often observed that the principles on which the internet is based were developed in a time in which trust among its users was the order of the day. but such a situation no longer obtains, so an interesting questionšwith enormous practical relevancešis how a new internet might be designed and architected with security being a principal feature. in its purist form, the internet can be conceptualized as a network that does its best to transmit bits between enduser nodes. these bits are not differentiated from one another, and a bit associated with a virus is delivered in exactly the same way as is a bit associated with a query to a search engine. the processing of these bits, from reassembly to interpretation, is the responsibility of the end nodes. this endtoend principle, and the lack of intelligence at the center of the internet, has been a powerful force for innovation and costeffective network implementation. but this principlešat least in its strongest, most pure formšhas come under intense scrutiny, as it is also at the heart of many security difculties.in most nextgeneration internet conceptualizations, the endtoend principle is modied to some extent in the name of enhancing security. clark, for example, argues that any future internet will have to divide responsibility for security among three elements: the network, the end node system, and the application.12 as an illustration, he argues that the network ought to be able to quarantine an end node that is behaving antisocially (e.g., if it is infected by a virus that causes known antisocial behavior, or if it is acting as a zombie in a botnet).a second view of modifying the endtoend principle is offered by casado et al. and their secure architecture for the networked enterprise (sane) architecture.13 sane is an architecture for transmission control protocol/internet protocol (tcp/ip) enterprise networks that relies on a logically centralized domain controller (dc) with a complete view of 12 david d. clark, ﬁrequirements for a future internet: security as a case study,ﬂ massachusetts institute of technology, computer science and articial intelligence laboratory, december 2005; available at http://nd.isi.edu/presentationles/clarkarchsecurity.pdf.13 martin casado et al., ﬁsane: a protection architecture for enterprise networksﬂ; available at http://yuba.stanford.edu/~casado/sane.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.200 toward a safer and more secure cyberspacethe network topology to construct routes between any two points on the network. hosts can only route to the dc, and users must rst authenticate themselves with the dc before they can request a capability to access services and end hosts. once the dc provides a route between two points on the network, that route can only be traversed through a single protection layer that resides between the ethernet and ip layer. this architecture enables enforcement to be provided at the link layer, to prevent lower layers from undermining it. in addition, it hides information about topology and services from those without permission to see them. and, it requires only one component to be trustedšnamely, the dcšin contrast to standard architectures in which multiple components must be trusted (e.g., rewalls, switches, routers, and authentication services).a different approach is offered by bryant et al., whose poly2 architecture separates network services onto different systems, uses applicationspecic (minimal) operating systems, and isolates specic types of network trafc (e.g., administrative, securityspecic, and applicationspecic trafc).14 using separate networks for carrying trafc of different types (and hence different sensitivities) allows for better separation of concerns, reduces interference, and increases condence in the authenticity of the information. trust in the overall architecture arises from the separation of untrusted systems and services, which also helps contain successful attacks against individual systems and services. from a programmatic standpoint, the national science foundation™s cisesupported future internet network design (find) initiative is an example of an effort to develop a new internet architecture from the ground up. (cise refers to the nsf™s directorate for computer and information sciences and engineering.) broadly speaking, the find initiative investigates two issues: (1) the requirements for the global network of  15 years from now and (2) how to reconceptualize tomorrow™s global network today if it could be designed from scratch. part of the find initiative is of course security. this focus is motivated by the simple observation that internet security is increasingly worse with time. clark™s arguments on security (above) were presented at a find conference in 2005.158.6 attack characterizationa problem very closely related to anomaly detection and forensics is that of attack characterization, sometimes also called attack assessment. 14 eric bryant et al., ﬁpoly2 paradigm: a secure network service architecture,ﬂ proceedings of the 19th annual computer security applications conference, ieee computer society, washington, d.c., 2003, p. 342.15 david d. clark, ﬁrequirements for a future internet: security as a case study,ﬂ massachusetts institute of technology, computer science and articial intelligence laboratory, december 2005; available at http://nd.isi.edu/presentationles/clarkarchsecurity.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 201used more or less interchangeably, these terms refer to the process by which systems operators learn that an attack is under way, who is attacking, how the attack is being conducted, and what the purposes of the attack might be.the rst problem is that while the actions of a potentially hostile party may be visible in cyberspace, the intentions and motivations of that party are usually quite invisible. how should a systems operator or owner distinguish between an event that is a deliberate cyberattack intended to compromise an it system or network and other events, such as accidents, system failures, or hacking by thrill seekers.a second problem is that a cyberattack may strike multiple targets. how would decision makers know that the same attacker was behind those multiple strikes? discussed in section 5.2 (misuse and anomaly detection systems), this question re˚ects the issue of largescale situational awareness. from the standpoint of the defender™s perspective, it might well be useful to know if attacks on given sites were in fact correlated in time, in space, in origin, or in type. collecting such data is difcult enough, since it may be quite voluminous. but analyzing these data to uncover such correlations and presenting the resulting information to decision makers in a comprehensible form present many interesting intellectual challenges.a third problem is that the identity of an attacker may well be uncertain, for an attacker may well seek to deny provenance or attribution information (section 5.1, attribution) that might establish his or her identity. but under some circumstances it may be as important to eliminate certain parties as not being responsible for an attack. consider a largescale cyberattack that damages key national infrastructure and is also made public. a variety of groups may seek to take credit for such an attack even if they have had nothing to do with carrying out the attack. in these circumstances, policy makers would surely need to be able to distinguish between valid and bogus claims. ascertaining the identity of an attacker is a forensics problem (section 7.3, forensics) writ large, but it also entails preincident collection and analysis of possible attack signatures associated with different parties.8.7 coping with denialofservice attacks8.7.1 the nature of denialofservice attacksdenialofservice (dos) attacks are coordinated attempts to overwhelm a given network resource (e.g., a web server) with malicious trafc or requests for information to such an extent that legitimate trafc cannot get through. such attacks are also often distributed in nature, originating from numerous and seemingly unrelated computers (often called zomtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.202 toward a safer and more secure cyberspacebies, slaves, or bots) from around the internet (box 2.3, on botnets). in most cases, the attacking machines are vulnerable computers that have been infected by malicious software or otherwise compromised by the real attacker (or handler), who controls the attacking machines or botnet from afar either by communicating directly with the machines or by an indirect control method such as passing instructions to the machines through an internet relay chat (irc) channel. distributed denialofservice attacks (ddos) can target the network link or the end node.16 a ddos attack on the network link seeks to make the targeted link severely congested. a ddos attack on an end node seeks to consume the node™s resources, such as the central processing unit (cpu) cycles. for example, the attack may cause unnecessary processing (applicationlevel attack) or may seek to consume memory by memory exhaustion. attacks on an endnode ddos usually fall into one of two types: bandwidth attacks or resource (or protocol) attacks.17 bandwidth attacks can be direct ˚oods of tcp, icmp, or udp packets seeking to overwhelm a machine, or they can be socalled re˚ector attacks in which the attacking machines use spoofed packets to appear as if they are responding to requests from the targeted machine. resource attacks can entail consuming all available connections on a machine by taking advantage of the way that network communications protocols work (e.g., by using halfopen tcp requests) or attempting to crash an intended target outright by using malformed packets or by exploiting weaknesses in software.all of these ddos attacks can be quite formidable and difcult to repel. for example, as a recent paper notes, even internet heavyweights are not immune from them: in ﬁjune 2004, the websites of google, yahoo! and microsoft disappeared for hours when their servers were swamped with hundreds of thousands of simultaneous webpage requests that they could not possibly serviceﬂ in a widespread ddos attack.188.7.2 responding to distributed denialofservice attacksthe rst step in responding to a ddos attack is, of course, detecting itšthe earlier the better. administrators use a number of trafc and  networkmonitoring tools (e.g., intrusiondetection systems, rewalls, and 16 xuhui ao, report on dimacs workshop on largescale internet attacks, september 2324, 2003; available at http://dimacs.rutgers.edu/workshops/attacks/internetattack903.pdf.17 shibiao lin and tzicker chiueh, ﬁa survey on solutions to distributed denial of service attacks,ﬂ (tr201) rpe report, september 2006; available at http://www.ecsl.cs.sunysb.edu/tr/tr201.pdf, p. 8.18 shibiao lin and tzicker chiueh, ﬁa survey on solutions to distributed denial of service attacks,ﬂ (tr201) rpe report, september 2006; available at http://www.ecsl.cs.sunysb.edu/tr/tr201.pdf, p. 3.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 203so on) to stay abreast of the health of their resources. however, inevitably one way of detecting a ddos attack is by getting a call from a user that a given resource or web site is unavailable. in any case, once detected, there are today several strategies for addressing a ddos attack: respond and block. this approach involves detecting and characterizing the attack and ideally gaining some kind of ﬁsignatureﬂ from the attack that can be shared with others who might be affected. this signature can then be used to lter the malicious network trafc, often by the internet service provider (isp) rerouting trafc for the victim through a ﬁscrubberﬂ node.19 in practice, if an attack is large enough, isps can ﬁblackholeﬂ offending ip addresses or eliminate their routes. that is, the outside path through which the malicious trafc comes can be shut down, thereby keeping at least the targeted service available to local clients. more importantly, this approach avoids collateral damage to other sites downstream of the chokepoint network link.hide. in this response, a web site™s true end points are hidden or are set up with very good lters. trafc is then routed via an overlay network that hides the nal destination and spreads the load. an example of this approach has been taken by keromytis et al. in the design and implementation of secure overlay services.20minimize impact. this approach involves simply trying to ride a ddos attack out, either by adding more bandwidth or by using a content distribution network (e.g., akamai) to lessen the load on a web site™s resources (box 8.3). also, tools such as captchas21 can be used to differentiate and lter legitimate trafc from illegitimate trafc. many web sites also choose to degrade their services to all users when under such an attack in order to continue providing what are seen as critical services to legitimate users.make the attacker work. for attacks aimed at cpu time or memory consumption, a common strategy is to force the attacker to solve 19 robert stone, ﬁan ip overlay network for tracking dos floods,ﬂ in 9th usenix security symposium, 2000; available at http://www.usenix.org/publications/library/proceedings/sec2000/fullpapers/stone/stone.ps.20 a.d. keromytis, v. misra, and d. rubenstein, ﬁsos: secure overlay services,ﬂ pp. 6172 in proceedings of acm sigcomm, august 2002; available at http://citeseer.ist.psu.edu/keromytis02sos.html.21 captchas are an automated means for attempting to determine whether or not a computer or network user is a human being. (captcha is an acronym for ﬁcompletely automated public turing test to tell computers and humans apart.ﬂ) they often involve changing a graphic in such a way that a human can still determine what it shows, while a computer or bot would have trouble. for more information, see http://www.captcha.net.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.204 toward a safer and more secure cyberspacesome sort of puzzle. a good puzzle is hard to compute but relatively cheap to check. examples include calculating a hash function where some bits of the input are specied by the defender, and the output has to have some number of highorder bits that are zeroes. most such schemes are based on a 1992 proposal by dwork and naor22; adaptations to network denialofservice attacks include tcp client puzzles23 and tls puzzles.2422 cynthia dwork and moni naor, ﬁpricing via processing or combatting junk mail,ﬂ proceedings of the 12th annual international cryptology conference on advances in cryptology, 740: 139147, lecture notes in computer science, springerverlag, london, 1992.23 a. juels and j. brainard, ﬁclient puzzles: a cryptographic countermeasure against connection depletion attacks,ﬂ pp. 151165 in proceedings of the 1999 network and distributed security symposium, s. kent (ed.), internet society, reston, va., 1999.24 drew dean and adam stubbleeld, ﬁusing client puzzles to protect tls,ﬂ proceedings of the 10th conference on usenix security symposium, 10: 1, 2001, usenix association, berkeley, calif.; available at http://www.csl.sri.com/users/ddean/papers/usenix01b.pdf.box 8.3 attack diffusionas noted in section 2.1 (interconnected information technology everywhere, all the time) in this report, increased interconnection creates interdependencies and vulnerabilities. nevertheless, it may also be possible to leverage such interconnections to defensive advantage. to illustrate the point, consider a denialofservice (dos) attack, which fundamentally depends on volume to saturate a victim.1 interconnection could, in principle, enable the automatic diffusion of incoming trafc across multiple ﬁabsorption servers.ﬂ (an absorption server is intended primarily to absorb trafc rather than to provide fullscale services.) while no one wouldbe victim could reasonably afford to acquire a large enough infrastructure to absorb a large dos attack, a service company could provide a diffusion infrastructure and make it available to customers. when a customer experienced a dos attack, it could use its connectivity to shunt the trafc to this diffusion infrastructure. at least one company provides such a service today. but the approaches are not without potential problems. for example, the domain name system may be used to diffuse requests to one of a number of servers. but doing so reveals the destination address of individual absorption servers, which in principle might still leave them vulnerable to attack. methods to hide the individual absorption servers are known, but they have potential undesirable effects on service under nonattack conditions. further, automatic attack diffusion can con˚ict with occasional user or internet service provider desires for explicit control over routing paths.1david d. clark, ﬁrequirements for a future internet: security as a case study,ﬂ december 2005; available at http://nd.isi.edu/presentationles/clarkarchsecurity.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 205however, as with most areas of cybersecurity, attackers and defenders are locked in an ongoing arms race trying to stay abreast (or ahead) of each other™s techniques and tactics; developments are occurring at a rapid pace. still, there are no ideal, comprehensive solutions for dealing with ddos attacks, owing in large part to the sheer number and availability of attacking machines. indeed, attackers are moving toward using everlarger numbers of machines in their attacks (i.e., larger botnets), more evenly distributed around the internet, and are attempting to make their attacks as indistinguishable as possible from legitimate trafc so as to confound the lters and response mechanisms used by defenders. there are three common motives for denialofservice attacks: vandalism, revenge, and extortion. the different types of attacks suggest the need for different response strategies.pure vandalism in some sense is the hardest to deal with, since it is typically an impulse crime committed without forethought and against more or less any site on the network. fortunately, the effects are rarely longlasting. more ominously, this type of attack may have fallen in importance not because of any substantive defensive measures but because of the shift by perpetrators to protmotivated cybercrime.the second causešrevengešis generally more annoying than serious. typically, one hacker will annoy another; the offended party replies by launching a denialofservice attack against the offender. these attacksšknown as packetingštend to be of limited duration; however, other users sharing the same access link are not infrequently affected as well. protmotivated ddos attacks, and in particular extortion attacks, are in some sense easier to deal with. the targets are more predictable and hence can take defensive measures. nonetheless, there is often insufcient time for a response. one common victim has been sports gambling web sites, since they sell a timesensitive product. (while online gambling is illegal in the united states, it is legal in other parts of the world, and u.s. companies often suffer collateral damage when ˚ooding attacks against the gambling sites overload chokepoint network links.) conventional law enforcementšﬂfollow the moneyﬂšmay be the most promising avenue, although the perpetrators generally employ moneylaundering in an attempt to evade prosecution.8.7.3 research challengesresearch challenges in dealing with denialofservice attacks focus on how to identify and characterize ddos attacks and how to mitigate their toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.206 toward a safer and more secure cyberspaceeffects. in the rst area, which includes the reliable detection of largescale attacks on the internet and the realtime collection and analysis of large amounts of attackmonitoring information, moore et al. have developed a technique, known as backscatter, for inferring certain dos activity.25 the technique is based on the fact that ddos attackers sometimes forge the ip source address of the packets they send so that the packets appear to the target to be arriving from one or more third parties. however, as a practical matter, these fake source addresses are usually generated at random (that is, each packet sent has a randomly generated source address). the target, receiving a spoofed packet, tries to send an appropriate response to the faked ip address. however, because the attacker™s source address is selected at random, the victim™s responses are scattered across the entire internet address space (this effect is called backscatter). by observing a large enough address range, it is possible to effectively sample all such denialofservice activity on the internet. contained in these samples are the identity of the victim, information about the kind of attack, and a timestamp that is useful for estimating attack duration. the average arrival rate of unsolicited responses directed at the monitored address range also provides a basis for estimating the actual rate of the attack being directed at the target. there are several limitations to this technique. the most important is the assumption that attack packets appear to come from forged source addresses. while this was certainly true of the rst generation of ddos attacks, many attackers no longer bother with such forgery. while the exact extent of forgery is debatable, some experts claim that the large majority of attacks no longer use forged addresses. two of the reasons are good; one, though, is cause for concern. first, operating system changes in windows xp service pack 2 make address forgery harder. second, a number of isps follow the recommendations in rfc 2827 and block (many) forged packets.26 forgery is often unnecessary, however; source addressbased ltering near the victim is rarely possible, and there are sufciently many attack packets that effective tracing and response are difcult.the second areašmitigating the effects of ddos attacksšspans a number of topics. one important topic is the development of better lters and router congurations. for example, the optimal placement of lters to maximize benet and minimize negative impact is not easy to determine. another example is the development of networklayer capabilities that 25 david moore et al., ﬁinferring internet denialofservice activity,ﬂ acm transactions on computer systems (tocs), may 2006; available at http://www.caida.org/publications/ papers/2001/backscatter/usenixsecurity01.pdf.26 p. ferguson and d. senie, rfc 2827, network ingress filtering: defeating denial of service attacks which employ ip source address spoong, may 2000. also known as bcp 38.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 207can be used to lter trafc efciently. an example is the implementation of ﬁpushbackﬂ congurations, an approach to handling ddos attacks that adds functionality to routers so that they can detect and preferentially drop packets that probably belong to a ddos attack, while also notifying upstream and downstream routers to do likewise.27 such an approach requires coordination between various routers beyond that which is available through standard routing protocols.another important topic relates to scale. today™s solutions do not scale up to be able to address the numbers of attackers that are seen from today™s botnets. therefore, one major research area is to develop scalable solutions for addressing ddos attacks or for weathering them (e.g., content distribution networks). other challenges involve developing ways to ensure that computers and their users are less susceptible to compromise by attackers or malicious code, thereby diminishing the resources available for attackers™ use in botnets. additional ddosrelated research could also be useful in areas such as network protocols, network infrastructure, network ˚ow analysis and control, metrics for measuring the impacts of ddos attacks, and better forensic methods and techniques for tracing and catching attackers.28still another topic is organizational and institutional. because certain promising approaches to dealing with ddos attacks depend on cooperation between isps (some of which may be in different countries and subject to different laws), nding ways to encourage and facilitate cooperation is important.29 research on this topic might include how responsibility and obligation for responding to attacks should be shared between isps and their customers; what kinds of business service model are needed; how to build formal collaborations for automated coordination among different sites, isps, and various agencies; and how to incentivize isps to deploy defensive measures.27 for more information on pushback, see ratul mahajan, steven m. bellovin, sally floyd, john ioannidis, vern paxson, and scott shenker, ﬁcontrolling high bandwidth aggregates in the network,ﬂ computer communications review 32(3): 6273, 2002. 28 for additional information on ddos attacks, see jelena mirkovic et al., a taxonomy of ddos attacks and ddos defense mechanisms, technical report #020018, university of california, los angeles, computer science department, available at http://www.eecis.udel.edu/~sunshine/publications/uclatechreport020018.pdf [undated]; xuhui ao, report on dimacs workshop on largescale internet attacks, center for discrete mathematics and theoretical computer science (dimacs), available at http://dimacs.rutgers.edu/workshops/attacks/internetattack903.pdf, 2003; and rich pethia, allan paller, and eugene spafford, ﬁconsensus roadmap for defeating distributed denial of service attacks,ﬂ project of the partnership for critical infrastructure security, sans institute, available at http://www.sans.org/dosstep/roadmap.php, 2000.29 xuhui ao, report on dimacs workshop on largescale internet attacks, september 2324, 2003; available at http://dimacs.rutgers.edu/workshops/attacks/internetattack903.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.208 toward a safer and more secure cyberspaceas one example, the entire community of isps would benet from knowing the frequency of dos attacks. isps are aware (or could be aware) of dos attacks through the measurements that they ordinarily make in the course of their everyday operations, since sustained rates of packet drops by routers, observable via the simple network management protocol (snmp), frequently indicate the existence of an attack. however, for competitive reasons, this information is rarely disclosed publicly, so the community cannot develop a complete picture of the situation. research (or at least investigation) is needed to determine mechanisms that would encourage the disclosure of such data to an independent third party and the publication of a sanitized version of these data.8.8 dealing with spamspamšwhat might loosely be dened as unsolicited email sent en masse to millions of usersšhas evolved from a minor nuisance to a major problem for the internet, both as a mechanism for delivering attacks (e.g., phishing) and as a means for propagating other types of attack (e.g., viruses). spam is undesirable from the recipient™s standpoint because he or she must continually spend time and effort to deal with unwanted emails. in small volume, it would be easy to delete unwanted emails that can be identied from the header. but spam email often uses deceptive headers in order to persuade users to open it (e.g., rather than saying ﬁsubject: viagra for sale,ﬂ the header will say ﬁsubject: greetings from an old friendﬂ), and by some accounts, spam accounts for over 90 percent of email sent on the internet.30 thus, it is not unreasonable to estimate that individuals spend hundreds of millions of personhours per year in dealing with spam. today, spam threatens to undermine the stability and usefulness of networked systems and to impose signicant economic costs and lost productivity.spending valuable time dealing with a nuisance is bad enough, but spam can also have serious consequences. for example, spam can clutter one™s mailbox so that desired emails are missed or other emails cannot be received; it forces isps or users to implement lters that may inadvertently lter wanted messages. because spam can prevent a user from doing useful things in his or her computing environment, spam can be regarded as a kind of denialofservice attack against individual users.spam can cause harm. one risk is a form of online identity theft. because it is easy to forge an electronic return address (so that an email appears to have been sent from the forged address), spam senders often insert legitimate email addresses (e.g., those harvested from online bul30 see, for example, http://www.postini.com/newsevents/pr/pr011007.php.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 209letin boards, chat rooms, and the like) as the purported sender of their spam email. the reputation of the legitimate email user is thus compromised, and the spam also generates for the legitimate user a ˚ood of ﬁmailerrejection noticesﬂ from email systems that reject the spam email for some reason.a second risk is that spam can compromise the integrity of the user™s computing environment, causing it to do things that are undesired from the user™s point of view. email systems are often designed to allow users to open and execute email attachments with a simple mouse click, or to access web pages referenced in an embedded link, or to display images or messages formatted as ﬁrich text.ﬂ such functionality increases the convenience and enhances the utility of email for the user. but when spammers exploit these features, the result can be that a hostile attachment is executed, a usercompromising web page is accessed (merely by accessing it), or a trap door is opened simply by viewing the email.it is true that clandestine applications can be delivered through many different mechanisms, and in principle there is nothing special about spam email as a delivery mechanism. but in practice, the ease with which email can be delivered suggests that emailšand payloads that it carriesšwill be used aggressively in the future for commercial purposes.31 once compromised, the user™s computing environment becomes a platform for active threats such as the following:divulging the personal information resident on the user™s computer. especially common would be nancial records that are stored by various personal money management systems, but in the future such information may include medical records. such information could be used to target users with specic and personalized communications that may be threatening. an example of a targeted personal email would be: ﬁdid you know the odds of dying with your disease are much higher now?ﬂ displaying advertisements by surprise (e.g., popunder ads).tracking the user™s informationseeking behavior (e.g., what web sites have been visited). today, the use of such traces is most often limited to identifying when a user is visiting a site that was visited in the past, but there is nothing in principle that prevents the entire 31 it is also true that the root cause of the problems caused by trojan horses is insecurities in the user™s computing environment. thus, one could argue, with considerable force and reason, that eliminating these insecurities would eliminate trojan horse problems as well as a host of other problems. on the other hand, it is unrealistic to expect that such insecurities would ever be eliminated entirely. more to the point, users will not be relieved to know that the reason they are suffering from trojan horses is that their operating systems are insecure.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.210 toward a safer and more secure cyberspacetrace from being made public knowledge. (for example, consider spyware from a group that opposes pornography that reports your use of sexually explicit web sites to a public database.)launching attacks on other computer systems without the user™s knowledge (e.g., as part of a botnet).from an institutional standpoint, spam consumes signicant amounts of bandwidth, for which isps and network operators must pay. indeed, large volumes of spam are in some ways indistinguishable from a denialofservice attack. thus, spam can have important security implications on a regional or national scale as well as being simply annoying to individual users. isps and users may also bear the cost and inconvenience of installing and maintaining lters to reduce spam volumes, as well as of maintaining a larger infrastructure to accommodate the vast amount of spam ˚owing through their networks (more servers, routers, adminstrators, ˚oor space, power, and so on). (an interesting question is thus how the collective cost to individuals and business compares with the benets gained collectively by the spam senders and those who actually buy something as a result of the spam.)spam is only one dimension of a commercial environment that bombards citizens with junk mail (e.g., catalogs and endless advertising pieces); long, unsolicited voicemails on our telephone mail systems; and unwanted faxes. but spam is different from the others in at least two signicant ways. first, the costs per message to transmit spam email and similar electronic messages is much smaller by several orders of magnitude than that for postal mail or telephone calls. second, spam can be more deceptive than junk snail mail (junk faxes and telemarketing phone calls are annoying but are small fractions of the total fax and phone trafc). before it is opened, spam email can have the identical look and feel of a legitimate email from an unknown party. policy makers at both the federal and state levels are seeking legislative remedies for spam, such as the canspam act of 2003 (17 u.s.c. 103). however, crafting appropriate and workable legislation has been problematic, with at least four separate dimensions that create difculty:as a commercially oriented activity, some forms of spam do create some economic benet. some small fraction of the spam recipients do re spond positively to unsolicited email that promotes various products or services. in this regard, it is important to remember that unsolicited commercial email does not consist solely of nigerian bank fraud messages or ads for viagra, but also includes ads for cars, software, sunglasses, and vacations. furthermore, the economics of email are such that if only a very small fraction of recipitoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 211ents of a given spam mailing respond positively, that is sufcient to make the sending of the original spam turn a prot.dening spam through a legislative process is very difcult. what is spam for one person may be an interesting curiosity to another. consequently, it is very difcult to develop regulations that capture the notion of spam in a sufciently precise manner to be legally enforceable and yet sufciently general that spam senders cannot circumvent them with technical variations.spam can be sent with impunity across national borders. regulations applying to domestic spam senders can easily be circumvented by foreign intermediaries. spam is arguably a form of free speech (albeit commercial speech). thus, policy makers seeking to regulate spam must tread carefully with respect to the first amendment.in the long run, addressing the spam problem is going to involve technology and policy elements. one important technical dimension is the anonymity of spam. because spam senders realize the unpopularity of the email that they produce, today™s spam senders seek a high degree of sender anonymity to make it difcult or impossible for the recipient to obtain redress (e.g., to identify a party who will receive and act on a complaint). thus, the provenance of a given email is one element in dealing with the spam problem, suggesting the relevance of the attribution research of section 5.1, ﬁattribution.ﬂ but even if the attribution problem itself is solved, there are complicating factors regarding spam. for example, as far as many people are concerned, the senders of email fall into three categoriesšthose known to the receiver to be desirable, those known to be undesirable, and those of an unknown status. provenancešat least as traditionally associated with identityšdoes not help much in sorting out the last category. moreover, botnets today send ﬁlegitimateﬂ email from compromised hostsšthat is, if my computer is compromised so that it becomes a zombie in a botnet army, it can easily send spam email under any email account associated with my computer. that mail will be indistinguishable from legitimate email from me (i.e., email that i intended to send). thus, preventing the compromise of a host becomes part of the complete spamprevention research agenda.yet another technical dimension of spam control is a methodology to examine content as well as origin of emails.32 that is, how can a computer be trained to differentiate spam from legitimate email? most 32 joshua goodman, gordon v. cormack, and david heckerman, ﬁspam and the ongoing battle for the inbox,ﬂ communications of the acm, 50(2): 2433, 2007.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.212 toward a safer and more secure cyberspacespamrecognition systems today have at least one machine learning component that performs such differentiation based on examples of both spam and nonspam email. much of the progress in antispam research has involved improving the relevant machine learning algorithms as spammers develop more sophisticated means for evading spamdetection algorithms. other relevant factors entail obtaining more examples of different kinds of spam (so that new kinds of detectionevasion techniques can be taken into account by spam detectors) and doing so more quickly (so that spammers have smaller windows in which to propagate their new variants).another dimension of spamdetection performance depends on the ability to extract the relevant content from the bits that actually constitute the email. ascii art, photographic images, and html encodings have all been used to evade ltering, with varying degree of success. indeed, imagebased spam, in which an email contains an embedded image of a message, is quite common today. all of these methods are based on the fact that that extraction of the content is computationally intensive and thus impractical to perform on all incoming emails. spam is, by denition, a collection of many emails with identical content. so spam might be identied by virtue of the fact that many copies of it are circulating on the internetšand there are ways that institutionally based spam lters could be able to identify a given email as being a part of this category. the obvious countermeasure for the spammer is to make each message slightly different, but in a way that does not alter the core message of the spam email, which itself suggests another research problem of identifying messages as ﬁidentical in semantic contentﬂ despite small differences at the binary level.the economics of spam are also relevant. if the incremental cost of sending spam were higher, the volume of spam could be reduced signicantly. but spammers are not the only parties to send email in bulkšorganizations with newsletters, for example, may send large volumes of email as well. the imposition of a small nancial cost per email would do much to reduce spam, but it would be difcult to deploy and also would violate longstanding practices that make email an effective mechanism of communication notwithstanding the spam problem. other ways of imposing cost include requiring a timeconsuming computation that makes it more difcult to send emails in bulk and requiring a proof that a human is involved in the sending of individual emails. how to impose costs on spammers, and only on spammers, remains an open technical and regulatory question.finally, as new communications channels emerge, new forms of spam are likely to emerge. for example, spam text messages to mobile and instant message spam are two relatively newer forms of spam. future toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 5šillustrative crosscutting research areas 213spam variants may include exploits related to locationaware devices (e.g., advertisements tied explicitly to the user™s location) and spam and spamlike payloads other than text delivered to mobile devices such as cellular telephones. an example of the latter is that with the increasingly popular use of voiceoverip, junk phone calls (also known as spit, for spam over internet telephony) may come to be a problem in the future. research will be needed to address these new forms of spam as well.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.214many of today™s most pressing security problems are the consequence of information technologies designed and built when security concerns were largely nonexistent. however, now that these technologies, which include personal computers (pcs) and the internet, are so widely deployed, the current state of the world does not seem to offer an obvious and direct path to better security.for this reason, category 6šspeculative research, is reserved for research ideas that are arguably plausible but which also might be regarded as somewhat speculative and ﬁoutoftheboxﬂ by the mainstream research community. investment in this category of research should account for only a small fraction of the cybersecurity research budget, but some investment is warranted if only to ensure that groupthink does not suppress ideas that might in fact have merit.specic examples of category 6 research are, almost by denition, controversial. that is, some researcher will propose an idea that he or she believes is worth exploring, and others in the community may argue that such a research direction is not original or new, lacks depth, does not provide insights that suggest opportunities for surprise or success, does not appear to be deployable on any meaningful timescale or for a meaningful user base, poses currently insoluble difculties, or must be approached with great caution if at all. indeed, unlike the areas described in categories 1 through 5 of the committee™s illustrative research agenda, the examples of category 6 research below are controversial in just these ways, even within the committee itself. these examples were selected 9category 6šspeculative researchtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 6šspeculative research 215through a process that required only a few members to support them and should not be taken as ideas that the committee as a whole thinks are worth signicant effort or emphasis. 9.1 a cyberattack research activityin many domains of security studies, theories of defense and theories of attack are inextricably interwoven. that is, insights on how best to defend are grounded in knowledge of how attacks might unfold, and a deep knowledge of attack methodologies should not be limited to potential attackers. for example, arson investigators know very well how to set res and agents from the bureau of alcohol, tobacco, firearms and explosives know a great deal about how to make bombs. similarly, a body of cyberattack knowledge that is independent of criminal intent may be very useful to cybersecurity researchers. although in today™s cybersecurity environment, many attacks are simple indeed, such a body of cyberattack knowledge would logically go far beyond the commonplace attacks of today to include at least some of the more sophisticated techniques that highend attackers might use.the utility of this approach is suggested by the use of red teams to test operational defenses. red team testing is an effort undertaken by an organization to test its security posture using teams that simulate what a determined attacker might do. the red team develops expertise relevant to its intended target, conducts reconnaissance to search for security weaknesses, and then launches attacks that exploit those weaknesses. because red teams have deep knowledge of attack, and in particular know how to look at a system from the outside and how to cross interfaces (such as hardware/software) that may effectively limit the view of insiders, it is possible that greater interaction between red team experts and cybersecurity researchers would prove fruitful.many important issues attend the establishment of a research activity intended to develop deep knowledge of cyberattack. for example:how should deep knowledge of cyberattack be acquired? cybercriminals and other adversaries develop knowledge by attacking real systems; sometimes their efforts cause real disruptions and loss. it is inconceivable that as a matter of national policy the u.s. government would endorse or support any effort that would result in such harm, and there might well be signicant liability issues associated with the conduct of such an activity. the availability of largescale testbeds for the research community might have some potential for mitigating this particular problem. moreover, once a plausible attack hypothesis has been developed, it might often be toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.216 toward a safer and more secure cyberspacedemonstrated on a small subset of the target system that has been temporarily disconnected (or duplicated) for the demonstration.how should such knowledge be shared? one model is to recruit cybersecurity researchers for ﬁtours of dutyﬂ with a ﬁcyberattack institute.ﬂ another model is to teach cyberattack techniques as part of cybersecurity education.1how should such knowledge be limited? this issue is the most important one to resolve if this approach is to be pursued. if placed at the disposal of an adversary, knowledge of cyberattack might be very dangerous indeed. yet if the knowledge is excessively limited, it is useless to the cybersecurity research community at large. this issue is particularly thorny in the context of academic research, in which the dissemination of research results is a sine qua non for advancement. nondisclosure agreements may be a feasible mechanism to protect knowledge acquired in the case of commercial systems, and security clearances or background checks may be necessary for government systemsšalthough it is easy to imagine that some commercial systems are more sensitive than certain government systems are. note also that the sensitivity of information about cyberattack increases as knowledge of the specic systems involved increases, suggesting that the study of generic attacks may enable greater information dissemination.in an environment in which vulnerabilities result from routine implementation and coding failures, it may be that deep knowledge of cyberattack is not needed to develop defenses. but against sophisticated attackers who can target systems that have been hardened against ﬁroutineﬂ attacks, deep knowledge of cyberattack may provide a context that can help to drive advanced defensive research.9.2 biological approaches to securitybiological systems are capable of healing themselves and defending themselves against outside attack. this basic fact has suggested to some researchers that biologically inspired approaches to cybersecurity may be worth some effort in exploring.what does ﬁbiological inspirationﬂ mean? a report of the national research council on computing and biology suggests that a biological organism may implement an approach to a problem that could be the 1 see, for example, george ledin, jr., ﬁnot teaching viruses and worms is harmful,ﬂ communications of the acm, 48(1): 144, 2005.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 6šspeculative research 217basis of a solution to a computing problem.2 but even if an implementation does not carry over well to a computing problem, it may be that its underlying principles do have some relevance.researchers exploring biological approaches to cybersecurity argue that the unpredictable pathogens to which an organism™s immune system must respond are analogous to some of the threats that computer systems face, and that the principles underlying the operation of the immune system may provide new approaches to computer security.3 they note, for example, that immune systems exhibit a number of characteristics that could reasonably describe how effective computer security mechanisms might operate in a computer system or network. in particular, the immune system is distributed, diverse, autonomous, tolerant of error, dynamic, adaptable, imperfect, redundant, and homeostatic.4 to go further, it is necessary to ask whether the particular methods by which the immune system achieves these characteristics have potential relevance to computer security. for example, forrest and hofmeyr have described models for network intrusion detection and virus detection based on an immunological distinction between ﬁselfﬂ (regarded as nondangerous) and ﬁnonselfﬂ (regarded as dangerous),5 and at least one company has introduced cybersecurity products based on these models. the primary advantage of the immunological approach in this context is that attacks need not be identied by matching a potential threat to the known signature of a previously identied virus or worm, but rather there would be a behavioral identication of that threat as a ﬁnonselfﬂ entity.despite some promising results, it remains to be seen how far immunological approaches to cybersecurity can be pushed. given that the immune system is a very complex entity whose operation is not fully understood, a bottomup development of a computer security system based on the 2 national research council, catalyzing inquiry at the interface of computing and biology, john c. wooley and herbert s. lin (eds.), the national academies press, washington, d.c., 2005.3 one of the rst papers to suggest that selfnonself discrimination as used by the immune system might be useful in computer security was by s. forrest, a.s. perelson, l. allen, and r. cherukuri, ﬁselfnonself discrimination in a computer,ﬂ proceedings of the 1994 ieee symposium on research in security and privacy, ieee computer society press, los alamitos, calif., 1994, pp. 202212. this paper focused mainly on the issue of protection against computer viruses but set the stage for a great deal of subsequent work.4 this discussion of the immune system is based on s. forrest and s. hofmeyr, ﬁimmunology as information processing,ﬂ design principles for immune systems and other distributed autonomous systems, l.a. segal and i.r. cohen (eds.), oxford university press, new york, 2001.5 s. forrest and s. hofmeyr, ﬁimmunology as information processing,ﬂ design principles for immune systems and other distributed autonomous systems, l.a. segal and i.r. cohen (eds.), oxford university press, new york, 2001. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.218 toward a safer and more secure cyberspaceimmune system is not possible today. the human immune system has evolved to its present state owing to many evolutionary accidents as well as the constraints imposed by biology and chemistryšmuch of which is likely to be artifactual and mostly irrelevant to the underlying principles that the system embodies and also to the design of a computer security system. further, the immune system is oriented toward problems of survival. by contrast, computer security is traditionally concerned with condentiality, accountability, and trustworthinessšand the relevance of immunological processes to condentiality and accountability is entirely unclear today.9.3 using attack techniques for defensive purposesviruses and worms exploit vulnerabilities in a system to take control of it. but the payload of a virus or a worm can, in fact, be programmed to harm the system or to benet it. in particular, it is technically possible to propagate system xes through such a mechanism. that is, a ﬁwhite hatﬂ virus could be programmed to exploit a system vulnerability in order to enter that system, and to close that vulnerability through the administration of a system patch or changing certain administrative settings, and nally to selfdestruct. known for many years,6 this type of application has advantages and disadvantages. for example, an advantage is that xes could be propagated very rapidly. but since this approach was rst proposed, the disadvantages have been sufcient to prevent its serious consideration. these disadvantages stem from technical, ethical/legal, and psychological reasons.7 potential technical disadvantages include the originator™s lack of control over how the ﬁwhite hatﬂ virus or worm will spread, confusion over the intent or purpose of a virus or worm whose behavior may be supercially similar to a nefarious one, waste of system and network resources, and potential escape from any controlled environment. potential ethical/legal issues include unauthorized data modication, copyright and ownership issues attending to the modication of resident software, and the legitimization of activities that are generally presumed dangerous today.8 potential psychological issues include the violation that 6 an early mention of this idea can be found in fred cohen, ﬁtrends in computer virus research,ﬂ asp, 1991, available at http://vx.netlux.org/lib/afc06.html; and frederick b. cohen, ﬁa case for benevolent viruses,ﬂ 1991, available at http://all.net/books/integ/goodvcase.html.7 vesselin bontchev, ﬁare ‚good™ computer viruses still a bad idea?,ﬂ virus test center, university of hamburg, germany; available at http://vx.netlux.org/lib/avb02.html. see also eugene h. spafford, ﬁresponse to fred cohen™s ‚contest™,ﬂ the sciences, january/february 1992, p. 4.8 for further discussion, see eugene h. spafford; ﬁare computer breakins ethical?ﬂ journal of systems and software, 17(1): 4148, 1992.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.category 6šspeculative research 219may be felt by users regarding the loss of control over their systems that viruses and worms necessarily entail.9.4 cyberretaliationa special case of using attack techniques for defensive purposes arises in the realm of active defense. traditionally, cybersecurity is based on the notion of passive defenseša defense that imposes no penalty on a wouldbe attacker apart from the time that the attacker needs to mount its attack. under such circumstances, the attacker can continue attacking unpunished until success or exhaustion occurs.the notion of cyberretaliation as a part of an active defense is intended to make cyberattackers pay a price for attacking (whether or not they are successful), thus dissuading a potential attacker and offering a deterrent to attacking in the rst place. but cyberretaliation raises both technical and policy issues. from a technical standpoint, the tools available today to support retaliation are inadequate. identication of cyberattackers remains problematic, as indicated in section 5.1 (attribution). today, the identication of an attacker is an enormously timeconsuming taskševen if the identication task is successful, it can take weeks to identify an attacker. furthermore, considerable uncertainty often remains about the actual identity of the attacker, who may be an individual using an institution™s computer without the knowledge or permission of that institution. such uncertainty raises the possibility that one™s retaliatory efforts might result in signicant collateral damage to innocents without even necessarily affecting the perpetrator. in addition, the technical mechanisms for striking back are generally oriented toward causing damage to computer systems rather than being directed at individual perpetrators. from a policy standpoint, cyberretaliation raises issues such as the dividing line between regarding a cyberattack as a law enforcement matter versus a national security matter, the appropriate denitions of concepts such as ﬁforceﬂ or ﬁarmed attackﬂ as they apply to cyberattacks, the standards of proof required to establish the origin of a cyberattack, and the nature of the appropriate rules of engagement that might be associated with a cyberattack.these comments should not be taken as denigrating passive cybersecurity measures, which remain central to the nation™s cybersecurity posture. nevertheless, passive defenses have strong limitations, and active defense may provide a more robust set of options if the technical and policy issues can be resolved.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.221part iiiconclusionpart iii of this report consists of chapter 10, which examines why insufcient action has occurred in the cybersecurity arena and provides a set of priorities for the future.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.22310.1 why has little action occurred?the committee on improving cybersecurity research in the united states believes that the cybersecurity threat is real, imminent, and growing in severity. moreover, as one of the most technologically advanced nations in the world, the united states has much to lose from the materialization of this threat. but this committee is not the rst committeešand this report is not the rst reportšto make this claim.as early as 1973, the electronic systems division of the u.s. air force noted the ease with which thencontemporary systems (such as os/360 and gcos) had been penetrated and argued that fundamental design ˚aws were responsible for allowing these penetrations.1 in 1974, fortune published an article for the general public presenting a general overview of the vulnerability of multiaccess computer systems to unauthorized tampering, the reliability of access controls, and ways in which systems have been exploited.2 in 1991, the national research council weighed in. computers at risk stated:3 1 r.r. schell, p.j. downey, and g.j. popek, ﬁpreliminary notes on the design of secure military computer systems,ﬂ january 1973, hq electronic systems division, hanscom air force base; available at http://csrc.nist.gov/publications/history/sche73.pdf.2 t. alexander, ﬁwaiting for the great computer ripoff,ﬂ fortune, 90(1): 142150, july 1974.3 national research council, computers at risk: safe computing in the information age, national academy press, washington, d.c., 1991.10looking to the futuretoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.224 toward a safer and more secure cyberspacewe are at risk. increasingly, america depends on computers. they control power delivery, communications, aviation, and nancial services. they are used to store vital information, from medical records to business plans to criminal records. although we trust them, they are vulnerable to the effects of poor design and insufcient quality control, to accident, and perhaps most alarmingly, to deliberate attack. the modern thief can steal more with a computer than with a gun. tomorrow™s terrorist may be able to do more damage with a keyboard than with a bomb. computers at risk was also one of the rst reports to suggest that networking between computers would dramatically worsen the cybersecurity situation by enabling problems to propagate electronically and by enlarging the set of potential attackersšand indeed this is exactly what has taken place.in 1997, the president™s commission on critical infrastructure protection noted:4 [t]he right command sent over a network to a power generating station™s control computer could be just as devastating as a backpack full of explosives, and the perpetrator would be more difcult to identify and apprehend. . . .[furthermore,] the rapid growth of a computerliterate population ensures that increasing millions of people around the world possess the skills necessary to conduct such an attack. the wide adoption of common protocols for system interconnection and the availability of ﬁhacker toolﬂ libraries make their task easier.while the possibility of chemical, biological, and even nuclear weapons falling into the hands of terrorists adds a new and frightening dimension to physical attacks, such weapons are difcult to acquire. in contrast, the resources necessary to conduct a cyber attack have shifted in the past few years from the arcane to the commonplace. a personal computer and a telephone connection to an internet service provider anywhere in the world are enough to cause harm. . . .the commission has not discovered an immediate threat sufcient to warrant a fear of imminent national crisis. however, we are convinced that our vulnerabilities are increasing steadily, that the means to exploit those weaknesses are readily available and that the costs associated with an effective attack continue to drop. what is more, the investments required to improve the situationšnow still relatively modestšwill rise if we procrastinate.4 president™s commission on critical infrastructure protection, critical foundations: protecting america™s infrastructures, october 1997; available at www.fas.org/sgp/library/pccip.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 225two years later, the national research council released another report, trust in cyberspace,5 which argued that it was necessary to move the focus of the [cybersecurity] discussion forward from matters of policy and procedure and from vulnerabilities and their consequences toward questions about the richer set of options that only new science and technology can provide.trust in cyberspace reiterated the emphasis on the security challenges posed by interconnected information technologies and networked information systems. it suggested that the research agenda would be driven in large part by the (then) newly found appreciation of the vulnerability of the nation™s critical infrastructure to new forms of attack.in 2003, the bush administration released the national strategy to secure cyberspace.6 this report called attention to a threat of ﬁorganized cyber attacks capable of causing debilitating disruption to our nation™s critical infrastructures, economy, or national security.ﬂ it further pointed out that ﬁthe attack tools and methodologies are becoming widely available, and the technical capability and sophistication of users bent on causing havoc or disruption is improving.ﬂ as for the consequences of cyber vulnerabilities, it noted:in peacetime america™s enemies may conduct espionage on our government, university research centers, and private companies. they may also seek to prepare for cyber strikes during a confrontation by mapping u.s. information systems, identifying key targets, and lacing our infrastructure with back doors and other means of access. in wartime or crisis, adversaries may seek to intimidate the nation™s political leaders by attacking critical infrastructures and key economic functions or eroding public condence in information systems. . . .cyber attacks on united states information networks can have serious consequences such as disrupting critical operations, causing loss of revenue and intellectual property, or loss of life. countering such attacks requires the development of robust capabilities where they do not exist today if we are to reduce vulnerabilities and deter those with the capabilities and intent to harm our critical infrastructures.in 2005, the president™s information technology advisory committee (pitac) released cyber security: a crisis of prioritization.7 this report noted:5 national research council, trust in cyberspace, national academy press, washington, d.c., 1999.6 see http://www.whitehouse.gov/pcipb/.7 president™s information technology advisory committee, cyber security: a crisis of  prioritization, national coordination ofce for information technology research and detoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.226 toward a safer and more secure cyberspacethe nation™s information technology (it) infrastructure, still evolving from u.s. technological innovations such as the personal computer and the internet, today is a vast fabric of computersšfrom supercomputers to handheld devicesšand interconnected networks enabling highspeed communications, information access, advanced computation, transactions, and automated processes relied upon in every sector of society. because much of this infrastructure connects one way or another to the internet, it embodies the internet™s original structural attributes of openness, inventiveness, and the assumption of good will. . . .these signature attributes have made the u.s. it infrastructure an irresistible target for vandals and criminals worldwide. the pitac believes that terrorists will inevitably follow suit, taking advantage of vulnerabilities including some that the nation has not yet clearly recognized or addressed. the computers that manage critical u.s. facilities, infrastructures, and essential services can be targeted to set off systemwide failures, and these computers frequently are accessible from virtually anywhere in the world via the internet. the reports mentioned above are only some of those issued in the past 15 years regarding the nation™s cybersecurity posture. taken as a whole and as described in appendix b, these reports point to an imminent and growing cybersecurity threat. why then is there not a national sense of urgency about cybersecurity? why has action not been taken to close the gap between our cybersecurity posture and the cyberthreat?the notion that no action to promote cybersecurity has been taken in the past 15 years is somewhat unfair. in recent years, most major information technology (it) vendors have undertaken signicant efforts to improve the security of their products in response to enduser concerns over security. many of today™s products are by many measures more secure than those that preceded these efforts. in addition, the sentinel events of september 11, 2001, spurred public concerns about security, and some of that concern has spilled over into the cybersecurity domain.nevertheless, these changes in the environment, important though they are, do not change the fact that the action taken in the last 15 years is nowhere near what is necessary to achieve a robust cybersecurity posture. consider then the consequences of inadequate action, and imagine that sometime in the future the nation experiences what some have called a ﬁdigital pearl harbor.ﬂ in the subsequent investigative frenzy, the nation asks, ﬁhow could this have happened?ﬂa digital pearl harbor wouldšby denitionšbe a surprise. but it would also be a surprise that could have been anticipated. in 2004, velopment, washington d.c., february 2005; available at www.nitrd.gov/pitac/reports/ 20050301cybersecurity/cybersecurity.pdf. hereafter, ﬁthe pitac report.ﬂtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 227bazerman and watkins described a predictable surprise as an event that takes an individual or a group by surprise, despite prior awareness of all of the information necessary to anticipate the events and their consequences.8 in particular, they identify several characteristics of predictable surprises:leaders know that a problem exists and that the problem will not solve itself.the problem worsens over time.solutions for the problem incur signicant costs in the present, while the benets of taking actionšalthough likely larger than the solution costsšare both uncertain and realized in the future.some parties whose efforts are needed to help solve the problem benet from inaction.to explain inaction, bazerman and watkins posit causes at the individual, organizational, and political levels. individual causes of inaction are rooted in cognitive biases that lead individuals to discount the future more heavily than is appropriate and thus to undervalue risks. they also prefer to run the risk of lowprobability highconsequence events in the future rather than to incur certain but smaller losses in the present. finally, they nd it difcult to take action when they have not personally experienced a problem and cannot imagine what it would mean in practical terms.organizations fail to act because they do not have processes in place to scan the environment for all sources of threat, to integrate those sources of information, to respond in a timely manner, or to incorporate lessons learned from those responses into their institutional memory. they also have structural issues that inhibit a coordinated response to the problem and/or have incentives in place that encourage people to behave in a way that damages the ability to achieve organizational goals.politically, leaders are reluctant to make decisions that impose certain costs now for benets that will almost certainly not be realized within their terms of ofce.most of these conditions can be seen in examining the current environment for cybersecurity. policy makers have been warned repeatedly that there is a cybersecurity problem and that without action the problem will not solve itself. all signs point to a worsening of the cybersecurity problem, and the only argument today is how fast it is getting worse. it is 8 max h. bazerman and michael d. watkins, predictable surprises: the disasters you should have seen coming, and how to prevent them, harvard business school press, cambridge, mass., 2004.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.228 toward a safer and more secure cyberspacesimply not credible to assert that the problem is getting better. putting into place adequate cybersecurity measures, both technical and procedural, will cost in terms of reduced productivity, increased expense, and greater inconvenience, although the costs of such measures are dwarfed by the potential future benets of avoiding certain kinds of cyberdisasters. and, both vendors and users of information technology benet from inaction, because they can avoid the costs of changing existing practices.from the committee™s perspective, the lack of adequate action in the cybersecurity space can be largely explained by three complementary reasons: the various cybersecurity reports issued to date have not provided the sufciently compelling information needed to make the case for dramatic and urgent action. if so, a sufciently ominous threat cloud will inspire decision makers to take action. but it is well known that detailed and specic information is usually more convincing than information couched in very general termsšunfortunately, detailed and specic information in the open literature about the scope and nature of the cyberthreat is lacking.even with the relevant information in hand, decision makers discount future possibilities so much that they do not see the need for presentday action. in this view, nothing short of a highly visible and perhaps ongoing cyberdisaster will motivate actions. decision makers weigh the immediate costs of putting into place adequate cybersecurity measures, both technical and procedural, against the potential future benets (actually, avoided costs) of preventing cyberdisaster in the futurešand systematically discount the latter as uncertain and vague. the costs of inaction are not borne by the relevant decision makers. the bulk of the nation™s critical infrastructure is owned and operated by privatesector companies. to the extent that these companies respond to security issues, they generally do so as one of the risks of doing business. but they do much less to respond to the threat of lowprobability, highimpact (i.e., catastrophic) threats, even though all of society at large has a signicant stake in their actions.9 9 for example, under today™s practices, a party that makes investments to prevent its own facilities from being used as part of a ddos attack will reap few benets from such investments, because such an attack is most likely to be launched against a different party but will consume few resources locally. but internetusing society would clearly benet if many rms made such investments. making parties liable for not securing their facilities against being illicitly used as part of a ddos attack (today there is zero liability) would change the incentives for making such investments.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 229as for the impact of research on the nation™s cybersecurity posture, it is not reasonable to expect that research alone will make any substantial difference. indeed, there is a very large gap between a successful ﬁin principleﬂ result or demonstration and its widespread deployment and use. closing this gap is the focus of category 3 research, described in chap ter 6. but, as this report argues, many other factors must be aligned in addition if research is to have a signicant impact. specically, it vendors must be willing to regard security as a product attribute that is coequal with performance and cost, it researchers must be willing to value cybersecurity research as much as they value research into highperformance or costeffective computing, and it purchasers must be willing to incur presentday costs in order to obtain future benets.10.2 priorities for actiondespite the analysis of section 10.1, the committee believes that meaningful action is possible to improve the cybersecurity posture of the nation. in certain contexts, it may be that the security risks inherent in using it may outweigh the benets of doing so, even after everything possible has been done to improve security in those contexts. (it is, of course, a topic worthy of research in itself to develop a decisionmaking framework that would help to identify such contexts.) nevertheless, for the majority of contexts in which it is today or will in the future be a necessary enabler, a set of circumstances does give the committee hope that progress is indeed possible. especially outside the intelligence community, it is increasingly common to nd security practitioners and researchers who realize that risk management, rather than risk avoidance, is the name of the game. this realization makes it possible for managers to take pragmatics steps forward rather than waiting for the silver bullet to be found. a more powerful technological base that can support approaches and techniques previously deemed unfeasible for technological reasons is now also available. most importantly, there is a growing awareness among end users that cybersecurity should be a more serious consideration in their acquisition decisions than it was in the past. this is likely to increase the demand for greater cybersecurity functionality.the committee has identied the ve action items below as warranting the highest priority. policy makers should carry out the following actions:create a sense of urgency about the cybersecurity problem commensurate with the risks.commensurate with a rapidly growing cybersecurity threat, suptoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.230 toward a safer and more secure cyberspaceport a robust and sustained research agenda at levels which ensure that a large fraction of good ideas for cybersecurity research can be explored.establish a mechanism for continuing followup on a research agenda.support infrastructure for cybersecurity research.sustain and grow the human resource base.10.2.1 item 1: create a sense of urgency about the cybersecurity problem commensurate with the risks.some lessons can be learned from the nation™s response to the y2k (year 2000) problem. in the early years of information technology, a programming practice arose of recording dates in a sixdigit format (mm/dd/yy). if programs embedding this practice were operative at the turn of the century, the result could have been that the year ﬁ2000ﬂ (recorded as ﬁ00ﬂ) would be interpreted as the year ﬁ1900,ﬂ thus causing many date comparisons to be made incorrectly. since this programming practice was widespread, and in particular was likely used in many critical systems, concerns arose that many of these critical systems would fail if this problem was not xed.both the extent and the severity of the problem were largely unknown, but the timing of the problem was absolutely clear and unambiguous. in realtime datedependent systems that used twodigit years, the problem would manifest itself on january 1, 2000, at midnight. in other systems, the problem would manifest itself upon rst system startup after january 1, 2000. consequently, many efforts were made to focus attention on the issue and to effect repairs. these efforts included legislation, public education and awareness, the replacement of old information technology, the development of backup and contingency plans, and insurance policies covering problems resulting from the y2k problem.in the late 1990s, the y2k problem was seen as an urgent one. moreover, in many ways, the y2k problem can be regarded as a kind of cybersecurity problem. plausible arguments existed suggesting that y2k problems were potentially widespread and serious. limited testing demonstrated, in a number of systems, the actual existence of y2k problems. nevertheless, the actual nature and scope of problems caused by twodigit years were unknown. y2k problems in one system often had ramications for the proper operation of other systems to which it was connected. business considerations, including continuity of operations, insurance, and liability, played important roles in motivating corrective actions.the national response to the y2k problem demonstrates that it is possible to take action on a large scale in response to an impending toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 231emergency. however, in one very fundamental aspect, the y2k problem and today™s cybersecurity problem are different. the y2k problem was certain to arrive on a specic date known to everyone (and the nature of the problem was well understood), whereas the arrival date and specic nature of a ﬁdigital pearl harborﬂ are highly uncertain. how, then, can a sense of urgency be created in the absence of a natural forcing deadline?from the committee™s perspective, two actions are necessary, both motivated by the discussion of section 10.1. the rst action relates to making more information available. because it is possible, though in the committee™s view unlikely, that the information available to decision makers is inadequate, the compilation of a truly authoritative threat assessment could have salutary benets. but to be truly authoritative, this assessment would have to draw on the best industry and intelligence data available. indeed, some of the necessary information is not available today in any meaningful sense, since many victims of cybersecurity incidents are reluctant to discuss these incidents for public attribution, and other data are classied.arrangements must thus be made to incentivize these parties to release the information, as discussed in sections 6.4.4.2 and 6.4.4.5. at the same time, actions must be taken to relieve the concerns of victimized parties about the harm that might result from the release of such information.the notion of developing measures to increase transparency and provide relevant information so that consumers can make informed decisions is not new, and some steps in this direction have been taken. for example, within the national security telecommunications advisory committee (nstac) context, incident information (e.g., outages, causes) is shared in the relevant community subject to a condentiality requirement. the infragard program is a federal bureau of investigation (fbi)sponsored effort that brings together businesses, academic institutions, state and local law enforcement agencies, and other participants to share information and intelligence preventing hostile acts in cyberspace. the department of homeland security (dhs) has established ﬁprocedures for handling protected critical infrastructure informationﬂ that govern the receipt, validation, handling, storage, marking, and use of critical infrastructure information voluntarily submitted to the dhs.10 nevertheless, such sharing proceeds somewhat tentatively. firms have an incentive to freeride on the information security expenditures of the other members of sharing organizations (ﬁthe tragedy of the commonsﬂ), and additional incentives need to be developed for rms to fully and truthfully reveal 10 federal register, 71(170), september 1, 2006. see http://edocket.access.gpo.gov/2006/067378.htm.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.232 toward a safer and more secure cyberspacesecurity information so that the social welfare benets of sharing can be accrued.11 a second reason for a reluctance to share information is that, for a given incident, a x for the problems that caused it may not be immediately available. sometimes, even the mere statement that there is a vulnerability in a particular system is enough to prompt special attention to that system from wouldbe attackersšattention that might result in the discovery of that vulnerability. a rst step toward an authoritative threat assessment could have been the national computer security survey sponsored by the bureau of justice statistics at the department of justice (doj) and the national cyber security division (ncsd) at the dhs. conducted by the rand corporation, this study was scheduled to be published in 2007, and would have had the advantage of being able to provide legal protection for the information provided by survey respondents. statutory provisions protect the condentiality of the information provided, prohibit the sharing of data with other agencies, provide exemptions from the freedom of information act (foia), and ensure immunity from legal processes.12 however, to be truly valuable for understanding the evolving threat and trends, the survey would have to be conducted on a regular and ongoing basis. unfortunately, this task was terminated before its completion by the doj and the ncsd.section 10.1 also indicated the possibilityšindeed, in the committee™s view, the great likelihoodšthat adequate information on the cybersecurity threat is available today. thus, the second action calls for changing the decisionmaking calculus that excessively focuses vendor and enduser attention on the shortterm costs of improving their cybersecurity postures. calls to change the decisionmaking calculus are often regarded suspiciously by those who would be affected by such changesšnot surprisingly, since their bases for business planning would, by denition, be changed. as noted in sections 6.4.4.5 and 6.4.4.6, there is enormous political resistance to notions of change that entail direct regulation or liability, resistance that in some cases is well grounded in uncertainty about ultimate effects. this is not to say that it is impossible to take meaningful policy actionšonly that such action may have to be more indirect and less obvious than some might prefer. such policy actions might include, for example, encouraging accounting rms and insurance rms to take into 11 see lawrence a. gordon, martin p. loeb, and william lucyshyn, ﬁsharing information on computer systems security: an economic analysis,ﬂ journal of accounting and public policy, 22(6): 461485, 2003.12 department of justice, bureau of justice statistics, national computer security survey web page, http://www.ojp.usdoj.gov/bjs/survey/ncss/ncss.htm. the law, noted on this web page, is p.l. 107347, title v and 44 u.s.c. paragraph 3501. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 233account the cybersecurity postures of their customers when providing audits or setting insurance rates. the committee recognizes that policy actions are, almost by denition, less compelling for focusing attention and stimulating action than are deadlines imposed by nature. but in the committee™s view, even weaker policy actions can stimulate some action, and every little bit helps. finally, although the committee did not take a position regarding the desirability of regulation or liability as a way to improve cybersecurity, it did agree that regulation and liability are tools of last resort to promote this end. in other words, the nation should not turn to regulation or liability as an approach to improving cybersecurity until decision makers conclude that other approaches have proven insufciently effective. in the meantime, while awaiting that judgment, it behooves the research community to consider how the tools of regulation and liability might sensibly be applied should those tools of last resort ultimately prove necessary. the alternative to such interim research is an illconsidered and unresearched regime of liability and regulation that might well be imposed hastily in the wake of a crisis, to the detriment of all. that is, the nation should not turn to regulation or liability as an approach to improving cybersecurity until decision makers conclude that other approaches have proven insufciently effective. 10.2.2 item 2: commensurate with a rapidly growing  cybersecurity threat, support a robust and sustained research  agenda at levels which ensure that a large fraction of good  ideas for cybersecurity research can be explored.given the need for breadth and diversity in the research portfolio within the areas of focus described in part ii of this report, the committee believes that the nation is ill served by a funding model that seeks to channel resources to a small number of specic research topics. instead, it makes more sense to conceptualize the overall research portfolio as one that focuses resources on sustaining the intellectually broad and diverse community capable of (1) generating ideas across a wide waterfront (as one might expect would be needed for a diverse threat) and (2) producing the cybersecurity expertise needed across all points in the it life cycle, including design, development, implementation, testing, operations, maintenance, upgrading, and retirement. note further that breadth in the research agenda does not mean that every topic should be funded equally. rather, it is the merits and rationales of individual proposals, toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.234 toward a safer and more secure cyberspacecombined with a cognizance of the threat environment and advances in technology, that should determine funding allocations.with this model, the scale of the necessary funding is set by the amounts needed to sustain this community at appropriate levels and to ensure that a large fraction of good ideas for cybersecurity research can be explored. in this context, a good idea is one that is determined to be good through some kind of evaluative process. in peerreviewed communities, peer review determines if an idea is ﬁgood.ﬂ in agencies such as the defense advanced research projects agency (darpa), program managers exert much in˚uence in deciding if an idea is good. several federal agencies have an important role to play in the cybersecurity research agenda. for two reasons, the committee does not make specic recommendations for which agencies should pursue which specic research topics. first, many of the topics described might well t into the agendas of multiple agencies. second and at the same time, the different agencies have different needsšespecially missionoriented agencies. however, the committee does urge that federal decision makers take into account historical strengths and missions of the various departments. for example, the department of energy (doe) is a logical place to support cybersecurity research efforts that relate to supervisory control and data acquisition (scada) systems, as such systems are an essential element of the electric grid, for which the doe has much oversight responsibility. the national institute of standards and technology (nist) and national security agency (nsa) have historically undertaken substantial research efforts in cryptography and other security technologies and have developed strengths that should be leveraged in future research to the extent that it can be done on an unclassied basis. with historical efforts in metrology, nist is also a natural place to focus research on cybersecurity metrics. darpa has historically conducted substantial research on systembuilding, and all of the department of defense (dod)šas well as much of the nondefense government portfolio and civilian workšwould benet substantially from advances in secure system building, as discussed in appendix b (section b.6.4.2). and, given its investigatordriven focus, the national science foundation (nsf) is the obvious agency to develop and sustain a broad national research portfolio.different agencies also support different kinds of research communities. for example, nsf tends toward smaller grants for individuals or small teams, with fewer and less specic deliverables. historically, darpa has built communities and encouraged large grants to address very hard problems, although recent management changes and policies have begun to change such practices. diversity in the character of research communities is also to be encouraged, because it is hard to predict what styles of research will result in progress. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 235as for the magnitude of the budget needed to sustain the committee™s principle, the committee notes that for the foreseeable future the cybersecurity threat will only grow. first, the threat is likely to grow at a rate faster than the present federal cybersecurity research program will enable us to respond, and the consequences of failing to provide an adequate response could be quite damaging to the nation.second, the pitac report implicitly enunciated a principle for funding cybersecurity research that the committee nds eminently sensible: most good research ideas should be supported and that proposals based on such ideas should be supported at or near the levels requested.13for these reasons, the committee concludes in general terms that both the scope and scale of federally funded cybersecurity research are seriously inadequate. to execute fully the broad strategy articulated in this report, a substantial increase in federal budgetary resources devoted to cybersecurity research will be needed.to provide some characteristic orders of magnitude for this discussion, the committee notes that the scale of today™s cybersecurity research budgets is probably somewhat larger than $160 million annually. this estimate is based on the pitac estimate for federally supported cybersecurity research in scal year (fy) 2004, both classied and unclassied, of about $160 million. although the committee was unable to nd data to support a similar estimate for fy 2005 or fy 2006, it also knows of no signicant change in the budget, a point suggesting that ﬁa little more than the fy 2004ﬂ is not an unreasonable guess. (the breakdown of the total $160 million between classied and unclassied research is unknown, although it is obvious that amounts supporting classied research are not accessible to the broad cybersecurity research community at large.)as a point of comparison, the committee notes a gartner group estimate that nancial losses stemming from phishing attacks alone exceeded 13 specically, the pitac report argued for a quadrupling of the nsf budget allocated to the cyber trust program ($31 million to $120 million), under which most of the nation™s governmentsupported unclassied basic cybersecurity research is performed. at the time, the pitac argument was based on a success rate for the cyber trust program that was about a factor of three lower than that for nsf as a whole (8 percent versus 25 percent) and the funding of most of the proposals supported at a level signicantly below the levels requested. according to karl levitt, program manager for the cyber trust program, the success rate in 2006 for the cyber trust program was about 12 percentšand was accomplished by eliminating for that year the funding for centerlevel grants and by signicantly reducing the funding awarded compared with that requested. the ratio of total amounts awarded to total amounts requested was less than 8 percent, a gure comparable to that of scal year 2004. in 2007, the success rate was increased to 20 percent, mostly because the cyber trust budget was increased to $34 million, the level that it was at in 20042006, but also because of not making centerlevel awards (karl levitt, nsf, personal communications to the committee, november 27, 2006, and june 21, 2007).toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.236 toward a safer and more secure cyberspace$2.8 billion in 2006.14 the reason that such losses are not more visible is that they are usually absorbed as a ﬁtaxﬂ on purchases (that vendors pass along to customers), and they are distributed as small losses and productivity losses over the population. thus, no one party suffers a huge loss (generally) that shows up in reports. but the overall expense is large.another point of comparison is the 2005 fbi computer crime survey, which estimated the cost of ﬁcomputer security incidentsﬂ in the 12month period from mid2004 to mid2005 at $67.2 billion to u.s. organizations.15 (the raw data for this survey were provided by 2,066 organizations on a selfreported basis, and the $67.2 billion aggregate gure is extrapolated.) it is hard to know how seriously to take this specic gure, which amounts to 0.5 percent of the u.s. gross national product; although statistics on the amount lost to cybercrime are generally of dubious reliability, there is no doubt that aggregate losses are considerable.the committee does not mean to imply that the dollars that could be saved through better cybersecurity should somehow subsidize a research effort. yet it is not unreasonable to suggest that the magnitude of such losses should have some bearing on the efforts devoted to cybersecurity research.fiscal reality today dictates that discretionary budgets for the foreseeable future will be very tight, if not declining in absolute terms. in the current budget environment, is it ﬁrealisticﬂ to recommend budget increases in a program or in a national portfolio? it is a truism that growth in the budget of any given program comes from one of two sourcesšan explicit decision to support it with additional appropriations without a corresponding offset somewhere else in the budget, or an explicit decision to increase the program™s budget while at the same time decreasing the budget of one or more other programs. but it is also true that no matter how tight budgets are in any given year, some programs grow, others shrink, and still others start anew while others terminate. thus, growth in existing programs or new program starts re˚ect political will and a judgment regarding the benets of such programs relative to other programs. the committee also makes three caveats about additional funding. first, policy makers should regard cybersecurity research as a continuing and ongoing need that will extend for the foreseeable future. as long as information technology continues to enable economic innovation and to 14 gartner press release, ﬁgartner says number of phishing emails sent to u.s. adults nearly doubles in just two years,ﬂ november 9, 2006; available at http://www.gartner.com/it/page.jsp?id=498245.15 see www.digitalriver.com/v2.0img/operations/naievigi/site/media/pdf/fbiccs2005.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 237be a pillar of prosperity, cybersecurity cannot be seen as a discrete problem to be solved once and for all, but rather as a class of problems that will continuously evolve as new technology and new threats continue to present new issues. as a result, a funding model calling for a onetime increase in cybersecurity research, even a substantial one over multiple scal years, is less relevant than one that continues to enable a large fraction of good ideas to be supported in the long term.second, additional funding should really be ﬁnew moneyﬂ rather than ﬁrelabeledﬂ money or money taken from other computer science research. in the words of the pitac report, for instance: [t]he increase in the nsf cise budget for civilian cyber security fundamental research [should] not be funded at the expense of other parts of the cise directorate. . . . signicant shifts of funding within cise towards cyber security would exacerbate the strain on these other programs without addressing the existing disparity between cise and other directorates. moreover, much work in ﬁotherﬂ cise areas is benecial to cybersecurity and thus reductions in those other areas would be counterproductive. [for example,] theoretical computer science underpins much encryption research, both in identifying weaknesses and in advancing the state of the art. algorithms research helps ensure that protocols designed for security can be efciently implemented. programming language research can help address security at a higher level of abstraction and can add functionalities such as security assurances to software. software engineering can help eliminate software bugs that are often exploited as security holes. and new computer architectures might enforce protection faster and at ner granularity. nor should cybersecurity research remain in the computer science domain alone. additional funding might well be used to support the pursuit of cybersecurity considerations in other closely related research endeavors, such as those related to creating highassurance systems and the engineering of secure systems across entire system life cycles (see the discussion in section 4.3).third, funding should be increased only at a rate consistent with the pace at which qualied researches are trained or move into the eld from other branches of computer science. ﬁboomandbustﬂ cycles often do harm to a eld, especially when they lead to unwise expenditures.10.2.3 item 3: establish a mechanism for continuing  followup on a research agenda.management of the complete cybersecurity research portfolio across the federal government requires that government decision makers have toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.238 toward a safer and more secure cyberspacea reasonably negrained understanding of the scope and nature of that portfolio. however, to the committee™s knowledge, a picture that is both adequately detailed and sufciently comprehensive does not exist today. to take just one example, the president™s information technology advisory committee was able to determine the darpa investment in cybersecurity research and development (r&d) for fy 2004 only within a fac tor of about four (that is, pitac determined that gure to be between $40 million and $150 million).the national coordination ofce (nco) for networking and information technology research and development (nitrd), which supports the planning, budget, and assessment activities of the federal government™s nitrd program, tracks the unclassied portion of the cybersecurity research and development portfolio. this portfolio, which accounts for about $175 million in the administration™s fy 2007 request, is focused on research and advanced development to prevent, resist, detect, respond to, and/or recover from actions that compromise or threaten to compromise the availability, integrity, or condentiality of computerbased systems. the nco supports the interagency working group on cyber security and information assurance (csia iwg), which coordinates programs, budgets, and policy recommendations for csia r&d.16the nitrd coordination process is an important rst step toward creating the picture that is needed for adequate management of the federal cybersecurity research portfolio. nevertheless, it could be strengthened in a number of important ways:distinguishing clearly between research and development. as presented, the nitrd gures aggregate research and development. because development efforts are most often focused on shortterm deliverables, aggregating research and development does not provide a clear indication of effort devoted to longerterm goals. including classied research and development in the big picture. the mere fact that research and development may be conducted under 16 the csia iwg reports to the nitrd subcommittee of the national science and technology council (nstc) committee on technology. the following nitrd agencies belong to the csia iwg: the department of defense (defense advanced research projects agency, ofce of the secretary of defense, dod service research organizations, and the national security agency), the environmental projection agency, the national aeronautics and space administration, the national institute of standards and technology, the national institutes of health, and the national science foundation. the following agencies participate in csia iwg activities: the central intelligence agency, the department of energy (lawrence livermore national laboratory), the department of homeland security, the department of justice, the department of state, the department of transportation (including the federal aviation administration), the department of the treasury, the disruptive technology ofce, the federal bureau of investigation, and the technical support working group.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 239classied auspices does not mean that such efforts produce no knowledge of value outside the military, diplomatic, and intelligence communities. it may mean, for example, that researchers and developers may have been asked to conduct their work in the context of specic problems whose details are classied. thus, classied work is at least potentially relevant to the nation™s broad efforts to secure cyberspace. (note that this notion does not suggest that the detailed spending gures for classied cybersecurity research should be made public or broadly availablešbut policy makers in both the executive and legislative branches [e.g., in the ofce of management and budget and in the relevant congressional committees] should have access to the ﬁbig pictureﬂ of cybersecurity research.)disaggregating (and publishing) governmentwide budget gures associated with different areas of focus. individual agencies will often group the contracts and grants they support into broader categories (box 10.1 presents an exemplary approach). but the major weakness in these agency efforts is that they are not comparable across agencies. that is, any relationship between the categories of one agency and another agency is due mostly to chance. establishing some common categories (and providing multiple crosswalks among them) that would be relevant across agencies would provide a more informative picture.tracking budget gures from year to year. the picture of federal cybersecurity research efforts evolves over time. thus, efforts must be made to provide comparable analyses from year to year if the time evolution is to be understood.note also that the comparability of budget gures in different categories across agencies depends largely on a small number of analysts who are knowledgeable about the subject matter doing the mapping from individual awards to budget categories for all of the agencies involved. the small number is essential, because otherwise an agency is likely to task an individual analyst to do this work for that agency, and this person will use different criteria and judgments for mapping than those that the analyst for a different agency would use. for similar reasons, it is important for the same analysts to do the categorizations from year to year, since doing so will enhance the yeartoyear comparability of the resulting gures.greater transparency into federal support for cybersecurity research would enable decision makers at all levels of responsibility, and in particular the program managers with direct responsibility for the execution of programmatic responsibilities regarding research, to understand the toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.240 toward a safer and more secure cyberspacebig picture of federal activities in this area. one benet is that program managers would be able to identify more easily excessive redundancy in research.17 a second benet is that transparency would facilitate greater 17 the committee notes that some degree of redundancy in research is not necessarily inappropriate, as it can mean working on different approaches to similar problems. it is true that centralized prioritysetting approaches generally seek to eliminate redundancy, but more often than not target all redundancy, whether useful or not. by contrast, conversations between program managersšwho are closer to the research actually being performed and thus more knowledgable about the nuances of the research they supportšare more likely to be able to identify excessive redundancies.box 10.1 a model categorization for understanding budgetsthe national science foundation (nsf) overview of the scal year 2004 awards for the cyber trust program and related awards included several substantive categorizations for the same awards, including the following:topic (security of nextgeneration operating systems and networking; forensic and law enforcement foundations; humancomputer interface for security functions; crossdisciplinary approaches; theoretical foundations and mechanisms for privacy, security, trust; composable systems and policies; presenting security concepts to the average user; improved ability to certify system security properties; improved ability to analyze security designs and to build systems correctly; more effective system monitoring, anomaly detection, attack recognition and defense; and integrating hardware and software for security).security lifecycle phase (understanding what to build; building things right; preventing attacks; detecting/understanding attacks; surviving attacks; system recovery/reconstitution; and forensics/dealing with perpetrators). security disciplines (operating system, lesystem, storage security; net security; application/database/web security; cryptography and applied cryptography; security/privacy/trust modeling and specication; secure system architecture; secure system development; security testing/evaluation; and forensics).the nsf provided multiple categorizations, noting on the web site (see the source in this box) that ﬁmost research projects have several dimensions, such as the expected time to yield results, where the project lies on scales ranging from empirical to theoretical work, from foundational to applied, and across domains and disciplines of study. any attempt to group projects into categories will consequently succeed better for some than for others.ﬂ accordingly, nsf presents multiple categorizations that constitute a framework for relating projects to each other and that provide an overall picture of the program.source: see http://www.nsf.gov/cise/funding/cyberawards.jsp#other.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 241scrutiny of research projects by the cybersecurity community at largešscrutiny that might help to terminate projects that were clearly going down the wrong path.1810.2.4 item 4: support infrastructure for cybersecurity research.making progress on any cybersecurity research agenda requires substantial attention to infrastructural issues. in this context, a cybersecurity research infrastructure refers to the collection of open testbeds, tools, data sets, and other things that enable research to progress and allow research results to be implemented in actual it products and services. without an adequate infrastructure, there is little hope for realizing the full potential of any research agenda.the reason is that cybersecurity is a systems and an operational issue. for example, realistic testbeds are needed for demonstrating or validating the operational utility of new cybersecurity technologies. realistic data sets of sufcient size, realism, and currency are similarly needed for security analysts to understand and characterize the various attacks against which they are defending (while keeping in mind that future attacks may not resemble past attacks).an infrastructure for cybersecurity research provides invaluable assistance in new ideas at a reasonable scale, in the wild, with real users; insight into appropriate paths to the ﬁtipping pointﬂ (the point of acceptance of an innovation after which the entire community feels that it no longer makes sense to refuse to accept it); and ways of exploring the achievement of fundamental change through incremental strategies that do not require all internet users and all their vendors to change before benet is realized.consider, for example, the need for cybersecurity testbeds. because a large part of the cybersecurity problem involves the rapid propagation of viruses and worms throughout the internet, a realistic testbed for testing defenses is necessary. in this context, ﬁrealisticﬂ means one of sufcient size and appropriate conguration to be in some sense representative of the internet as a whole. a testbed enables defenses against viruses and 18 the committee is fully aware of tensions between category 6 research (speculative research that may be regarded as ﬁoutoftheboxﬂ by the mainstream research community) and research that ought to be terminated. indeed, supporters of the latter will almost always claim that their research is in the former category. there is no denitive response to such a claim, but it helps to observe that category 6 research is not intended to be the funding opportunity of last resort for every bad idea in the world, that program managers will need to make informed and reasoned judgments about research to be funded under the category 6 rubric, and that the amount of funding devoted to category 6 research is supposed to be a relatively small fraction of overall budgets in any case.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.242 toward a safer and more secure cyberspaceworms to be tested under relatively controlled conditions. propagation speed, destructiveness, and virulence of an attack can be evaluated in a safe environment (i.e., without consequences for the larger internet). most importantly, a testbed can be instrumented quite thoroughly so that the detailed mechanisms of an attack can be better understood. (an example of a cybersecurity testbed is the cyber defense technology experimental research [deter], a joint project of the university of california at berkeley; the university of southern california™s information sciences institute [uscisi]; and mcafee associates. the deter network was launched in late 2003 under a 3year grant from the nsf in cooperation with the dhs.)cybersecurity testbeds also include research platforms. a good example of a research platform serving as a testbed is multics, which served as the focal point for the exploration and demonstration of new ideas over several generations of researchers.19a cybersecurity research infrastructure also includes largescale data sets that allow researchers to accurately represent certain kinds of attacks ˚owing across the internet. in the absence of such largescale data sets, which ought to be open to any legitimate cybersecurity researcher, the efcacy of a solution may be based on nonrepresentative situations or attacks. an example of an effort to make such data available to the cybersecurity research community is the dhssponsored protected repository for the defense of infrastructure against cyber threats (predict) initiative. predict provides cybersecurity developers and evaluators with highquality, regularly updated, network operations data sources that provide timely and detailed insight into cyberattack phenomena occurring across the internet, and in some cases will reveal the effects of these attacks on networks that are owned or managed by the data producers. 10.2.5 item 5: sustain and grow the human resource base.human capital is a particularly important concern for cybersecurity, since people are the originators of new ideas. recommendation 2 of the pitac report cyber security: a crisis of prioritization dealt directly with this point. that recommendation stated:[t]he federal government should intensify its efforts to promote recruitment and retention of cyber security researchers and students at research universities, with a goal of at least doubling the size of the 19 multics (multiplexed information and computing service) was a mainframe time sharing operating system begun in 1965 and used until 2000. more information on multics can be found at http://www.multicians.org/.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 243civilian cyber security fundamental research community by the end of the decade. in particular, the federal government should increase and stabilize the funding for fundamental research in civilian cyber security, and should support programs that enable researchers to move into cyber security research from other elds. the reasoning underlying this recommendation was, and remains, sound. today, cybersecurity research is not a broadbased effort that engages a substantial fraction of the computer science research community. for example, only a small fraction of the nation™s graduating doctoral students in it specialize in cybersecurity, only a few professors conduct research in cybersecurity, and only a few universities support research programs in these elds.the committee aligns itself with the spirit of this recommendation, if not necessarily its specic scale. in times of crisis, calls for new technology usually invoke the memory of the manhattan project to build the atomic bomb. but the need to build human capital for the cybersecurity eld suggests that it is not the manhattan project that provides the right metaphor, but rather the national response to sputnik. the manhattan project resulted in the deployment of hardwarešwhereas a primary result of sputnik was the national defense education act, which focused attention on and generated substantially greater support for increasing science and mathematics education. analogously, the committee believes that increasing human capital for cybersecurity ought to be an essential part of the national response to the cybersecurity problem.consider, then, two key dimensions of the human capital issue in cybersecurity research addressed in the following subsections.10.2.5.1 enlarging the pool of researchersuniversities are the primary source of human capitalšand graduate study is essentially the only source for the researchers of the future. for a eld in which new ideas are always needed (and in light of the increasing sophistication of cybersecurity threats), growing the supply of such researchers and exploiting the power of many minds at work are critical for success and essential if we are to have even a remote hope of staying ahead of the curve, or even keeping pace with it.there are only two strategies for increasing the number of researchersštraining new entrants to specialize in the eld (that is, graduate students) and enticing alreadyestablished researchers in other elds to join the eld. either strategy depends on demonstrating to these prospective new researchers thatšin addition to important and interesting intellectual problemsšthere is a future to working in the eld, a point suggesting toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.244 toward a safer and more secure cyberspacethe importance of research support for the eld that is both adequate and stable. regarding adequacyšincreasing the number of researchers in a eld necessarily entails increased support for that eld, and no amount of prioritization within a xed budget will result in signicant growth in that number. regarding stabilityšstable or growing levels of funding act as a signal to potential graduate students about the importance of the eld and, by implication, the potential for professional advancement. avoiding negative signals to prospective researchers is also important. for example, given the uncertainties of research, funding models for individual research contracts or grants that demand shortterm deliverables and that include go/nogo decisions reduce the number of qualied individuals who regard that research eld as being worth a career commitment. they also bias the conduct and scope of the research effort. research that cannot be published or otherwise disseminated is also an inhibitor, given that the potential for recognition by one™s peersšwhatever the formšis a powerful motivator for many researchers and indeed a career enhancer for those in academia.yet another issue is that of making the broadest possible use of available talent. one aspect of such talent is graduate student labor, upon which much of university research is based. graduate students, who work under the supervision of faculty members, are nevertheless expected to make original contributions to knowledge in their specialties. when the federal government places restrictions on the research work that foreign graduate students can perform, it reduces the pool of talent available to further the research agendašand given that foreign graduate students constitute a signicant fraction of the graduate student population, it diminishes the talent pool signicantly. a second aspect of the talent issue is that of the participation of females and nonasian minorities in advanced it education. apart from issues of simple equity, enhancing diversity in intellectual backgrounds and personal histories of the cybersecurity research workforce is likely to expand the range of approaches proposed and taken to address unsolved problems, an outcome that may well lead to more rapid progress. moreover, anecdotal evidence from some cybersecurity researchers suggests that a higher percentage of these underrepresented students are involved in cybersecurity research than in other subspecialties within computer science.10.2.5.2 enhancing cybersecurity knowledge and awareness in the future it workforce a number of government efforts to promote the education of security specialists focus on teaching specialists about current technologies, organizational management, and best practices with current products and toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 245services. such efforts are useful, but they do not speak to development of a cadre of computer scientists and engineers and it leaders that will focus on how to make the next generation of products and services more secure.today, designers and developers of it products and services are often not schooled in what it means to design and develop with cybersecurity in mind. software engineering has not traditionally been conceptualized or practiced with an assumption that there was an active adversary. but now designers and developers must approach their tasks under the assumption that every line of code may someday be attacked. the use of threatbased design and development is a shift in the development of it products. education must be seriously revamped if this shift is to take place on a large scale.put differently, in the long run, security will require the integration of a cybersecurity perspective in virtually every it course, with the goal of promoting a security culture throughout the masses of systems designers, developers, and systems administrators and not just in cybersecurity researchers. that is, every software and hardware course of study should integrate the research results from the study of security requirements, architectures, and tools with an eye toward training future it workersšnot just future security experts, but also every it practitioner, researcher, educator, systems administrator, computer designer, and programmer. consider what such revamping of mindset might mean in the it life cycle. whereas the old mindset in hardware and software design focused on performance and functionality, respectively, the new mindset should also focus equally on security and attack resilience. as an example, current software engineering education stresses some form of object reuse, generalization of interfaces, and modularization, but it does not address the security implications of such features. the various parts of a program that reuse an object may have different security expectations, generalized interfaces may expose too much ﬁattack surface,ﬂ and modularization itself has the side effect of creating accessible interfaces.whereas security was implemented as an afterthought in previous computer designs, it should be an integral part of the initial designs for future secure and attackresilient computer architectures, and it should be integrated into every aspect of the hardware and software design life cycles and research agendas. whereas in the old mindset, design principles help primarily to critique a system after the design has been completed, the new mindset calls for clear examples of design that demonstrate how such principles can be incorporated into new designs.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.246 toward a safer and more secure cyberspacewhereas the response to security breaches was reactive in the old mindset (e.g., the ﬁpatch and prayﬂ approach, with vendors supplying software patches after vulnerabilities are identied or their products are attacked), it should be proactive in the anticipation of new types of attacks in the new mindset. whereas many security products implemented only perimeter security (e.g., rewalls) in the old mindset, the new mindset would emphasize pervasive negrained authorization. for example, secure computer architecture would include security  features in the processor architecture, the hardware platform architecture, the operating system kernel, and the networking protocols; each of these components would be designed and implemented with considerable thought being given to security products. whereas the old mindset dealt with faulttolerance, or the resistance to physical aging, deterioration, and transient faults, the new mindset must also deal with very intelligent (human) attackers and malicious programs (malware). for example, current software engineering education does not emphasize that inputs to a program affecting program ˚ow must always be checked for validity before it is passed to the program, even when data are made available at internal interfaces to program components. every operation must be considered from the standpoint of how it can be spoofed, tampered with, replaced, or locked up.whereas in the old mindset, there was time to deal with a security breach, the new mindset needs to also consider malware such as future viruses and worms that can infect all computers on the internet in a few seconds. hence, responses at human operator timescales are woefully inadequate, and more autonomic responses should be researched, and deployed if promising. whereas in the old mindset, security was treated as mainly a software issue, the new mindset should consider both hardware and software dimensions of a solution. whereas in the old mindset, security experts operated in separate domains such as cryptography, network security, operating system security, and software vulnerabilities, the new mindset should emphasize the integration of these separate areas, crosspollination of ideas, and working toward the best system solution, given security, performance, cost, and usability goals. whereas in the old mindset, students are primarily indoctrinated in the importance of correct design and implementation, the new mindset gives equal emphasis to notions of defensive design and implementation in which the expectation is that programs must deal with user mistakes and malicious adversaries.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.looking to the future 247whereas in the old mindset, a system is considered secure until demonstrated otherwise by a practical attack, the new mindset suggests that a system should be regarded as insecure until there is evidence that suggests its resistance to attack.these comments are not intended to suggest that every designer and developer of it products, services, and applications must become a security specialist as well. many of today™s security specialists argue, with considerable force and persuasiveness, that security is hard, that only a few folks can get it right, and that if security has to be addressed over and over again in every application, the likely result will be myriad insecure applications. other parts of this report have suggested that security functionality can be made easier to use (e.g., section 6.1, section 4.1.2.1). but the argument for changing the security mindset across all designers and developers is just thatšto create a mindset that appreciates and acknowledges the value of security and enables the designers and developers to engage in productive and meaningful interaction and dialogue with security specialists in the course of their work.also important is eliminating the intellectual mindset that characterizes many graduates of today™s it educational programsša ﬁcowboyﬂ mentality antithetical to the disciplined and structured approach needed to design and develop secure systems. in the notsodistant past, it was fairly routine for the pressure of bringing products and service to market quickly to take precedence over all other considerations, including security. while this mindset has begun to change, and vendors are realizing that paying attention to security is likely to have some impact on their bottom line, the committee strongly believes that there is a long way to go before a disciplined and structured development effort is routine in all vendors. in the short run, organizations will adopt this approach if it enables them to ship a securityacceptable product more quickly or cheaply, and they will train their programmers inhouse. but in the long run, it is clear that the educational system willšand shouldšbear most of the burden of integrating security as an important educational element in almost every it course. this will call for treating security as a coequal to functionality and performance in most subjects.the committee believes that those responsible for educating the future it workforce must work with cybersecurity researchers if the integration of such a perspective is to occur. if a cybersecurity perspective is to become pervasive throughout the it workforce, it will require a much larger number of faculty specializing in cybersecurity research. the number of such faculty, in turn, is a direct function of the sustained research support available, even acknowledging that not all teaching faculty are research faculty or vice versa.the direct relationship between faculty size and research support is toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.248 toward a safer and more secure cyberspaceparticularly important if and when departments are contracting. in such times, it is difcult to obtain slots for any subspecialty, and especially so ifšas is the case with the cybersecurity specializationšthere is not a critical mass of those faculty members already in the department. thus, targeted funding to support the cybersecurity specialization would be particularly important if the number of such faculty is to grow.support for infrastructure is also needed for cybersecurity education. developing cybersecurity expertise requires handson experience with security products, so that their capabilities and limitations can be understood and intuitions developed for when they are or are not helpful. such infrastructure is often neglected in funding programs, and those that do exist are limited in time, amounts, and schools. 10.3 concluding commentsthe primary purpose of this report is to formulate a cybersecurity research agenda. but the scope and the nature of this agenda are inextricably intertwined with the character of the threat to cyberspace. accordingly, this report argues that the threat to cybersecurity is real, signicant, and growing rapidly. but because the combination of adversary threats and technical or procedural vulnerabilities of the future is impossible to predict in anything but the most general terms, a broad cybersecurity research agenda (section 3.4.4, principle 4: respect the need for breadth in the research agenda.) is necessary to develop new knowledge that can be used to strengthen defenses against the cyberattacks of tomorrow. furthermore, the research agenda must examine both technical and nontechnical issues. there is of course a central role to be played by technologistsšbut they must work hand in hand with organizational specialists, psychologists, anthropologists, sociologists, manufacturing specialists, and many others if the desired outcomešsystems that are more secure in the real worldšis to be achieved.in section 10.2, the committee identied ve action items for the nation™s policy makers: creating a sense of urgency about the cybersecurity problem commensurate with the risks, supporting a robust and sustained research agenda at levels which ensure that a large fraction of good ideas for cybersecurity research can be explored, establishing a mechanism for continuing followup on a research agenda, supporting the infrastructure needed for cybersecurity research, and sustaining and growing the human resource base. if these items are successfully addressed, real progress can be made toward realizing a more secure cyberspace and toward making the cybersecurity bill of rights more a reality than a vision.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendixestoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.251committee membersseymour (sy) e. goodman, chair, is a professor of international affairs and of computing, respectively, at the sam nunn school of international affairs and the college of computing at the georgia institute of technology. he is also a codirector of the center for international strategy, technology and policy and associate director for policy of the georgia tech information security center. previously he has been director of the consortium for research on information security and policy at the center for international security and cooperation and the school of engineering at stanford university. dr. goodman is interested in the international diffusion and the national absorption of information technology (it); the digital divide problems for small, poor and remote villages; and national and international security dimensions of it. he is contributing editor for international perspectives for communications of the association for computing machinery (acm) and has served with many study and advisory groups, including the president™s commission on critical infrastructure protection. he received a b.s. degree in engineering from columbia university (1965) and a ph.d. in applied mathematics/mathematical physics from the california institute of technology (1970). dr. goodman has previously served on several national research council (nrc) committees, including as chair of the meeting on technical responses to cyberattack and their legal implications. he also chaired the rst large committee (committee to study international developments in computer science and technology) ever to produce a study for the computer science and appendix acommittee and staff biographiestoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.252 toward a safer and more secure cyberspacetelecommunications board (cstb); the committee produced the report global trends in computer technology and their impact in export control, published in 1988.david aucsmith is the security architect and chief technology ofcer for microsoft corporation™s security business unit, responsible for dening the overall security architecture for microsoft products. he is currently working on a unied security architecture that spans microsoft™s products and is responsible for governmentspecic features in the windows platform. before joining microsoft in 2002, mr. aucsmith was the chief security architect at intel corporation for 8 years. his responsibilities included working on security technology for hardware and software, together with random number generation, cryptography, steganography, and networkintrusion detection. mr. aucsmith has been heavily involved in computer security and cybercrime issues for more than 20 years. he is an industry representative to numerous international, government, and academic organizations: he is a member of the advisory board of the national security agency, cochairman of the fbi™s information technology study group, and a member of the president™s task force on national defense and computer technology. mr. aucsmith holds 29 patents for digital security technology. he received a b.s. degree in biochemistry from the university of georgia, an m.s. in physics from the naval postgraduate school, and an m.s. in information and computer sciences from the georgia institute of technology.steven m. bellovin is a professor at columbia university. he was a fellow at at&t labs research, where he did research in networks and security and why the two do not get along. he has embraced a number of public interest causes and weighed in (e.g., through his writings) on initiatives (e.g., in the areas of cryptography and law enforcement) that appear to threaten privacy. he is currently focusing on cryptographic protocols and network management. dr. bellovin is a coauthor of the book firewalls and internet security: repelling the wily hacker (addisonwesley, 2nd edition, 2003), and he is one of the security area directors for the internet engineering task force. he received a b.a. degree from columbia university and m.s. and ph.d. degrees in computer science from the university of north carolina at chapel hill. he was a member of the computer science and telecommunications board (cstb) committees that produced the nrc reports trust in cyberspace (1999), idsšnot that easy: questions about nationwide identity systems (2002), information technology for counterterrorism: immediate actions and future possibilities (2003), and who goes there? authentication through the lens of privacy (2003). dr. bellovin is a member of the national academy of engineering (nae).toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix a 253joel s. birnbaum was formerly senior technical adviser to the chief executive ofcer (ceo) of the hewlettpackard (hp) company. dr. birnbaum™s role was to help the company shape its technology strategy and to communicate this strategy to the marketplace. prior to this, he served as the company™s rst chief scientist, a consulting position, created for him upon his retirement in february 1999 from his position as senior vice president for research and development (r&d) and director of hp laboratories. dr. birnbaum joined hp in 1980 after 15 years at ibm™s thomas j. watson research center in yorktown heights, n.y., where he had last served as director of computer sciences. his rst assignment at hp was as the founding director of the computer research center within hp labs, which conducted research into new directions in computer architecture, hardware, and software, as well as some novel applications. in 1984 dr. birnbaum was named an hp vice president and director of hp labs. in 1986 he was named general manager of the information technology group. he managed the development of all core hardware platforms and systems software for the precision architecture product line, hp™s rst reduced instruction set computers (riscs). after the rst successful shipment of these systems in 1988, he was named general manager of the new information architecture group, which developed systems architectures for cooperative computing environments, the basis of hp™s product line today. in 1991 he was elected senior vice president of r&d and once again director of hp labs. in this role, as a member of the management staff, he was responsible for coordinating hp™s global research and development, directing central research, and acting as the company™s chief technical ofcer. he is a fellow of the institute of electrical and electronics engineers (ieee), the acm, and the california council on science and technology, and a foreign member of the royal academy of engineering. he holds a bachelor™s degree in engineering physics from cornell university and master™s and doctoral degrees in nuclear physics from yale university. he has been granted an honorary doctorate by the technion university of israel. dr. birnbaum is a member of the national academy of engineering.anjan bose is dean of the college of engineering and architecture and distinguished professor of electric power engineering at washington state university. he has served as an engineer and manager in industry and as chair and then dean at washington state university. he also served as the program manager in the engineering division of the national science foundation (nsf) for a year. dr. bose is a researcher in the operation and control of power grids, and his methods and software are widely used in grid control centers around the world. he received the third millennium medal and the outstanding power engineering educator toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.254 toward a safer and more secure cyberspaceaward from the ieee. he serves on the board of directors of the governorappointed washington technology council (vicechair since 2000) and the indian institute of technology foundation. he served on the committee appointed by the secretary of energy to study electric power blackouts. dr. bose is the author or coauthor of more than 75 journal articles and book chapters and has served on the editorial board of several ieee publications. he is active on several national and international technical committees in the eld of electric power engineering. dr. bose is a fellow of the ieee. he received a b.s.e.e. degree from the indian institute of technology, kharagpur (1967); an m.s.e.e. from the university of california, berkeley (1968); and a ph.d.e.e. from iowa state university (1974). he is a member of the nae.barbara fraser is a senior consulting engineer in the technology policy and consulting engineering organization for cisco systems, inc., and is responsible for in˚uencing the security features and characteristics of the company™s products. her primary goal is to help cisco develop and implement a coherent, achievable network security strategy for all cisco products. ms. fraser™s current activities and interests include improving internet protocol security (ipsec) protocols, increasing security in internet operating systems (ios) software, and improving security testing in cisco™s overall engineering development processes. she participates in cisco™s ipsec steering group and is also an adviser to cisco™s product security incident response team (psirt). ms. fraser is an active member of the internet engineering task force where she cochairs the ipsec working group. she was editor of the site security handbook, and has contributed to a number of other request for comments (rfcs). she has been a delegate to the g8 cybercrime workshops around the world and was also a trustee of the internet society. for 10 years prior to joining cisco, ms. fraser was a senior member of the technical staff at the software engineering institute (sei), located at carnegie mellon university. she was one of the early members of the computer emergency response team (cert) coordination center (cert/cc). while at the sei, she led a team that designed and developed a security assessment method and supporting tools, and performed eld assessments at major nancial institutions, technology producer corporations, and government agencies and organizations. ms. fraser earned a b.s. degree in biology at florida state university and an m.s. in computer science from the university of central florida.james gosler is a sandia fellow for information operations studies. he was commissioned in the u.s. navy in 1975, and following his activeduty service he became a member of the technical staff at the sandia national toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix a 255laboratories. early contributions included establishing a performance modeling/simulation program in the dataprocessing operating systems design area and the development of attack methodologies for both cryptographic and nuclear weaponsystems in the adversarial analysis group. in 1989 mr. gosler became sandia™s rst visiting scientist to the national security agency, where he consulted on computer security concerns  and established and chaired key information security and technology (infosec)related working groups. in 1996 mr. gosler entered the senior intelligence service at the central intelligence agency as the rst director of the clandestine information technology ofce. in 2001 he returned to sandia as a senior scientist; there he supports national information operations, information assurance, critical infrastructure, and terrorism initiatives. he has completed numerous professional courses and schools, including the national senior cryptologic course, the national senior intelligence course, harvard™s program for senior executives in national and international security, and the intelligence fellows program. mr. gosler received a b.s. degree in physics and mathematics and an m.s. in mathematics.william guttman is a distinguished service professor of economics and technology at the h. john heinz iii school of public policy and management at carnegie mellon university. he was also part of the founding group of carnegie mellon™s cylab, one of the world™s largest universitybased research initiatives focused on dependability and security in software and networked systems, where he serves as cochairman of the operations committee and director of cylab™s sustainable computing consortium. he previously directed the sloan software industry center at carnegie mellon. dr. guttman™s teaching and research interests include international economic policy as well as competition, innovation, and public policy in the global software industry. earlier in his career, he served in various advisory capacities at the u.s. department of state, the world bank, the international monetary fund, and the organisation for economic cooperation and development (oecd). he is the author of several issued and pending software patents and has written two books on economic policy, among many other academic writings. after receiving a b.a. degree from the university of california, los angeles, he was a british council scholar and received his master™s and doctoral degrees from balliol college, oxford university.ruby b. lee is the forrest g. hamrick professor of engineering and professor of electrical engineering at princeton university, with an afliated appointment in the computer science department. she is the director of the princeton architecture laboratory for multimedia and security toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.256 toward a safer and more secure cyberspace(palms). her current research is in building security into core computer architecture, protecting critical information, providing hardware ﬁsafetynetsﬂ for software vulnerabilities, mitigating information leaks boosted by modern microprocessor architecture features, and designing innovative instructionset architecture to accelerate software cryptography and cryptanalysis. she is a fellow of the acm, a fellow of the ieee, associate editorinchief of ieee micro, and an editorial board member of ieee security and privacy. prior to joining the princeton faculty in 1998, dr. lee served as chief architect at hewlettpackard, responsible at different times for processor architecture, multimedia architecture, and security architecture. she was a key architect of the precision architectureœreduced instruction set computers (parisc) architecture used for hp workstations and servers. she pioneered adding multimedia instructions to microprocessors, facilitating ubiquitous and pervasive multimedia. she coled an intelhp architecture team designing new instruction set architecture for multimedia and data parallelism for 64bit intel microprocessors. simultaneous with her fulltime hp tenure, dr. lee was also consulting professor of electrical engineering at stanford university. she has a ph.d. degree in electrical engineering and an m.s. in computer science, both from stanford university, and an a.b. with distinction from cornell university, where she was a college scholar. she has been granted more than 115 u.s. and international patents and has authored numerous conference and journal papers on computer architecture, multimedia, and security topics.fernando (fred) luiz was most recently division general manager with the hewlettpackard company before retiring in 2002. during a 17year career, he was a member of the research staff working on the rst commercial risc system at hp labs; r&d laboratory director; and director of the distributed systems architecture laboratory. he was also division general manager for hp™s unix software systems and division general manager for enterprise security. he was also chief input/output (i/o) architect for hp™s parisc computer line and a senior technical strategist within hp. from 1987 to 1991, he was with rolm corporation, working on the architecture and design of computer integrated telephony systems with interests in the integration of automated and interactive voice sequences into complex and distributed transaction systems. prior to working at hp, mr. luiz was with ibm corporation for 20 years, as a lead engineer for ibm i/o for disk drives, design and development engineer, principal architect at storage technology, and system and eld engineer. he has obtained 10 u.s. patents and several foreign patents. mr. luiz has an m.s.e.e. degree, with graduate studies in software tools, communication networks, and business administration and management.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix a 257teresa f. lunt is principal scientist and area manager of the security group and area manager of the theory group at xerox palo alto research center (parc), where she heads a project to develop technologies to protect privacy in terroristtracking applications. previously she was assistant director for distributed systems in the information technology ofce of the defense advanced research projects agency (darpa), as well as program manager of darpa™s information survivability program, where she launched a series of darpafunded security programs that continue today. at sri international, ms. lunt led the development of the seaview multilevel secure database system, the nextgeneration intrusion detection expert systems (nides) intrusiondetection system, and the dissect tool to detect inferences of highly sensitive information from less sensitive information. she received an a.b. degree from princeton university (1976) and an m.a. in applied mathematics from indiana university (1979). she is a member of the current nrc panel on survivability and lethality analysis and a former member of the nrc committee on networkcentral naval forces.peter g. neumann is principal scientist with stanford research institute (sri) international™s computer science laboratory. he was at bell laboratories in murray hill, n.j., in the 1960s, during which time he was heavily involved in the muliplexed information and computing services (multics) development jointly with the massachusetts institute of technology and honeywell international, inc. he is concerned with computer systems and networks, security, reliability, survivability, safety, and many riskrelated issues such as votingsystem integrity, crypto policy, social implications, and human needs including privacy. he moderates the acm risks forum, edits the monthly ﬁinside risksﬂ column in communications of the acm, chairs the acm committee on computers and public policy, cofounded people for internet responsibility, and cofounded the union for representative international internet cooperation and analysis. he is a fellow of the acm, ieee, american association for the advancement of science (aaas), and sri. he has taught at stanford university; the university of california, berkeley; and the university of maryland. he received a.b., s.m., and ph.d. degrees from harvard university (1954, 1955, and 1961, respectively); he also holds a doctorate from darmstadt. dr. neumann was a member of the cstb committees that produced the nrc reports cryptography™s role in securing the information society (1996) and computers at risk: safe computing in the information age (1991).stefan savage is an assistant professor in the department of computer science and engineering at the university of california, san diego. his current research interests focus on largescale network security, wireless toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.258 toward a safer and more secure cyberspacenetworking, and selfmanaging distributed systems. previously he has worked broadly in the eld of experimental computer systems, including research on widearea networking, realtime scheduling, operating system construction, disk array design, concurrency control, and performance analysis. he recently served as coorganizer of the 2003 center for discrete mathematics and theoretical computer science (dimacs) workshop on largescale internet attacks, as founding program chair of the acm workshop on rapid malcode (worm), and as founding program cochair of the acm/usenix symposium on networked systems design and implementation (nsdi). professor savage holds a b.s. degree in applied history from carnegie mellon university (1991) and a ph.d. in computer science and engineering from the university of washington (2002).william l. scherlis is a professor in the school of computer science at carnegie mellon university (cmu), a member of cmu™s international software research institute, and the founding director of cmu™s ph.d. program in software engineering. he is principal investigator of the  5year high dependability computing project with nasa. his research relates to software evolution, software assurance, and collaboration technology. he served 6 years at darpa, with responsibilities including research and strategy in computer security, highperformance computing, and information infrastructure, before departing in 1993 as senior executive responsible for coordination of software research. he has served as program chair for a number of technical conferences and has more than  70 scientic publications. he holds an a.b. degree from harvard university and a ph.d. in computer science from stanford university. he chaired the cstb committee that produced the nrc report information technology research, innovation, and egovernment (2002) and its two workshop summaries.fred b. schneider is a professor in the department of computer science and director of the information assurance institute at cornell university. dr. schneider™s research is intended to support the construction of concurrent and distributed systems for highintegrity and missioncritical settings. he is coauthor, with david gries, of the introductory text a logical approach to discrete math (springerverlag, 1997) and author of the monograph on concurrent programming (springerverlag, 1997). a member of the editorial board for ieee transactions on dependable and secure computing, dr. schneider is also associate editorinchief for ieee security and privacy magazine and comanaging editor for springerverlag texts and monographs in computer science. he was a member of the 1995 darpa/innovative space based radar antenna technology (isat) study on defensive information warfare. he currently serves on the nsf comtoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix a 259puter and information science and engineering (cise) advisory board and the grifs institute™s board of directors. a consultant to industry, dr. schneider serves on technical advisory boards for cigital, inc., fortify software, intel corporation, microsoft corporation, and packet general networks; he also serves as a consultant to darpa and in a senior technical advisory position with fast search and transfer asa (ﬁfastﬂ) on matters of reliability and security. he is a fellow of the acm and aaas and the recipient of a doctor of science [honoris causa] degree from the university of newcastleupontyne (2003). dr. schneider holds a b.s. degree from cornell university (1975) and a ph.d. from the state university of new york, stony brook (1978). he is a current board member of cstb and chaired the cstb committee that produced the nrc report trust in cyberspace (1999).alfred z. spector is currently a technology consultant and was recently vice president of strategy and technology for ibm™s software business, responsible for technical and business strategy, various technical and business initiatives, standards, and software engineering across the worldwide software group. prior to that, he was vice president of services and software in ibm research, responsible for ibm™s worldwide services and software research. before that, dr. spector was the general manager of marketing and strategy for ibm™s aim business, with responsibility for a number of ibm software product families including customer information control system, websphere, and mqseries, and the general manager of ibm™s transaction systems software business. dr. spector was also founder and ceo of transarc corporation, a pioneer in distributed transaction processing and widearea le systems, and an associate professor of computer science at carnegie mellon university. he is a member of the computer science and telecommunications board of the national research council. he remains active in the eld of distributed computing, but his interests have inevitably broadened due to his recent job assignments. dr. spector received his ph.d. in computer science from stanford university and his a.b. in applied mathematics from harvard university. he is a member of the national academy of engineering, a fellow of the ieee and acm, and the recipient of the 2001 ieee computer society™s tsutomu kanai award for major contributions to stateoftheart distributed computing systems and their applications. john wankmueller is vice president for electronic security and technology at mastercard international. he is responsible for the global security architecture and technologies used in emerging channels and mastercard™s electronic commerce infrastructure. mr. wankmueller is currently working on the security infrastructure for payments involving consumertoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.260 toward a safer and more secure cyberspaceowned mobile devices as well as biometric verication methods. previously he worked on the design and development of the secure electronic transaction (set) specication jointly created by mastercard, visa, ibm, microsoft, gte, and others. mr. wankmueller helped develop mastercard™s integrated chip (smart) card business plan to migrate mastercard products to integrated circuit (ic) chip technology. he also originated mastercard™s rst centralized neural network fraud detection technology project. in 1994 he initiated mastercard™s efforts to create a secure payment standard over open networks like the internet. prior to joining mastercard, mr. wankmueller was a staff member in at&t™s research and development area. he holds a bachelor™s degree in mathematics from fordham university new york and a master™s degree from new york university.jay warrior leads distributed systems research at agilent laboratories. he has more than 15 years of experience creating new networkingtechnologybased business opportunities for honeywell, fisher rosemount systems, and hp/agilent. he has led multiple efforts in networking standards setting and currently chairs the ieee standards working group that developed ieee 1451.1, a u.s. standard for networkindependent interfaces for smart sensors to enable easy support of multiple communication protocols within products. in 1999 he received the ieee standards association award for his efforts. at hp and agilent laboratories, dr. warrior led the team that developed an internetbased distributed system technology that was incorporated into two cellular infrastructure monitoring product lines. he was a laboratory scientist and program manager in the distributed measurement and control program at hewlettpackard laboratories. dr. warrior recently cofounded sensor networking applications and technology forum (snafunet) and established java distributed data acquisition and control (jddac), a joint effort between agilent laboratories and sun microsystems creating open source java technology for sensor networks.staff membersherbert s. lin is senior scientist and senior staff ofcer at the computer science and telecommunications board, national research council of the national academies, where he has been study director of major projects on public policy and information technology. these studies include a 1996 study on national cryptography policy (cryptography™s role in securing the information society); a 1992 study on the future of computer science (computing the future: a broader agenda for computer science and engineering); a 1999 study of the u.s. department of defense systems for command, toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix a 261control, communications, computing, and intelligence (realizing the potential of c4i: fundamental challenges); a 2001 study on workforce issues in high technology (building a workforce for the information economy); and a 2002 study on protecting children from internet pornography and sexual exploitation (youth, pornography, and the internet). prior to his nrc service, he was a professional staff member and staff scientist for the house armed services committee (19861990), where his portfolio included defense policy and arms control issues. he also has signicant expertise in mathematics and science education. he received his doctorate in physics from the massachusetts institute of technology (mit).kristen batch is an associate program ofcer with the nrc™s computer science and telecommunications board. she is currently involved with several projects focusing on emerging wireless technology and spectrum policy, biometrics technologies, and privacy in the information age. while pursuing an m.a. in international communications from american university, she interned at the national telecommunications and information administration, in the ofce of international affairs, and at the center for strategic and international studies, in the technology and public policy program. she also earned a b.a. degree in literary and cultural studies and spanish from carnegie mellon university and received two travel grants to conduct independent research in spain.jennifer m. bishop, program associate, began working with the nrc™s computer science and telecommunications board in 2001. she was involved in several studies, including those on telecommunications research and development, policy consequences and legal/ethical implications of offensive information warfare, and assessing the information technology research and development ecosystem. she also maintained cstb™s databases, managed the cstb web site, produced update, the cstb newsletter, and designed book covers and promotional materials. prior to joining cstb, ms. bishop worked for the city of ithaca, new york, coordinating the police department™s transition to a new structured query language (sql)based time accrual and scheduling application, a project that grew out of her experience maintaining the police records databases. her other work experience includes designing customized hospitality industry performance reports for smith travel research, and freelance publication design. she is interested in the social and cultural impacts of information technology, including researching and developing effective information design for education and lifelong learning. in her spare time, ms. bishop is a visual artist working in oil and mixed media. she holds a b.f.a. degree from cornell university™s college of architecture, art, and planning.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.262 toward a safer and more secure cyberspacecharles n. brownstein was the director of the nrc™s computer science and telecommunications board from january 2004 to september 2005. he joined the nrc in 2004 from the corporation for national research initiatives (cnri), where from 1994 to 2004 he directed the cross industry working team and did independent research with support from nsf and darpa. his interests are in innovation, applications, and impacts of information technology, internet performance, and the technologypolicy interface. dr. brownstein joined cnri in 1994 after a 20year career at nsf. there he served in positions including program director for telecommunications policy and it applications, division director for information science and technology, deputy assistant director and assistant director of nsf for cise, and director of the ofce of planning and assessment. his federal achievements are recognized by presidential meritorious and distinguished senior executive service awards and by nsf™s distinguished service award.janice m. sabuda is a senior program assistant at the nrc™s computer science and telecommunications board. she currently supports all cstb activities and is involved in several studies, including improving cybersecurity research in the united states, information technology and the states: public policy and public interests, planning meeting on fundamental research challenges in computer graphics, privacy in the information age, and radio frequency identication (rfid) technologies: a workshop. previously, she focused on the congressionally requested study that resulted in youth, pornography, and the internet (2002) and the project that resulted in global networks and local values (2001). prior to joining the cstb in august 2001, ms. sabuda worked as a customer service representative at an online fundraising company and as a client services analyst at a prospect research rm. she is currently pursuing a certicate in event management from the george washington university center for professional development. she received her b.s. (1999) in business administration from the state university of new york college at fredonia.ted schmitt is a program ofcer for the nrc™s computer science and telecommunications board. he is currently involved in the cstb projects providing a comprehensive exploration of cybersecurity and the use of it to enhance disaster management. before joining cstb, mr. schmitt was involved in the development of the digital publishing industry and played an active role in various related standards groups. prior to that, he served as technical director at a number of small technology companies in germany, sweden, and the united states. he started his career in 1984 as a software engineer for ibm, earning two patents and several technitoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix a 263cal achievement awards. mr. schmitt received an m.a. in international science and technology policy from george washington university. he received a b.s. degree in electrical engineering in 1984 and a b.a. in german in 1997 from purdue university, and studied at the universität hamburg, germany.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.264b.1 introductionsince september 11, 2001, many cybersecurity activities have been undertaken by the federal government,1 the research community, and private industry. this appendix reviews these activities, providing a snapshot of the efforts undertaken to address cybersecurity concerns over the past several years. specically, federal cybersecurity policy activity since 2001 is reviewed. a number of federal government reports that detail cybersecurity risks and challenges that need to be overcome are summarized. also summarized are best practices and procedures, as well as options for making progress, as identied in these reports. efforts for improving publicprivate collaboration and coordination are identied. reports aimed at elaborating the necessary elements of a research agenda are also reviewed. the nal section reviews the current federal research and development (r&d) landscape and describes the particular focus and the types of support being provided at various federal agencies with cybersecurity responsibilities.several general impressions about the state of cybersecurity and some common themes about the type of actions required to improve it can be drawn from the various activities summarized here. first, there are 1 the congressional research service issued the report computer security: a summary of selected federal laws, executive orders, and presidential directives on april 16, 2004; the report outlines the major roles and responsibilities assigned various federal agencies in the area of computer security. see http://www.fas.org/irp/crs/rl32357.pdf.appendix bcybersecurity reports and policy:the recent pasttoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 265no ﬁsilver bulletsﬂ for xing cybersecurity. the threats are evolving and will continue to grow, meaning that gaining ground against these threats requires an ongoing, societywide, concerted and focused effort. a culture of security must pervade the entire life cycle of information technology (it) system operations, from initial architecture, to design, development, testing, deployment, maintenance, and use. a number of focus areas are particularly important to achieving such a culture: collaboration among researchers; coordination and information sharing among the public and private sectors; the creation of a sufciently large and capable core of research specialists to advance the state of the art; the broadbased education of developers, administrators, and users that will make securityconscious practices become second nature just as optimizing for performance or functionality is; making it easy and intuitive for users to ﬁdo the right thingﬂ; the employment of business drivers and policy mechanisms to facilitate security technology transfer and the diffusion of r&d into commercial products and services; the promotion of riskbased decision making (and metrics to support this effort). second, several areas for research focus (or areas to support such research), consistent with those identied in this report, are identied across nearly all of the activities summarized in this appendix. these areas are authentication, identity management, secure software engineering, modeling and testbeds, usability, privacy, and benchmarking and best practices. understanding the intersection between critical infrastructure systems and the it systems increasingly used to control them is another common theme for research needs. finally, taken together, the activities reviewed give an overall sense thatšunless we as a society make cybersecurity a priorityšit systems are likely to become overwhelmed by cyberthreats of all kinds and eventually to be limited in their ability to transform societal systems productively. this future is avoidable, but avoiding it requires the effective coordination and collaboration of private and public sectors; continuous, comprehensive, and coordinated research; and appropriate policies to promote security and to deter attackers. given the global nature of cyberthreats, it also requires effective international cooperation. this survey does not focus on activity under way that aims to further international cooperation. however, considerable efforts are under way at the regional intergovernmental and international governmental levels.22 see, for example, delphine nain, neal donaghy, and seymour goodman, ﬁthe international landscape of cyber security,ﬂ chapter 9 in detmar w. straub, seymour goodman, and richard baskerville (eds.), information security: policies, processes, and practices, m.e. sharpe, new york, forthcoming 2008.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.266 toward a safer and more secure cyberspaceb.2 cybersecurity policy activity since 2001the u.s. congress passed the cybersecurity research and development act3 in november 2002. section 2(2) of the act noted the ubiquitous and pervasive nature of information and communications technology, stating that revolutionary advancements in computing and communications technology have interconnected critical infrastructures ﬁin a vast, interdependent physical and electronic network.ﬂ section 2(2) pointed to the increased societal dependence on that infrastructure, stating that ﬁexponential increases in interconnectivity have facilitated enhanced communications, economic growth, and the delivery of services critical to the public welfare, but have also increased the consequences of temporary or prolonged failure.ﬂ section 2(4) found that that computer security technology and systems implementation lack the following:sufcient longterm research funding;adequate coordination across federal and state government agencies and among government, academia, and industry; and sufcient numbers of outstanding researchers in the eld.the cybersecurity research and development act of 2002 called for signicantly increasing federal investment in computer and network security research and development to improve vulnerability assessment and technological and systems solutions, to expand and improve the pool of information security professionals, and to improve information sharing and collaboration among industry, government, and academic research projects. the national science foundation (nsf) and the national institute of standards and technology (nist) are called on to create programs necessary to address these issues. the act authorized appropriations for both agencies to support the specied programs, though appropriations were never made to match authorized levels.the bush administration noted its support for the legislation as it was developed,4 and issued the national strategy to secure cyberspace5 in february 2003. the report noted that securing cyberspace is a difcult strategic challenge and emphasized the need for a coordinated and focused effort, taking in federal, state, and local governments, the private sector, and individual americans. it calls on the newly formed department of 3 cybersecurity research and development act of 2002, p.l. no. 107305.4 ofce of management and budget, h.r. 3394šcyber security research and development act, february 5, 2002; available at http://www.whitehouse.gov/omb/legislative/sap/1072/ hr3394r.html. 5 the white house, the national strategy to secure cyberspace, february 2003; available at http://www.whitehouse.gov/pcipb/cyberspacestrategy.pdf. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 267homeland security (dhs) to take the leadership role and become the federal center of excellence in addressing the ve priorities it identied for cyberspace security: a national response system, a threat and vulnerability reduction program, awareness and training programs, the securing of governmentadministered systems, and international cooperation. research and development for cybersecurity are not heavily emphasized in the report, and the roles of nsf and nist are not mentioned.the federal information security management act of 2002 (fisma) established a ﬁcomprehensive framework for ensuring the effectiveness of information security controls over information resources that support federal operations and assets.ﬂ6 nist was designated as the agency responsible for setting guidelines and procedures to be met by all federal agencies with regard to securing their information systems.the national infrastructure advisory council (niac) was created by executive order in october 2001 to make recommendations to the president regarding the security of cyber and information systems of the u.s. national security and economic critical infrastructures. niac became part of dhs in february 2003 under executive order 13286.7 the council is chartered to examine ways that partnerships between the public and private sectors can be enhanced to improve cybersecurity.8 members of niac represent major sectors of the economyšbanking and nance, transportation, energy, information technology, and manufacturing. the council also includes representatives from academia, state and local governments, and law enforcement. it is intended that niac work closely with the president™s national security and telecommunications advisory committee (nstac). homeland security presidential directive 7 (hspd7): ﬁcritical infrastructure identication, prioritization, and protection,ﬂ issued in december 2003, aims to establish ﬁa national policy for federal departments and agencies to identify and prioritize united states critical infrastructure and key resources and to protect them from terrorist attack.ﬂ9 the directive makes dhs responsible for coordinating overall efforts aimed at enhancing and protecting critical infrastructure, including cyber infrastructure. as part of that responsibility, dhs is required to create a national plan for 6 federal information security management act of 2002, sec. 301 of the egovernment act of 2002, p.l. no. 107347. 7 see http://www.fas.org/irp/offdocs/eo/eo13286.htm.8 u.s. department of homeland security (dhs), charter of the national infrastructure advisory council, july 1, 2005; available at http://www.dhs.gov/interweb/assetlibrary/niaccharter.pdf. 9 homeland security presidential directive 7 (hspd7), ﬁcritical infrastructure identication, prioritization, and protectionﬂ; available at http://www.whitehouse.gov/news/releases/2003/ 12/200312175.html.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.268 toward a safer and more secure cyberspacecritical infrastructure protection. the department is directed to work with the ofce of science and technology policy (ostp) to coordinate interagency r&d for enhancing critical infrastructure. dhs is also required to develop an annual r&d development plan jointly with ostp.dhs issued the national infrastructure protection plan (nipp) in june 2006, as required by hspd7; the plan provides ﬁan integrated, comprehensive approach to addressing physical, cyber, and human threats and vulnerabilities to address the full range of risks to the nation.ﬂ10 the nipp provides the framework and sets the direction for implementing this protecting of critical infrastructure. the plan is meant to provide a roadmap for identifying assets, assessing vulnerabilities, prioritizing assets, and implementing protection measures in each infrastructure sector. the nipp delineates roles and responsibilities among all stakeholders. it is part of dhs™s effort to take a leadership role and act as the federal center of excellence concerning infrastructure protection. in addition, each sector has developed a critical information/key resources sector specic plan (ssp). the ssps were published in may 2007. dhs is the lead agency for the development of the it and communications ssps, and there is a cyber component to each of the remaining 15 ssps.the national plan for research and development in support of critical infrastructure protection,11 issued jointly by dhs and ostp in april 2005, specically addresses r&d not covered in the february 2005 interim nipp. it is required to be updated annually, as specied in hspd7. the plan notes, in this initial version, a focus on (1) creating a baseline, including the identication of existing major r&d efforts within federal agencies, and (2) highlighting longterm goals of federal r&d for critical infrastructure. it identies nine themes that encompass both cyber and physical concerns: detection and sensor systems; protection and prevention; entry and access portals; insider threats; analysis and decisionsupport systems; response, recovery, and reconstitution; new and emerging threats and vulnerabilities; advanced infrastructure architectures and systems design; and human and social issues.the plan provides examples of federal agency efforts already under way or that are part of nearterm planning for each of the nine themes. priority focus areas for each theme are also specied. three longterm strategic goals are identied:10 see http://www.deq.state.mi.us/documents/deqwbwwsinterimnipp.pdf. 11 department of homeland security and ofce of science and technology policy, ﬁthe national plan for research and development in support of critical infrastructure protection,ﬂ 2005; available at http://www.dhs.gov/interweb/assetlibrary/st2004nciprdplan finalapr05.pdf. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 269a national common operating picture for critical infrastructure,a nextgeneration computing and communications network with security ﬁdesignedinﬂ and inherent in all elements rather than added after the fact, andresilient, selfdiagnosing, and selfhealing physical and cyber infrastructure systems. the plan states that future versions will ﬁmore strongly integrate both technical and budgetary aspects of r&d effortsﬂ and provide all stakeholders with information about progress toward solutions, alignment of efforts to meet evolving threats, and discovery of needs and vulnerability gaps.the energy policy act of 200512 addresses the need for cybersecurity standards to protect the energy infrastructure. it includes a requirement that the federal energy regulatory commission (ferc) establish an electric reliability organization (ero) to establish and enforce reliability standards for the reliable operation of existing bulkpower system facilities, where ﬁreliable operationﬂ is understood to mean prevention of instability, uncontrolled separation, or cascading failures of bulkpower systems as a result of a sudden disturbance, including a cybersecurity incident. the north american electric reliability corporation (nerc)ša voluntary industry group composed of electrical utilitiesšwhich sought the provisions specied in the act, was certied by the ferc as the ero on july 20, 2006.13 b.3 identifying exposures, best practices, and proceduresa number of recent reports have addressed continuing cybersecurity exposures of critical infrastructures. collectively, they identify the nature of the exposures as well as a number of challenges that must be overcome to address them. several of the reports make recommendations regarding best practices and procedures necessary to reduce the risks from cyberattacks. more generally, they recommend that available cybersecurity technology be more systematically adopted throughout existing critical infrastructure systems.12 the energy policy act of 2005, p.l. no. 109058; sec. 1211, ﬁelectric reliability standards,ﬂ contains the passages relevant to cybersecurity.13 federal energy regulatory commission, ﬁorder certifying north american electric reliability corporation as the electric reliability organization and ordering compliance filing,ﬂ july 20, 2006; available at ftp://www.nerc.com/pub/sys/allupdl/docs/ferc/ 20060720erocertication.pdf. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.270 toward a safer and more secure cyberspacein march 2004 the u.s. general accounting ofce (gao) issued critical infrastructure protection: challenges and efforts to secure control system.14 gao undertook the study resulting in the report at the request of the house committee on government reform and its subcommittee on technology, information policy, intergovernmental relations and the census. the committee and subcommittee had asked gao to report on potential cyber vulnerabilities, focusing on signicant cybersecurity risks associated with control systems, potential and reported cyberattacks against these systems, key challenges to securing control systems, and efforts to strengthen the cybersecurity of control systems. the gao report found that several factors have contributed to the escalation of the risks of cyberattacks against control systems, including the adoption of standardized technologies with known vulnerabilities, the connectivity of control systems with other networks, insecure remote connections, and the widespread availability of technical information about control systems. it also found that securing control systems poses signicant challenges. these include ﬁthe limitations of current security technologies in securing control systems, the perception that securing control systems may not be economically justiable and con˚icting priorities within organizations regarding the security of control systems.ﬂ the gao report identies the need for greater collaboration and coordination among government agencies and with the private sector. it recommends that dhs implement the responsibilities outlined in the national strategy to secure cyberspace, specically calling on dhs to ﬁdevelop and implement a strategy for coordinating with the private sector and other government agencies to improve control system security, including an approach for coordinating the various ongoing efforts to secure control systems.ﬂ15 in april 2004 niac issued the report best practices for government to enhance the security of national critical infrastructures.16 the report notes how much convergence there is between physical and information infrastructures and indicates the need to view security as including both physical and cyber issues. the niac report concludes that, while market forces are the most powerful drivers of change, government intervention can be appropriate and benecial in certain areas. it focuses on four infrastructure sectors and nds that a deep understanding of sector dynamics is critical for effective government intervention.14 see http://www.gao.gov/new.items/d04354.pdf. 15 see http://www.gao.gov/new.items/d04354.pdf.16see http://www.dhs.gov/interweb/assetlibrary/niacbestpracticessecurityinfra structures0404.pdf. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 271also in april 2004, the u.s.canada power system outage task force issued its final report on the august 14, 2003 blackout in the u.s. and canada.17 the report found that, while the blackout was not caused by a cyberattack, the potential opportunity exists for cyber compromise of the energy management system (ems) and supporting information technology infrastructure. it also noted that a failure in a software program not linked to malicious activity may have signicantly contributed to the power outage. in all, the task force report made 15 recommendations related to the cybersecurity aspects of protecting the ems. it called for the following: cybersecurity management standards and procedures, planned and documented corporatelevel security governance and strategies, implementation of detection controls, improvement of diagnostic and forensic capabilities, scheduled risk and vulnerability assessments, a central point for sharing security information, the establishment of clear authority to in˚uence corporate decision making, and procedures to prevent or mitigate inappropriate disclosure of information. in may 2004, the gao issued its second study, technology assessment: cybersecurity for critical infrastructure protection, in which it found that available cybersecurity technologies were not being deployed to their full extent, while continued r&d was needed for additional technology. the report identied three broad categories of actions that the federal government can undertake to increase the use of cybersecurity technologies:18help critical infrastructures determine their cybersecurity needs, such as developing a national critical infrastructure protection (cip) plan, assisting with risk assessments, and enhancing cybersecurity awareness;take actions to protect its own systems, which could lead others to emulate it or could lead to the development and availability of more cybersecurity technology products; andundertake longterm activities to increase the quality and availability of cybersecurity technologies in the marketplace.17 available at https://reports.energy.gov/blackoutfinalweb.pdf; see chapter 9 beginning at p. 131 for a discussion of the cybersecurity aspects of the blackout. 18 see http://www.gao.gov/new.items/d04321.pdf. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.272 toward a safer and more secure cyberspacethe may 2004 gao report found a number of cybersecurity research areas in need of continuing attention, including the composition of secure systems, the security of networkembedded systems, security metrics, the socioeconomic impact of security, vulnerability identication and analysis, and wireless security. it also notes that federal cybersecurity research programs are already beginning to address these research areas.in january 2005 nist issued a detailed report entitled security considerations for voice over ip systems: recommendations of the national institute of standards and technology19 that made nine recommendations for providing secure voiceoverinternet protocol (voip) services, noting that voip introduces potential new cybersecurity risks. the recommendations include the development of appropriate network architecture and the importance of physical controls in preventing unauthorized access to information.a report from the environmental protection agency™s (epa™s) ofce of the inspector generalšepa needs to determine what barriers prevent water systems from securing known supervisory control and data acquisition (scada) vulnerabilitiesšissued january 2005, identied several reasons why vulnerabilities have not been addressed:20 current technological limitations may impede implementing security measures.companies may not be able to afford or justify the required investment.utilities may not be able to conduct background checks on existing employees.ofcials may not permit scada penetration testing.technical engineers may have difculty communicating security needs to management.this report from epa™s ofce of the inspector general recommended that the epa notify dhs and congress of problems for which it found no apparent solutions.the congressional research service (crs) report creating a national framework for cybersecurity: an analysis of issues and options, issued in february 2005, states that ﬁdespite increasing attention from federal and state governments and international organizations, the defense against attacks on these systems has appeared to be generally fragmented and varying widely in effectiveness. concerns have grown that what is needed is a national cybersecurity frameworkša coordinated, coherent set of 19 see http://csrc.nist.gov/publications/nistpubs/80058/sp80058nal.pdf. 20 see http://www.epa.gov/oig/reports/2005/200501062005p00002.pdf. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 273public and privatesector efforts required to ensure an acceptable level of cybersecurity for the nation.ﬂ21 the crs report identies various approaches taken, all of which are recommended by one or more of the reports described in this section. these include adopting standards and certication, promulgating best practices and guidelines, using benchmarks and checklists, using auditing, improving training and education, building security into enterprise architecture, using risk management, and employing metrics. it notes that ﬁnone of them are likely to be widely adopted in the absence of sufcient economic incentives for cybersecurity.ﬂ the crs report also notes concerns about the effectiveness of market forces to provide adequate cybersecurity and the narrow scope of the policy activity in contrast with the apparent need for broad policy actions as called for in the 2003 national strategy to secure cyberspace and similar documents. it also identies the response to the year2000 computer problem and federal safety and environmental regulations as models for possible federal action to promote cybersecurity, and further notes that the federal government might do the following: encourage the widespread adoption of cybersecurity standards and best practices,leverage the procurement power of the federal government,make the reporting of incidents mandatory,use product liability actions to promote attention to cybersecurity,facilitate the development of cybersecurity insurance, and strengthen federal cybersecurity programs in dhs and elsewhere.released in may 2005, the gao report critical infrastructure protection: department of homeland security faces challenges in fullling cybersecurity responsibilities notes that dhs has become the focal point for critical infrastructure protection. the report identies 13 responsibilities that dhs has regarding cybersecurity. it states that ﬁwhile dhs has initiated multiple efforts, it has not fully addressed any of the 13 key cybersecurityrelated responsibilities that we [gao] identied in federal law and policy, and it has much work ahead in order to be able to fully address them.ﬂ it states that the interim national infrastructure protection plan is one of several efforts that dhs has undertaken to address its responsibilities for cybersecurity, but notes that dhs has not undertaken a number of critical activities. it cites several organizational barriers and underlying challenges that dhs will need to overcome to assume the key role envi21 see http://www.law.umaryland.edu/marshall/crsreports/crsdocuments/rl327770 2222005.pdf. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.274 toward a safer and more secure cyberspacesioned for it in strengthening the cybersecurity of critical infrastructures and serving as the strong cybersecurity focal point envisioned in federal law and policy.22 in september 2006, the gao report coordination of federal cyber security research and development sought to identify the federal entities involved in cybersecurity r&d; actions taken to improve oversight and coordination of federal cybersecurity r&d, including the development of a federal research agenda; and methods used for technology transfer at agencies with signicant activities in this area.23 the september 2006 gao report reviews policy actions over the past few years, describes the nature of cybersecurity research support by the various federal agencies, and presents a description of the organization of federal cybersecurity r&d oversight and coordination. it notes several important steps taken by federal agencies to improve the oversight and coordination of federal cybersecurity r&d, including the following: chartering an interagency working group to focus on this type of research, publishing a federal plan for cybersecurity and information assurance research that is to provide baseline information and a framework for planning and conducting this research, separating the reporting of budget information for cybersecurity research from other types of research, and maintaining governmentwide repositories of information on r&d projects. one shortcoming specically identied in this 2006 gao report regarding coordination is the continuing lack of an r&d roadmap called for in the national strategy to secure cyberspace. (a call for input as a rst step to creating such a roadmap was made in april 2006 by the interagency working group on cyber security and information assurance. see section b.5, notable recent efforts at identifying a research agenda, below, for a description of this activity.) overall, the 2006 gao report found that while progress is being made, key elements of the federal research agenda called for in the national strategy to secure cyberspace have yet to be developed. to strengthen federal cybersecurity r&d programs, the 2006 gao report recommends that the ofce of science and technology policy establish rm timelines for the completion of the federal cybersecurity r&d agendašincluding nearterm, midterm, and longterm researchšwith the following elements: timelines and milestones for conducting r&d activities; goals and measures for evaluating r&d activities; assignment of responsibility for implementation, including the accomplishment of the focus areas and suggested research priorities; and the alignment of 22 see gao05434; available at http://www.gao.gov/new.items/d05434.pdf.23 see gao06811; available at http://www.gao.gov/new.items/d06811.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 275funding priorities with technical priorities. the report also recommends that the director of the ofce of management and budget issue guidance to agencies on reporting information about federally funded cybersecurity r&d projects to governmentwide repositories. in the 2006 report from the association of computing machinery (acm) entitled globalization and offshoring of software, chapter 6 focuses on cybersecurity risks and exposures presented as a result of the offshoring of software development. the chapter argues that ﬁoffshoring exacerbates existing risk and introduces new types of risk by opening more opportunities for incursion, accident, or exposure; and it may greatly complicate jurisdictional issues.ﬂ this chapter raises a number of issues that it argues must be dealt with to address these risks and exposures. it concludes that the concerns raised need ﬁnot lead to a wholesale condemnation and rejection of offshoring but rather to the recognition of the inadequate attention so far paid to these risksﬂ and the need for ﬁprudently cautious, thoughtful, and effective practices in preventing and dealing with these risks.ﬂ24b.4 publicprivate collaboration, coordination, and cooperationfederal and state governments have taken steps to secure information systems that they manage. fisma is an example of policy aimed at securing information infrastructure managed by the public sector. yet, dhs estimates that 85 percent of all critical infrastructures are operated by the private sector.25 the national strategy to secure cyberspace identies publicprivate partnership as the cornerstone of securing cyberspace. this emphasis echoes and reinforces that placed on privatesector involvement in presidential decision directive (pdd) 63, the clinton administration™s policy on ﬁcritical infrastructure protection,ﬂ issued in may 1998.26 this section identies steps taken by government and the private sector to actively engage privatesector participation, collaboration, and partnership with the public sector. 24 association of computing machinery, job migration task force, globalization and offshoring of software, 2006, especially pp. 61 through 632; available at http://www.acm.org/globalizationreport.25 department of homeland security, press release, ﬁdhs launches protected critical infrastructure information program to enhance homeland security, facilitate information sharing,ﬂ washington, d.c., february 18, 2004; available at http://www.dhs.gov/xnews/releases/pressrelease0350.shtm.26 presidential decision directive (pdd) 63, ﬁcritical infrastructure protection,ﬂ may 22, 1998; available at http://www.fas.org/irp/offdocs/pdd/pdd63.htm.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.276 toward a safer and more secure cyberspaceb.4.1 information sharing and analysis centerspresidential decision directive 63 created the national infrastructure protection center (nipc). the nipc was intended to serve as a national focal point for gathering information on threats to the infrastructures. pdd 63 further recommended the creation of information sharing and analysis centers (isacs), meant to ﬁserve as the mechanism for gathering, analyzing, appropriately sanitizing and disseminating private sector informationﬂ to both industry and appropriate government agencies.27 pdd 63 recommended that an isac be created for each major infrastructure in the united states. the owners and operators of the infrastructure would determine the design and functions of the center for their sector in consultation with the federal government. the function of the nipc was integrated into the national protection and programs directorate of dhs as a result of the directives of hspd7. several sectorspecic isacs for the chemical industry, electric power, emergency management and response, nancial services, food and agriculture, real estate, state government, surface transportation, telecommunications, and water have been established to allow critical private sectors and infrastructure owners to share information and work with dhs to improve protection of the infrastructure and to coordinate response to threats.the isac council was created in 2003 ﬁto advance the physical and cyber security of the critical infrastructures of north america by establishing and maintaining a framework for valuable interaction between and among the isacs and with government.ﬂ28 a 2004 white paper from the isac council sought to describe the degree of penetration that each isac has had into the infrastructure of the united states.29 the white paper noted that penetration varied widely from sector to sector, with overall participation at approximately 65 percent of the u.s. private infrastructure. it also noted the importance of government funding support to assist isacs in reaching numerous small but critical infrastructure owners who are unable to afford isac membership and the dedication of resources necessary to participate.30b.4.2 alliances and partnershipsin september 2002 the workshop called accelerating trustworthy internetworking (ati) was held to initiate discussion on how to encour27 pdd 63, ﬁannex a. structure and organization.ﬂ28 information sharing and analysis centers (isac) council web site, http://www.isac council.org/about/index.php. 29 isac council, ﬁreach of the major isacs,ﬂ white paper, january 31, 2004; available at http://www.isaccouncil.org/about/index.php.30 isac council, ﬁreach of the major isacs,ﬂ p. 8.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 277age collaborative activities across academia, industry, and government in the emerging interdisciplinary trustworthy internetworking area. ati participants included government agencies, private industry, universities, and nonprot organizations. the goal was to accelerate progress toward highgrade commercial security for internetworking applications.31 a second ati workshop held in january 2004 continued the work of the initial workshop and resulted in the 2004 accelerating trustworthy internetworking workshop report.32 the report notes a number of trends emerging since the 2002 workshop. for example:the critical role of it in infrastructure protection has become clearer and has led to an interest in applications drivers that focus on both critical and pervasive scenarios;the key role of the private sectoršand the importance of relationships among government, universities, industry, and other sectorsšin addressing this challenge has been made more clear;the need for fundamental (not incremental) cybersecurity improvement goals has been recognized, as has the need for a perva sive trustworthy internetworking environment to support critical applications;there is a growing realization that achieving a trustworthy internet for these applications may well require a new paradigm, or architecture; hence the reference to trustworthy internetworking;the recently formed department of homeland security has taken responsibility for cybersecurity, and congress has become increasingly interested in this area; andthe national science foundation and dhs are focusing research resources on cybersecurity.the ati workshop report states that the ﬁfull sustainable potential for scalable and pervasive information technologies cannot be achieved until the architectural framework broadly adopted in pervasive market driven applications, also functions as the underlying framework for critical applications driven by needs of national and domestic security.ﬂ33 it recommended the development of a collaborative research organization based at a consortium of universities to serve as a ﬁsafe place where competing companies can meet with university researchers and set commonalitiesﬂ 31 accelerating trustworthy internetworking (ati) workshop report, september 35, 2002; available at http://www.ati2002.org/.32 accelerating trustworthy internetworking (ati) workshop report, april 2004; available at http://www.gtisc.gatech.edu/2004site/ati2004/atireportfinal42504.pdf.33 ati workshop report, april 2004, p. 1. italics in the original.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.278 toward a safer and more secure cyberspaceand provide a focal point for government involvement. further objectives included building communityshared ﬁroad mapsﬂ to encourage support for research collaboration, pilot projects, testbeds, and testcase sharing. three major industry alliance groups have formed since the release of the 2003 national strategy to secure cyberspace, which emphasized the importance of privatesector participation in improving cybersecurity through the adoption and diffusion of cybersecurity technology. the three groups are the national cyber security partnership (ncsp),34 the trusted computing group (tcg),35 and the cyber security industry alliance (csia).36the ncsp, led by the business software alliance, the information technology association of america, technet, and the u.s. chamber of commerce, was established in 2003 as a publicprivate partnership to develop shared strategies and programs to better secure and enhance america™s critical information infrastructure. ncsp created the following ve task forces composed of cybersecurity experts from industry, academia and government: awareness for home users and small businesses, cybersecurity early warning, corporate governance, security across the software development life cycle, and technical standards and common criteria. each task force produced a report with recommendations for action, published between march and april 2004.37 ncsp notes that ﬁlike most risks in life, cyber security risks can be mitigated, but not completely eliminated. the nature of the threat is constantly evolving. not all companies and institutions will share the same level of commitment to protecting their cyberdependent resources from attack.ﬂ38 it advocates increased spending by government agencies to put in place the appropriate people, processes, and technologies in order to demonstrate leadership in cybersecurity. it says that ﬁattempts by government to legislate or regulate cybersecurity would be counterproductive, creating a least common denominator for cyber security practitioners and doing little to stop those intent on wrongfully hacking into systemsﬂ; it further notes that industry failure to take proactive steps to demonstrate its commitment to and to make substantial improvements in cybersecurity will open the door for greater government involvement. while ncsp states its intent to continue activities for the foreseeable future, no new activity has occurred since the release of the task force reports in 2004.34 information available at http://www.cyberpartnership.org/initgovernance.html.35 information available at https://www.trustedcomputinggroup.org/home.36 information available at https://www.csialliance.org/home. note that this organization is distinct from the interagency working group on cyber security and information assurance, which goes by the same acronym. 37 see http://www.cyberpartnership.org/init.html. 38 see http://www.cyberpartnership.org/aboutfaq.html. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 279also formed in 2003, the trusted computing group is a ﬁnotforprot organization formed to develop, dene, and promote open standards for hardwareenabled trusted computing and security technologies, including hardware building blocks and software interfaces, across multiple platforms, peripherals, and devices.ﬂ39 tcg has more than  135 members, including component vendors, software developers, systems vendors, and network and infrastructure companies. it has issued standards for the trusted platform module (tpm) used in personal computers (pcs) and other systems and a software interface specication to enable application development for systems using the tpm. it has also issued a trusted server specication and trusted network connect specication to enable network protection. tcg continues to be active and is developing specications for storage, peripherals, and mobile devices.the cyber security industry alliance, formed in 2004, is a public policy and advocacy group exclusively focused on cybersecurity policy issues. its membership consists primarily of privatesector information security rms. its mission is to enhance cybersecurity through public policy initiatives, publicsector partnerships, corporate outreach, academic programs, alignment behind emerging industry technology standards, and public education. perhaps its most visible effort has been its regular consumer survey to determine the ﬁdigital condence index,ﬂ which is meant to measure public attitudes regarding the security of information systems. among other things, the alliance tracks proposed legislation related to cybersecurity issuesšfor example, spyware, phishing, identity theft, and privacy. b.4.3 privatesector support for cybersecurity research in academiaa number of privatesector companies have supported cybersecurity academic research. for instance, microsoft has funded research in universities on trustworthiness through a request for proposals process for the past few years.40 some companies have placed provisions on the results of such research, limiting availability to the sponsoring company for some period of time prior to their being generally available to the wider community or restricting publication of detailed excerpts of the data. detailed or comprehensive gures about funding levels or the conditions placed on such funding are not publicly available. 39 see https://www.trustedcomputinggroup.org/about/.40 microsoft and the external research and programs group announced the recipients of two request for proposal programs, trustworthy computing and virtual earth digital photography. see http://www.microsoft.com/presspass/features/2006/feb06/0221research.mspx.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.280 toward a safer and more secure cyberspaceb.5 notable recent efforts at identifying a research agendathe academic and policy communities concerned with cybersecurity have held numerous conferences and issued a number of reports aimed at identifying critical elements for a research and development agenda based on the current state of cybersecurity in existing information systems infrastructure. the 2002 report of the national research council (nrc) entitled making the nation safer: the role of science and technology in countering terrorism dedicated a chapter to cybersecurity.41 the report outlined a broad it research agenda for improving cybersecurity and counterterrorism efforts, including information and network security, emergency response, and information fusion. it emphasized that none of these areas ﬁcan be characterized by the presence of a single impediment whose removal would allow everything else to fall into place.ﬂ the report stressed that none of these areas is new, but called for additional research because the existing technologies are not sufciently robust or effective, they degrade performance or functionality too severely, or they are too hard to use or too expensive to deploy. finally, the report noted that the research and development agenda is one of the means of leverage that is readily available (beyond constructive engagement with the private sector) to the federal government for in˚uencing progress toward better cybersecurity.the institute for information infrastructure protection (i3p), a consortium of academic research centers, government laboratories, and notforprot research organizations, was founded in september 2001. i3p identies as its primary role the coordinating of a national cybersecurity r&d program; helping to build bridges between academia, industry, and government; and reaching out to government and industry so as to foster collaboration and information sharing and to overcome historical, legal, and cultural problems that have prevented some research organizations from working together. i3p issued its cyber security research and development agenda in january 2003, stating that it sought to ﬁhelp meet a welldocumented need for improved research and development to protect the nation™s information infrastructure against catastrophic failures.ﬂ this report, which denes an r&d agenda for cybersecurity and says that the agenda will continue to evolve as required, identies eight areas as underserved and ripe for new or additional r&d:42 41 national research council, making the nation safer: the role of science and technology in countering terrorism, the national academies press, washington, d.c., 2002. 42 institute for information infrastructure protection (i3p). the 2003 cyber security research and development agenda is available at http://www.thei3p.org/about/2003cybersecurity rdagenda.pdf. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 281enterprise security managementtrust among distributed autonomous partiesdiscovery and analysis of security properties and vulnerabilitiessecure system and network response and recoverytraceback, identication, and forensicswireless securitymetrics and modelslaw, policy, and economic issuesa brief problem description, existing research and capabilities, and potential research areas are identied for each general area. in addition, i3p maintains a directory of organizations that work in the area of cybersecurity. the president™s national security telecommunications advisory committee (nstac)43 held a series of research and development exchange workshops in 2003,44 2004,45 and 2006.46 the r&d exchange workshops are part of what nstac sees as its evolving mission, to offer advice to the government on how to protect the information infrastructure from threats and vulnerabilities that might ultimately jeopardize the country™s national and economic security.47 nstac is part of the national communication system (ncs), which became part of dhs. its work plan includes initiatives that intersect with various programs set forth in the 2000 national plan for information systems protection,48 ﬁi.e., information sharing, the security and reliability of converged networks, and research and development issues related to converged networks.ﬂ the 2004 research and development exchange workshop proceedings identies ve ndings regarding the trustworthiness of telecommunications and information systems:43 the president™s national security telecommunications advisory committee is composed of up to 30 industry chief executives representing the major communications and network service providers and information technology, nance, and aerospace companies. nstac was created by executive order to provide industrybased advice and expertise to the president on issues and problems related to implementing national security and emergency preparedness communications policy.44 national security telecommunications advisory committee, 2003 research and development exchange proceedings: research and development issues to ensure trustworthiness in telecommunications and information systems that directly or indirectly impact national security and emergency preparedness, may 2003; available at http://www.ncs.gov/nstac/reports/2003/2003%20rdx%20proceedings.pdf. 45 the 2004 research and development exchange workshop proceedings are available at http://www.ncs.gov/nstac/reports/2005/2004%20rdx%20workshop%20proceedings.pdf. 46 see a summary of the conference objectives and brieng slides, available at http://www.ncs.gov/nstac/rd/nstacrdexchangeont.html.47 see ﬁhow the nstac is tackling today™s issues,ﬂ available at http://www.ncs.gov/nstac/nstac.html. 48 see http://www.fas.org/irp/offdocs/pdd/cipplan.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.282 toward a safer and more secure cyberspacecollaboration is essential for successful r&d initiatives. . . .ubiquitous, interoperable identity management and authentication systems must be embedded into future networks. . . .a need to examine interdependencies between critical infrastructures, especially the implications of the intersection between telecommunications and electric power. . . .a need to in˚uence business drivers and policy levers and provide other incentives to promote a culture of security. . . .agreement on a common agenda is critical to achieve progress in trustworthiness r&d.the national science foundation sponsored the workshop ﬁsecurity at line speedﬂ in november 2003. the goal of the workshop was to ﬁdisseminate information on problems, discuss potential solutions and identify areas requiring additional researchﬂ related to coupling the performance requirements of advanced applications with the necessities of prudent network security.49 the workshop consensus was as follows:solutions exist, but they are not easy. . . . there are network architectures and technologies that are useful. . . . there are steps that the research community can take to adapt their protocols and approaches to better t the realities of the current level of security threats. the use of layered authentication and authorization services offer new opportunities for security. the traditional benets of education and awareness, mixed with appropriate policies, remain. . . .but they may not be sufcient. applied security research, well anchored in the realities of performance issues and network constraints, could signicantly advance the future options available. . . . the investment in research and deployment may need to be considerable.the future open networks will require new research. . . . the state of networking is at a crossroads. if no action is taken, we will continue to see attacks, experience pain and create barriers that will eventually hinder the ability for the network to support the original goal of the internet. . . .50the nsf workshop report notes the need for new research alternatives requiring basic research to begin to address the need for improvements in network performance and security brought about by the changing reality of how networks are used. it calls for userlevel tools that simplify the process of protecting hosts and user education to increase understand49 security at line speed workshop: workshop findings and report, available at http://apps.internet2.edu/sals/les/20031108wrsalsv1.1.pdf.50 security at line speed workshop: workshop findings and report, available at http://apps.internet2.edu/sals/les/20031108wrsalsv1.1.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 283ing of the importance of security. it notes the need for the research and creation of tools to assist administrators. finally, it notes the need for a set of applications communications standards that are coordinated and managed by an objective organization that can support competing efforts.also in november 2003, the computing research association (cra) held the conference ﬁgrand research challenges in information security and assurance.ﬂ51 grand research challenges seek to inspire creative thinking and vision. as specic examples, cra cites future research that might emerge from factors such as pervasive networking and mobility; increasing volumes of data; smaller, cheaper embedded computing; and a growing population of usercentric services. the identication of the following four grand challenges resulted from the cra conference:52 the elimination of epidemicstyle attacks (viruses, worms, email spam) within 10 years; the development of tools and principles that allow largescale systems to be constructed for important societal applicationsšsuch as medicalrecords systemsšthat are highly trustworthy despite being attractive targets; the development of quantitative informationsystems risk management to be at least as good as quantitative nancial risk management within the next decade; andthe provision of endusers with security controls that they can understand and privacy that they can control for the dynamic, pervasive computing environments of the future.the basis of the grand challenges requires the sharing of information on computer security risksša tactic that the community has been reluctant to adopt, unlike the telecommunications industry, which shares information on outages.53 the cra conference presented two alternative futures, depending on whether or not the grand challenges can be met. one future envisioned overwhelming unsolicited junk, rampant identity theft, frequent network outages, frequent manual intervention, and largely unchecked abuses of laws and rights. the alternative future envisioned a world with no spam or viruses, uninterrupted communications, usercontrolled privacy, and balanced regulation and law enforcement. the cra conference argued that meeting the challenges (which go beyond those of national defense) requires a focus on longterm research, 51 see http://www.cra.org/activities/grand.challenges/security/home.html. 52 see http://www.cra.org/activities/grand.challenges/security/grayslides.pdf. 53 summary of remarks by richard demillo, georgia institute of technology, in a presentation to the nrc committee, washington, d.c., july 27, 2004.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.284 toward a safer and more secure cyberspacebecause the immediacy of the threat focuses too much on nearterm needs and an enlarged talent pool. the institute for security technologies studies (ists) issued law enforcement tools and technologies for investigating cyber attacks: a national research and development agenda in june 2004; the report addresses the highestpriority technological impediments that face law enforcement when it is investigating and responding to cyberattacks and for which research and development might provide solutions. it documents the ﬁcontinuing, critical, unmet needs of the law enforcement community for solutions to assist in the investigation and prosecution of cyber attacks,ﬂ and it prioritizes the needs of the cyberattack investigative community that can form the basis for targeted research and development. the ists report identies a number of themes:54 the need to automate tasks in the investigative process,tools that produce evidencequality data,reducing the cost of available tools,reducing the reliance on insiders or individuals who may be suspects in cyberattacks, andthe need for continued and expanded publicprivate partnership, collaboration, and information sharing.in february 2005 the president™s information technology advisory committee (pitac) issued a report to the president entitled cyber security: a crisis of prioritization (hereafter, ﬁthe pitac reportﬂ).55 the committee was established to provide ﬁthe president, congress, and the federal agencies involved in networking and information technology research and development (nitrd) with expert, independent advice on maintaining america™s preeminence in advanced information technologies, including such critical elements of the national infrastructure as high performance computing, largescale networking, and high assurance software and systems design.ﬂ56 the pitac report stresses how vital the information technology infrastructure has now become for communication, commerce, and control of physical infrastructure. it also stresses that the it infrastructure is highly vulnerable to terrorist and criminal attacks and that the vulnerabilities are growing rapidly. it cites broad consensus among computer scientists that endless patching is not a solution and that the longterm answer requires fundamentally new security models and 54 see http://www.ists.dartmouth.edu/tag/randd.htm. 55 see http://www.nitrd.gov/pitac/reports/20050301cybersecurity/cybersecurity.pdf. 56 see the president™s information technology advisory committee web site at http://www.nitrd.gov/pitac/. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 285methods. the report identies four key issues, all related to cybersecurity research. specically, it found the following:inadequate fundingšfederal r&d funding for fundamental research in civilian cybersecurity is inadequate. increased funding is needed for nsf to support such research.lack of researchers and educationšthe research community is too small to support the necessary research and education. increased and stable funding is needed to promote recruitment and retention of researchers and students.ineffective technology transferšcurrent technology transfer efforts are inadequate to successfully transfer federal research investments into civiliansector best practices and products. the development of metrics, models, data sets, and testbeds is needed so that new products and best practices can be evaluated. partnerships with the private sector need strengthening.lack of coordination and oversightšcurrent federal r&d effort is unfocused and inefcient. a focal point for coordinating cybersecurity r&d efforts is needed: specically, the interagency working group on critical information infrastructure protection (ciip).the pitac report offers 10 priority areas for increased research focus: authentication technologies; secure fundamental protocols; secure software engineering and software assurance; holistic system security; monitoring and detection; mitigation and recovery methodologies; cyber forensics; modeling and testbeds; metrics, benchmarks, and best practices; and nontechnology issues (psychological, societal, institutional, legal, and economic) that can affect cybersecurity. nsf was singled out by the report for increased fundingša total of $90 million annuallyšto support fundamental research in civilian cybersecurity. pitac was disbanded in june 2005 by the bush administration. an executive order designated the president™s council of advisors on science and technology (pcast) to serve in the role of pitac.57 in july 2005 the ﬁostp/omb memorandum on administration, fy 2007 r&d budget prioritiesﬂ called for placing high priority on r&d investments in cyber infrastructure protection as well as highend computing.58 it specically called for agencies to work through the national 57 executive order 13385, ﬁcontinuance of certain federal advisory committees and amendments to and revocation of other executive orders,ﬂ september 30, 2005, available at http:// edocket.access.gpo.gov/2005/pdf/0519993.pdf.58 joint memorandum of the ofce of management and budget and the ofce of science and technology policy, ﬁostp/omb memorandum on administration, fy 2007 r&d budget priorities,ﬂ washington, d.c., july 8, 2005.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.286 toward a safer and more secure cyberspacescience and technology council (nstc) to generate a detailed gap analysis of r&d funding re˚ecting the importance of cybersecurity and the need to ensure that areas in need of research be covered in the federal r&d program.the infosec research council (irc)59 issued its hard problem list 2005 in november 2005.60 as the report notes, the hard problems on this list were chosen because they represent fundamental technical challenges that arise in building and operating trustworthy systems, because they are inherently complex, and because of their importance to government missions. they do not (as the report also states) by any means represent the only challenges to the eld of it security. the eight topic areas identied as most relevant over the next 5 to 10 years are as follows:globalscale identity management: globalscale identication, authentication, access control, authorization, and management of identities and identityrelated information;insider threat: mitigation of insider threats in cyberspace to an extent comparable to that of mitigation of comparable threats in physical space;availability of timecritical systems: guaranteed availability of information services, even in resourcelimited, geospatially distributed, ondemand ad hoc environments;building scalable secure systems: design, construction, verication, and validation of system components and systems ranging from crucial embedded devices to systems composing millions of lines of code;situational understanding and attack attribution: reliable understanding of the status of information systems, including information concerning possible attacks, who or what is responsible for the attack, the extent of the attack, and recommended response;information provenance: the ability to track the pedigree of information in very large systems with petabytes of information;security with privacy: technical means for improving information security without sacricing privacy; and59 the infosec research council consists of u.s. government sponsors of information security research from the department of defense, the intelligence community, and federal civil agencies. the irc provides its membership with a communitywide forum for discussing critical information security issues, conveying the research needs of their respective communities, and describing current research initiatives and proposed courses of action for future research investments. further information on the irc is available at http://www.infosecresearch.org.60 infosec research council (irc), ﬁhard problem list 2005,ﬂ available at http://www.infosecresearch.org/docspublic/20051130irchplfinal.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 287enterpriselevel security metrics: the ability to effectively measure the security of large systems with hundreds to millions of users.in april 2006 the interagency working group on cyber security and information assurance (csia), under the auspices of the nstc, issued the federal plan for cyber security and information assurance research and development.61 csia reports jointly to the nstc subcommittee on infrastructure and the nstc subcommittee on nitrd. the plan is intended to provide ﬁbaseline information and a technical framework for coordinating multiagency r&d in cyber security and information assurance.ﬂ62 the scope of the plan is limited specically to federal r&d objectives. within this scope the plan is comprehensive in its laying out the breadth of technical perspectives on cybersecurity r&d. it also provides an overview of the threats, threat agents, asymmetric advantages of those agents, vulnerability trends, and infrastructure sectors of particular immediate concernšthat is, industrial process control systems and the banking and nance sector.this federal plan also aims to respond to recent calls for improving the overall federal cybersecurity r&d program. specically, it responds to the following reports and policy actions already discussed: the ﬁostp/omb memorandum on administration, fy 2007 r&d budget prioritiesﬂ; cyber security: a crisis of prioritization, the 2005 pitac report; the 2003 national strategy to secure cyberspace; and the cyber security research and development act of 2002 (p.l. no. 107305). seven broad objectives are identied by the plan as being strategic to federal r&d efforts:631. support research, development, testing, and evaluation of cyber security and information assurance technologies aimed at preventing, protecting against, detecting, responding to, and recovering from cyber attacks that may have largescale consequences.2. address cyber security and information assurance r&d needs that are unique to critical infrastructures.3. develop and accelerate the deployment of new communication protocols that better assure the security of information transmitted over networks.4. support the establishment of experimental environments such as testbeds that allow government, academic, and industry researchers to 61 national science and technology council, federal plan for cyber security and information assurance research and development, national coordinating ofce for networking and information technology research and development, april 2006; available at http://www.nitrd.gov/pubs/csia/csiafederalplan.pdf.62 national science and technology council, federal plan for cyber security, 2006, p. ix.63 national science and technology council, federal plan for cyber security, 2006, p. x.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.288 toward a safer and more secure cyberspaceconduct a broad range of cyber security and information assurance development and assessment activities.5. provide a foundation for the longterm goal of economically informed, riskbased cyber security and information assurance decision making.6. provide novel and nextgeneration secure it concepts and architectures through longterm research.7. facilitate technology transition and diffusion of federally funded r&d results into commercial products and services and privatesector use.these objectives were drawn from a review of legislative and regulatory policy requirements, analyses of cybersecurity threats and infrastructure vulnerabilities, and agency mission requirements. the federal plan makes a detailed analysis of federal cybersecurity r&d technical and funding priorities for areas broken into eight categories, each with several subcategories. for each subcategory, a denition of the area, its importance, the current state of the art, and the existing capability gap are provided. the eight categories and their subcategories are as follows:641. fundamental cyber security and information assurance, including authentication, authorization, and trust management; access control and privilege management; attack protection, prevention, and preemption; largescale cyber situational awareness; automated attack detection, warning, and response; insider threat detection and mitigation; detection of hidden information and covert information ˚ows; recovery and reconstitution; and forensics, traceback, and attribution. 2. securing the infrastructure, including secure domain name system; secure routing protocols; ipv6, ipsec, and other internet protocols; and secure process control systems.3. domainspecic security, including wireless security; secure radio frequency identication; security of converged networks and heterogeneous trafc; and nextgeneration priority services.4. cyber security and information assurance characterization and assessment, including software quality assessment and fault characterization; detection of vulnerabilities and malicious code; standards; metrics; software testing and assessment tools; riskbased decision making; and critical infrastructure dependencies and interdependencies.5. foundations for cyber security and information assurance, including hardware and rmware security; secure operating systems; securitycentric programming languages; security technology and 64 national science and technology council, federal plan for cyber security, 2006, part ii.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 289policy management methods and policy specication languages; information provenance; information integrity; cryptography; multilevel security; secure software engineering; faulttolerant and resilient systems; integrated, enterprisewide security monitoring and management; and analytical techniques for security across the it systems engineering life cycle.6. enabling technologies for cyber security and information assurance r&d, including cyber security and information assurance r&d testbeds; it system modeling, simulation, and visualization; internet modeling, simulation, and visualization; network mapping; and red teaming.7. advanced and nextgeneration systems and architectures, including trusted computing base architectures; inherently secure, highassurance, and provably secure systems and architectures; composable and scalable secure systems; autonomic systems; architectures for nextgeneration internet infrastructure; and quantum cryptography.8. social dimensions of cyber security and information assurance, including trust in the internet; and privacy.the r&d priorities identied in the federal plan are compared with both the irc and pitac reports. the generally close alignment between the three reports is called ﬁparticularly noteworthy.ﬂ65 authentication, secure software engineering, security throughout the system life cycle, monitoring and detection, modeling and testbeds, metrics, benchmarking and best practices, and privacy are all identied as top r&d priorities in various ways across all three reports. the federal plan makes 10 recommendations for federal strategic interagency r&d to strengthen cybersecurity and information assurance in it infrastructure, noting the need to collaborate and coordinate with the private sector:66 1. target federal r&d investments to strategic cyber security and information assurance needs. . . . 2. focus on threats with the greatest potential impact. . . . 3. make cyber security and information assurance r&d both an individual agency and an interagency budget priority. . . . 4. support sustained interagency coordination and collaboration on cyber security and information assurance r&d. . . . 5. build security in from the beginning. . . . 6. assess security implications of emerging information technologies. . . .65 national science and technology council, federal plan for cyber security, 2006, p. 21.66 national science and technology council, federal plan for cyber security, 2006, pp. 2326. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.290 toward a safer and more secure cyberspace 7. develop a roadmap for federal cyber security and information assurance r&d. . . . 8. develop and apply new metrics to assess cyber security and information assurance. . . . 9. institute more effective coordination with the private sector. . . .10. strengthen r&d partnerships, including those with the international partners. . . .the federal plan stresses the need for interagency coordination to be strengthened within the context of the continuing missionspecic focus of the various agencies cooperating through nitrd. in october 2006, csia requested input from the computing community on the roadmap for cybersecurity r&d called for in the recommendations (item 7 above).67 it specically sought input in four broad topics: r&d strategic issues, r&d technical topics and priorities (as listed in the request), r&d roadmap, and r&d recommendations in the federal plan. the gao had noted in a september 2006 report the lack of steps taken to date toward creating such a roadmap.b.6 the current federal research  and development landscapethis section characterizes the current research activity in cybersecurity being supported by various federal agencies in line with their respective mission focuses. the nature of supported activity in cybersecurity is outlined for each agency. research focus areas are identied, and a summary of the activitiesšbased on focus areašis provided for each agency supporting or undertaking r&d research.b.6.1 the nature of supported activity in cybersecuritythe nature of the activity supported by federal agencies varies depending on the mission of the agency. the following summarizes the primary goals of the support that each agency provides for cybersecurity: national science foundation (nsf)šbasic research, building research capacity.defense advanced research projects agency (darpa)šmission67 subcommittee on networking and information technology research and development, ﬁinvitation to submit white papers on developing a roadmap for cybersecurity and information assurance research and development,ﬂ october 31, 2006; available at http://www.nitrd.gov/subcommittee/csia/csiawhitepapersfinal103106.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 291oriented with the objective of rapid technology transfer for military operational use.department of homeland security (dhs)šdevelopment and nearterm deployment of useful cybersecurity technologies.national institute of standards and technology (nist)šstandards, guidelines, and certication.department of energy (doe)šprovision of a trustworthy environment for access to distributed resources and for supporting collaborative management of those resources.national security agency (nsa) and intelligence agenciesšthe unclassied and defensive portion of these agencies™ mission is applied research aimed at growing the capabilities necessary to protect national information infrastructure, including support for education aimed at building the necessary domestic cadre of cybersecurity researchers and developers. other agencies (e.g., federal aviation administration [faa], department of justice [doj], department of defense [dod])šmissionspecic objectives relating to protecting information systems and infrastructure.the agencies use a variety of approaches to support research to address their primary goals. some agencies do all of their research in government laboratories, while others fund a mixture of university or privateindustry research. nsf, darpa, and dhs made recent solicitations directed at supporting cybersecurity research. nsf supports a broad range of basic research in several areas of cybersecurity research. nsf™s cyber trust program is dedicated to supporting basic cybersecurity research. it has funded a number of centerscale research efforts of limited scope and duration to provide support for specic focus areas. nsf also supports cybersecurity research through various other programs. darpa supported one unclassied program directed at cybersecurity in 2004. all research projects in this program focus on one aspect of cybersecurity research. this is consistent with recent darpa programs addressing cybersecurity. dhsšin keeping with the cybersecurity mission specied for it in the national strategy to secure cyberspacešfocused on operational aspects of cybersecurity through its national cybersecurity division (ncs), although (as noted in the pitac report) less than 1 percent of its r&d budget is spent on cybersecurity research. the homeland security advanced research projects agency (hsarpa) solicited proposals for cybersecurity research and development from the academic and private sectors. the focus of this solicitation was on the improvement of existing technologies, the development of toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.292 toward a safer and more secure cyberspacenew technologies, and technology transfer. doe cybersecurity research is closely coupled with the science applications that it is focused on supportingšprimarily, secure collaborative management of infrastructure resources. the primary focus of nist™s computer security division is cybersecurity tools, standards, best practices, and guidelines. it performs inhouse research on cybersecurity in support of this focus. b.6.2 interagency cooperation and coordinationseveral coordinating bodies within the federal government address various aspects of cybersecurity r&d. two of these, nitrd and ciip, are under the nstc. furthermore, nitrd™s interagency working group (iwg) on cyber security and information assurance was responsible for the creation of the 2006 federal plan for cyber security and information assurance research and development. as noted previously, this plan was intended to address concerns about the need for more comprehensive coordination of the federal cybersecurity r&d agenda, expressed in the pitac report and other reports and policy instruments. several agencies participated in the csia iwg: nist, dod, dhs, the department of state, faa, the department of the treasury, the intelligence community, nasa, the national institutes of health (nih), and nsf.the role of the nitrd program is to provide an interagency coordination function that ensures that unclassied strategic federal it r&d objectives are covered by the various mission agencies and to provide a mechanism for identifying and addressing gaps in it r&d. all agencies active in cybersecurity research are included in nitrd. the csia federal plan is meant to provide a framework for coordinating interagency r&d in the context of the nitrd structure.b.6.3 research focus areascreating trustworthy information infrastructure requires addressing many problems. cybersecurity can be compromised by a weakness in any aspect of a system or network. thus, cybersecurity research must encompass a broad range of it disciplinesšhardware, networking, and so on. a trustworthy system should aim to be secure by design, but it should also be able to detect, prevent, and survive attacks. the security life cycle begins with architecture and ends with the ability to identify attackers after the fact. the csia federal plan previously summarized provides a sense of the breadth of issues that must be considered in order to comprehensively address cybersecurity. current research can be classied in a number of waysšfor example, using the categories and subcategories used in the federal plan. nsf used toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 293security discipline and lifecycle classications for categorizing projects for its 2004 core cybersecurity awards.68 categorization is helpful for identifying those areas receiving considerable focus and those that are currently receiving limited funding support, although no conclusions can be drawn directly from relative funding in these various areas about the need for funding in a particular focus areašan area may have been well researched in the past, or may be perceived to hold less promise. the following subsections provide specics about the nature of cybersecurity r&d at each of the agencies that supported or conducted such research.b.6.4 agency specicsb.6.4.1 national science foundation the national science foundation is the leading agency supporting nondefense basic research in cybersecurity. the cybersecurity research and development act of 2002 includes specic language regarding nsf™s lead role in cybersecurity research and development. it also authorizes appropriations for research.69 the cyber trust program is the centerpiece of nsf™s support for cybersecurity research, although the program has not been funded to the fully authorized level.70 the cyber trust program was established in response to the cybersecurity act to provide a focal point for cybersecurity activity at nsf. since 2004, the cyber trust program has awarded more than 100 research grants, including the funding of several centerscale cybersecurity research efforts. other nsf programsšinformation technology research, embedded hybrid systems, small grants for exploratory research, network research testbeds, and experimental infrastructure networkšsupported awards for cybersecurity research. these programs supported more than 100 additional cybersecurity projects. projects vary in length from 1 to 5 years, with annual awards ranging from $150,000 to $1.5 million for the centerscale projects. nearly all the awards include some support for graduate and postdoctoral students. according to karl levitt, program manager for the cyber trust program, the success rate in 2006 for the cyber trust program was about 12 percentšand was accomplished by eliminating for that year the funding for centerlevel grants and by signicantly reducing the funding awarded compared with that requested. the ratio of total amounts awarded to total amounts requested 68 see http://www.nsf.gov/cise/funding/cyberawards.jsp.69 p.l. no. 107305, secs. 47.70 see the cyber trust program home page at http://www.nsf.gov/funding/pgmsumm.jsp?pimsid=13451&org=cise. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.294 toward a safer and more secure cyberspacewas less than 8 percent, a gure comparable to that of scal year (fy) 2004. in 2007, the success rate was increased to 20 percent, mostly because the cyber trust budget was increased to $34 million, the level it was in 20042006, but also because of not making centerlevel awards.71the type of research being performed covers a broad range of the categories listed in the federal plan, although some areas receive signicant focus and others relatively little.72 the cybersecurity research and development act explicitly identies a number of areas to receive attention. each of the areas specied was the focus of at least some projects awarded funding. the act authorized funding of $40 million for fy 2004 and $46 million for fy 2005, excluding center funding, for which separate authorizations were specied. funding for cybersecurity r&d supported by nsf has grown over the past several years, starting at approximately $30 million in fy 2004; it has not risen to the level recommended by the pitac report, however.in addition to awards to eligible individuals, the cybersecurity research and development act calls for nsf to establish computer and network security research centers to ﬁgenerate innovative approaches to computer and network security by conducting cuttingedge, multidisciplinary research.ﬂ the act authorizes centerscale appropriations for fy 2003 through fy 2007, although centerscale awards were eliminated in the fy 2006 solicitation.73 centerscale awards are typically 5year grants, with annual funding ranging from $1.5 million to $4 million. each centerscale project involves researchers from multiple universities addressing multidisciplinary aspects of each project. several centerscale projects have been established thus far through the cyber trust program, including the following: security through interaction modeling will ﬁexplore ways to create more effective and usable defenses by modeling these networks of interactions and making the models an integral part of the defenses.ﬂ74the center for internet epidemiology and defenses will work ﬁto understand how the internet™s open communications and software vulnerabilities permit worms to propagate, to devise a globalscale 71 karl levitt, nsf, personal communications to the committee, november 27, 2006, and june 21, 2007.72 the national science foundation did a breakdown of some of the fy 2004 cybersecurity funding. the summary of this breakdown is available at the cyber trust program web page, http://www.nsf.gov/funding/pgmsumm.jsp?pimsid=13451&org=cise.73 national science foundation, cyber trust program solicitation, nsf 06517, washington, d.c., 2006.74 nsf press release 04124, september 21, 2004, ﬁnsf announces two cybersecurity centers to study internet epidemiology and ecologyﬂ; available at http://www.nsf.gov/news/newssumm.jsp?cntnid=100434. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 295early warning system to detect epidemics . . . , to develop forensics capabilities . . . , and to develop techniques and devices that can suppress outbreaks before they reach pandemic proportions.ﬂ75 the center for correct, usable, reliable, auditable and transparent elections will ﬁinvestigate software architectures, tamperresistant hardware, cryptographic protocols and verication systems as applied to electronic voting systems.ﬂ76trustworthy cyber infrastructure for the power grid will ﬁcreate technologies that will convey critical information to grid operators despite cyber attacks and accidental failures. the solutions created are expected to be adaptable for use in other critical infrastructure systems.ﬂ both doe and dhs will collaborate to fund and manage this center. 77a major cybersecurity research project funded outside the auspices of the nsf cyber trust program is the team for research in ubiquitous secure technology (trust).78 trust seeks to address a parallel and accelerating trend of the past decadešthe integration of computing and communications across critical infrastructures in areas such as nance, energy distribution, telecommunications, and transportation. the center is an nsf science and technology center, chartered to investigate key issues of computer trustworthiness in an era of increasing attacks at all levels on computer systems and informationbased technologies. as noted on its web site, trust is ﬁdevoted to the development of a new science and technology that will radically transform the ability of organizations (software vendors, operators, local and federal agencies) to design, build, and operate trustworthy information systems for our critical infrastructure.ﬂ the project takes a highly crossdisciplinary approach, including researchers in relevant areas of computer security, systems modeling and analysis, software technology, economics, and social sciences. education and technology transfer are also important components. trust also receives funding from the air force ofce of scientic research.b.6.4.2 defense advanced research projects agency in line with its agency mission, the defense advanced research projects agency™s research focus has been on military applications of infor75 nsf press release 04124, september 21, 2004. 76 nsf press release 05141, august 15, 2005, ﬁnsf awards $36 million toward securing cyberspaceﬂ; available at http://www.nsf.gov/news/newssumm.jsp?cntnid=104352.77 nsf press release 05141, august 15, 2005.78 detailed information about the project is available at the trust project web site at http://www.truststc.org/overview.htm.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.296 toward a safer and more secure cyberspacemation security. darpa began an information security research program in 1994.79 the information survivability program, was the initial program, followed by the information assurance program. these programs focused on a number of security aspects, including retrotting security and survivability technology for legacy systems, intrusion detection and response, survivability in the face of attack, highassurance operating system construction, the composing of trustworthy systems from less trustworthy components, and secure collaboration allowing data sharing and communication over a network. darpa expanded its information security investment in 1999. from 1999 to 2003, six programs were funded, covering a range of information security areas and extending research in areas covered by the earlier programs: composable high assurance trusted systemsšhighassurance operating systems composed out of interoperable subsystems, to provide the required trustworthiness.cyber panelšmonitoring for attacks and allowing operators to manage system security and survivability.dynamic coalitionsšsecure communication and data sharing across a network.fault tolerant networksšcontinued network operation in the presence of successful attacks; that is, intrusion tolerance at the network layer and below.organically assured and survivable information systemsšsustained operation of missioncritical functions in the face of known and future cyberattacks; that is, intrusion tolerance at the host and system level.operational partners in experimentationšaccelerated transition to deployment.darpa sponsored three conferences between 2000 and 2003 called ﬁdarpa information survivability conference and expositionsﬂ (discex i, discex ii, discex iii) to present the ndings of the research programs. these programs began winding down in 2003 and had ended by early 2005. much of the staff focused on information assurance and security left darpa as these programs wound down and have not been replaced. the institutional knowledge has largely left or become classied.79 much of the discussion concerning past support for cybersecurity at darpa is drawn from the information survivability conference and exposition iii, washington, d.c., april 2003; available at http://csdl.computer.org/comp/proceedings/discex/2003/1897/00/1897xi.pdf. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 297one unclassied program, selfregenerative systems (srs), focused on information security; it began in 2004 and was scheduled to run for  18 months. this program supports 11 research projects. the funding rate for srs was approximately 12 percent. funding projects were about evenly split between universities and the private sector, with four projects being performed jointly by universities and corporations. the overarching theme of the srs program is on survivability, resilience, and adaptation in the face of attack, with four specic focus areas: code diversity to reduce the impact of exploiting a single ˚aw across systems; attack masking and recovery; scalable redundancy to achieve survivability and resilience; and detection, prevention, and mitigation from insider threats. measurable goals have been set for projects, re˚ecting their applied nature. at least two classied programs are also under way, with largely shortterm research and deployment goals. darpa is also cofunding two projects with nsf. in recent years, concerns have been expressed about a shift toward classied, shorterterm, and militarymissionfocused research in darpa™s cybersecurity portfolio. for example, in 2005, the pitac report commented as follows:80 darpa historically used a large portion of its budget to fund unclassied longterm fundamental researchšin general, activities with a time horizon that exceeds ve years. this provided darpa with access to talented researchers in the nation™s nest research institutions and helped cultivate a community of scholars and professionals who developed the eld. by fy 2004, however, very little, if any, of darpa™s substantial cyber security r&d investment was directed towards fundamental research. instead, darpa now depends on nsfsupported researchers for the fundamental advances needed to develop new cyber security technologies to benet the military. additionally, the emergence of cyber warfare as a tool of the warghter has led darpa to classify more of its programs. the combined result is an overall shift in darpa™s portfolio towards classied and shortterm research and development and away from its traditional support of unclassied longerterm r&d.in the 2 years since the pitac report was issued, the committee has seen no evidence to suggest a signicant change in darpa™s approach to cybersecurity research. the extent to which darpa emphasizes classied and shortterm 80 president™s information technology advisory committee, cyber security: a crisis of  prioritization, national coordination ofce for information technology research and development, washington d.c., february 2005, p. 19; available at www.nitrd.gov/pitac/reports/ 20050301cybersecurity/cybersecurity.pdf.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.298 toward a safer and more secure cyberspacer&d over unclassied longerterm r&d is dependent on many factors, not the least of which is darpa™s interpretation of its mission. the tension between these two different foci has been re˚ected in many ways, not the least of which is the many changes in the very name of the agency since its birth in 1958.81 if darpa continues to emphasize classied, shortterm research, that may well raise concerns among academic researchers about the longterm sustainability and future of working in cybersecurity research. a second possible result of the shift toward shortterm, militarymissionfocused research is that such a research program may not sufciently focus on issues relevant to the commercial sector (which develops and operates much of the nation™s critical infrastructure). for example, military and intelligence applications often emphasize condentiality over integrity and availability, whereas the commercial sector is often as concerned or more concerned about integrity and availability. also, military and intelligence applications are more likely to emphasize risk avoidance, whereas commercial enterprises are more likely to emphasize risk management.b.6.4.3 department of homeland securitythe department of homeland security has both an operational functionšpreparedness and responsešand a research function for cybersecurity. the national strategy to secure cyberspace gave dhs the lead role in cybersecurity, calling on it to become the center of excellence for response, vulnerability reduction, training and awareness, and securing government cyberspace.82 dhs created the national cyber security division (ncsd) under the department™s national protection and programs directorate in june 2003 in response to the national strategy requirements.83 ncsd has three operating branches: u.s. computer emergency readiness team (uscert); strategic initiatives to advance cybersecurity 81 in 1958, department of defense (dod) directive 5105.15 established the advanced research projects agency. in 1972, another dod directive changed the agency™s name to defense advanced research projects agency (darpa). in 1993, darpa was redesignated the advanced research projects agency at the direction of president william j. clinton. in 1996, the defense authorization act for fy 1996 changed the agency™s name back to defense advanced research projects agency (darpa). see http://www.darpa.mil/body/arpadarpa.html.82 discussion in this section is drawn, in part, from the written statement of donald (andy) purdy, jr., to the house subcommittee on federal financial management, government information, and international security, july 19, 2005; available at http://hsgac.senate.gov/les/purdytestimony.pdf.83 dhs press release, june 6, 2003, ﬁridge creates new division to combat cyber threatsﬂ; available at http://www.dhs.gov/dhspublic/display?content=916.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 299training, education, software assurance, exercises, control systems, critical infrastructure protection, and standards and practices; and outreach and awareness.in july 2005, newly appointed dhs secretary michael chertoff proposed creating a new position of assistant secretary for cybersecurityšmoving the responsibility for cybersecurity up one level in the organizational structure, although the position took more than 14 months to ll.84 cybersecurity research at dhs is supported through the science and technology (s&t) directorate. the s&t mission includes conducting, stimulating, and enabling research and development. however, the current emphasis is on short to mediumterm needs related to the implementation of the national strategy to secure cyberspace, including testing, evaluation, and timely transition of capabilities with approximately 85  to 90 percent of the s&t budget focused on these areas.85 the remaining 10 to 15 percent of the budget is for the support of longterm, breakthrough research. the mission of the cyber security research areašone of 15 s&t research portfolios organized into three categoriesšis to ﬁlead cyber security research, development, testing, and evaluation endeavors to secure the nation™s critical information infrastructure, through coordinated efforts that will improve the security of the existing cyber infrastructure, and provide a foundation for a more secure infrastructure.ﬂ86 this broad mission is re˚ected in the r&d areas that dhs identies as important to address: secure systems engineering, information assurance benchmarks and metrics, wireless and embedded systems security, critical infrastructure, and cybersecurity education. there is specic focus on technologytransfer issuesšmoving from research to deployment. around $300 million has been spent annually on cybersecurity research for the past decade. yet, the transition path has not existed to produce commercial products from this research. government funding trends have moved roughly $100 million into classied areasšresulting in even less research available to eventually produce commercial products.87 84 see the organizational charts for 2005, http://www.dhs.gov/interweb/assetlibrary/dhsorgchart2005.pdf, and the proposed structural adjustments, http://www.dhs.gov/ interweb/assetlibrary/dhsorgchart.htm. the position was lled for the rst time in september 2006.85 background for the discussion of cybersecurity research missions of the department of homeland security is drawn from presentations given by douglas maughan, dhs, to the committee on july 27, 2004, and presentations given at the hsarpa cyber security research and development bidder™s conference held on september 23, 2004, in arlington, va. (see http://www.hsarpabaa.com/main/cybersecuritybidders9132004.pdf).86 see http://www.dhs.gov/dhspublic/interapp/editorial/editorial0549.xml.87 statement of douglas maughan, hsarpa program manager, in a brieng to the committee on july 27, 2004.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.300 toward a safer and more secure cyberspacethe homeland security advanced research projects agency (hsarpa) under s&t created the cyber security r&d center in 2004. hsarpa initiated the cyber security research and development (csrd) program in 2004.88 program funding supported approximately half of the proposals deemed worthy of pursuing. there was concerted effort to reach out to the private sector for proposals, but few privatesector submissions were received.89 the dhs s&t cybersecurity agenda includes several other activities in addition to the broad agency announcement for csrd. the cyber defense technology experimental research projectšfunded and run jointly with nsfšprovides an experimental testbed to facilitate nationalscale cybersecurity experimentation. the protected repository for defense of infrastructure against cyber threats is aimed at providing cybersecurity researchers with sufcient access to data necessary to test their research prototypes. signicant steps are being taken to protect the data against privacy concerns and to protect the data providers from abuse. a joint governmentindustry steering committee has been formed to address issues related to domain name service security (dnssec). two workshops were held in 2004. nist provided additional funding for this activity. the secure protocols for routing infrastructure activity is similar to the dnssec activity, with a governmentindustry steering committee and workshops. cyber economic assessment studies are being undertakenšin keeping with the focus on technology transferšto examine costevaluation methods for cybersecurity events and to enhance understanding of business cases and investment strategies that promote cybersecurity and risk prioritization. two small business innovation research grants were awarded in 2004 addressing intrusion detection and identication of malicious code. b.6.4.4 national institute of standards and technologythe cybersecurity research and development act species the role of the national institute of standards and technology in cybersecurity research.90 the computer security divisionšone of eight divisions in the information technology laboratoryšis the focal point at nist for 88 homeland security advanced research projects agency (hsarpa) broad agency announcement (baa) 0417; available at http://www.hsarpabaa.com/.89 discussion of committee members with douglas maughan, hsarpa program manager, on may 25, 2005.90 see secs. 811 of the cybersecurity research and development act of 2002 (p.l. no. 107305).toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 301cybersecurity. csd describes its mission as improving information security in four ways:91raising awareness of it risks, vulnerabilities, and protection, particularly in new and emerging technologies; researching, studying, and advising agencies of it vulnerabilities, and devising techniques for the costeffective security and privacy of sensitive federal systems; developing standards, metrics, tests, and validation programs to promote, measure, and validate security in systems and services; to educate consumers; and to establish minimum security requirements for federal systems; anddeveloping guidance to increase secure it planning, implementation, management, and operation.four focus areas re˚ect this mission: cryptographic standards and applications; security testing; security research/emerging technologies; and security management and guidance.92 csd performs inhouse research and provides services to dhs, nsa, and other agencies to support their cybersecurity missions. csd™s computer security resource center (csrc)93 acts as a focal point for raising awareness about cybersecurity. csd issues reports, such as security considerations for voice over ip systems, to raise awareness of it risks in emerging technologies. nist runs the national vulnerability database (nvd) with funding from dhs™s national cyber security division. nvd is ﬁa comprehensive cyber security vulnerability database that integrates all publicly available u.s. government vulnerability resources and provides references to industry resources.ﬂ94 the bulk of nist™s efforts (~$15 million) are focused on setting guidelines, evaluation tools, and standards for nonnational security computers, and providing assistance to improve partnering of industry and academia. for instance, nist provides coordination and guidance for how federal agencies implement and meet federal information security management act requirements. it provides security selfassessment tools, organizes workshops, and gives training sessions and awareness meet91 statement of edward roback, national institute of standards and technology, in a brieng to the committee, july 27, 2004. see also http://csrc.nist.gov/mission.html. the statement ﬁcybersecurity research and developmentﬂ by arden bement, jr., nist technology administration, before the u.s. house committee on science, may 14, 2003, provides additional background information for this section. 92 see http://csrc.nist.gov/focusareas.html#sret. 93 see http://csrc.nist.gov/index.html.94 see http://nvd.nist.gov.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.302 toward a safer and more secure cyberspaceings. it develops encryption standards and cryptography toolkits. the common criteria process,95 run by nsa under the national information assurance partnership,96 provides a means for the evaluation of information technology products for conformance to the international common criteria for information technology security evaluation.nist performs intramural cybersecurity r&d focused on internet protocol security (ipsec), mobile networks and devices, access control and authentication mechanisms, and improved automation testing. it also provides fundingšjointly with dhsšfor i3p97 run by dartmouth college™s institute for security and technology studies. in 2001 nist provided nine research grants under its critical infrastructure protection grants program. funding for this program was not reauthorized, although the cybersecurity research and development act calls for the establishment and support of research fellowships.nist also supports cyber forensics and law enforcement. it maintains the national software reference library, sets standards for forensic tools and methods, and does some testing of tools and devices for forensic analysis.the intelligent systems division of the manufacturing engineering laboratory at nist formed the process control security requirements forum in 2001 to address cybersecurity issues related to scada systems. in october 2004, the forumšcomposed of vendors, system integrators, end users of industrial control systems, and nist staffersšissued the rst draft of the system protection prole for industrial control systems, which is ﬁdesigned to present a cohesive, crossindustry, baseline set of security requirements for new industrial control systems.ﬂ98 b.6.4.5 department of energythe ofce of science (sc) at the u.s. department of energy supports cybersecurity r&d focused on ﬁproviding a trustworthy environment for access to distributed resources and for supporting collaborations.ﬂ99 research projects are conducted at universities as well as at the lawrence berkeley national laboratory. cybersecurity research is tightly coupled with science applications that are the primary mission at doe. in particular, much of the focus of cybersecurity research is on distributed 95 see http://csrc.nist.gov/cc/.96 see http://niap.nist.gov/.97 see http://www.thei3p.org/.98 see http://www.isd.mel.nist.gov/projects/processcontrol/. 99 written comments provided by daniel hitchcock, department of energy, to the committee at a meeting on july 27, 2004. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 303authorization and secure collaboration using shared resources. from the perspective of the security life cycle, doe efforts emphasize attack prevention and intrusion detection. in fy 2005 doe provided support, along with dhs, for an nsffunded centerscale projectšthe center for trustworthy cyber infrastructure for the power gridšwhich will support 19 researchers across three universities with creating secure network protocols that enable efcient sharing of supply and demand information. b.6.4.6 national security agencythe national security agency focuses largely on applied research to meet the needs of dod and the intelligence community. approximately 120 internal researchers work on cybersecurity. about 50 percent of the nsa budget for cybersecurity goes to nonacademic organizations doing classied research; 10 to 15 percent of the budget supports academic organizations. in his statement before the house select committee on homeland security subcommittee on cybersecurity, science and research and development, thennsa director of information assurance daniel g. wolf noted that the agency now spends the bulk of its time and resources ﬁengaged in research, development and deployment of a full spectrum of information assurance technologies for systems processing all types of information.ﬂ100 he identied a number of priority areas for research, including assured software design tools and development techniques, automated patch management, resilient systems, attack identication, and attribution. he expressed concerns about foreign hardware and software being used in critical systems and noted nsa™s work on a trusted microelectronic capability. nsa provides support for civilian cybersecurity research in various ways, including funding and technical advice to nsf, darpa, nist, and dhs.101 nsa sponsors the information assurance technical framework forum (iatff) to foster dialogue between u.s. government agencies, industry, and academia. the iatff document provides guidance for protecting information and systems. nsa supports several other outreach programs for system security assessment, security design and evaluation, 100 statement by daniel g. wolf, director of information assurance, national security agency, before the house select committee on homeland security, subcommittee on cybersecurity, science and research and development, hearing titled ﬁcybersecurityšgetting it right,ﬂ july 22, 2003; available at http://www.globalsecurity.org/security/library/congress/2003h/030722wolf.doc.101 the discussion of national security agency support for cybersecurity research is drawn from the presentation to the committee by grant wagner, nsa information assurance research group, on july 27, 2004.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.304 toward a safer and more secure cyberspaceand security professional certication. nsa developed security enhanced linux (selinux) as an enhancement to the linux kernel that implements mandatory access control and rolebased access control. selinux was released to the linux community for enhancement and extension.102one of the major priorities for nsa is the growth of a vibrant civil service cybersecurity research community. to that end, nsa is a supporter of education and capacity building in cybersecurity. the nsa, jointly with dhs, sponsors 75 designated centers as part of its centers for academic excellence in information assurance education (cae/iae) program. this program is part of the broader national information assurance education and training program, which also supports the national colloquium for information systems security education and the national information assurance training and education center.103 no independent assessment of the cae program has been conducted to determine if the requirements are appropriate, applied appropriately, or whether the program is actually helping to achieve its stated goals. some individuals associated with schools in the program have questioned the lack of clear delineation between programs that conduct research and graduate education and those that are primarily vocational in nature. nonetheless, the program has succeeded in bringing attention to educational efforts as little else has done.b.6.4.7 disruptive technology ofce, ofce of naval research, and air force research laboratorythe disruptive technology ofce,104 ofce of naval research (onr), and air force research laboratory through its air force ofce of scientic research (afosr) all support cybersecurity research related to their intelligence and military missions. these agencies have been a source of funding continuity, supporting signicant unclassied education and research in cybersecurity, as well as funding classied research. afosr, for instance, supports the information assurance institute at cornell university. it also supports, with nsf, the trust center (described above). onr manages a major multidisciplinary university research initiative program (funded from the ofce of the secretary of defense) on ﬁsecure mobile code.ﬂ102 see the nsa selinux web page at http://www.nsa.gov/selinux/.103 see http://www.nsa.gov/ia/academia/cisse.cfm and http://niatec.info/.104 formerly known as the advanced research and development activity (arda).toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix b 305b.6.4.8 federal aviation administrationthe federal aviation administration™s cybersecurity efforts are focused on its mission of providing for the safety and security of the faa infrastructure. its cybersecurity research activities ﬁleverage developments by other agencies.ﬂ105b.6.4.9 national aeronautics and space administrationnasa has no project current or planned directly related to cybersecurity. it does support research, such as the high dependability computing project, which addresses another aspect of trustworthy computingšsystem reliability. the project web site notes that ﬁdependability is a major challenge for all complex softwarebased systems. aspects of dependability include safety critical reliability, software safety, high security, high integrity, and continuous operation.ﬂ106105 national science and technology council, federal plan for cyber security, 2006, p. 113.106 high dependability computing project (hdcp); see http://hdcp.org. toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.306although the briefers listed below provided much useful information of various kinds to the committee on improving cybersecurity research in the united states, they were not asked to endorse the conclusions or recommendations of this study, nor did they see the nal draft of this report before its release.briefers and presenters to the committee july 27, 2004  washington, d.c.lee badger, defense advanced research projects agency richard demillo, georgia institute of technology peter freeman, national science foundationelizabeth grossman, house committee on science (majority staff)robert herklotz, air force ofce of scientic research daniel hitchcock, department of energy gary koob, high condence software and systems coordinating group carl landwehr, national science foundation chan lieu, senate committee on commerce, science and transportation (minority staff) douglas maughan, department of homeland security edward roback, national institute of standards and technology brian shaw, central intelligence agency appendix ccontributors to the studytoward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.appendix c 307grant wagner, national security agency brian witten, (formerly) defense advanced research projects agencybriefers and presenters to the committee march 10, 2005 washington, d.c.djenana campara, chief technology ofcer, klocwork, inc.beki grinter, associate professor, college of computing, georgia institute of technology robert rigby, director, managed security services, security operation center, mci briefers and presenters to the committee july 19, 2005 mountain view, californiaalan karp, hewlettpackard, inc. lawrence roberts, anagran, inc.william worley, secure64, inc.toward a safer and more secure cyberspacecopyright national academy of sciences. all rights reserved.