detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/5812computer science and artificial intelligence32 pages | 6 x 9 | paperbackisbn 9780309058315 | doi 10.17226/5812panel on computer science and artificial intelligence, national research councilcomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.computer science and artificialintelligencenrl strategic seriespanel on computer science and artificial intelligencenaval studies boardcommission on physical sciences, mathematics, and applicationsnational research councilnational academy presswashington, d.c. 1997icomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn from the councils of the national academy of sciences, the national academy of engineering, and the institute of medicine.the members of the panel responsible for this report were chosen for their special competences and with regard for appropriate balance.this report has been reviewed by a group other than the authors according to procedures approved by a report review committee consisting of members of the national academy of sciences, the national academy of engineering, and the institute of medicine.the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific andengineering research, dedicated to the furtherance of science and technology and to their use for the general welfare. upon the authority ofthe charter granted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientificand technical matters. dr. bruce alberts is president of the national academy of sciences.the national academy of engineering was established in 1964, under the charter of the national academy of sciences, as a parallelorganization of outstanding engineers. it is autonomous in its administration and in the selection of its members, sharing with the nationalacademy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsors engineering programs aimed at meeting national needs, encourages education and research, and recognizes the superior achievements of engineers.dr. william a. wulf is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy of sciences to secure the services of eminent members ofappropriate professions in the examination of policy matters pertaining to the health of the public. the institute acts under the responsibilitygiven to the national academy of sciences by its congressional charter to be an adviser to the federal government and, upon its own initiative, to identify issues of medical care, research, and education. dr. kenneth i. shine is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology with the academy's purposes of furthering knowledge and advising the federal government. functioning in accordancewith general policies determined by the academy, the council has become the principal operating agency of both the national academy ofsciences and the national academy of engineering in providing services to the government, the public, and the scientific and engineeringcommunities. the council is administered jointly by both academies and the institute of medicine. dr. bruce alberts and dr. william a.wulf are chairman and vice chairman, respectively, of the national research council.this work was performed under department of navy contract n0001493c0089 issued by the office of naval research under contract authority nr 201124. however, the content does not necessarily reflect the position or the policy of the department of the navy or thegovernment, and no official endorsement should be inferred.the united states government has at least a royaltyfree, nonexclusive, and irrevocable license throughout the world for governmentpurposes to publish, translate, reproduce, deliver, perform, and dispose of all or any of this work, and to authorize others so to do.copyright 1997 by the national academy of sciences. all rights reserved.copies available from:naval studies boardnational research council2101 constitution avenue, n.w.washington, d.c. 20418printed in the united states of americaiicomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.panel on computer science and artificial intelligenceruth m. davis, pymatuning group, inc., chairwalter r. beam, alexandria, virginiageorge cybenko, dartmouth collegesteven k. feiner, columbia universityw. michael mccracken, georgia institute of technologybrian p. mccune, mccune & associatesraj reddy, carnegie mellon universityvictor vyssotsky, digital equipment corporationnavy liaison representativespaul g. blatch, office of the chief of naval operations (n911t1)ronald n. kostoff, office of naval researchconsultantsidney g. reed, jr.iiicomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.naval studies boarddavid r. heebner, science applications international corporation (retired), chairgeorge m. whitesides, harvard university, vice chairalbert j. baciocco, jr., the baciocco group, inc.alan berman, center for naval analysesnorman e. betaque, logistics management institutenorval l. broome, mitre corporationgerald a. cann, raytheon companyseymour j. deitchman, institute for defense analyses (retired)anthony j. demaria, demaria electrooptics systems, inc.john f. egan, lockheed martin corporationrobert hummel, courant institute of mathematical sciences, new york universitydavid w. mccall, at&t bell laboratories (retired)robert j. murray, center for naval analysesrobert b. oakley, national defense universitywilliam j. phillips, northstar associatesmara g. prentiss, jefferson laboratory, harvard universityherbert rabin, university of marylandjulie jch ryan, booz, allen and hamiltonharrison shull, naval postgraduate school (retired)keith a. smith, u.s. marine corps (retired)robert c. spindel, applied physics laboratory, university of washingtondavid l. stanford, science applications international corporationh. gregory tornatore, applied physics laboratory, johns hopkins universityj. pace vandevender, prosperity institutevincent vitto, lincoln laboratory, massachusetts institute of technologybruce wald, arlington education consultantsnavy liaison representativespaul g. blatch, office of the chief of naval operations (n911t1)ronald n. kostoff, office of naval researchstaffronald d. taylor, directorpeter w. rooney, program officersusan g. campbell, administrative assistantmary (dixie) gordon, information officerchristopher a. hanna, project assistantivcomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.commission on physical sciences, mathematics, and applicationsrobert j. hermann, united technologies corporation, cochairw. carl lineberger, university of colorado, cochairpeter m. banks, environmental research institute of michiganlawrence d. brown, university of pennsylvaniaronald g. douglas, texas a&m universityjohn e. estes, university of california at santa barbaral. louis hegedus, elf atochem north america, inc.john e. hopcroft, cornell universityrhonda j. hughes, bryn mawr collegeshirley a. jackson, u.s. nuclear regulatory commissionkenneth h. keller, university of minnesotakenneth i. kellermann, national radio astronomy observatorymargaret g. kivelson, university of california at los angelesdaniel kleppner, massachusetts institute of technologyjohn kreick, sanders, a lockheed martin companymarsha i. lester, university of pennsylvaniathomas a. prince, california institute of technologynicholas p. samios, brookhaven national laboratoryl.e. scriven, university of minnesotashmuel winograd, ibm t.j. watson research centercharles a. zraket, mitre corporation (retired)norman metzger, executive directorvcomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.vicomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.prefacethe panel on computer science and artificial intelligence was established in early 1992 by the navalstudies board (nsb) of the national research council in response to a request from the naval researchlaboratory (nrl). the nrl called on the nsb to establish a panel of experts in the fields of computer scienceand artificial intelligence to interact informally with the laboratory's research staff regarding plans, facilities,capabilities, prospects, and problems faced by the represented communities (government, academia, andindustry) and to address the tasks contained in the formal terms of reference. those tasks delineated thefollowing priority topics:ł software production. provide a critical examination of the scientific issues that could be pursued (asopposed to commercial developments that are likely to evolve without fundamental r&d activities).adaptive software (machine learning). what opportunities are envisioned in this area?interface technology. what are the scientific issues that are to be examined over the next decade andwhich hold the potential for providing an improved base for sound developments in this field? whatcenters of activity worldwide are currently active leaders in such activities?speech synthesis/recognition. what fundamental pursuits are likely to lead to further principles in thisfield (as opposed to commercial developments, which will indeed provide more sophisticated systemsunder many conditions)?neural networks. which scientific pursuits are required to place the behavior of these systems on a firmbasis? where are the leadership roles associated with this set of issues?facilities. what facilities are the highest priority to emphasize in furthering the unique strengths that agovernment laboratory brings to this field? which facilities are most appropriate at a university?in addition, communications between timothy coffey, director of research at the naval researchlaboratory, and the panel's chair, ruth m. davis, provided further clarification concerning the terms of referenceand the objectives of the panel: the panel was to provide an outside perspective on key scientific and technicaltopics and to highlight technical opportunities for nrl. in particular, the panel was asked for such perspectivesin the areas of artificial intelligence (ai) and humancomputer interface (hci). the panel was also requested toassess industrial interest in recommended opportunity areas.the panel was not asked to conduct a critical review of nrl's current research program in computerscience and ai/hci and did not do so.the panel performed its task in the course of four meetings: march 2627, 1992, at which discussions wereheld with timothy coffey and presentations were made by nrl's information technology division and humancomputer interface laboratory; june 2425 and september 2829, 1992, at which presentations were made bygovernment and academic experts on computer science and ai research programs; and october 2122, 1992,which included further discussions with timothy coffey.nrl has a considerable investment in computer science and is a node of the u.s. high performancecomputing consortium. its ai research laboratory was established some 20 years ago and is the onlygovernment laboratory of its kind.prefaceviicomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.prefaceviiicomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.contentschapter 1 introduction 1 content 1 selected definitions 1 grand challenge areas 2chapter 2 artificial intelligence and humancomputer interface 4 importance of ai and hci to the department of defense 4 types of investment required for ai and hci 4 general recommendations regarding ai and hci 5chapter 3 grand challenge areas 7 representation and modeling of complex systems 7 collaborative problem solving 8 machine learning and adaptive systems 11 reasoning under uncertainty 12 virtual worlds (reality) 15 neurophysiological models of cognition 17 industrial interest in grand challenge areas 18contentsixcomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.contentsxcomputer science and artificial intelligencecopyright national academy of sciences. all rights reserved.chapter 1introductioncontentthe focus of this report is on artificial intelligence (ai) and humancomputer interface (hci) technology.observations, conclusions, and recommendations regarding ai and hci are presented in terms of six grandchallenge areas which serve to identify key scientific and engineering issues and opportunities. chapter 1presents the panel's definitions of these and related terms. chapter 2 presents the panel's general observations andrecommendations regarding ai and hci. finally, chapter 3 discusses computer science, ai, and hci in terms ofthe six selected "grand challenge" areas and three time horizons, that is, short term (within the next 2 years),midterm (2 to 6 years), and long term (more than 6 years from now) and presents additional recommendations inthese areas.selected definitionsthe scientific and engineering disciplines that make up or are closely allied with ai and hci are ofrelatively recent origin. they date back to the 1950s at the earliest, with the first encyclopedia article on aiappearing in 1967. ai and hci have been rapidly changing and expanding both in intellectual content and inapplication, especially in the last decade. the recent accelerated pace of change has been due in no small part tothe almost breathtaking innovations and product developments in the supporting microelectronics, electrooptics,and display technologiesšall hardwareintensive areas.growth in the amount of new terminology and technical jargon always accompanies such changes andadvances in technology. recognizing the futility of attempts to craft comprehensive definitions in light of theserapid changes, the panel has opted to provide brief descriptions of four frequently used terms: artificialintelligence, humancomputer interface, virtual worlds, and synthetic environments.artificial intelligenceartificial intelligence is the collection of computations that at any time make it possible to assist users toperceive, reason, and act. since it is computations that make up ai, the functions of perceiving, reasoning, andacting can be accomplished under the control of the computational device (e.g., computers or robotics) inquestion.1ai at a minimum includes representations of "reality," cognition, and information, along with associated methods of representation; learning; of vision and language; and (defined below).humancomputer interfacehumancomputer interface (hci) consists of the following: the machine integration and interpretation of data and their presentation in a form convenient to thehuman operator or user (i.e., displays, human intelligence emulated in computational devices, andsimulation and synthetic environments).2 bidirectional communication of information between two powerful1 modification of the definition presented in patrick winston, artificial intelligence, 3rd edition, addisonwesley,reading, mass., 1992, p. 5.2 defense science and technology strategy, office of the secretary of defense, defense research and engineering,washington, d.c., july 1992 (extracts).introduction1computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.information processors: people and computers. information can be in the form of data, symbolicknowledge, or control specifics.3virtual worldsa virtual world, or virtual reality, is a precise recreation of a realworld environment via multisensory dataand computer graphics that allows interaction between humans and synthesized objects. it consists of a set ofmultisensory devices employed as both actuators and effectors. "virtual" is often used synonymously withcomputergenerated or synthetic.synthetic environmentsa synthetic environment is a reconstructed multipurpose environment with a mix of real and computersynthesized (simulated) objects under computer control. it allows interaction between combinations of real andsynthesized objects. a synthetic environment consists of a digital and analog representation of a physicalenvironment with specified fidelity and complexity and is scalable to any size and degree of complexity.grand challenge areasthe grand challenge areas selected by the panel should be understood in the context of the usage of thatterm in the high performance computing and communications (hpcc) 1991 initiative of alan bromley,president bush's science advisor, stated as follows: "the hpcc program is driven by the recognition thatunprecedented computational power and capability is needed to investigate and understand a wide range ofscientific and engineering grand challenge problems. these are fundamental problems whose solution is criticalto national needs."4the panel tailored this concept to its work in the following manner: grand challenge areas are thosefundamental problem areas to which the application of scientific and engineering resources will yield muchneeded improvements in capabilities and performance. they also serve to identify key scientific and engineeringissues and opportunities.in selecting the grand challenge areas, the panel applied the following two constraints:leadingedge technologies were considered, and research and technology application communities had to believe that the grand challenges weresusceptible to resolution and that their resolution would provide demonstrable valueadded to nontrivialuser groups.the panel chose the following six grand challenge areas: representation and modeling of complex systems, problem solving, learning and adaptive systems,under uncertainty, (reality), and models of cognition.panel members concurred that organizing their observations and findings concerning the nrl prioritytopics in the terms of reference (see the preface) according to the grand challenge areas selected would bringfocus to their work and would permit easy presentation of highlights, issues, and highvalue applications.table 1.1 summarizes the relationship of the nrl priority topics to the grand challenges.table 1.1 can be read as follows: software production, particularly for increasingly complex systems,presents challenges in the extensive collaborative and sometimes3 nrl human computer interaction laboratory information brochure, 1991.4 committee on physical, mathematical and engineering sciences, federal coordinating council for science, engineeringand technology, grand challenges: high performance computing and communications, supplement to the president'sfiscal year 1992 budget.introduction2computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.concurrent problemsolving effort involved, and in realistic representation and modeling.5 software for complexsystems also presents challenges in reasoning under uncertainty.6 adaptive software presents challenges inmachine learning and reasoning under uncertainty. interface technology develops collaborative (with the user)problem solving and virtual reality. speech synthesis and recognition present challenges in collaborative problemsolving, machine learning/adaptive systems, reasoning under uncertainty, and virtual worlds. neural networkspresent challenges in machine learning, reasoning under uncertainty, and neurophysiological models of cognition.table 1.1 linkages between grand challenge areas and nrl priority topics.grand challenge areasnrl priority topicsrepresentation and modeling of complex systemssoftware productioncollaborative problem solvinginterface technology, speech synthesis/recognitionmachine learning and adaptive systemsadaptive software, speech synthesis/recognition, neural networksreasoning under uncertaintyadaptive software, speech synthesis/recognition, neural networksvirtual worlds (reality)interface technology, speech synthesis/recognitionneurophysiological models of cognitionneural networksthe sixth topic in the terms of reference was facilities, and the related questions were ''what facilities arethe highest priority to emphasize in furthering the unique strengths that a government laboratory brings to thisfield? which facilities are the most appropriate at a university?" this topic is addressed in the presentation ofeach grand challenge area to the extent possible on the basis of the panel's collective experience.5 computer science and technology board, national research council, scaling up: a research agenda for softwareengineering, national academy press, washington, d.c., 1989, p. 4.6 john e. hopkins and kenneth kennedy, computer science, achievements and opportunities, society for industrial andapplied mathematics, philadelphia, pa., 1989, p. 73.introduction3computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.chapter 2artificial intelligence and humancomputer interfaceimportance of ai and hci to the department of defensefrom the time of the first embryonic computer developments in the late 1940s and early 1950s, dod hasencouraged and sponsored ai and hci r&d in the laboratories of industry, academia, and government.advancements in ai and hci have allowed dod to accelerate work toward its goal of improving nationalsecurity while reducing the risk faced by individuals in hostile environments.this goal has manifested itself in strong support for and pressure to advance technologies that permit total replacement of humans in hostile environments by "satisfactory" perceiving, reasoning, andacting mechanicalelectronic surrogates; permit combinations of robots and humans to carry out needed functions in hostile environments withminimal or much reduced risk to the human; permit remote control of robots or humanrobot systems in hostile environments to substantially reducethe risk to the human; improve dramatically via education and training the capability of humans to perform satisfactorily inhostile environments, principally via simulation, emulation, and modeling processes and procedures; and expedite the design, development, and manufacture of products, systems, and platforms of high qualityin a timely manner and at least cost via concurrent engineering, computeraided design (cad),computeraided manufacturing (cam), flexible computerintegrated manufacturing (fcim), and otherautomated design and production technologies.the hardware, software, reasoning, and representation technologies that make up ai and hci have played asignificant role in approaching this strategic dod goal. relevant technology advances include unmanned vehicles (auvs), design, and platforms, factories, space asset command and control (c2),rformanceenhancing simulation, and remote sensor, weapons, and platform management.with the termination of the cold war, and the resulting reduction in budget, force levels, and manpower,dod has begun placing greater emphasis on technologies such as those just mentioned in order to leverageremaining resources.types of investment required for ai and hcinrl should be aware that two factors will influence the type of investment required for ai and hci, asfollows: is more labor intensive than capital intensive, and hci research isartificial intelligence and humancomputer interface4computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.more capital intensive than labor intensive. ai is dependent upon highperformance computer systems, which fortunately are rapidly decreasing inprice and operating costs. industry competition should continue to drive these costs down.industrial interest in ai and hci can be measured in terms of their use in industrial operations and theextent of external (usually government) funding of industrial programs.ai practitioners and users would concur that ai has an apparently solid future in academia and a bright,expanding future in applications. today ai is pervasive in academic institutions, although its applications areprimarily in industry and government. wellknown and widespread examples of ai applications include thefollowing: expert systems, multisystem analysis, natural language processing, pattern recognition, roboticcontrol, and computer vision.hci is rapidly acquiring all of the attributes of a scientific specialty area of computer science and, accordingto many experts, will shortly be perceived as such. the hardware resource base for hci is shared fairly equallybetween academia and industry.the skill base for ai and hci is currently shared fairly equally between academia and industry.government is primarily an hci customer rather than a research source. the diversity of the required skill basefor ai and hci makes it difficult for a single research organization to sustain the minimum skill requirements.one attractive option is for nrl to form longterm arrangements with other research groups to pool skill basesin order to meet programmatic needs. this pooling is a costeffective means for obtaining more current skillsthan are often available in a government laboratory with a stable professional population and a low attrition rate.fortunately, the growing success of multimedia networking has essentially negated any justification for"owning" all needed skills at one facility. nrl is encouraged to enter into such strategic alliances via multimedianetworking to maintain the necessary diversity in its ai and hci skill base. it is further encouraged to establishjoint projects in as many research or application areas as is feasible. however, the laboratory is cautioned thatcooperative networking programs need to be explicitly defined, with formal, agreedon objectives.general recommendations regarding ai and hcithe panel made a number of observations and reached a number of general recommendations regarding aiand hci: nrl's research program in ai and hci should be goaloriented, with specific, substantive content, andnot simply aimed at maintaining an "awareness" of the ai and hci fields. the ai and hci strategicplanning process therefore would be more akin to a corporate model for planning than to an academicmodel. in support of the navy's many unique and varied operational requirements, nrl should support andpromote ai as a strong research component. linking the strategic planning process to known navyneeds for ai and hci technology, particularly during this period of restructuring and downsizing whenoperational leverage is paramount, will allow nrl to better assess its research and programmaticstrengths alongside those of other defense research centers and laboratories. nrl management should manage and support ai as a recognized scientific specialty area withincomputer science. in doing so, it should be recognized that ai is still immature and is more "science"than engineering in nature. nrl should accelerate its hci programs and support capital investment in hci as a key research areafor a defense laboratory.artificial intelligence and humancomputer interface5computer science and artificial intelligencecopyright national academy of sciences. all rights reserved. hci is dependent upon customized electronic devices and components such as highresolution displaysand interactive electronics and often requires teleoperating and video devices. customized hciequipment rather than high computer power epitomizes hci needs. budgets for both ai and hci shouldreflect the need for periodic equipment replacement and modernization due to the rapid obsolescence ofsupporting equipment.artificial intelligence and humancomputer interface6computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.chapter 3grand challenge areasafter considerable discussion and debate, the following grand challenge areas were selected: representation and modeling of complex systems, problem solving, learning and adaptive systems,under uncertainty, (reality), and models of cognition.each of the six grand challenge areas is discussed in turn in this chapter. for the most part, thesediscussions include a description of the grand challenge area; research objectives over the short term (within thenext 2 years), midterm (2 to 6 years), and long term (more than 6 years from now); ongoing leadingedgeactivities and organizations; needed resources delineated in terms of research skills, facilities, cooperativearrangements and opportunities, and level of effort; and opportunities for nrl.some subjects listed above may not be included in all discussions. the reader is referred to table 1.1 and itsaccompanying discussion in chapter 1 for an explanation of the crosslinkage of the grand challenge areas to thenrl priority topics.the panel recommends that nrl give highest priority to investment and applications in the six grandchallenge areas.the panel's informal assessment of industrial interest in the six grand challenge areas is given at the end ofthis chapter.representation and modeling of complex systemsdescriptionprior to the advent of the computer, traditional engineered systems (e.g., bridges, airplanes, and ships) weremodeled by a mathematical formalism combined with a set of engineering heuristics for how to apply the theoryto given situations. today, we are faced with the design, construction, maintenance, and use of much morecomplex systems. they require representations of the problem that go beyond systems of equations andmodeling techniques and require more than closedform solving, numerical approximation, or numericalsimulation. the dimensions of this complexity can be exemplified as follows: a system today is a heterogeneous system of subsystems, so that no one representation and modelingparadigm suffices. a system is typically controlled by a softwarebased supervisory system that is usually the single mostcomplex subsystem and is best modeled in detail by discrete, logical models rather than continuous,physical ones. one or more human users are part of the overall system and require interactions with the othersubsystems to allow for monitoring and control.the grand challenge is to be able to model entirely in software a range of complex systems. two specificapplication milestones that would validate this achievement are the following: the ability to design and evaluate in software a sophisticated new weapon system, including carryingplatform, sensors, weapons, communications, control systems, and human decision makers. this"prototype before build" capability (smallerscale examples of which include boeing's use of computeraided design (cad), computeraided software engineeringgrand challenge areas7computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.(case), and computeraided manufacturing (cam) in the design of the 777) would help the navy tostay even with rapidly changing threats, technologies, priorities, and budgets. the building of a fully autonomous undersea or air vehicle to perform one mission with reasonablegenerality.research objectivesdesirable research objectives in this area are as follows:short termšintegration of discrete, continuous, and symbolic representations of models.midtermšvalidation of internal consistency and completeness and against external specifications;representation and explanation of complex models to humans; and computationconstrained,satisfactorily approximate solutions based on dynamic, variableresolution models controlled bymetamodels.long termšglobal optimization across complex models; and very high level languages for systemdesign (including decisionsupport software) and theory of model design.ongoing leadingedge activities and organizationstypes of ongoing research activities in this area and organizations involved are as follows: representation activitiesšstanford university and carnegie mellon university,activitiesšbolt, beranek and newman laboratories, software engineering activitiesšdefense advanced research projects agency (darpa) knowledgebased systems application (kbsa) centers, kestrel institute, university of southern california (usc)/isi, stanford university, carnegie mellon university, and harvard university, and hardware computeraided design (cad) activitiesšdarpa centers, stanford university, andcarnegie mellon university.needed resourcesthe necessary ingredients for research in this area are summarized below:skillsšexpert systems, simulation and modeling, automated software design and synthesis, computeraided design, and human physiology.facilitiesšmajor computational resources to execute and validate complex models: distributedworkstations plus parallel computer available over the network could suffice.cooperation opportunitiesšmultiple groups must collaborate to model complex systems (e.g., a ship)because the expertise never resides totally in one organization. two or more research groups couldcollaborate by modeling different subsystems of a problem.level of effortšfor small, theoretical tasks, one person could make progress; large, demonstrationoriented tasks would require a group of at least five, for example, one engineering system researcher,one simulation/modeling researcher, one application expert, one knowledge engineer, and oneprogrammer.collaborative problem solvingdescriptioncollaboration or group work is generally described as a social process used to more effectively performtasks. these tasks include problem solving, idea generation, decision making, and conflict resolution.collaboration includes both formal and informal methods. formal methods can be characterized as structuredcollaboration sessions withgrand challenge areas8computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.predetermined agendas and anticipated results. in contrast, informal methods are generally ad hoc in nature andconstitute much of the daily practice of performing tasks in organizations (e.g., one seeks help from a colleagueon an attribute of a problem one is trying to solve). many researchers are emphasizing informal collaboration asa model of problem solving in organizations. quite often, formal methods are used because of the size of theconstituency needed to solve the problem, the diversity of opinions on its potential solution, and the anticipationof adversarial interactions. although formal and informal methods are very different models of interaction, inactual practice in organizations the methods are often intertwined.understanding how people solve problems is requisite to determining whether or not technologies can aid inthe process. a number of studies comparing problem solving with and without supporting technologies havebeen made over the past several years. many of them have found that formal meetings using group decisionsupport technologies improved the productivity of groups, shortened the time to final decisions, and in somecases quantitatively improved the decisions themselves. these studies have mainly considered formal meetings,where participants were schooled in the technologies, and therefore some researchers have questioned thevalidity of these studies. sociologists, psychologists, anthropologists, and cognitive scientists have beencharacterizing the tasks of groups, but several issues have not been studied in depth. for example, most taskcharacterizations do not include group activities that are important to the conduct of tasks but are not directlyrelated to the tasks, such as learning and interpersonal relationship building. in addition, there has been littlestudy of the impact of collaboration technologies on the problem solving task itself (primarily owing to thecurrent state of the technology).research objectivesthe grand challenge in collaborative problem solving is to provide accurate descriptions of tasks and their interrelationships, tool framework to support multiple decisionmaking models and dimensions, understanding of the impact of group decision support system (gdss) tools on the decisionmakingprocess, of the use of intelligent agents in the decisionmaking process, and of corporate memory into the decisionmaking process.desirable research objectives can be summarized as follows:short termšan example of gdss is ventana corporation's group systems tools, originally developedat the university of arizona and now a commercial product. numerous other commercial gdss toolsare in use in industry and government. most of these commercial tools have been developed by usingthe literature as a guide, even though some of them were originally developed in research environments.at this stage of the technology, most of the systems are based on portrayals of commonly understoodactivities in organizations. elements contributing to decision making, such as brainstorming and voting,are encapsulated in these tools, with the primary objective to preserve information and to force structureon the decisionmaking process.decision making has been characterized as having three dimensions: time (synchronous orasynchronous), locale (collocated or distributed), and group size. research needs to be conducted toverify that these are sufficient parameters, or to add others in order to more accurately describe theimpact of these dimensions on decisionmaking processes and then reflect that research in thetechnologies.grand challenge areas9computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.for example, does a set of tools designed for collocated groups function similarly for distributedgroups with the addition of video and audio support, and do those additions properly rectify the lack ofcollocation?midtermšmidterm research is needed to more properly formulate cognitive models of decision makingin terms of the true interactions of humans and organizations, including studying the impact of thetechnologies themselves on the process. the question of the utility of formal processes also needs to beaddressed. researchers in organizational behavior and management should understand the real needs offormal processes of decision making, since these processes were developed to preserve information,force rigor on the process, and collocate stakeholders to ensure unanimity in the decision. the impact ofdecentralized organizations and the dissolution of hierarchical management techniques will havesignificant impacts on the technologies that were designed for hierarchical decision processes.long termšlongterm research implications are anticipated to be quite complex. questions that couldbe addressed in longterm research include the following: if decision making is supported by intelligentagents incorporated into the tools, what is the impact on the process (e.g., in biasing of decisions orchange of resolution time)? if every element of the process and the results of decisions is preserved(including analysis of all interactions), will decisions ever be made, and if so, will they be moreconservative? if elements of interaction can be appropriately modeled and described, will decisionmaking revert to the highest levels of an organization, or, to put it another way, if decisions can be madeby machine, will empowerment of the employees become a moot point?ongoing leadingedge activities and organizationscurrent leadingedge research activities in this area are being carried out by the following organizations: tech and the university of arizona, centers for information management research; center; corporation;university, denmark;of michigan;packard laboratories; anda partial list of current major users of collaborative problem solving technology includes the following: command; major corporations, including ibm, bellsouth, and boeing; and numerous universities, including the university of arizona, georgia tech, indiana university, and theuniversity of georgia.needed resourcesan effective research program in collaborative problem solving would require skills in the following areas:cognitive science, sociology, anthropology, computer science, organizational behavior, and managementinformation systems.opportunities for nrla number of highly leverageable technologies are applicable to collaborative problem solving, for example,in meetings. traditional meetings are often frustrating and unproductive because of factors such as lack of groupconsensus, poor notetaking, and low group participation. many times, groups become sidetracked. in addition,some participants may have a hidden agenda, while others may be apprehensive about participatinggrand challenge areas10computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.because they are uncertain how their ideas or comments will be received. it has been found that if gdss, alsoreferred to as electronic meeting systems, is used to apply information technology to the meeting environment,group productivity, efficiency, and satisfaction are improved.7 when this technology is used efficiently, meetingsultimately culminate in an effective decisionmaking process by the given group.this technology can be used in any type of decisionmaking process, including procurement decisions,strategic planning activities, planning and implementing of total quality management (tqm) principles, systemand software requirement definition and representation, and war gaming (both adversarial and cooperative).to take best advantage of such technology opportunities, nrl would benefit from having or developing thefollowing critical resources:conduct largescale, longterm case studies;incorporate ai research results into collaborative problemsolving technologies; and connections with major research universities working in the area (e.g., through cooperative sharedagreements).machine learning and adaptive systemsdescriptiona grand challenge for engineering is to design systems that can adapt to and learn from their operatingenvironments. while learning and adaptation are basic capabilities in biological systems, they have beenextremely difficult to implement in synthetic, engineered systems. only recently have the memory andcomputational requirements necessary for minimal learning and adaptation become available. these advanceshave resulted in an explosion of ideas and research in machine learning.specific successful implementations of learning and adaptive systems exist in the areas of supervisedlearning (e.g., the ability to generalize from empirical input/output data), unsupervised learning (e.g., the abilityto categorize unlabeled data using generic clustering concepts), and adaptive filtering and control (e.g., whereplant structural models are known and plant dynamics need to be estimated).in spite of successful applications and a growing body of theory, machine learning and adaptive systemssuffer from having poor models of the underlying problems being solved. there are no universal criteria forcharacterizing one learning problem as being more difficult than another (e.g., in what quantitative measure islearning japanese easier or more difficult than learning to discriminate sonar signals?). while some measuressuch as metric entropy have been proposed, they are theoretical constructs that cannot be applied directly topractical problems. the present situation, in which many methods such as neural networks, casebasedreasoning, and more traditional statistical methods compete on the basis of hyperbole and performance on toyproblems, cannot continue.the grand challenge in machine learning and adaptive systems is to identify a scientific methodology andtheory that characterize classes of practical learning and adaptation problems. these characterizations wouldthen be used to evaluate performance, select solution methods, and eliminate heuristics as much as possible.progress in this area would result in better validation techniques and a guarantee of performance in thenumerous autonomous applications for which learning and adaptation are currently proposed.7 nunamaker, j.f., alan r. dennis, joseph s. valacich, douglas r. vogel, and joey f. george, electronic meetingsystems to support group work, communications of the acm, 34(7), june 1991.grand challenge areas11computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.research objectivesin the three time frames of interest, several research objectives can be suggested:short termša number of navy applications are suitable for solution by machine learning and/oradaptive methods. apply various competing existing learning and adaptation techniques to theseapplications and build a database of performance results.midtermšstudy the performance database and empirically categorize which applications are bestsolved by which methods. develop models for learning and adaptation problems that explain thedatabase results. develop the appropriate mathematical theory to support the models.long termšapply and correct the mathematical models that characterize learning problems on newapplications to verify the theory.ongoing leadingedge activities and organizationstypes of leadingedge research activity and organizations involved include the following: evaluation of classification techniques (lincoln laboratories, r. lippmann), interpretations of neural networks (brown university, s. geman), experiments on neural networks (oxford university, d. ripley), properties of learning problems (at&t bell laboratories, holmdel, v. vapnik), and length learning criterion (ibm san jose, j. rissanen).needed resourcesfor any effective research program in machine learning and adaptive systems, the types and combinationsof resources required can be summarized as follows:skillsšmathematicians, computer scientists, statisticians, engineers, and cognitive scientists need tocooperate in this effort.facilitiesšaccess to navyrelevant applications is essential. significant computer power is needed tosolve realistic applications and perform simulations. such facilities already exist at nrl.cooperative arrangementsšarrangements to share data and approaches with other researchers workingon similar empirical investigations are essential. empirical data can be collected at different sites,providing efforts are coordinated.level of effortšabout three senior researchers and six assistants would be required.opportunities for nrlnrl already has a number of efforts in machine learning and adaptive systems. focusing those activitieswith the goal of discovering models for learning requires better coordination but not necessarily more resources.overall, the field of machine learning is full of techniques but short on methodology. nrl can have significantimpact on the scientific application of existing techniques on real applications problems.reasoning under uncertaintydescriptionmodern problems, including many that face navy planners, are increasingly complex. these complexitiescan be characterized as follows: broad, possibly global, scope; are subtle, timevarying multiple objectives, and different constituenciesgrand challenge areas12computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.in the united states and abroad often have different sets of objectives; some of the simplest and most desirable solutions are not attainable within the constraints that willexist; and effective solutions may require involvement of forces and organizations outside of those that havetraditionally cooperated.methods are available for computeraided solution of even highly complex problems, if (1) they aregoverned by stable constraints or rules; (2) they are solvable using wellunderstood processes and resources,under control of the responsible manager; (3) they are analogous to similar situations within the knowledge orexperience of the manager and organization; and (4) they are subject to little or no uncertainty in knowledge ofthe circumstances.the grand challenges address aspects of the solving of complex problems, through representation andmodeling, collaborative solution, machine learning, and virtual worlds. while few complex problems are withoutsignificant uncertainties, those uncertainties are commonly suppressed in the interest of making the problemeasier, or, at best, the problem is solved for a range of parameters that are presumed to include the uncertaintiesto a satisfactory degree. while such methods are suitable when the nature of the solution is invariant to theuncertainty, they are not satisfying when uncertainty is so great that totally different approaches to solution couldbe required to meet the potential demands.uncertainty takes many forms in solving complex military problems. usually, knowledge is fragmentary.one may know the classes and counts of ships constituting an enemy task force, but not the particular vessels,their state of readiness, ammunition supplies, and other critical information. on the other hand, even theinformation one supposedly has in hand regarding enemy resources may be erroneous. erroneous assessments ofone's own resources or of enemy resources have historically been common in military actions. union generalmcclellan's belief that confederate troops near richmond in 1862 outnumbered his own, though quite incorrect,led to a reticence to attack and allowed lee's much smaller army to chase him away from threatening richmond.further uncertainty may be imposed by deliberately deceptive actionsšanything from decoy weapons to radioreporting of nonexistent activity. overall, the battle manager must deal with uncertainties in everything from thecapabilities of the opposable forces to the objectives of the enemy (or even of some of the forces reporting tohim).not all of the uncertainty needs to be dealt with at the same time. in military activity, uncertainty prior toaction often occurs in understanding the circumstances and objectives of an opponent or in assessing one's owncapabilities and limitations. during military actions, a high level of confusion in reports of sightings and actionsis not uncommon. the toplevel realities of the drama are seldom perceived correctly by the individual players,and even the sequence of events is sometimes unclear from firsthand reports.preaction knowledge of the enemy is based on surveillance or military intelligence. knowledge of one'sown resources relies on complete, unbiased reporting of readiness by one's own commanders. during militaryaction, new information arrives through the agency of command, control, and intelligence (c2i) systems.it is probably easiest to find examples of uncertainty in intelligence activities. examples abound fromearlier wars; for example, the misreporting of cruisers as aircraft carriers (or the converse) was not uncommon inworld war ii. during the cold war, continuing intelligence interest in the numbers and capabilities of sovietintercontinental ballistic missiles (icbms), sealaunched ballistic missiles (slbms), and other hightechnologyweapons was thwarted by the secrecy of the soviet union.it has already been established in dod longterm intelligence activities that rulebased expert systems haveutility for weapon system identification using familiar modes of observation. there is much less experience andgrand challenge areas13computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.little confidence in approaches for reasoning under uncertainty in the nearrealtime decisions of military tacticalmanagement. there, both the situation itself and reports about it are changing. if battle managers are to makerational decisions, they must reason under uncertainty and with time constraints.an idealistic way of phrasing the grand challenge in this area is to provide means whereby a militarycommander can make optimal use of all available valid and timely information. implied in this objective is notonly the ability to recognize uncertainty, but also the ability to use redundancy in data from reliable independentsources to reduce that uncertainty.this is a multifaceted problem area. the nature of its solutions may, likewise, be manifold. an approach inwhich a powerful computer suggests a specific action and adds ''trust me!" is clearly not acceptable. theknowledge and wisdom of human decision makers must be incorporated in the outcomes. if there are manyhuman experts involved, some form of "calibration" of their opinions and judgment is desirable.research objectivesshort termšin the short term, it is difficult to identify specific objectives. for one thing, the scope ofthe set of problems is so great that subsets of interest to the corporate navy need to be defined. one ofthe possible subareas would be the application of belief theory (of which the dempstershafferapproach may be the best known) to characterize the confidence of estimates. this could be used, forexample, to calibrate intelligence estimates based on (belief) characteristics of the estimators. it couldalso be used by a decision maker to determine, in comparison to contemporary or historical norms, ifhis or her decision is aggressive or nonaggressive, timely (or precipitate or slow), and where its weakestaspects may lie.for intelligence applications, applied research could address reduction of uncertainty in both automated andhuman reports. if, for example, the limitations of sensors are properly incorporated in fusing their data, moreaccurate assessment should be possible.we have traditionally relied on human interpreters to scan sensor imagery. this too is a case of reasoningunder uncertainty, since the objects of interest may be hidden or camouflaged and the image quality may benaturally limited by range, bandwidth, and/or atmospherics. large differences are seen in human ability torecognize militarily significant objects in infrared imagery. however, whether the next logical step would be toprovide automation aids for human or interpreters or to scan and analyze electronically is not clear. althoughaccuracy is uncertaintylimited in this application, credible research must deal with realistic constraints andobjects.a possible set of objectives can be delineated as follows for the midterm and long term:midtermšdevise metrics appropriate to comparison of traditionally incommensurate information anddevise computerapplicable representation algebra(s) that will permit manipulation of currentlyincommensurate sets of related data, which can probably reduce uncertainty in individual data,preferably using methods faster than enumeration.long termšdevise computational methods that permit the combination of incomplete and/or incorrectdata from multiple contemporary observations, context description, and historical experience todemonstrably reduce thegrand challenge areas14computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.uncertainty in situations or events described by current data.ongoing leadingedge activities and organizationstypes of activities in this area, and organizations and individuals involved, include the following: and mason university, d. schum.needed resourcesfor an effective research program, the following kinds of resources are needed: expertise in representational and computational algebras, application expertise in numerical analyses and computer problem solving, or tactical data streams as well as business data suitable for use as source, and computing power.these resources are available or accessible to nrl by cooperative arrangements.virtual worlds (reality)descriptionthe scientific and engineering area is concerned with the development of knowledgebased multimediainterfaces that support realtime intersection with true threedimensional input and output devices.the current state of the art in commercial user interfaces emphasizes the use of twodimensional windows,with which users interact by using twodimensional devices such as "mice." even users of threedimensionalgraphics workstations usually view graphics whose projections appear in twodimensional windows and aremanipulated under mouse control. research in threedimensional user interfaces addresses the use of interactivethreedimensional graphics, coupled with true threedimensional stereo displays and threedimensionalinteraction devices that monitor the user's movements in threespace, as well as threedimensional audio andhaptic feedback. the goal is to harness the physiological capabilities and training that enable us to performphysical tasks effectively in three dimensions and apply them to develop effective user interfaces for computerbased tasks.for an informationintensive user interface to be effective for a wide range of situations and users, it mustbe able to information to people onthefly, using multiple output media and user input couched in multiple input media. to meet these requirements, a system must generate technical material in real time in each individual output medium (written text, speech, staticgraphics, and animation), understand technical material in real time in each individual input medium with performance equal tothat of a human expert, and coordinate realtime generation and understanding of multimedia interactions with humans, combiningmultiple input and output media, with performance equal to that of a human expert.research objectivesthe set of suggested shortterm, midterm, and longterm objectives considered in totality is as follows: develop realtime operating system support for highly parallel asynchronous input (from large numbersof threedimensional trackers) and output (to multiple display modalities).grand challenge areas15computer science and artificial intelligencecopyright national academy of sciences. all rights reserved. build effective "augmented realities" that enrich the user's existing environment with additionalinformation, merging synthesized material with what the user normally sees, hears, and feelsšoverlaying or replacing it, as appropriate. develop better hardware that produces highquality, highresolution, widefield displays (graphics,sound, haptic, and temperature) and tracking (hand, body, and eye). for example, there is a key need for"seethrough" displays whose images are overlaid on the environment to build "augmented realities." ageneralpurpose visual display technology must allow differential visual accommodation, correspondingto real and virtual objects at different distances in the same image. it must also be able to perform fullvisiblesurface determination with all objects, both real and virtual. virtual objects should be able toocclude real objects, and real objects should be able to occlude virtual ones. determine how to map abstract task domains effectively to a threedimensional environment in which itwill be possible to visualize and manipulate objects in the domain. determine how to take advantage of the richness of threedimensional gesture to reduce reliance onicons to express actions in current user interfaces. for example, rather than moving an item to the "trashcan," it may be disposed of by using an appropriate gesture. determine how to ensure that threedimensional user interfaces will be usable, especially in anenvironment that supports enduser programming and customization. the problem is that in a world ofwholebody computer interaction, there may no longer be any distinction between human factors (asusually understood) and the human factors of computer interfaces. the existing hardware that limitscapabilities (and that also limits mistakes) will be gone. apply ai techniques (e.g., interactive knowledgebased generation and understanding) to design virtualworlds for visualization automatically. design highquality multimedia systems, but only after designing systems that function well in a singlemedium. proceeding in this fashion is particularly important with regard to knowledgebasedinformation presentation systems. improvements are needed in the ability to perform highqualitygeneration and understanding in individual media. there is much work to be done in generation andunderstanding of individual media, ranging from those media that have long been explored by airesearchers (e.g., written text and speech) to less wellcharted terrain (e.g., graphics, audio, and haptics). develop methods to predict and evaluate presentation quality. the system should be able to predict thequality of a presentation in the course of designing it (and, on the basis of these predictions, to refine thepresentation until it is adequate). this requires the ability to evaluate the presentation, estimating how it"will" affect the user (and evaluating the user's response, estimating how it "has" affected the user). theability to evaluate the presentation makes possible timequality tradeoffs. for example, in a crisissituation, a timely rush job might be preferred over a later, higherquality presentation. develop generation and understanding capabilities for temporal media (media in which informationcontext is presented over time in a way that is controlled explicitly by the producer) in animation,speech, and audio. issues here include how to phrase information (e.g., for maximal comprehension).for example, the ability must be developedgrand challenge areas16computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.to generate output and understand input that communicates complex temporal relations. develop facilities for coordinated generation and understanding of multiple media. the key challenge isto ensure that material in different media reinforce rather than interfere with each other.ongoing leadingedge activities and organizationsleading groups and their area of activities include the following:universityšthreedimensional user interfaces (visual displays); universityšthreedimensional ui, virtual worlds, multimediavi (mmvi), mmui;künstlichen intelligenz (saarbrücken)šmmui; t.j. watsonšvirtual worlds;amesšvirtual worlds;of north carolinavirtual worlds, threešdimensional ui;of pennsylvaniašthreedimensional ui, virtual worlds;of washingtonšvirtual worlds; and centeršthreedimensional ui.needed resourcesin order to do effective research in this area, the following types of resources are required:skill basešcomputer scientists, cognitive scientists, electronic engineers, optoelectronic engineers, andapplication area specialists.equipmentšhighperformance, threedimensional workstations and threedimensional interaction anddisplay devices (e.g., graphics, sound, and touch).these resources exist within or are accessible to nrl through cooperative arrangements.neurophysiological models of cognitiondescriptioncurrent approaches to humancomputer interfaces are largely based on traditional sensory capabilities, thatis, sight, sound, and touch. there is much commercial and research activity exploring those interfaces. thisgrand challenge goes beyond those ideas and proposes to explore internal neurophysiological representations ofknowledge with the ultimate goal of using such representations for direct lowlevel computer interactions withthe human nervous system. by the same token, understanding the internal representation of knowledge will belikely to result in better computer implementation of learning, cognitive, and other intelligent functions.this challenge is timely. the past two decades have witnessed significant progress in our understanding ofthe biological mechanisms for memory, learning, and sensory processing. most of that progress has been at thelowlevel, neuronal level, whereas correlations with higherlevel functions and representations useful forcognition and intelligence are not yet understood. accelerating the study of those correlations will allow moredirect humancomputer interfaces to be implemented.notable examples of these ideas are already being explored. preliminary studies of semiconductor chipimplants into neuronal tissue are being studied for motor control interfaces (at dartmouth medical center andstanford university). moreover, the use of the electroencephalographic (eeg)type readings of brain activity hasallowed researchers to interface thought patterns directly with computer input (at fujitsu laboratories in japan).these are but two examples of researchers attempting to bridge the gap between lowlevel neural activity andhigherlevel functionality.continued progress will require collaboration among neurophysiologists,grand challenge areas17computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.computer scientists, electrical engineers, mathematicians, and psychologists. success will enable thedevelopment of more efficient humancomputer interfaces that occur at a lower level and the design of betterperforming artificial intelligence systems.research objectivesthe following objectives are suggested for research in this area:short termšorganize an interdisciplinary nrl team to select a specific cognitive function and/orknowledge representation. models for that phenomenon are formulated. experiments and equipment totest those models are designed.midtermšperform experiments to validate hypothesized models. models are modified and retested.development of novel interface technology coincides with experimentation.long termšimplement technology to use verified models for lowlevel humancomputer interfaces innavy applications.ongoing leadingedge activities and organizationstypes of research and institutions and individuals involved include the following: models of the ear (n. kiang, massachusetts general hospital), neural chip implants (j. rosen, dartmouth medical school and white river junction va hospital; g.kovaks, stanford university),and ear (c. mead, california institute of technology), interface (fujitsu laboratories, japan), and electrical stimulation and cardiomyoplasty (various engineering and medical schools).needed resourcesfor effective research in this area, the following kinds of resources are needed:skillsšthis research is best carried out by teams whose members are versant in neuroscience,physiology, signal processing, control theory, computer science, and mathematical modeling andinstrumentation.facilitiesšan effort encompassing all aspects of the challenge would most likely consist of teammembers who have access to dedicated facilities. wet laboratories for experimenting with live tissuemight be best located in hospitals or medical schools. modeling and computing facilities can be offsite.fabrication of interface instruments will probably require machine room capabilities typically found atnrl and other engineering research laboratories.cooperative arrangementsšarrangements to share data and approaches with other researchers workingon similar empirical investigations are essential. empirical data can be collected at different sites,providing coordination is made.level of effortšfive senior scientists distributed over the technical areas, ten research associates, andfive technicians are required for a sustained multiyear effort.opportunities for nrlnrl has significant inhouse expertise in neural networks, control, cognitive science, and instrumentation.with unique access to navy applications, the laboratory can develop its research program in this direction andplay a leading role in future opportunities as the field opens up.industrial interest in grand challenge areasthe panel's informal assessment ofgrand challenge areas18computer science and artificial intelligencecopyright national academy of sciences. all rights reserved.industrial interest in the six grand challenge areas is as follows:representation and modeling of complex systemsšconsiderable and increasing interest by industry,collaborative problem solvingšconsiderable and increasing interest by industry,machine learning and adaptive systemsšsignificant interest and investment by industry,reasoning under uncertaintyšsome interest by industry but no trend apparent in industry,virtual worlds (reality)šsignificant interest and investment by industry and a growing consumer andcommercial market envisioned by industry, andneurophysiological models of cognitionšlittle interest by industry.grand challenge areas19