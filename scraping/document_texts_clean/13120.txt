detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/13120communicating national science foundation science andengineering information to data users: letter report31 pages | 8.5 x 11 | paperbackisbn 9780309210034 | doi 10.17226/13120panel on communicating national science foundation science and engineeringinformation to data users; committee on national statistics; national researchcouncilcommunicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 1 committee on national statistics the keck center panel on communicating nsf science and engineering information to data users 500 fifth street, nw washington, dc 20001 phone: 202 334 3096 fax: 202 334 3751 www.nationalacademies.org/cnstat march 9, 2011 dr. lynda carlson director national center for science and engineering statistics national science foundation 4201 wilson boulevard, suite 965 arlington, va 22230 dear dr. carlson, this letter report from the panel on communicating national science foundation (nsf) science and engineering information to data users recommends action by the national center for science and engineering statistics (ncses), formerly the division of science resources statistics (srs), on four key issues: data content and presentation, meeting changing storage and retrieval standards, understanding data users and their emerging needs, and data accessibility. the panel members are listed in appendix a. the recommended actions in this letter report can be considered as preliminary steps for ncses to prepare for initiatives that will foster a transition from current practices and approaches to an improved program of data dissemination. these and other issues will be discussed in the panel™s final study report, which is scheduled to be issued in mid2011. this letter report also includes a summary of the workshop that was held on october 27œ28, 2010; see appendix b. the workshop focused on the several aspects of the ncses™s current approaches to communicating and disseminating statistical informationšincluding ncses™s information products, website, and database systems. it included presentations from ncses staff and representatives of key user groupsšincluding the academic research, private nonprofit research, and federal government policymaking communities; see appendix c for the workshop agenda. panel charge and issues the ncses, as a means of fulfilling its mandate to collect and distribute information about science and engineering enterprise for the national science foundation, conducts an ambitious program of data dissemination in several formats: hardcopy and electroniconly publications, an extensive ncses website, and two tools that are used to retrieve data from the ncses database: the integrated science and engineering resource data system (webcaspar) and the scientists and engineers statistical data system (sestat). these outputs and tools serve a broad community of information users, with wideranging data needs, statistical knowledge, access preferences, and technical abilities. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 2our panel was asked to review the ncses communication and dissemination program that is concerned with the collection and distribution of information on science and engineering and recommend future directions for the program. specifically, we were asked to:  review ncses™s existing approaches to communicating and disseminating statistical information, including the center™s information products, website, and database systems. [this review will be conducted in the context of both current ﬁbest practicesﬂ and new and emerging techniques and approaches.]  examine existing ncses data on websites, information gathered by and from ncses staff, volunteered comments of users, and input solicited by the panel from key user groups and assess the varied needs of different types of users within ncses™s user community. consider the impact that current federal and nsf website guidance and policies have on the design and management of ncses™s online (internet) communication and dissemination program.  consider current research and practice in collecting, storing, and utilizing metadata, with particular focus on specifications for social science metadata developed under the data documentation initiative (ddi).  consider the impact of governmentwide activities and initiatives (such as fedstats and data.gov) and the emerging user capability for online retrieval of government statistics.  improving data delivery, presentation, and quality  in their presentations to the panel, the ncses staff produced a large hardcopy stack of tabulations, noting that the stack represented just one of the center™s periodic reports. the staff also noted that, even though the center has largely shifted to electronic dissemination, the dictates of data accuracy and reliability require that a great deal of ncses time is spent in checking data and formatting the data for print and electronic publication.1 for example, each page of the hard copy must be checked by someone looking at the source data. this effort comes at the expense of ensuring data integrity at the source. we believe this emphasis is misplaced. although it will never be possible to fully avoid edit and quality checks because errors are prone to creep into data at any stage in processing, there is much to be gained by focusing primarily on the quality of the incoming ﬁrawﬂ data from the source. this approach is best ensured by adopting a comprehensive database management framework for the process, rather than the current primary focus on review of the tabular presentation. a framework that ensures integrity of the data at the source of the data, buttressed by the availability of metadata (that is, data about the data), is the necessary foundation of real improvement in data dissemination.  recommendation 1: the national center for science and engineering statistics should transition to a dissemination framework that emphasizes database management rather than data presentation and strive to ensure integrity of the data at the source. all of the tables published by ncses are selections, aggregations, and projections of the underlying microlevel observations. the recommendation above envisions that, wherever  1this information is based on the nsf presentation to the panel, slide numbers 14œ16. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 3possible, published tables should be defined explicitly in these terms and produced by an automated process that includes metadata. the panel acknowledges that in some casesšsuch as the ncses™s science and engineering indicatorsšthis approach may not be feasible since an extensive data appendix is necessary to support the analysis in the report. however, in general, a web release (following the practice that ncses currently employs for the most detailed statistical tables) of the raw data will reduce the burden on ncses™s staff and will form the basis of a transition from ﬁtablesﬂ to ﬁinformationﬂ and provide the users with more timely information. this structured approach to release of data will also provide transparency in the process, and assuage any user concerns about the delay between data collection and its availability. in its presentations, ncses staff stressed that they are a comparatively small organization with limited resources. one way that these limited resources could be stretched is for ncses to consider digital distribution channels, including enhanced use of pdf files and, after investigation of cost and benefits, perhaps facilitating printondemand publication. ncses may wish to consider turning to the printondemand technology of the u.s. government printing office as a potential means of controlling the costs associated with printing and distributing the few remaining hardcopy reports that it produces. it is important that the data provided by contractors to ncses include machinereadable metadata that capture the statistical properties of the data and of the collection and research design. the appropriate form and content of these metadata are being considered in the federal statistical agencywide statistical community of practice and engagement (scope) initiative, which was discussed by ron bianchi (representing the economic research service of the u.s. department of agriculture) at the workshop (see appendix b). it is likely that such metadata are produced in the data collection process, since computerassisted telephone interviewing (cati) and other related survey tools use much of this information in their operations. however, metadata are currently not included in the required deliverables to nsf from contractors. the shift to increased provision of raw data is potentially a major and significant enhancement, that has the potential to offer great direct benefit, but such a change will also require consideration of secondorder effects. care will need to be taken to ensure that data confidentiality is assured when providing users with crosssource microdata: consequently, rules about publishable cell size, for example, will have to be carefully considered.2 the greater transparency inherent in making more raw data available also increases the risk that users could juxtapose data in ways that lead to invalid interpretations, though this danger can certainly be lessened by the accessibility of robust metadata that explain the meaning (and limitations) of the data. the current state of metadata technology permits tagging the data items with permanent uniform resource locator (url) and uniform resource identifier (uri) codes that enable identifying the source and meaning of the data items.   2several reports of the committee on national statistics address the need to maintain the confidentiality of data provided to government agencies in confidence: national research council (1979), privacy and confidentiality as factors in survey response (washington, dc: national academy press); national research council (1993), private lives and public policies: confidentiality and accessibility of government statistics, panel on confidentiality and data access, g.t. duncan, t.b. jabine, and v.a. dewolf, eds. (washington, dc: national academy press); national research council (2009), protecting student records and facilitating education research: a workshop summary, m. hilton, rapporteur (washington, dc: the national academies press); and national research council (2010), protecting and accessing data from the survey of earned doctorates: a workshop summary, t.j. plewes, rapporteur (washington, dc: the national academies press). communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 4another positive benefit of providing transparency and tools for exploratory access to data is that users will be in a position to identify errors in the data, and ncses should be prepared to solicit and accept error reports and make corrections as necessary. clearly, when the general public has access and tools to combine data across data sources there will be additional questions about data accuracy and usefulness, and ncses will need to do its best to educate users and respond to users™ discoveries. finally, when considering data release and management, it is important to have a longterm data management plan. yet according to staff, the ncses™s current approach to archival issues is ad hoc. in view of the importance of these data for historical reference, longterm archival access is needed, and it could be assured through proper policies and practices. at a minimum, all of the collected data and publications should be scheduled for retention by the national archives and records administration. in this regard, the nsf sustainable digital data preservation and access network partners (datanet) initiative is a ready inhouse source of information on best practices and tools for implementing an active archival program.  modernizing data capture, storage, and retrieval  emerging technologies for data capture, storage, and retrieval will dramatically change the context in which ncses will provide data to users in the future. for ncses, the key to taking advantage of these technologiesšwhich are designed to increase the efficiency of data capture, storage, and retrieval and to permit users to access the data interactively (such as with web 2.0)šis to focus on procedures for entry of the raw data into the system. it is critically important that data enter the system in as disaggregated form as possible. furthermore, it is critically important that the data be accompanied by the machineactionable documentation (metadata) needed to establish the data™s history of origin and ownership (know as provenance) and to include a record of any modifications made during data editing and cleanup. the documentation also needs to include the measurement properties of the data with sufficient detail and accuracy to enable publicationready tables to be automatically generated in a statistically consistent manner. the data also need to be able to take advantage of the web development capabilities embedded in data.gov and other emerging dissemination means to ﬁmashupﬂ data sources (a web page or application that uses and combines data, presentation, or functionality from two or more sources to create new services). these capabilities, incorporating such tools as open application programming interface (api), enrich results and enhance the value of the data to data users. unfortunately, ncses is not very well positioned to take advantage of these new developments because the survey data that are entered into the center™s database are received from the survey contractors in tabular format (though machine readable) rather than in an easily accessible microdata format. this is not unique to the science and engineering data. the committee heard from suzanne acar (representing the u.s. department of the interior and the federal data architecture subcommittee) that this is a governmentwide issue, one which will be taken up by a group of the world wide web consortium (w3c),3 which has plans to develop contract templates to enable governmental organizations to properly specify the format for receipt of the data from their contractors. ron bianchi (representing the economic research service of the  3w3c is an international community of member organizations, a fulltime staff, and the public to develop web standards: see http://www.w3c.org [november 2010].communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 5u.s. department of agriculture) stated that this is also a concern for the newly formed statistical community of practice and engagement (scope), and that current plans for this coordinating activity that involves most of the large federal statistical agencies include developing a template for contract deliverables specifications.  recommendation 2: the national center for science and engineering statistics should incorporate provisions in contracts with data providers for the receipt of data in formats, and accompanied by metadata, that will allow efficient access for thirdparty visualization and integration and the use of analysis tools. implementing this recommendation will be no simple task for ncses. currently, ncses manages 13 major surveys, involving contracts with five private sector organizations and the u.s. census bureau: see table 1. furthermore, adding this requirement may initially incur additional costs to support a shift from the current practice of formatting the data after it is received to requiring contactors to input the data in a new format. to enable the receipt of metadata from contractors in a universallyaccessible format, ncses will need to adopt an electronic data interchange (edi) metadata transfer standard. the selection and adoption of a metadata transfer standard would be more effective if ncses accomplished this through participation in a governmentwide initiative, such as the w3c contract template development, or the scope effort focused on the federal statistical agencies.  understanding data users and their emerging needs  ncses is strongly committed to serving the needs of data users, but it has little evidence of how well it is meeting those needs. ncses has made several notable attempts to gather this intelligence about user needs, but it does not have a formal, consistent, structured, and continuing program for doing so. one problem for ncses is that there are multiple levels of users for which products must be developed. for the most part, outreach efforts have been addressed to primary users, who are mostly researchers and analysts of research and development (r&d) expenditures and the r&d workforce. these users represent the most visible of usersœresearchers and analysts in the federal agencies that support government science and engineering analysis, in academia, and in the private sector. (several of these users gave presentations at the workshop). however, the needs of a group of secondary users (those who rely on ncses products to understand and gauge the implications for programs, policy, and advocacy) and tertiary users (such as policy makers and librarians) are given less attention, mostly because outreach to these groups is so difficult. it is incumbent on ncses to consider the needs of all of these groups and the technology platforms they use to access the data as ncses considers the program of measurement and outreach discussed in this letter. ncses could consider novel means of harvesting information about data use to analyze usage patterns, such as reviewing citations to ncses data in publications, periodicals, and news items. reaching out to document librarians and other secondary users by means of surveys or interviews would be another worthwhile initiative. one means of assisting in assuring that the needs of the secondary and tertiary data users are met is to assure that programs of outreach are specially directed to members of the mediašthose who rerelease the ncses data and interpret them to the public. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 6among the tools that ncses has used to assess user needs, according to john gawalt (ncses program director for information and technology services at the time of the workshop), are a web statistics analysis program that analyzes web server log file content and displays the traffic information on the basis of the log data (urchin) and software that collects and presents information about user behavior on its website (webtrends). with proper permissions and protections, ncses is also contemplating using cookies to identify return users and increase the efficiency of filling data requests. it also has plans to sponsor and field a customer survey to formally measure satisfaction. in seeking a model for outreach to users, ncses could consider modeling its efforts on the very aggressive program of statistics canada, described at the workshop by panel member diane fournier. statistics canada uses a combination of online questionnaires and focus groups to assess user needs and the usability of its website. the information has been used by statistics canada to develop a profile of its users and how they access the database. one advantage of this approach, although it is resource intensive, is the possibility of gathering use information from a wide range of users, both from those who are knowledgeable and regular users and from secondary and tertiary users who are less familiar with the data.  another initiative that ncses could undertake to better determine user needs is to renew the data workshops that ncses conducted for several years but have been discontinued. those workshops brought together users and potential users of licensed data. this same approach could be useful for acclimating users to webbased data, and to introduce frequent users to changes in data dissemination practices and procedures. such data workshops would be a good way to find out how knowledgeable data users use ncses data and to find out what concerns users have about the data. recommendation 3: the national center for science and engineering statistics should proceed with its plans to conduct a customer survey through use of an online questionnaire; should analyze patterns of data use by web users; and should consider reinstating the program of user workshops in order to educate users about the data and to learn about the needs of users in a structured way.  data accessibility  the panel heard from judy brewer (director of the web accessibility initiative [wai] at the w3c) on the issue of accessibility of information on the web. her presentation and the discussion that followed the presentation raised several important issues. the convention when considering web design for individuals with disabilities is to ensure that the site is accessible to those who are visually impaired. however, there is a much wider range of ways in which someone™s accessibility to information should be considered when developing websites and web applications. for example, a chart that is color coded may not be readily interpreted by someone with color blindness, multimedia files may not be accessible to someone who is deaf unless they are accompanied by transcripts, and someone with a cognitive disability such as attention deficit disorder may find websites that lack a clear and consistent organization difficult to navigate. a range of guidance materials are available for developing accessible websites. section 508 of the 1998 amendments to the u.s. rehabilitation act (29 u.s.c. 794d) governs the accessibility of electronic and information technology for people with disabilities, and specifies communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 7the minimum standards for accessibility.4 other standards include the ﬁweb accessibility initiativeﬂ of w3c, which provides guidance and tools for a range of websites and applications. even more significant, given the possibility for rich dynamic interaction with these data resources, is that w3c has also developed standards for access to dynamic content, with specific guidelines in four categories:  accessible rich internet applicationsšaddress accessibility of dynamic web content, such as those developed with ajax, dynamic html, or other such technologies; authoring tool accessibility guidelinesšaddress the accessibility of the tools used to create websites; user agent accessibility guidelinesšaddress assistive technology for web browsers and media players; and  web content accessibility guidelinesšaddress the information in a website, including text, images, forms, and sounds.  in addition to issues of the usability and navigability of websites and web applications, there are issues related to the use and navigation of the datasets. tabular data formats can be difficult to understand for those who must use screen readers, and data that are not organized in a transparent or immediately understandable way may be of limited or no utility for users with cognitive disabilities. through this presentation and the panel™s subsequent discussion, it became clear that the issue of the accessibility of tabular data and data visualization is a research question. although w3c has pioneered standards for accessibility of dynamic user interfaces, many other issues including table navigation, navigation of large numeric datasets, and dynamic data visualization raise computerhuman interaction challenges that have been explored only peripherally. the issue of accessibility is a clear opportunity for nsf to partner with scientists with disabilities and those who work on interface design and so lead by example.  recommendation 4: the national science foundation should sponsor research and development on accessible visualization and other means for exploring tabular data. the panel recognizes that such a farreaching initiative is almost certainly beyond the capability and resources of ncses, and so our recommendation is to the national science foundation. a program of research and development might fit well into the portfolio of other nsf units and could be considered for funding under such programs as the broadening participation research initiation grants in engineering program. the importance of promoting scientific visualization as an aid to usability and accessibility is a recognized component of nsf™s cyberinfrastructure vision5 and is inherent in its humancentered computing cluster initiatives. although nsf is not in a position to pioneer tool development, identifying the appropriate research areas is something that will have a major impact in the field. ncses could share the knowledge gained through these research and development activities with the broader community of practice and so have a major impact on a wide range of   4a summary of section 508 is available online at http://www.section508.gov/index.cfm?fuseaction=stdssum [november 2010]. 5national science foundation, cyberinfrastructure vision for 21st century discovery, march 2007, p. 28. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 8potential users of ncses™s data (as well as other statistical datasets), thus making the data available to potential users for whom they are now inaccessible. as a final note, the panel wishes to commend ncses for encouraging this review of its dissemination practices. this is a particularly opportune time for incorporating lessons learned in several u.s. and international initiatives that are designed to increase the transparency, usability and accessibility of government data. implementing the recommendations in this interim report will go a long way toward laying the basis for significant improvements in the way center data are disseminated.  sincerely yours, kevin novak, chair panel on communicating nsf science and  engineering information to data users   attachments: appendix ašpanel members appendix bšworkshop summary appendix cšworkshop agenda communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 9table 1 summary of selected characteristics of nsf science and engineering surveys survey current contractor database retrieval tool/ publication availability of microdata series initiated/archivingeducation of scientists and engineers survey of earned doctorates  national opinion research center (norc) webcaspar; infobriefs; science and engineering degrees; science and engineering indicators; women, minorities, and persons with disabilities in science and engineering; doctorate recipients from united states universities: summary report; academic institutional profiles access to restricted microdata can be arranged through a licensing agreement; a secure data access facility/data enclave providing restricted microdata access is under development with norc 1957 (conducted annually, limited data available 1920œ1956) survey of graduate students and postdoctorates in science and engineering rti international webcaspar; infobriefs; graduate students and postdoctorates in science and engineering; science and engineering indicators; women, minorities, and persons with disabilities in science and engineering; academic institutional profiles data for the years 1972œ2008 are available in a public use file format 1975 (conducted annually) science and engineering workforce survey of doctorate recipients norc sestat; infobriefs; characteristics of doctoral scientists and engineers in the united states; science and engineering indicators; women, minorities, and persons with disabilities in science and engineering; science and engineering state profiles access to restricted data for researchers interested in analyzing microdata can be arranged through a licensing agreement 1973 (conducted biennially) national survey of recent college graduates mathematica policy research, inc., and census bureau sestat; infobriefs; characteristics of recent science and engineering graduates; science and engineering indicators; women, minorities, and persons with disabilities in science and engineering access to restricted data for researchers interested in analyzing microdata can be arranged through a licensing agreement 1976 (conducted biennially) national survey of college graduates census bureau sestat; infobriefs; science and engineering indicators; women, minorities, and persons with disabilities in science and engineering public use data files are available upon request 1962 (conducted biennially) communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 10 research and development funding and expenditures business research and development and innovation survey (brdis) census bureau iris; infobrief; business and industrial r&d; science and engineering indicators; national patterns of research and development resources; science and engineering state profiles census research data centers 1953 (conducted annually) survey of federal funds for research and development synectics for management decisions, inc. webcaspar; infobrief; federal funds for research and development; science and engineering state profiles; science and engineering indicators; national patterns of research and development resources data tables only 1952 (conducted annually) survey of federal science and engineering support to universities, colleges, and nonprofit institutions synectics for management decisions, inc. webcaspar; infobrief; federal science and engineering support to universities, colleges, and nonprofit institutions; science and engineering state profiles; science and engineering indicators; national patterns of research and development resources data tables only 1965 (conducted annually) survey of r&d expenditures at federally funded r&d centers icf macro webcaspar; infobrief; r&d expenditures at federally funded r&d centers; academic research and development expenditures; science and engineering indicators; national patterns of research and development resources data tables only 1965 (conducted annually) survey of research and development expenditures at universities and colleges icf macro webcaspar; infobrief; academic research and development expenditures; science and engineering indicators; national patterns of research and development resources; science and engineering state profiles; academic institutional profiles data tables (selected items) only 1972 (conducted annually, limited data available for various years for 1954œ1970) survey of state research and development expenditures census bureau infobrief; state government r&d expenditures; science and engineering indicators data tables only 1964 (conducted occasionally) communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 11 science and engineering research facilities survey of science and engineering research facilities rti international webcaspar; scientific and engineering research facilities; science and engineering indicators microdata from this survey for the years 1988œ2001 are not available  1986 (conducted biennially) other surveys survey of public attitudes toward and understanding of science and technology norc, via an s&t module on the general social survey science and engineering indicators data tables only icpsr, 1979œ2001; cd, 1979œ2004; (conducted biennially)   communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 12appendix a  panel on communicating national science foundation science and engineering information to data users  kevin novak (chair), integrated web strategy and technology, american institute of architects, washington, dc micah altman, institute for quantitative social science, harvard university elana broch, office of population research, princeton university john m. carroll, college of information sciences and technology, pennsylvania state university patrick j. clemins, r&d budget program, american association for the advancement of science, washington, dc diane fournier, client services division, statistics canada, ottawa christiaan laevert, dissemination unit, eurostat, luxembourg andrew reamer, george washington institute of public policy, the george washington university, washington, dc  emily ann meyer, costudy director thomas plewes, costudy director michael j. siri, program associate communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 13appendix b workshop summary  introduction the national center for science and engineering statistics (ncses), formerly the division of science resources statistics (srs), of the national science foundation (nsf), in seeking to fulfill its mandate for collecting and disseminating information about science and engineering, conducts an ambitious program of data dissemination. the program includes a variety of release formats, including numerous hardcopy and electroniconly publications. the extensive ncses website also houses the integrated science and engineering resource data system (webcaspar) and the scientists and engineers statistical data system (sestat), which are tools used to retrieve data from ncses databases. these formats and tools serve a broad community of information users, with differing data needs, statistical knowledge, access preferences, and technical abilities. as part of a program of periodic review of all of its activities, ncses requested that the committee on national statistics of the national research council appoint an expert group to conduct a study of its dissemination program. as part of its work, the panel on communicating national science foundation science and engineering information to data users organized a workshop, which was held in washington, dc, on october 27œ28, 2010. the purpose of the workshop was to bring together ncses leadership and staff, data users, and representatives of the data storage, retrieval, and dissemination community to gather information for several of the panel™s study tasks: document current (traditional) practices of ncses for communicating and disseminating information in hard copy publication format as well as on the internet through the ncses website, and the webcaspar and sestat database retrieval systems;  consider the needs of significant data users;  evaluate the website design from the perspective of usability, including consideration of navigation aids, usercentered design techniques, and interactivity; consider the impact on the ability of ncses to improve communication and dissemination, given nsf website policy and governmentwide policies;  evaluate the impact of current governmentwide initiatives, such as data.gov, for retrieval of government statistics; and  consider new and emerging tools for retrieval and display of information, including using the semantic web for linking with other databases.  the first section of this summary covers u.s. agency initiatives on data dissemination. the second section looks at international initiatives. the final section considers accessibility issues. see appendix b for the workshop agenda. current status of the dissemination program with regard to the dissemination of its varied and important data, ncses has been in a change mode for some time. ncses has taken steps to move from, in the words of center communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 14director lynda carlson, ﬁspewing out reams of data tables to providing our customers information.ﬂ for example, few of the data series and analytical products are currently released as printed matter, in sharp contrast to a decade ago, when paper was the primary mode of dissemination. although progress has been made, the leadership of ncses is concerned that much more needs to be done to improve the dissemination of data, and for this reason, carlson stated, ncses requested this panel™s study to carefully review ncses™s approach to communicating and disseminating statistical information in the context of current ﬁbest practicesﬂ and new and emerging technologies. this review was asked to consider the needs of different types of users in ncses™s user community, current federal and nsf website guidance and policies, existing staff and contract resources, and broader governmentwide activities and initiatives. in her introductory remarks to the workshop, carlson requested that the panel consider what ncses might do differently in terms of publication types, online report formats, data access (online data tools and data files), documentation of survey methods, data quality, accessibility, and outreach and notifications. this is a tall order, particularly when considering the wideranging mandate of this rather small statistical agency. ncses™s permanent staff of about 45 employees and its contractors have responsibility to collect data and maintain databases on research and development (r&d), science and engineering (s&e) education, the s&e workforce, and related areas; designing and conducting major surveys (currently, 11 of them, several dating back to the early 1950s); collecting and analyzing science and technologyrelevant data from other agencies and organizations (both domestic and international); providing a global context for u.s. data; enabling comparisons and benchmarking through collaboration with the organisation for economic cooperation and development (oecd) and other international and national statistical agencies; producing the biennial science and engineering indicators products (under the guidance of the national science board) and congressionally mandated reports (such as women, minorities, and persons with disabilities in science and engineering); and, finally, conducting a program of dissemination of data and analyses to a wide range of data users. much of the internal responsibility for the dissemination program of ncses falls to john gawalt, deputy director and acting program director of its information and technology service program. in his presentation to the workshop, gawalt summarized the current status of the dissemination program and discussed ncses™s various products and publications. two of the products appear in both print and electronic formats: infobrief, which is published when needed to highlight results from recent surveys and analyses, and special analytical reports, such as the reports on women, minorities and persons with disabilities in science and engineering and science and engineering indicators. other products are in electronic form only. they include a series of extensive tables and technical material for each of the 11 periodic surveys, as well as special reports (national patterns of r&d resources, academic institutional profiles, and s&e state profiles), working papers, and methodology reports. several other specialized products, such as brief summaries (infocards) and cds, are also prepared. underlying all the reports and publications is a data repository, maintained by ncses, which houses the results of the contractorcollected survey and administrative data and several online databases, which are available to both ncses staff and the public. there are four major databases, three of which have existed for some time:  communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 15scientists and engineers statistical data system (sestat) this database tool captures information about employment, educational, and demographic characteristics of scientists and engineers in the united states. the data are collected from three national surveys of this population: the national survey of college graduates (nscg), the national survey of recent college graduates (nsrcg), and the survey of doctorate recipients (sdr). the data can be downloaded from the web or through the sestat data tool, which allows users to generate custom data tables.  integrated science and engineering resources data system (webcaspar) this database system contains information about academic s&e resources and is newly available on the web. included in the database is information from several of ncses™s academic surveys, as well as information from a variety of other sources, including the national center for education statistics. the system is designed to retrieve multiyear information about individual fields of s&e at individual academic institutions. the system provides a user with opportunities to select variables of interest and to specify whether and how information should be aggregated. output can be requested in hardcopy form or in lotus, excel, or sas (statistical analysis system) formats for additional manipulation by the researcher.  industrial research and development information system (iris) this system links an online interface to a historical database with more than 2,500 statistical tables containing all industrial r&d data published by nsf from 1953 through 1998. these tables are drawn from the results of nsf™s annual survey of industrial research and development, the primary source for nationallevel data on u.s. industrial r&d. iris resembles a databank more than a traditional database system: rather than firmspecific microdata, it is the most comprehensive collection of historical national industrial r&d statistics currently available. the tables in the database are in excel spreadsheet format, which are accessible either by defining various measures (e.g., total r&d) and dimensions (e.g., size of company) of specific research topics or by querying the report in which the tables were first published. the most recent addition to ncses™s dissemination offerings are publicuse files and restricted (licensed) datasets:  publicuse microdata files ncses takes pains to protect the data that are provided by individuals from disclosure. thus, ncses develops microdata files for release to the public in a format that will not permit identification of respondents. in some cases, respondents can be protected by ensuring that the files contain records from which identifying information (such as name and address) has been deleted from the records. in most cases, however, it is necessary to suppress selected fields or recode variables in order to provide researchers with as much microdata as feasible.  licensed datasets in some cases, the protection of respondent confidentiality would require such extensive recoding that the resulting file would have little, if any, research utility. in these cases, ncses does not issue a publicuse file. instead, ncses has developed a licensing procedure that permits a researcher to use the data files at nsf™s offices in arlington, virginia, or at the researcher™s academic institution under carefully controlled circumstances (for details, see http://www.nsf.gov/statistics/database.cfm [december 2010]). communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 16 requirements of data users  at the workshop, the panel heard from key data users from the federal government, the agencies that support federal government s&e analysis, academia, and the private sector. these presenters were asked to address, from their perspective, the current practices of nsf for communicating and disseminating information in hardcopy publication format as well as on the internet through the ncses website, and the webcaspar and sestat database retrieval systems. the panel had asked these data users to comment on the means used to obtain information on nsf s&e expenditure and human resource data; the comprehensiveness, quality, timeliness, or other aspects of the nsf publications and data release program; use of the website; use of the webcaspar and sestat databases; and the content, presentation, accessibility, and tools available for these databases. office of science and technology policy representing the office of science and technology policy (ostp), kei koizumi summarized the extensive use of nsf s&e information by this agency of the executive office of the president. he typically accesses the ncses data primarily through the ncses website, through the detailed statistical tables for individual surveys. he commented that the infobrief series is useful in that it informs him about which data are new. he reads each infobrief and explores some of the data further. for data outside his core area (r&d expenditures data), he often looks for the data in s&e indicators, and, if needed, he goes to the most current data on the nsf ncses website. he uses webcaspar to access historical data and long time series. his overall comments focused attention on the timeliness of the data, suggesting that, to users, the data are never timely enough although some of the lags are understandable. he remains optimistic that next year the data will be available earlier. he expressed concerns over the quality of the data, and the methodology employed in the federal funds survey, which were summarized in a recent national research council report.6 science and technology policy institute the science and technology policy institute (stpi) was created by congress in 1991 to provide rigorous objective advice and analysis to ostp and other executive branch agencies, offices, and councils. bhavya lal and asha balakrishnan reported on the activities and interests of stpi, which can be considered a very sophisticated user of nsf s&e information. stpi supports sponsors in three broad areas: strategic planning; portfolio, program, and technology evaluation; and policy analysis and assessment. in their presentation, lal and balakrishnan reported on several specific examples of the attempts by stpi to use nsf s&e information. in one task, investigators sought to determine the amount of research funded by government and industry for specific subfields of interest (i.e.,  6national research council. (2009). federal spending data for research and development: a pathway to modernization, panel on modernizing the infrastructure of the national science foundation federal funds survey, committee on national statistics, division of behavioral and social sciences and education. washington, dc: the national academies press. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 17networking and information technology). they were able to obtain percentage basic research of r&d ﬁby sourceﬂ and ﬁby performerﬂ for government and industry, but not broken out by specific fields and sectors of interest as broad as networking and information technology. they were able to get data on industry r&d by fields (i.e., north american industry classification system [naics] codes), but without the breakdown of basic research, applied research, and development funding. based on this experience, the investigators recommended that nsf provide access to the data in a raw format.  their overall view was that access to nsfncses data tables and briefs is extremely helpful in stpi™s support of ostp and executive agencies. however, access to the data in a raw formatšincluding datasets underlying special tabulations related to publications, patents, and other complex datašwould better enable assessment of emerging fields. similarly, they would like access to more notes on conversions, particularly to international data, to understand underlying assumptions: for example, china™s s&e doctoral degrees. for their work, they requested more detail on r&d funding/r&d obligations by field of science and by agency, although, for their needs, that data need not be publicly available. academic uses paula stephan of georgia state university, who classifies herself as a ﬁchronicﬂ user of nsf s&e information, summarized her uses of the data. she has a license with nsf (see above), and about 40 to 50 times a year, she uses restricted files pertaining to sdr, sed and sestat. she also uses infobriefs and the science and engineering indicators appendix tables, and she accesses data through webcaspar. graduate students use webcaspar to build tables and such create variables as stocks of r&d, stocks of graduate students, and stocks of postdoctorates by university and field. she reported that webcaspar can be difficult for new users to navigate, but they have to use webcaspar because the ncses web page does not always have the most uptodate links to data. for example, the number of doctorates for 2007 and 2008 is available only from webcaspar. she commented that the s&e indicators appendix tables are easy to use and that the tables are very well named so it is easy to find data. the ability to export the data to excel allows one to easily analyze data. stephan noted that she does not use table tools, but her colleague, henry sauermann, did so for a study, and he reported that table tools provided him exactly what he needed (starting salaries for industry life scientists). she pointed out that the nsf staff have been very responsive to user needs. for example, in 2002 users recommended that ncses collect information on starting salaries of new ph.d.s in the sed, and, beginning in 2007, the question was on the sed. she suggested a need for more user support. there were data workshops for 3 years that brought together users and potential users of licensed data. this same approach could be useful for acclimating users to webbased data. it would be a good way to find out how people use the data and to find out difficulties with or questions that people have about the data. like other users, stephan commented that a major problem of the data is timeliness. the lack of timeliness affects the ability of researchers to assess current issues, such as the effect of the 2008œ2010 recessions on salaries, availability of positions, the length of time individuals stay in postdoctoral status, and the mobility of s&e personnel. as an example of the lag, she pointed out that the 2008 sdr will be publicly released in november 2010, but the restricted data will not be released for licensed use until sometime in 2011. the data were collected in october communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 182008. owing to this lag, the data will provide little useful information about how the recession affected careers: analysts will have to wait until fall 2012 to get the 2010 data and will have to wait until sometime in 2013 to get the restricted data. similarly, the earliest sed data collected during the recessionšfor july 1, 2008œjune 30, 2009šwere not scheduled to be released until november 2010 (note: the data release was subsequently delayed to allow for correction of data quality issues in race and ethnic data). so it is ﬁearlyﬂ recession data, though it will be analytically important because it will be the third year for which salary data have been collected in sed: when these sed salary data are available, analysts will be able to learn a good deal comparing the data with earlier years. however, such analyses will have to wait until november 2011 when the 2010 sed (july 1, 2009œjune 30, 2010) data are released (and assuming that salary data are made available). stephan pointed out the timeliness is not a new issue. she quoted a 2000 national research council report: ﬁsrs must substantially reduce the period of time between the reference date and data release date for each of its surveys to improve the relevance and usefulness of its data.ﬂ7 private sector users jeffrey alexander, a senior science and technology policy analyst with sri international, is a frequent user of nsf s&e information and a contractor to nsf. in his presentation, he summarized his previous privatesector uses of the information, mainly focused on uses of the data for analysis of technology applications at the state level. he accessed data from the website and through use of webcaspar. he stated a major caution about the comparability of data sources and noted that good metadata (data about the data) are not generally available for ncses data. in particular, he said there is a need for more geographic metadata so one can be confident in matching nsf data with data from the bureau of labor statistics and other sources. like other users, he expressed a concern over the timeliness of the data and said that timeliness is a key factor in the relevance of the data. with regard to access, alexander said he often needs trend data, so he most generally goes to the tables on the web page to extract specific data items. he finds that he has problems in downloading multiple files, and he finds that the webcaspar and sestat tools are not very user friendly. a useful enhancement would be to enable searches for variables across the various surveys. he does not use the printed publications, although he finds that the infobriefs are very useful in announcing and highlighting new products. alexander suggested that the ncses needs to become a center of information for the user community, and it should devote more attention to reaching out to larger users with information about how to access data as well as to seek input for improvements.  federal dissemination initiatives  over the years, several significant programs have been initiated to increase the availability of federal government information in electronic format. for the ncses, as part of  7recommendation 5 in national research council. (2000). measuring the science and engineering enterprise: priorities for the division of science resource studies. committee to assess the portfolio of the division of science resources studies of nsf, office of scientific and engineering personnel and committee on national statistics. washington, dc: national academy press. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 19the statistical community, the fedstats gateway (www.fedstats.gov) has, for several years, incorporated pointers to the s&e data in both the list of topics (education, r&d, and workforce) and the agency listings portion of the fedstats home page. the pointers in fedstats guide the user to the ncses home page at which the subject matter appears.  data.gov ncses was an early member of the federal government™s open government initiative, data.gov, when it was initiated in may 2009. workshop presenter alan vander mallie, the program manager in the general services administration, stated that data.gov aims to promote accountability and provide information for citizens on what their government is doing with tools to enable collaboration across and all levels of government. it is a onestop website for free access to data produced or held by the federal government, designed to make it easy to find, download, and use the data, including databases, data feeds, graphics, and other data visualizations. vander mallie reported that, at its inception in 2009, data.gov consisted of 47 raw datasets and 27 tools to assist in accessing the data in some of the complex data stores. currently (at the time of the workshop), the program supports 2,895 raw datasets and 638 tools, which are accessed through raw data and tool catalogues. raw data are defined as machinereadable data at the lowest level of aggregation in structured datasets with multiple purposes. the raw datasets are designed to be ﬁmashed up,ﬂ that is, linked and otherwise put in specific contexts using web programming techniques and technologies. in the future, vander mallie said, data.gov is slated to continue to expand its coverage of datasets and tools and to continue to support communities of interest by building community pages that collect related datasets and other information to help users find data on a single topic in one location. one objective is to make data available through the application programming interface (api), permitting the public and developers to directly source their data from data.gov. expansion into the semantic web (sometimes called web 3.0) is also part of the future plan for data.gov. the objective is to enable the public and developers to create a new generation of ﬁlinked dataﬂ mashups. working toward this goal, data.gov has an indexed set of resource enscription framework documents that are available and is working with the world wide web consortium (w3c) to promote international standards for persistent government data (and metadata) on the web. plans are also in place for expanding mobile applications, improved ﬁmetataggingﬂ (to facilitate implementation of standards to describe the data), and enhancing data visualization across agencies. in short, the idea is to give agencies a powerful new tool for disseminating their data and a onestop locale for the public to access the data. suzanne acar, senior information architect for the u.s. department of the interior and cochair of the federal data architecture subcommittee of the chief information officer council (see www.cio.gov), put the current and future data.gov into context by discussing an agency perspective on the lessons learned from this program to improve access to the federal government™s data. she discussed the evolution of enterprise data/information management (eim)ša framework of functions that can be tailored to fit the strategic information goals of any organization. for agencies, like nsf, to benefit from the capabilities of web 2.0 and web 3.0, it is important to ensure consistent quality of information and official designations of authoritative data sources. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 20statistical community of practice and engagement  the federal statistical agencies, as a group, have begun to organize to enhance dissemination of their data in a project called the statistical community of practice and engagement (scope). as described by ron bianchi of the economic research service of the u.s. department of agriculture, who heads the planning committee, scope represents a recognition on the part of the leadership of statistical agencies that there are efficiencies for both the agencies and users from more cross agency collaboration, harmonization of definitions and terminology, identification of best practices, and sharing of the development of common tools that support best practices. scope envisions that the dissemination platform for federal statistical data will be a modernized fedstatsšwhich has name recognition but is technologically outdated. it will use the data.gov statistical community as scope™s public interface and dissemination platform, store datasets on the data.gov dataset hosting platform that is currently being developed, and harness data.gov cloud computing power. in recognition of the fact that statistical data collected by federal statistical agencies often raise issues of complexity as well as of confidentiality and privacy, bianchi said that scope will aim to develop userfriendly data delivery and data display tools to address 508 compliant alternatives to tabular displays, develop displays of complex sample survey data while protecting confidential microdata, and develop visualization tools for multifaceted statistical designs. the statistical agencies that are part of scope, which will include ncses, will participate in promoting data harmonization and integration through the development of metadata and data exchange. specifically, the project will take the fundamental steps of developing and implementing stats metadata 1.0 (for delivery in fiscal 2012) and establishing common definitions to facilitate data exchange and interoperability (by fiscal 2013). the goal is to promote development and use of common platforms for data collection and data analysis and to suggest research on solutions to the ﬁdata mosaicﬂ problem in the current technology environment.  american factfinder  ncses™s three major dissemination toolsšsestat, webcaspar, and irisšhave been in place without major modification for some time, and some workshop participants commented that it needs a retooling. in thinking about an approach to retooling, one approach would be to consider what other government agencies have done or are doing to improve their dissemination tools. one such tool is the census bureau™s primary webbased data dissemination vehicle, the american factfinder. this tool enables the retrieval of data from the decennial census, the economic census, the american community survey, annual economic surveys, and the population estimates programšall very large databasesšin tabular, map, or chartform data products, as well as an online access to archived data (through download). jeffrey sisson, the american factfinder program manager, reported that the system is now in the process of being redesigned with many goals: increase the effectiveness of user data access; guide users to their data without forcing them to become experts; improve turnaround time; increase the efficiency and flexibility of dissemination operations; address growing usage and data volume needs; and provide a platform that evolves over time, avoiding technology obsolescence. the overall goal of the redesign is to make information easier to find, update the communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 21look and feel of the site, increase its functionality; implement topic and geographybased search and navigation; standardize functionality and look across all data products and surveys; implement new and improved table manipulations; and implement charting functionality. sisson said that the plan for the redesign was based on stakeholder and user feedback, usability studies, and a usability audit. based on the usability studies, the census bureau selected the following areas for improvement: usability and customer satisfaction; visual elements; conventional layout; consistent structure; and layering of information. this information is presented in table b1. sisson reported that the new american factfinder system is scheduled to launch in january 2011. in the meantime, the census bureau has provided email updates on the status of the project, developed a virtual tour of the new system, and, on a flow basis, will be issuing tutorials on the new system. dataweb in his introduction to the discussion of the census bureau™s dataweb network, cavan capps, the chief of dataweb applications, described the major tasks facing statistical agencies: how to present the right data with the right context to meet users™ needs through effective data integration; how to ensure that the most recent and most correct data are displayed; and how to facilitate the efficient reuse of data for different purposes. in his presentation, he stated that the dataweb network was one of three parts to the census bureau™s approach to these challenges the other two are hotreports and dataferrett. the dataweb project was started in 1995 to develop an open source framework that networks distributed statistical databases together into a seamless unified virtual data warehouse. it was originally funded by the u.s. census bureau, with participation at various times by the bureau of labor statistics, the centers for disease control and prevention, harvard university, and nonprofits institutions. the software provides an open source, serviceoriented architecture that pulls data from different database structures and vendors and normalizes them into a standard stream of data. the normalized stream is intelligent and supports standard transformations, can geographically map itself correctly using the correct vintage of political geography, understands standard code sets so that data can be combined in statistically appropriate ways, understands how to weight survey data appropriately, and understands variance and other statistical behaviors. capps described dataweb as having the capacity for handling different kinds of data in the same environment or framework. it is empowered by statistical intelligence: documentation, statistical usage rules, and data integration rules. its features include storing the data one time, but using it many times. dataferrett and hotreports both use the dataweb framework. hotreports are much like the ncses infobriefs. they are targeted to local decision makers with limited time and statistical background. designed to bring together relevant variables for local areas, they are topically oriented and updated when needed. they have been developed to be quick to build using a drag and drop layout. dataferrett is a data web browser that is targeted at sophisticated data users and integrates multiple datasets. it speeds analytical tasks by allowing data manipulation and incorporating advanced tabulation and descriptive statistics. its mapping and business graphics use statistical rules. it has the capability of adding regressions and other advanced statistics.  communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 22summary of data dissemination practices  panel member micah altman began his summary by noting that this is an exciting, fastchanging time for electronic data dissemination in the public sector. he summarized the state of current practice in terms of publicly available systems for online numeric data sharing, publishing, and visualization. the systems can be further classified as open and closed source (summarized in table b2).  dataverse network is an opensource and standardsbased virtual data archive tool. it handles moderately sized data and supports long term access and preservation and supports data documentation initiative (ddi) metadata. it is a leading example of standardbased open systems.  protoviz is a toolkit for dynamic visualization of complex data. this open source tool is in javascript and handles smallsized databases. it supports a partial grammar of graphics in highlevel abstractions. it is a leading example of dynamic data visualization.  factual is a data manipulation tool used in the commercial sector. it is closed source and handles moderately sized databases. it extensively supports collaborative data manipulation in such functions as data linking, aggregation and filtering, and it has extensive mashup support, with google restful and java json api™s for extraction and interrogation of datasets. it also integrates with google charts and maps. it is a very interesting example of collaborative data editing. tableau is an extraction tool that produces linked dynamic tables and graphics using raw data as the input. it handles moderately sized data, and it supports downloads in csv and pdf formats, as well as html tables.  google has a number of offerings, including google sheets, which is an exceltype tool that has apis for integration and handles small datasets; fusion tables, which focuses on data sharing, linking, and merging; and google public data explorer, which searches across data elements and has some visualization capability.  altman observed that dissemination is a dynamic field in the private sector, and that many of the startup dissemination and datasharing services have closed. in view of this uncertainty, he said users would be well advised to mitigate risk of adopting any of these systems by using open source software when possible, to retain preservation copies of files in other institutions, to limit use to dissemination only (not for managing data), and to leverage metadata and apis to create one data source that is then disseminated through multiple sources. altman identified research challenges and gaps between the state of the art and the state of the practice. research challenges in this area include petascale online analysis, interactive statistical disclosure limitation, business models for longterm preservation, and data analysis tools for the visually impaired. closable gaps include managing nontabular complex data and metadatadriven harmonization and linkage across data resources. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 23international initiatives  the computer revolution and the development of the web have generated a large number of initiatives to improve statistical data dissemination not only in the united states, but also internationally. the workshop included presentations from panel members christiaan laevaert and diane fournier on the dissemination initiatives of their institutions, the european community and statistics canada. eurostat: focus on data usability the statistical office of the european union (eurostat) compiles statistical data that are, for the most part, collected by member states. christiaan laevaert said that eurostat adds value by providing statistics at the european level that enable comparisons between countries and regions and by disseminating these data, free of charge, in consolidated format through publications and online databases. disseminating this information is a large undertaking. in january 2010, for example, the eurostat website had 2.8 million visitors and 3 million page views. there were 400,000 dataset extractions, 400,000 table consultations, and more than 400,000 publication downloads in pdf format. the site is among the top five visited websites of the european commission. in the past, hardcopy publications constituted a very large, cumbersome workload for eurostat in a process that has meant that data at the moment of publishing are already 6œ9 months older than what can be found on the website. the agency has published annually 5œ15 printed statistical books, 15 pocket books, and 120 ﬁstatistics in focusﬂ and various methodological publications. large amounts of content have been created and are disseminated in paper and pdf format. similar content is often created repetitively in different forms for different purposes. in order to improve the situation, laevaert said, the eurostat board of directors asked to examine the possibilities to disseminate the content of publications more effectively. the subsequent discussions led to the creation of a wikitype system for the dissemination of statistical articles and related textual content. this new system does not only change the manner of dissemination, but also the way of collaboration in the preparation of publications. the wiki approach was selected because eurostat databases have a wide variety of users: one group is a particular challenge to servešthe nonexpert data user. the agency has taken on the task of making the data more useful to this group by developing a dissemination aid called statistics explained. information in statistics explained is disseminated using a wiki technology with electronic publication. the wiki explains what the statistics really mean, what is behind the figures, and how they can be of use, in an easily understandable language. numerous hyperlinks allow for easy navigation. more than 250 articles are contained in this system, with some 800 glossary items, and the wikitype website assures a high ranking in search engines. in september 2010, 60,000 unique visitors per month were counted. eurostat has realized a synergy between its main website and statistics explained by mutual deep links that assure visitors a coherent navigation between the two websites. laevaert said that this dissemination strategy has changed the way eurostat does business. it has introduced a new production process for publications and a paradigm shift in the way users are servedšby focusing first on statistics explained first and later on publication. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 24however, unlike wikipedia, information can only be updated by eurostat staff, thus ensuring the authenticity and reliability of the content, so updating the system involves a large part of the staff: more than 200 of the 800plus eurostat staff contribute to content updates. while statistics explained is addressed to nonexpert users, the retrieval system of eurostat focuses on all types of users, including more sophisticated ones. it allows users to reuse data with tools they prefer. thus, users are provided with various data formats and visualization tools, including xls, html, txt, xml, spss, and pcaxis. each of the more than 5,000 datasets disseminated on the website are also available in several raw formats in the bulk download facilityštsv, sdmxml, and dft. a table of contents file in xml format facilitates machinetomachine interactions. laevaert noted that eurostat is also rethinking its approach to visualization tools, adapting procedures to take advantage of cloud computing and being able to supply data in formats required by emerging tools. working with google, the data featured on google™s public data explorer are being integrated into google search with onebox. the google search integration makes datasets searchable in 34 languages and assures the highest ranking in search results. currently, four eurostat datasets have been integrated, which has significantly improved the overall visibility of its data. statistics canada user outreach  although statistics canada uses many of the same dissemination practices and tools as are used by ncses and other u.s. statistical agencies, diane fournier said it has contributed significantly to the enhancement of the dissemination experience by its sharp focus on data users and usability. the program of usability assessment includes a website evaluation survey and ongoing consultations with users through focus group discussions and usability testing in a lab environment. the agency has recently been a partner in testing new governmentwide design standards. the lessons learned as a result of these activities have resulted in a home page redesign, search improvements, and the development of a ﬁstatistics by variableﬂ tool to permit direct retrieval of certain variables (not yet available). website evaluation studies were conducted from 1997 until 2007, usually on an annual basis. in 2010, an online questionnaire that reached all website visitors was live for 15 days and, with almost 10,000 respondents, the response rate (responses as a percent of visitors) was 3 percent. the representation of the online respondents was similar to that of earlier surveys: 27 percent were students; 21 percent were from the government and public sector; and 20 percent represented the business and private sector. about 15 percent of users accessed the internet through mobile devices, but more traditional computers were used more often: desktops pc by 72 percent and laptops or notebooks by 61 percent. in an interesting comparison, in a visitor pattern analysis during a 6month period from april to september 2009, 0.4 percent of all website visitors used mobile devices. the 2010 survey focused on the subject of task completion. some 65 percent of respondents accomplished what they set out to accomplish, and, not surprisingly, satisfaction also registered at 65 percent. when asked for three priority suggestions for improvement of the website experience, the top suggestions were to ﬁmake it easier to access to data/information,ﬂ ﬁimprove the search engine/search results,ﬂ ﬁoffer additional free data/information,ﬂ ﬁsimplify the site layout/design,ﬂ and ﬁuse clearer/plain language.ﬂ communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 25usability testing is also used by statistics canada, fournier reported. it involves observing ﬁreal usersﬂ complete specific tasks to see if the experience meets user needs, functions as expected, and is intuitive for its intended audience. as a result of these user outreach initiatives, statistics canada has taken steps to provide better access to the latest content and paid more attention to serving dissemination through mobile devices. in addition, the agency is continuing to improve search technology and has begun to archive content. fournier said that statistics canada sees real benefit in continued consultations with users, continued collaborative efforts with national and international agencies and departments, and continued participation in canada™s governmentwide design standards that focus on brand recognition. accessibility issues  in order for ncses science and engineering information to be used, it must be accessible to users. by nearly eliminating the hardcopy publication of the data in favor of electronic dissemination, mainly through the web, ncses is committed to the provision of webbased data in an accessible format, not only for trained sophisticated users, but also for users who are less confident of their ability to access data on the internet. importantly, the user population also includes people who are disabled and for whom, by law and right, special accommodations need to be made. the panel benefitted from a presentation by judy brewer, who directs the web accessibility initiative (wai) at w3c. w3c hosts the wai to develop standards, guidelines, and resources to make the web accessible for people with disabilities; ensure accessibility of w3c technologies (20œ30 per year); and develop educational resources to support web accessibility. as a federal government agency, nsf is governed by the socalled section 508 regulations. these amendments to the rehabilitation act require federal agencies to make their electronic and information technology accessible to people with disabilities. section 508 was enacted to eliminate barriers in information technology, to make available new opportunities for people with disabilities, and to encourage development of technologies that will help achieve those goals. the u.s. access board has responsibility for the section 508 standards and has announced its intention to harmonize the web portions of its section 508 regulations with web content accessibility guidelines (wcag) 2.0, for which wai has responsibility. brewer also quoted statistical policy directive number 4 (march 2008), which directs statistical agencies to make information available to all in forms that are readily accessible. brewer stated that web 2.0 adds new opportunities for persons with disabilities, and that data visualization is a key to effective communication. however, people with disabilities face a number of barriers to web accessibility, including missing alternative text for images, missing captions for audio, forms that ﬁtime outﬂ before you can submit them, images that flash and may cause seizures, text that moves or refreshes before you can interact with it, and websites that do not work with assistive technologies that many people with disabilities rely on. in response to a question, brewer addressed the continued problem of making tabular information accessible, and she requested input on where the wai should go in this area. she referred to a national institute of standards and technology workshop on complex tabular information that resulted in several recommendations. brewer argued for publishing existing science and engineering data in compliance with section 508 requirements, while continuing research and development on accessibility communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 26techniques for new technologies, improved accessibility supports for cognitive disabilities, and more affordable assistive technologies. she said wai would partner with agencies to ensure that dissemination tools are accessible. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 27table b1 areas for improvement for american factfinder identified from usability studies  area for improvement goal measure visual elements homepage should be more visual to improve visitor expectations, reduce perceived complexity, and improve the look and feel of the site easier to absorb and assess through better balance of text and visuals use of images, color and negative space can help convey what to expect and make the page easier to digest  conventional layout search should be presented in the best practice format as a text box directly on the homepage prevents visitors from going through a multistep process to perform a query search is less likely to be overlooked or to blend in with other links/options surrounding it consistent structure navigation options should appear in the same location throughout the site visitors don™t have to search for them or use their browser™s back button layering information should improve content management and reduce scrolling by more effectively layering page information less scrolling gives visitors the impression that the information is much easier to absorb layering ensures more information is presented higher up on the pagešand avoids overwhelming visitors with too much content at once source: data from presentation by jeffrey sisson, u.s. census bureau, at the workshop on communicating national science foundation science and engineering information to data users, october 28, 2010. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 28table b2 publicly available systems for online numeric data sharing, publishing, and visualization source data sharing publishing visualization only open dataverse network prefuse flare processing protovis  closed  data 360 factual google fusion tables google sheets many eyes swivel statplot beyond 20/20 collectica nesstar sda tableau trackngraph google vis ap visifire source: micah altman, data dissemination: state of the private sector practice, workshop on communicating national science foundation science and engineering data to users, october 28, 2010. permission granted by author. communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 29 appendix c workshop agenda goals for the workshop:  1. obtain information from nsf management on the current status of dissemination of science and engineering data, and their plans for the future 2. obtain information from data users on their requirements 3. hear from experts in visualization, next generation tools, and accessibility about the current state of the science in data dissemination  wednesday, october 27, 2010 room 204, keck center, 500 fifth street nw, washington, dc open session 9:00œ9:15 am welcome, discussion of agenda for the workshop (continental breakfast served) kevin novak, chair  9:15œ10:15 current status and plans for dissemination of s&e information lynda carlson, director, division of science resources statistics national science foundation john gawalt, program director, information and technology services program, division of science resources statistics, national science foundation 10:15œ10:30 break  10:30amœ12:00 pm panel discussion: user evaluation of nsf s&e information dissemination moderator: patrick clemins, panel member  paula stephan, georgia state university jeff alexander, sri international kei koizumi, ostp bhavya lal, ida stpi 12:00œ1:00 working lunch (atrium)  (continued discussion of dissemination issues)  1:00œ2:00 u.s. government dissemination initiatives moderator: elana broch, panel member communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 30open government initiative (data.gov) alan vander mallie, program manager, data.gov, program management office, office of innovative technologies, office of citizen services and innovative technologies, general services  administration  2:00œ3:00 statistical agency initiatives moderator: andrew reamer, panel member community of practice initiative ron bianchi, economic research service american fact finder jeffrey sisson, american fact finder, census bureau  3:00œ3:15 break  3:15œ4:30 international initiatives moderator: diane fournier, panel member  eurostatšdata usability: public data explorer and statistics explained christiaan laevaert, panel member statistics canadašweb redesign initiatives diane fournier, panel member 4:30œ5:00 private sector initiatives moderator: micah altman, panel member 5:00 pm panel in recess  6:00œ7:30 working dinner (by invitation)  (panel will discuss day 1 presentations and prepare for day 2) thursday, october 28, 2010 room 110, keck center, 500 fifth street nw, washington, dc open session 8:30œ8:45 am review of first day workshop and discussion of agenda (continental breakfast served) kevin novak, chair 8:45œ10:00 w3c initiatives, data.gov, and web 2.0 communicating national science foundation science and engineering information to data users: letter reportcopyright national academy of sciences. all rights reserved. 31suzanne acar, u.s. department of the interior and federal data architecture subcommittee  10:00œ10:15 break 10:15œ11:00 accessibility of nsf internet data (508 compliance) judy brewer, web accessibility initiative, world wide web consortium  11:00œ12:00 pm open discussion kevin novak, chair 12:00œ1:00 working lunch  (continued discussion of accessibility issues)  thursday, october 28, 2010 room 110, keck center, 500 fifth street nw, washington, dc closed session 1:00œ2:30 committee discussion of workshop lessons learned 2:30œ3:30 plans for interim report  3:30 pm adjourn 