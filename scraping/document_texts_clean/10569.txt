detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/10569the internet under crisis conditions: learning fromseptember 1194 pages | 6 x 9 | hardbackisbn 9780309381819 | doi 10.17226/10569committee on the internet under crisis conditions: learning from september 11;computer science and telecommunications board; division on engineering andphysical sciences; national research councilthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.committee on the internet under crisis conditions:learning from september 11computer science and telecommunications boarddivision on engineering and physical sciencesthe national academies presswashington, d.c.www.nap.eduthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.the national academies press 500 fifth street, n.w. washington, dc 20001notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn fromthe councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsiblefor the report were chosen for their special competences and with regard forappropriate balance.support for this project was provided by the association for computingmachineryõs special interest group in data communication (acm sigcomm);the ibm corporation; and the vadasz family foundation, a contributor to thecomputer science and telecommunications boardõs program on information technology and society. any opinions, findings, conclusions, or recommendationsexpressed in this publication are those of the authors and do not necessarilyreflect the views of the organizations that provided support for the project.international standard book number 0309087023cover image courtesy of verizon communications. cover designed by jenniferbishop.copies of this report are available from the national academies press, 500 fifthstreet, n.w., lockbox 285, washington, dc 20055; (800) 6246242 or (202) 3343313 in the washington metropolitan area. internet, http://www.nap.edu.copyright 2003 by the national academy of sciences. all rights reserved.printed in the united states of americathe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific and engineering research, dedicated to the furtherance of science and technology and to their use for the generalwelfare. upon the authority of the charter granted to it by the congress in 1863,the academy has a mandate that requires it to advise the federal government onscientific and technical matters. dr. bruce m. alberts is president of the nationalacademy of sciences.the national academy of engineering was established in 1964, under the charterof the national academy of sciences, as a parallel organization of outstandingengineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsorsengineering programs aimed at meeting national needs, encourages educationand research, and recognizes the superior achievements of engineers. dr. wm. a.wulf is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy ofsciences to secure the services of eminent members of appropriate professions inthe examination of policy matters pertaining to the health of the public. theinstitute acts under the responsibility given to the national academy of sciencesby its congressional charter to be an adviser to the federal government and, uponits own initiative, to identify issues of medical care, research, and education. dr.harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology withthe academyõs purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by theacademy, the council has become the principal operating agency of both thenational academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientific and engineeringcommunities. the council is administered jointly by both academies and theinstitute of medicine. dr. bruce m. alberts and dr. wm. a. wulf are chair andvice chair, respectively, of the national research council.www.nationalacademies.orgthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.ivcommittee on the internet under crisis conditions:learning from the impact of september 11craig partridge, bbn technologies, chairpaul barford, university of wisconsin, madisondavid d. clark, massachusetts institute of technologysean donelan, sbc communicationsvern paxson, international computer science instituteõs center forinternet researchjennifer rexford, at&t labsðresearchmary k. vernon, university of wisconsin, madisonstaffjon eisenberg, senior program officer and study directormarjory s. blumenthal, directordavid padgham, research associatekristen batch, research associatedavid drake, senior project assistantjanet d. briscoe, administrative officerthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.vcomputer science and telecommunications boarddavid d. clark, massachusetts institute of technology, chaireric benhamou, 3com corporationdavid borth, motorola labsjohn m. cioffi, stanford universityelaine cohen, university of utahw. bruce croft, university of massachusetts, amherstthomas (ted) e. darcie, at&t labsðresearchjoseph farrell, university of california, berkeleyjoan feigenbaum, yale universityhector garciamolina, stanford universitywendy kellogg, ibm thomas j. watson research centerbutler w. lampson, microsoft corporationdavid liddle, u.s. venture partnerstom m. mitchell, carnegie mellon universitydavid a. patterson, university of california, berkeleyhenry (hank) perritt, chicagokent college of lawdaniel pike, classic communicationseric schmidt, google, inc.fred schneider, cornell universityburton smith, cray, inc.lee sproull, new york universitywilliam stead, vanderbilt universityjeannette m. wing, carnegie mellon universitystaffmarjory s. blumenthal, directorherbert s. lin, senior scientistalan s. inouye, senior program officerjon eisenberg, senior program officerlynette i. millett, program officercynthia patterson, program officersteven woo, dissemination officerdavid padgham, research associatekristen batch, research associatephil hilliard, research associatejanet d. briscoe, administrative officermargaret huynh, senior project assistantdavid c. drake, senior project assistantthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.vijanice sabuda, senior project assistantjennifer bishop, senior project assistantbrandye williams, office assistantthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.viiprefacealthough secondary to the human tragedy resulting from the september 11, 2001, attacks on the world trade center and the pentagon,telecommunications issues were significant that day both in terms of damage (physical as well as functional) and of mounting response and recovery efforts. the internet has come to be a major component of the nationõs(and the worldõs) communications and information infrastructure. peoplerely on it for business, social, and personal activities of many kinds, andgovernment depends on it for communications and transactions with themedia and the public. thus there is interest in how the internet performed and was used on september 11.unlike the situation with longerstanding telecommunications services (notably the public telephone network), there are few regulations,policies, or practices related to the internetõs functioning in emergencysituations. nor are there many publicly available data to help policymakers or the industry itself assess the internetõs performanceñeither ona continuing basis or in the aftermath of a crisis. no regular system existsfor reporting failures and outages, nor is there agreement on metrics ofperformance.1 some experiences are shared informally among network1a pilot effort was made by the federal communications commission to collect outageinformation under the auspices of the network reliability and interoperability council, butthis was limited to a voluntary trial, recently ended in 2002. interest in mounting a newvoluntary effort continues in some quarters.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.viiiprefaceoperators or in forums such as the north american network operatorsgroup (nanog), but that information is not readily accessible for national planning or research purposes. the decentralized architecture ofthe internetñalthough widely characterized as one of the internetõsstrengthsñfurther confounds the difficulty of collecting comprehensivedata about how the internet is performing.it is therefore unsurprising that no definitive analyses exist on theimpact of september 11 on the internet, though a few conflicting anecdotal reports about its performance that dayñsuch as several presentations at nanog indicating relatively little effect2 and press accountssuggesting that the impact was severe3ñhave appeared.responding to an initial request in early 2002 from the association forcomputing machineryõs special interest group in data communication(acm sigcomm), the computer science and telecommunications board(cstb) established the committee on the internet under crisis conditions: learning from the impact of september 11. the committeeõs chargewas twofold: to organize an exploratory workshop for gathering data andaccounts of experiences pertinent to the impact of september 11 on theinternet, and to prepare a report that summarizes the internetõs performance that day and offers conclusions on better preparing for and responding to future emergencies.a diverse group of industry representatives and researchers participated in the workshop (see appendix a). they were invited to shareinformation candidly, with the understanding that the organizing committee would take care not to publish sensitive or proprietary information. consequently, although the committee has strived to present asmuch detail as possible, specific figures or names of organizations havebeen omitted in some instances. following the workshop, the study committee decided to supplement what was obtained there, so additionalinformation in several areas was gathered from a number of sources.2north american network operators group 23rd meeting, october 2123, 2001, oakland, calif. presentations available online at <http://www.nanog.org/mtg0110/agenda.html>.3according to an article in computerworld: òextent of cyberinfrastructure devastation onsept. 11 unprecedented, officials say. for several tense hours on sept. 11, the nation wasdeaf, dumb and blind due to the ôabsolutely massiveõ loss of communications infrastructureresulting from the collapse of the world trade center, a senior government official said lastweek.ó the article goes on to focus on consequences of damage to a verizon central officebut implies much wider impact. dan verton. 2002. òdigital destruction was worst imaginable,ó computerworld, march 4. available online at <http://www.computerworld.com/managementtopics/management/recovery/story/0,10801,68762,00.html>.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.ixprefacethe overall human and economic costs of the september 11 attacksñwhich dwarf in significance the attacksõ effects on the internetñhavebeen widely covered and are not examined here. instead, this reportfocuses on three issues related to the internet: (1) the local, national, andglobal consequences of the destruction that occurred in new york city;(2) the impact of the crisis, including the actions of users as well as theeffects of the physical damage; and (3) how people made use of theinternet in a time of crisis.the project was smallñreflecting its relatively narrow focus and theobjective of producing a report quicklyñand had limited resources. theseconsiderations, combined with the relative paucity of data, mean that thecommitteeõs assessment was not comprehensive. instead, the committeeexamined several sources of data that revealed the overall status of theinternet on september 11 as well as shortly thereafter, and it drew on thedetailed experiences of several internet service providers. this was sufficient to derive a rough sense of that dayõs impact on the internet infrastructure nationwideñand worldwide.the committee and the cstb acknowledge the financial support provided for this project by acm sigcomm, the ibm corporation, and thevadasz family foundation. their support enabled but did not influencethe outcome of the committeeõs work.the committee also wishes to thank the workshop participants fortheir thoughtful contributions and for their comments on a draft of thisreport. responsibility for the report, however, remains with the authoringcommittee.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.xiacknowledgment of reviewersthis report has been reviewed in draft form by individuals chosen fortheir diverse perspectives and technical expertise, in accordance with procedures approved by the national research councilõs report reviewcommittee. the purpose of this independent review is to provide candidand critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meetsinstitutional standards for objectivity, evidence, and responsiveness tothe study charge. the review comments and draft manuscript remainconfidential to protect the integrity of the deliberative process. we wishto thank the following individuals for their review of this report:geoffrey baehr, u.s. venture partners,steven bellovin, at&t labsñresearch,scott bradner, harvard university,geraldine macdonald, america online, inc.,udi manber, yahoo! inc., andandrew odlyzko, university of minnesota.although the reviewers listed above provided many constructivecomments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the final draft of the reportbefore its release. the review of this report was overseen by robert r.everett, honorary trustee of the mitre corporation. appointed by thenational research council, he was responsible for making certain that anthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.xiiacknowledgment of reviewersindependent examination of this report was carried out in accordancewith institutional procedures and that all review comments were carefully considered. responsibility for the final content of this report restsentirely with the authoring committee and the institution.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.xiiicontentssummary and findings 11 introduction11a brief overview of the internet, 11what would it mean for the internet to fail?, 13a brief overview of events on september 11, 2001, 142 the network experience21overview of damage and impairment, 22collapse of north and south towers, 23building 7 collapse and damage to verizon central office, 23electrical power at colocation sites in lower manhattan, 24internetwide (global) phenomena, 25routing and reachability, 25traffic load across the internet, 29domain name system, 31specific nonlocal effects, 31difficulties accessing pops, 32disruption of the dns in south africa, 32interdependency in hospital wireless networks, 33restoration efforts, 33isp cooperation, 34improvising to restore connectivity, 35the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.xivcontentsthe experiences of other communications networks:telephone, wireless voice and data, and broadcasting, 36telephone, 36cellular telephones, 37broadcast television and radio, 383 the user experience40impact on business in the immediate area, 40people on the net, 41the internet as a source of news, 42the internet as a means of communicating betweenindividuals, 44the internet and community, 47overall use of the internet, 484 perspectives on the internet experience ofseptember 1149other outages: operator errors and infrastructure faults, 49operator error, 50infrastructure faults, 51attacks on, or with, the internet, 53baseline: effects of damage on september 11, 53if the internet were the target, would there begreater impact?, 54possible effects of a deliberate electronic attack with theaid of, or against, the internet, 575 measuring the internet61network measurement methods and tools, 62active measurement tools, 63passive measurement tools, 64measurement challenges, 67proprietary data, 67consistency in data and analysis, 67representativeness, 67the future: targeted assessment during a crisis, 68global network monitoring, 68targeted measurement during a crisis, 69appendixesaparticipants in march 56, 2002, workshop73bcommittee member and staff biographies74the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.1summary and findingsoverviewthe events of september 11, 2001, in addition to their other consequences, caused localized physical damage to the internet in one of thenetworkõs most important hubs, new york city. communications infrastructure located in the world trade center itself and nearby at theverizon central office at 140 west street, along with fiberoptic cables thatran under the trade center complex, was destroyed. electrical power inlower manhattan was disrupted, and local telecommunications facilitiesthere suffered a variety of problems with their backup power systems.serious effects on communications networks, however, were confinedto new york city and a few other regions highly dependent on it for theirconnectivity. in some cases, automatic rerouting at the physical or network levels allowed internet traffic to bypass many of the infrastructureõsfailed parts. most local internetconnectivity problems that could not beresolved by automatic rerouting were fixed within hours or days throughthe rapid deployment of new equipment or reconfiguration of the system.although users outside new york city were also affected by theevents of september 11, most of the difficulties experienced were not dueto serious problems in the internet infrastructure itself but rather to disruptions stemming from subtle interdependencies between systemsñitturned out that some services depended indirectly on connections madein new york city.even though their network connectivity had not been impaired, manythe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.2the internet under crisis conditionsusers had difficulty reading some popular news web sites. unprecedented levels of user demand immediately following the attack severelystressed the server computers for these sites. web service providersquickly took a number of stepsñsuch as reducing the complexity of webpages, using alternative mechanisms for distributing content, and reallocating computing resourcesñto respond successfully to demand.despite these problems, the internet, taken as a whole, was not significantly affected. for example, it did not suffer the kinds of overloadsthat are often associated with the telephone system in a time of crisis. theresilience of the network during the september 11 crisis was a credit to theingenuity and perseverance of the people who worked to restore communication service near the attack sites; and fundamentally, it was testimonyto the internetõs inherently flexible and robust design.however, the internetõs performance on september 11 does not necessarily indicate how it might respond to being directly targeted. furthermore, it is clear that the experience of individual internet serviceproviders (isps) and corporate networks on september 11 does not generalize: damage suffered, and ability to respond, varied widely from placeto place. in particular, the modest effect on internet communicationsoverall does not indicate how well an individual isp (and its customers)would fare in an attack targeted specifically to that isp. representativesof several isps told the committee that what made september 11 a relatively untroubled (albeit unnerving) day for them was simply the fact thattheir facilities were not concentrated at 140 west street. but the experience did establish the internetõs overall resilience in the face of significantinfrastructural damage.findingsthe workshop organized by the committee on the internet undercrisis conditions: learning from the impact of september 11 yielded anumber of insights about what happened and did not happen to theinternet as a result of the attacks of september 11, 2001. it also provideda number of lessons learned that could reduce the impact of future crises,and it pointed to some ways in which the internet itself could play agreater role in crisis response.finding 1. the events of september 11 had little effect on internetservices as a whole. the network displayed considerable flexibilitythat underscored its adaptability in the face of infrastructure damage and the demands imposed by a crisis.in much of the data that the committee examined, an observer wouldbe hardpressed to find any unusual impact from the events of septemberthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.3summary and findings11 outside the immediately affected areas. connectivity indeed droppedon the morning of september 11 at some locations in the internet, and itdropped as well during several subsequent intervals when electricalpower disruptions affected telecommunications facilities in lower manhattan. but connectivity recovered quickly, and the magnitude of its losswas actually less than has been seen in other incidents affecting theinternet. for some users, however, the events of september 11 significantly affected their internet experience, disrupting their connectivityaltogether or limiting their ability to obtain information from certain newssites.measures of overall internet traffic suggest that traffic volumes weresomewhat lower on september 11 than on a typical business day, withmany who normally would have been using the internet turning to television for news and to phone calls for reaching loved ones. traffic didincrease in two areasñthe quest for news and the use of internet communications as a substitute for telephone calls. news web sites, strainingunder unprecedented levels of demand, took a number of steps to enhance their ability to handle the traffic (box 3.1 in chapter 3 describescnnõs experience in particular and the strategies it employed). lowbandwidth email and instant messaging were used as substitutes fortelephone service, especially where conventionaltelephone and cellularnetwork congestion was high.overall, the internet experience on september 11 was in no way comparable to the trials of some other communications media, such as thecellular phone services in greater new york, which suffered from localinfrastructure damage and regional congestion. in part, this differencereflects the internetõs unique design (described in box 4.1 in chapter 4).a number of examples of how the internet was used in the hours anddays immediately following the september 11 attacks highlight the flexibility afforded by that design. nysernet, a nonprofit networking consortium, was able to reroute connectivity to bypass physical damage inlower manhattan. it proved relatively easy to reconnect the new yorkacademy of medicine to the internet by means of a juryrigged wirelesslink. when telephone service was impaired (through local damage totelephone circuits and disruption of some tollfree systems), some network operators were able to use instant messaging and voiceoverinternet protocol (ip) to coordinate activities. cnn and other information providers adapted their content and modified the ways in which theydelivered web data to accommodate the extraordinary demand for news.a wireless instantmessaging service saw increased use on september 11and in the following days. various groups rapidly set up web sites forexchanging information on the disaster and the possible whereabouts ofmissing people.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.4the internet under crisis conditionsan important point about these responses is that they required nocentral coordination. individuals and groups were able to spontaneouslycraft solutions to their problems and to deploy them quickly.finding 2. while the committee is confident in its assessment thatthe events of september 11 had little effect on the internet as awhole (finding 1), the precision with which analysts can measurethe impact of such events is limited by a lack of relevant data.the data available to the committee to gauge the impact of september11 included active measurements of packet delay and loss over a smallfraction of the internetõs paths, selected passive monitoring of applicationlevel behavior and globalrouting activity, and data from a survey ofinternet users. in some cases, this information was sufficient for drawingqualitative conclusions. but the committeeõs examination also revealedthe paucity of internet data available to the research community. available data are limited for reasons that include the following:¥factors intrinsic to the internetõs design. one cannot, for example,determine how many individual users are actually affected by the loss ofroutes to a particular set of addresses. it is also hard to know if users whohave lost connectivity through one route have reestablished connectivitythrough another oneñnew connections might have been made at a higherlevel of aggregation, in which case data showing fewer routes availablewould not mean worse connectivity.¥modest size of the measurement universe. the measurements ofinternet activity that are made on a regular basis are rather limited. forexample, connectivity is monitored to some extent by examining routingtables, but only from particular vantage points. routes themselves areperiodically traced to probe connectivity, but only with coarse time granularity. data collected on traffic volumes (workload) are often consideredproprietary, and much of the measurement of internet activities is conducted by small research groups with modest resources. moreover, theavailable analysis and modeling tools for probing internet behavior couldbe much improved.¥tendency to simply discard data. even when information is collected,it is often retained only for a short time. in a number of cases, requests forworkload data and other detailed logs of internet activity during september 11 showed that the data had already been discarded by the time of thecommitteeõs march 2002 workshop.¥nonavailability of good measures of the overall state of the internet. oneof the consequences of the fragmented and often proprietary measurement infrastructure is that data are gathered piecemeal in diverse waysand stored in various formats; there is no commonly accepted way ofthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.5summary and findingsstandardizing what information is collected and integrating the data toenable characterization of the internetõs overall health. therefore, readycomparison of september 11 to a òtypicaló day was not possible. theinformation available to the committee generally permitted only roughcomparisons in the context of a particular set of data (e.g., data on thereachability of a particular set of internet addresses suggest that the effects of september 11 were similar to those of a severed fiberoptic cable).one exception was that some conclusions could be drawn about theinternet as a whole when specific measurements could be correlated withdata from surveys of internet users (which are designed to be representative of all u.s. users).the inability to measure in detail the effects of september 11 on theinternet does not by itself provide a clear mandate for building a newand widespread internet measurement system, which would be bothcomplex and costly. gathering data across all internet providers wouldprobably require new regulations to compel their cooperation. there is,however, a relatively easy way to help improve understanding of theinternetõs behavior during crises or other anomalous events: simply holding on to the relevant data. one lesson from september 11 with regard tointernet measurement is that important data from such circumstancesare typically discarded soon after the fact. it may be useful to find waysto alert network managers to the importance of archiving data collectedduring significant events so that more detailed analysis can be performedlater on.finding 3. the events of september 11 did have a major effect onthe services offered by some information and service providers.although the internet as a whole was largely unaffected by the eventsof september 11, those services and service providers that were affectedwere often hit hard. the surge in demand for news overwhelmed thewebserver capacity of at least two major news services, for example, andnearby infrastructure serving the new york stock exchange and its member firms was heavily damaged.also, while many of the effects of september 11 were highly localized(like the attacks themselves), some parties far from the physical disastersites were affectedñisps in parts of europe lost connectivity because theyinterconnected with the rest of the internet in new york city, and southafrica experienced disruptions associated with the domain name system(dns).finding 4. peopleõs use of internet services on and immediatelyfollowing september 11 differed from what has been typical.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.6the internet under crisis conditionspeople used the internet very differently in the aftermath of the september 11 attacks. for example, they sent less email overall (althoughsome substituted email for phoning where the telephone networks werecongested), and they used news sites more heavily. they made greateruse of instant messaging. the overall picture that emerges is that individuals used the internet to supplement the information received fromtelevision (which was the preferred source of news). those unable toview television often substituted internet news. the telephone, meanwhile, remained the preferred means of communicating with friends andloved ones, but chat rooms and email were also used, especially wherethe telephone infrastructure was damaged or overloaded.the levels of other activities on the internet, such as ecommerce,declined. one consequence of this decrease was that in spite of largernumbers of persontoperson communications, total load on the internetdecreased rather than increased, so that the network was not at risk ofcongestion.finding 5. september 11 demonstrated the internetõs overall resilience to physical attacks. but it also revealed that in parts of thesystem, redundancy appears to have been inadequate.the attacks of september 11 were not directed at the internet. nonetheless, because new york city is a major worldwide datacommunications hub and a number of key communications links and facilities wereconcentrated in a handful of sites near the world trade center complex,the attack caused significant damage to internet elements. on the basis ofits analyses of the effects of the attack, of steps taken to restore connectivity, and of various òwhat ifó scenarios, the committee concludes that therichness of the internetõs interconnectivity provides effective protectionagainst a localized physical attack. although the committee heard fromworkshop participants that a carefully designed, distributed attack againsta number of physical locations, especially if carried out in a repeatingpattern, could be highly disruptive, it concluded that an attack at a singlepoint or a small number of points is probably survivable.regarding the infrastructural damage that occurred on september 11,the level of internet redundancy was adequate outside the immediatelyaffected area. however, parts of the internet were not as redundant asone might suppose. links that were logically distinct turned out to runover the same fiber spans or to be connected to major systems through thesame trenches or buildings. colocation of capacity and equipment cutsexpenses, but it obviously increases vulnerability to common outages.improving the robustness of the communications infrastructure may require conscious tradeoffs between reliability and cost. finally, certainproviders and certain regions of the world are heavily dependent on athe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.7summary and findingsfew key connection points; diversifying those points would significantlyimprove robustness.the connectivity problems outside new york city illustrate that endtoend communication on the internet depends on the functioning of several different (often geographically separate) systems such as local phonelines, modem banks, authentication servers, and dns servers. in addition, some wireless applications (handheld devices at hospitals, for example) depend on internet access to reach application services located inthe same building. a hospital in new york city learned on september 11that wireless personal digital assistants (pdas), on which doctors rely toaccess medical information, were connected through an external isp network. thus when the hospitalõs sole link to the internet was briefly broken by the collapse of the twin towers, doctors had trouble accessinghospital records. isps and users alike should be aware of these potentialvulnerabilities and take appropriate steps to improve redundancy whereconnectivity is missioncritical.finding 6. the internet experience on september 11 exposed a number of subtle operational issues that merit attention from users andoperators.most disasters impart useful lessons on what might be done better inthe future. the september 11 experiences of isps and users were noexception:¥internet operations depend on the public telephone network. one specific vulnerability is the use of tollfree telephone numbers for communicating between different isp operation centers. this practice makesinternet operations vulnerable to outages in the tollfree system (whichinvolves an extra database lookup as compared with directdialing of atoll call). and the tollfree system indeed had a partial failure on september 11 as a result of call volume, complicating isp coordination. moregenerally, although the public telephone network and the internet are forthe most part logically distinct, they are closely tied physically becauseboth depend on the same fiberoptic infrastructure. this shared vulnerability suggests that in the future the two networks be analyzed together;for example, to what degree are they dependent on the same physicalfacilities and to what degree can they actually substitute for one another?¥telecommunicationsfacility disaster planning should factor in supportfor operational personnel, and ensuring a capability for remote operation shouldbe considered wherever possible. one isp reported difficulty in feeding itsoperations staff, as all the businesses around its center in northern virginia had closed. there was some difficulty getting diesel fuel deliveredto backup power generators serving telecommunications facilities inthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.8the internet under crisis conditionslower manhattan. key data centers were sometimes inaccessible as aresult of areawide closures, even though they themselves had not suffered damage. operators that could manage their sites remotely, however, reported that this capability was valuable for keeping services running.¥key businesses and services that must operate in a disaster should examine their dependence on internet connections and plan accordingly. severalexamples of interdependencies arose in workshop discussions: (1) a newyork city hospital relied on an external internet link to connect wirelesspdas, (2) the nyc.gov web site was disconnected from the internet bythe attack, and (3) major news sites had difficulty accommodating higherdemand. specific responses that may be appropriate for organizationsand web sites likely to be used in an emergency include these: (1) providing redundant network connectivity (from more than one network provider and by way of more than one physical link or conduit), (2) performing an endtoend audit of internet dependencies, and (3) establishingplans for dealing with greatly increased traffic loads.¥network operators and telecommunications interconnection facility operators should review their emergency power procedures. power problemscaused transient disruptions to internet connectivity as well as possibledamage to the equipment because of overheating (when cooling systemsfailed). most network operators and isps had already established procedures for dealing with power failures, and in new york city these procedures generally worked as planned. but not enough attention appears tohave been paid to the possibility that some backup systems could fail. forexample, a number of disruptions to the internet occurred 8 to 12 hoursafter the power was shut off in lower manhattan because backup batteries and generators failed. reports also suggest that isps, unlike someother utilities, were not granted access to the restricted zone in lowermanhattan, which further complicated their recovery efforts. specificproblems included these:ñpoor operating procedure resulted in a facilityõs backup generatorbeing shut off to conserve fuel, which in turn led to service interruptionswhen grid electrical power was lost.ñfuel delivery problems, including delivery of the wrong type offuel to one location, made it difficult to keep generators running.ñcommunications equipment was allowed to continue operatingeven when electrical power necessary for cooling systems had been lost.ñfiber termination circuits were not connected to generators andfailed when their 8hour batteries failed.ñbackup generators shut down when their air intake filters becamethe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.9summary and findingsclogged with dust, a problem that could possibly have been averted ifmore rapid access for maintenance had been possible.several prudent steps could be taken to reduce future disruptions.operators should evaluate their vulnerabilities to multiday electrical outages. in particular, the evaluation should determine the primary andbackup power source for every major device (server, router, switch) andindependently powered link (e.g., synchronous optical network[sonet] or pointtopoint fiber). operators should also identify howeach device will respond to a power outage (after both primary andbackup power fail) and how it will resume functioning when power isrestored. operators should develop contingency plans that allow them toprovide services for the maximum period of time (in particular, all keydevices should use the longestlived backup power supplies available)and restore most services remotely after an outage. operators should alsoidentify special needs (e.g., fuel for generators and the space in which toplace additional generators if they are needed) that may require the consent of local authorities, and they should have plans for coordinating withauthorities in the event of an emergency.finding 7. the experience gained from the events of september 11points to ways in which the internet could be better leveraged infuture crises.it is reasonable to anticipateñand thus to plan forñincreased use ofthe internet in future crises, and lessons learned from september 11 indicate some of the issues that deserve attention.on the one hand, it is clear that in the immediate aftermath of adisaster, people will typically turn on television sets (to get news) and callfamily and friends on the telephone (to convey news, report on theirstatus, or supplement television news with information of a more personal nature); they tend not to use the internet. the data from september11 show that this pattern held on that day; even heavy internet users wentfirst to the television and the telephone.on the other hand, it is also clear that if the television or telephonewas unavailable or failed to provide the information people needed, theyturned to the internet even if they normally were not heavy internetusers. for instance, it appears that much of the surge in demand at onlinenews sites on the morning of september 11 came from people who did nothave access to television sets at their workplace. people also appear tohave used the internet to supplement information available from othersources, as evidenced by marked shifts in topics searched on the internet.these behaviors suggest that disaster planning should include examinathe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.10the internet under crisis conditionstion of how the internet might be used to disseminate information in afuture crisis.the experiences of september 11 also indicate the value of efficientinternet or internetstyle data communication in a disaster. these alternatives, such as text messaging and email, make more efficient use oflimited communications capacity than do other services. by midday onseptember 11, the cellularphone networks in manhattan were severelycongested, yet there are reports that people who used their cell phones orwirelessequipped pdas to send instant messages were able to communicate effectively. email and instant messages were also used as a substitute for telephone calls.although better communication over the internet could simply havebeen the result of the relative overprovisioning of the internetrelatedcommunication infrastructure, there are several fundamental reasonswhy, for example, using a pda to send a short text message such as òiõmok and am walking homeó is far more efficient and more likely to succeed than making a cellphone call when the network is congested. first,the internet degrades under load more gracefully than does the voicenetwork. if sufficient capacity is not available, the cellphone networkwill not permit new calls to be set up. in contrast, the internet makes useof mechanisms that continue to accept new messages but reduce transmission rates when the network is congested. also, by virtue of theirflexible design, internetstyle communications lend themselves to humanactions that reduce the loadñwhether by substituting a brief text messagefor a dataintensive voice call or removing dataintensive graphics from aweb page (as cnn did in the face of high loads). a lesson here is thatorganizations responsible for disaster planning should encourage awareness of this more efficient way to communicate.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.111introductiona brief overview of the internetthe internet is a worldwide collection of networks, operated by some10,000 internet service providers (isps),1 that accommodates a diversityof applications such as email, instant messaging, the world wide web,and numerous other, more specialized functions.this system involves multinational telecommunications carriers, cablecompanies, corporate networks, nonprofitorganization networks, governmentagency networks, sole proprietorships, and even hobbyists. eachnetwork consists of a set of opticalfiber, coppercircuit, or wireless communications links that connect to òendhostsóñdesktop personal computers (pcs) or servers that provide web contentñor to specialized computers known as routers that control the paths taken by data packets. theinterconnection of these networks is facilitated by a set of standardizedprotocols that determine how data and routing information are exchanged.the networks of the internet are not only interconnected but for themost part are richly interconnected. its architecture, which dynamicallyadjusts the routes that packets follow in response to changes in the network (such as failures of communications links), emphasizes redun1boardwatch magazine (<http://www.boardwatch.com>) lists 9,400; cyberatlas (<http://cyberatlas.internet.com/bigpicture/geographics/article/0,,5911151151,00.html>) putsthe worldwide figure at more than 11,400.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.12the internet under crisis conditionsdancy.2 however, this redundancy has its limits; only a finite number ofpaths connect any given point to the rest of the system. also, geographyand economics mean that some locations have a high concentration ofinternet facilities while others only have few.new york city, a principal focus of this report, can be thought of as aòsuperconnected node.ó this is largely because the city has a great manyinternet users, private data networks, isps, and fiberoptic grids.3 forexample, more than 600 dialup isps and over 300 digital subscriber line(dsl) providers are listed in the isp directory boardwatch for the boroughof manhattan alone. fiberoptic cables enter and exit manhattan by wayof at least five different rightsofway. at least 74 u.s. and multinationaltelecommunications carriers have equipment in new york, either in colocation facilities or in private suites. the city is served by more than 100international internet carriers, and it has direct links with 71 countries.4connected to the internet through the longhaul fiber networks ofseveral major carriers, new york city is also a major interconnectionpoint for these carriers.5 interconnection is for the most part done at oneof several key òcarrier hotelsóñbuildings in which carriers lease space inorder to link with other carriers located in the same building. internetproviders connect with each other through private connections at thecarrier hotels, either directly through internet exchange points such as thenew york internet exchange (nyix) or indirectly through transit providers. most transatlantic telecommunication cables landing along the newjersey/new york coastline are òbackhauledó to one of the manhattan2the redundancy and distributed character of the internet clearly echo the design contemplated in paul baranõs seminal studies of packet networks at rand. the series, together with brief commentary, is available online at <http://www.rand.org/publications/rm/baran.list.html>.3the lower manhattan telecommunications usersõ working group (lmtuwg. august 2002. building a 21st century telecom infrastructure: lower manhattan telecommunications usersõ working group findings and recommendations) reports six physically distinctfiber networks in lower manhattan (at&t, con edison communications, mci worldcom,metromedia fiber network, time warner, and verizon). information supplied to the committee by anthony townsend indicates more than 40 providers of fiber in manhattan, notall of which are physically distinct (because of sharing and resale by providers).4telegeography, inc. october 2001. telegeography 2002: global statistics and commentary.washington, d.c. executive summary available online at <http://www.telegeography.com/ products/books/pg/pdf/pg2002exesum.pdf>.5in addition to new york city, washington, d.c., stands out on the east coast of theunited states as having a high concentration of internet facilities. several internet serviceproviders maintain networkcontrol and data centers near washington, d.c., and in northern virginia. thus, in most isp networks, the new york citytowashington, d.c., corridorcontains the largest number of circuits.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.13introductioncarrier hotels to facilitate interconnection with other network operators.in some cases, the only route by which carriers can interconnect with thetransatlantic cables is at one of the new york city carrier hotels.local internet access may be provided through a number of differenttechnologies, including dialup, integrated services digital network(isdn), dsl, t1, cable modem, wireless, and sonet fiber. many ofthese connections take place over the network of the local exchange carrier, verizon, and the longhaul fiber networks connect to verizonõs central offices as well. several isps that have registered as competitive localexchange carriers (clecs) also have equipment in these central offices;collocated equipment there connects their networks to verizon facilitiesthat in turn connect the isps to their customers through dsl or isdn.finally, dialup customers use the verizon local network to place phonecalls to modems operated by their isps. other highspeed local datacircuits are supplied by such companies as time warner cable, frontier,cablevision/lightpath, metromedia fiber network, inc. (mfn), at&tlocal services, and worldcom.what would it mean for the internet to fail?there are two principal types of failure that the internet can incur:1.parts of the network, such as interconnection points or communicationslinks, are damaged or destroyed, and consequently the internet stops functioningas expected. there are two obvious manifestations of this kind of failure.first, the internet could be damaged enough that it is partitionedñsplitinto separate networksñso that a user might be able to reach some websites or send email to some places but unable to communicate with others. second, the internet could remain fully interconnected but the damage might cause a reduction in capacity that impairs the networkõs operation in a material way. that is, when some links are damaged and newroutes are constructed by the network to bypass the failed components,the backup paths are often of lower bandwidth. thus there is less overallcapacity, and increased network congestion is a likely outcome. a usermight, for example, experience significantly greater webpage loadingtimes and be unable to view video clips.2.changes in network use result in higher loads that cause parts of thenetwork to be overwhelmed by traffic. for example, increased network use ina particular geographical area could overload the aggregate capacity connecting that area to the rest of the internet. or, increased demand on aparticular service, such as a web site, might exceed the capacity of thelinks to that service or the capacity of the computers providing it.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.14the internet under crisis conditionsboth types of failureñwhether or not either of them occurred as aresult of the september 11 attacksñare considered in this report.a brief overview of events on september 11, 2001as the catastrophe at the world trade center unfolded, elements ofthe communications and power infrastructures were impaired, damaged,or destroyed. box 1.1 provides a detailed outline of what transpired onand immediately after september 11. local effects, such as damage toverizon switching centers and lastmile facilities, had direct effects onlower manhattanñnotably, the loss of telephone lines and damage to thecellularphone system. at the same time, the infrastructural damage hadeffects that extended beyond the immediate area. following is a summary of the key events and their effects on telecommunications, includingthe internet:¥8:45ð10:00 a.m. towers are attacked and set afire. interior worldtrade center (wtc) communication is disrupted. increased volume congests local exchanges and wireless networks. limited physical damageoccurs to the surrounding local telephone networks.¥10:00ð11:00 a.m. towers collapse. because the wtc was a significant wireless repeater site, some wireless connectivity is disrupted (sprintpcs, verizon, at&t wireless). several ispsõ points of presence (pops) inthe complexñthose of worldcom, at&t local service, and verizon/genuityñare destroyed. some data and privateline services to a diverseset of customers in new york city, connecticut, massachusetts, and evensome european locations are disrupted.¥11:00 a.m.ð5:00 p.m. local power failures occur and some equipment is switched over to battery and/or generators. fires burn in thewtc complex.¥5:20ð5:40 p.m. wtc building 7 collapses, destroying a consolidated edison electrical substation in the process. the collapse alsobreaches the 140 west street verizon central office building, causing damage to equipment and the flooding of basement power systems. the fires,collapse, and flooding knock out much of the telecommunications servicein lower manhattan.although there were other significant events on september 11, 2001,this report mainly examines those in new york city. the crash of unitedairlines flight 93 in somerset county, pennsylvania, and that of american airlines flight 77 into the pentagon did not appear to have any additional impact on the public internetõs infrastructureñthough they weredefinitely a factor in shaping how people made use of the network. thethe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.15introductionbox 1.1detailed time line of the events of september 11, 2001, and thedays immediately followingdate and timeeventinternet effect9/11/20017:59ð8:42 a.m.american airlines flight 11,united airlines flight 175,united airlines flight 93, andamerican airlines flight 77 take off.8:40 a.m.federal aviation administration(faa) notifies north americanaerospace defense command(norad) american flight 11hijacked.8:43 a.m.faa notifies norad americanflight 175 hijacked.8:46 a.m.american airlines flight 11crashes into north tower(wtc 1) of world trade center.8:46 a.m.fighter scramble order: twof15s dispatched from otis airnational guard base infalmouth, mass. (airborne 8:52 a.m.).8:52 a.m.port authority transhudson(path) train service ordered stopped.9:02 a.m.united flight 175 crashes intobbc, cnn, msnbc,south tower (wtc 2).new york times, yahoonews, and other newsweb sites becomeextremely unresponsive.smaller local andregional news sites suchas sfgate.com andnando.net stillresponsive.9:12 a.m.òrescueó path train departswtc station.9:17 a.m.faa shuts down all new yorkcity airports.9:21 a.m.all bridges and tunnels in newyork city closed.continuesthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.16the internet under crisis conditions9:24 a.m.faa notifies norad americanflight 77 hijacked; line kept open;united flight 93 reported hijackedduring same call.9:24 a.m.fighter scramble order: two f16sdispatched from langley air forcebase, va. (airborne 9:30 a.m.).9:32 a.m.new york stock exchange closed.9:37 a.m.american flight 77 crashes intopentagon.9:39 a.m.all new york city vhfstations, except cbs 2,off the air. many radiostations also off the air.9:40 a.m.faa orders nationwide airtraffic halt.9:45 a.m.passenger on united flight 93makes cellphone call.10:03 a.m.united airlines flight 93 crashesin somerset county, pa.10:05 a.m.wtc 2 (south tower) collapses.verizon (south tower),genuity pops in worldtrade center destroyed,at&t local services popin subbasementoperating on batterypower.10:10 a.m.portion of pentagon collapses.10:28 a.m.wtc 1 (north tower) collapses.10:31 a.m.transatlantic circuitreported down afternorth tower collapse.10:32 a.m.isp operators report trafficvolume decreasingslightly on networks.11:02 a.m.all new york city bridges openedfor outbound traffic only.box 1.1continueddate and timeeventinternet effectthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.17introduction11:12 a.m.hundreds of ds3 circuitsreported down in newyork city.11:39 a.m.cnn.com back up withvery low graphics.1:02 p.m.new york city mayor giulianiorders evacuation of manhattansouth of canal street.1:16 p.m.worldcom ss7 longdistance switchexperiences problems.2:26 p.m.at&t reports its longdistance network isintact, but someequipment was damagedin its local new yorkservice.3:48 p.m.cnn.com employsakamai content servernetwork to increasecapacity.3:48 p.m.covad reports serviceaffected by fire in/near140 west street centraloffice.4:35 p.m.commercial power fails because of25 broadway, 32 oldfire at world trade center buildingslip, 140 west street on7 (built over consolidated edisongenerator power.substation); con edison reportsarea bordered by dover street onthe north, the east river to the east,william street to the west, andwall street to the south withoutcommercial power.5:20 p.m.world trade center building 7verizonõs 140 west streetcollapses.central office wallsbreached by falling steelbeams.box 1.1continueddate and timeeventinternet effectcontinuesthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.18the internet under crisis conditions7:17 p.m.u.s. attorney general ashcroftannounces fbi has set up website for tips about the attacks:<www.ifccfbi.gov>.7:33 p.m.verizon announces payphones inlower manhattan free for local calls.8:30 p.m.president bush addresses the nation.9:54 p.m.federal emergency managementagency notifies primary emergencyalert system stations by email toòmake any and all preparationsóif primary communication methodsfail (estimated time).10:07 p.m.isp dialaccessequipment overheating in32 old slip. reductionin inbound calls fromnew york city area.10:26 p.m.generator stopped at 32old slip; some carrierson battery.10:36 p.m.verizon circuits at 60hudson street reporteddown.11:21 p.m.nyc.gov (161.185.0.0/16) offline.9/12/20011:09 a.m.generator started at 32old slip; verizon circuitsstill down.2:30 a.m.sprint reports that powerfluctuations at a newyork city switchingfacility disrupted sprintvoice, data, and wirelessin southern connecticut.9:00 p.m.incorrect report of structuralproblems at 60 hudson street.box 1.1continueddate and timeeventinternet effectthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.19introduction10:22 p.m.nyc.gov restored online.fuel truck allowed intoarea to refuel 25broadway.9/13/20015:38 p.m.25 broadway generatorfailure; some equipmenton battery.saix (south africainternet exchange), nyix(new york internetexchange), dante,teleglobe, and manyother providers affected.9:28 p.m.25 broadway generatorrepaired.9:47 p.m.25 broadway generatorfails (again).9/14/200111:59 a.m.fiber cut south ofwashington, d.c.(mfn).8:26 p.m.32 old slip power fails.8:55 p.m.32 old slip powerrestored.11:10 p.m.25 broadway restored onconsolidated edisonsupplied generator.9/15/20011:28 p.m.25 broadway generatorout of fuel; because ofmisjudged fuelconsumption and fueltruck travel time.8:03 p.m.25 broadway generatorrefueled.source: compiled from various news reports and reports obtained by the committee fromrepresentatives of various internet service providers.box 1.1continueddate and timeeventinternet effectthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.20the internet under crisis conditionsdestruction at the pentagon certainly had some effect on military communications, but those are not considered in this report. however, as isdiscussed in chapter 2, indirect impacts on internet operations in thewashington, d.c., metropolitan area were felt as the normal course ofbusiness was disrupted.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.212the network experienceseptember 11, 2001, started out more or less routinely on the internet.early tuesday morning is a common time for internet service providers(isps) to schedule maintenance activities on their network, and on thatparticular tuesday there were some instances of delay or packet lossbetween 2:00 a.m. and 5:00 a.m., when verizon updated software on eastcoast framerelay switches and other isps made changes in their networks. but by 6:00 a.m. eastern time, it appears that the internet routingand traffic loads were normal for the start of a workday.that normalcy would be shattered for the internet, as for so manyother operations, when american airlines flight 11 crashed into theworld trade centerõs north tower at 8:46 a.m. within minutes, majoronline news sites were struggling to serve between 3 and 10 times theirnormal load as internet users sought details. one news web site estimated that traffic to its web servers was doubling every 7 minutes, beginning around 8:50 a.m., until about 9:30 a.m.by just after 9 a.m., when united airlines flight 175 crashed into theworld trade centerõs south tower, the web sites of cnn, msnbc, thenew york times, yahoo! news, and others were observed to be slowingsignificantly. the cause would later be reported to have been the loads onthese sitesõ servers, not connectivity problems in reaching servers acrossthe internet. then the south tower collapsed, damaging equipment andcircuits in the trade center complex. the subsequent collapse of thenorth tower, the collapse of world trade center building 7 (a 47storystructure), damage to the neighboring verizon central office, and powerthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.22the internet under crisis conditionscuts in lower manhattan all had disruptive effects on the internet andother communications systems.how did the internetõs communications infrastructure in particularexperience all these events? how much did the events in new york city,and in washington, d.c., affect the movement of data throughout theinternet? how were isps affected by the events of september 11? howserious were the impacts? what actions did isps (and others) take inresponse?this chapter sets out to answer those questions, as best they can beanswered with the available information. data pertaining to the internetoperations that day were of two types: quantitative data on the system asa whole and on the response of particular networks, and anecdotal reports from network operators, users, and news media that help providecontext and possible explanations for the changes on the internet, both atthe macro and micro levels, that were deemed necessary after the attacks.how comprehensive and authoritative is this information? some ofitñfor example, data on changes in the internetõs routing configurationsñpermit the overall impact on the internet to be measured. reports onspecific incidents, on the other hand, do not allow generalizations aboutthe whole system, though they do provide insights into the kinds of localproblems that could arise in the future and the responses that may mitigate them. still, the participation in this study of several national ispsand one new york regional isp, together with the anecdotal informationobtained though informal informationsharing relationships within theinternet operator community, permit at least a reasonable sampling of theoverall experience. in addition, user surveys taken by the pew internetand american life project allowed the committee to relate reported userbehavior to some isp measurements.1 however, in a number of instances,data that would inform the committeeõs understanding of what transpiredon and shortly after september 11 were lacking (a detailed discussion ofinternetmeasurement issues is presented in chapter 5).overview of damage and impairmentthe terrorist attacks in new york city caused an immediate disruption in communications within the world trade center complex. soonthereafter, the collapse of the twin towers damaged and destroyed equipment of several wireless providers and some data circuits serving the1lee raime and bente kalsnes. 2001. the commons of the tragedy: how the internet wasused by millions after the terror attacks to grieve, console, share news, and debate the countryõsresponse. pew internet & american life project, washington, d.c., october 10. availableonline at <http://www.pewinternet.org/reports/toc.asp?report=46>.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.23the network experiencenew york city area, the northeastern united states, and europe. duringthe rest of the day on september 11, local power failures caused temporary equipment outages.these events had several types of effects on isps and internet users,including the following:¥loss of internet connectivity in the vicinity of the attacks. the effects innew york city were extensive as a result of the catastrophic damage atthe world trade center site, the large number of nearby institutions, andthe important role that new york city plays in the internet infrastructure.two main factors contributed to the loss of internet connectivityñthepermanent destruction of networking equipment at the site and the lossof power and cooling in adjacent areas for varying lengths of time. (bycontrast, the attack in washington, d.c., did not appear to have a directinfluence on network connectivity for institutions outside the pentagon.)¥connectivity loss at òout of townó locations in the united states and inother parts of the world. several isps elsewhere in the united states andoverseas experienced connectivity problems resulting from the loss offiberoptic lines that ran through manhattan and the temporary disruption of access to manhattanbased services. (the experience of these networks and providers offers insights into how to plan for future incidents.)¥surges in demand for some internet services. as word of the attacksbegan to spread, internet users turned to a variety of news sites for moreinformation. the greatly increased load on these sites made it difficult forall requests to be met.collapse of north and south towersinternet facilities were destroyed when the world trade centerõstwin towers collapsed. several isps, including at&t local systems,genuity, verizon, and worldcom, had points of presence (pops)ñfacilities at which customers are connected to an ispõs networkñlocated in thetrade center complex. also, a number of fiberoptic cables ran throughthe complex in conduits, and circuits of one major telecommunicationscarrier ran through the port authority transhudson (path) subsiterail tubes that link manhattan and new jersey. mfn alone reported theloss of more than 1,300 optical fibers as a result of the towersõ collapse.building 7 collapse and damage to verizon central officeat approximately 3:45 p.m., isps received reports of a fire in or nearthe verizon central office at 140 west street. from a local perspective, thebiggest effects probably came from the collapse of building 7 of the tradethe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.24the internet under crisis conditionscenter complex at about 5:20 p.m.; this collapse caused extensive damagein verizonõs central office, across the street at 140 west street, crushingthe walls and cable vaults and causing the office to begin to flood. theresult was disrupted service over the course of the evening. some 14,000business and 20,000 residential customers lost telephone service (approximately 300,000 voice circuits). data communications, with a total capacity equivalent to 3.6 million 56 kilobitpersecond (kbps) circuits (or 90 oc48 sonet links), were also disrupted. ultimately, all customers directlyconnected to equipment located at west street lost internet service. several competitive local exchange carriers (clecs) and isps also had equipment in the west street building, and service in their networks was affected as well.damage to 140 west street also caused further damage to fiber linksalready compromised by the collapse of the twin towers. in some casesthe fiberoptic infrastructure had selfhealed by routing around the damage done by the towersõ collapse; the sonet fiberoptic rings commonlyused for metropolitanarea networks can be configured to automaticallyrecover in the event of a single cut in the ring. but the infrastructure wasnot designed to heal from a second break in the fiber.as a result of these events, internet connectivity to several universities, medical colleges, and hospitals, and to the city governmentõs officialweb site, was interrupted. isps took a number of steps to restore connectivity, as described below.electrical power at colocation sites in lower manhattanin addition to the direct effects from the collapse of the twin towersand building 7, there were indirect effects of the attacks, especially regarding electrical power. these disruptions had consequences for othercritical telecommunications facilities, even those located outside the areaof the attacksõ direct physical impacts.to be sure, telecommunications facilities operators make provisionsfor power failures. isp colocation facilities and telephone central officescontain backup batteries and generators. the exact battery time and fuelcapacity of individual offices is not public information, but they generallyare provisioned for between 8 and 72 hours of backup in case of commercial electricutility failure. most facilities routinely test their backup systems to ensure thatthey work. however, it is still not uncommon for a backup system to failto start up correctly when regular power fails.2 still, by 4:35 p.m., several2participants at the committeeõs meeting in washington, d.c., estimated that backupsystems fail to start correctly in about 1 out of 10 tests.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.25the network experienceinternet colocation facilities near the world trade center complex wereoperating on backup generators because commercial utility power hadfailed or been turned off (by consolidated edison, the local electric utility).luckily enough, the backup power systems at all the colocation andphone facilities in lower manhattan apparently turned on properly whenconsolidated edison was forced to turn off power just before 10:00 p.m. onseptember 11. however, as the power outage extended over multipledays (past the planned life of the backup power systems), maintainingpower became a serious issue as batteries expired and backup generatorsran out of fuel.following the loss of the grid electricity supply, some fiberoptic links,which depend on electrically powered termination devices at each end forsending and receiving pulses of light over the fiber, failed. it is standardpractice to attach these devices to batteries, which provide several hoursof backup power. however, several providers apparently failed to anticipate significantly longer power outages, such as providing additionalbackup using electrical generators. consequently, in the early morning ofseptember 12, some minor perturbations in internet connectivity occurredin the new york city area when the backup batteries supplying opticaldevices ran out of power themselves.although power problems did not persist beyond the month of september 2001, some longerterm effects may still remain. in particular,some networking equipment in the area around the world trade centersite may have sustained damage from overheating, caused by the loss ofpower to cooling systems and excessive dust in the air conditioning. oneconcern from such incidents is that the affected equipment, though stilloperating, could be less reliable in the future.internetwide (global) phenomenarouting and reachabilitychanges in routing information exchanged using the border gateway protocol (bgp) indicate changes to the internet protocol (ip) routingtopology (see chapter 5 for more details). route withdrawals (indicatingthat a path to a group of internet addresses is no longer available) andadvertisements (indicating how to reach a group of internet addresses)are routine events. they occur, for example, as circuits go up and downand when network operators make changes in their networks to adjusttraffic flows across different routes.the collapse of the south tower was the first event to cause visibleeffects on global routing. figure 2.1 (prepared by renesys corporation,using data collected by the ripe [r”seaux ip europ”ens] network coorthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.26the internet under crisis conditions102,000104,000106,000108,00081416182022nimda1012wtc 2 down25 bway power out25 bway power backday in september 2001number of reachable prefixesfigure 2.1 number of reachable network prefixes as reported by several bgpcore routers from the united states, europe, and japan from september 8 to september 22, 2001. (all times gmt.) major events are marked on the plot.source: renesys corporation analysis of ripe ris archives.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.27the network experiencedination center from several sources) shows changes to the bgp routingtable. events are reflected in reachability measures as well: matrixnetsystems recorded a brief 8 percent decrease in the ability to reach(ping) a select number of sites on the internet in the minutes following thecollapse of the first tower (see figure 2.2).3 a loss of this magnitude foran extended period of time would generally be considered a serious problem, but its occurrence for a brief period of minutes is less soñand certainly not unprecedented. data from a full month show other dips inreachability, but of a smaller magnitude (see figure 2.3).internet routing and reachability measurements returned nearly tonormal within 15 minutes of the collapse of the south tower. however,matrix netsystems and telstra bgp data show that on september 11,about 1 to 2 percent of the approximately 105,000 routes did not return tonormal for almost 24 hours. some of these routes were for businesseslocated in the world trade center complex. interestingly, others wereassociated with isps in other countriesñitaly, germany, romania, andsouth africa, for example. the collapse of the north tower appears tohave caused some transatlantic circuits to fail, and these isps obviouslydepended on their new york city links for more than just connectivity tothe united states (see box 2.1).an analysis of the bgp message activity measured during and afterseptember 11 shows that some global routing òeventsó (spikes in thevolume of bgp messages) did take place because of outages caused by theattacks. however, the magnitude of these events was quite modest.overall, the rate of bgp routing advertisements and withdrawals suggests that the internet was actually more stable than normal on september11. one possible reason for this overall stability is that network operatorsunderstandably tend to avoid optional maintenance and hardware orsoftware changes during emergencies. anecdotal information from network operators also suggests that many operators were watching thenews instead of making normal changes to their routers. the most significant traffic and routing events occurred several hours after the attacks;they resulted from damage to the verizon central office at 140 west streetand power failures at the telehouse 25 broadway internet colocationfacility. several of these events are visible in figure 2.1.3different sets of hosts used by matrix netsystems display ònormaló reachability levelsof less than 100 percent because the list of hosts in each set is kept constant to enablecomparisons over long intervals and some hosts on the list no longer exist.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.28the internet under crisis conditions%formatted wed sep 12 11:39:36 2001 gmttimezone (msdw2, new york, ny)http://www.matrixnetsystems.comcopyright © 2001 matrix netsystems, inc.gmt edt sep 1103:0005:0007:0009:0011:0013:0015:0017:0019:0021:0023:00sep 1011 pmsep 113 am5 am7 am9 am11 am1 pm3 pm5 pm7 pm112233441122334480828486889092949698100reachability %4 world isp1000 (1098)3 dns tld servers (12 www (335)1 internet (1267))figure 2.2 reachability of four representative sets of internet hosts on september 11, 2001. source: matrix netsystems, inc.%formatted sat sep 15 23:07:21 2001 gmttimezone (msdw2, new york, ny)gmt edt sep9/39/49/59/69/79/89/99/109/119/129/139/149/15aug 31sep 1sep 2sep 3sep 4sep 5sep 6sep 7sep 8sep 9sep 11sep 13112233441122334480828486889092949698100reachability %4 world isp1000 (1082)3 dns tld servers (1)2 www (341)1 internet (1267)http://www.matrixnetsystems.comcopyright © 2001 matrix netsystems, inc.figure 2.3 reachability of four representative sets of internet hosts during 12days in september, 2001. source: matrix netsystems, inc.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.29the network experiencebox 2.1how damaged cables in new york city could affect the internetin other countriesit may seem surprising that events in new york city could have disrupted internetconnectivity far from u.s. shores, but one explanation is the structure of the international telecommunications market. the pricing and availability of internationalphone circuits are complex and do not necessarily reflect such simple measures asdistance. they do reflect such factors as treaties, other historical ties between countries, and geography. for example, it is often easier to run a cable under water thanacross land. also, in many cases, it is much less expensive for an internet serviceprovider (isp) in country a to connect with an isp in neighboring country b byleasing a line to the united states (or, in some cases, to the united kingdom) thansimply by leasing a line that runs directly from a to b. as a result, many regionschoose to interconnect their various isps in the united states. new york city (andlondon) are key interconnection points for africa and parts of europe. miami, florida, is a major interconnection point for central and south america. it is this counterintuitive interconnection pattern that explains why the collapse of the world tradecenter affected networks in italy, germany, romania, and south africa.traffic load across the internetactive pingstyle probes are used by a number of entities to monitorthe internet. data from these sources showed only a small loss in overallconnectivity during september 11 and a corresponding slight increase inpacket delay times and loss. one example, collected by the cooperativeassociation for internet data analysis (caida), is shown in figure 2.4.measurements such as these reflect a sort of global average, highlightingthe fact that from a global traffic perspective, the events of september 11were actually quite localized in scope.these observations are supported by passive measurements of packettraffic. reports of several isps that participated in the committeeõs workshop indicated that the total level of internet traffic in fact dropped slightlyon september 11 compared with that on the previous tuesday. the normal internet pattern, by contrast, is for traffic volume to increase slightlyeach week.one isp provided workshop participants with detailed informationabout traffic on its backbone that confirmed the general reports receivedfrom other isps. the isp providing the detailed information did notexperience any unusual peak traffic loads, delay, or loss within its backbone. nor did it report any unusual routing instability there. impactswere confined to the edges of its network, such as customeraccess lines.this view is supported by data from yahoo, which averaged roughly 1the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.30the internet under crisis conditionsfigure 2.4 reachability seen by various caida monitors in september 2001.source: caida.billion page views per day at that time. traffic to news sites jumpedthreefold on september 11, and queries related to a search for newsjumped 50fold; yet the overall traffic was just slightly lower than normal.not all isps reported lower traffic levels, however. some that specialize in content delivery (i.e., isps that combine regional or national networks and highperformance web servers to provide highperformanceweb hosting) saw a large increase in traffic. one nationwide contentdistribution network (akamai) saw traffic jump 350 percent above normal, likely reflecting increased interest on september 11 in particular content, such as news images, and additional use of its service by some majorcontent providers.another measure of internet use is the rate at which dialup users login to their isps. consistent with reports that overall traffic declined, datafrom america online (aol) show logins on september 11 falling belowthe rate on september 10 during the period immediately following theplane crashes and during the evening hours (see figure 2.5). two plausible explanations are that internet news sites were experiencing highcongestion levels and that users were watching television to obtain newsand information.23456789101112131415day in september 200105,00010,00015,00020,00025,00030,000number of replying destinations in a cyclepalo alto, calif.college park, md.moffett field, calif.amsterdamtokyo herndon, va.marina del rey, calif.tokyo washington, d.c.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.31the network experiencedomain name systemnot all internet applications and services were affected significantlyby the crisis. an example is the domain name system (dns)ñan important internet service that looks up a name (e.g., <www.example.com>) inits databases and returns the internet protocol address (e.g., 190.0.34.72)associated with that name.4 this process is known as name resolution.measurements of dns activity during september 11 show that the loadon the root servers was normal to lightñmost likely because caching ofdomain names on endhosts is typically very effective in reducing load onthe system, especially when most users are accessing commonly requestedsites during a crisis event. there was, however, a dns problem in southafrica stemming from the loss of connectivity in new york, as describedin the following section.specific nonlocal effectsas noted earlier, the damage around the world trade center complex had impacts worldwide. in addition to interruptions in local ispsõ010,00020,00030,00040,00050,00060,00070,00080,00090,00012 am2 am4 am6 am8 am10 am12 pm2 pm4 pm6 pm8 pm10 pm10 sept11 sept8:45 a.m.aa flight 11 crashes into the wtc north tower.9:03 a.m.ual flight 175 crashes into the wtc south tower.9:43 a.m.aa flight 77 crashes into pentagon.10:05 a.m.wtc south tower collapses.1:04 p.m.president bush declares us military worldwide is on high alert. 8:30 p.m. president bush delivers televised address to the nation. logins per minutetimefigure 2.5 aol logins per minute on september 10 and september 11, 2001.source: geraldine macdonald, america online.4w. stevens. 1994. tcp/ip illustrated, vol. 1: the protocols. addisonwesley, boston.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.32the internet under crisis conditionsconnectivity to the rest of the internet, there were more complexñandsurprisingñeffects on the connectivity of providers, some of them located well outside new york city. these effects, resulting from subtleinterdependencies between different systems and protocols, includeddialup access problems for isps with pops located in new york city;loss of connectivity for networks in such disparate places as romania andat the european organization for nuclear research (cern) in geneva,switzerland; and dns problems in south africa. several of these problems are detailed below.difficulties accessing popsisps that offer dialup connectivity must provide several facilities,including modem banks and pops. customers prefer to make a local(nontoll) call to connect to their isps, so the providers seek to have modembanks in most local calling areas. once connected through a modembank, customers must authenticate themselves with the isp before beingconnected to the internet or allowed to use ispprovided services such asemail or customercreated web pages. building a network that providesthese capabilities in each local calling area is expensive and hard to maintain, so it is common practice for isps to simply connect a set of modembanks to a single pop (a practice known as backhauling, because the ispòhauls the data backó to a common point). in this way, the equipmentrequired at each modem bank is kept to a minimum. because such popsoften cover several states or even a larger region, and because severalprovidersõ pops for the northeastern united states happened to be locatedin new york city, some customers in other states found that even thoughthey could establish a dialup connection, they could not connect to theinternet. their local modem banks, unbeknownst to them, were connectedto a new york city pop that was out of service.disruption of the dns in south africainternet disruptions in new york city led to at least one protocolrelated delayed reactionñdisruption of dns serviceñfar away. someusers in south africa reported difficulty resolving domain names endingin .za, the toplevel domain for south africa, in the days following september 11. as a result, they could not access internet services (such asweb servers) within the country, despite the fact that there were no physical network disruptions in south africa itself at that time.the answer to how this happened even though networks and dnsservers in south africa continued to operate lies in the design of the dns.to reduce the load on name servers, the dns supports automatic cachingthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.33the network experienceof frequently used names, allowing common requests to be handled withinformation in caches operated by a userõs isp. only requests that are notcached are passed to higherlevel servers, and if no cached information isfound, ultimately the request is passed to the dnsõs root servers. however, this caching does not completely isolate these users from loss ofconnectivity with the root servers. to ensure that updated informationpropagates throughout the internet, dns entries have an expiration dateassociated with them. once an entry expires, a cache flushes the storedinformation and requests a fresh copy. if the root server cannot bereached, this flushed information cannot be restored.interdependency in hospital wireless networksanother surprising problem resulted from the loss of internet connectivity in several hospitals. today, many hospitals rely on handheld computers and wireless connectivity to provide doctors with bedside accessto hospital databases (for receiving updated laboratory reports, for example). it turns out that by contracting with an outside carrier to providethis wireless connectivity, the hospitals introduced a dependence oninternet links. thus if the internet link between the hospital and thewireless carrier fails, the wireless devices will lose access even to internaldatabases.surmounting interdependencies such as these is important, becausethey can lead to surprising failure modes, and it is difficultñbecauseinterdependencies can arise from effects ordinarily hidden by the layeredstructure of the internet architecture, or by the tendency of commercialinternet services to keep private (for competitive reasons) the specificsabout their underlying interconnection structures. these interdependenciescan become even more difficult to comprehend in the face of technologiesthat complicate the basic structure of internet connectivity, such as virtualprivate networks, private address realms interconnected using networkaddress translators, overlay networks, firewalls, or transparent proxies.in some cases, such technologies make interconnection easier by hidinginternal details of the networks. at the same time, their presence cancomplicate interconnection by imposing additional hurdles that must benegotiated beyond the basic internet protocol connectivity.restoration effortsdespite the physical destruction in new york city on september 11,internet connectivity was quickly restored for many of the affected institutions. probably the most enduring image of datacommunications restoration was the tremendous effort to put the new york stock exchangethe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.34the internet under crisis conditionsòback in business.ó but a number of other efforts to restore internetconnectivity were mounted rapidly. these activities, which involved theuse of alternate paths to the internet as well as the rapid deployment ofnew infrastructure, were usually less visible and more improvised, thoughgenerally effective.isp cooperationas the events of september 11 unfolded, many internet service providers took steps to ensure that their networks would continue to runsmoothly. their actions ranged from increasing staff at network operations centers to coordinating with other isps to assure connectivity.ordinarily competitive service providers cooperated to restore connectivity lost after verizonõs 140 west street facility was damaged. forexample, nysernet (a nonprofit networking consortium) and appliedtheory (a forprofit spinoff of nysernet) reconfigured routers, sharedtheir circuits, and made use of other circuits as far away as buffalo, newyork, to restore service to medical institutions in new york city; thisroundabout approach was necessary because the two organizationsõ personnel could not enter the cordonedoff area south of 14th street to accessequipment.one result was that nyc.gov, the official new york city web site,was back in service on september 12 at 8:22 p.m. after a few days, accessrestrictions in lower manhattan were relaxed, and nysernet and applied theory staff could enter facilities in lower manhattan to reconfigurecapacity on other sonet rings and restore service to schools, hospitals,and city governments on long island. similar cooperation was reportedin london and amsterdam as isps made use of interconnection facilitiesin those cities to reconnect networks that normally would link in newyork city.isps encountered some glitches as they sought to communicate witheach other to coordinate their activities. the isps typically have the phonenumbers of one anotherõs network operations centers so that their staffscan cooperate during major outages. in most cases, these are tollfreenumbers. but during the middle of the day on september 11, tollfreedialing on the worldcom telephone network was disrupted (though thetollfree service of other major providers remained operational) as a resultof link failures and an increased volume of phone calls.5 some isps then5worldcom estimated that 187,465 tollfree queries failed during an approximately 12hour period, starting at 9:00 a.m. on september 11. according to worldcomõs outage reportto the federal communications commission: òthe root cause of the problem has beenisolated to message congestion between the signal control points (scps) in west orange,the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.35the network experiencefound themselves scrambling to exchange nontollfree numbers that theynormally would not have expected to need.some isps also discovered problems with their contingency plans.not all isps require that their equipment automatically restart in case of apower failure; their expectation had been that in the very rare event ofboth primary and backup power failure, they would be able to manuallyrestart their systems once power was restored. but the power outage atthe telehouse facility and its location in a limitedaccess area made thoseexpectations untenable. the lesson is, in fact, not new. telephone companies and some of the more savvy isps already knew it. nonetheless, theincident points to the need for all telecommunications providers to consider such contingencies and to be equipped to deal with them.another operational challenge faced by isps working to restore ormaintain their networks was that of basic support for personnel. givenlocal business closures in the wake of the attacks and the extended shiftsthat staff were required to work, some isps found it difficult to obtainfood service for them.improvising to restore connectivityin a number of cases, improvised links allowed connectivity to berestored. some of these efforts relied on the internetõs architecture, whichis compatible with almost any sort of communications link and accommodates almost any sort of service. for example:¥wireless data links using unlicensed spectrum were used to reestablish customer connectivity from sites in lower manhattan to sitesslightly farther north, where internet links were undamaged.¥time warner cable (twc) deployed cable modem service to provide connectivity in state and local government offices. for example,when wnyw (fox) and police plaza lost their digital subscriber line (dsl)connections, twc replaced the internet connectivity with road runnercable modem service. twc also supplied new york cityõs morgue withnew jersey, dominguez hills, california, and irving, texas and the switch network resulting from a mass calling event following the terrorist attacks in new york and washington,d.c. multiple link failures contributed to the congestion. as a result of the congestion, scpservers were intermittently unable to respond to queries, causing toll free service calls fromthe switch network to time out and fail.ó (worldcom. 2001. final service disruption report,no. 01149. worldcom, washington, d.c., october 11. available online at <http://www.fcc.gov/bureaus/engineeringtechnology/filings/networkoutage/2001/reports/01149.pdf>.)the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.36the internet under crisis conditionsstatic ip addresses so that it could create its own networks, and cable androad runner service were installed at the staten island red cross. voiceoverip (voip) phones running over the cable network were used to support communications among city and state offices.6¥internet phones were used in new york city as a way of circumventing problems with the local and longdistance phone networks. organizations making these facilities available included local universities(chiefly for their students), time warner, and cisco.¥in washington, d.c., a temporary ip infrastructure was deployedat the old naval research laboratory facility to provide communicationsservices for the department of defense units from the pentagon.in addition, many users communicated using unconventional means.institutions that had lost network connectivity were given the temporaryuse of other offices with internet access through the generosity of othercompanies and universities.also, once it was discovered by the late afternoon of september 11that making longdistance calls was often easier in new york city thanplacing local calls, isps began to advise residents having difficulty dialinginto their internet service providers to make longdistance phone calls inorder to reach modems in other locations. anecdotal accounts suggestthat a large number of people did just that.the experiences of other communications networks: telephone, wireless voice and data, andbroadcastingthe internet was only one of several communications systems affected by the events of september 11. to place its experience in context,this section provides a brief overview of the other communications networksõ efforts that day.telephoneas an indication of how quickly news travels (and a testament to howwell the communications infrastructure was working), changes cameswiftly. apparently the first communications impact outside new yorkcity occurred right after united airlines flight 175 struck the south towerat 9:02 a.m., as the load on some telephone switches in northern new6òworld trade center tragedy: time warner cable of new york city & ny1 newsefforts.ó time warner cable news release, september 14, 2001.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.37the network experiencejersey impaired parts of the national tollfree calling system (discussedabove, in the context of isp coordination). because of congestion, thegovernment emergency telecommunication system, which provides authorized users with priority access to telephone circuits, was employed bygovernment officials. by about 9:15 a.m., the situation was quite exceptional. in new york city, call volumes were making it increasingly difficult to call into or out of the city.outside the city, the impact was more muted. with the exception ofsome difficulty with tollfree numbers, the telephone network was working well (although the load was higher than normal). the crash of american airlines flight 77 into the pentagon at 9:37 a.m. did not dramaticallychange this picture, except to increase call volume into and out of thewashington, d.c., area, thereby adding the nationõs capital to the list ofdifficulttocall places. about the same time, as it was learned that thetwo new york planes had originated in boston, call loads in boston alsogrew.at noon, telephone traffic remained high. indeed, the number oftelephone calls reported to have been completed by verizon on september 11 was approximately double that of a typical day. however, it appears that difficulties in calling out of new york city may have eased bythenñfor example, aol recommended that users unable to connect to itsnew york modem banks with a local number try calling a longdistanceaccess number to get online; this advice apparently worked for manyusers.at 5:20 p.m., world trade center building 7 collapsed, severely damaging verizonõs 140 west street central office. although some of theequipment in the building continued to run for several more hours, localtelephone connectivity through the exchange was ultimately lost. unfortunately, the damage to the building included the disabling of some of themonitoring equipment, so it is not possible to determine exactly howtelephone service degraded over the evening of september 11. anothereffect of the damage to 140 west street was to further damage fiber linksalready affected by the collapse of the twin towers, causing additionalconnectivity losses.cellular telephonesas word of the attacks spread, the cellular telephone system in thenortheastern united states began to be heavily loaded. nationally, callvolume rose 50 percent above normal. one can compare this rate with the30 percent increase typical on motherõs day, the canonical example of anexceptional calling day. cellular telephone systems are usually engithe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.38the internet under crisis conditionsneered to support traffic during busy hours with only about 4 percent ofcalls being blocked (given a busy signal). regionally, the experience was even more dramatic. new york cityhad a 400 percent increase in call attempts during the day. at about 11:00a.m., the volume was up 1,300 percent for at least one major carrier. washington, d.c., had a 125 percent increase for the day. new england as awhole saw a 75 percent increase. the cellular system was not engineeredfor these loads, so callblocking rates grew accordingly. in new york, 75percent of calls were blocked (92 percent at the morning peak). in washington, d.c., 56 percent of calls were blocked.wireless internetñusing such devices as research in motionõs blackberryñalso rose on september 11. traffic surged by 60 percent around10:00 a.m. and stayed high through the early afternoon.7although there have been reports that a large number of cellularphone sites were disabled by the collapse of the twin towers, the industry maintains that only five sites were damaged in the attacks. in anycase, by late afternoon on september 11, a combination of damage totelephone lines and the loss of power caused 160 cell sites in lower manhattan to become inoperable (slightly under 5 percent of the new yorkcity cellular infrastructure). over the hours and days that followed, thecellular operators adopted a variety of measures, such as the installationof temporary sites and the use of alternate radio frequencies, to restore (orin some cases, such as at the pennsylvania crash site, to increase) capacity.in lower manhattan, full capacity was restored within a week.8broadcast television and radiotransmission facilities of 9 of the 14 localarea television stations,along with those of 5 local radio stations, were lost when the north towerof the world trade center was destroyed. of the stations that lost theirtransmission facilities, only 2 were able to quickly restore serviceñwcbstv (channel 2), which switched to a fullpower backup antenna at theempire state building, and wxtv (channel 41). for households thatsubscribed to cable, there was much less impact: most television stationsdeliver their feeds to cable operators directly, by way of fiber or microwave links, and the new york cablesystem operators reported no serviceinterruptions outside lower manhattan. (however, the impact on broad7from reports by carriers to the federal communications commission.8data from kathryn condello, 2001, òwireless industry: impact and recovery effortssummary reportó (presentation to the network reliability and interoperability council),cellular telecommunications and internet association, washington, d.c., october 30.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.39the network experiencecast viewers was greater in new york city than it might have been inother metropolitan areas, as household cable penetration is only about 50percent, significantly less than the nationwide average of 70 percent.)to speed the restoration of broadcast service, the federal communications commission gave stations temporary authority to locate replacement transmitters at any reasonable site, provided they would not causeinterference with other stationsõ activities. shortly after the world tradecenter buildings collapsed, a number of broadcasters set up transmittersat a tower in alpine, new jersey. since then, six networks have relocatedtransmitters to the empire state building, and two have remained at thealpine site. broadcasters do not consider this pair of sites adequate,however, for the long term: the empire state building does not haveenough physical or electrical capacity for all of the broadcasters, and thealpine tower, by virtue of its relatively modest height and remote location, does not serve as sizable a market as the world trade center sitedid. efforts are now under way to select one or more permanent transmitter sites that are more suitable.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.403the user experienceimpact on business in the immediate area wall streetarea financial institutions were of course significantlyaffected by the september 11 attacks, though in varying degrees. somecompanies were severely hurtñcantor fitzgerald, for example, lost amajority of its employees and all of its facilities in the world trade center. other firms suffered primarily from the loss of their physical offices.at morgan stanley, most employees escaped the area before the twintowers collapsed, but the firmõs offices, along with all the informationtechnology (it) equipment in place there, were completely destroyed.other companies located near the world trade center, such as merrilllynch and lehman brothers holdings, inc., also could be categorized asòheadquarters rendered unusableó;1 and a great deal of additional spacein the areas abutting ground zero was rendered either temporarily orpermanently out of commission. the new york stock exchange itselfwas shut down for almost a week, in part because many firms did nothave the communications capability for completing trades and in partbecause the exchange had communications and physicaldamage issuesof its own to contend with.some financial firms faced power and communications disruptionseven though their office space and it infrastructure had not been directly1randall smith. 2001. òat morgan stanley, readiness saved lives,ó wall street journal,september 14, p. c1.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.41the user experiencedamaged. most significant for companies in lower manhattan, the collapse of building 7 of the world trade center and the consequent damageto verizonõs central office across the street disrupted voice and data linesthat linked wall street to the world.2 another nearby verizon office thatserved the new york stock exchange was also affected, with 20 percent ofits highspeed data lines òout of actionó and the rest òoperating onlysporadically.ó3some local firms reported not being seriously affected. for example,the director of infrastructure at blackwood trading llc was quoted assaying that òif he hadnõt seen the attack, he wouldnõt have known ithappened.ó blackwood was relatively well prepared for such a disaster:while its data center is housed on wall street, the firm backs up all itstrade data to remote centers in new jersey, which is on a separate powergrid; it was able to execute more than a òhalfmillion trades before thenasdaq voluntarily shut down,ó according to that executive.4 indeed,data loss was less of a problem than one might think. most large wallstreet firms had responded to the earlier world trade center bombing (in1993) by focusing their attention on crisis management,5 which resultedin the institution of thorough databackup or colocation procedures.cantor fitzgeraldõs espeed, for example, had mirrored the firmõs entireoperations at other sites.6people on the netdata on peopleõs usage of the internet following the terrorist attackscame from a variety of sources. probably the most detailed informationavailable to the committee was from the pew internet and american life2shawn tully. 2001. òrebuilding wall street,ó fortune, vol. 144, no. 6: pp. 92100.available online at <http://www.fortune.com/indexw.jhtml?channel=artcol.jhtml&docid=204166>.3emily thornton et al. 2001. òthe view from ground zero,ó business week online,september 13. available online at <http://www.businessweek.com/bwdaily/dnflash/sep2001/nf20010913005.htm>.4mark hall and lucas mearian. 2001. òit focus turns to disaster recovery,ó idg,september 11. available online at <http://www.cnn.com/2001/tech/industry/09/11/disaster.recovery.idg/index.html>.5shawn tully. 2001. òrebuilding wall street,ó fortune, vol. 144, no. 6: pp. 92100. available online at <http://www.fortune.com/indexw.jhtml?channel=artcol.jhtml&docid=204166>.6edward cone and sean gallagher. 2001. òcantor fitzgeraldñfortyseven hours,óbaseline, october 29. available online at <http://www.baselinemag.com/article/0,3658,apn=2&s=2101&a=17022&ap=1,00.asp>.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.42the internet under crisis conditionsproject, which surveyed internet users immediately after september 11.7the project had been conducting telephone surveys of internet users forsome time before the crisis, and it continues surveying users even now;thus its data not only present a picture of how users behaved that day butalso allow comparison with their behavior both before and after the attack.other useful sources of data on user behavior included webusagemeasurements from webhancer, search statistics from major search sitessuch as aol and google, and data from content providers such ascnn.com and akamai. together, these data provide a very telling portrait of what people wanted, needed, and expected from the internet inthose extraordinary circumstances.the internet as a source of newsmany people learned of the terrorist attacks on the world trade center and the pentagon while they were at work or on their way to work.8and because people often do not have access to television sets at theirplace of work, there is reason to believe that they then turned to internetnews sites for information.in what is sometimes referred to as a òflash crowdó9 event, nationaland international demand for timely information soared, and many newsweb serversñthose of cnn, msnbc, and the new york times, for exampleñexperienced unprecedented loads. an anecdote regarding cnnõsweb site <www.cnn.com> gives a vivid example of just how fast thedemand for internetaccessible news grew. when the director of the facility saw on tv that the second plane had just struck, he stood up in hiscubicle and shouted to other staff members to take steps (such as bringingextra servers online) to prepare for an increased demand for news. by thetime he sat down, that spike had already arrived. (box 3.1 discusses thecnn experience, including steps that the network took to keep up withdemand, in more detail.)7lee raime and bente kalsnes. 2001. the commons of the tragedy: how the internet wasused by millions after the terror attacks to grieve, console, share news, and debate the countryõsresponse. pew internet & american life project, washington, d.c., october 10. availableonline at <http://www.pewinternet.org/reports/toc.asp?report=46>.8while it is difficult to get a precise estimate, data from the census bureau suggest thatalmost half of the u.s. workforce was at work or en route when the planes hit. informationavailable online at <http://www.bls.gov/newsrelease/flex.t07.htm>.9the term òflash crowdó was coined by science fiction writer larry niven, who wrote ashort story by that title about masses of people teleporting to see exciting events they seereported in the news.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.43the user experienceduring the remainder of the month after september 11, the number ofinternet users who sought to get news online increased by about 25 percent, even though internet use for some other purposes (such as shoppingor sending email) declined. indeed, survey data indicate that the totalnumber of internet users declined by about 10 percent in the week immediately following september 11 (see table 3.1).even given the surge in demand for online news, all the evidence isthat internet users, in the same proportion as the general population,preferred to get their news from television. a poll by the pew projectshowed that in the week after september 11, television was the mainsource of information for 79 percent of americans and for 80 percent ofthe heaviest internet users (see table 3.2). heavy internet users relied onthe internet as much as on radio and newspapers, while americans overall relied on the radio and newspapers far more than they depended onthe internet.one possible reason for this seeming contradictionñhigh online demand for news and high reliance of internet users on televisionñis thatonce they were home from work (where they relied largely on the internet)on september 11, most people turned on their television sets and got thelatest news without having to go online for further information. anotherpossible reason was frustration with the internet: 43 percent of internetusers reported at least some trouble accessing web sites in the first hoursafter the attacks, and 15 percent reported great difficulties.10 yet anotherpossible reason is that news organizations generally do not provide livestreaming video programming.11 in the end, about a fifth of those whohad difficulty reaching a site gave up on using the internet for newsduring that period.12another important point is that many people appear to have used theinternet not as a replacement for regular news sources but as a supplement. major search engines reported that the information sought by userschanged dramatically on september 11 and in the following days. forexample, on september 12, a number of talk shows mentionednostradamus, a renaissance writer renowned for his prophecies. thereafter, ònostradamusó was at the top of the list or near the top at manypopular search engines; at yahoo, for example, it was number 1.13 google10raime and kalsnes, 2001, the commons of the tragedy.11a scalable technology known as multicast could support streaming video to large numbers of viewers, but it is not commonly employed by content providers.12raime and kalsnes, 2001, the commons of the tragedy.13google <http://www.google.com/press/zeitgeist/911search.html>; yahoo <http://websearch.about.com/gi/dynamic/offsite.htm?site=http://buzz.yahoo.com/>; lycos<http://websearch.about.com/gi/dynamic/offsite.htm?site=http://50.lycos.com/091101%5fspecial.html>.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.44the internet under crisis conditionsbox 3.1cnn.com on september 11, 2001september 11, 2001, has certainly not been the only highdemand period experienced by internet news sites. for example, interest in the results of the 2000 general election fueled a steep rise in demand. but september 11 set new records, andconsequently the ability to reach major news web sites that day was reduced forsome people.1to use this experience to better understand the demands on news servers duringa crisis event and to identify measures that can help deal with that demand, a representative from cnnõs internet division was invited to participate in the workshopheld by the committee on the internet under crisis conditions. key elements ofcnnõs experience follow.on september 11, cnnõs overall demand surged greatly, with the measureddaily load (as expressed in page views) increasing on september 11 to 132 millionñnearly 10 times the more typical load of 14 million on september 10. the measureddemand of september 11 probably underestimates total user demand, however, because not all users were able to successfully load the web page as the demandinitially surged after the crash of the first airplane. the number of hits (pages orimages requested) doubled every 7 minutes, resulting in an orderofmagnitude increase in less than 30 minutes. demand for news continued to grow in the hoursfollowing the attack, with the load on september 12 reaching 304 million pageviewsñmore than twice that measured on september 11.keeping up with demand after the first airplane crash was very challenging for thecnn operations staff, who employed a combination of several techniques to dealwith the load:¥reducing web page complexity. the cnn.com main web page was significantly reduced in size (i.e., as measured by the number of separate elements such asreported that ònostradamus,ó òcnn,ó and òworld trade centeró were thetop three terms among people whose searchengine usage increased during the week ending september 13.14the internet as a means of communicating between individualson september 11, many people felt the need to communicate rightaway with family, friends, and colleagues. the purpose of these communications ranged from emergency responses (as officials in new york14google. 2002. ògoogle search statistics from 9/11/01,ó google, mountain view, calif.available online at < http://www.google.com/press/zeitgeist/911search.html>.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.45the user experiencecity and washington, d.c., sought to deal with the crisis) to trying simply to make sense of what was happening.although the internet was one medium by which people chose tocommunicate, it is important to emphasize that the preferred mode ofpersonal communications was the telephone. indeed, even heavy internetusers reported using the telephone more than the internet (and at a higherrate than the national average). while 63 percent of americans phoned afamily member about the attacks on september 11 or in the followingdays, 75 percent of heavy internet users called a family member duringthat period.1515raime and kalsnes, 2001, the commons of the tragedy.headline pictures and graphical menu bars for selecting additional content), consistent with cnnõs inplace strategy for handling highdemand periods. in fact, themain page was stripped down to the bare bonesñeven further than the usual minimumñto increase its ability to serve pages. indeed, at its minimum complexity, thepage could fit into a single ip packet.¥adding more servers. a number of other server systems are colocated withthe servers assigned to cnn.com. these systems, which normally are used for othercnn and turner broadcasting content, were for the most part experiencing significantly reduced volume that day. thus, a number of them were reconfigured andadded to the cnn.com server pool. (interestingly, cnn did retain server capacity forthe cartoon network, which saw an increase in volumeñlikely reflecting parentsõdesire to provide children with an alternative to the disturbing news.)¥temporarily employing a thirdparty contentdistribution network. cnn arranged to significantly increase its use of the akamai content delivery network inorder to reduce the load on the cnn servers themselves. that is, the cnn webpages temporarily pointed web browsers to retrieve images from akamai serversinstead of from the usual cnn systems.the net effect of all of these efforts was to enable overall capacity to increase overan order of magnitude within hours of the event, permitting cnn to cope with thegreatly increased demand.1for example, according to a report in computerworld, the webmeasuring company keynoteobserved that the availability (responsiveness to requests to download web pages) of the websites of cnn, the new york times, abc news, msnbc, and usa today were all significantlyreduced following 9:00 a.m. on september 11. (todd r. weiss. september 11, 2001. ònewssites simplified after performance bogs down.ó computerworld. available online at <www.computerworld. com/managementtopics/ebusiness/story/0,10801,63729,00.html>.)the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.46the internet under crisis conditionstable 3.1internet use by activity, august through september 2001aug. 13ðsept. 10asept. 12ð19bsept. 20ðoct. 1cactivity(percentage)(percentage)(percentage)going online for any565157purposesending or reading514249emailgetting news online222726seeking hobby201022informationbrowsing for fun201320doing workrelated171315researchseeking medical or535health informationbuying products422an = 1,351; margin of error is 3 percent.bn = 1,138; margin of error is 3 percent.cn = 525; margin of error is 6 percent.source: lee raime and bente kalsnes. 2001. the commons of the tragedy: how the internetwas used by millions after the terror attacks to grieve, console, share news, and debate thecountryõs response. pew internet & american life project, washington, d.c., october 10,p.7. available online at <http://www.pewinternet.org/reports/toc.asp?report=46>.table 3.2main source of information following september 11, 2001main sourceall americansaheaviest internetof information(percentage)usersb (percentage)television7980radio76newspaper77internet26talking with others21an = 1,029; margin of error is 3 percent.bn = 260; margin of error is 7 percent. the pew study defines the heaviest internet usersas those who have more than 3 yearsõ experience online and who log on from home everyday. this group constitutes about 20 percent of all internet users and about 11 percent ofthe u.s. adult populationsource: lee raime and bente kalsnes. 2001. the commons of the tragedy: how the internetwas used by millions after the terror attacks to grieve, console, share news, and debate thecountryõs response. pew internet & american life project, washington, d.c., october 10,p.10. available online at <http://www.pewinternet.org/reports/toc.asp?report=46>.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.47the user experienceat the same time, about onethird of americans had difficulty placinga phone call on september 11 (see òthe experiences of other communications networksó in chapter 2 for more detail on the telephone systemand its performance), and about one in eight turned to the internet tocommunicate with friends and loved ones. much of the communicationwas through email, which was used almost as soon as the attacks began,though a modest fraction of internet users (13 percent) reported usinginstant messages.16 anecdotal reports both from washington, d.c., andnew york city suggest that instant messaging proved a viable alternativefor office workers who were unable to use their phones but still hadinternet access.those directly affected by the attacks also made use of internet communications. some people trapped at the top of the twin towers wereable to email colleagues and family.17 some communications from thetwin towers were from people who used wireless pdas, such as thosefrom research in motion (blackberry), to send messages even after inbuilding infrastructure had been knocked out.finally, internet telephony provided a useful alternative communications channel for some people who had lost telephone service, thoughapparently the total number of such calls was small compared to thoseplaced through the conventional telephone network.the internet and communityin the hours and days following the attacks, a number of web siteswere created (or adapted from existing sites) to help fill various disasterrelated needs. they included the following:¥missing person and òiõm aliveó lists. for example, prodigy communications created an òiõm okó online message center to help people findinformation about loved ones.¥relief supply requests.¥solicitations for relief contributions. companies such as amazon.comand yahoo used their internet billing systems to facilitate peopleõs donations to the american red cross.16raime and kalsnes, 2001, the commons of the tragedy.17new york times. 2002. òfighting to live as the towers died.ó may 26, p. 1, col. 1.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.48the internet under crisis conditionsoverall use of the internettotal use of the internet declined, as discussed above. (instances inwhich particular isps instead saw a rise in traffic levels appear to beattributable to their serving news and other content that were in higherdemand on september 11.) the decrease in overall demand is apparentin both the pew internet users survey data and in reports of isps, including presenters at the workshop.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.494perspectives on the internet experienceof september 11the overall events of september 11 were so extraordinary and shocking that it is sometimes difficult to put them in perspective. there is atendency to look for echoes of the twin towersõ fall in everything onesees. this chapter seeks to provide some of that perspective by examining other major communications events occurring on the internet andseeing how they compared. then it considers what could happen to theinternet if attacked directly (rather than suffering collateral damage) or ifit were used as an integral part of the attack itself.other outages:operator errors and infrastructure faultsthe committeeõs conclusion is that september 11, with respect to itsimpact on the internet, was a relatively minor incident. yet quantifyingthat observation has proved difficult. there are neither general norms ofinternet performance nor infrastructure to monitor the network comprehensively. rather, individuals and organizations rate the internetõs performance differently, according to their own priorities.still, there are several basic measures that interested parties generallyuse to assess the internetõs performance:¥traffic levels. how much does traffic vary from that of a typicalday?¥border gateway protocol (bgp) reachability and update rates. howthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.50the internet under crisis conditionsmany regions of the network are being advertised by bgp, and how oftenis the information about various parts of the network changing?¥measured reachability. rather than relying on bgp, one can measure internet connectivity directly by attempting to communicate with anumber of systems scattered throughout the network and reporting ononeõs actual ability to exchange data.in the following paragraphs, these metrics are used to examine somerecent internet events that most people consider exceptional and to compare them with those of september 11.operator errornetwork operators often joke that a single misplaced comma in anappropriate configuration file could take down the internet. while thatwas certainly true in the late 1980s,1 operators today have welldefinedprocedures and methods for checking configurations before putting theminto their networks. furthermore, most operators employ systems toprotect their network from configuration errors in other networks. however, operational errors do still occur from time to time, and some of thesehave major effects.to illustrate how local errors can have global impact, let us consideran example from the domain name system (dns)ña distributed database that keeps the nametoaddress mappings for the internet. if aweb browser needs to find the internet address of the name <www.nationalacademies.org>, for example, the browser queries the dns.the dns is a hierarchical database that makes heavy use of caching.to explain the process by simplifying somewhat, the way that a namesuch as <www. nationalacademies.org> is looked up in the dns is asfollows: the browser asks a local dns server if it knows the name <www.nationalacademies.org>. if the local server knows the name, it returns theip address for <www.nationalacademies.org>; if not, the server consults1 of 13 root servers. the root servers act as query managers; though theyrarely answer a query themselves, they tell the local server what dnsserver it should consult to get the definitive answer about <www.nationalacademies.org>.what makes the dns work and keeps the root servers from beingoverwhelmed with queries is the systemõs use of caching. once a local1in the late 1980s, the internet often suffered from socalled blackhole problemsñrouters misconfigured to erroneously report to other routers that they have the best possibleroute to every point on the internet. a black hole effectively encourages all nearby routersto send all traffic to it and then discards all the incoming traffic as undeliverable.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.51perspectives on the internet experience of september 11server is told the address of <www.nationalacademies.org>, it is expectedto cache that address for some period of time (a few hours or days), sothat the next time the server is asked about <www.nationalacademies.org> it will not have to query the root servers again. the exact time thata name is cached is controlled by the owner of the name. for example,the national academies determine how long the name <www.nationalacademies.org> can be cached at a server.in february 2001, a router that connected the dns servers for namesending in microsoft.com to the rest of the internet was misconfigured,and the router stopped forwarding traffic. it turned out that, contrary torecommended practice, microsoft had placed all the microsoft.com servers on the same local network; thus, when the router stopped working, noone could query about names ending in microsoft.com. furthermore,microsoft had decided to keep the cache times on its names very shortñabout 2 hours. as a result, within that time every name ending inmicrosoft.com effectively became unknown on the internet.unfortunately, in terms of impact on the network, microsoft namesare very popular. as the dns dropped microsoft names from caches, anyquery about a microsoft site had to be sent to the root servers, whichwould then point the queries at the microsoft.com servers. because theservers were unreachable, the query would fail, no names would becached, and the next query for a microsoft site would again result in aquery of the root servers. loads jumped by 25 percent at some rootservers until the misconfigured router was repaired.2 in contrast, theevents of september 11 had no discernible effect on the number of queriesto the root servers.infrastructure faultsin many ways, the effects on the internet from the september 11 attacks were similar to other, albeit accidental, òinfrastructure faultsó thatthe internet has incurred. figure 4.1 illustrates the effects on the globalinternet of one such type of fault, a òfiber cut,ó on november 23, 1999,when a major internet link was severed. the figure plots internetreachability using the same methodology as was used in figure 2.2 inchapter 2. the effects of the fiber cut are comparable to those of theseptember 11 damageñall in all, about a 6 to 7 percent loss in overallinternet connectivity, but shortlived. figure 4.2 shows another outage2nevil brownlee, k.c. claffy, and evi nemeth. 2001. dns measurements at a root server.cooperative association for internet data analysis, san diego. available online at <http://www.caida.org/outreach/papers/2001/dnsmeasroot/>.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.52the internet under crisis conditions%formatted wed nov 24 20:13:34 1999 gmttimezone (jpc1, austin, tx)gmt cst nov 23nov 2203:009 pm05:0011 pm07:002 am09:004 am11:006 am13:008 am15:0010 am17:00noon19:002 pm21:004 pm23:0011223311223380828486889092949698100reachability %3 dns tld servers (520)2 www (525)1 internet (1969)http://www.matrixnetsystems.comcopyright © 2001 matrix netsystems, inc.figure 4.2 impact of damage from hurricane floyd on the reachability of tworepresentative sets of internet hosts. source: matrix netsystems, inc.figure 4.1 impact of a 1999 fiber cut on the reachability of two representativesets of internet hosts (1, 2) and the domain name system root servers (3).source: matrix netsystems, inc.%formatted wed sep 22 14:29:25 1999 gmttimezone (jpc1, austin, tx)gmt cdt sep 13sep 12sep 14sep 13sep 15sep 14sep 16sep 15sep 17sep 16sep 18sep 17sep 19sep 185 am12:005 am12:005 am12:005 am12:005 am12:005 am12:005 am12:003 pm1122112280828486889092949698100reachability %2 mping from miq beacons to www (550)1 mping from miq beacons to internet (2068)http://www.matrixnetsystems.comcopyright © 2001 matrix netsystems, inc.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.53perspectives on the internet experience of september 11with similar effects but a different cause; here, the downward spikes onseptember 17, 1999, coincide near the peak of the physical damage inflicted by hurricane floyd. again, the magnitude of the spikes are comparable with that of september 11, 2001.attacks on, or with, the internetbaseline: effects of damage on september 11 on september 11, an important interconnection point (at 140 weststreet in new york city) was severely damaged, some longdistance communications links (especially those under the world trade center complex) were severed, and there was a localized electrical power outage.those experiences, together with discussions about them with severalinternet service providers, give some indication of the internetõs vulnerability to a direct and deliberate physical attack. as detailed in chapter 2,the effects of the terrorist attacks were complex, but by simplifying somewhat, some broad patterns emerge:¥most of the attacksõ effects were local. the majority of the seriouscommunications disruptions were suffered by networks and customersñsuch as the stock exchanges, covad dsl customers, and the parts ofnysernet in lower manhattanñphysically close to 140 west street.effects of the attacks were substantially less notable in upper manhattan,and nationally they were hard to discern at all.¥nonlocal effects occurred in surprising places. some internet customers in western new england found that connectivity problems in newyork affected their ability to dial in to their isp. and one of the mostseriously affected parts of the internet turned out to be an ocean awayñinsouth africa.¥rich communications infrastructure and the flexibility of the internettechnology eased recovery. while a number of address ranges were brieflyremoved from the internet by the attacks, most of them were back on thenetwork in less than a day. the rich communications infrastructure of theunited states made it feasible for most isps to reroute around the damage. in cases where rerouting was not an option (as at locations in lowermanhattan), it was often possible to improvise new connectivity (e.g., aieee 802.11b wireless link extending out a window in new york city).oversimplifying a little, it was only sites within a few blocks of the worldtrade center or sites with limited communications infrastructure (e.g.,some of the nonu.s. areas affected by the collapse) that had difficultyrecovering. and even in many of the difficult cases, recovery time wasstill measured in days (not weeks or months).the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.54the internet under crisis conditions¥long power outages caused serious harm to communications. one canargue that, from the perspective of the internet, the most serious effect ofthe attacks on the world trade center was that power had to be shut offto lower manhattan. the power outage at telehouse had an effect oninternet connectivity that was comparable to that of the towersõ collapsesearlier. extended power outages tend to be a feature of physical disasters(whether they have human or natural causes), and they have great impact: the nationõs communications infrastructure ultimately relies on powered equipment to carry data.if the internet were the target, would there be greater impact?if attackers were out to physically damage the internet infrastructuredirectly, it is unlikely that 140 west street would be near the top of theirlist. even within manhattan, several facilities contain substantially moreinternet equipment and are more important to the internetõs operation.many have speculated that a physical attack on one of the majorinternet exchange locations, such as maeeast (near washington, d.c.)or the paix facility (near san francisco), would cause serious disruptions. internet exchange locations are facilities at which a number of ispsinstall routers on a common network. this mode of interconnection isoften more costeffective than is arranging a separate physical connectionto each network at which an isp wishes to peer. concern is simultaneously heightened as well: an attack on an exchange location wouldbreak multiple connections between isps.but as best as the committee can determine, such an attack would notpose a serious risk to the internet as a whole. most isps are connected toit at more than one point, both to increase their redundancy in the face ofunintended eventsñsuch as fiber cuts and power failuresñand becausethey generally seek to exchange traffic with other isps as close as possibleto the trafficõs origin, thereby avoiding additions to the load on their ownnetworks. indeed, the largest isps are connected to one another at dozensof points throughout the united states. the committee finds no reason tobelieve that there is a point (or even a small number of points) in theinternet that, if removed, would partition the countryõs system into adisconnected group of networks.another concern is that an attacker could sever a critical fiberopticlink. however, as a matter of practice, large isps maintain networks withredundant paths to ensure connectivity in such circumstances. to besure, the level of redundancy can turn out to be lower than the literalcounting of links would suggest. in a number of places, fiber runs areconcentrated in particular rightsofway, as was illustrated by a 2001 incithe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.55perspectives on the internet experience of september 11dent in which a fire in a baltimore, maryland, train tunnel destroyed anumber of links. but carriers work hard to discover such vulnerabilities,and large networks deploy geographically distinct links that allow a damaged link to be bypassed (though performance in terms of capacity ordelay may suffer until that link is restored). the september 11 experiencedemonstrated such redundancy in major internet links.indeed, it turns out that failures of one or more internet componentsare not infrequent events. fiber cuts occur often, and most major internetexchange points have failed at one time or another. in the past, there haveeven been simultaneous failures of exchange points in at least three different locations. some of these events have had noticeable effects on one ormore isps, but the impact is not felt across the internet. as is described inbox 4.1, the internetõs basic design makes it resilient in the face of failuresñincidents do not tend to ripple across the whole network.there is, however, some reason to believe that it might be possible fora motivated attacker to cut the internet links between the united statesand other countries; these links appear to have less redundancy than ispresent within the backbones of major u.s. isps. it is highly likely thatsuch an attack would also separate a number of countries outside theunited states from each other. moreover, such incidents could lead toindirect effects along the lines of the degradation of south africaõs dnscapability following the world trade center attacks.the principal issue with international connectivity is that most of thetransoceanic fiberoptic communications cables land in north america ata few sites. as noted in chapter 2, one reason why new york city is asuperhub for the internet is that a large number of the transatlantic cablesmake landfall close to the city. similarly, miami, florida, is a hub forconnectivity with latin america. the vulnerability is further increasedbecause, for economic reasons, most connections to these transoceaniccables are made at carrier hotels in new york city rather than at thelanding points themselves; it is much cheaper to run one fiberoptic cablefrom the landing to an interconnection point than it is for each carrierwishing to connect to the fiber to run separate lines. many of the individual landing points are themselves also vulnerable to attack.it should also be noted that although it is difficult for a physical attackto damage the internet as a whole, there are a number of ways to attack anindividual isp, many of which would cause problems for several hours ordays. economies of scale can be achieved by concentrating equipment ina small number of locations, and some isps, as well as content isps (whichrun large web farms), seem particularly prone to doing so, even going sofar as putting all their òeggsó (servers) in one òbasketó (location), whichobviously makes the isp more vulnerable to physical attack. (some ispsthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.56the internet under crisis conditionsbox 4.1how the internetõs design makes it resilientthe internet differs fundamentally from most of the other communications networks in how it adapts to equipment failures and increases in traffic load, a legacy ofthe design goals of the early days of the arpanet.1 whereas the telephone networkhas very complicated switches but simple òedge devicesó (i.e., telephones), the internet places much of its intelligence in the endhosts. the network provides a relatively simple service of besteffort packet delivery. packets flow through the networkindependently and may be lost, corrupted, or delivered out of order. the fact thatthe internet protocol (ip) offers such a simple packetdelivery service makes it easierto continue providing the service during transient network failures. after a failure,the network routers communicate among themselves to compute a new path, if possible, to the packetõs destination. some packets may be lost during this transitionperiod, but the communication continues after the routers start using the new path.building on top of the ip, the endhosts implement transportlayer protocols thatcoordinate the endtoend delivery of data between applications. the transmissioncontrol protocol (tcp) underlies most communication on the internet, such as thedownloading of web pages. tcp provides the main mechanism needed by mostinternet applicationsña logical connection that delivers a sequence of bytes fromthe sender to the receiver in an ordered, reliable fashionñand it is used for much ofthe traffic over the internet. hosts running tcp adapt their behavior to networkcongestion.2 in response to loss or delay, the tcp sender reduces the transmissionrate to avoid overloading the network. during periods of heavy load, tcp senderstraversing the same bottlenecked link transmit at a lower rate to share the limitedresources.this adaptability has the advantage that application performance tends to òdegrade gracefullyó under heavy load, though such a degradation in performance maydrop to a level that is unacceptable for some users. it may be acceptable for applications such as email (which can be queued and delivered as bandwidth becomesavailable) and instant messaging (which requires little bandwidth), but it can be disruptive for web downloads and can unacceptably degrade multimedia streaming.do operate multiple facilities, but even then, they tend to locate themwithin the same cluster of buildings. this strategy is not sufficientlyrobust, as power failures would likely cause problems across the entirecomplex.)finally, the committee learned during its workshop that a carefullydesigned distributed attack against a number of physical locations, especially if done in a repeating pattern, could be highly disruptive. an attackat a single point, however, is survivable.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.57perspectives on the internet experience of september 11possible effects of a deliberate electronic attackwith the aid of, or against, the internetas previously noted, the internet itself was not a target on september11, 2001, nor, apparently, was it used by terrorists for anything more thantheir own informationacquisition or communication needs. however,the internet could plausibly play a more central role in future terroristattacks. acquiring the expertise necessary to use it in that way would beanalogous to the efforts of the september 11 attackers in learning how topilot jet aircraft. once the expertise was acquired, the internet could bethe adaptation of the tcp to network congestion is in sharp contrast to the control mechanisms in the traditional telephone network, which determine the path forthe call and allocate the necessary bandwidth before transmitting any data. forexample, the telephone network dedicates 64 kilobits per second for each telephonecall on each link in its route. the connection is not established unless sufficientresources are available, ensuring that existing telephone calls are not affected by thedecision to accept a new connection. a disadvantage of this approach is that usersmay experience blocked calls (i.e., busy signals) after network failures and duringperiods of heavy call volume, but it has the advantage that the heavy load does notdegrade the quality of ongoing phone conversations. in addition, the telephonenetwork has mechanisms for imposing priority on which calls are accepted. forexample, the network can be configured to favor outgoing calls in disaster areas toenable victims to reach the outside world.the internet, meanwhile, was designed for robustness and adaptivity to serve allusers. though the hardware and software components in early ip networks were notvery reliable, especially in comparison with the mature technology in the telephonenetwork, the designers of the arpanet wanted the network to continue to functioneven if a natural disaster or malicious attack caused individual components to fail.these design principles enabled the internet to withstand the localized physical attacks it endured on september 11. the attacks separated a small number of networksfrom the rest of the internet, but by and large the infrastructure was able to adapt byexploiting alternate routes around the failed equipment and by having endhostsadjust their sending rates to the available bandwidth.1david d. clark. 1988. òthe design philosophy of the darpa internet protocols,ó pp. 106114 in sigcomm ô88, proceedings of the acm symposium on communications architecturesand protocols, august 1618, 1988, stanford, calif. association for computing machinery, newyork, n.y.2van jacobson. 1988. òcongestion avoidance and control,ó sigcomm õ88, proceedingsof the acm symposium on communications architectures and protocols, august 1618, 1988,stanford, calif. association for computing machinery, new york, n.y.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.58the internet under crisis conditionsutilized by terrorists in a number of ways and in the pursuit of diversegoals.the potential, range, and plausibility of terrorist attacks on or withthe internet are thoroughly explored in making the nation safer: the role ofscience and technology in countering terrorism, a recent national researchcouncil publication3 to which the committee defers for a complete discussion. this section only sketches some of the possibilities for terroristuse of the internet, primarily to develop a contrast with the actual impacton the internet from september 11.if the aim is terror, then widespread internet failures could causeconfusion and possibly instill panic, particularly if such failures occurredin conjunction with separate physical attacks. broader attacks of any formcould have this effect, but the internet would prove a particularly valuable element because of its use by some as a news channel and especiallybecause its functioning and vulnerabilities remain a mystery to much ofthe populaceñpeople might fear the worst if a significant disruption tothe internet were to occur.a different internetrelated means for instilling panic would be tocreate misinformation. this could be done directly, by altering the contents of internet news sites. alternatively, information in the domainname system database could be changed to redirect names to incorrectaddresses, or the routing system could be tampered with so that userswould be connected to substitute servers.4 each technique could exposeusers to web pages, seemingly authentic, that contained either subtly orgrossly incorrect information crafted by the attackers.attackers could also attempt to use the internet either to directlyinflict damage or to augment damage inflicted by other means. for example, they could undermine systems whose operations rely on using theinternet or are susceptible to manipulation through the internet (see making the nation safer for further discussion).another form of terrorist attack could involve the direct infliction ofdamage, by nonphysical means, on the internetõs own systems. this mightbe done in several ways:3national research council. 2002. making the nation safer: the role of science and technology in countering terrorism. national academies press, washington, d.c. available onlineat <http://books.nap.edu/html/stct/index.html>. for an extended discussion, see theforthcoming computer science and telecommunications board report on information technology for countering terrorism.4some of the risks of dns and routing attacks are described in computer science andtelecommunications board, national research council. 1999. trust in cyberspace. national academy press, washington, d.c.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.59perspectives on the internet experience of september 11¥by the deletion of information (such an attempt might not be highlyeffective, however, as mechanisms exist to deal with the routine occurrence of corrupted information);¥by disabling hardware (for some machines, it is possible to usesoftware to render the hardware inoperable); or¥by rendering services inaccessible (for example, if computers under attackersõ control continually flood a service with bogus traffic).these threats might seem minor compared to physical damage thatattackers could inflict, except that the scale of such softwarebased attacksis potentially immense. and it is well established that attackers can acquire access to hundreds or thousands of machines to be used as launching points for coordinated followon attacks.toolkits that exist for automatically scanning and exploiting a widevariety of security flaws in internet servers could also be used as weapons. when coupled with software that then repeats the scanning andexploiting (using each newly compromised machine as an additionalplatform), they become a òwormó or a virus (the distinction being thatviruses require some user action to activate them, while worms do not).though not a new concept, worms recently gained notoriety with theadvent, in the summer of 2001, of code red and nimdañworms thatinfected several hundred thousand internet hosts in a matter of hours.furthermore, recent theoretical work has pointed to more efficientspreading strategies that appear to enable a worm to compromise a vulnerable population of a million servers in a matter of minutes, perhapseven in tens of seconds.5 and a plausible potential exists for compromising perhaps 10 million internet hosts in a surreptitious òcontagionó fashion that, while taking longer than the quick propagation of worms such ascode red, would make the worm much harder to detect; it would notexhibit the telltale scanning used by rapidly propagating worms.the ability to acquire hundreds of thousands or even millions of hostswould enable terrorists to launch truly internetwide attacks. one formof attack would be distributed denialofservice (ddos) floods, in whichan immense stream of traffic is sent to a particular internet service orresource (such as a particular router or access link). such attacks gainednotoriety in february 2000 with a series of floods that targeted popularinternet sites such as yahoo.given the state of the art in defending against such attacks, it would5s. staniford, v. paxson, and n. weaver. august 2002. òhow to own the internet inyour spare time,ó in proceedings of the usenix security symposium, august 59, 2002, sanfrancisco, california, usa. usenix association, berkeley, calif.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.60the internet under crisis conditionsbe very difficult to deal with attacks from even a few thousand coordinated hosts. thus a hundred or a thousand times as many hosts wouldutterly overwhelm any known defensive measuresñwith the result thatattackers could launch many ddos attacks simultaneously against a widerange of services. for example, they could plausibly target all of the rootname servers (of which 13 are currently deployed and operated by variousorganizations) and all of the major internet news outlets and the cybersecurity analysis and response sites. or, they could use the machines tooverwhelm the components of the public telephone network. or theycould pursue both strategies at the same time.the skills required to launch wormbased attacks are not extremelydifficult to acquire, and the damage and confusion that they would causecould be quite significant. thus, they appear to constitute a major form ofinternet threatñone for which, at present, there is little in the way ofdefense. however, making the nation safer does provide recommendations on some possible countermeasures for such cyberterrorism.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.615measuring the internetthe information collected by the committee provided a rough pictureof what occurred on and after september 11 with respect to internet performance. the two key sources were reports from people and directmeasurements of internet systems (such as links, routers, and hosts).the information that was available indicated some interesting contrasts between september 11 and a òtypicaló day. network traffic loadsmeasured in several isp networks the day of the attacks were generallylighter than normal. however, demand on servers at the major news websites was unprecedentedñto such an extent that several of these systemswere rendered inoperative for a period of hours. at the same time, several measurements suggested that the impact of the events of september11 on the internet was modest. the effects on the network infrastructurecaused by physical damage in lower manhattan and at the pentagonwere quite limited, and they appeared smaller, or no worse, than whatwould result from other incidents. for example, with respect to data onthe reachability of a particular set of internet addresses, september 11 wasmore or less equivalent to a fiber cutña nontrivial but relatively routineevent. these data were supplemented by other informationñpolls ofinternet users, for example.measurements of internet systems from the september 11 crisis, however, were quite limitedñin part because sources had usually discardedthe data before the committeeõs analysis began (some five months afterthe attacks) and in part because of inherent limitations in the data thatwere collected and retained.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.62the internet under crisis conditionsthe ability to report comprehensive details of the internetõs responseduring september 11, or during any crisis for that matter, is further constrained by a number of factors. one of the consequences of the internetõsfragmented and often proprietary measurement infrastructure is that dataare taken piecemeal in diverse ways and stored in various formats. as aresult, information that was available to the committee generally permitted only rough comparison with a normal or typical day in the context ofa particular set of data. measurement difficulties also arise from the size,complexity, and diversity of the internet and from the fact that a greatdeal of the data that do exist are considered proprietary by the companiesthat collect them.in the course of the committeeõs work, it became clear that a numberof questions could not be answered with the available information. theseincluded:¥how did internet traffic vary from normal activity during and after theattacks? some traffic data were available from individual isps, but it wasnot always clear how to extrapolate from these localized observations to amore generalized view.¥what was the mix of applications used before, during, and after the attacks? again, some local data were available from some isps, but it wasunclear, as above, if they constituted a collective picture.¥how much demand was there on news services before, during, and afterthe attacks? some news services were so overwhelmed by demand thattheir monitoring systems shut down.¥how much connectivity was lost as a result of the attacks? how manyusers were affected, and for how long? how quickly was connectivity restored?answering these questions would require data from a large number ofisps or from a carefully targeted sample of isps.these unanswered questions suggest that a more robust assessmentof crisis events in the future will require new approaches to gatheringnetwork measurement data. in addressing how measurement of theinternet may be improved, this chapter discusses methods and tools formeasurement; the data available from september 11; types of measurements required to fully assess the internet under crisis; challenges to befaced in gathering and analyzing these measurements; and suggestionsfor the future.network measurement methods and toolssince the internetõs inception, measurement has been a significantelement of networking research, starting with the network measurementthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.63measuring the internetcenter at the university of california, los angeles, in 1970. early on,when the system was operated as a governmentfunded research network, measurement was simpler owing to the explicit research character,relatively modest scale, and simple topology of the network, and to theabsence of proprietary constraints. with commercialization and sustainedrapid growth, the network has become much larger and more complexñmaking comprehensive measurement harder and more expensiveñand ahost of commercial interests have further limited how and where measurements can be made and who can make them. at the same time,measurement remains an important activity, particularly from the perspective of network operations.these constraints notwithstanding, the continued interest in measuring a wide range of internet characteristics both for operation and research has led to the development of an array of tools (though researchersõ access to them has not been unfettered).active measurement toolsactive measurement tools are based on the concept of sending probepackets into the network and measuring their behavior as they flowthrough it. the probe packets are typically emitted from a generalpurpose endhost such as a personal computer. probe packets are sent toward a destination host by providing a target ip address (or domainname) to the measurement tool. the injection of probe packets into thenetwork provides an indication of the routing behavior, propagation delay, queuing delay, and loss that would be experienced by normal datapackets. when (and if) the probes arrive at a destination, either theirarrival is logged or response packets are returned to the sender. when aresponse packet is returned, its arrival back at the original sender islogged, constituting the conclusion of one measurement. active probingcan also be done by approximating the behavior of typical applications,such as sending a request for a web page.active probes are important because one can gain crucial insight intonetwork conditions for a specific endtoend path at a specific time, whichmay not be possible if one monitoring occurs at only a single point. furthermore, active measurements generally do not require special participation by intermediate nodes, making them easy to deploy and execute.while active probe tools provide important data about specific endtoend conditions, there are a number of drawbacks to their use. first, theact of placing a probe into the network causes a perturbation (dubbed theòheisenberg effectó by analogy to the uncertainty principle in physics)that may lead to a change in the networkõs operating conditions. becauseof this problem, common practice is to use active measurement tools tothe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.64the internet under crisis conditionssample the network at sufficiently low rates so as not to significantlyperturb the networkñavoiding, for example, significant additions to congestion. however, the resultant measurement data are limited in theirability to capture events at time scales finer than the sampling rate and areconstrained by the necessarily small number of source and receiver locations. a second drawback is that any one system used to conduct activemeasurements is limited by routing protocols and internet topology tomeasuring only a portion of the internet. finally, active measurementtools are limited in their ability to assess aspects of volume (for example,the total amount of traffic flowing along a given path). some of theselimitations of active probes can be addressed by passive measurementtools.passive measurement toolspassive measurement methods are based on logging different aspectsof traffic observed at specific vantage points in the network. the data thatcan be collected by passive means may have a variety of forms, fromaccess logs to packet traces to detailed activity counters on routers. thesedata can be collected either at endhosts or at nodes within the network.passively collected data can be displayed in real time (as is often done bynetwork operators) or placed in a repository for offline analysis.passive measurement data can provide great insight into the activities on a link or at a node. however, they have some significant drawbacks. such data are almost always considered proprietary and are rarelymade available for general analysis. passive collection of network datacan result in extremely large data sets, which greatly complicate archivingand analysis. passive measurement tools are also prone to various typesof errors that require careful attention. the subsections below describeseveral common passive measurement tools.web access logslogging access activity is a standard feature in web server softwarethat is usually enabled by content providers. log entries contain the timeat which a particular web file was requested, the ip address of the requester, the name and size of the requested file, and the status code returned to the requester. content access logs can be used to assess manyaspects of server behavior, including load, content being requested, andthe sources of requests.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.65measuring the internetpackettrace collectionpacket traces can be a summarization of traffic (ip flow measurements) or the details of individual packets on a given link. such measurements require access to a network device (such as a router, switch, or linksplitter) or access to a broadcast local area network. a standard tool forlogging individual packets is òtcpdump,ó1 which uses packet filters tocapture selected packet activity from the network interface. a typical logentry from tcpdump consists of a time stamp, the source/destination ip/port numbers, the transport protocol name, details from the packet header,and details of the packet payload. collection of this information, especially the packet payload itself, provides valuable insights into networkuse. however, almost all organizations that collect such detailed tracesare unwilling or unable to share the traces with other parties, owing toprivacy and confidentiality concerns. border gateway protocolbecause of the internetõs distributed and very dynamic operation, theindividual isps must continuously keep each other informed about theirown networkõs reachability. the protocol that they use for this purpose iscalled the border gateway protocol (bgp). by examining changes in therouting information provided by bgp, one can trace changes in the statusof the internet. each commercial isp (e.g., uunet or att) or network ofa major organization (e.g., the national science foundation or the massachusetts institute of technology) uses bgp to inform all other isps andnetwork operators that it provides connectivity for particular sets of addresses and that packets destined for those addresses should be sent to it.such advertising of connectivity is called a bgp route announcement.thus, isps adjacent to uunet would repeat uunetõs route advertisement to their neighbors, with the added information that the relaying isphad connectivity and thus could relay packets through to uunet, ifneeded. if a neighborõs connectivity to uunet failed for some reason,then it needs to tell its own neighbors that it can no longer relay packetsthrough to uunet; this information is advertised using a bgp routewithdrawal. bgp update messages are logged for public use at a numberof òlooking glassó sites, such as route views.2the size of a bgp routing table, which indicates how many announcedpaths are available, gives an overview of network status. as of june 2002,1tcpdump. online at <www.tcpdump.org>.2route views, university of oregon. online at <http://www.antc.uoregon.edu/routeviews>.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.66the internet under crisis conditionsa typical core bgp table contained roughly 100,000 entries (the exact sizedepends on the vantage point). a significant drop in the size of a corerouting table is an indication of some sort of connectivity loss. observingthe route advertisements and withdrawals also provides information onthe internetõs health. if a route is withdrawn for an extended period oftime, one may assume that some form of network outage has taken place.this failure may result from infrastructural damage, misconfiguration byan isp, or simply scheduled maintenance. the withdrawal of all routes toa particular part of the network indicates a significant loss of connectivity.routes that are repeatedly withdrawn and announced are an indicationeither of unstable links or instability in the routing system itself.bgp tables are constructed and updated through exchanges amongpeer networks. however, each table only provides information on thenetwork as seen from a given vantage point. a drop in connectivity seenat that point might, therefore, represent a local failure rather than something more widespread. assessing the overall status of the network thusrequires examining many, carefully selected bgp tables that in aggregatereflect the shape of the entire network.3simple network management protocolthe simple network management protocol (snmp) 4 is an importantcomponent in the daily operation of largescale networks. it is the protocol used by network management systems to communicate with networkelements such as routers and switches. snmp enables network management systems both to query network elements for data and to send data tonetwork elements. data that are maintained and available from networkelements through the snmp are specified by a management informationbase (mib). this data set is gathered passively by network elements.most of the items in the mib data set are simple activity counters, such asthe number of packets transferred on a specific link. one of the main usesof snmp mib data is to ensure that a network is performing within acceptable operational limits. management systems are configured to provide multiple òviewsó into the network based on its topological configuration, enabling network managers to assess in nearly real time the stateof their systems.snmp mib data are ubiquitous in a network and could be very useful3q. chen, h. chang, r. govindan, s. jamin, s. shenker, and w. willinger. 2002. òtheorigin of power laws in internet topologies revisited,ó in proceedings of ieee infocom2002, june. new york, n.y.4w. stevens. 1994. tcp/ip illustrated, vol. 1: the protocols. addisonwesley, boston.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.67measuring the internetin assessing the state of the internet during a crisis. however, they aretypically considered proprietary and are only available to the operatorsrunning a specific network.measurement challengesproprietary dataas indicated above, business and legal considerations can mean thatmost data about internet behavior during crisis conditions may never bemade public. if these data were available, the assessment of internet behavior during a crisis, or indeed, at any other time, would be greatlysimplified. there would be challenges in organizing and normalizing thedata, but these procedures would readily lend themselves to scientificmethods. however, convincing large network providers to make theirdata publicly available is at best an uphill battle and at worst a pipedream. an alternative approach would be to mandate reporting by ispsto an agency such as the federal communications commission (indeed,reports of certain types of outages in the public telephone network mustbe so filed under present rules).consistency in data and analysisthere is no guarantee that data gathered at different sites are consistent. time stamps, units, and field descriptions for data can all be different. owing to sampling and the possibility of measurement errors, thereare also issues of the basic accuracy of particular measurements. furthermore, even if the data are consistent, the tools and data analysis methodsmust also be consistent in order to evaluate and validate results.representativenessthe heterogeneity of the internet infrastructure and its users, applications, protocols, and media all render it difficult if not impossible to makerepresentative statements about overall internet behavior on the basis of asmall number of measurements. this heterogeneity manifests itself inseveral ways, such as:¥available bandwidth. wireless users with a lowbandwidth connection to the internet exhibit dramatically different behavior from userswith corporate highbandwidth connections. highbandwidth users aremuch more likely to access multimedia content such as video streams.¥network congestion. the levels of congestion in the internet varythe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.68the internet under crisis conditionsdramatically. many parts of the united states have highbandwidth linkswith relatively low utilization. in contrast, other parts of the networkhave modest capacity and high utilization, which in turn result in highloss rates for packets traversing them.¥connectivity. some parts of the network are richly connected withmany alternate paths, while other parts of the internet are dependent ononly a single link for connectivity.such factors make it virtually impossible to assess the health of theinternet without measurement data from a large and diverse set of vantage points.the future: targeted assessment during a crisisthis section discusses what data would be required for a more robustassessment of internet characteristics during crisis events (or any othertime) and how these data might be gathered.global network monitoringa thorough analysis of internet behavior during crisis events requiresclean, consistent data from a number of vantage points across all networklayers. in a general sense, this means that the following data are requiredfrom sufficient numbers and types of protocols, networks, geographicpoints, and time scales:¥application and servicelevel data such as web server logs,¥endtoend connectivity, delay, and loss data such as those gathered by active probes,¥packet traffic data such as ip flow or router management information base logs, and¥global interdomain routing data.only modest quantities of data from each category in this list wereavailable for september 11. better understanding of future events willdepend on the consistency, perspective (geographic and topological location), and time scale of measurement data.perhaps the most extreme means for gathering data robustly during acrisis would be to construct a measurement infrastructure targeted forthis specific purpose. but a more practical approach would be the creation of a welldefined data repository into which network operatorscould submit data collected throughout the event. this approach wouldthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.69measuring the internethave the significant benefit of not requiring the facilitator of the repository to deploy and manage measurement systems. it might also enabledata gathering from areas of the internet that would otherwise be inaccessible. the drawbacks of this approach would be the difficulties associatedwith maintaining consistency in submitted data and relying on others tochoose where the data are gathered. it would also require the establishment of welldefined policies on submission, privacy, and the use of data.another challenge would be in calibrating methods of analysis for comparing or aggregating different data sources.maintaining a robust set of network data would also provide a firmerbasis for simulating internet behavior. models could be used to assesshow the internet might perform in different failure modes. this capabilitycould provide key insights into internet vulnerabilities and potentiallyalleviate circumstances in which connectivity was lost, as occurred inseveral instances on september 11.targeted measurement during a crisiseffective assessment of internet behavior during a crisis would begreatly enhanced by the ability to adjust the scope of what is being measured in accordance with the specific situation. this kind of targetedassessment would be facilitated by the establishment of a general repository of contact information for network operators, content providers, andgroups that run networkmonitoring infrastructures. two examples ofsuch lists are jared mauchõs compilation of information on network operations5 and caidaõs compilation of internet measurement activities.6when a crisis arises, measurement data could quickly be solicited fromgroups on this list in areas that are topologically close (from an internetperspective) to the geographic location of the crisis. maintaining such arepository would require resources; however, restricting the objective totargeted measurement of medium to largescale events would make thiseffort much more manageable. making sense of measurements takenduring particular network events also requires the capture of a baselineònormal day.ó75see <http://puck.nether.net/netops>.6see <http://www.caida.org/analysis/performance/measinfra>.7the characterization of a typical internet day is discussed in more detail in computerscience and telecommunications board, national research council, 2001, looking over thefence at networks: a neighbor's view of networking research, national academy press, washington, d.c.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.appendixesthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.73appendix aparticipants in march 56, 2002,workshopfred baker, ciscoaristotle balogh, verisignpaul barford, university of wisconsin, madisonk. claffy, cooperative association for internet data analysisdavid d. clark, massachusetts institute of technologychase cotton, sprint technology servicessean donelan, sbc communicationsstuart i. feldman, ibm researchgeoffrey s. french, veridiandeirdre kostick, at&ttimothy lance, nysernetwilliam lefebvre, cnn internet technologiesgeraldine macdonald, america onlinebruce maggs, akamai/carnegie mellondavid moore, cooperative association for internet data analysisandrew t. ogielski, renesyscraig partridge, bbn technologiesvern paxson, international computer science instituteõs center forinternet researchjohn s. quarterman, matrix netsystemslee rainie, pew internet and american lifejennifer rexford, at&t labsðresearchdavid safford, ibm researchsteve schneider, state university of new york, institute of technologyanthony townsend, new york universitymary k. vernon, university of wisconsin, madisonthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.74appendix bcommittee member andstaff biographiescraig partridge, chair, is a chief scientist at bbn technologies (a verizoncompany), where he leads a variety of internetrelated research efforts.his current major projects involve an innovative way to trace internetpackets to their origin and the use of signal processing techniques toperform traffic analysis. in the mid1980s, dr. partridge designed theprocess by which internet email is routed. he is the chairman of theassociation for computing machineryõs special interest group in datacommunication (one of the two major professional societies in datacommunications). he is the former editorinchief of acmõs computercommunication review and of the ieee network magazine, and a consultingeditor for addisonwesleyõs professional computing series. a memberof the technical advisory boards of matrix.net and arbor networks,dr.partridge is a former consulting professor at stanford university andhe spent 1990 as a visiting research fellow at the swedish institute ofcomputer science. he is a fellow of the institute of electrical and electronics engineers (ieee) and holds a.b., m.sc., and ph.d. degrees fromharvard university. dr. partridge was a member of the computer science and telecommunications board (cstb) committee that authored theinternetõs coming of age, and he is also a member of cstbõs committee oninternet navigation and the domain name system.paul barford is an assistant professor of computer science at the university of wisconsin, madison. his research interests include wide areanetworks and protocols, internet measurement, network performancethe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.75appendix bmodeling and analysis, and the world wide web. dr. barford is on thetechnical advisory board of epicrealm, inc., and serves on the programcommittees of acm sigmetrics 2003, the ieee workshop on internetapplications 2003, the 2002 institute for pure and applied mathematics(ipam) workshop on large scale communications networks, and the2002 international performance and dependability symposium. dr. barfordis the leader of the badger internet group (big), which conducts researchin network performance and network management. he received his ph.d.in computer science from boston university in december 2000.david d. clark graduated from swarthmore college in 1966 and received his ph.d. from the massachusetts institute of technology (mit) in1973. he has worked since then at the mit laboratory for computerscience, where he is currently a senior research scientist in charge of theadvanced network architecture group. dr. clarkõs research interestsinclude networks, network protocols, operating systems, distributed systems, and computer and communications security. after receiving hisph.d., he worked on the early stages of the arpanet and on the development of tokenring localareanetwork technology. since the mid1970s,dr. clark has been involved in the development of the internet. from1981 to 1989, he acted as its chief protocol architect and chaired the internetactivities board. his current research area is protocols and architecturesfor very large and very high speed networks. specific activities includeextensions to the internet to support realtime traffic, explicit allocation ofservice, pricing, and new network technologies. in the security area,dr.clark participated in the early development of the multilevel securemultics operating system. he developed an information security modelthat stresses integrity of data rather than disclosure control. dr. clark is afellow of the acm and the ieee and is a member of the national academy of engineering. he received the acm special interest group in datacommunication (sigcomm) award and the ieee award in internationalcommunications, as well as the ieee hamming award for his work onthe internet. he is a consultant to a number of companies and serves onseveral technical advisory boards. dr. clark chaired the committee thatproduced the cstb report computers at risk: safe computing in the information age. he also served on the committees that produced the cstbreports toward a national research network; realizing the information future:the internet and beyond; and the unpredictable certainty: information infrastructure through 2000. he currently chairs the computer science andtelecommunications board of the national academies.sean donelan is directorinternet security at sbc communications. hehas extensive experience with peering, fiberoptic cable cuts, data centerthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.76the internet under crisis conditionssecurity, cracking, power outages, and other networking topics. beforejoining sbc, mr. donelan was design engineer at equinix, where he wasresponsible for the technical standards of equinix internet business exchange centers and identifying new technologies. before joining equinix,he was a principal technical staff member at at&t laboratories. there heworked on internet service for concert, the joint venture between at&tand british telecommunications. he also acted as the lead internet service provider (isp) representative to the u.s. year 2000 coordinationcenter for isps that were not represented by firsttier providers. prior tojoining at&t, mr. donelan was at data research associates (dra) for 14years. he served in a variety of positions, from database programmer tosenior network architect. he was responsible for building a nationwidebackbone network that provides internet and database services to morethan 3,000 libraries. at dra, mr. donelan wrote the first commerciallibrary catalog search engine on the world wide web.vern paxson received his m.s. and ph.d. degrees from the university ofcalifornia, berkeley. he is a senior scientist at the international computer science instituteõs center for internet research in berkeley and astaff computer scientist at the lawrence berkeley national laboratory,and he serves on the technical advisory boards of a number of internetrelated companies. dr. paxsonõs research focuses on internet measurement and on detection and analysis of internet attacks. his doctoralthesis, which pioneered the use of òmeasurement infrastructureó for conducting largescale internet measurement studies, was awarded thesakrison memorial prize of the university of california, berkeley, foroutstanding dissertation research; this work was also cited as best studentpaper from acm sigcomm for a paper derived from one of its chapters.dr. paxsonõs study of internet routing was awarded the ieee communications societyõs william r. bennett prize paper award, and he was againawarded the bennett prize for his paper (with s. floyd) òdifficulties insimulating the internetó in ieee/acm transactions on networking. hiswork on the òbroó intrusion detection system was awarded best paper atthe usenix security symposium, and subsequent research on detectingbackdoors led to a usenix security symposium best student paper awardfor his student coauthor (y. zhang). dr. paxson serves on the editorialboard of ieee/acm transactions on networking. he has been active in theinternet engineering task force (<www.ietf.org>), chairing workinggroups on performance metrics, transport control protocol (tcp) implementation, and endpointcongestion management, and he has served onthe internet engineering steering group as an area director for transport.dr. paxson has coauthored 10 requests for comments (rfcs) specifyinginternet engineering task force standards and practices. as current chairthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.77appendix bof the internet research task force (<www.irtf.org>), he is an ex officiomember of the internet architecture board (<www.iab.org>). dr. paxsonserved as program committee cochair for the 2002 acm sigcommconference, and he is program committee chair for the 2003 usenix security symposium. he was a founding member (in 2001) of the internetmeasurement workshop, and continues to serve on its steering committee.paxson was a member of the committee that produced cstbõs lookingover the fence at networks: a neighborõs view of networking research.jennifer rexford is a member of the network management and performance department at at&t labsðresearch in florham park, new jersey.her research focuses on routing protocols and traffic measurement, withthe goal of developing new methods and tools for operating large internetprotocol networks. dr. rexford serves on the steering committee for theinternet measurement workshop, the editorial board of ieee/acm transactions on networking, and the advisory boards of acm sigcomm, arbornetworks, and mentornet. she is a senior member of the ieee and coauthor of the book web protocols and practice: http/1.1, networking protocols, caching, and traffic measurement (addisonwesley, 2001) withbalachander krishnamurthy. dr. rexford received her b.s.e. degree inelectrical engineering from princeton university in 1991, and her m.s.e.and ph.d. degrees in computer science and electrical engineering fromthe university of michigan in 1993 and 1996, respectively.mary k. vernon is a professor and vilas associate both in the computersciences department and industrial engineering department at theuniversity of wisconsin, madison. her research targets the developmentand stateoftheart application of computer systems performance modeling techniques that can be used to design new nearoptimal computer/communication system architectures with known performance properties. dr. vernon has made contributions to commercial bus arbiters, cachecoherence protocols, mesh interconnection networks with wormhole routing, the sequent symmetry bus design, commercial memory system design methods, analysis of parallel shared memory system architectureswith complex modern processors, the cray unicos operating systemsemaphore architecture, production parallel system job scheduling policies, the design of large parallel and distributed applications, scalableprotocols for ondemand streaming with packet loss recovery, optimizedmedia content delivery networks, media content delivery cost models,customized mean value analysis modeling techniques, logp modelingtechniques, task graph analysis techniques, interpolation approximationtechniques, and petri net modeling techniques. her current research includes development of analytic modeling methods, networked systemsthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.78the internet under crisis conditionssecurity, scalable multimedia delivery protocols and content distributionnetworks, design of widely distributed adaptive applications, and jobscheduling policies for the teragrid. dr. vernon received the nationalscience foundation (nsf) presidential young investigator award in 1985,the nsf faculty award for women in science and engineering in 1990,the acm fellow award in 1995 for òfundamental contributions to performance analysis of parallel computer architectures and for leadership inthe computing research community,ó and a university of wisconsin,madison vilas associate award in 2000. she is a coinventor on two u.s.patents for bus arbitration protocols and on four recent u.s. patent applications for new streaming media delivery protocols. she has publishedmore than 80 technical papers, including three that have won bestpaperawards. she has served on the editorial boards of ieee transactions onparallel and distributed systems and ieee transactions on software engineering, the 1993 nsf blue ribbon panel for high performance computing,the nsf computer information science and engineering advisory board,the board of directors of the computing research association, externaladvisory committees for various engineering colleges and computer science departments, and as recent chair of the acm sigmetrics.staffjon eisenberg, study director, is a senior program officer with the computer science and telecommunications board (cstb) of the nationalacademies. at cstb, he has been study director for a diverse body ofwork, including a series of studies exploring networking technologiesand internet and broadband policy. current studies include an examination of emerging wireless technologies and spectrum policy and a reviewof the national archives and records administrationõs digital materialspreservation strategy. in 19951997 he was a aaas science, engineering,and diplomacy fellow at the u.s. agency for international developmentwhere he worked on environmental management, technology transfer,and telecommunications policy issues. he received his ph.d. in physicsfrom the university of washington in 1996 and a b.s. in physics withhonors from the university of massachusetts at amherst in 1988.as its director, marjory blumenthal manages the computer science andtelecommunications board of the national academiesña 20memberboard of leaders from industry and academiañand its many expertproject committees and staff. she designs, develops, directs, and overseescollaborative study projects, workshops, and symposia on technical, strategic, and policy issues in computing and telecommunications. these activities address trends in the relevant science and technology, their uses,the internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.79appendix band economic and social impacts, providing independent and authoritative analysis and/or a neutral meeting ground for senior people in government, industry, and academia. marjory is the principal author and/orsubstantive editor of numerous reports and articles. the majority of herwork has been interdisciplinary. before joining cstb, marjory was manager, competitive analysis and planning, for ge information services.there she directed an analytical team supporting business development,product marketing, and field sales and developed business alliances fordomestic and international network services. previously she was a projectdirector at the former office of technology assessment, evaluating computer and communications technology trends and their social and economic impacts. there, among other things, she produced an internationally acclaimed study of computers in manufacturing and theirimplications for industries and employment. marjory is a member of thesanta fe institute science board, the advisory board of the pew internet& american life project, the tprc board of directors, the editorial boardof acm transactions on internet technology, and the acm, aea, andieee. in 1998 marjory was a visiting scientist at the massachusetts institute of technology, laboratory for computer science. at mit she developed and taught a course on public policy for computer science graduatestudents and pursued personal research interests. marjory did her undergraduate work at brown university and her graduate work (as an nsfgraduate fellow) at harvard university.david padgham, research associate, began with cstb in 1998, workingon, among other things, the studies that produced trust in cyberspace,funding a revolution, and realizing the potential of c4i. more recently, hehas assisted with the research and production of broadband: bringing homethe bits, lc21: a digital strategy for the library of congress, the internetõscoming of age, looking over the fence at networks, and information technology research, innovation, and egovernment. currently, he is providingresearch support for two cstb projects: one focusing on privacy in theinformation age and one looking at digital archiving and the nationalarchives and records administration. he holds a masterõs degree inlibrary and information science (2001) from the catholic university ofamerica in washington, d.c., as well as a bachelor of arts degree (1996) inenglish from warren wilson college in asheville, n.c.kristen batch is a research associate with the computer science andtelecommunications board. she will be involved with upcoming projectsfocusing on wireless communication technologies and telecommunications research and development. while pursuing an m.a. in internationalcommunications from american university, she interned at the nationalthe internet under crisis conditions: learning from september 11copyright national academy of sciences. all rights reserved.80the internet under crisis conditionstelecommunications and information administration, in the office ofinternational affairs, and at the center for strategic and internationalstudies, in the technology and public policy program. she also earned ab.a. from carnegie mellon university in literary and cultural studies andin spanish, and she received two travel grants to conduct independentresearch in spain.d.c. drake joined the staff of cstb in september 1999. he is currentlyhandling work on a number of projects, including one on critical information infrastructure protection and the law and another on a researchagenda for counterterrorism. he came to washington, d.c., in january1999 after finishing a masterõs in international politics and communications at the university of kentucky and earning a b.a. in internationalrelations and german from rhodes college in 1996. he has worked forthe hannsseidl foundation in munich, germany, and in washington,d.c., for the national conference of state legislaturesõ international programs office and for the majority staff of the senate foreign relationscommittee.janet briscoe is the administrative officer for the computer science andtelecommunications board. she has been a part of the team since 1997.janet has over 15 years of experience in administrative management. herareas of expertise include process improvement, problem solving, problem resolution, troubleshooting, time management, and organizationaleffectiveness. prior to joining cstb, janet worked as a support servicesmanager for norrell corporation (19911996), where she was contractedto provide administrative management services to two of norrellcorporationõs clients (ernst & young and ibm). she also worked as awordprocessing manager for shannon & luchs (19861991). janet is veryactive in her local church and community, where she serves in severalleadership positions. she is also a volunteer for junior achievement ofthe washington, d.c., area. janet holds a b.s. degree in organizationalmanagement from columbia union college.