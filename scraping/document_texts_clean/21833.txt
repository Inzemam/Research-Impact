detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/21833cybersecurity dilemmas: technology, policy, and incentives:summary of discussions at the 2014 raymond and beverlysackler u.s.u.k. scientific forum36 pages | 8.5 x 11 | paperbackisbn 9780309380058 | doi 10.17226/21833national academy of sciences; royal societycybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.technology, policy, and incentivessummary of discussions at the2014 raymond and beverly sackler u.s.u.k. scientic forumcybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.forewordthe introduction of the internet and the world wide web has revolutionized the ways we work, socialize, shop, and access information. more and more aspects of our lives are being transferred online to create a world that is steadily more reliant on digital technology. a single global digital infrastructure has been created as a platform that must meet the diverse demands of different countries and sectors. as a result, cybersecurity is a growing concern for individuals, public and private organizations, and nations alike. more and more data are being shared and stored online, creating massive pools of personal information that are vulnerable to attack and exploitation by criminal and state actors. the truly international nature of digital infrastructure creates a medium in which criminals can act maliciously, crossing borders with ease. as a result there are important international dimensions of cybersecurity and an increased need for communication and coordination between governments and companies, not just at a national level but also on a global scale. cybersecurity is no longer solely the interest of cryptographers and software developers; it affects all of our lives, personal and professional.the u.s. national academy of sciences and the royal society share a mission: to promote the use of science to benet society and inform critical policy debates. this summary of the discussions that took place on the subject of cybersecurity on december 8 and 9, 2014, in washington, d.c., will serve as a reference for decision makers, educators, and others seeking an overview of the cybersecurity dilemmas facing the world. since 2008, the raymond and beverly sackler u.s.u.k. scientic forums have sparked new excitement and enthusiasm for the exchange of ideas among thought leaders from the united states and united kingdom on topics of worldwide scientic concern. this most recent forum, on cybersecurity, demonstrates how much remains to be achieved through collaboration and discussion between the two nations. as presidents of the national academy of sciences and the royal society, we are pleased to introduce the latest piece of work supported by the sacklers™ inspired generosity.dr. ralph cicerone president, national academy of sciencessir paul nursepresident, royal societycybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas1contentssummary 31 security in cyberspace 5tradeoffs in cyberspace 6costs and benets 7law enforcement and the internet 8technological innovations 8setting priorities 9retroactive security 10regulation and deterrence 10cybersecurity research 112 safeguarding privacy 12 big data 13 notice and consent 14 other approaches to privacy protection 15 balancing competing demands for privacy 16 controlling the use of data 17 controlling the collection of data 18 norms for data use 193 international relations and national security 20 law enforcement and intelligence 21 network effects in surveillance 22 private companies in an international arena 23 arms control as a model for cybersecurity 25 making progress on international issues 264 accelerating progress in cybersecurity 29 gaining and maintaining trust 29 strengthening the workforce 30 exerting leadership 31 preparing for an uncertain future 32cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas2acknowledgmentsthe following individuals served on the steering committee of distinguished researchers:ross anderson frs, university of cambridge,eric grosse, google, inc.,andrew hopper frs, university of cambridge,1butler lampson nas, microsoft corporation,susan landau, worcester polytechnic institute,john mccanny frs, queen™s university belfast,william press nas, university of texas at austin,1angela sasse, university college london, andfred schneider, cornell university.this summary of the forum is drawn from the presentations and discussions of participants at the meeting. it was reviewed in draft form by steven bellovin, richard clayton, and kieron o™hara. the reviewers provided comments and suggestions but were not asked to endorse the views in the document, nor did they see the nal draft before its release.oversight of the review process was provided by nas council member stephen fienberg. the summary was prepared by consultant writer steve olson and with staff assistance from lynette millett, alice jamieson, and jon eisenberg.sincere thanks to the raymond and beverly sackler u.s.u.k. scientic forum for support of this activity.the national academy of sciences (nas) was established to advise the united states on scientic and technical issues when president lincoln signed a congressional charter in 1863. the national academies of sciences, engineering, and medicine have issued numerous reports on topics related to cybersecurity, privacy in the information age, and societal implications of information technology. the royal society is a selfgoverning fellowship of many of the world™s most distinguished scientists. its members are drawn from all areas of science, engineering, and medicine. it is the national academy of science in the u.k. the society™s fundamental purpose, re˚ected in its founding charters of the 1660s, is to recognize, promote, and support excellence in science, and to encourage the development and use of science for the benet of humanity. 1profs. hopper and press served as cochairs of the steering committee and of the forum.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas3the raymond and beverly sackler u.s.u.k. scientic forum ﬁcybersecurity dilemmas: technology, policy, and incentivesﬂ was held on december 8 and 9, 2014, at the washington, d.c., headquarters of the national academies of sciences, engineering, and medicine. with support from the computer science and telecommunications board (cstb) of the academies, the forum was organized by a steering committee of distinguished researchers from the united states and the united kingdom.the forum brought together approximately 60 participants from academia, government, industry, philanthropy, and nongovernmental organizations. participants included former senior government ofcials from the united states and the united kingdom as well as individuals from both countries who have been critical of the policies of their respective governments. the forum was held under the chatham house rule, which species that the ideas expressed at a meeting may not be attributed to any particular individual or institution and that the list of attendees may not be circulated beyond those who participated. the intention was to create a setting where participants could speak frankly as individuals, even about issues that affect their own organizations or countries. the twoday meeting included presentations and discussions on such topics as cybersecurity and international relations, privacy, rational cybersecurity, and accelerating progress in cybersecurity. this summary of the forum is drawn from the comments made by participants at the meeting but does not re˚ect a consensus of those present or of the sponsoring organizations. however, the observations and proposed actions in this document provide an overview of key issues in cybersecurity from a group of people working at the forefront of the eld. summarycybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas4cybersecurity can be seen as demanding a tradeoff between functionality and security: users demand ˚exibility and complexity in the systems they use, but this demand signicantly increases the difculty of ensuring the security of the system. although perfect cybersecurity is not possible, there are many opportunities to improve systems and better protect their users. a major concern for individuals is how they can protect their privacy in a world where data about them are increasingly collected, stored, and used for a variety of purposes. different stakeholders have con˚icting interests in the balance between privacy and data collection. although some service providers are primarily interested in collecting as much data as possible, even if it is not immediately useful, individual customers value their privacy and autonomy. customers™ stored data may be anonymized, but such data can be stitched back together to create a detailed prole of an individual with relative ease. if data collection and storage are not carefully controlled, they can introduce new opportunities for criminals to gain access to them for malicious purposes.in our interconnected world, cyberspace is a key topic that transcends borders and should in˚uence (as well as be in˚uenced by) international relations. as such, both national and international laws will need careful evaluation to help ensure the conviction of cybercriminals, support companies that work internationally, and protect national security. to meet the growing demand for protecting national security, international law and norms could be strengthened to reduce the risk of international cyberattacks. in addition, there is a growing need for future leaders in both the private and public sectors understand and articulate the implications of cybersecurity risks for their own organizations and for the wider economic and social system.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas5security in cyberspace individuals, businesses, governments, and society at large have tied their future to information technologies, and activities carried out in cyberspace have become integral to daily life. yet these activitiesšmany of them drivers of economic developmentšare under constant attack from vandals, criminals, terrorists, hostile states, and other malevolent actors. in addition, a variety of legitimate actors, including businesses and governments, have an interest in collecting, analyzing, and storing information from and about individuals and organizations, potentially creating security and privacy risks. cybersecurity encompasses all the activities designed to protect work being carried out in cyberspace from the hostile actions of adversaries. cybersecurity is made extremely difcult by the incredible complexity and scale of cyberspace. the challenges to achieving cybersecurity constantly change as technologies advance, new applications of information technologies emerge, and societal norms evolve.on december 8 and 9, 2014, the raymond and beverly sackler u.s.u.k. scientic forum ﬁcybersecurity dilemmas: technology, policy, and incentivesﬂ examined a broad range of issues associated with cybersecurity. organized by the national academy of sciences and the royal society, the forum brought together about 60 invited participants in washington, d.c., for a day and a half of presentations and discussions on such topics as cybersecurity and international relations, privacy, rational cybersecurity, and accelerating progress in cybersecurity. this summary of the forum is drawn from the comments made by participants at the meeting and does not re˚ect a consensus of those present or of the sponsoring organizations. rather, it explores some of the more prominent dilemmas surrounding cybersecurity, identied in italicized boldface text, as well as issues related to those dilemmas.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas6tradeoffs in cyberspace they want a technology to have the most modern and powerful features, be convenient to use, offer anonymity in certain circumstances, and be secure. but these attributes have competing requirements. for example, simpler systems are fairly easily made secure, but over time people demand more functionality, and the greater complexity that results makes systems less secure. similarly, although a complex system can be better protected by isolating it or by sanitizing all input, doing so makes the system less useful and less valuable to its users.users of computing and communications technologies understandably focus on getting the job done. if a security solution gets in the way, these people will nd ways around itšfor example, by remotely connecting an unsecured laptop so they can work at home or demanding that a particular information technology work in almost any circumstance or setting.because of these con˚icting desires, many abstract cybersecurity goals are not realistic. security is often a relatively low priority for the individuals using information systems. indeed, unless users see a clear advantage in the security being provided, they generally are unwilling to tolerate systems that are slower or more expensive or less capable simply because they are more secure.it is hard to estimate the total cost of cybersecurity breaches. security experts understandably tend to focus on the worst things that could happen to systems, and users and cybersecurity vendors likewise often claim very large estimates of the damage resulting from breaches. individual users, on the other hand, tend to think more about what has happened to them, to people they know, or to people they recognize as being similar to themselves. moreover, the people being harmed by security lapses or measures may not be the same people who decide which security approaches and methods to use. the harms that result from cybersecurity breaches can go well beyond economic costs. they include embarrassment and disruption, such as private pictures being distributed or data about corporate salaries being released. economic and other harms to particular individuals or companies (or nations) can be signicant. the harms from breaches may be small for any one individual but large in the aggregate. an ongoing challenge in cybersecurity is to understand the costs of breaches as compared to the costs (sometimes in the form of inefciencies) of additional security measures.˛˛˛˛˛˛cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas7costs and benets one way to think about the cybersecurity problem is to see it purely in terms of attackers and targets. a target has something that an attacker wants, and an attacker uses information technologies to try to get it. this view diminishes the importance of the context, including the value of the asset and the cost of the attack.but the values of assets differ. some targets are the equivalent of nuclear launch codes, which need extremely highassurance protections. others are online newspaper subscriptions, which need lower assurance protections. also, attacks generally have costs for the attacker, both in terms of the resources required to mount the attack and potential costs if an attack is detected and punished. unless the expected return from an attack is greater than the cost of the attack, the attack will be uneconomical.these tradeoffs require that decisions be made about the effort devoted to protecting assets. for example, what needs to be done to protect highassurance assets, and what can be neglected in protecting lowassurance assets? treating lowassurance assets as valuable assetsšas is done, for example, when complex password rules are applied to lowassurance assets, or when people exaggerate the costs of cybercrimešleads to the irrational use of resources. in addition, sometimes it may be easier and cheaper to disrupt criminal activity down the line rather than to thwart it in advance by introducing rigorous security measures. for instance, it could be made harder to use stolen data, or the markets where criminal goods and services are exchanged could be disrupted. further, the complexity that makes security hard also makes it difcult for individuals to be successful cybervillains on their own. even if one person could, say, steal data, that person would still need a network of other specialists (such as malware designers, fake website designers, and money launderers) to carry out a criminal enterprise that exploits the data. if these networks can be disrupted, then the potential payoff of cybercrime can be limited.today, no good answer exists to the question of how rigorously people should protect their internet accounts, or how much money should be spent on improving computer security. even a simple question such as whether to mask passwords as people type them in (that is, replacing the symbols with a bullet, asterisk, or some other character) is difcult to answer, because the threat of shoulder surng, where people steal someone else™s password by reading it as they type it in, could be replaced by other threats when passwords are masked. in fact, many claims about which practices are most effective in computer security are difcult to refute, both because there is no relevant evidence available and because gathering such evidence, if it existed, would be difcult. cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas8law enforcement and the internetlaw enforcement activities frequently engage with information and activities in cyberspace, whether testing an alibi or attempting to uncover terrorist plots. in addition, access to communications data has become an important investigative tool for the police. for example, the large majority of serious crime cases prosecuted in the united kingdom are said to rely on such access, in part because the data are relatively easy to obtain, whereas in the past such cases were prosecuted by other means.nonetheless, online criminal activities can run far ahead of the capabilities of law enforcement. highly sophisticated gangs are using computer and communications technology to steal, smuggle, blackmail, sell drugs, and conduct other criminal activities on a large scale. software to facilitate criminal acts can be purchased from hacking specialists, so those who benet from a crime no longer need to be cyberexperts themselves. the most serious criminals then can base themselves in jurisdictions that do not have established mechanisms for assisting other countries with law enforcement cases. at the same time, an understanding of criminal motives and structures can aid law enforcement efforts. criminal coalitions will need to generate specic trustpromoting structures and systems, which (given they are to be used by criminals) is a nontrivial problem. in these situations, technological innovationswhile technology cannot provide perfect security, new technology could provide greater security than exists today. for example, tamperproof audit trails and logs could cover all uses of data and enhance deterrence. robust identity systems could be applied to people, programs, and machines. technology development could change the balance and nature of tradeoffs, and careful analysis of problems could yield improvements.stronger security technologies and procedures have been developed, but evidence of their efcacy and cost effectiveness is still lacking. highassurance systems are possible, but they would likely be less functional and agile. fundamental challenges include deciding which parts of the computing world need which levels of protection, determining how much added security will cost, and agreeing on how those costs should be distributed.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas9setting prioritiesproviding cybersecurity typically means that tradeoffs have to be made among the desired attributes of systems. setting priorities can guide these tradeoffs. one option is to limit the aspirations of systems by not trying to make everything secure. for example, the designers or users of a system could decide what really needs to be protected and what is not as important, just as people decide which assets to put in a bank vault and which to protect less securely. in this way, rational security policies would protect people only as much as they need to be protected.as an example of setting priorities, the computing world could be divided into sectors that are more safe and accountable and sectors that are less safe and accountable. the sectors that call for more security might require centralized management and ways to control the input to systems, since they would still have vulnerabilities. one way to implement such an approach would be to identify a sector that handles only fully authenticated interactions, with accountability achieved by allowing interactions only with parties that are fully identied. identity could be established through a combination of the person, the machine, and the program, and full audit logs could further enhance accountability.one challenge with this approach would be moving information from a less secure zone to a more secure zone. information could be sanitizedšfor example, by taking out all the scripting language and other executable code. that would reduce functionality, but there would have to be reasonable assurance that the more secure zone had not been compromised.another way to establish priorities would be to make it harder to target important assets. most accounts contain relatively lowvalue assets, and attackers cannot target everyone with the most sophisticated possible attacks, since such attacks are expensive. furthermore, it can be costly for an attacker to gure out which accounts contain more valuable assets. systems also could be designed to enable their users to remain obscure on the internetšfor example, by dividing their information among multiple unlinked accounts, which would make it harder to identify valuable targets.approaches like these would have to overcome difculties. for example, weakly protected accounts can become more valuable over time as people use them more and for more things. today, for instance, basic email accounts should be viewed as extremely sensitive, since they are often used to reset passwords for a wide variety of services. yet the security on the accounts may not be upgraded in line with their increase in value over time, rendering their users more vulnerable.˛˛˛˛˛˛cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas10retroactive securitygiven that perfect security is not possible in cyberspace, one possibility is to move toward retroactive security measures rather than try to prevent all the bad things that could happen. for example, in the nancial system, the fundamental basis for security is that almost any transaction can be undone. preventive measures would still exist, but the emphasis would be on reacting to security issues after the fact rather than on trying to anticipate all possible threats. in this way, the focus would be on actual problems rather than hypothetical worstcase problems, as is often the case with physical security systems. using this approach, actions that cannot be undone would have to be handled much more carefully. a challenge for retroactive security and the setting of priorities as described above is that the question of which things need high security is highly contextdependent. an individual™s ﬁmother™s maiden nameﬂ is not a secret or a security concern until it is used to answer a nancial institution™s security question. similarly, whether a transaction can be undone or not is context and timedependent (for example, does the institution involved still exist?). it can be a challenge to know in advance whether something is sensitive or whether it can be undone. regulation and deterrencethe government could enhance its response to cybersecurity threats in a number of ways. it could increase its oversight and regulation of computer and communications technologies. it could use its convening power to encourage companies and institutions to comport with best practices. it could mandate a ﬁsafety cultureﬂ approach (similar to that seen in aviation) to cybersecurity and privacy not only in government agencies but also in the private sector. it could insist that companies provide security and privacy mechanisms in their products. tort law could be interpreted in new ways or amended to provide increased penalties for cybersecurity breaches.one aspect of regulation is deterrence through the threat of some kind of punishment. however, the people conducting cyberattacks are usually difcult or impossible to nd and punish. denial is easy, proof is hard, and prompt attribution is particularly difcult. furthermore, cyberattacks and cyberexploitation are usually indistinguishable until an explicit attack is executed. cybersecurity can be violated, for example, by the placement of a capability that allows access for some future unknown purposes.deterrence also runs the risk of sweeping up unintentional as well as deliberate attempts to contravene security. people who face a choice between getting their work done and observing unrealistic security guidelines make rational choices, so they need rational security systems.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas11although it would be difcult to require accountability throughout a communications network, the nodes (i.e., servers or enduser devices) of a network could be made accountable for their cybersecurity provisions. for example, they could be locked out of a network or strongly isolated if they were found to be insufciently secure. administrators would need to detect which nodes are vulnerable or acting maliciously and be able to punish or isolate them. this authority could be delegated to a professional third party, with the responsibility decentralized rather than concentrated in a single location.˚˚ economic incentives can be a more efcient intervention. for example, the u.s. securities and exchange commission and the u.k. financial conduct authority could adopt new rules requiring that data breaches or noncompliance with best security practices be reported to investors in quarterly reports. if companies are seen as acting in ways that harm their customers, they will not keep their customers™ business. as is often said in the technology industry, a competitor is just a click away for consumers.cybersecurity researchadditional research could yield substantial progress on many of the questions that still surround cybersecurity. for example, more study of how people applyšor circumventšsecurity systems would be useful for designing more rational systems. metrics for levels of security and values of assets could enable goodenough security rather than absolute security. is it possible to reduce the maximum harm that attackers can do while increasing the level of assurance that can be provided to potential targets given a particular level of available resources? can an optimal cybersecurity model be envisioned along with pathways to move toward such a model? can a machine learning system identify patterns of bad behavior in past activities and use those patterns to detect ongoing bad behaviorša goal of many intrusion detection systems today? how quickly can such approaches adapt when adversaries can use similar technologies to understand what patterns of behavior they need to change to remain undetected? both foundational and more applied research could yield longterm progress.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas12safeguarding privacycybersecurity tools and techniques are one of the foundations for trust that information will be protected, such as that trade secrets will be safeguarded or that personal information will be kept condential. as people conduct more of their daily lives online, opportunities to acquire and misuse nancial, medical, sexual, and other forms of personal information are multiplying. furthermore, the continued development and spread of computer and communications technologies are creating new ways for companies, governments, and criminals to gain access to information that people would rather keep to themselves. and once data have been generated and exist somewhere, disclosure of those data creates the potential for harm. a particular challenge is that even if disclosure of some data is not likely to cause harm, aggregation of those data with other data may be harmful. researchers have explored potential technical solutions to some aspects of this problem, such as differential privacy, but these work at best in limited circumstances, and the general challenge persists. individuals have many preferences about their privacy, and those preferences are not xed. they are dynamic, informed by context, shaped by relationships with other people and institutions, and constantly under negotiation. sometimes these preferences coalesce socially into expectations, norms, or conventions that are associated with particular contexts. at the same time, governments, communities, social networks, and businesses have legitimate interests in acquiring, analyzing, and using data about individuals. these interests may be commercial, governmental, or social, but they all create a desire or a need for personal information.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas13big datathe advent of the era of ﬁbig dataﬂ is further complicating the protection of privacy. today, data are being transacted, computed, observed, and sensed, and data from many different sources can be combined. individuals do business with companies, live in communities, associate with each other in societies, and are overseen by governments. data are used for health care, law enforcement, intelligence, politics, education, and virtually every business. all of these data can be stored indenitely, replicated, and combined in unlimited ways. for example, software now exists that can analyze a person™s social media posts, connect them with other data about that person available online, and construct a surprisingly detailed and accurate prole of that individual.in the modern world, an individual™s physical, mental, and emotional state is constantly being quantied based on the data he or she generates. in some cases, people are aware that they are generating data and may give permission for these data to be used in certain ways. but these data can be used for multiple purposes, some of which people want and others of which they do not want. as examples, data can be used to identify suspects in a crime, approve loans, sense early alzheimer™s disease, detect a person™s learning style, infer sexual orientation or political afliation, estimate income, identify a network of friends or acquaintances, recognize where a person is through public cameras, or detect when a person is home. furthermore, data that can be used benecially are the same data that can be misused. for example, data generated by playing a game online could be used to identify health problems among older people, or they could be used to calculate reaction times and discriminate against older employees. big data can reveal people™s activities at a continuous and intimate level and can be used in ways that make many people uncomfortable. for example, someone may enter a query into a search website and, the next day, encounter targeted advertisements for an associated product. but often the only way to acquire a service or product is to divulge the information demanded by the provider of that service or product. people may choose to use specialized adfree search engines or browse the web using privacyenhancing technologies to limit the amount of targeted advertising they receive. however, people using these approaches may experience a lower quality or utility of service or even no service at all.˛˛˛˛˛˛cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas14notice and consentone way people may control the collection and use of their data is through the procedure known as notice and consent. it is a contractual agreement that assumes and respects the free exchange of information and services. it serves notice that an institution wants personal data, describes what the institution will do with the data, and explains what an individual will receive in exchange for the use of his or her data. the individual replies to this notice with a yes or a no (for instance, by clicking a button on a webpage). yes gives consent and enables access to the service; no denies consent and, generally, the individual™s access to the service. in this way, individuals manage their privacy by trading it against incentives offered in the marketplace. notice and consent makes no moral claim about whether privacy is good or not. it is simply an exchange agreement.as originally developed in the 1970s, notice and consent was a simple and easytounderstand system designed to respect individual autonomy and the desire to derive value from data. it worked well at a time when data collection was much less pervasive than it is today and did not include the collection of extremely negrained bits of data (such as the timing and targets of swipes on a smartphone). today, notice and consent, as currently used, has serious ˚aws. first, for consent to be useful, it has to be informed. but to cover all contingencies, consent notices have become long, dense, difcult to readšand usually remain unread. if an individual is not informed, that person™s autonomy is largely an illusion. furthermore, people cannot make informed decisions every time the use of a technology demands personal data, especially as technology becomes more embedded in everyday activities. the individual user is being asked to assess one of the psychologically more difcult tradeoffs: that between an immediate and predictable good and a longterm and unspecied risk. moreover, cumulative effects are also hard to assess. an individual piece of information may be harmless, but when many such pieces are aggregated, the aggregate may reveal sensitive information. notice and consent typically demands a yes or no answer, but someone may want their data used for some purposes and not for others. also, preferences, technology, and the use of data can change over time, but notice and consent makes no provision for such change. given the complexity of the digital world, most people would be hard pressed to manage every aspect of their privacy.˛˛˛˛˛˛˛cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas15even if people were given a set of options rather than a binary consent option for the use of their data, they generally cannot be told exactly how their data will be used in the future. companies may do their best to lay out the risks of providing personal information, but they may not be able to anticipate all such risks. for example, a company may discover a use for data that was not apparent when the data were collected.asymmetric access to and use of information means that the users of a technology generally do not know much about what is done with their data. many users also do not care much about the effects of disclosure in the distant future. firms that depend on mining private data do not go out of their way to publicize their use of the information and consequent threats to privacy.notice and consent does not, moreover, necessarily preclude transfer of data to third parties. as a result, information granted for one purpose may be transferred to someone else who uses it for another purpose. the existence of privacy policies does not necessarily safeguard privacy; such policies could specify, for instance, that all of a person™s data will be indiscriminately sold.the provisions of a privacy policy may apply only to personally identifying information and not to information that has been ﬁanonymizedﬂ by removing personal identiers from that information. however, anonymized information often can be reidentied by crossreferencing it with other data sources.finally, much of the information being gathered about individuals today is not subject to notice and consent. it is gathered through administrative records, transactions, and other activities of daily life, and what can be inferred by combining such data may be more harmful than any individual piece of data.other approaches to privacy protectionas discussed earlier, better cybersecurity protections and stronger accountability can help to ease the dilemmas associated with privacy. however, they cannot completely solve problems with privacy, because like notice and consent they place an undue burden on the user. thirdparty privacy services could place the task in the hands of experts, but if such services then had to be purchased by individuals, inequities would be inevitable.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas16one alternative to notice and consent that is used more commonly in the european union than in the united states is the concept of legitimate interests. it calls for balancing the interests of the data controller against the interests of the data subject. under the framework outlined in the u.k.™s data protection act, data controllers receive guidance about how to identify and protect these interests. in the united states, the federal trade commission act has an unfairness provision that might be used to implement a similar framework. such a step would be consistent with the responsible use of data and could provide the basis for a universal approach to privacy protections.one limitation of the legitimate interests approach is that it does not offer guidance on yettobeinvented uses of data. also, how such a concept would be implemented remains uncertain. it could complement notice and consent, but other approaches are needed.an analogue to the ﬁright to be forgottenﬂ approach has potential to deal with some of the problems of notice and consent. if such a right were part of a consent regime, it could be interpreted conservatively as a person™s right to revisit consent over time and withdraw data that have been supplied. review of consent could also be triggered by any change in a privacy policy, enabling an individual to renegotiate an existing contract. such an approach would respect the life cycle of information, the importance and social value of which can change as the context changes.balancing competing demands for privacy˚ even in a simple abstract model with just one data holder and two data subjects who exchange only cash and data, there are many scenarios in which the resulting ˚ows of cash and data will not necessarily benet everyone. in more complex situations, different denitions of optimality are similarly liable to lead to mixed distributions of both benets and costs.within neoclassical economic theory, there are contrasting arguments for and against increased privacy protections. one argument is that privacy creates economic inefciencies and therefore reduces economic welfare. another argument is that stakeholders in the marketplace tend to overinvest in data collection and use, which is also inefcient and creates the risk that data will be inadvertently released that in the rst place were never needed. similarly, recent empirical research on privacy shows that either the protection of data or the collection of data can have benecial and negative cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas17consequences. for example, in the united states, states that legislate stricter privacy for medical data have been shown to experience lower adoption of new health technologies, in particular electronic medical records. but other results show that states with more protections on health information are more likely to see creative and innovative approaches because the innovators have a better sense of what can and cannot be done and are less subject to regulatory uncertainty. similarly, the data industry can be viewed in different ways. if it allows a better match between consumers and merchants by enabling them to nd each other with minimal costs, then consumers, merchants, and the data industry can all win. but if the data industry is an oligopoly with only a few gatekeepers who control the relationship or contracts between consumers and merchants, the data industry will have the upper hand with both merchants and consumers. in this case, the lack of competition can reduce choice, and resources can be transferred from consumers and merchants to the data industry rather than creating a bigger economic pie for everyone. the outcome remains an open question.at the root of many of these discussions is the question of who owns the data. can an optimal balance between privacy on the one hand and data collection and use on the other be identied or maintained? an even more relevant question may be whether the interests of different stakeholders can be balanced. the more control consumers have over their data, the more risks they are likely to take with those data, in the same way that adding safety features to cars, such as antilock braking systems, may lead drivers to drive faster because they feel secure. moreover, transparency and control are necessary but not sufcient conditions for privacy protection. in the absence of other protections, there may instead be ﬁresponsibilization,ﬂ whereby end users are forced to take responsibility for something over which they actually have little control.controlling the use of datagiven the problems with current privacy regimes in this era of big data, rather than specifying that particular methods be used to protect privacy, government could regulate uses of data that pose risks. these risks could involve nancial losses, physical injury, unlawful discrimination, identity theft, loss of condentiality, and social or economic disadvantage. under such a system, some uses of some data would be regulated or forbidden, ˛˛˛˛˛cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas18even if the data were gathered through notice and consent. data could continue to be used for benecial purposes, while harmful uses would be avoided because they would be illegal. regulations could be applied to what might be termed ﬁpersonally impactful inferencesﬂšthe combinations of existing data that represent potentially harmful use. controls over the use of data also could apply to proling activity.decisions about how data would be used and how such use would be controlled could emerge from individuals, communities, businesses, government, and society at large. these decisions could take the form of legislation, regulation, or informal standards, although different entities would have to negotiate who makes the decision, and the approach would need to be scalable so as to be widely applicable. if such a regime were to be attempted and as people gained familiarity with it, potential harms and benets would become more apparent, so controls over use could change over time and vary from place to place.controlling the collection of dataan alternative or complement to controlling the use of data would be to control the collection of data. disincentives to the bulk collection of data can be put in place. entities that ask for too much data or permission to do too much with data can be identied and dissuaded from their actionsšfor example, by bringing those actions to the attention of potential users. the principle of purpose limitation in the european union™s data protection directive, under which businesses can retain data only for as long as they need them, could be strengthened so that businesses do not retain data just in case a future use should arise.users could be given more granular control over the data they generate. for example, they could have more control over the generation of data by technologies such as cell phones. however, other information is also being gathered, such as by municipal cameras that record license plates. furthermore, computers connected to the internet typically send out voluminous quantities of data that can be hard to hide, and exceptional efforts to turn on privacy controls can make a user even more visible to those who are looking for such actions. indeed, people have little control over the generation of ﬁmicrodataﬂ from everyday activities even though such data can be combined in revealing ways.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas19norms for data usea widely accepted set of norms for the use of data could help to protect privacy. for example, the following norms, similar to the framework provided by the fair information practice principles,2 could be promoted and implemented: the use of data should benet users or protect others. benets may be hard to pinpoint, but discussion among people representing multiple perspectives can often arrive at conclusions. at the least, the entities collecting the data could be required to explain to people how they or others are benetingšif, say, such data collection is helping to stop fraud. data should be kept secure. security is essential to safeguard the uses of data and protect privacy. users should be able to inspect, export, delete, and edit data they have provided. if people are able to review the data they have provided, they can see whether the information is accurate or they can decide to delete it. allowing the data to be edited can be more of a challenge, since people may misrepresent themselves or their past activities or not understand the context in which the data were gathered and for what purposes. in some cases, moreover, deletion would be inappropriatešsuch as with nancial data that need to be retained for accounting and legal purposes.2the fair information practice principles are rooted in a 1973 report from the u.s. department of health, education and welfare, records, computers, and the rights of citizens. cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas20international relations  and national securitycyberattacks can come from anywhere in the world. the relevant technology and expertise to conduct them across borders are widespread and exist in both the public and private sectors. moreover, just as information technologies can be used to conduct crimes, they can be used as weapons to instigate or escalate con˚icts and crises. threats exist in such areas as cybersecurity attacks, electronic warfare, information operations, and psychological operations, with malevolent actors ranging from criminals and terrorists to entire nations. a cyberattack could escalate to the point where one of the parties views it as an act of war. the more apocalyptic scenarios consider what offensive cyber actions can do to highly developed states with critical infrastructures that depend on internet capabilities.conventional weapons require huge investments, whereas small groups with much more modest resources can develop and deploy cyberweapons. many actors see a cyberattack as an instrument of asymmetric warfare against the united states and the united kingdom and their allies. they may not be able to compete on the basis of military hardware, but they can compete in cyberspace. for all these reasons, cybersecurity has critical international dimensions.governments face a tradeoff between on the one hand using new exploits to gain access to the plans and actions of adversaries and, on the other, exposing and xing the same exploits to increase the security of communications. the public wants transparency, but the public and private sectors must deal with the use of information technologies for national security threats. the private sector wants to protect privacy to maintain the trust of consumers but is subject to demands for information from governments. cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas21law enforcement and intelligencelaw enforcement generally does not have the capability to deal with the high level of criminal activity that is occurring on networks, which is why law enforcement agencies in some places have increasingly turned to intelligence agencies for help. it would be expensive to provide law enforcement with the capabilities already present in intelligence agencies, and duplicating a capability that already exists is inefcient.an issue here is that intelligence and law enforcement have traditionally had different goals: law enforcement typically has reacted to crimes, while intelligence agencies typically have sought to prevent threats from being realized. now law enforcement is being asked to prevent crimes as well, which is one reason it has called on the services of the national security community, especially for dealing with foreign threats inside their countries.in the united kingdom, legislation passed in 1985 (the interception of communications act), 1994 (the intelligence services act), and 2000 (the regulation of investigatory powers act) provided for using information technologies to tackle terrorism and serious crime. though rarely used in the past, these provisions are now used frequently. government funds national intelligence agencies to protect national security, including the protection of armed forces operating overseas, countering proliferation, and uncovering statesponsored cyberattacks. these agencies have developed sophisticated means of electronic espionage, and law enforcement is keenly interested in using these same tools to attack crime.the united kingdom decided more than 20 years ago, well in advance of its european partners, to impose the same basic regime for limiting intrusive investigative activity on its intelligence activities as on law enforcement. laws regarding intelligence aim at preventing intelligence from being used for political purposes or commercial advantage. not all countries can be expected to adopt such a model, but it suggests norms that could increasingly be adopted. intelligence agencies could be regulated by publicly accessible laws, not by secret laws or presidential directives. intrusive methods could be authorized by a warranting process. principles of proportionality and necessity could be written into law and imposed as legal requirements. intelligence activity could be independently overseen, particularly when it supports law enforcement, by an independent court to assess claims of abuse and award redress if powers have been abused.the existing regime of mutual legal assistance treaties may require modernization to tackle cybercrime and terrorism on an international scale. acquiring data through these treaties can take many months, which is too long to prevent many crimes or deal with a national security emergency. there are increasing jurisdictional disputes as more countries pass laws entitling their police and intelligence services to cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas22seize data held in other countries while forbidding foreign agencies to do the same. minimum standards for warrants, transparency, and jurisdiction could be implemented through a new international agreement.network effects in surveillancetechnology companies tend to view in˚uence and prots in terms of networks. they try to develop and establish operating systems, social networks, software platforms, and other products in the expectation that other people will add value to those products. this has implications for cybersecurity, in that the emphasis is on rapidly increasing the number of people who use a platform, not on securing it. for example, if there are a lot of users, developers will create apps for them, and if there are a lot of apps, users will nd the platform more appealing. in markets ranging from mainframes to personal computers to routers to social networks, security has tended to be added, if at all, only in the later stages of market competition.network effects can be seen in the intelligence world as well. as intelligence increasingly acts more like an information industry, network effects related to where most of the information accumulates and who has access to it will come into play. network effects can in˚uence the actions of intelligence and law enforcement agencies. for example, network effects can entangle countries with other states that use, or provide, the same platforms. low marginal costs and technical lockin can make it very expensive for governments or other entities to build independent networks, even if they perceive a strategic advantage in doing so.no matter their political inclinations, most policy makers have given little thought to network effects, even though these effects could have a powerful in˚uence on the distribution of power in the future. for example, network effects could convey power from the leading countries to an association of developed democracies, in the same way that network effects have drawn countries outside the european union into the association.the economic models used in information technology (it) and in government have traditionally been quite different. applying lessons learned about network effects in the it industry to international security and surveillance could prove fruitful and might illuminate strategic policy questions about surveillance, information sharing, and international affairs. ˛˛˛˛˛˛˛cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas23private companies in an international arena these companies have to abide by the laws of the countries in which they are based, and these laws typically take one of three forms; they prohibit the disclosure of information; require the disclosure of information; are agnostic as to whether information has to be released.two main statutes affect the disclosure of information in the united states. the rst is the stored communications act, which prohibits communications companies from sharing or disclosing data except in certain situations. this law does not cover responding to foreign requests in most situations. the second is the pen register act, which is part of the electronic communications privacy act. it prohibits companies from disclosing data that move across networks unless certain exceptions apply. in the united kingdom, the main statute that covers the protection of personal information is the data protection act, which implements the european union™s data protection directive. it prohibits the transfer of personal data to any country outside the european economic area, unless that country can ensure an adequate level of personal data protection.as companies receive more and more requests from foreign countries, they have developed policies to try to address these requests. many of the largest companies have published transparency reports that describe the legal processes associated with the release of information. these processes are very similar, although there are some differences from company to company.in general, if the foreign country requesting the information respects the rule of law, has a good legal system and a good human rights record, and the request complies with the local law of the jurisdiction in question, then a company is much more likely to disclose the data. however, requests are considered on a casebycase basis, which is a resourceintensive process. sometimes companies have no choice but to curtail or eliminate their operations within a given country because of the legal demands or restrictions they face in that country.the revelation that the u.s. government has conducted largescale surveillance of entities outside the united states has led some countries to consider enacting laws that would impede such actions. other countries also have sought to enhance their own surveillance authorities, as a way to protect their own citizens.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas24a proliferation of such laws would further increase the difculties companies face in deciding how to respond to data requests. a country where a data subject is located may have a law that prohibits the release of data. another country without such a law may be interested in those data and request them. companies try to navigate their way around con˚icting sovereign interests, but the situation is difcult and is likely to become more so. current mechanisms would need to be improved or new ones found to satisfy each country™s sovereign interests.issues like these have arisen in other contexts, so precedents and models do exist for making decisions. for example, treaties are the classic way for countries to deal with disagreements. in the context of information, the most important treaties are mutual legal assistance treaties. in some cases, countries can take advantage of mechanisms unilaterally. for example, a country could say that it is permissible for companies within its jurisdiction to cooperate with requests from other jurisdictions in particular situations. in such a case, domestic law can facilitate information sharing without going through difcult treaty negotiations.in a joint investigation, law enforcement in two countries may be interested in the same criminal act, in which case an agency in the rst country can get information from data providers in that country and share it with authorities in the second country. sharing of information among law enforcement agencies also can happen informally without opening a joint investigation. other options are available for international data sharing, creating several choices for a given situation.other countries have been considering whether they should require the use of local service providers instead of nonlocal providers in the possibly naïve hope of blocking efforts by the u.s. government to gain access to data. similarly, many countries are dening internet sovereignty in terms of control and censorship, which could affect hardware, software, and conventional practices in those countries.however, such laws are likely to increase costs, and they will not eliminate all security issues and may introduce new ones. they also will not necessarily advance the economic and social interests of those countries, since they erect what is essentially a tariff barrier, making it more expensive to offer digital services in that country while facilitating censorship and social control.companies will continue to struggle with the competing demands from different nationstates, but network effects will press against the desire to establish separate, closed internets. the existing multistakeholder governance system for the internet can help resolve some but not all jurisdictional problems.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas25arms control as a model for cybersecurityprotection from hostile cyber actions falls into four broad categories: cyberdefense œ protecting important it assets. cyberdeterrence œ dissuading adversaries from launching hostile operations. cyberpreemption and damage limitation œ reducing the capability of the forces that an adversary might use.  cyber arms control œ can entail workable agreements with potential adversaries to reduce the likelihood of hostile cyber operations and reducing damage should hostile operations occur.arms control agreements can have varying scope. they can be universal, such as the geneva conventions that prohibit attacks on certain kinds of targets. they can be multilateral or bilateral, such as the agreements among nato members or between the united states and russia. or they can be unilateral, where one country takes action for such purposes as reassuring others about its true purposes. arms control agreements also can have varying mechanisms. treaties, memoranda of understanding, and coordinated unilateral policies can all control the actions of signatories to the agreement.one application of an arms control framework to cybersecurity might involve limitations on acquiring offensive capabilities. however, verication, a key element in arms control, may be very difcult. the operational capability of such a limit would depend on research and development, not on delivering manufactured systems. moreover, seeing activities in cyberspace is hard unless they are conducted on a large scale. cyberoperations depend on deception. behavior does not always reveal intent, and intent is important in cyberspace, as elsewhere. understanding intent depends on deeper knowledge, which would if revealed enable the adversary to anticipate actions and mount more effective defenses. finally, the instrumentation needed to gather data would likely be extensive, highly intrusive, and easy to evade.another application of an arms control framework could be limiting the use of cyberattacks, for example, on national nancial systems or power grids. such limits may require cooperative measures, such as electronic identication of prohibited targets, analogous to the timehonored painting of a red cross on a hospital or ambulance. such arrangements may not ensure compliance, but they could create or reinforce international or national norms regarding the acceptability of such behavior and be enforceable through reciprocal threat. they could also help to inhibit overt threats or to clarify redlines in an escalation ladder.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas26cyberdeterrence has major legal and policy implications. it can work at the legal, policy, or operational level. for example, deterrence could involve dening a line past which a response is swift, sure, and damaging. one problem, however, is that redlines are constantly moving as the issues and technologies evolve, thus increasing the need for dialogue. the importance of these issues further emphasizes the importance of simulations and exercises.the most likely application of an arms control framework would be through  condencebuilding measures. examples from traditional arms control include notication of activities that might be observed but misinterpreted, means for communication during times of tension, agreed conventions for behavior, and noninterference with gathering data for verication of compliance.even small steps could yield progress. development of a common vocabulary and conceptual structure could enhance mutual understanding. the desire to curb activities that countries generally agree are illegal could foster international cooperation. and communicating during crises, differentiating espionage from attack, cooperating against thirdparty provocateurs, or declaring cyber ceaseres could prevent inadvertent escalation.making progress on international issuesthe international dimensions of cybersecurity will have a profound impact on the future of it. the freedom, governance, and stewardship of the internet are in play. issues such as cyber sovereignty, censorship, and net neutrality are all highly salient.national cyber strategies for peacetime, con˚ict, crisis, and warfare could be strengthened. procedures to engage with adversaries could be compared and correlated within a country and perhaps internationally, as through the formation of cyber alliances or condencebuilding measures. cyber architectures, technologies, designs, and innovations in such areas as the cloud, big data, encryption, and identity management could be tracked and their impacts on international relations assessed. cyberrelated commandandcontrol systems, battle management, and situational awareness could all receive much greater attention. gaming, exercises, simulations, and other forms of assessment could enhance preparation.nonstate actors are wild cards for managing stability, because they can instigate or escalate crises. the legal notion that states are responsible for the actions of their citizens is often unenforceable in today™s world. however, attribution of actions is not necessarily as difcult as many nonstate actors assume it is. nonstate actors could be identied in a noncrisis period so that they do not continue to believe that they are acting anonymously.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas27international law and norms to protect against international cyberattacks could be strengthened. a nation that nds itself under a massive cyberattack should be able to call for and expect international support. article 28 of the united nations declaration of human rights, which protects the rights and freedoms set forth in the declaration, applies in the online world as well as the of˚ine world. international humanitarian law also applies in cyberspace. principles of protecting civilians and avoiding collateral damage apply in cyberspace. if it is a war crime to drop a bomb on a hospital, it is a war crime to disable a hospital with a cyberattack. the government cannot delegate to the private sector the responsibility to police the internet. however, companies do have a responsibility to their shareholders and owners to protect their reputations. if a company makes no reasonable attempt to detect illegal activities or cooperate with authorities, its reputation can suffer. this is another reason for dialogue between the public and private sectors.at an international level, existing and new norms could be established and reinforced. for example, the u.s. president has suggested one new normšnamely, that the defense should prevail in the choice between keeping a vulnerability for future covert use and disclosing it to bolster cyberdefense. the military logic is that the breach of a defense can be much more serious than losing the hypothetical value of a future tool. similarly, nations could agree that nuclear commandandcontrol and space systems are offlimits to cyberattacks because such attacks might irrevocably destabilize an already tense situation. another potential norm is that intelligence agencies will not monitor the communications of heads of state and government of close friends and allies except when there is a compelling national security purpose. however, attempts to set up a blanket nospying agreement are not likely to succeed.in law enforcement, a set of norms could dene the principles of cooperation in international law enforcement. the main objective of the budapest convention on cybercrime is to create a common policy for protecting society against cybercrime, especially by adopting appropriate legislation and fostering international cooperation. this rst international treaty addressing internet and computer crime had been ratied by 46 states as of june 2015. other examples of cooperation include the exchange of airline passenger information, the sharing of watchlist data, and mutual legal assistance arrangements. however, data sharing can prove controversial when it con˚icts with existing privacy laws. another possibility would be a cyber council, such as a standing body within the united nations or another international organization, where discussions can take place as the issues and technologies evolve. all participating nations would need to buy in so that everyone has a voice and a stake in the process.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas28within countries, organizations could be established to build ﬁcyber bridgesﬂ between the needs and capabilities of the public and private sectors. today such efforts are often piecemeal and temporary, but more permanent and substantial entities could be created. for example, institutions could work to bridge responsibilities and capabilities between law enforcement and intelligence agencies.international cybersecurity activities, including international surveillance, require oversight. the general public cannot be invited into a national security agency, but proxies for the public could safeguard trust. these individuals would need training and guidance to do their jobs well, and they would need the right level of authority, but general principles could be established to guide their oversight.as pointed out in chapter 1, the potential of technology to protect bad actors remains a point of contention, as systems that offer extremely strong protection become increasingly available. yet the use of unusually strong protections also could heighten the surveillance of the people who chose to use them. at the same time, even if stronger protections become more widely used, existing and new technologies that are less secure will continue to yield tremendous amounts of information about potential threats. as more and more information is digitized, it will become available to supplement traditional intelligence and law enforcement methods.in many cases, laws do not align among countries. this places companies in the uncomfortable position of having to try to comport with irreconcilable laws simultaneously. companies try to achieve a balance on these issues. governments could enhance collaboration by providing more protection for or assistance to the private sector with regard to these challenges.in addition to the usual con˚icts between national interests, cooperation among countries in cyberspace is hampered by policy makers™ unfamiliarity with the issues, rapidly changing technologies, and not many precedents. the sociological issues are as important as, if not more important than, the technological issues in international affairs. these sociological issues comprise public policy, planning, organizational structure, legal affairs, governance, and leadership.countries have fundamental differences in their approach to such areas as human rights, free speech, and sovereignty. views on democracy, privacy, intellectual property, and many other legal protections can have a strong in˚uence on cybersecurity. many kinds and levels of engagement and dialogue will be needed to accommodate different national perspectives, world views, policies, and technologies. however, network effects make it difcult for countries to withdraw from existing networks. one result is likely to be some degree of sociocultural convergence as people use the same tools and exchange information.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas29progress in cybersecurity has been slow, and government, rather than leading by example, has often lagged behind other sectors. the rate of progress could be accelerated, but this will require a sustained effort by multiple stakeholders to understand the current context, make changes, and monitor the consequences of actions taken. resilience, ˚exibility, and adaptability may be more useful than heavyweight defenses.gaining and maintaining trustgiven the importance of information technologies in modern life, government has a responsibility to take extra precautionary steps. governments could make new efforts to protect information to the proper level, prioritize resources, and achieve both oversight and transparency.3 trust has a technological dimension. for example, establishment of identity is being advanced in both the united kingdom, with the identity assurance programme, and the united states, with the national strategy for trusted identities in cyberspace program. these programs allow private sector rms providing authentication services to 3for example, in 2013 the u.k. government increased funding for the national cyber security programme by £210 million, putting the total for the 5year program at £860 million. as part of an upgrade in cybersecurity after recent breaches, senior civil servants now have increased responsibility for managing risks. organizations that supply services to the u.k. government must now comply with a ﬁcyber essentialsﬂ scheme by adopting a set of technical controls.accelerating progress in cybersecuritycybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas30federate identity and use the right identity for the right purpose. large companies with hundreds of millions of users across the world may be able to provide more trustworthy authentication services than the government. they perform billions of authentications per day and may be better placed to spot attacks and block them faster than smaller players, including small nations. the current trend is for people to use authentication services from large rms such as google, facebook, or microsoft rather than governmentissued ids when accessing privatesector services.the users of it have a role in maintaining cybersecurity. user educationšfor instance, in the area of phishingšcan strengthen this role, although it is not clear what kinds of education would be most effective or longlasting. moreover, in many cases users have little choice about whether and how to participate in certain systems, for they are compelled to share or use data or use certain technologies. imposing additional, complex responsibilities could be unfair. in any case, studies are needed to determine how education can be most effective in this domain. for example, it could be focused on areas with the lowest marginal costs for users to change behavior and the highest marginal benets in terms of cybersecurity.strengthening the workforcea critical boost to cybersecurity could come through developing national talent, including elite individuals and teams. today, both the public and the private sectors are having trouble nding enough qualied cybersecurity workers. furthermore, professions such as the law and psychology also need people with cybersecurity backgrounds. especially important are people who can translate or mediate between those who focus on organizational intent and those with expertise in technology.hiring strictures and lower salaries in government are among the factors that impede progress in the public sector, but not in all agencies. for example, the u.s. national security agency generally has been able to get the people it needs, in part by identifying and attracting people with strong backgrounds and providing the necessary specialized training in cybersecurity. the signals intelligence agencies in both the united states and the united kingdom work with colleges, universities, and schools to interest students in science, technology, engineering, and mathematics and demonstrate how these skills might be applied in government. intelligence agencies have many different kinds of jobs, allowing people to follow multiple career paths.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas31exerting leadershipcybersecurity could be enhanced if the leaders of organizations pressed for cybersecurity, not just the people within the organization with responsibility for it and cybersecurity. if leaders had an understanding of and interest in the topic, cybersecurity could be an ongoing concern, not something to be checked off and forgotten. for example, senior decision makers could be running desktop exercises in the boardroom or at the executive management level to test how their organizations would respond in times of a cyber crisis. they could disseminate informed and proactive messages about organizational resilience.leaders do not need to be experts in cybersecurity, but they do need to ask how security ts into their organizations. can security be managed? what risks are being taken? can security be outsourced to another organization? these kinds of benchmarking questions are being asked by leaders and in boardrooms today, which is a sign of progress.stronger leadership could also provide organizations with greater ˚exibility. business executives, for example, might argue that they succeed in part by taking and accepting risk and that accepting some cybersecurity risk, rather than focusing on comprehensive cybersecurity protection, is the best approach. such an approach provides further incentive for shifting focus from compliance to risk management, a direction already outlined in the u.s. national institute of standards and technology (nist) framework for critical national infrastructure cybersecurity programs. in this way, the need for security could become more widely accepted by leaders even though they may not understand all the technical details and even though the riskbased approach also has problems.while some government agencies respond to ongoing assessments of risk itself, they tend more often to be driven by compliance. but compliancebased measures tend to look to the past, not to future threats, and they can lead to a ﬁboxtickingﬂ approach to security. again, leadership within government and its agencies can encourage thinking in terms of risk and resilience.˛˛˛˛˛˛cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.cybersecurity dilemmas32preparing for an uncertain futurecybersecurity is a highstakes issue that will continue to grow in importance. what happens with it will affect many aspects of public and private life, so cybersecurity policies need to be considered carefully. at the same time, cyberspace continues to change very rapidly, creating new opportunities for malevolent actors to disrupt the system. it can be hard to change a system that always has to be on and is used by most of the population almost continually, especially with limited funds and time.the fundamental importance of the internet to modern life points to the need for a continuing multistakeholder governance model with open standards. the problems people have are different and require different solutions, which calls for a multifaceted approach. many entities have interests in these decisions, which requires not only that they have a voice in them but that people have a common understanding of cyberspace. this can be difcult, since different perspectives need to be combined to see the larger whole. also, since many parties will be involved in improving security, the technical infrastructure will need to accommodate a wide range of inputs into the decisions about what is going to be allowed.innovative ways of thinking about the problemšfor example, a complex systems approach, or biological metaphors for predatorœprey relationships, or evolutionary perspectives on privacy policies over timešmay bring progress. technological developments, too, can yield major progress. for example, moving the operations of a government agency or of a business to the cloud could raise cybersecurity concerns, but such a move could also enable the upgrading and rethinking of an entire network.in both the public and the private sectors, some groups are farther ahead than others in providing cybersecurity. all groups can benet from becoming more resilient, which can put one in mind of some other relevant ﬁrwordsﬂ: respond, retaliate, restore, repair, reconstitute, reroute, reboot, write out, and recover. groups are now better at recognizing incidents, but many still have not implemented the cycles of improvement and change that can steadily improve strategies, capabilities, and resources. all organizations would benet from acknowledging that they are vulnerable to cyberattack and cybersecurity failures and that they have issues that need to be addressed.the challenges that will arise in the future are difcult to anticipate, since most of the important applications of the future almost certainly have not yet been invented. even a decade ago, important features of the world that exists today could not have been anticipated, and the pace of innovation shows no signs of slowing down. cybersecurity is a problem that cannot be xed quickly or easily. rather, many partial solutions and potentials paths forward exist and will need to be implemented, which will require collaboration, collective action, andšmost of allšdetermination.cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.for further readingfor more detailed discussion of many of the topics addressed in this document, see the following national research council reports, published by the national academies press, washington, d.c. (before 2002, national academy press):at the nexus of cybersecurity and public policy: some basic concepts and issues, 2014protecting individual privacy in the struggle against terrorists: a framework for program  assessment, 2008engaging privacy and information technology in a digital age, 2007toward a safer and more secure cyberspace, 2007trust in cyberspace, 1999cryptography™s role in securing the information society, 1996computers at risk: safe computing in the information age, 1991 cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientific forumcopyright national academy of sciences. all rights reserved.