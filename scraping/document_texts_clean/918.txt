detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/918methods for designing software to fit human needs andcapabilities: proceedings of the workshop on software humanfactors50 pages | 5 x 8 | paperbackisbn 9780309077811 | doi 10.17226/918committee on human factors, national research councilmethods for designing software to fit human needs and capabilities: proceedings of the workshop on software...copyright national academy of sciences. all rights reserved.methods for designingsoftware to fit humanneeds and capabilitiesproceedings of the workshop on software humanfactorsnancy s.anderson and judith reitman olson, editorscommittee on human factorscommission on behavioral and social sciences and educationnational research councilnational academy presswashington, d.c. 1985iabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.notice: the project that is the subject of this report was approved by thegoverning board of the national research council, whose members are drawnfrom the councils of the national academy of sciences, the national academyof engineering, and the institute of medicine. the members of the committeeresponsible for the report were chosen for their special competences and withregard for appropriate balance.this report has been reviewed by a group other than the authors accordingto procedures approved by a report review committee consisting of membersof the national academy of sciences, the national academy of engineering,and the institute of medicine.the national research council was established by the national academyof sciences in 1916 to associate the broad community of science andtechnology with the academy's purposes of furthering knowledge and ofadvising the federal government. the council operates in accordance withgeneral policies determined by the academy under the authority of itscongressional charter of 1863, which establishes the academy as a private,nonprofit, selfgoverning membership corporation. the council has become theprincipal operating agency of both the national academy of sciences and thenational academy of engineering in the conduct of their services to thegovernment, the public, and the scientific and engineering communities. it isadministered jointly by both academies and the institute of medicine. thenational academy of engineering and the institute of medicine wereestablished in 1964 and 1970, respectively, under the charter of the nationalacademy of sciences.the committee on human factors in the commission on behavioral andsocial sciences and education is sponsored jointly by the air force office ofscientific research, the army research institute for the behavioral and socialsciences, the office of naval research, the national aeronautics and spaceadministration, and the national science foundation.this work relates to department of the navy grant no. n0001485g0093 issued by the office of naval research under contract authority nr196167. however, the content does not necessarily reflect the position or thepolicy of the government, and no official endorsement should be inferred.the united states government has at least a royaltyfree, nonexclusive andirrevocable license throughout the world for government purposes to publish,translate, reproduce, deliver, perform, dispose of, and to authorize others so todo, all or any portion of this work.available from: committee on human factors, national researchcouncil, 2101 constitution avenue, n.w., washington, d.c., 20418.iiabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.workshop on software human factorsnancy s.anderson (chair), department of psychology, university ofmarylandelizabeth k.bailey, software metrics, inc., falls church, va.stuart l.card, xerox palo alto research center, palo alto, calif.john m.carroll, watson research center, ibm corporation, yorktownheights, n.y.alphonse chapanis, industrial and human factors consulting services,baltimore, md.h.rex hartson, department of computer science, virginia polytechnicinstitute and state universitydavid r.lenorovitz, computer technology associates, inc, englewood,colo.marilyn m.mantei, graduate school of business administration,university of michiganjudith reitman olson, graduate school of business administration,university of michiganrichard w.pew, bolt beranek and newman laboratories, inc., cambridge,mass.phyllis reisner, ibm research, san jose, calif.janet walker, symbolics, inc., cambridge, mass.john a.whiteside, digital equipment corporation, maynard, mass.robert c.williges, department of industrial engineering and operationsresearch, virginia polytechnic institute and state universityiiiabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.ivabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.committee on human factorsthomas b.sheridan (chair), mechanical engineering and appliedpsychology, massachusetts institute of technologynancy s.anderson, department of psychology, university of marylandalphonse chapanis, industrial and human factors consulting services,baltimore, md.jerome elkind, systems development, xerox corporation, palo alto, calif.baruch fischhoff, decision research (a branch of perceptronics, inc.),eugene, ore.oscar grusky, department of sociology, university of california, losangelesrobert m.guion, department of psychology, bowling green stateuniversityjulian hochberg, department of psychology, columbia universityk.h.eberhard kroemer, ergonomics laboratory, virginia polytechnicinstitute and state universitythomas k.landauer, bell communications research, morristown, n.j.judith reitman olson, graduate school of business administration,university of michiganrichard m.pew, bolt beranek and newman laboratories, inc., cambridge,mass.stover h.snook, ergonomics laboratory, liberty mutual researchcenter, hopkinton, mass.robert c.williges, department of industrial engineering and operationsresearch, virginia polytechnic institute and state universitystanley deutsch, study directoranne m.sprague, administrative secretaryvabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.viabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.contents foreword ix preface xi introduction 1 the need for new methods 2 the product development cycle 3 human factors methods in research and productdesign 4 analysis: gathering ideas 4 design: the initial design 6 formal analysis of the initial design 10 building a prototype 11 prototype testing with users 12 redesign 16 implementation: monitoring continued performance 16 other methods 18 advances and successes 21 future methods 22 conclusion 25 references 26contentsviiabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.contentsviiiabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.forewordthe committee on human factors was established in october 1980 by thecommission on behavioral and social sciences and education of the nationalresearch council. it is sponsored by the office of naval research, the airforce office of scientific research, the army research institute for thebehavioral and social sciences, the national aeronautics and spaceadministration, and the national science foundation. the principal objectivesof the committee are to provide new perspectives on theoretical andmethodological issues, identify basic research needed to expand and strengthenthe scientific basis of human factors, and to attract scientists both inside andoutside the field to perform needed research. the goal of the committee is toprovide the solid foundation of research as a base on which effective humanfactors practices can build.human factors issues arise in every domain in which humans interact withthe products of a technological society. in order for the committee to perform itsrole effectively, it draws on experts from a wide range of scientific andengineering disciplines. the committee includes specialists in the fields ofpsychology, engineering, biomechanics, cognitive sciences, machineintelligence, computer sciences, sociology, and human factors engineering.other disciplines participate in the working groups, workshops, and symposiaorganized by the committee. each of these disciplines contributes to the basicdata, theory, and methods required to improve the scientific basis of humanfactors.forewordixabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.forewordxabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.prefacecomputers are pervasive in civilian and military equipment systems. thecompatibility of computerbased devices and human users is predominantlydependent on the characteristics of the software. the term software humanfactors refers to the process of designing software to be effective for human use,i.e., easy to learn and use, productive, and efficient. however, no specificefforts have been made to operationally define the objectives of software humanfactorsša necessary step both to focus research goals and to provide aframework for development of general application principles.while a large amount of research has been performed on software featuresrelated to ease of use or user compatibility, most of these studies have beenlimited to a few features investigated in a specific context. consequently,results from different studies cannot be integrated, and it is hard to drawconclusions that can be generalized to other situations. overriding problems inthe development of principles of software human factors are the lack ofknowledge of how research on software human factors should be conducted anda paucity of techniques for measuring performance. for example, little is knownabout how to collect user data on ﬁease of learning,ﬂ how to define errors, howto record complex responsetime metrics, and how to measure user satisfaction.researchers interested in the development of principles for the design ofusercompatible software have great need for guidance in both researchmethods and performance measurement techniques. as an initial effort to fulfillthis need, the committee conducted a twoday workshop to bring togetherhighly qualified researchers with knowledgeprefacexiabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.about how to design software to be usable based on studies in diverse fields.the workshop on software human factors was convened in june 1983 inwashington, d.c. the impetus for the workshop grew directly from the reviewof the state of research and practice in humancomputer interaction in thecommittee's 1983 report, research needs for human factors. the workshophad three goals:š to identify current methods used to design and evaluate humanfactors aspects of software, including overall design and methods forcollecting data on user performance;š to ascertain what we know from software research results that wedid not know 10 years ago; andš to identify new research methods that are needed, both to developdesign principles for software and to discover how users understandsoftware systems.a group of 14 nationally recognized, active researchers in the field ofhumancomputer interaction from both industry and academia were invited toparticipate in the workshop. these workshop members represented a variety ofpertinent disciplines, including human factors, cognitive psychology, computerscience, experimental psychology, social psychology, and businessadministration. the relevant bodies of knowledge represented by theparticipants include experimental design and data analysis, human performancemeasurement, software design, information processing, learning, and attitudeassessment. prior to the workshop, participants prepared short, informalposition papers on the issues for distribution. to accomplish the goal ofcollecting the desired knowledge about the design of software, the group spenttwo days listing both design and evaluation methods currently in use for theproduct development of good software and relevant research methods forunderstanding basic issues in usersoftware interaction; describing each methodand constructing a list of references in which these methods are used;categorizing methods according to their uses in various stages of softwareproduct development or in more basic research; and suggesting new methodsand techniques, designating their possible uses, and indicating which appear tohave high nearterm payoff.the technical aspects of the workshop were organized by committeemembers nancy s.anderson and alphonse chapanis. the meeting was chairedby nancy anderson.prefacexiiabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.the report that follows, edited by nancy anderson and judith reitman olson,is based on discussions from the workshop and written materials and referencescontributed by the participants during and subsequent to the workshop. specialappreciation is extended to robert t.hennessy and m.jeanne richards,formerly of the committee staff, for their contributions in making the sessionsproductive and pleasant; to stanley deutsch, study director of the committee,for his contributions to the organization and preparation of the report; tochristine mcshane, of the commission staff, for editorial support; and to annesprague, administrative secretary, for secretarial and administrative support.they all helped to usher this report to publication.nancy s.anderson, chairworkshop on software human factorsprefacexiiiabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.prefacexivabout this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.introductionat present, software for specific applications and usercomputer interfacesare aggressively developed in industry, but they are designed largely with onlythe designer's intuition as guide and often without empirical testing with endusers. two observations made in a popular software magazine point out theresulting problem:the computer systems and software we have today are too damn complicatedfor the end user. there is too much to learn, too many fiddly details, too muchjargon, too much said that shouldn't be and not enough said that should be–(a. johnsonlaird, software news, april 1982).data processing still has one ongoing problem to solve: the end user'sdissatisfaction with today's systems. the entire industry has been grapplingwith this problem of ergonomics, or the interface between human and machine.in the case of data processing, ergonomics involves the development of ﬁuserfriendlyﬂ systems which can be operated by the user at the terminal and whichgenerate results that the user can understand and utilize (m.parks, softwarenews, february 1983).because of such difficulties, some industry and academic research groupsare developing an interest in gathering and building appropriate guidelines frombasic research and incorporating these guidelines and observations of users'behavior into the design process. a new field has emerged called softwarepsychology or the psychology of humancomputer interaction. it is in a veryexciting stateša relatively new amalgam ofintroduction1about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.experimental/cognitive psychology, computer science, business, and engineering.the field is growing in a variety of sectors. there are more human factorsgroups in industry than ever before. approximately 50 universities in thiscountry and abroad have phd programs in humancomputer interaction, whichare housed in psychology, computer science, social sciences, engineering,business, and english departments (mantei and smelcer, 1984). many moreschools offer one or more courses in the area. the association for computingmachinery has a special interest group for computerhuman interaction(sigchi). the human factors society has a group called the computersystems technical group, which is concerned with human factors aspects ofinteractive computing systems, the data processing environment, and softwaredevelopment. consumer demand for computers is increasing at a rapid pace,and many schools are acquiring computers for tutoring and the wordprocessingand mathematical tools that they provide. the systems that sell are those thatprovide the right usability and functionalityšthat provide the right design forthe end user.the need for new methodsdesigning systems to fit the end user is a difficult process. the field issearching for new methods. classical experimental designs (e.g., controlledfactorial designs) may not be appropriate for industrial settings in which costeffectiveness and timeliness are major concerns. however, tests of single,intuitiondriven designs with users, measuring their performance andsatisfaction, do not advance our general knowledge about designs and do notindicate why certain features are good or bad.there are, however, hybrid methods being used in industry, and new, morecomplex laboratory tests being constructed to assess users' performance in andunderstanding of complex systems. these methods are described below, alongwith their advantages and disadvantages and where they fit into the productdevelopment cycle. each method is annotated with references to a few keyarticles that report its use.introduction2about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.the product development cyclesoftware products are typically developed in three general stages:1. analysisšthe product's functionality and initial hardware/softwareconstraints are determined, analysis is made of the product'sprojected costs and benefits, and a development schedule isprojected.2. designšthe product is designed, first at the level of functionalspecifications and later in complete detail, then coded and tested,ending with a running system.3. implementationšthe product is distributed and installed in its finallocations, and users are trained and then operate the equipment.at all three stages human factors considerations appear:1. in assessing users' needs and capabilities during the analysis phase;2. in designing and redesigning the system with human factorsprinciples of usability, and in testing prototypes with end usersduring the design stage; and3. in monitoring use of the system after its implementation, gatheringinformation for redesign to correct errors or to add new, usefulfeatures.in what follows the methods appropriate to each of these stages aredescribed. these methods, or their variants, are useful for both laboratoryresearch and industry. they may be used in the slower, more controlledenvironment of the laboratory, where research is designed to study people'sperformance on complex tasks. and they contribute equally to design andevaluation in industry, where timeliness is frequently considered to be moreimportant than the ability to generalize from the results.introduction3about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.human factors methods inresearch and product designanalysis: gathering ideasthe ideas behind products typically arise from three major sources: fromthe redesign of an existing product, from an identified need in the marketplace,and from a new technological capability that provides a useful new function tousers. information about the success of existing products can be obtained eitherby asking their users for their opinions and uses of the systems or by gatheringunobtrusive data about their use. information about a new product can comefrom reports of needs from potential users.reports from usersquestionnaires and interviews are the most common methods forgathering information about the success of a product or the needs for newfunctions or a new product. both questionnaires and interviews are goodmethods for eliciting information about how a person goes about his or herwork, what aids or tools he or she uses or desires, what kind of knowledge ortraining is required to do the work, what difficulties he or she reports about thework, where the work originates and where it goes, what interactions arenecessary with other people to do the work, and how the user thinks the workprocess could be improved. questionnaires are more rigid in format thaninterviews, since interviews can go where the interviewee leads, oftenuncovering unanticipated new information. the principal disadvantage ofinterviews, however, is that they are timeconsuming; only one person can beinterrogated at a time. by aggregating information fromhuman factors methods in research and product design4about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.a number of interviewees or questionnaires, one can construct a general pictureof users' needs and construct some tentative system concepts for helping theusers do their work (kelley and chapanis, 1982; rosson, 1983).diaries provide a similar form of informal data gathering and are used touncover the needs and capabilities of the potential users of a new product. dataabout work can be gathered in detail over a long period of time, especiallyabout how much time particular kinds of activities take and their sequentialdependencies. because a shorter time elapses between the occurrence of anevent and its report, diaries give a more accurate record of actual activity thanretrospective reports in questionnaires and interviews (mantei and haskell,1983).a common marketing technique for gathering information about existingor potential users' needs is the focus group. instead of interviewing a single userat a time, groups of users who are either similarly trained or who share commongoals are first told about some potential capabilities of a system, then asked todiscuss how they might find uses for these capabilities. occasionally activebrainstorming from these sessions generates very good ideas. the same kind ofmethod is used to collect opinions about an existing product and to ask forsuggestions for improvements. often designers will gather expert users of asystem and ask their opinion about how to improve the system or how to designa new, computerbased tool for aiding their work (alawar et al., 1981). theadvantage of such methods is that the participants stimulate each others'thoughts, uncovering ideas or suggestions they may not have thought ofindividually. that is also its disadvantage: a participant's true opinions can beswayed by group pressure.inferring needs from natural observationone of the main drawbacks of the methods listed above is that they rely onusers' perceptions of their needs and capabilities. sometimes new products meetneeds unforeseen by their users; sometimes users, either consciously orunconsciously, distort their daily work activities and feelings about existingworking conditions. in such cases, it may be better to collect information, notby asking users, but by watching their behavior and inferring their needs andcapabilities from their activities.human factors methods in research and product design5about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.two methods are often used to collect information about users' behavior innatural work settings. in the case of activity analysis, an observer watches andrecords certain behaviors of the workers. the data may be collected by directobservation or by analyzing video or film recordings. individual samples ofcategorized activities are aggregated into activity frequency tables, graphs, orstate transition diagrams. such performance analyses are particularly useful inassessing the changes made in work by comparing activity before and after anew system or design change is implemented (hartley et al., 1977; hoecker andpew, 1980).logging and metering techniques involve observations of what a user doeswith a system, but the measurement is embedded directly into the software.these procedures can include a simple record with a timestamp of everyinteraction that a user makes with the computer, or it can involve a completehard copy representation of a sequence of particular display frames. powerfullogging and metering software can also categorize certain recognizable eventsand summarize their times. for example, one could summarize such events astime to complete a task, user and/or system response time, and frequencies andtypes of errors.logging and metering procedures are typically embedded in theoperational software. where there are limits to the access to such software, onecan connect a second computer in tandem to the first and direct data about theuser's activities to it, in essence providing a ﬁpassive tap.ﬂ in this way, loggingdoes not interfere with system response times, and information about the userinputs and the system responses can be recorded in detail for future use (seewhiteside et al., 1982; goodwin, 1982).design: the initial designdesigners go through two stages in constructing an initial design, eitherimplicitly, driven by intuition or experience, or explicitly, using some or all ofthe detailed tools described below. first, the designers decide what the user isgoing to do, conducting an informal or formal task analysis. second, theyspecify what the interface will look like and what the dialog will consist of.there are a variety of methods that apply to this stage, where designers useinformal orhuman factors methods in research and product design6about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.formal guidelines, consult end users, or have some theorybased judgments todraw on.determining what the user needs to dothe most common form of analyzing the user's activities is called a taskanalysis. task analysis is the process of analyzing the functional requirementsof a system to ascertain and describe the tasks that people perform. it focusesboth on how the system fits within the global task the user is trying to perform(e.g., prepare a report of a projected budget) and what the user has to do to usethe system (e.g., access the application program, access the data files, etc.).task analysis has two major aspects: the first specifies and describes thetasks, and the second, and more important, analyzes the specified tasks todetermine such system or environmental characteristics as the number of peopleneeded, the skills and knowledge they should have, and the training necessary.the first step involves decomposition of tasks into their constitutent subtasksand annotating each subtask for its essential elements and theirinterdependencies. the second step involves examination of the actual tasks andinterdependencies, assessing how difficult each is, what knowledge is required,where the information resides, etc. results of task analyses are used not only inwriting functional specifications for a particular application, but also forassigning work to groups of workers, arranging equipment in an efficientconfiguration, determining task demands on people, and developing operatingprocedures and training manuals (see bullen and bennett, 1983; bullen et al.,1982).specifying the initial designan initial system or interface design is constructed next. with the globaltasks the user has to perform specified as above, the designer groups thesubtasks according to logical function from the perspective of the user buttempered by system/hardware constraints. then the actual interface or systemdetails come from three sources: design guidelines or principles, intuitions ofthe designer sometimes aided by intuitions of the users themselves, and theorybased judgments.human factors methods in research and product design7about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.in generating an initial design, the designer can address existing designguidelines for general prescriptions of how to specify particular components ofthe interface. for example, if the interface has a menu, the guideline mayprescribe that the alternatives should be listed by order of frequency of use orcluster them according to functional similarity, rather than displayedalphabetically or randomly. current design guidelines (e.g., woodson andconover, 1966; van cott and kinkade, 1972) include prescriptions about suchtopics as the readability of type fonts, the brightness levels of display screens,keyboards designed to fit hand shape and function, and rules for makingabbreviations and symbols (see also schneiderman, 1982; smith, 1982).current guidelines, however, are more concerned with perceptual andperformance characteristics than with the cognitive properties of the interaction.thus, they would prescribe appropriate type fonts, but not what words thesefonts should express to the user to suggest the appropriate analogy forperforming the task on the system. there are several major caveats in the use ofdesign guidelines: the prescriptions or recommendations contained may havebeen derived from situations or research not applicable to the system beingdesigned; new or unaccounted for variables may interact in unanticipated ways;and current guidelines do not always publish the source of the recommendation,whether it was generated by a controlled laboratory study or derived from thecollected wisdom of experience. guidelines have to be applied with care.though design guidelines have their flaws, they are very useful in placinga particular new design in a setting of conventional wisdom. often the designer,skilled in interacting with systems and cognizant of the end tasks that are beingsupported in this design, cannot foresee the difficulties the new user will havewith the system. design guidelines provide suggestions to the designer that willin many cases be better than those based solely on intuition. (for a recentversion of guidelines, see smith, 1984.)the skills and knowledge of users themselves can be used to advantage byincorporating users in the design team. users can provide some critical insightsabout how they think of the task and thus the system (e.g., what kinds ofinformation should be accessible when, what the screens should look like tomimic the original, a noncomputer version of the task, what commands ought tohuman factors methods in research and product design8about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.be called). they know the procedures and terminology and, with propersupport, can contribute to the design and layout of forms and menus as well asact as critics of the design. gould and lewis (1985) and miller and pew (1981)provide examples of the involvement of users in the design process. other waysin which the sophisticated user can be involved in the design of softwaresystems can be found below in the section on prototype testing with users.a third source of information about the original design specification ispsychological theories. theorybased judgments can constrain aspects of adesign or suggest promising areas of investigation. for example, theories ofcolor contrast can provide insight into the appropriateness of certaincombinations used in screen highlighting or predict the readability of a newmonochrome display color. because fitt's law accounted for movement timefor placing a cursor in a desired position with a mouse and for placing theappropriate finger on a desired key location, two conclusions follow: theinvention of faster pointing devices was unlikely to increase performance andthe design of keyboards with larger peripheral key caps would increase theaccuracy of keying (card et al., 1978; card et al., 1980b).part of the difficulty in constructing a design and analyzing its usabilityhas to do with how the interface is specified. verbal descriptions of how asystem works are particularly unsuited for conveying the flow of an interactionand the choices the user has at each point. several specification languages orformats have been explored recently not only to serve as a way of conveying tothose who actually build or code the system what it will do but also as a way ofconcretely specifying the system to analyze its usability.one way to specify the interaction is to use an interactive tool kit called ahumancomputer dialog management system. this system guides the definitionof the interaction language that describes the actions of the user and the systemand the screen formats displayed at each moment. hartson et al. (1984), jacob(1983), and wasserman (1982) provide good examples of this kind of interfacedefinition.* a second format for displaying*this is also a system that allows rapid embodiment of the functioning of a new,developing system and thus is a tool for rapid prototyping.human factors methods in research and product design9about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.what the system does at each state is a state transition diagram, recently used asa description of a system's workings in kieras and polson (1983).design: formal analysis of the initial designonce an initial design is specified, even if it is a partial design, it can besubjected to several kinds of scrutiny. the goal in this analysis stage is to makethe initial design as good as possible before it is made into the prototype foruser testing. three methods aid in this process: structured walkthroughs,decomposition, and tasktheoretic analytic models.structured walkthroughs involve construction of tasks that a user carriesout on a simulated system. the user tries out the system by going through thetask, step by step, screen by screen, command by command. this can be donewith the design as specified in a number of different formats, using anexperimental simulation of a prototype or even with the experimenterpresenting paper and pencil figures of the screens, menus, and commands in theappropriate sequence. the technique helps to identify confusing, unclear, orincomplete instructions, illogical or inefficient operations, unnatural or difficultprocedures, and procedural steps that may have been overlooked because theywere implicitly rather than explicitly defined. gould et al. (1983), ramsey(1974), ramsey et al. (1979), and weinberg and friedman (1984) provideexamples of the use of structured walkthroughs.a second kind of formal analysis, called decomposition, is proposed inreitman et al. (1985). in this analysis, the major components of the design areseparated and analyzed for their impact on cognition. the picture displayed onthe screen, for example, is assessed for how it helps or hinders the user's abilityto perceive meaningful relationships or the system model. the commands areassessed for their load on longterm memory, how easy they are to remember,and how confusable they are among each other. for each component, a seconddesign alternative is constructed to fit within the general guidelines of usability.then, through discussion and debate, the design team decides which alternativeof each component is the better design. this method encourages careful scrutinyof the proposed design and often encourages designers to specify betterinterfaces before the first prototype is built.human factors methods in research and product design10about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.the third kind of formal techniques invoke tasktheoretic analytic models.these models provide representations and analyses that assess, for example,which parts of a metaphor aid performance and which do not (douglas andmoran, 1983) and how big the user's shortterm memory load is at each step ofthe interaction (kieras and polson, 1985). prime examples of these techniquesinclude metaphor analysis (carroll and thomas, 1982; carroll and mack,1982), assessment of mental models (dekleer and brown, 1983; dekleer andbrown, in press; and others in gentner and stevens, 1983), development ofproduction rule systems that represent the user's knowledge of the task (kierasand polson, 1985), object/ action analysis (called ﬁexternal/internal taskmappingﬂ by moran, 1983), the goms model (card et al., 1980b; 1983), andformal grammar notation systems (reisner, 1981a, 1984; blesser and foley,1982).these task analytic models are very useful tools. however, none of themyet encompasses all of the cognitive aspects of the interaction; each focuses onone or more important aspects. these methods require training to use and oftentake a long time. however, they all have the advantage of being based on soundtheories of human behavior and can provide important analysis of usabilitybefore any coding of software or running of subjects is contemplated. there is atradeoff, then, between time spent in analysis and time spent testing users inthe laboratory or the field. the hope embodied in this approach is that as thescience of userinterface design grows, analytic tools will improve to the pointof making the actual user testing of designed systems merely a last, short checkof a good, finished design.design: building a prototypethree methods provide simulations or quick versions of significant aspectsof a new system so it can be tried by actual users. the methods are calledfacading, the wizard of oz technique, and rapid prototyping.facading is the technique of quickly and inexpensively building asimulation of the external appearance (i.e., the ﬁfacadeﬂ) of a system's interface.its advantages are that it is quick and relatively easy; the target system'sunderlying complexity and/or final computational capability is ﬁfinessed.ﬂ tobe maximally beneficial, the facade must embody some level of the functionalhuman factors methods in research and product design11about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.capability of the final target system. it does not just generate a series of staticsnapshots of the system but rather includes the control structure, flow, orconnectivity of the final system. hanau and lenorovitz (1980) and lenorovitzand ramsey (1977) provide good examples of the use of this technique,a variant of the facading technique is the wizard of oz technique. insteadof having the computer embody the simulated system, hidden human operatorsintercept user commands and provide output back to the user. often thetechnique is used to test a new interface language: the hidden human operatorintercepts the new commands, translates them into the real system commands,and, after receiving output from the real computer system, retranslates themback to the tested enduser (see gould et al., 1983; gould and boies, 1978;ford, 1981; kelley, 1983; wixon et al., 1983).rapid or fast prototyping are terms applied to the more formalizedbuilding of a prototype in a hurry. the speed of building a running systemdepends mainly on the underlying supporting software, which makes thespecific prototype programmable from existing modules. ideally, the prototypeprogramming language separates elements of the dialog from the actualimplementation software. for example, the designer can specify the placementof the command input line or the menu choices variously without having toprogram new modules to execute these different input formats. one of these, theﬁdialog management system,ﬂ is under development by hartson and hiscolleagues (hartson et al., 1984; yunten and hartson, 1984); another system isdescribed in wasserman (1982) and wasserman and shewmake (1982).another project that uses rapid prototyping methods is reported in hayes et al.(1981).design: prototype testing with userswhen a prototype of some form has been built, actual users are thenbrought in to use the system and report their opinions about it. these tests canvary greatly in how well controlled their designs are and how representative theset of tested users are of the final population of users. moreover, users are askedto perform several kinds of tasks, some testing the normal, frequent tasks thatregular users will be expected to perform, others testing those subtasks thoughtto be especially difficulthuman factors methods in research and product design12about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.either for the system (e.g., those producing long system response times) or forthe user (e.g., the longest sequence of commands for a particular type of task).prototype tests differ in what kinds of data are taken from the userštimes anderrors, thinking aloud protocols, or attitudes.experimental designsfield tests to evaluate systems are fashioned after laboratory tests commonin the academic field of experimental psychology. in general, they require thecomparison of at least two systems, systems that differ in only one componentor variable. measures are designed to reflect the performance attributable to theeffects of that variable, and subjects are chosen to be representative of thepopulation of end users. of particular importance are various techniques forcontrolling irrelevant variables. for example, one must ensure that measures ofintelligence of the test subjects do not differ across both conditions, affectingthe results in addition to the effects of the independent variables.often the rules of good experimental design are violated in the interest ofproceeding quickly. subjects who are different from the end users but moreavailable may be tested; comparisons may be made between two systems thatdiffer on more them one variable; measures may be taken that are less sensitivethan those that will directly test why performance on one system is better orworse than another; occasionally only one system is tested and performance onit is measured against some predetermined standard (e.g., a 10minute rule fortime to learn a system). the closer the test is to good experimental design, themore quickly the findings can advance knowledge about the important aspectsof good humancomputer interface. however, as is often the case indevelopment, the goal is not ultimate knowledge but rather global assessment ofthe adequacy of a particular interface or system. a compromise designprocedure is described in reitman et al. (1984). the use of experimental designis found in ledgard et al. (1981), reisner et al. (1975), reisner (1977, 1981b),and williges and williges (1982).one variant from controlled experimental evaluation that has been founduseful in the development of interfaces is called quasiexperimental design. thesehuman factors methods in research and product design13about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.designs involve capturing data at several time intervals, typically of durationsmeasured in weeks or months. sometime during the data capturing intervals, achange or a modification of a system is introduced; the data being captured areexpected to reflect the impact of this change. some of these quasiexperimentaldesigns allow for comparisons with a control group. these designs are hard tocontrol, since the investigator must typically take existing groups of users,giving one the change and the other no change. inherent differences in existinggroups is a major worry in evaluating the results. a complete description of thistechnique can be found in cook and campbell (1979); koltum (1982) and rice(1982) provide good examples of this method.selection of tasks to performthere are two reasons one has users try out a prototype system: to identifypoints of difficulty for the user so that those points can be redesigned and tomeasure standard use of the system, so that later changes in hardware can beassessed or so those concerned with the staffing of a large operation of userscan determine how many people will be needed. for the first purpose, tasks areselected that stress the system and the user, generally called critical incidents.for the second purpose, tasks are selected to estimate basic characteristics ofthe system's use, called benchmark tests.in terms of critical incidents, the goal is to set up situations or tasks thathave been shown historically to tax the user and/or the system and aresufficiently important that they can make the difference between success orfailure on task or system performance. one might, for example, require the userto access items distant from what is being presented on the current screen or toperform a long command sequence, to determine the loads of this part of thedesign on the user's ability to imagine the stored information's underlyingstructure or the mnemonic characteristics and grammatical rules implied by thecommand sequences. the goal is to set up situations in which the data will tellthe designers something about the limits of human or system performance.these tasks are illustrated in the work of alawar et al. (1981), kelley andchapanis (1982), and flanagan (1954).human factors methods in research and product design14about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.in benchmark tests, the goals are quite different. the designer wants tomeasure the likely performance times and errors expected in normal use. thetasks are not designed to tax the system or the user, but rather to berepresentative of the kinds of frequent tasks the system will normally support.typically, tasks are constructed to measure the expected amount of time it takesa new user to learn a system, the amount of time it takes the user to perform aset of predefined tasks, and the amount of time it takes the system to respond toa user's request. a good study that illustrates the use of this method is that of theevaluation of eight text editors by roberts and moran (1983). a study ofdatabase interfaces using benchmarks was done by mantei and cattell (1982).kinds of data collectedthere are four major kinds of data collected in tests of systems: the time ittakes to perform a task, the frequency and kinds of errors, the goals andintentions of the users, and the attitude of the user.the amount of time a task takes (either how long an entire task takes orhow long each successive keystroke takes) reflects the time it takes the user toperceive inputs, categorize and plan appropriate actions, and execute properresponses. error frequencies and types reflect the difficulties users have withthese processes and often point to the cause of the error (whether the errorresponse is similar to one in a similar plan, was generated from confusion witha similar screen, has a label that sounds the same as another, etc.) a simpleanalysis of users' times and errors is found in reisner et al. (1975) and reisner(1977). a comprehensive analysis of users' times is found in card et al. (1980b,1983). other uses of times and errors can be found in boies (1974), rosson(1984), sheppard and kruesi (1981), and thomas and gould (1975).a more thorough, complicated kind of data to collect during evaluationinvolves the user's thinking aloud while performing the task. typically the useris videoand soundrecorded while he or she is performing the tasks. therecording captures what is said and done, what is displayed on the screen, whatsections of the documentation are being examined, what parts of the taskinstructions the user is reviewing, etc. the mosthuman factors methods in research and product design15about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.complete protocols ask the subjects to verbalize their intentions, what theirgoals are, and what current plans they have about reaching their goals. otherbehavior is directly observable; thoughts and plans typically are not. thismethod has been used by mack et al. (1983), carroll and black (1982), andcard et al. (1980a) in their studies of skilled text editing. more completedescriptions of the technique and its advantages and disadvantages can be foundin lewis (1982), olson et al. (1984), and ericsson and simon (1980).a third kind of data collected in evaluation sessions is the users' opinionsabout the system's ease of use and functionality. a common instrument used toscale users' global attitudes about the system is the evaluation component ofosgood et al.'s (1957) semantic differential (see good, 1982, for an example ofits use). questionnaires and interviews also tap users' reactions to particularcomponents of the system. one problem with users' reports, however, is thatthey are typically distorted by their experience with other, similar systems. or auser may have difficulty separating components of the system such; forexample, a user who has a very difficult time using a system may report that heor she likes it a great deal, recognizing how much easier it is to perform the taskon a computer compared with previous manual methods.redesigntypically as the prototype of the original design is tested, errors are foundand revisions suggested. the methods appropriate to the initial design areappropriate also at the stage of redesign. this part of the design process iteratesthrough ﬁfixingﬂ and ﬁtestingﬂ until either an acceptable level of performance isreached or the deadline for developing the system is reached.implementation: monitoring continuedperformancejust as data were collected in the original conception and analysis phase ofproduct development, data are collected on the system as implemented. at thisstage, activity analyses, diaries, logging and metering, and questionnaires andinterviews are all appropriate methods for assessing whether the product asdesigned is performhuman factors methods in research and product design16about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.ing as predicted in the final environment. if problems are found in the field,either small corrections are made in the code (e.g., changing what a command iscalled is easy to change in the code but can have an enormous impact on theease of use), or a redesign is called for, sending the product design process backto prototype development or fully back to the top of the cycle.human factors methods in research and product design17about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.other methodsthree additional methods are worth mentioning, though they do not fitneatly into the scheme above. they include the dialog specification procedure,experimental programming, and case studies.the dialog specification method is a global procedure that cuts across thefirst several steps outlined above. it is a procedure that prescribes a method fordeveloping an interactive dialog with a system and sets a design standard. themethod includes task analysis and flow charting of user activities as well asstandard means of communicating the specific design requirements to theprogrammer. the design standard describes acceptable screen layouts,interactive devices and how they are to be used, acceptable command languagesyntax, etc., down to a level of detail compatible with the specificity of therange of applications to which it is intended to apply. for example, if all designsconcerned telephone management applications, the specification would dealonly with the range of tasks in this domain. these specifications are built fromhuman factors principles as well as accumulated data from user testing. pew etal. (1979) describe this method more fully.experimental programming is similarly a more global method fordesigning systems and interfaces. it is a more flowing, adaptive techniqueinvolving users, designers, and programmers (sometimes all in the sameperson). someone builds a prototype of a new system with some fraction of thefunctionality and some fraction of the user interface in place. this prototype isthen used by a variety of programmer/users who generate suggestions for newfeatures and suggestions for revisions for existing functions. as manysuggestions as possible are incorporated into the prototype; the good featuresother methods18about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.survive, poor features disappear. occasionally, when new features areincompatible with the old, a competing prototype is built. sometimes someonemerges the most popular ideas from both. this method is very informal. theonly rules for its application are that everyone's opinion get a fair hearing andthat anyone in the community can implement a change.this method allows for progressively better understanding of theapplication as well as the computation and interface requirements. its weaknesslies in its casual nature and that it relies on the opinion of users, most of whomare programmers; its strength lies in its exploratory, evolutionary, democraticnature. one wellknown product that benefited from experimental programmingis the emacs text editor (stallman, 1980), which pioneered such concepts asusercustomization, online documentation, and a particular command style. inaddition, teitelman (1972) used experimental programming to develop theconcept called dwim (ﬁdo what i meanﬂ), which included a set of facilitiesthat automatically corrected predictable errors.a third global technique goes under the rubric of case studies. case studiesinvolve observation and analysis of a singe user, group, or project. theinformation collected may range from informal, subjective impressions todetailed quantitative data. because case studies involve no comparison orcontrol group, they are not very useful in inferring causality. as a result they arenot appropriate for building a data base of basic research results from which toconstruct theories and principles. they can, however, be extremely useful forgaining insights when one is first investigating an area of interest and forproviding concrete demonstrations of the use of new methods and tools.an example of a case study in which new insights were gained about adomain involved the use of the ada system. the purpose of the study was tounderstand the problems that are likely to arise when the system is firstintroduced into an organization (bailey et al., 1982). a second case studyinvolved a demonstration of new methods for designing systems to beembedded in special purpose hardware, such as airplanes and tanks (britton etal., 1981). the documentation and related products produced by this case studyprovide examples that others may use in trying to apply the methods to theirown software projects. brooks (1975) documents the use of a case study in alarge computer programming project. and, theother methods19about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.case study by baker (1972) was extremely influential in leading the structuredprogramming revolution. others include gould and boies (1978, 1983, 1984),and heninger (1980).other methods20about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.advances and successesover the last 10 years, it has become clear that research on the issuessurrounding humancomputer interaction is worth doing. the design of thehumancomputer interface makes a marked difference in users' performance.software products exist that embody welldesigned interfaces derived fromhuman factors input: the xerox star, apple lisa, and macintosh workstations and the rolm and ibm mail systems are examples. in addition, majorchanges in the design of the telephone directory assistance system, as well asoriginal designs of telecommunication control devices, were a result of humanfactors studies.human factors research has also shown the usefulness of some importantgeneric display and control devices: the partitioning of screens into windows,icons for the control of operations and the display of objects, better helpmessages, and better defined response and function keys. in addition, more isknown about users' limitations and adaptability.human factors design is also influencing documentation and training forsoftware use (felker, 1980). because software is more available to a variety ofusers, there is an increased awareness by the public of the need to makesoftware easy to learn and use.advances and successes21about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.future methodsalthough we have catalogued a variety of methods to be used in thesoftware design and research process, some needs for information are stillunmet. the research needs fall roughly into three categories of needs: newtheories, new representations, and new data collection and analysis methods.theoriesthree particular kinds of theories are seen as needed. automation theorieswould tell us what should be automated and what should be assigned to thehuman processor. such theories would also prescribe an appropriate mix ofautomation and human control. some seeds of theories are suggested in thefield of supervisory control and in office analysis techniques, but a moreexplicit theory is needed to prescribe the best mix of human and computerprocessing.theories of individual differences would tell us about the different kinds ofcomputer support required and desired by different user populations. specialcontinuing interest focuses on the differences between naive or casual users andexpert or dedicated users.theories of standardization would tell us about which aspects of a systemshould be standardized for all users (as in the basic control devices in anautomobile) and which can be customized for adaptation by and for specificusers.in addition, two taxonomies are needed: a characterization of the kinds oftasks for which software can be built (so that design prescriptions can be tied,perhaps to particular classes of tasks) and a characterization onfuture methods22about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.the kinds of users that use software applications (related to the theories ofindividual differences described above). the partial taxonomy of humancomputer interface tasks advanced by lenorovitz et al. (1984) provides abaseline for this effort.representationmany of our analyses outside the testing of a working system with real endusers require some specification of what the system can do, what the userknows about how the system works, and how the user conceives of the task.there is thus a need for better representational schemes than those now beingused. one such scheme would describe a complex system so that documentationand training could be better designed. another would represent exactly how asystem worksšthe interface, dialog, communication, or transactionšso thatthe design could be both analyzed for its fit to users' needs and capabilities andconveyed to those who have to program it.we need techniques for inferring what a user currently understands of asystem, a method for extracting the appropriate information from the user andfor displaying the resulting understanding or ﬁmental model.ﬂ these techniquesare as useful in basic research on the performance of complex tasks as they arein the applied design process. (a report of the committee on human factors'workshop on mental models in the use of information systems is scheduled forpublication in 1985.)data collection, measures, and analysesalthough we have a rich variety of measures to collect from usersinteracting with a system, we have no direct measures of the user's affect nor dowe collect any of the neurophysiological responses that accompany intensework, frustration, and satisfaction. in addition, there is a need for betterhardware tools for collecting logging and metering information without slowingthe system that the user normally interacts with. more specific methods areneeded for analyzing the mountain of data that comes from protocol analysis,not only in deducing how the user is satisfying his or her task goals andsubgoals, but also in deducing ongoing memory and perceptual loads on theuser and how the user compensates for them in perfuture methods23about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.forming the task. our task analysis methods need to be expanded to includemore cognitive aspects of the user's performance, his or her memory, language,and perceptual aspects.research methods considered most likely to produce high payoff in thenear future include:š representations of the users' understanding of a system;š representations of a dialog to convey the design to programmers;š more comprehensive task analyses that include memory, perceptual,and language considerations as well as timing and error predictions;andš hardware advances that allow the collection of logging andmetering data for tapping the current use of a system.future methods24about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.conclusionthe field of software human factors is rising in its research needs fasterthan the scientific data base is growing. additional basic research is clearlyneeded. educational programs are now training future researchers andpractitioners in this field. data in laboratories and industry need to be collectedmore systematically and disseminated more widely. as a compendium ofcurrent methods, their descriptions and evaluations, and references to existingliterature that use these methods, this report should then help coalesce the fieldand move it toward fruitful work in the future.conclusion25about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.referencesalawar, j., chapanis, a., and ford, w.r. 1981 tutorials for the first time computer user. ieeetransactions in professional communication. pc24(1):30œ37.bailey, j., basili, v., gannon, j., katz, e., kruesi, e., sheppard, s., and zelkowitz, m. 1982monitoring an ada software development project. ada letters 2(julyœaugust):58œ61.baker, f.t. 1972 chief programmers team management of production programming. ibm systemsjournal 11:56œ73.blesser, t., and foley, j.d. 1982 towards specifying and evaluating the human factors of usercomputer interface. pp. 309œ314 in proceedings of the human factors of computingsystems. new york: association of computing machinery.boies, s.j. 1974 user behavior on an interactive computer system. ibm systems journal 13:2œ18.britton, k.h., parker, r.a., and parnas, d.l. 1981 a procedure for designing abstract interfaces fordevice interface modules. proceedings of the 5th international conference on softwareengineering. orlando, fla: ieee.brooks, f.p. 1975 the mythical man month: essays on software engineering. reading, mass.:addisonwesley.bullen, c.v., and bennett, j.l. 1983 office workstation use by administrative managers andprofessionals. ibm research report rj 3890.references26about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.bullen, c.v., bennett, j.l., and carlson, e.d. 1982 a case study in office workstation use. ibmsystems journal 21(3):351œ369.card, s.k., english, w.k., and burr, b.j. 1978 evaluation of mouse, ratecontrolled isometricjoystick, stop keys, and text keys for text selection on a crt. ergonomics 21:601œ631.card, s., moran, t., and newell, a. 1980a computer textediting: an information processinganalysis of a routine cognitive skill. cognitive psychology 12:32œ74.1980b the keystroke level model for user performance with interactive systems. communicationsof the acm 23:396œ410.1983 the psychology of human computer interaction. hillsdale, n.j.: lawrence erlbaum.carroll, j.m., and mack, r.l. 1982 metaphor, computing systems and active learning. ibmresearch report rc 9636.carroll, j.m., and thomas, j.c. 1982 metaphor and the cognitive representation of computingsystems. ieee transactions on systems, man, and cybernetics 12:107œ116.cook, t.d., and campbell, d.t. 1979 quasiexperimentation: design and analysis issues for fieldsettings. chicago: rand mcnally.dekleer, j., and brown, j.s. 1983 assumptions and ambiguities in mechanistic mental models. ind.gentner and a.s.stevens, eds., mental models. hillsdale, n.j.: lawrence erlbaum.in press a qualitative physics based on confluences. in b.moore and j.hobbs, eds., formal modelsof the commonsense world. norwood, n.h.: ablex.douglas, s.a., and moran, t.p. 1983 learning text editing semantics by analogy. chi83. pp. 207œ211 in proceedings of the conference on human factors in computing systems. newyork: association of computing machinery.ericsson, k.a., and simon, h.a. 1980 verbal reports as data. psychological review 3:215œ251.felker, d.c., ed. 1980 document design: a review of the relevant research. american institutefor research. technical report 75002œ4/80, washington, d.c.references27about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.flanagan, john c. 1954 critical incident technique. psychological bulletin 51:327œ358.ford, william r. 1981 natural language processing by computerša new approach. ph.d.dissertation. department of psychology, johns hopkins university.gentner, d., and stevens, a.l. eds. 1983 mental models. hillsdale, n.j.: lawrence erlbaum.good, m. 1982 an ease of use evaluation of an integrated document processing system. chi 82. pp.142œ147 in proceedings of human factors in computing systems. new york: associationof computing machinery.goodwin, n.c. 1982 effect of interface design on usability of message handling systems. pp. 69œ73in proceedings of the human factors society. 26th annual meeting, seattle, wash.gould, j.d., and boies, s.j. 1978 writing, dictating, and speaking letters. science 201:1145œ1147.1983 human factors challenges in creating a principal support systemšthe speech filing approach.acm transactions on office information systems l(4):273œ298.1984 speech filingšan office system for principals. ibm systems journal 23(1):65œ81.gould, j.d., and lewis, c. 1985 designing for usability of key principles and what designers think.communications of the acm 28:300œ311. new york: association of computingmachinery.gould, j.d., conti, john, and hovanyecz, todd 1983 composing letters with a simulated listeningtypewriter. communications of the acm 26:295œ308.hanau, p.r., and lenorovitz, d.r. 1980 a prototyping and simulation approach to interactivecomputer system design. pp. 23œ25 in proceedings of the 17th design automationconference, minneapolis, minn.references28about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.hartley, c., brecht, m., pagersy, p., weeks, g., chapanis, a., and hoecker, d. 1977 subjectiveestimates of work tasks by office workers. journal of occupational psychology 50:23œ36.hartson, h.r., johnson, d.h., and ehrich, r.w. 1984 a humancomputer dialogue managementsystem. pp. 57œ61 in proceedings of interact ‚84, london. amsterdam: elsevierscience publications.hayes, p., ball, e., and reddy, r. 1981 breaking the manmachine communication barrier.computer 14(3):19œ30.heninger, k.l. 1980 specifying software requirements for complex systems: new techniques andtheir application. ieee transactions on software engineering. se6(1):2œ13.hoecker, d.g., and pew, r.w. 1980 user input to the design and evaluation of computerassistedservice delivery. report #4358. cambridge, mass.: bolt beranek and newman inc.jacob, r.j.k. 1983 using formal specifications in the design of the humancomputer interface.communications of the association of computing machinery 26(4):259œ270.johnsonlaird, a. 1982 most software more complicated than needed. software news 2(4):47.kelley, j.f. 1983 natural language and computers: six empirical steps for writing an easytousecomputer application. ph.d. dissertation, department of psychology, johns hopkinsuniversity.kelley, j.f., and chapanis, a. 1982 how professional persons keep their calendars: implications forcomputerization. journal of occupational psychology 55:241œ256.kieras, d.e., and polson, p.a. 1983 a generalized transition network representation for interactivesystems. chi83. pp. 103œ106 in proceedings of the conference on humanfactors incomputing systems . new york: association of computing machinery.references29about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.1985 an approach to formal analysis of user complexity. international journal of manmachineinteraction, in press.koltum, p.l. 1982 evaluation of a teaching approach for introductory computer programming.ph.d. dissertation, department of computer sciences, university of north carolina.ledgard, h., singer, a., and whiteside, j.a. 1981 directions in human factors for interactivesystems. new york: springerverlag.lenorovitz, d.r., and ramsey, h.r. 1977 a dialogue simulation tool for use in design of interactivecomputer systems. pp. 95œ99 in proceedings of the human factors society annualmeeting. santa monica, calif: human factors society.lenorovitz, d.r., phillips, m.d., ardrey, r.s., and kloster, g.v. 1984 a taxonomic approach tocharacterizing humancomputer interfaces. in humancomputer interaction, g.salvendy,ed., proceedings of the first usajapan conference on humancomputer interaction.amsterdam: elsevier science publications.lewis, c. 1982 using the ﬁthinking aloudﬂ method in cognitive interface design. ibm researchreport rc #9265.mack, r.l., lewis, c. and carroll, j.m. 1983 learning to use word processors: problems andprospects. acm transactions on office information systems 1:254œ271.mantei, m., and cattell, r.g.g. 1982 a study of entitybased data base interfaces. acm sigchibulletin 14(1).mantei, m., and haskell, n. 1983 autobiography of a firsttime discretionary microcomputer user.chi 83. proceedings of the conference on human factors in computing systems. newyork: association of computing machinery.mantei, m., and smelcer, j.b. 1984 listing of doctoral programs in humancomputer interaction.acm sigchi bulletin 16(2):12œ40.references30about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.miller, d.c., and pew, r.w. 1981 exploiting user involvement in interactive system development.pp. 401œ405 in proceedings of the human factors society annual meeting. santa monica,calif: human factors society.moran, t.p. 1983 getting into a system: externalinternal task mapping analysis. chi83. pp. 45œ49in proceedings of the conference on human factors in computing systems. new york:association of computing machinery.olson, g.m., duffy, s.a., and mack, r.l. 1984 thinkingoutloud as a method for studying realtime comprehension processes. pp. 253œ286 in d.e.kieras and m.a.just, eds., newmethods in reading comprehension. hillsdale, n.j.: lawrence erlbaum.osgood, c.e., suci, g.j., and tannenbaum, p.h. 1957 the measurement of meaning. champaignurbana: university of illinois press.parks, m. 1983 productivity tools enable users to obtain better (not more) code. software news 3(2):22œ23.pew, r.w., rollins, a.m., and williams, g.a. 1979 generic mancomputer dialoguespecification: an alternative to dialogue specialists. bolt beranek and newman inc.,cambridge, mass.polson, p., and kieras, d.e. 1985 a quantitative model of learning and performance of text editingknowledge. chi85. in proceedings of the conference on human factors in computingsystems. new york: association of computing machinery (in press.)ramsey, h.r. 1974 plans: human factors in the design of acomputer programming language . pp.39œ41 in proceedings of the human factors society annual meeting. santa monica,calif.: human factors society.ramsey, h.r., atwood, m.e., and willoughby, j.k. 1979 paper simulation techniques in userrequirements analysis for interactive computer systems. pp. 64œ68 in proceedings of thehuman factors society annual meeting. santa monica, calif.: human factors society.references31about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.reisner, p. 1977 use of psychological experimentation as an aid to development of a querylanguage. ieee transactions on software engineering se3(3):218œ229.1981a formal grammar and human factors design of an interactive graphics system. ieeetransactions on software engineering se7(2):229œ240.1981b human factors of database query languages: a survey and assessment. computing surveys13:13œ31.1984 formal grammmar as a tool for analyzing ease of use: some fundamental concepts. inj.thomas and m.schneider, eds., human factors in computer system norwood, n.h.:ablex.reisner, p., boyce, r.f., and chamberlain, d.d. 1975 human factors evaluation of two data basequery languages: square and sequel. pp. 447œ452 in proceedings of the nationalcomputer conference, arlington, va.: american federation of information processingsocieties press.reitman, j.s., whitten, w.b.,ii, and gruenenfelder, t.m. 1985 a general user interface for enteringand changing tree structures, nested menus, and decision trees. in proceedings of nyusymposium on user interface design. norwood, n.h.: ablex.rice, ronald e. 1982 human communication networking in a teleconferencing environment.ph.d. dissertation, department of computer sciences, stanford university.roberts, teresa l., and moran, thomas p. 1983 the evaluation of text editors: methodology andempirical results. communications of the acm 26:265œ283.rosson, mary beth 1983 patterns of experience in text editing. chi83. pp. 171œ175 in proceedingsof the conference on human factors in computing systems. new york: association ofcomputing machinery.1984 effects of experience on learning, using, and evaluating a text editor. human factors 26:463œ475.references32about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.sheppard, s.b., and kruesi, e. 1981 the effects of the symbology and spatial arrangement ofsoftware specifications in a coding task. general electric companyinformation systemsprograms report tr813882003 . arlington, va.: general electric.shneiderman, b. 1982 systems message design: guidelines and experimental results. in a.badreand b. scheiderman, eds., directions in humancomputer interaction. norwood, n.h.:ablex.smith, s.l. 1982 usersystem interface design for computerbased information systems. mitrecorporation report esdtr82132. bedford, mass.: mitre corporation.smith, s.l., and mosier, j.n. 1984 design guidelines for usersystem interface software. mitrecorporation report esdtr84190. bedford, mass.: mitre corporation.stallman, r.m. 1980 emacs manual for its users. ai lab memo 554. masschusetts institute oftechnology, cambridge, mass.sullivan, m.a., and chapanis, a. 1983 human factoring: a text editor manual. behaviour andinformation technology 2:113œ125.teitelman, w. 1972 do what i mean: the programmer's assistant. computers and automation 21(4)8œ11.thomas, j.c., and gould, j.d. 1975 a psychological study of query by example. in proceedings ofthe national computer conference. arlington, va.: american federation of informationprocessing societies press.van cott, h., and kinkade, r.g., eds. 1972 human engineering guide to equipment design.prepared by the american institutes for research for the u.s. department of defense.available from the u.s. government printing office, washington, d.c.: u.s. departmentof defense..references33about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.wasserman, anthony i. 1982 the user software engineering methodology: an overview. pp. 591œ628 in a.a.verrijnstuart, ed., information system design methodologies. amsterdam:north holland press.wasserman, anthony i., and shewmake, david t. 1982 rapid prototyping of interactiveinformation systems. software engineering notes 7(5):171œ180.whiteside, j., archer, n., wixon, d., good, m. 1982 how do people really use text editors? pp. 29œ40 in proceedings of the sigoa conference on office information systems, philadelphia.wienberg, g.m., and friedman, d.p. 1984 reviews, walkthroughs, and inspections. ieeetransactions on software engineering se10(1).williges, r.c., and williges, b.h. 1982 modeling the human operator in computer based data entry.human factors 24:285œ299.wixon, d.r., whiteside, j.a., good, m.d., and jones, j.r. 1983 building a user defined interface.chi83. pp. 24œ27 in proceedings of the conference on human factors in computingsystems. new york: association of computing machinery.woodson, w.e., and conover, d.w. 1966 engineering guide for equipment designers. 2nd ed.berkeley: university of california press.yunten, t., and hartson, h.r. 1984 a supervisory methodology and notation (superman). inh.r.hartson, ed, advances in humancomputer interaction. norwood, n.h.: ablex.references34about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.methods for designing software to fit human needs and capabilities: proceedings of the workshop on ...copyright national academy of sciences. all rights reserved.references35about this pdf file: this new digital representation of the original work has been recomposed from xml files created from the original paper book, not from theoriginal typesetting files. page breaks are true to the original; line lengths, word breaks, heading styles, and other typesettingspecific formatting, however, cannot beretained, and some typographic errors may have been accidentally inserted. please use the print version of this publication as the authoritative version for attribution.