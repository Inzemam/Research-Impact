detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/12615ensuring the integrity, accessibility, and stewardship ofresearch data in the digital age178 pages | 6 x 9 | paperbackisbn 9780309136846 | doi 10.17226/12615committee on ensuring the utility and integrity of research data in a digitalage; committee on science, engineering, and public policy; national academy ofsciences; national academy of engineering; institute of medicineensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.committee on ensuring the utility and integrity of  research data in a digital agecommittee on science, engineering, and public policy ensuring the integrity, accessibility,and stewardship of research datain the digital ageensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.the national academies press  500 fifth street, n.w.  washington, dc 20001notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn from the councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsible for the report were chosen for their special competences and with regard for appropriate balance.this study was supported by the national research council, united states department of agriculture, national aeronautics and astronautics administration, united states geological survey, united states department of health and human services, united states department of energy, eli lilly and company, burroughs wellcome fund, nature publishing group, the rockefeller university press, new england journal of medicine, american chemical society, federation of american societies for experimental biology, american association for the advancement of science, american geophysical union and ieee.the material is based upon work supported by nasa under award #nnx07ap21g. any opinions, ndings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily re˚ect the views of the national aeronautics and space administration.this material is also based upon work supported by the department of energy [ofce of science] under award number defg0208er15926. disclaimer: this report was prepared as an account of work sponsored by an agency of the united states government. neither the united states government nor any agency thereof, nor any of their employees, makes any warranty, express or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights. reference herein to any specic commercial product, process, or service by trade name, trademark, manufacturer, or otherwise does not necessarily constitute or imply its endorsement, recommendation, or favoring by the united states government or any agency thereof. the views and opinions of authors expressed herein do not necessarily state or re˚ect those of the united states government or any agency thereof.library of congress cataloginginpublication datacommittee on science, engineering, and public policy (u.s.). committee on ensuring the utility and integrity of research data in a digital age. ensuring the integrity, accessibility, and stewardship of research data in the digital age / committee on ensuring the utility and integrity of research data in a digital age, committee on science, engineering, and public policy. p. cm. includes bibliographical references and index. isbn13: 9780309136846 (pbk.); isbn10: 0309136849 (pbk.); isbn13: 9780309136853 (pdf); isbn10: 0309136857 (pdf) 1. researchštechnological innovations. 2. information technologyšscientic applications. 3. electronic information resourcesšmanagementšunited states. 4. electronic information resourcesšaccess control. i. title.  q180.55.i45c66 2009 001.4028558šdc22 2009036322cover graphic provided by wellformed.eigenfactor (http://wellformed.eigenfactor.org/), a cooperation between moritz stefaner (visualization design) and the eigenfactor project (data analysis).additional copies of this report are available from the national academies press, 500 fifth street, n.w., lockbox 285, washington, dc 20055; (800) 6246242 or (202) 3343313 (in the washington metropolitan area); internet, http://www.nap.edu.copyright 2009 by the national academy of sciences. all rights reserved.printed in the united states of americaensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprot, selfperpetuating society of distinguished scholars engaged in scientic and engineering research, dedicated to the furtherance of science and technology and to their use for the general welfare. upon the authority of the charter granted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientic and technical matters. dr. ralph j. cicerone is president of the national academy of sciences.the national academy of engineering was established in 1964, under the charter of the national academy of sciences, as a parallel organization of outstanding engineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsors engineering programs aimed at meeting national needs, encourages education and research, and recognizes the superior achievements of engineers. dr. charles m. vest is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy of sciences to secure the services of eminent members of appropriate professions in the examination of policy matters pertaining to the health of the public. the institute acts under the responsibility given to the national academy of sciences by its congressional charter to be an adviser to the federal government and, upon its own initiative, to identify issues of medical care, research, and education. dr. harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology with the academy™s purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both the national academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientic and engineering communities. the council is administered jointly by both academies and the institute of medicine. dr. ralph j. cicerone and dr. charles m. vest are chair and vice chair, respectively, of the national research council.www.nationalacademies.orgensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.committee on ensuring the utility and integrity of research data in a digital agedaniel kleppner (cochair), lester wolfe professor of physics, emeritus, massachusetts institute of technology, cambridgephillip a. sharp (cochair), institute professor, the david h. koch institute for integrative cancer research, massachusetts institute of technology, cambridgemargaret a. berger, professor of law, brooklyn law school, brooklyn, new yorknorman m. bradburn, tiffany & margaret blake distinguished service professor emeritus, university of chicago, washington, dcjohn brauman, j. g. jacksonœc. j. wood professor emeritus, department of chemistry, stanford university, stanford, californiajennifer t. chayes, managing director, microsoft research new england, cambridge, massachusettsanita jones, lawrence r. quarles professor of engineering and applied sciences, school of engineering and applied sciences, university of virginia, charlottesville linda p. b. katehi, provost and vice chancellor for academic affairs, university of illinois, urbanachampaignneal f. lane, malcolm gillis university professor and senior fellow of the james a. baker iii institute for public policy, rice university, houston, texasw. carl linberger, e.u. condon distinguished professor of chemistry and fellow, joint institute for laboratory astrophysics, university of colorado, boulderrichard luce, vice provost and director of university libraries, robert w. woodruff library, emory university, atlanta, georgiathomas o. mcgarity, joe r. and teresa lozano long endowed chair in administrative law, school of law, university of texas, austinsteven m. paul, executive vice president, s&t and president, lilly research laboratories, eli lilly & company, indianapolis, indianateresa a. sullivan, provost and executive vice president for academic affairs and professor of sociology, university of michigan, ann arbormichael s. turner, bruce v. diana m. rauner distinguished service professor and chair, department of astronomy and astrophysics, university of chicago, chicago, illinoisj. anthony tyson, distinguished professor of physics, department of physics, university of california, davisvensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.steven c. wofsy, abbott lawrence rotch professor of atmospheric and environmental sciences, department of earth and planetary sciences, harvard university, cambridge, massachusettsprincipal project staffthomas arrison, study director (after july 2007)deborah d. stine, study director (up to july 2007)steve olson, consultant writerneeraj p. gorkhaly, senior program assistantalbert swiston, christine mirzayan science & technology policy graduate fellowsage arbor, christine mirzayan science & technology policy  graduate fellowviensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.committee on science, engineering and public policygeorge m. whitesides (chair), woodford l. and ann a. flowers professor of chemistry and chemical biology, harvard university, cambridge, massachusettsclaude r. canizares, vice president for research, associate provost, bruno rossi professor of physics, massachusetts institute of technology, cambridgeralph j. cicerone (ex ofcio), president, national academy of sciences, washington, dc edward f. crawley, professor of aeronautics and astronautics and of engineering systems, department of aeronautics and astronautics, massachusetts institute of technology, cambridgeruth a. david, president and ceo of anser institute for homeland security (analytic services, inc.), arlington, virginiahaile t. debas, chancellor emeritus, university of california, san franciscoharvey fineberg (ex ofcio), president, institute of medicine, washington, dcjacques s. gansler, roger c. lipitz chair in public policy and private enterprise, school of public policy, university of maryland, college park elsa m. garmire, sydney e. junkins professor of engineering, dartmouth college, hanover, new hampshirem. r. c. greenwood (ex ofcio), chair, pga, and professor of nutrition and internal medicine, university of california, davisw. carl lineberger, professor of chemistry, university of colorado, boulderc. dan mote, jr. (ex ofcio), president, university of maryland, college parkrobert m. nerem, professor and director, parker h. petit institute for bioengineering and bioscience, georgia institute of technology, atlantalawrence t. papay, ceo and principal, pqr, llc, maineville, ohioanne c. petersen, deputy director, center for advanced study in the behavioral sciences, stanford university, palo alto, californiasusan c. scrimshaw, interim president, sage colleges, troy, new yorkwilliam j. spencer, chairman emeritus, sematech, austin, texaslydia thomas (ex ofcio), cochair, guirr, and chairman and ceo, mitretek systems, falls church, virginiacharles m. vest (ex ofcio), president, national academy of engineering, washington, dcnancy s. wexler, higgins professor of neuropsychology, columbia university, new york, new yorkviiensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.mary lou zoback, vice president for earthquake risk applications, risk management solutions, inc., newark, californiastaffwilliam ostendorff, directormarion ramsey, administrative associatepeter hunsberger, financial associateensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.prefacedata are the foundation on which scientic, engineering, and medical knowledge is built. the generation, analysis, communication, and preservation of data are in a period of profound change, and research is being similarly transformed.the development and rapid advance of digital technologies have enabled immense quantities of data to be created, processed, and disseminated around the world. these data can capture the characteristics of phenomena in far greater detail and with a dynamic verisimilitude never before possible. data from different elds are being combined, yielding deep insights into formerly intractable problems. the open sharing of data, tools, and services over the internet is creating new ways of carrying out research and new relationships among researchers. new research topics and elds are emerging between the boundaries of traditional disciplines, and the questions that investigators can address are rapidly expanding.these changes in the nature and conduct of research are greatly enhancing the capabilities of researchers. however, these changes also are posing challenges, and in some cases they have had negative consequences. a major impetus for this study was a letter sent from the editors of several leading journals to national academy of sciences president ralph cicerone (see appendix c) pointing out that the improper manipulation of digital images submitted to scholarly journals has become a signicant issue for editors and publishers. more broadly, changes in the use of research data have raised the stakes for the methods traditionally used to ensure the integrity and utility of data. research data and results are increasingly critical inputs to a widening variety of policy debates and decisions. transparency on the part of investigators with regard to the collection of data, methods of analysis, and presentation of results is essential for the research enterprise to serve the public as an objective source of unbiased ixensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.x prefaceinformation. in that regard, another major impetus for this report was the recent controversy over the interpretation and use of data to reconstruct historical changes in global temperatures. in this case, the combination of an important policy topic, differences in datasharing expectations between elds, and unclear expectations among researchers and members of the public opened researchers to heightened scrutiny, skepticism, and even harassment.as plans for this study took shape, it became clear that the issues involving research data extend well beyond the most immediate connotations of the term ﬁdata integrity.ﬂ thus, the charge issued to our committee asked us to look at several critical issues:an ad hoc committee will conduct a study of issues that have arisen from the evolution of practices in the collection, processing, oversight, publishing, ownership, accessing, and archiving of research data. the key questions to be addressed are:1.  what are the growing varieties of research data? in addition to issues concerned with the direct products of research, what issues are involved in the treatment of raw data, prepublication data, materials, algorithms, and computer codes?2.  who owns research data, particularly that which results from federally funded research? is it the public? the research institution? the lab? the researcher?3.  to what extent is a scientist responsible for supplying research data to other scientists (including those who seek to reproduce the research) and to other parties who request them? is a scientist responsible for supplying data, algorithms, and computer codes to other scientists who request them?4.  what challenges do the science and technology community face arising from actions that would compromise the integrity of research data? what steps should be taken by the science and technology community, research institutions, journal publishers, and funders of research in response to these challenges?5.  what are the current standards for accessing and maintaining research data, and how should these evolve in the future? how might such standards differ for federally funded and privately funded research, and for research conducted in academia, government, nongovernmental organizations, and industry?the study will not address privacy issues and other issues related to human subjects.at our committee™s rst meeting, it quickly became apparent that even this wideranging charge did not encompass the full range of pressing issues ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.preface xiinvolving research data. digital technologies have been changing research at a pace that would have been hard to predict even a decade ago. practices and expectations for data sharing vary considerably from eld to eld and are rapidly evolving. national and homeland security concerns affect the policy environment governing access to various types of data. in some areas the costs of maintaining collections and transferring them to new digital media raise questions about who is responsible for undertaking and nancing longterm stewardship. a growing variety of investigators and research elds face difcult choices involving tradeoffs between sustaining existing data collections and performing new research.the purpose of this report is to explore the evolving roles and responsibilities of researchers, research institutions, research sponsors, journals, publishers, and others in generating, analyzing, disseminating, and preserving research data. many of the methods used to validate the quality of data, make data available to other researchers, and preserve data for future uses are unique to specic disciplines. focusing on these disciplinespecic methods would yield a report that is both too narrow and too transitory given the transformative in˚uence of rapidly changing technologies.instead, we decided to base our report on the broad principles that have characterized science and engineering research for hundreds of years and will continue to do so in the future. in particular, we decided to focus on three broad and intertwined issues that we have characterized as integrity, access, and stewardship. for each of these issues, we state a general principle that applies throughout the research enterprise. we then use these three broad principles to formulate recommendations that apply in more specic circumstances. we have also highlighted, within the text and in sidebars in each chapter, useful efforts by researchers, institutions, research elds, research sponsors, professional societies, and journals to facilitate the realization of our broad objectives. and we have identied issuesšsome new and some oldšthat will need continued attention as technology continues to reshape the research enterprise.although this report addresses all of the components of the research enterprise, its primary focus is on the roles and responsibilities of the investigator. this is appropriate, given the composition of the committee and the nature of the task. the actions of researchers inevitably in˚uence all the other parts of the research enterprise, and each of these parts also has responsibilities in maintaining the integrity, accessibility, and stewardship of research data. however, researchers must take the lead in addressing new and pressing issues involving research data. in general, the report attempts to re˚ect the perspectives of individual researchers in different elds with respect to the generation, preservation, and sharing of research data in science as a whole and in specic elds.following the executive summary, chapter 1 introduces the main issues covered in the report by examining the terms used in the report and the varieties of research data. chapter 2, on the integrity of research data, looks at ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.xii prefacethe challenges to data integrity created by rapidly changing technologies and at responses to those challenges. chapter 3 discusses the responsibility for researchers to make publicly available the data on which research results are based, and the variety of challenges this poses in different elds and settings. and chapter 4 describes the longterm value of research data and methods to preserve data for future uses.the changes in the daily practices and activities of researchers due to the rapidly changing technologies provide a unique opportunity to reinforce and extend the traditional openness and collaborative nature of science.in preparing this report, our committee has taken advantage of a number of studies by the national academy of sciences, the national academy of engineering, the institute of medicine and the national research council. appendix b provides a list of recent reports on relevant subjects. for example, the committee spent some time reviewing and discussing a recent controversy over the interpretation and use of data to reconstruct historical changes in global temperatures, as described in the 2006 nrc report surface temperature reconstruction for the last 2,000 years. the importance of data in research and in societal decisions will continue to increase as science and engineering exert an ever greater in˚uence on society and as digital technologies continue to remake our world. the committee and the members of the committee on science, engineering, and public policy hope and trust that this report will stimulate further dialogue to strengthen science and engineering in a datarich world.phillip a. sharp daniel kleppnermassachusetts institute of technology massachusetts institute of technologyensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.this report has been reviewed in draft form by individuals chosen for their diverse perspectives and technical expertise, in accordance with procedures approved by the national academies™ report review committee. the purpose of this independent review is to provide candid and critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meets institutional standards for objectivity, evidence, and responsiveness to the study charge. the review comments and draft manuscript remain condential to protect the integrity of the process. we wish to thank the following individuals for their review of this report: frederick anderson, mckenna, long & aldridge llp; michael carroll,  american university; ian foster, argonne national laboratory; john graham,  indiana university; myron gutmann, interuniversity consortium for political and social research; henry horbaczewski, reed elsevier, inc.; jerome kassirer, tufts university; michael keller, stanford university; joan lippincott, coalition for networked information; david moorman, social sciences and humanities research council of canada; james ostell, national library of medicine; robert pike, google; david robinson, rutgers university; sandford shattil, university of california, san diego; and john white, university of arkansas.although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the nal draft of the report before its release. the review of this report was overseen by william press, university of texas, austin and warren washington, national center for atmospheric research. appointed by the national academies, they were responsible for making certain that an independent examination of this report was carried out in accordance with institutional procedures and that all review comments were carefully considered. responsibility for the nal content of this report rests entirely with the authoring committee and the institution.acknowledgment of reviewersxiiiensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.contentssummary 11 research data in the digital age 11 challenges posed by research data in a digital age, 19 descriptions of terms used in the report, 22 the varieties of research data, 27 structure of the report, 292 ensuring the integrity of research data 33 the roles of data producers, providers, and users, 40 the collective scrutiny of research data and results, 41 peer review and other means for ensuring the integrity of data, 43 data integrity in the digital age and the role of data professionals, 50 general principle for ensuring the integrity of research data, 51 the obligations of researchers to ensure the integrity of  research data, 51 the importance of training, 54 producing clear, uptodate standards for data integrity:  a shared responsibility of the research enterprise, 56 the roles of data professionals, 573 ensuring access to research data 59 barriers to sharing data, 63 the costs of limiting access to data, 70 data access issues in research affecting public policy or private  interests, 71 ownership of research data and related products, 73xvensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.xvi contents legal and policy requirements for access to data, 80 the international dimensions of access to research data, 83 general principle for enhancing access to research data, 84 responsibilities of researchers, 86 responsibilities of research fields, 88 responsibilities of research institutions, research sponsors,  professional societies, and journals, 904 promoting the stewardship of research data 95 the loss and underutilization of research data, 96 infrastructure and incentives for the stewardship of data, 99 annotating data for longterm use, 106 fostering data stewardship for the broad research enterprise, 107 general principle for enhancing the stewardship of research data, 109 responsibilities of researchers, 109 responsibilities of research institutions, research sponsors, and  journals, 1125 defining roles and responsibilities 115 assigning roles and responsibilities, 115 researchers, 115 research institutions, 118 research sponsors, 119 professional societies and journals, 119 conclusion, 120appendixesa biographical information on the committee members  121b relevant national academy of sciences, national academy of  engineering, institute of medicine, and national research  council reports 133c letters from journals 143index 155ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.advances in digital computing, communications, sensors, and storage technologies are revolutionizing nearly every area of scientic, engineering, and medical research. today, researchers are employing sophisticated technologies to generate, analyze, and share data to address questions that were unapproachable just a few years ago. they are carrying out detailed simulations to guide theoretical approaches and to validate new experimental approaches. they are working in interdisciplinary and often international teams on complex integrative problems that require inputs from a multitude of perspectives. they are using data generated by others to augment their own data and sometimes to address problems that the original researchers could not have envisioned. digital technologies have fostered a new world of research characterized by immense datasets, unprecedented levels of openness among researchers, and new connections among researchers, policy makers, and the public.even as these new capabilities are expanding the power and reach of research, they are raising complex issues for researchers, research institutions, research sponsors, professional societies, and journals. digital technologies can complicate the process of verifying the accuracy and validity of research data, in part because of the enormous rate at which data can be generated and the intricate processing those data undergo. the high rate of innovation in digital technologies, a lack of standards, and issues such as privacy, national security, and possible commercial interests can inhibit the sharing of data, which can reduce the ability of researchers to verify results and build on previous research. huge increases in the quantity of data being generated, combined with the need to move digital data between successive storage media and software environments as technologies evolve, are creating severe challenges in preserving data for longterm use. and these issues are not restricted to largescale research summary1ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.2 ensuring the integrity, accessibility, and stewardship of dataprojects; they can be especially acute for the smallscale projects that continue to constitute the bulk of the research enterprise.this report examines the consequences of the changes affecting research data with respect to three issues: integrity, accessibility, and stewardship. because of the enormous range in the detailed procedures and styles of research from eld to eld, it is impossible to formulate specic recommendations for every eld. instead, for each of the three issues examined in this report, the authoring committee has developed a fundamental principle that applies in all elds of research regardless of the pace or nature of technological change. the report then explores the implications of these three central principles for the various components of the research enterprise.1 developing the policies, standards, and infrastructure needed to ensure the integrity, accessibility, and stewardship of research data is a critically important task. it will require sustained effort on the part of all stakeholders in the research enterprise. the committee believes that the broad principles stated in this report provide the appropriate framework for this undertaking.ensuring the integrity of research datathe elds of science, engineering, and medicine span the totality of physical, biological, and social phenomena. research in all these elds is based on certain fundamental procedures and convictions. however, each research eld has its own characteristic methods and scientic style. consequently, research is too broad an enterprise to permit many generalizations about its conduct.one theme, however, threads through its many elds: the primacy of scrupulously recorded data. because the techniques that researchers employ to ensure the integrityšthe truth and accuracyšof their data are as varied as the elds themselves, there are no universal procedures for achieving technical accuracy. the term ﬁintegrity of dataﬂ also has a structural meaning, related to the data™s preservation and presentation. this is the subject of chapter 4. there are, however, broadly accepted practices for generating and analyzing research. in most elds, for instance, experimental observations must be shown to be reproducible in order to be credible. even this fundamental principle can have exceptions. for instance, observations with an historical element, such as the explosion of a supernova or the growth of an epidemic, cannot be reproduced. other general practices include checking and rechecking data to conrm their accuracy and validity and submitting data and research results to peer review to ensure that the interpretation is valid. in addition, some practices may be employed only within specic elds, such as the use of doubleblind clinical trials.many of the traditional methods for ensuring the integrity of datašwhether universal or discipline specicšare being modied as digital technologies alter 1 in this summary, the principles appear in boldface type and the recommendations drawn from the principles are presented in italic type.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.summary 3capabilities and procedures. because of the huge quantities of data generated by digital technologies, an increasing fraction of the processing and communication of data is done by computers, sometimes with relatively little human oversight. if this processing is ˚awed or misunderstood, the conclusions can be erroneous. documenting work ˚ows, instruments, procedures, and measurements so that others can fully understand the context of data is a vital task, but this can be difcult and timeconsuming. furthermore, digital technologies can tempt those who are unaware of or dismissive of accepted practices in a particular research eld to manipulate data inappropriately.several recent incidents and trends provided an impetus for this study, such as the challenge journals face in preventing inappropriate manipulation of digital images in submitted papers and wellpublicized, albeit rare, cases of research misconduct involving fabricated or manipulated data. assessing the broad set of institutions, policies, and practices that have been put into place to prevent and detect research misconduct, including the fabrication or inappropriate manipulation of data, was beyond the scope of this study. nevertheless, the committee recognizes that the advance of digital technologies presents special challenges to the individuals and institutions charged with ensuring responsible conduct in research. since these individuals and institutions will continue to play a critical role in ensuring the integrity of research data, it is important that they adapt their procedures in order to function effectively in the digital age.the most effective method for ensuring the integrity of research data is to ensure high standards for openness and transparency. to the extent that data and other information integral to research results are provided to other experts, errors in data collection, analysis, and interpretation (intentional or unintentional) can be discovered and corrected. this requires that the methods and tools used to generate and manipulate the data be available to peers who have the background to understand that information.the traditional way for submitting data and results to the scrutiny of other researchers is through peer review, which allows the validity of data and results to be judged for quality by a research community before dissemination. although traditional peer review practices remain essential for evaluating the importance and validity of research, it has become clear that these have limitations when it comes to ensuring that digital data have been appropriately collected, analyzed, and interpreted. fortunately, it has also become clear that the advance of digital technologies is providing new opportunities to ensure data integrity through greater openness and transparency. the emergence and growth of accessible databases such as genbank and the sloan digital sky  survey illustrate these opportunities in widely disparate disciplines.2 yet in 2 dennis a. benson, ilene karschmizrachi, david j. lipman, james ostell, and david l. wheeler. 2006. ﬁgenbank.ﬂ nucleic acids research 34(database):d16œd20. available at http://nar.oxfordjournals.org/cgi/content/abstract/34/suppl1/d16. see also robert c. kennicutt, jr., 2007. ﬁsloan at ve.ﬂ nature 450:488œ489.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.4 ensuring the integrity, accessibility, and stewardship of datamany elds, a lack of technological infrastructure, cultural norms and expectations, and other factors act as barriers to openness and transparency.the integrity of data in a time of revolutionary changes in research practice is too important to be taken for granted. consequently, this report afrms the following general principle for ensuring the integrity of research data:data integrity principle: ensuring the integrity of research data is essential for advancing scientic, engineering, and medical knowledge and for maintaining public trust in the research enterprise. although other stakeholders in the research enterprise have important roles to play, researchers themselves are ultimately responsible for ensuring the integrity of research data.this straightforward principle leads to several specic recommendations.recommendation 1: researchers should design and manage their projects so as to ensure the integrity of research data, adhering to the professional standards that distinguish scientic, engineering, and medical research both as a whole and as their particular elds of specialization.some professional standards apply throughout research, such as the injunction never to falsify or fabricate data or plagiarize research results. these are fundamental to research, and have been conrmed by leading organizations and codied in regulations.3 other standards are relevant only within specic eldsšsuch as requirements to conduct doubleblind clinical trials. researchers must adhere to both sets of standards if they are to maintain the integrity of research data, and they can adhere to professional standards only if they fully understand the standards.recommendation 2: research institutions should ensure that every researcher receives appropriate training in the responsible conduct of research, including the proper management of research data in general and within the researcher™s eld of specialization. some research sponsors provide support for this training and for the development of training programs. researchers, research institutions, research sponsors, professional societies, and journals all are responsible for creating and sustaining an environment that supports the efforts of researchers to ensure the integrity of research data. in some cases, digital technologies are having such a dramatic effect on research practices that some professional standards affecting the integrity of 3 national academy of sciences, national academy of engineering, and institute of medicine. 1992. responsible science: ensuring the integrity of the research process. washington, dc: national academy press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.summary 5research data either have not yet been established or are in ˚ux. the recent recognition of the inappropriate manipulation of digital images submitted in journal articles illustrates the need for the research enterprise to continue to set clear expectations for appropriate behavior and effectively communicate those expectations. recommendation 3: the research enterprise and its stakeholdersšresearch institutions, research sponsors, professional societies, journals, and individual researchersšshould develop and disseminate professional standards for ensuring the integrity of research data and for ensuring adherence to these standards. in areas where standards differ between elds, it is important that differences be clearly dened and explained. specic guidelines for data management may require reexamination and updating as technologies and research practices evolve. although all researchers should understand digital technologies well enough to be condent in the integrity of the data they generate, they cannot always be expected to be able to take full advantage of new capabilities. in an increasing number of elds, professionals with expertise specically in the generation, analysis, storage, or dissemination of data are playing an essential role in taking advantage of digital technologies and ensuring the integrity of research data. recommendation 4: research institutions, professional societies, and journals should ensure that the contributions of data professionals to research are appropriately recognized. in addition, research sponsors should acknowledge that nancial support for data professionals is an appropriate component of research support in an increasing number of elds.ensuring access to research dataadvances in knowledge depend on the open ˚ow of information. only if data and research results are shared can other researchers check the accuracy of the data, verify analyses and conclusions, and build on previous work. furthermore, openness enables the results of research to be incorporated into socially benecial goods and services and into public policies, improving the quality of life and the welfare of society.despite the many benets arising from the open availability of research data and results, many data are not publicly accessible, or their release is delayed, for a variety of reasons. data may be withheld because they are being used to generate a commercial product or service, because of condentiality considerations, or because of national security concerns. furthermore, in some elds it is acceptable for researchers to have a limited period of exclusivity in which the data are used only by the principal investigators and their immediate ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.6 ensuring the integrity, accessibility, and stewardship of dataassociates. in areas of potential commercial applications, patenting considerations, contractual restrictions, and technological constraints also can limit or delay the accessibility of data.legitimate reasons may exist for keeping some data private or delaying their release, but the default assumption should be that research data, methods (including the techniques, procedures, and tools that have been used to collect, generate, or analyze data, such as models, computer code, and input data), and other information integral to a publicly reported result will be publicly accessible when results are reported, at no more than the cost of fullling a user request. this assumption underlies the following principle of accessibility:data access and sharing principle: research data, methods, and other information integral to publicly reported results should be publicly accessible.although this principle applies throughout research, in some cases the open dissemination of research data may not be possible or advisable. granting access to research data prior to reporting results based on those data can undermine the incentives for generating the data. there might also be technical barriers, such as the sheer size of datasets, that make sharing problematic, or legal restrictions on sharing as discussed in chapter 3. nevertheless, the main objective of the research enterprise must be to implement policies and promote practices that allow this principle to be realized as fully as possible.this principle has important implications for researchers.recommendation 5: all researchers should make research data, methods, and other information integral to their publicly reported results publicly accessible in a timely manner to allow verication of published ndings and to enable other researchers to build on published results, except in unusual cases in which there are compelling reasons for not releasing data. in these cases, researchers should explain in a publicly accessible manner why the data are being withheld from release.this principle may seem to apply only to publicly funded research, but a strong case can be made that much data from privately funded research should be made publicly available as well. making such data available can produce societal benets while also preserving the commercial opportunities that motivated the research.as discussed earlier, differences in technological infrastructure, publication practices, datasharing expectations, and other cultural practices have long existed between research elds. in some elds, aspects of this ﬁdata cultureﬂ act as barriers to access and sharing of data. with the growing importance of research results to certain areas of public policy, the rapid increase of interdisciplinary research that involves integration of data from different disciplines, and ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.summary 7other trends, it is important for elds of research to examine their standards and practices regarding data and to make these explicit.data accessibility standards generally depend on the norms of scholarly communication within a eld. in many elds these norms are now in a state of ˚ux. in some elds, researchers may be expected to disseminate data and conclusions more rapidly than is possible through peerreviewed publications. digital technologies are providing new ways to disseminate research resultsšfor example, by making it possible to post draft papers on archival sites or by employing software packages, databases, blogs, or other communications on personal or institutional web sites.data sharing is greatly facilitated when a eld of research has standards and institutions in place that are designed to promote the accessibility of data. recommendation 6: in research elds that currently lack standards for sharing research data, such standards should be developed through a process that involves researchers, research institutions, research sponsors, professional societies, journals, representatives of other research elds, and representatives of public interest organizations, as appropriate for each particular eld.if researchers are to make data accessible, they need to work in an environment that promotes data sharing and openness. recommendation 7: research institutions, research sponsors, professional societies, and journals should promote the sharing of research data through such means as publication policies, public recognition of outstanding datasharing efforts, and funding. recommendation 8: research institutions should establish clear policies regarding the management of and access to research data and ensure that these policies are communicated to researchers. institutional policies should cover the mutual responsibilities of researchers and the institution in cases in which access to data is requested or demanded by outside organizations or individuals.promoting the stewardship of research dataresearch data can be valuable for many years after they are generated. data that led to initial insights can sometimes be used to generate new ndings in the same or entirely different research elds. existing data can be reanalyzed or combined with new data to verify published results or arrive at new conclusions. in some research areas, accessible databases have become essential parts of the research infrastructure, comparable to laboratories, research facilities, and computing devices and networks.maintaining highquality and reliable databases can be costly, especially ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.8 ensuring the integrity, accessibility, and stewardship of dataover long time periods. obviously not all data should be preserved, but deciding what to save and what to discard becomes more difcult as increasing quantities of data are generated. because the future uses of data are difcult to predict, returns on investments in stewardship can be uncertain. furthermore, in many elds of research, there is no consensus as to who should maintain large databases or who should bear the costs. these problems can be especially difcult for investigators involved in small projects, who can face great challenges in deciding which data will be useful, in documenting those data thoroughly for future uses, and in nding funds from limited budgets for data preservation.the value of data for longterm use suggests the following general principle for the stewardship of data:data stewardship principle: research data should be retained to serve future uses. data that may have longterm value should be documented, referenced, and indexed so that others can nd and use them accurately and appropriately.curating data requires documenting, referencing, and indexing the data so that they can be used accurately and appropriately in the future. data stewardship must start at the beginning of the project, not partway through or at the end of the project. recommendation 9: researchers should establish data management plans at the beginning of each research project that include appropriate provisions for the stewardship of research data.because data without accompanying information about how they were derived can be useless, arranging for preserved data to be annotated so that they retain their longterm value is among the most important tasks for researchers establishing a data management plan.this recommendation is not meant to imply that individual researchers are responsible for ensuring indenite preservation of their own data, but that they ensure that data that are judged to have potential longterm value are prepared and transferred to the appropriate archives or repositories. researchers should work in partnership with their institutions, sponsors, and elds to formulate and implement their plans. researchers need to participate in the development of policies and standards for data annotation, preservation, and longterm access. data need not be annotated in such detail that nonspecialists can immediately use them, but guidelines should exist for the degree of expertise required to use a data collection. researchers also need to develop procedures for error reporting, tracking, and correction. these policies and standards will vary greatly from eld to eld because they depend on the nature and potential uses of data. nevertheless, ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.summary 9establishing such policies is the collective responsibility of the researchers in each eld.recommendation 10: as part of the development of standards for the management of digital data, research elds should develop guidelines for assessing the data being produced in that eld and establish criteria for researchers about which data should be retained.researchers need a supportive institutional environment to fulll their responsibilities toward the stewardship of data. recommendation 11: research institutions and research sponsors should study the needs for data stewardship by the researchers they employ and support. working with researchers and data professionals, they should develop, support, and implement plans for meeting those needs. the problem of paying for longterm stewardship of research data and other digital scholarly work is difcult, and solutions need to be developed over time. it is important that requirements for improved data management practices not be imposed as unfunded mandates. in the digital age, data management needs to be integrated into research program funding as an essential component of the conduct of research. where appropriate, grant applications should include costs for data stewardship.many issues regarding the integrity, accessibility, and stewardship of research data are common across the research enterprise. bodies that oversee multiple elds of research should disseminate lessons learned and help to foster interdisciplinary cooperation. within the u.s. federal government, a recent report by the interagency working group on digital data explores the needs for preservation and dissemination of publicly funded research data.4 at the nongovernmental level, the national research council recently established a new board on research data and information that will address emerging issues in the management, policy, and use of research data at the national and international levels.4 interagency working group on digital data. 2009. harnessing the power of digital data for science and society. washington, dc: national science and technology council, executive ofce of the president.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.1research data in the digital agein a 1965 article in electronics magazine, gordon moore, the cofounder of intel, observed that the number of components on an integrated circuit per unit of cost was doubling on a regular basisša period he later set at 2 years.1 what came to be known as moore™s law has become a dening property of the digital age.2 for more than half a century, the power of computing available at a given cost has risen exponentially, which has increased computer power by many orders of magnitude. today, the most powerful computers can perform more than a million billion operations per second. storage devices can handle petabytes of information.3 data can be transferred at rates of 10 gigabits (or 10 billion bits) per second (see box 11 for a description of units of size for data). sensors such as the chargedcoupled devices used in modern cameras and telescopes can acquire data from billions of pixels simultaneously. furthermore, in key areas of computing, moore™s law continues to hold.4 many measures of computing power continue to double every 1 to 2 years. as a result, the quan1 gordon e. moore. 1965. ﬁcramming more components onto integrated circuits.ﬂ electronics 38(19):114œ117.2 michael s. turner. 2007. ﬁscientic discovery in the information age.ﬂ presentation at the de lange conference on emerging libraries: how knowledge will be accessed, discovered, and disseminated in the age of digital information, march 6, houston, tx. available online at http://delange.rice.edu/vi/el/turnerdelange2007.pdf?action=details&event=921.3 a petabyte represents a million billion characters, the equivalent of the text in one billion books.4 not all measures of computing power are increasing exponentially. for example, the transfer rate of data within computers from memory devices to the central processing unit is growing slowly and at a linear rate. physical limitations on the power of single processors have constrained the continued general application of moore™s law. however, new algorithms for processors and storage units linked in parallel may lead to resumed exponential increases in computing power in the future.11ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.12 ensuring the integrity, accessibility, and stewardship of databox 11 units of size for databit: the fundamental unit of digital information, equivalent to a 1 or a 0, or to an electronic switch being on or off. bit is short for binary digit.byte: the information stored in eight bits. a byte can be used to store one character of english text.kilobyte: the information stored in approximately 1,000 bytes, which is the equivalent of about 15 lines of text.megabyte: the information stored in approximately 1,000 kilobytes. a large novel contains about a megabyte of information, and a standard compact disc holds about 680 megabytes of digital information.gigabyte: the information stored in approximately 1,000 megabytes. a typical hard drive (as of 2008) holds about 500 gigabytes of information.terabyte: the information stored in approximately 1,000 gigabytes. the printed information stored in the library of congress equals approximately 10 terabytes.petabyte: the information stored in approximately 1,000 terabytes. all u.s. academic research libraries combined contain about 2 petabytes of information.exabyte: the information stored in approximately 1,000 petabytes. according to one estimate,a human beings have spoken about 5 exabytes of words over the course of our species™ history.a see http://www2.sims.berkeley.edu/research/projects/howmuchinfo2003/.tity of data being created and stored by businesses, individuals, government, scientic institutions, and individuals is growing rapidly. figure 11 shows one consulting rm™s projection of how information and available storage will grow in the coming years.this exponential increase in computing power has had profound consequences for many aspects of modern society, including scientic, engineering, and medical research.5 using digital technologies, researchers can measure, describe, and model phenomena much more comprehensively and in far greater detail than was possible in the past. they can detect and analyze the products 5 alexander szalay and jim gray. 2006. ﬁscience in an exponential world.ﬂ nature 440:413œ414.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 13figure 11 projected global information creation and available storage. note: one exabtyte equals one billion gigabyptes.source: idc white paper sponsored by emc, the diverse and exploding digital universe, march 2008. available at: http://www.emc.com/collateral/analystreports/diverseexplodingdigitaluniverse.pdf.of highenergy particle collisions to probe the underlying structure of matter. they can extract information about the functioning of nerve cells and construct models of neural processing. they can combine simultaneous measurements of atmospheric and oceanic conditions to predict the effects of pollutants on climates. they can extract patterns of health from extensive databases of genetic and medical records. examples of the impact of digital technologies on research elds appear as sidebars throughout this report, and the number of such examples could be multiplied many times.the advances in digital technologies have caused a massive increase in the quantity of data generated by research projects. the proposed large synoptic survey telescope is expected to gather 30 terabytes of data per night and more than 60 petabytes over its lifetime (see box 12). particle physics experiments conducted with the large hadron collider at cern (figure 12) will generate 15 petabytes of data annually. even relatively smallscale projects can generate immense quantities of data that can be valuable in multiple research elds. these quantities of data are much too large to examine by hand. instead, computers must conduct the initial analysis of data before the processed and condensed results are reviewed by researchers.figure 11.eps1,8002005available storage, 2007264ebother1%exabytesavailable storageinformation created2006200720082009201020111,6001,4001,2001,0008006004002000tape21%optical22%disk56%ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.14 ensuring the integrity, accessibility, and stewardship of databox 12 digital data in astronomy as astronomical observatories have become more powerful, they also have become more dataintensive.a table 11 shows the trend in recent decades. the sloan digital sky survey (sdss), for example, has delivered an unprecedented ood of data since it began operation in 2000. the sdss uses a dedicated 2.5meter telescope on apache point, new mexico, equipped with two specialpurpose instruments. the telescope™s camera can image 1.5 square degrees of sky at a timešabout eight times the area of the full moon. a pair of spectrographs can measure spectra ofšand hence distances tošmore than 600 galaxies and quasars in a single observation. a customdesigned set of software pipelines keeps pace with the enormous data ow from the telescope. in its ˚rst 5 years of operation, the sloan telescope searched more than 8,000 square degrees of the northern skyšabout a ˚fth of the entire skyšin ˚ve wavelength bands. it recorded some 217 million objects, mostly galaxies, stars, and asteroids, and measured spectra for around 675,000 of these.b with funding from multiple sources and countries, the sdss has followed a policy of freely releasing data annually, with separate web sites for research users and the general public. a recent release, data release 7 (dr7), in november 2008, included some 16 terabytes of images and spectra. its current phase, sdssii, is among the largest astronomical collaborations ever undertaken, involving more than 300 astronomers, astrophysicists, and engineers at 25 institutions around the world. the sdss has helped to revolutionize the interactions between a telescope, its data, and its user communities. because the sdss data archive is available to any astronomer, roughly half of the 2,100 refereed papers based on sdss data have come from authors outside the project itself, and that proportion is rising. in fact, for the past 2 years, the sdss has produced the most highimpact papers of any astronomical observatory.c at the same time, the project has extended the ﬁreachﬂ of those wishing to participate in frontier astronomy research or to simply enjoy the ability to ﬁbe thereﬂ as amateur a˚cionados. the public is offered both the raw data of sdss and, at a ﬁskyserverﬂ web site, a range of search tools to help them use the data. teachers are encouraged to adapt the projects for use in the classroom. sdss data also are available through the national virtual observatory (http://www.usvo.org), a collaborative effort involving universities, supercomputer centers, observatories, and data repositories.d even bigger projects are under development. for example, the large synoptic survey telescope (http:/www.lsst.org) that is currently being developed will generate as much data each night as a complete sdss. as the ﬁliving lsst document, version 1.0, of may 15, 2008ﬂ put it: lsst has been conceived as a public facility: the database it will produce, and the associated object catalogs that are generated from that database, will be made available to the world™s astronomical research community and to the public at large with no proprietary period. the software which created the lsst database will be open source. lsst will be a signi˚cant milestone in the globalization of the information revolution. lsst will put terabytes of data each night into the hands of anyone who wants to explore it, and in some sense will become an internet telescope: the ultimate network peripheral device to explore the universe, and a shared resource for all humanity.a alexander szalay and jim gray. 2001. ﬁthe worldwide telescope.ﬂ science 293:2037œ2040.b robert c. kennicutt, jr. 2007. ﬁsloan at ˚ve.ﬂ nature 450:488œ489.c j. p. madrid and f. d. macchetto. 2006. ﬁhighimpact astronomical observatories.ﬂ bulletin of the american astronomical society 38:1286œ1287.d alexander szalay, johns hopkins university, presentation to the committee, december 10, 2008.table 11 data trends in astronomy researchcosmic microwave background (cmb) surveys: collect information used to understand the origin and evolution of the universe yearsurveydata items (pixels)1990cosmic background explorer (cobe) 1,0002000boomerang (balloonborne millimeterwave telescope)10,0002002cosmic background imager (cbi)50,0002003wilkinson microwave anisotropy probe (wmap)1,000,0002009planck10,000,000galaxy surveys: collect two dimensional optical images of galaxies and quasars yearsurveyobjects 1970lick observatory1,000,0001990automatic plate measuring facility (apm)2,000,0002005sloan digital sky survey (sdss)200,000,0002009visible and infrared telescope for astronomy (vista)1,000,000,0002015large synoptic survey telescope (lsst)120,000,000,000galaxy redshift surveys: collect three dimensional optical catalogs of galaxies and quasarsyearsurveyobjects1986center for astrophysics (cfa) 3,5001996las campanas redshift survey (lcrs)23,00020032df galaxy redshift survey 250,0002005sloan digital sky survey (sdss)750,0002007sdss colorredshift survey20,000,0002015lsst colorredshift survey4,000,000,000note: there are 100 billion galaxies in the observable universe, meaning that lsst will record about 20 percent.source: presentation to the committee by alex szalay, johns hopkins university, december 2007, updated in 2008 with comments by tony tyson and michael turner.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 15box 12 digital data in astronomy as astronomical observatories have become more powerful, they also have become more dataintensive.a table 11 shows the trend in recent decades. the sloan digital sky survey (sdss), for example, has delivered an unprecedented ood of data since it began operation in 2000. the sdss uses a dedicated 2.5meter telescope on apache point, new mexico, equipped with two specialpurpose instruments. the telescope™s camera can image 1.5 square degrees of sky at a timešabout eight times the area of the full moon. a pair of spectrographs can measure spectra ofšand hence distances tošmore than 600 galaxies and quasars in a single observation. a customdesigned set of software pipelines keeps pace with the enormous data ow from the telescope. in its ˚rst 5 years of operation, the sloan telescope searched more than 8,000 square degrees of the northern skyšabout a ˚fth of the entire skyšin ˚ve wavelength bands. it recorded some 217 million objects, mostly galaxies, stars, and asteroids, and measured spectra for around 675,000 of these.b with funding from multiple sources and countries, the sdss has followed a policy of freely releasing data annually, with separate web sites for research users and the general public. a recent release, data release 7 (dr7), in november 2008, included some 16 terabytes of images and spectra. its current phase, sdssii, is among the largest astronomical collaborations ever undertaken, involving more than 300 astronomers, astrophysicists, and engineers at 25 institutions around the world. the sdss has helped to revolutionize the interactions between a telescope, its data, and its user communities. because the sdss data archive is available to any astronomer, roughly half of the 2,100 refereed papers based on sdss data have come from authors outside the project itself, and that proportion is rising. in fact, for the past 2 years, the sdss has produced the most highimpact papers of any astronomical observatory.c at the same time, the project has extended the ﬁreachﬂ of those wishing to participate in frontier astronomy research or to simply enjoy the ability to ﬁbe thereﬂ as amateur a˚cionados. the public is offered both the raw data of sdss and, at a ﬁskyserverﬂ web site, a range of search tools to help them use the data. teachers are encouraged to adapt the projects for use in the classroom. sdss data also are available through the national virtual observatory (http://www.usvo.org), a collaborative effort involving universities, supercomputer centers, observatories, and data repositories.d even bigger projects are under development. for example, the large synoptic survey telescope (http:/www.lsst.org) that is currently being developed will generate as much data each night as a complete sdss. as the ﬁliving lsst document, version 1.0, of may 15, 2008ﬂ put it: lsst has been conceived as a public facility: the database it will produce, and the associated object catalogs that are generated from that database, will be made available to the world™s astronomical research community and to the public at large with no proprietary period. the software which created the lsst database will be open source. lsst will be a signi˚cant milestone in the globalization of the information revolution. lsst will put terabytes of data each night into the hands of anyone who wants to explore it, and in some sense will become an internet telescope: the ultimate network peripheral device to explore the universe, and a shared resource for all humanity.a alexander szalay and jim gray. 2001. ﬁthe worldwide telescope.ﬂ science 293:2037œ2040.b robert c. kennicutt, jr. 2007. ﬁsloan at ˚ve.ﬂ nature 450:488œ489.c j. p. madrid and f. d. macchetto. 2006. ﬁhighimpact astronomical observatories.ﬂ bulletin of the american astronomical society 38:1286œ1287.d alexander szalay, johns hopkins university, presentation to the committee, december 10, 2008.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.16 ensuring the integrity, accessibility, and stewardship of datafigure 12 lhc at cern.source: © cern. see http://cdsweb.cern.ch/record/42370.however, the most consequential changes being fostered by digital technologies involve issues that range beyond the quantities of data generated.6 today, researchers can access a rapidly expanding range of digital information from around the world almost instantaneously. they can use this information to analyze their results, as when biologists compare dna sequences they have generated to sequences stored in worldwide databases. they can incorporate information from others with their own data to make discoveries that would otherwise have been impossible, as when epidemiologists combine census and economic data to analyze the prevalence of disease. they can analyze data produced by others to answer questions that could not have been anticipated by the data™s creators, as when astronomers use digital sky surveys to investigate newly recognized phenomena in distant galaxies. for some areas of science, engineering, and medical research in the digital age, carrying out laboratory experiments to corroborate or disprove hypotheses has given way to a process of hypothesis testing based on computational analysis and modeling.the creation of inexpensive, complex sensors is contributing to the data explosion by enabling new research approaches in a variety of elds, particularly in the earth sciences. projects such as the national science foundation™s network for earthquake engineering simulation and national ecological observa6 national research council. 2001. issues for science and engineering researchers in the digital age. washington, dc: the national academies press.figure 12.epsbitmap imagelow resensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 17tory network, as well as the national aeronautics and space administration™s earth observing system, depend heavily on sensor networks.digital technologies also are making possible a new kind of science that depends on simulations combined with experimentation and observation.7 cosmologists can combine simulations of galactic dynamics with astronomical observations of distant galaxies to analyze the early evolution of the universe. records of calls made with cell phones can be compared to mathematical  models of social networks. researchers can model the functions of cells, simulate the effects of modifying those functions, and then recreate these modications in real cells to alter biological function and rene the original models. largescale simulations of natural phenomena can be as valuable as data drawn from observations of the natural world.the advances in research enabled by highperformance computing and highperformance communications are contributing to a steady growth of collaborations and interdisciplinary projects. digital communication technologies enable researchers to communicate and exchange data with colleagues around the world, creating electronic collaborations that can catalyze progress. by making it possible to address more complex and integrative questions, these technologies also catalyze interdisciplinary collaboration. as one indicator of this trend, consider the growth in the number of authors on research papers over time. over the course of 40 years, according to a computerized analysis of millions of published science and engineering papers, the number of authors for papers in the sciences nearly doubled, from 1.9 to 3.5.8 in the environmental sciences, the fraction of papers with multiple authors rose from 25 percent to 82 percent; in economics, it rose from 9 percent to 52 percent.collaborations have also become more international. in 2003, 20 percent of all research publications had authors from more than one country, compared with 8 percent in 1988.9 citations to literature produced outside the author™s home country rose from 42 percent of all citations in 1992 to 48 percent in 2003.however, the most farreaching effects of digital technologies are not evident in traditional measures of research collaboration. researchersšand especially young researchersšare developing new ways to interact with each other and with the subjects they study.10 they exchange information in virtual 7 the 2020 science group. 2006. towards 2020 science. redmond, wa: microsoft corporation. available at http://research.microsoft.com/enus/um/cambridge/projects/towards2020science/downloads/t2020sreporta4.pdf.8 stefan wuchty, benjamin f. jones, and brian uzzi. 2007. ﬁthe increasing dominance of teams in production of knowledge.ﬂ science 316:1036œ1039.9 national science board. 2006. science and engineering indicators 2006. arlington, va: national science foundation.10 carolyn y. johnson. 2008. ﬁout in the open: some scientists sharing results.ﬂ the boston globe, august 21, p. a1.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.18 ensuring the integrity, accessibility, and stewardship of datacommunities, write and read blogs on research developments, and are pioneering new methods to conduct research and share their results. in the long run, these developments are likely to have a more profound effect on research than increases in the pace or scale of traditional practices. these developments can be difcult to foresee. for example, research in many elds is moving toward much more open and collaborative models that are both served and driven by technology, and this trend is likely to result in research environments very different from those that have prevailed in the past. although our committee has not tried to predict the longterm outcomes of this process, ongoing changes can be expected to continue to transform how research is done and how researchers interact with each other.the rapid spread of digital technologies also is transforming the relationship between researchers and the broader public that supports and expects to benet from research. when research results that underlie important public policies are available electronically, they can be examined and questioned by any member of the public. individuals interested in specic issuesšwhether the regulation of an environmental toxin or the development of therapies for a human diseasešcan monitor, comment on, and even shape ongoing research.similarly, digital technologies have profound implications for scientic, engineering, and medical education.11 students can have access to research information from instruments in distant locations.12 computer owners around the world can contribute to the solution of particular research problems by allowing their computers to become parts of distributed computational networks.13 data from cuttingedge research are being made available on the internet for use not only by the research community but by educators or anyone else interested in the subject.14 members of the public are participating in research projects as varied as analyses of genetic variation and galactic structure.15 although fascinating, the full consequences of changing technologies for scientic, engineering, and medical education or for direct public participation in research lie outside the scope of this report.11 national research council. 2002. preparing for the revolution: information technology and the future of the research university. washington, dc: the national academies press.12 an example is the education and outreach project of the national virtual observatory (http://www.virtualobservatory.org).13 an example is the seti@home project (http://setiathome.berkeley.edu), which uses computer time provided by volunteers to analyze astronomical data for signs of intelligence.14 ryan scranton, andrew connolly, simon krughoff, jeremy brewer, alberto conti, carol christian, craig sosin, greg coombe, and paul heckbert. 2007. ﬁsky in google earth: the next frontier in astronomical data discovery and visualization.ﬂ available at http://arxiv.org/pscache/arxiv/pdf/0709/0709.0752v2.pdf.15 for the analysis of genetic variation, see https://www3.nationalgeographic.com/genographic. for the analysis of galactic structure, see http://www.galaxyzoo.org.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 19challenges posed by research data in a digital agerapid advances in computing and communication technologies have changed the professional responsibilities, interpersonal interactions, and daily practices of researchers. many of these changes have strengthened the research enterprise, both by enabling researchers to ask new questions of nature and by providing new means of achieving research objectives. at the same time, some changes have raised important issues involving researchers, research institutions, sponsors, and journals.16 these issues are the focus of this report on the integrity, accessibility, and stewardship of research data.as discussed in chapter 2, although advances in digital technologies allow phenomena and objects to be described more comprehensively and accurately, they also can complicate the process of verifying the accuracy and validity of the data (see box 13 for an example). digital technologies require the translation of phenomena and objects into digital representations, which can introduce inaccuracies into the data. digital data often undergo several layers of complex processing as they move from an instrument or sensor to the point of being reviewed by a researcher. if this processing is not properly done or is misunderstood, the results can be misleading. in some cases, researchers may intentionally or unintentionally distort data in a misguided attempt to emphasize particular features and downplay others. in the worst cases, researchers can falsify or fabricate data, thereby violating both the ethical and methodological standards of research integrity. many of these considerations apply as well to data that are not generated or stored digitally, but digital technologies both expand and intensify the challenge of maintaining the integrity of data.chapter 3 describes the challenges that researchers face in maintaining the traditional openness of research in a digital age. electronic technologies provide researchers with many new ways of communicating data to others, but providing other researchers with access to large databases can be difcult and expensive. with smaller, heterogeneous databases, where quality control and documentation tend to be less formal, sociological and technological factors can restrict data sharing. also, an increasing range of restrictions are being placed on research data as this information becomes more valuable for commercial uses, which can limit the distribution and utilization of data within and beyond the research community.even as more research data are being created, their value for future uses is increasing. chapter 4 describes the need to preserve many research data for longterm use, even in situations where those uses cannot be currently envisioned. digital storage technologies, application environments, and operating systems change every few years, which means that digital bits must continually 16 national research council. 2001. issues for science and engineering researchers in the digital age, washington, dc: national academy press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.20 ensuring the integrity, accessibility, and stewardship of databox 13 digital data in the neurosciences the neurosciences illustrate both the potential value of wellorganized and accessible data and the variety of issues raised by the increased importance of data handling and data sharing. it is not surprising that the neurosciences are rich in the use of and need for data, given the complexity of the nervous system. the brain has roughly a hundred billion neurons and more than 1,000 subdivisions, each with different structures and circuitry. in the past, neurological research has depended heavily on autopsy for clues about function and structure. now it relies heavily on in vivo imaging methods and computational models, both of which depend on computing power and mathematical techniques. this new universe of neuroscience data is too vast and complex for manual analysis. largescale detailed maps of the brain can require some 25 gigabytes of memory per image. also, neuroscientists must work across multiple scales of resolution because they do not yet know which levels are critical for many neurological processes. they must integrate such diverse datasets as cellular neuroimaging, gene expression data, genotype data, neuronal morphology, and clinical data. making neuroscience data widely available holds tremendous potential for helping science and society. this includes:facilitating replication and validation of experimental results,promoting collective analyses of large numbers of experiments by different groups,improving communication within and between groups, andpromoting collaboration. several very effective databases have been developed in the neurosciences. they include:the cell centered database, started in 2002, makes twodimensional and threedimensional static and dynamic microscopic data available to the research community. it also links data obtained at cellular and subcellular scales to molecular and higher order structure. it is built on the biomedical informatics research network and telescience grid infrastructure for distributed collaboration.sumsdb is a repository of brainmapping data, including surfaces and volumes, with both structural and functional data. it includes more than 500 studies on monkeys, rodents, apes, humans, and others, totaling about 10 percent of the published literature. it also includes a data mining tool called webcaret so that sumsdb can be searched online without downloading. its designers have made attempts to provide metadata and show the source of data, including links to online publications. many questions have arisen in developing these and other databases. which digital data and data stored on ˚lm need to be stored? do calibrations (i.e., the characterization of an instrument™s response to known stimulus) need to be stored, and if so which ones? should proprietary tools be stored so that users can see how the primary data were processed? for now, there is reason to err on the side of depositing too much data, because no one knows what subsequent researchers will need. however, it is likely that just a small percentage of databases will ˚nd widespread use, which complicates, rather than simpli˚es, the task of storage. complex databases always include errors. obvious errors, such as coordinates that lie outside the brain, can be found more easily when data are shared. however, policing data before they are added to a database can be so timeintensive that it can discourage database building. fortunately, new technologies for assuring the quality of data based on advances in such areas as pattern recognition and learning theory, combined with rapid advances in data processing and storage, are providing new and automated methods for testing the quality of data. another problem is that most data assigned to databases in the neurosciences are not adequately annotated, and even those with annotation tend to use nonstandard terminology, making them ﬁislandsﬂ of diverse resources. such databases may not be useful for comparative studies or other purposes. issues of who has rights to use data also are far from resolved. a researcher may work for 5 years to assemble data on a transgenic mouse and be reluctant to give the data away. to make data open and accessible, incentives may need to be developed to encourage scientists to share their data. another issue is whether journals may be responsible for receiving and storing all primary or supplementary data. most publications lack a suitable place to enter and store supplementary data, and who should pay for this service remains unresolved. these issues, most of which we discuss later in this report, are being extensively explored in the research and policymaking communities. many questions do not yet have clear answers that extend across all research disciplines.source: this box draws on presentations to the committee by david van essen, washington university in st. louis, and maryann martone, university of california, san diego on december 10, 2007.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 21box 13 digital data in the neurosciences the neurosciences illustrate both the potential value of wellorganized and accessible data and the variety of issues raised by the increased importance of data handling and data sharing. it is not surprising that the neurosciences are rich in the use of and need for data, given the complexity of the nervous system. the brain has roughly a hundred billion neurons and more than 1,000 subdivisions, each with different structures and circuitry. in the past, neurological research has depended heavily on autopsy for clues about function and structure. now it relies heavily on in vivo imaging methods and computational models, both of which depend on computing power and mathematical techniques. this new universe of neuroscience data is too vast and complex for manual analysis. largescale detailed maps of the brain can require some 25 gigabytes of memory per image. also, neuroscientists must work across multiple scales of resolution because they do not yet know which levels are critical for many neurological processes. they must integrate such diverse datasets as cellular neuroimaging, gene expression data, genotype data, neuronal morphology, and clinical data. making neuroscience data widely available holds tremendous potential for helping science and society. this includes:facilitating replication and validation of experimental results,promoting collective analyses of large numbers of experiments by different groups,improving communication within and between groups, andpromoting collaboration. several very effective databases have been developed in the neurosciences. they include:the cell centered database, started in 2002, makes twodimensional and threedimensional static and dynamic microscopic data available to the research community. it also links data obtained at cellular and subcellular scales to molecular and higher order structure. it is built on the biomedical informatics research network and telescience grid infrastructure for distributed collaboration.sumsdb is a repository of brainmapping data, including surfaces and volumes, with both structural and functional data. it includes more than 500 studies on monkeys, rodents, apes, humans, and others, totaling about 10 percent of the published literature. it also includes a data mining tool called webcaret so that sumsdb can be searched online without downloading. its designers have made attempts to provide metadata and show the source of data, including links to online publications. many questions have arisen in developing these and other databases. which digital data and data stored on ˚lm need to be stored? do calibrations (i.e., the characterization of an instrument™s response to known stimulus) need to be stored, and if so which ones? should proprietary tools be stored so that users can see how the primary data were processed? for now, there is reason to err on the side of depositing too much data, because no one knows what subsequent researchers will need. however, it is likely that just a small percentage of databases will ˚nd widespread use, which complicates, rather than simpli˚es, the task of storage. complex databases always include errors. obvious errors, such as coordinates that lie outside the brain, can be found more easily when data are shared. however, policing data before they are added to a database can be so timeintensive that it can discourage database building. fortunately, new technologies for assuring the quality of data based on advances in such areas as pattern recognition and learning theory, combined with rapid advances in data processing and storage, are providing new and automated methods for testing the quality of data. another problem is that most data assigned to databases in the neurosciences are not adequately annotated, and even those with annotation tend to use nonstandard terminology, making them ﬁislandsﬂ of diverse resources. such databases may not be useful for comparative studies or other purposes. issues of who has rights to use data also are far from resolved. a researcher may work for 5 years to assemble data on a transgenic mouse and be reluctant to give the data away. to make data open and accessible, incentives may need to be developed to encourage scientists to share their data. another issue is whether journals may be responsible for receiving and storing all primary or supplementary data. most publications lack a suitable place to enter and store supplementary data, and who should pay for this service remains unresolved. these issues, most of which we discuss later in this report, are being extensively explored in the research and policymaking communities. many questions do not yet have clear answers that extend across all research disciplines.source: this box draws on presentations to the committee by david van essen, washington university in st. louis, and maryann martone, university of california, san diego on december 10, 2007.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.22 ensuring the integrity, accessibility, and stewardship of databe transferred from one storage platform and software environment to another if they are not to be lost. digital data also need to be annotated in sufcient detail that future researchers, sometimes in elds well removed from those of the data™s original creators, can both use the data and understand their limitations. maintaining data collections for longterm use thus requires continued investment and planning, which can compete with expenditures for ongoing research.descriptions of terms used in the reportin describing issues as broad as those covered in this report, it is essential to have clear understanding of the basic terms. research datadespite the importance of research data, there exists no standard or widely accepted denition of exactly what research data are. for the purposes of this report, we have treated data as information used in scientic, engineering, and medical research as inputs to generate research conclusions (see box 14 for denitions from other reports). this usage encompasses a wide variety of information. it includes textual information, numeric information, instrumental readouts, equations, statistics, images (whether xed or moving), diagrams, and audio recordings. it includes raw data, processed data, published data, and archived data. it includes the data generated by experiments, by models and simulations, and by observations of natural phenomena at specic times and locations. it includes data gathered specically for research as well as information gathered for other purposes that is then used in research. it includes data stored on a wide variety of media, including magnetic and optical media.17though our concerns in this report lie largely with the application of digital technologies in research, our examination of the issues is not limited to  digital data. nor does this report address just those areas traditionally considered ﬁscience.ﬂ it applies to all efforts to derive new knowledge about the physical, biological, or social worlds and thus encompasses research in engineering and in all of the physical, biological, behavioral, and social sciences. the conclusions in the report generally apply to quantitative data. however, many of our conclusions also apply to qualitative data, though we have not focused on the issues unique to qualitative data. also, this report does not address research in the humanities, which lies outside the committee™s charge and expertise.17 as a point of comparison, the ofce of management and budget denes research data as ﬁthe recorded factual material commonly accepted in the scientic community as necessary to validate research ndings, but not any of the following: preliminary analyses, drafts of scientic papers, plans for future research, peer reviews, or communications with colleagues. this ﬁrecordedﬂ  material excludes physical objects (e.g., laboratory samples).ﬂ see omb circular a110 at http://www.whitehouse.gov/omb/circulars/a110/a110.html.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 23box 14 definitions of ﬁresearch dataﬂ from other reportsﬁdata are facts, numbers, letters, and symbols that describe an object, idea, condition, situation, or other factors.ﬂa ﬁa reinterpretable representation of information in a formalized manner suitable for communication, interpretation, or processing. examples of data include a sequence of bits, a table of numbers, the characters on a page, the recording of sounds made by a person speaking, or a moon rock specimen.ﬂb ﬁany information that can be stored in digital form, including text, numbers, images, video or movies, audio, software, algorithms, equations, animations, models, simulations, etc. such data may be generated by various means including observation, computation, or experiment.ﬂc a national research council. 1999. a question of balance: private rights and the public interest in scientic and technical databases. washington, dc: national academy press, p. 15.b consultative committee for space data systems. 2002. reference model for an open archival information system (oais). washington, dc: national aeronautics and space administration, p. 19. available at http://public.ccsds.org/publications/archive/650x0b1.pdfc national science board. 2005. longlived data collections: enabling research and education in the 21st century. arlington, va: national science foundation, p. 13. the term ﬁdataﬂ in this report excludes physical objects (including living organisms) and other materials used in research, such as biological reagents or the devices, instruments, or computers that generate experimental or observational data. in many cases, these physical objects can be described in written, numeric, or visual forms, and these descriptions constitute data. however, because materials are tangible whereas data are generally intangible, different issues surround their use, storage, and dissemination. some of the observations and conclusions in this report apply to materials as well as to data, and on occasion we make this extension of our conclusions explicit. however, the treatment of materials in research introduces issues that are beyond the subject matter of this report.18finally, our denition excludes information that can be important in research but is not used to generate research conclusions, including interpre18 issues related to sharing research materials in the life sciences have been addressed by a previous national research council report. see national research council. 2003. sharing publicationrelated data and materials: responsibilities of authorship in the life sciences. washington, dc: the national academies press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.24 ensuring the integrity, accessibility, and stewardship of datative statements, or matters of personal judgment, such as peer reviews, plans for future research, communications with colleagues, or personnel assessments. of course, the line between research data and subjective judgments is sometimes difcult to draw, since subjective judgments can in˚uence the structure ascribed to data. nevertheless, a distinction exists, and we do not mean to imply that all of the information associated with research necessarily constitutes research data.metadataas used in this report, the term ﬁmetadataﬂ refers to descriptions of the content, context, and structure of information objects, including research data, at any level of aggregation (for example, a single data item, many items, or an entire database). according to the national science foundation report cyberinfrastructure vision for the 21st century, metadata ﬁsummarize data content, context, structure, interrelationships, and provenance (information on history and origins). they add relevance and purpose to data, and enable the identication of similar data in different data collections.ﬂ19 metadata make it easier for data users to nd and utilize data, particularly if they are machinereadable.metadata are extremely diverse, ranging from written descriptions of instruments and software to the largely tacit knowledge on which the success of an investigation often depends. they are a critical part of the context needed to assess the integrity of data and use data accurately. metadata are themselves data, since they consist of descriptive, factual information about data. thus, conclusions about data in this report generally apply to metadata as well, although special considerations sometimes apply to metadata.until fairly recently, the term ﬁmetadataﬂ was used primarily by the library community and by individual research communities.20 as digital data has become more important in a variety of disciplines and elds, the scope and value of metadata have grown, leading to the development of metadata standards. metadata standards represent an agreed set of terminologies, denitions, and values to be provided for data in a given eld or community.2119 nsf cyberinfrastructure council (2005), nsf™s cyberinfrastructure vision for 21st century discovery, arlington, va, national science foundation.20 tony gill, anne j. gilliland, maureen whalen, and mary s. woodley. 2008. introduction to metadata, version 3.0. los angeles, ca: j. paul getty trust. available at www.getty.edu/research/conductingresearch/standards/intrometadata/index.html.21 u.s. geological survey, coastal and marine biology infobank. usgscmgﬁformalmetausgs cmg ﬁformal metadataﬂ denition. seewalrus.wr.usgs.gov/infobank/programs/html/denition/fmeta.html.accessedsee walrus.wr.usgs.gov/infobank/programs/html/denition/fmeta.html. accessed december 8, 2008.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 25raw and processed dataraw data directly from an instrument or data that have not been documented or processed usually are of little value to anyone except the individuals who generate or collect them. in many elds, capturing data that are ﬁwholeﬂ or ﬁperfectﬂ may be difcult or impossible. instruments may only partially and imperfectly record phenomena. researchers may not even see the raw data on which their conclusions are based. in some cases, raw data may exist in a computer buffer for only a fraction of a second before they undergo processing. in other cases, raw data may be so voluminous that they cannot be examined in anything other than a processed or condensed form. however, raw data may need to be retained to validate research ndings and, in some research elds, to support patent applications, investigate instances of research misconduct, or justify public policies.data used to draw conclusions, derive ndings, and build models may undergo many changes as they are processed, distributed, and archived. they are analyzed, aggregated, and reformulated by researchers. data often are organized into structures for longterm storage and access that require the expertise of professionals trained in the management and handling of large databases.as soon as raw data are processed, the algorithms, computer programs, and other techniques used in that processing become crucial to their understanding. many data cannot be properly interpreted or used without understanding the processing they have undergone, and it is generally impossible to judge the integrity of processed data without access to the metadata documenting how they were processed. in some cases, this processing may be so machine dependent that the metadata must include either a thorough representation or a copy of the devices used to do the processing. consequently, to judge the accuracy and validity of data, researchers, policy makers, and other users of data may need a thorough understanding of the tools and procedures used to analyze those data. in many cases, a high level of expertise is needed to use metadata in order to place data in context.given the relatively broad denitions of data and metadata that we have adopted in this report, a great many issues are obviously associated with the generation, use, dissemination, and preservation of research data in the digital age. in this report, however, we focus on three specic issues, which we describe using the terms integrity, accessibility, and stewardship.integrityintegrity describes an uncompromising adherence to ethical values, strict honesty, and absolute avoidance of deception. integrity also describes the state of being whole and complete, of being totally unimpaired. thus, the word ﬁintegrityﬂ has both an ethical meaning and a structural or methodological meaning. in this report we use the word ﬁintegrityﬂ in both senses.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.26 ensuring the integrity, accessibility, and stewardship of dataaccording to one denition, ﬁbeing assured of data™s integrity means having condence that the data are complete, veried, and remain unaltered.ﬂ22 this is possible only if researchers adhere to professional and ethical standards of their elds. in some research elds, these standards are written, but in many areas they exist as tacit knowledge that is passed from senior researchers to beginning researchers over the course of a research apprenticeship. these professional standards, in turn, describe the methods, procedures, and tools that researchers are expected to employ to minimize error and bias in their work. consequently, integrity in research has both an individual and a communal meaning. researchers maintain the integrity of research data by adhering to the professional standards of their elds.researchers are expected to describe their methods and tools to others in sufcient detail that the data can be checked and the results veried. completely and accurately describing the conditions under which data are collected, characterizing the equipment used and its response, and recording anything that was done to the data thereafter are critical to ensuring data integrity. thus, for experimental data, integrity implies that the data can be reproduced in a test or experiment that repeats the conditions of the original test or experiment. for observational data, data of high ﬁqualityﬂ (a term that we sometimes will use as a synonym for data integrity) have been validated through comparison with data whose quality is known or by being generated with an instrument that has been adequately calibrated or tested.accessibilityin this report, accessibility refers to the availability of research data to researchers other than those who generated the data. accessibility is a critical element of integrity, because data must be available to others in order for the validity of those data to be veried. however, in some cases an investigator may not be able to make data available to the public. for example, in private companies, data may need to be restricted for commercial reasons. in such cases, data are frequently made available within the company to evaluate their integrity.in this report, the term ﬁaccessibilityﬂ generally implies public access as well as availability to other researchers upon request. accessibility does not necessarily imply free access, because providing access to data entails nancial costs that must be met. also, access does not necessarily imply that researchers must provide inquirers with the training and expertise they would need to understand or use data. however, data should be accompanied by sufcient metadata for colleagues to assess the integrity of those data.22 university of minnesota research data management online workshop (www.research.umn.edu/datamgtq1/mdi020.html).ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 27stewardshipin the broadest possible sense, the term ﬁutilityﬂ in the name of our committee refers to all of the various applications of research data. both integrity and accessibility are critical elements of utility, because research data must have integrity and be broadly accessible to be effectively utilized.however, our focus in this report is on a specic aspect of utility that we refer to as data stewardshipšthe longterm preservation of data so as to ensure their continued value, sometimes for unanticipated uses. stewardship goes beyond simply making data accessible. it implies preserving data and metadata so that they can be used by researchers in the same eld and in elds other than that of the data™s creators. it implies the active curation and preservation of data over extended periods, which generally requires moving data from one storage platform to another. the term ﬁstewardshipﬂ embodies a conception of research in which data are both an end product of research and a vital component of the research infrastructure.the varieties of research dataas the examples presented throughout this report illustrate, research data are so varied that they can be described in their entirety only in the most general terms. different research elds have very different approaches to the treatment of research data. even at the level of individual research groups, expectations and demands can vary greatly from one investigator to another. this tremendous variety within the research community complicates the task of arriving at conclusions that apply across all elds of research. research elds are also characterized by diversity in the origins of data and by the size and other characteristics of data collections.diversity across disciplinesthere is great diversity in the ways data are gathered and analyzed both among and within disciplines. the sidebars in this and other chapters describe some of the diversity among disciplines, but individual disciplines also harbor great diversity in the ways data are gathered and analyzed. data in physics, for example, range from small datasets generated by a ﬁtabletopﬂ experiment to the terabytes of data generated by an acceleratorbased experiment. databases in the social sciences may be freely available to all researchers in some elds and tightly restricted in other elds. some elds within a discipline may have traditions of storing data for extended periods while others discard data relatively quickly. (in this report, ﬁeldﬂ refers to an area of research smaller than a discipline. in many cases, a eld can be roughly associated with the community of researchers who follow and publish articles in a relatively small collection ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.28 ensuring the integrity, accessibility, and stewardship of dataof related journalsšwhat analysts of science have referred to as ﬁinvisible colleges.ﬂ23)furthermore, some of the most interesting and productive areas of research today involve researchers from multiple disciplines working together on complex, integrative problems.24 in some cases, these areas of multidisciplinary research become so well dened that they evolve into research elds of their own, as in astrobiology. in other cases, researchers may come together to work on a multidisciplinary project and then disband once the project is over. in interdisciplinary research, different traditions of data treatment meet and sometimes clash, and new ways to gather, analyze, and store data may need to be developed to address novel challenges.diversity in origins of datathe practices for analyzing, disseminating, and storing research data vary greatly from eld to eld.25 for example, in some elds, observational data can be recreated by other researchers, but in other elds observations are impossible or impractical to make a second time. in these cases, observational data may need to be carefully archived for future use, including uses that cannot currently be foreseen.data generated through computer simulations are increasingly important in a variety of elds.26 data generated entirely by computation can in principle be regenerated, assuming that enough is known about the hardware, software, and inputs used in the computation. however, each of these three components of a computation may be so complex or indeterminate that the computational data have some of the characteristics of observational data. furthermore, many simulations involve random inputs, so that successive simulations will not be exactly the same. in some cases, sharing and preserving the models and software tools used to create a simulation will be more important for verifying and building upon research than sharing and preserving the data generated. in other cases, the data themselves have value and can represent such a large investment of resources that they may need to be preserved for subsequent use in the same way that unique observational data are preserved. 23 daryl e. chubin. 1983. sociology of sciences: an annotated bibliography on invisible colleges, 1972œ1981. new york: garland.24 national academy of sciences, national academy of engineering, and institute of medicine. 2005. facilitating interdisciplinary research. washington, dc: the national academies press.25 national research council. 1995. preserving scientic data on the physical universe: a new strategy for archiving our nation™s scientic information. washington, dc: national academy press.26 ghaleb abdulla, terence critchlow, and william arrighi. 2004. ﬁsimulation data as data streams.ﬂ sigmod record 33(1):89œ94.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 29data from experiments may be reproducible if a robust description of the experiment is available. in practice, however, it may not be possible to recreate the exact conditions of the experiment. an experimental apparatus also may be so costly to build or use that experiments can be conducted only once or over a limited time period. if so, longterm preservation of the data generated by the experiment may be essential for optimizing the experiment™s value.diversity in types of data collectionsin this report, we use the term ﬁdatabaseﬂ to refer to a collection of data that is organized to permit search, retrieval, processing, and reorganization of stored information. databases include datasets, which are collections of similar or related data. we use the term ﬁdata collectionﬂ interchangeably with ﬁdatabase.ﬂin its report longlived data collections: enabling research and education in the 21st century, the national science board divided data collections into three broad categories (box 15).27 ﬁresearch collectionsﬂ are the products of one or more focused research projects and typically serve just the research group that generated the data. ﬁresource collectionsﬂ serve a single science or engineering community and are generally intermediate in size and budget. ﬁreference collectionsﬂ serve large segments of the research and education communities and are often supported by large budgets.these categories may seem to correspond to smallscale research, intermediatesized research projects, and largescale research, but the national  science board™s report shows that such an association can be misleading. using digital technologies, relatively smallscale projects can generate immense quantities of data that become the basis for research in many related elds. largescale reference data collections may be the product of many small projects linked through digital networks. or large projects may produce focused data collections that serve a narrow research purpose and never become publicly available. thus, distinguishing research data by the size of the group that generated those data is problematicšin part because of new capabilities created by digital technologies.structure of the reportthe remainder of this report is organized into three thematic chapters and a nal summary chapter. chapter 2 considers the integrity of data throughout their life cycle, from their collection to their disposal or preservation. maintaining the integrity of research data is a fundamental obligation of researchers; 27 national science board. 2005. longlived data collections: enabling research and education in the 21st century. arlington, va: national science foundation.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.30 ensuring the integrity, accessibility, and stewardship of databox 15 three types of data collections the national science board (nsb) has organized data collections into the three categories described below. in addition, the nsb de˚ned ﬁcollectionﬂ to refer ﬁnot only to stored data but also to the infrastructure, organizations, and individuals necessary to preserve access to the data.ﬂ research data collections are the products of one or more focused research  projects and typically contain data that are subject to limited processing or curation. they may or may not conform to community standards, such as standards for ˚le formats, metadata structure, and content access policies. quite often, applicable standards may be nonexistent or rudimentary because the data types are novel and the size of the user community [is] small. research collections may vary greatly in size but are intended to serve a speci˚c group, often limited to immediate participants. there may be no intention to preserve the collection beyond the end of a project. one reason for this is funding. these collections are supported by relatively small budgets, often through research grants funding a speci˚c project. (example: the fluxes over snow surfaces project, http://www.atd.ucar.edu/rtf/projects/floss.) resource or community data collections serve a single science or engineering community. these digital collections often establish communitylevel standards either by selecting from among preexisting standards or by bringing the community together to develop new standards where they are absent or inadequate. the budgets for resource or community data collections are intermediate in size and generally are provided through direct funding from agencies. because of changes in agency priorities, it is often dif˚cult to anticipate how long a resource or community data collection will be maintained. (example: the arabidopsis information resource, http://www.arabidopsis.org.) reference data collections are intended to serve large segments of the research and education community. characteristic features of this category of digital collections are a broad scope and a diverse set of user communities including scientists, students, and educators from a wide variety of disciplinary, institutional, and geographical settings. in these circumstances, conformance to robust, wellestablished, and comprehensive standards is essential, and the selection of standards by reference collections often has the effect of creating a universal standard. budgets supporting reference collections are often large, reecting the scope of the collection and breadth of impact. typically, the budgets come from multiple sources and are in the form of direct, longterm support, and the expectation is that these collections will be maintained inde˚nitely. (example: protein data bank, http://www.pdb.org.)source: national science board (2005), longlived data collections: enabling research and education in the 21st century, arlington, va, national science foundation.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.research data in the digital age 31achieving this objective in the digital age can be either easier or more difcult than in earlier times.chapter 3 considers the issues of accessing and sharing research data. the research enterprise is built on the precept that researchers will make the data on which publicly disseminated conclusions are based available to their colleagues so that others can verify and build on those data. accessibility is vital for ensuring the integrity of research data and facilitating their future use.chapter 4 discusses the stewardship of research data, that is, their longterm preservation in databases for various future research uses and other applications. preserving data collections can be expensive and difcultšso much so that it can compete with the conduct of research. yet the loss of many kinds of research data also can incur substantial costs.the nal chapter reorganizes recommendations that have appeared earlier in the volume according to different actors within the research community rather than thematically. it also discusses how action can be motivated when responsibility for research integrity, accessibility, and stewardship is shared across the components of the research community. each part of the research enterprise has much to gain or lose, depending on how research data are managed, and each has a role to play in ensuring the integrity, accessibility, and stewardship of research data.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.2ensuring the integrity of research datathe elds of science span the totality of natural phenomena and their styles are enormously varied. consequently, science is too broad an enterprise to permit many generalizations about its conduct. one theme, however, threads through its many elds: the primacy of scrupulously recorded data. because the techniques that researchers employ to ensure the truth and accuracy of their data are as varied as the elds themselves, there are no universal procedures for achieving technical accuracy. there are, however, some broadly accepted practices for pursuing science. in most elds of science, for instance, experimental observations must be shown to be reproducible in order to be creditable.1 other practices include checking and rechecking data to ensure that the interpretation is valid, and also submitting the results to peer review to further conrm that the ndings are sound. yet other practices may be employed only within specic elds, for instance, the use of doubleblind trials, or the independent verication of important results in separate laboratories.although the pervasive use of highspeed computing and communications in research has vastly expanded the capabilities of researchers, if used  inappropriately or carelessly, digital technologies can lower the quality of data and compromise the integrity of research.2 digitization may introduce spurious information into a representation, and complex digital analyses of data can yield misleading results if researchers are not scrupulously careful in monitoring and understanding the analysis process. because so much of the processing 1 even this fundamental principle can have exceptions. for instance, observations with a historical element, such as the explosion of a supernova or the growth of an epidemic, cannot be reproduced.2 the challenges of maintaining data integrity over the long term, including the decay of physical storage media and improper manipulation of archived data, are discussed in chapter 4.33ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.34 ensuring the integrity, accessibility, and stewardship of dataand communication of digital data are done by computers with relatively little human oversight, erroneous data can be rapidly multiplied and widely disseminated. some projects generate so much data that signicant patterns or signals can be lost in a deluge of information. as an example of the challenges posed by digital research data, box 21 explores these issues in the context of particle physics research.because digital data can be manipulated more easily than can other forms of data, digital data are particularly susceptible to distortion. researchersšand othersšmay be tempted to distort data in a misguided effort to clarify results. in the worst cases, they may even falsify or fabricate data.box 21 digital data in particle physics from the invention of digital counting electronics in the early days of nuclear physics, to the creation of the world wide web and the data acquisition technology for the large hadron collider (lhc), particle physics has been a major innovator of digital data technology. the lhc, which recently came into operation at the european center for nuclear research (cern) in geneva, has spawned a new generation of data processing. the accelerator collides two beams of protons, resulting in about a billion protonproton collisions every second. these collisions occur at several points around the 27km circumference of the circular accelerator. this ˚rst step of the process is dif˚cult enough to imagine, but the next steps are even more amazing. part of the energy carried by the two colliding protons is converted into matter by fundamental processes of nature. some of these processes are well understood, but others might represent major discoveries that could deepen our understanding of the universešfor instance, the creation of particles that constitute the socalled dark matter inferred from astrophysical measurements. the spray of energetic outgoing particles from one such collision is called an event. the particles in the spray have speeds approaching the speed of light. they y out of the protonproton collision point into a surrounding region that is instrumented with an array of sophisticated particle detection devices, collectively called a detector. the detector senses the passage of subatomic particles, creating a detailed electronic image of the event and providing quantitative information about each particle such as its energy and its relation to certain other particles. each protonproton collision generates about 1 megabyte of information, yielding a total rate of 1 petabyte per second. it is not practical to record this staggering amount of information, and so the experimenters have devised techniques for rapidly selecting the most promising subset of the data for exhaustive analysis. only a tiny fraction of the delugešperhaps one in a trillionšwill be due to new kinds of physical processes of fundamental importance. once the detector has recorded an event, a highspeed system performs a rapid analysis (within 3 microseconds) that retains typically 1 in 30,000 of all events. a second rapid analysis step reduces the rate of permanently recorded data down to about 100 events per second. research at the lhc is carried about by international collaborations that construct, operate, and analyze the data from each of the four main detectors. the scale of the research borders on the fantastic: two of the collaborations each have about 2,000 members from 40 different countries; the volume of the atlas detector, for example, is about half that of notre dame cathedral, and the mass of iron in its gigantic solenoid magnet is approximately that in the eiffel tower. lhc detectors are complex systems that require meticulous calibration, alignment, and quality control procedures. the data from an lhc detector ow from the arrays of devices that track the particles emitted when the protons collide. the data processing system determines the momentum and energy of each particle radiated from a collision, and identi˚es how the particles are correlated in space and time. the thousands of detection devices, the magnetic ˚eld in which the collisions occur, and the properties of the complex digital data acquisition system must all be known accurately. the complexities of data analysis in lhc experiments are comparable to those of the apparatus itself. ensuring the integrity of data from a particle physics experiment presents special challenges because no form of traditional peer review would be suf˚cient. the experiments are so complicated that a knowledgeable outsider who attempted to evaluate the performance of the detection system would require years for the job. consequently, the particle physics community has developed a method for reliable internal quality assurance that goes beyond straightforward peer review. as part of each major collaboration, multiple dataanalysis teams work to evaluate the performance of the apparatus and analyze the data independently, withholding their ˚nal results until the latest possible moment. in effect, in the particle physics community a major portion of the role that was traditionally played by straightforward peer review has been augmented by a process of critical selfanalysis.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 35as an example of how digital data can be inappropriately manipulated, consider the case of digital images in cell biology. when the journals published by the rockefeller university press, including the journal of cell biology, adopted a completely electronic work ˚ow in 2002, the editors gained the ability to check images for changes in ways that were not possible previously. the journal of cell biology, in consultation with the research community it serves, therefore adopted a policy that specied its expectations and procedures:no specic feature within an image may be enhanced, obscured, moved, removed, or introduced. the grouping of images from different parts of the same gel, or from difbox 21 digital data in particle physics from the invention of digital counting electronics in the early days of nuclear physics, to the creation of the world wide web and the data acquisition technology for the large hadron collider (lhc), particle physics has been a major innovator of digital data technology. the lhc, which recently came into operation at the european center for nuclear research (cern) in geneva, has spawned a new generation of data processing. the accelerator collides two beams of protons, resulting in about a billion protonproton collisions every second. these collisions occur at several points around the 27km circumference of the circular accelerator. this ˚rst step of the process is dif˚cult enough to imagine, but the next steps are even more amazing. part of the energy carried by the two colliding protons is converted into matter by fundamental processes of nature. some of these processes are well understood, but others might represent major discoveries that could deepen our understanding of the universešfor instance, the creation of particles that constitute the socalled dark matter inferred from astrophysical measurements. the spray of energetic outgoing particles from one such collision is called an event. the particles in the spray have speeds approaching the speed of light. they y out of the protonproton collision point into a surrounding region that is instrumented with an array of sophisticated particle detection devices, collectively called a detector. the detector senses the passage of subatomic particles, creating a detailed electronic image of the event and providing quantitative information about each particle such as its energy and its relation to certain other particles. each protonproton collision generates about 1 megabyte of information, yielding a total rate of 1 petabyte per second. it is not practical to record this staggering amount of information, and so the experimenters have devised techniques for rapidly selecting the most promising subset of the data for exhaustive analysis. only a tiny fraction of the delugešperhaps one in a trillionšwill be due to new kinds of physical processes of fundamental importance. once the detector has recorded an event, a highspeed system performs a rapid analysis (within 3 microseconds) that retains typically 1 in 30,000 of all events. a second rapid analysis step reduces the rate of permanently recorded data down to about 100 events per second. research at the lhc is carried about by international collaborations that construct, operate, and analyze the data from each of the four main detectors. the scale of the research borders on the fantastic: two of the collaborations each have about 2,000 members from 40 different countries; the volume of the atlas detector, for example, is about half that of notre dame cathedral, and the mass of iron in its gigantic solenoid magnet is approximately that in the eiffel tower. lhc detectors are complex systems that require meticulous calibration, alignment, and quality control procedures. the data from an lhc detector ow from the arrays of devices that track the particles emitted when the protons collide. the data processing system determines the momentum and energy of each particle radiated from a collision, and identi˚es how the particles are correlated in space and time. the thousands of detection devices, the magnetic ˚eld in which the collisions occur, and the properties of the complex digital data acquisition system must all be known accurately. the complexities of data analysis in lhc experiments are comparable to those of the apparatus itself. ensuring the integrity of data from a particle physics experiment presents special challenges because no form of traditional peer review would be suf˚cient. the experiments are so complicated that a knowledgeable outsider who attempted to evaluate the performance of the detection system would require years for the job. consequently, the particle physics community has developed a method for reliable internal quality assurance that goes beyond straightforward peer review. as part of each major collaboration, multiple dataanalysis teams work to evaluate the performance of the apparatus and analyze the data independently, withholding their ˚nal results until the latest possible moment. in effect, in the particle physics community a major portion of the role that was traditionally played by straightforward peer review has been augmented by a process of critical selfanalysis.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.36 ensuring the integrity, accessibility, and stewardship of dataferent gels, elds, or exposures must be made explicit by the arrangement of the gure (i.e., using dividing lines) and in the text of the gure legend. if dividing lines are not included, they will be added by our production department, and this may result in production delays. adjustments of brightness, contrast, or color balance are acceptable if they are applied to the whole image and as long as they do not obscure, eliminate, or misrepresent any information present in the original, including backgrounds. without any background information, it is not possible to see exactly how much of the original gel is actually shown. nonlinear adjustments (e.g., changes to gamma settings) must be disclosed in the gure legend. all digital images in manuscripts accepted for publication will be scrutinized by our production department for any indication of improper  manipulation. questions raised by the production department will be referred to the editors, who will request the original data from the authors for comparison to the prepared gures. if the original data cannot be produced, the acceptance of the manuscript may be revoked. cases in which the manipulation affects the interpretation of the data will result in revocation of acceptance, and will be reported to the corresponding author™s home institution or funding agency.šthe journal of cell biology, instructions to authors,  http://www.jcb.org/misc/ifora.shtmlhaving developed this policy, the editors at the journal of cell biology began to screen all of the images in accepted articles for evidence of inappropriate manipulation. for example, simple brightness and contrast adjustments could reveal inconsistencies in the background of the image that are clues to manipulation. in this way, the editors could determine whether the images presented in a manuscript were an accurate representation of what was actually observed and whether the quality or context in which the images were obtained was apparent.over the course of the next 5 years, the editors screened the images in 1,869 accepted papers.3 over a quarter of the manuscripts contained one or more images that had been inappropriately manipulated. in the vast majority of those cases, the manipulation violated the journal™s guidelines but did not affect the interpretation of the data, and the articles were published after the authors revised the images in accordance with the guidelines.in 18 of the papersšabout 1 percent of the total for which the editors sought and obtained the original datašthe editors determined that the image manipulations affected the interpretation of the data. the acceptance of those papers was revoked, and they were not published. in only one case did the authors state that the original data could not be found and withdrew the paper. according to a federal denition of research misconduct developed by the ofce of science and technology policy, misconduct consists of fabrication, fal3 these gures are from mike rossner, the rockefeller university press, presentation to the committee, april 16, 2007. for background, see mike rossner and kenneth m. yamada. 2004. ﬁwhat™s in a picture: the temptation of image manipulation.ﬂ journal of cell biology 166(1):11œ15.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 37sication, or plagiarism of research results.4 however, the editors at the journal of cell biology do not consider the element of ﬁintentﬂ in their inquiries into potential violations of their guidelines. they obtain the original data directly from the authors, since whether an image has been inappropriately manipulated can be determined only by comparing the submitted gures with the original data. initial inquiries from the journal emphasize that questions are being asked only about the presentation of data, not its integrity, and inquiries are kept strictly condential between a journal and authors. the section on image manipulation in the white paper on promoting integrity in scientic journal publications by the council of science editors, which was written by the editors at the journal of cell biology, suggests that ﬁjournal editors should attempt to resolve the problem before a case is reported. this is because the vast majority of cases do not turn out to be fraudulent.ﬂ5since the journal of cell biology adopted its policy, other journals, including the proceedings of the national academy of sciences and nature, have begun screening images for evidence of inappropriate manipulation (see table 21). generally, these journals have screened a subset of papers and have made the additional level of scrutiny known to authors in the hope that this will act as a disincentive to manipulation.6 in addition, software is being developed that may automate at least part of the screening process so that more images can be examined with less expense.publishers of scientic, engineering, and medical journals continue to grapple with issues related to technological change and ensuring the integrity of published results. concurrent with the present study, a number of leading journals have held a series of meetings to discuss these issues. one question is whether the additional efforts on the part of journals to screen digital images entail additional responsibilities. for example, suppose a journal screens digital images in a manuscript, nds something suspicious, and after undertaking an inquiry and nding that an image has been fraudulently manipulated rejects the paper. does the journal have further responsibilities, and if so what are they? according to the white paper on promoting integrity in scientic journal publications by the council of science editors, when a journal ﬁsuspects an article contains material that may result in a nding of misconduct, the editor can notify some or all of the following parties: the author who submitted the article, all authors of the article, the institution that employs the author(s), the sponsor of the study, or an agency that would have jurisdiction over an inves4 ofce of science and technology policy, federal policy on research misconduct. available at http://ori.dhhs.gov/education/products/rcrintro/c02/b1c2.html.5 editorial policy committee. 2006. cse™s white paper on promoting integrity in scientic journal publications. reston, va: council of science editors, p. 50.6 unfortunately, the experience of the editors of the journal of cell biology indicates that this is not the case, because the rates at which they see image manipulation have not declined over the past 5 years.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.38 ensuring the integrity, accessibility, and stewardship of datatable 21 analysis of journal policies naturesciencepnasjcbnejmacsagufasebaieeeesaaerdata and methods accessdoes the journal require that all data be made available on request to journal editors and reviewers?yesyesyesyesnoyesyesyesyesyesnobdoes the journal require deposition of data in a public repository?yesyesyesyesyescencouragednodyesnonoeyesare authors required to provide algorithms or computer programs used in the collection, report, or analysis of data?nononoyesyesfyesnoyesnonoyesimage manipulationis image manipulation prohibited?nononononononononononodoes the journal require that image manipulation be reported?yesyesyesyesyesnonononononodoes the journal require that digital techniques be applied to the entire image?yesyesyesyesnononononononodoes the journal use software tests to detect image manipulation?yesyesyesyesnononononononoethics and scientific misconductis there a specified ethical statement?yesyesyesyesyesyesyesyesyesyesnodoes the journal have a scientific misconduct investigation or reporting policy in place?yesgyeshyesiyesjyesyesyesyesyesyesnokey: pnas=proceedings of the national academy of sciences; jcb=journal of cell biology and other rockefeller university press; nejm=new england journal of medicine; acs=american chemical society journals; agu=american geophysical union journals; faseb=federation of american societies for experimental biology journals; ieee=institute of electrical and electronics engineers journals; esa=ecological society of america journals; aer=american economic reviewa faseb is reviewing their policies as this goes to press.b the authors have to provide the editors with their data and programs after acceptance for publication (data and programs are then posted to a public repository); authors are not required to provide data and other information to reviewers.c for certain studies only.d only if the author wishes to cite the data must it be in a public depository. agu does strongly encourage all authors to deposit their data but it is not a requirement for publication.e encouraged.tigation of the matter (e.g., ori [ofce of research integrity]).ﬂ7 in practice, however, an editor may be reluctant to initiate action that could have disciplinary consequences.8another question is whether the high incidence of inappropriate manipulation of images in the above example re˚ects a lack of experience with applying 7 editorial policy committee. 2006. cse™s white paper on promoting integrity in scientic journal publications. reston, va: council of science editors, p. 50.8 d. butler. 2008. ﬁentirepaper plagiarism caught by software.ﬂ nature news 455:715. ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 39table 21 analysis of journal policies naturesciencepnasjcbnejmacsagufasebaieeeesaaerdata and methods accessdoes the journal require that all data be made available on request to journal editors and reviewers?yesyesyesyesnoyesyesyesyesyesnobdoes the journal require deposition of data in a public repository?yesyesyesyesyescencouragednodyesnonoeyesare authors required to provide algorithms or computer programs used in the collection, report, or analysis of data?nononoyesyesfyesnoyesnonoyesimage manipulationis image manipulation prohibited?nononononononononononodoes the journal require that image manipulation be reported?yesyesyesyesyesnonononononodoes the journal require that digital techniques be applied to the entire image?yesyesyesyesnononononononodoes the journal use software tests to detect image manipulation?yesyesyesyesnononononononoethics and scientific misconductis there a specified ethical statement?yesyesyesyesyesyesyesyesyesyesnodoes the journal have a scientific misconduct investigation or reporting policy in place?yesgyeshyesiyesjyesyesyesyesyesyesnokey: pnas=proceedings of the national academy of sciences; jcb=journal of cell biology and other rockefeller university press; nejm=new england journal of medicine; acs=american chemical society journals; agu=american geophysical union journals; faseb=federation of american societies for experimental biology journals; ieee=institute of electrical and electronics engineers journals; esa=ecological society of america journals; aer=american economic reviewa faseb is reviewing their policies as this goes to press.b the authors have to provide the editors with their data and programs after acceptance for publication (data and programs are then posted to a public repository); authors are not required to provide data and other information to reviewers.c for certain studies only.d only if the author wishes to cite the data must it be in a public depository. agu does strongly encourage all authors to deposit their data but it is not a requirement for publication.e encouraged.f on request.g species steps that will be taken in cases of suspected plagiarism and failure to provide data.h policies are ﬁin place regarding reporting scientic misconduct, but these are internal and not listed externally.ﬂi ﬁcases of deliberate misrepresentation of data will result in rejection of the paper and will be reported to the corresponding author™s home institution or funding agency.ﬂj ﬁcases in which the (image) manipulation affects the interpretation of the data will result in revocation of acceptance, and will be reported to the corresponding author™s home institution or funding agency.ﬂsources: compiled from journal web sites. all journals are peerreviewed publications. additional information provided by journals 2009.the standards of science to digital data or an underlying disregard for the standards of science. the recommendations presented later in this chapter address the need for researchers not only to understand the reasons for maintaining the integrity of research data, but also the methods for doing so.9all research data, whether digital or not, are susceptible both to error and 9 national academy of sciences, national academy of engineering, and institute of medicine. 2009. on being a scientist: responsible conduct in research, 3rd ed. washington, dc: the national academies press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.40 ensuring the integrity, accessibility, and stewardship of datato misrepresentation. digital technologies can introduce technical sources of error into data analysis, communication, or storage systems. at the frontiers of human knowledge, the data that bear on a problem can be very difcult to separate from irrelevant information.10 research methods may not be rmly established, and even the questions being asked may not be fully dened.furthermore, researchers may have incentives to structure research or gather data in ways that favor a particular outcome, as in the case of drug  studies funded by companies that stand to prot from particular results.11 in addition, researchers can have philosophical, political, or religious convictions that can in˚uence their work, including the ways they collect and interpret data.12 because of the many ways in which data can depart from empirical realities, everyone involved in the collection, analysis, dissemination, and preservation of data has a responsibility to safeguard the integrity of data.the roles of data producers, providers, and usersthe example from the journal of cell biology illustrates the different roles that individuals and groups can play in ensuring the integrity of data. for the purposes of this report, we have divided these individuals and groups into three categoriesšdata producers, data providers, and data usersšthough it should be kept it mind that many individuals and organizations fall into more than one of these categories.data producers are the scientists, engineers, students, and others who generate data, whether through observations, experiments, simulations, or the gathering of information from other sources. often the creation of data is an explicit objective of research, but data can be generated in many ways. for example, administrative records, archaeological artifacts, cell phone logs, or many other forms of information can be adapted to serve as inputs to research. data also are produced by government agencies in the course of performing tasks for other purposes (such as remote sensing for weather forecasts or conducting the decadal censuses), and these data can be used extensively for research. this report focuses on data produced through activities that are related primarily to research, but the general principles laid out in this report apply to all data used in research.10 e. brian davis. 2003. science in the looking glass: what do scientists really know? new york: oxford university press.11 sheldon krimsky. 2006. ﬁpublication bias, data ownership, and the funding effect in science: threats to the integrity of biomedical research.ﬂ pp. 61œ85 in rescuing science from politics: regulation and the distortion of scientic research, eds. wendy wagner and rena steinzor. new york: cambridge university press.12 national academy of sciences, national academy of engineering, and institute of medicine. 2009. on being a scientist: responsible conduct in research, 3rd ed. washington, dc: the national academies press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 41data providers consist of the individuals and organizations who are responsible, whether formally or informally, for making data accessible to others. sometimes a data provider may be simply the producer of those data, because data producers generally are expected to make data available to verify research conclusions and allow for the continued progress of research. in other cases, data may be deposited in a repository, center, or archive that has the responsibility of disseminating the data. journals also can be data providers, either through the articles they publish or through the provision of supplementary material that supports a published article.data users are the individuals and groups who access data in order to use those data in their own work, whether in research or in other endeavors. at one extreme, the users of data may belong entirely to the community of originating researchers (as in the case of elementary particle physics, which is described in this chapter). at the other extreme, a given body of data may be of wide interest to people outside a research eld (as in the case of climate records, which is discussed in chapter 3). data producers are generally data users, but the collective body of data users extends beyond the research community to policy makers, educators, the media, the courts, and others. data users can work in elds quite different from those of data producers, which means that they have an interest in being able to access data that are well annotated in order to use them accurately and appropriately.as described below, each of these three groups has particular responsibilities in ensuring the integrity of research data. the collective scrutiny of research data and resultsin chapter 1, we noted that measures of data integrity have both individual and collective dimensions. at an individual level, ensuring integrity means ensuring that the data are complete, veried, and undistorted. this is essential for science and engineering to progress, but it is not sufcient because progress in understanding the world requires that knowledge be shared. this process of submitting research data and results derived from those data to the scrutiny of others provides for a collective means of establishing and conrming data integrity. when others can examine the steps used to generate data and the conclusions drawn from those data, they can judge the validity of the data and results and accept (perhaps with reservations) or reject proffered contributions to science. of course, the collective scrutiny of research results cannot guarantee that those results will be free of error or bias. for instance, it is noteworthy that important phenomena such as plate tectonics, chaotic motion in mechanical systems, or the functions of ﬁjunkﬂ dna were overlooked for decades because of theoretical perspectives that shaped the collection of data in those elds. nevertheless, by bringing multiple perspectives to bear on a common body of ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.42 ensuring the integrity, accessibility, and stewardship of datainformation, the error and bias inherent in individual perspectives can be minimized. in this way, the frontiers of understanding continually advance through the collective evaluation of new data and hypotheses.data producers, providers, and users are all involved in the collective scrutiny of research data and results. data producers need to make data available to others so that the data™s quality can be judged. (chapter 3 discusses the accessibility of research data.) data providers need to make data widely available in a form such that the data can be not only used but evaluated, which requires that data be accompanied by sufcient metadata for their content and value to be ascertained. (chapter 4 discusses the importance of metadata.) finally, data users need to examine critically the data generated by themselves and others. the critical evaluation of data is a fundamental obligation of all researchers.completely and accurately describing the conditions under which data are collected, characterizing the equipment used and its response, and recording anything that was done to the data thereafter are critical to ensuring data integrity. in this report we refer to the techniques, procedures, and tools used to collect or generate data simply as methods, where a ﬁmethodﬂ is understood to encompass everything from research protocols to the computers and software (including models, code, and input data) used to gather information, process and analyze data, or perform simulations. the validity of the methods used to conduct research is judged collectively by the community involved in that research. for example, a community may decide that doubleblind trials, independent verication, or particular instrumental calibrations are necessary for a body of data to be accepted as having high quality. scientic methods include both a core of widely accepted methods and a periphery of methods that are less widely accepted. thus, discussions of data integrity inevitably involve scrutiny of the methods used to derive those data.the procedures used to ensure the integrity of data can vary greatly from eld to eld. the methods highenergy physicists use to ensure the integrity of data are quite different from those of clinical psychologists. the cultures of the elds of research are enormously varied, and there are no universal procedures for achieving technical accuracy. some practices may be employed only within specic elds, such as the use of doubleblind trials. some of these eld specic methods may be embodied in technical manuals, institutional policies, journal guidelines, or publications of professional societies. other methods are part of the collective but tacit knowledge held in common by researchers in that eld and passed down to beginning researchers through instruction and mentoring.in contrast to eldspecic methods, some methods used to ensure data integrity extend across most elds of research. examples include the review of data within research groups, replication of previous observations and experiments, peer review, the sharing of data and research results, and the retention of raw data for possible future use.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 43the importance of understanding the particular methods used (whether eldspecic or general) is signaled in some publications by a ﬁmethods sectionﬂ that describes the procedures used to derive a result. in some print journals, methods sections are being squeezed by pressures to cut costs, though conventionally sized or longer methods sections may be available in supplementary material online. researchers also may abbreviate methods sections to keep some procedures private in order to obscure the processes used to derive data.to some extent, researchers must simply trust that other researchers have adhered to the methods accepted in a eld of scientic, engineering, or medical research. sometimes it is impossible to specify in enough detail the procedures used to gather or generate data so that others will get exactly the same results. in such cases, assistance from the original researcher may be necessary for other researchers to replicate or extend earlier results.the importance of understanding the methods of collecting or generating the data emphasizes the importance of understanding the context of data. most data cannot be properly interpreted without at least somešand frequently detailedšunderstanding of the procedures, instruments, and processing used to generate those data. thus, data integrity depends critically on communicating to other researchers and to the public the context in which data are generated and processed.peer review and other means for ensuring  the integrity of dataof all the social processes used to maintain the integrity of the research enterprise, the most prominent is peer review of articles submitted to a scholarly journal for publication. review of submitted articles by the authors™ peers screens for quality and relevance and helps to ensure that professional standards have been maintained in the collection and analysis of data. it provides a forum in which the collective standards of a eld can be not only negotiated but enforced, because of the researchers™ interests in having their results published. peer review examines whether research questions have been framed and addressed properly, whether ndings are original and signicant, and whether a paper is clearly written and acknowledges previous work. peer review also organizes research results so that the most important research appears in specic journals, which allows for more effective communication.because peer review is such an effective tool in quality control, it also is used in evaluating researchers. researchers are judged for purposes of hiring and promotion largely on the basis of publication in peerreviewed journals. furthermore, publication in these journals remains the most important way to disseminate qualitycontrolled contributions to knowledge. the number of peerreviewed journals is continuing to grow, and importance of peer review has not diminished during the digital era.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.44 ensuring the integrity, accessibility, and stewardship of datahowever, changes in the way research is conducted, including many changes caused by digital technologies, have put pressure on the peer review system.13 the volume or diversity of research data supporting a conclusion may overwhelm the ability of a reviewer to evaluate the link between the data and that conclusion. as supporting information for a nding in a submitted paper increasingly moves to lengthy supplemental materials, reviewers may be less able to judge the merits of a paper. in addition, journals and funders can have trouble nding peer reviewers who are competent and have the time to judge complex interdisciplinary manuscripts.peer review cannot ensure that all research data are technically accurate, though inaccuracies in data can become apparent either in review or as researchers seek to extend or build on data. the research system is based to a large degree on trust. as described later in this chapter, training and the development of standards are crucial factors in building trust. broader cultural forces such as reward systems, the reputation of researchers and their institutions, and social and cultural penalties for violation of trust also serve to build and maintain trust.a recent example that illustrates both the limitations of peer review and the strengths of the cumulative nature of science is the case of seoul national university researcher woo suk hwang. major advances in stem cell technology that were reported by hwang and his colleagues and published in the journal science were based on fabricated data.14 the fraud was uncovered and conrmed after the original publication because of continued scrutiny of the results by the research community. another case involving fabricated data is described in box 22.changes in publication practices are affecting peer review. largely because of advances in digital communications, the scholarly publishing industry is undergoing dramatic changes, some of which are having a major in˚uence on the economics of the industry.15 peer review is expensive because of the time devoted to the process by editors, reviewers, and authors responding to reviewers™ comments. changes in the economics of scholarly publishing may put pressure on editors and publishers to lessen the emphasis on peer review as they strive to cut costs and increase efciency.at the same time, digital technologies can strengthen peer review by  catalyzing and facilitating new ways of reviewing publications. for example, 13 stevan harnad. 1998. ﬁlearned inquiry and the net: the role of peer review, peer commentary and copyright,ﬂ learned publishing 11:183œ192. available at http://cogprints.org/1694/0/harnad98.toronto.learnedpub.html. accessed february 23, 2007.14 mildred k. cho, glen mcgee, and david magnus. 2006. ﬁlessons of the stem cell scandal.ﬂ science 311(5761): 614œ615. 15 national academy of sciences, national academy of engineering, and institute of medicine. 2004. electronic scientic, technical, and medical journal publishing and its implications. washington, dc: the national academies press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 45box 22 breach of trust beginning in 1998, a series of remarkable papers attracted great attention within the condensedmatter physics community. the papers, based largely on work done at bell laboratories, described methods that could create carbonbased materials with longsought properties, including superconductivity and molecularlevel switching. however, when other materials scientists sought to reproduce or extend the results, they were unsuccessful. in 2001, several physicists inside and outside bell laboratories began to notice anomalies among the papers. several contained ˚gures that were very similar, even though they described different experimental systems. some graphs seemed too smooth to describe reallife systems. suspicion quickly fell on a young researcher named jan hendrik schön, who had helped create the materials, had made the physical measurements on them, and was a coauthor on all the papers. bell laboratories convened a committee of ˚ve outside scientists to examine the results published in 25 papers. schön, who had conducted part of the work in the laboratory where he did his ph.d. at the university of konstanz in germany, told the committee that the devices he had studied were no longer running or had been thrown away. he also said that he had deleted his primary electronic data ˚les because he did not have room to store them on his old computer and that he kept no data notebooks while he was performing the work. the committee concluded that schön had engaged in fabrication in at least 16 of the 25 papers. schön was ˚red from bell laboratories and later left the united states. in a letter to the committee, he wrote that ﬁi admit i made various mistakes in my scienti˚c work, which i deeply regret.ﬂ yet he maintained that he ﬁobserved experimentally the various physical effects reported in these publications.ﬂ the committee concluded that schön acted alone and that his 20 coauthors on the papers were not guilty of research misconduct. however, the committee also raised the issue of the responsibility that coauthors have to oversee the work of their colleagues. the committee concluded that the extent of this responsibility had not been established within the research community. the senior author on several of the papers, all of which were later retracted, wrote that he should have asked schön for more detailed data and checked his work more carefully, but that he trusted schön to do his work honestly. in response to the incident, bell laboratories instituted new policies for data retention and internal review of results before publication. it also developed a new research ethics statement for its employees.source: national academy of sciences, national academy of engineering, and institute of medicine. 2009. on being a scientist: responsible conduct in research. washington, dc: the national academies press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.46 ensuring the integrity, accessibility, and stewardship of datasome journals have been experimenting with making reviews open and public.16 in some cases, reviewers™ names are known to authors and readers. in other cases, their reviews and authors™ responses become part of the online record of publication. more radical innovations, such as the continuous improvement of published materials through wikis and similar approaches, or peer rankings and commentary on published papers, could further change both journals and the institution of peer review.although it is clear that traditional peer review processes remain vital for evaluating the importance and relevance of research, the advance of digital technologies is providing new opportunities to ensure the integrity of data. the emergence and growth of accessible databases such as genbank and the sloan digital sky survey illustrate these opportunities in widely disparate disciplines.17many researchers post databases, draft papers, oral presentations, simulations, software packages, or other scholarly products on personal or institutional web sites. repositories, such as the nature precedings repository established by the nature publishing group for the life sciences, allow researchers to share, discuss, and cite preliminary ndings.18 the web allows widespread dissemination of critiques, commentaries, blogs, and other communications. all of these communications can be widely disseminated without undergoing a formal peer review process. in these cases, the quality of research results and the underlying data may be uncertain, and other researchers may have questions in deciding whether to rely on that research in their own work.the processes for reviewing data that are preserved in a repository or otherwise made widely available to researchers can be quite different from the procedures for reviewing data presented in a publication.19 trust in the quality of data may require personal knowledge of how the data were collected and analyzed. metadata that carefully describe the origins and subsequent processing of the data can increase condence in the validity of the data.in some cases, digital technologies can assist in ensuring data quality and building trust in the integrity of the data. veried technical methods for gather16 a number of open access journals maintain open peer review processes. the traditional journal nature experimented with an open peer review process during 2006, nding that the open process was not popular with authors or reviewers. sarah greaves, joanna scott, maxine clarke, linda miller, timo hannay, annette thomas, and philip campbell. 2006. ﬁoverview: nature™s peer review trial.ﬂ nature doi:10.1038/nature05535. available http://www.nature.com/nature/peerreview/debate/nature05535.html. this report is also discussed in an editorial. 2006. ﬁpeer review and fraud.ﬂ 444:971. 17 dennis a. benson, ilene karschmizrachi, david j. lipman, james ostell, and david l. wheeler. 2006. ﬁgenbank.ﬂ nucleic acids research 34(database):d16œd20. available at http://nar.oxfordjournals.org/cgi/content/abstract/34/suppl1/d16. see also robert c. kennicutt, jr. 2007. ﬁsloan at ve.ﬂ nature 450:488œ489.18 see http://precedings.nature.com/.19 christine l. borgman. 2007. scholarship in the digital age: information, infrastructure, and the internet. cambridge, ma: mit press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 47ing, analyzing, and disseminating data can establish tight connections between natural phenomena and representations of those phenomena. digital technologies also can allow for the widespread dissemination of data and research results to potential reviewers and data users. the emergence and growth of accessible databases such as genbank and the sloan digital sky survey illustrate these opportunities in widely disparate disciplines.20 (box 23 on clinical research in this chapter describes another example.) however, it can be difcult to verify the integrity of results based on large datasets that have undergone substantial processing.in cases where research results or underlying data are distributed electronically without undergoing peer review, researchers may be able to nd other ways to submit them to collective evaluation. for example, they may be able to submit data to informal review by colleagues or open review by users of electronic documents. to advance science, in some cases it may be desirable to disseminate data and conclusions in ways other than through peerreviewed publications. electronic technologies are greatly enhancing this dissemination.however, widespread dissemination of research results and underlying data that have not been vetted through the social mechanisms characteristic of research poses the risk that the conclusions drawn from available data can be distorted. furthermore, it can be difcult for a community to assess the validity of evaluations that are outside traditional peer review processes. and academic disciplines and institutions are just beginning to develop methods for evaluating and rewarding researchers for the production of results that have not undergone peer review or have undergone only informal review.21fields of research may settle on methods that enhance the quality of research without following all the steps of a formal review process. for example, a research community may structure itself to examine and verify research procedures and data, even though the data are not publicly accessible, as happens in highenergy physics. another example is research in economics, where authors often work on papers for extended periods, presenting preliminary version of their papers (and data) at conferences and receiving ofcial critiques from their colleagues prior to submitting a paper for publication.in other cases, the accuracy of data may be continuously reviewed as they are incorporated into ongoing research in such a way that their accuracy is checked; for example, this is one of the quality control mechanisms used with 20 dennis a. benson, ilene karschmizrachi, david j. lipman, james ostell, and david l. wheeler. 2006. ﬁgenbank.ﬂ nucleic acids research 34(database):d16œd20. available at http://nar.oxfordjournals.org/cgi/content/abstract/34/suppl1/d16. see also robert c. kennicutt, jr. 2007. ﬁsloan at ve.ﬂ nature 450:488œ489.21 acrl scholarly communications committee. 2007. establishing a research agenda for scholarly communication: a call for community engagement. chicago: association of college and research libraries. available at http://acrl.ala.org/scresearchagenda/index.php?title=mainpage.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.48 ensuring the integrity, accessibility, and stewardship of databox 23 using digital technologies to enhance data integrity digital technologies can pose risks to data integrity, but they also offer ways to improve the reliability of research data. by enabling phenomena and objects to be described and analyzed more comprehensively, they make it possible to remove some of the simplifying assumptions inherent in earlier research. they enable researchers to build checking and veri˚cation procedures into research protocols in ways that reduce the potential for error and bias. automated data collection that is quality controlled can be much more accurate when either substituting for or supplementing human observations. although examples from many disciplines could be cited, a good example is the use of digital technologies in clinical research, including the conduct of clinical trials and plans to link clinical trial information with individuals™ electronic health records. access to the data behind the production of new drugs and other medical treatments is often a contentious issue because of the proprietary traditions of the pharmaceutical industry and concerns about the privacy and security of patients enrolled in clinical trials. nonetheless, the trend in drug development is toward openness, as databases are made more widely available and prepublication information is published in electronic form to make signi˚cant ˚ndings quickly available. for example, a glaxosmithkline clinical trial register has been created to afford online access to factual summaries of clinical trails of marketed prescription medicines and vaccines.a although some specialty journals oppose this practice, the general trend toward openness is being pulled by powerful demands for public assurances about accuracy, completeness, and timeliness. in the united states the federal government has been the primary force behind making drug development data both electronic and public. the food and drug administration (fda), for example, is moving away from onsite audits of clinical trials to statistically based sampling and electronic audits. the agency is adapting many tools borrowed from the banking, nuclear, and other sectors where security checks and balances have been in place for a long time. an important catalyst for electronic data handling has been the fda™s issuance of regulation 21 cfr part 11 in 1997,b which provided criteria for acceptance of electronic records and electronic signatures. this regulation not only opened the door to electronic submissions but also encouraged the widest possible use of electronic technology in all fda program areas, including data storage, archiving, monitoring, auditing, and review. a signi˚cant goal was that data should be shareable between sponsors and reviewers. in 2004, fda made electronic submission mandatory and called for electronic data handling as well, with the primary goal of faster product reviews and acceptance. fda is currently planning to adopt single standards for the full life cycle of clinical  trials, from the protocol through the capture of source data to analysis, submission, and archiving. industry has long been viewed as opposed to making data supporting clinical trials or publications public, partly out of a desire to maintain competitive advantages and partly out of concern that data could be misjudged, mishandled, or otherwise abused in a public forum. this attitude is starting to change as the use of the internet becomes widespread (the accessibility of data is discussed in more detail in the next chapter).c the next frontier of the evolution of clinical research toward an electronic future is the electronic integration of clinical trials data and patients™ health records. this integration is anticipated to open new areas of research that feature enhanced risk assessment, improved natural history and epidemiological assessment, more reliable information, and better drug use. the primary challenge is to develop standards to bridge the different standards and terminologies used in clinical trials with those used in medical recordkeeping. this process presents daunting dif˚culties, including:health records include a broader range of terminology than clinical trials. for example, a myocardial infarction might be described in a medical record as coronary insuf˚ciency, chest discomfort, or other terms that may be dif˚cult to capture in an electronic system.the codes for most electronic health records were developed for reimbursement and billing purposes, not for clinical use or research.health records data are retrospective, which can make it dif˚cult to check for errors. questions have been raised about whether digitizing individuals™ electronic health records will compromise their security and privacy. will inappropriate usage be properly restricted? will companies be able to acquire and share these data? if companies use the data to develop publications, will they later be liable to requests to make the primary data available to others? another potentially dif˚cult problem is that the merging of two datasets might make it possible to identify patients who have been ﬁdeidenti˚edﬂ in each. although these and other potential concerns must be addressed, the experience since implementation of 21 cfr part 11 a decade ago is encouraging. existing processes, standards, and computer systems have been largely effective in maintaining the accuracy, integrity, and privacy of data. furthermore, there are grounds to believe that these experiences can be extended to the effective handling of individuals™ electronic health recordsšas witnessed, for example, by the success of the u.s. department of veterans' affairs in developing secure practices.a frank w. rockhold and ronald i. krall. 2006. ﬁtrial summaries on results databases and journal publicationﬂ (letter). lancet 367:1633œ1635.b food and drug administration. 2003. guidance for industry, part 11, electronic records; electronic signaturesšscope and application. available at http://www.21cfrpart11.com/˚les/fdadocs/part11˚nalguidancesep2003.pdf.c eve slater, director on the boards of vertex pharmaceuticals and theravance, inc., presentation to the committee, april 16, 2007.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 49box 23 using digital technologies to enhance data integrity digital technologies can pose risks to data integrity, but they also offer ways to improve the reliability of research data. by enabling phenomena and objects to be described and analyzed more comprehensively, they make it possible to remove some of the simplifying assumptions inherent in earlier research. they enable researchers to build checking and veri˚cation procedures into research protocols in ways that reduce the potential for error and bias. automated data collection that is quality controlled can be much more accurate when either substituting for or supplementing human observations. although examples from many disciplines could be cited, a good example is the use of digital technologies in clinical research, including the conduct of clinical trials and plans to link clinical trial information with individuals™ electronic health records. access to the data behind the production of new drugs and other medical treatments is often a contentious issue because of the proprietary traditions of the pharmaceutical industry and concerns about the privacy and security of patients enrolled in clinical trials. nonetheless, the trend in drug development is toward openness, as databases are made more widely available and prepublication information is published in electronic form to make signi˚cant ˚ndings quickly available. for example, a glaxosmithkline clinical trial register has been created to afford online access to factual summaries of clinical trails of marketed prescription medicines and vaccines.a although some specialty journals oppose this practice, the general trend toward openness is being pulled by powerful demands for public assurances about accuracy, completeness, and timeliness. in the united states the federal government has been the primary force behind making drug development data both electronic and public. the food and drug administration (fda), for example, is moving away from onsite audits of clinical trials to statistically based sampling and electronic audits. the agency is adapting many tools borrowed from the banking, nuclear, and other sectors where security checks and balances have been in place for a long time. an important catalyst for electronic data handling has been the fda™s issuance of regulation 21 cfr part 11 in 1997,b which provided criteria for acceptance of electronic records and electronic signatures. this regulation not only opened the door to electronic submissions but also encouraged the widest possible use of electronic technology in all fda program areas, including data storage, archiving, monitoring, auditing, and review. a signi˚cant goal was that data should be shareable between sponsors and reviewers. in 2004, fda made electronic submission mandatory and called for electronic data handling as well, with the primary goal of faster product reviews and acceptance. fda is currently planning to adopt single standards for the full life cycle of clinical  trials, from the protocol through the capture of source data to analysis, submission, and archiving. industry has long been viewed as opposed to making data supporting clinical trials or publications public, partly out of a desire to maintain competitive advantages and partly out of concern that data could be misjudged, mishandled, or otherwise abused in a public forum. this attitude is starting to change as the use of the internet becomes widespread (the accessibility of data is discussed in more detail in the next chapter).c the next frontier of the evolution of clinical research toward an electronic future is the electronic integration of clinical trials data and patients™ health records. this integration is anticipated to open new areas of research that feature enhanced risk assessment, improved natural history and epidemiological assessment, more reliable information, and better drug use. the primary challenge is to develop standards to bridge the different standards and terminologies used in clinical trials with those used in medical recordkeeping. this process presents daunting dif˚culties, including:health records include a broader range of terminology than clinical trials. for example, a myocardial infarction might be described in a medical record as coronary insuf˚ciency, chest discomfort, or other terms that may be dif˚cult to capture in an electronic system.the codes for most electronic health records were developed for reimbursement and billing purposes, not for clinical use or research.health records data are retrospective, which can make it dif˚cult to check for errors. questions have been raised about whether digitizing individuals™ electronic health records will compromise their security and privacy. will inappropriate usage be properly restricted? will companies be able to acquire and share these data? if companies use the data to develop publications, will they later be liable to requests to make the primary data available to others? another potentially dif˚cult problem is that the merging of two datasets might make it possible to identify patients who have been ﬁdeidenti˚edﬂ in each. although these and other potential concerns must be addressed, the experience since implementation of 21 cfr part 11 a decade ago is encouraging. existing processes, standards, and computer systems have been largely effective in maintaining the accuracy, integrity, and privacy of data. furthermore, there are grounds to believe that these experiences can be extended to the effective handling of individuals™ electronic health recordsšas witnessed, for example, by the success of the u.s. department of veterans' affairs in developing secure practices.a frank w. rockhold and ronald i. krall. 2006. ﬁtrial summaries on results databases and journal publicationﬂ (letter). lancet 367:1633œ1635.b food and drug administration. 2003. guidance for industry, part 11, electronic records; electronic signaturesšscope and application. available at http://www.21cfrpart11.com/˚les/fdadocs/part11˚nalguidancesep2003.pdf.c eve slater, director on the boards of vertex pharmaceuticals and theravance, inc., presentation to the committee, april 16, 2007.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.50 ensuring the integrity, accessibility, and stewardship of databiological data that are made publicly available as soon as they are generated. the rapid release of validated, highquality data requires analysis and planning by the researchers who built the datagathering and processing system (which requires that those researchers be rewarded for their efforts) and the design of systems that incorporate innovative automated dataquality assessment. in these cases, provisions may need to be made for continually updating data as errors are detected and improved methods are developed, resulting in databases that evolve as elds advance.table 22 summarizes the policies of federal agencies regarding data integrity and data sharing.data integrity in the digital age and  the role of data professionalsin the digital age, the methods used to maintain data integrity are increasingly complex. as new methods and tools are brought into practice, researchers are continually challenged to understand them and use them effectively. furthermore, providing data to users inevitably becomes more involved as the size and complexity of databases increase. because methods continually change as digital technologies evolve, researchers may be required to make a substantial investment of time in order to keep pace.in some elds, the researchers themselves may be at the forefront of efforts to meet these data challenges, but in many elds the challenges are met at least in part by what we call in this report ﬁdata professionals.ﬂ these individuals have a very wide range of responsibilities for data analysis, archiving, preservation, and distribution.22 often, they are the leaders in developing new methods of data communication, data visualization, educational outreach, and other key advances. they also often participate in the development of standards, formats, metadata, and quality control mechanisms. they can bring new perspectives on existing datasets or new ways of combining data that yield important advances. through their familiarity with rapidly changing digital technologies, they can enhance the ability of others to conduct research. they also are in a unique position to make digital data available to the broadest possible range of researchers, educators, students, and the general public. educational opportunities, viable career paths, and professional recognition all help ensure that data professionals are in a position to make needed contributions to research.22 national science board. 2005. longlived data collections: enabling research and education in the 21st century. arlington, va: national science foundation.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 51general principle for ensuring  the integrity of research datathe new capabilities and challenges posed by digital technologies point to the need for a renewed emphasis on data integrity. the assumption that traditional practices will sufce is no longer tenable as digital technologies continue to transform the nature of research. researchers must be aware of how the integration of digital technologies into research affects the quality of data. as the generation and dissemination of data become the primary objectives of some research projects, researchers need to nd ways to validate the quality of those data. they need to take steps to ensure that digital technologies enhance rather than detract from data integrity.these observations lead to the following general principle:data integrity principle: ensuring the integrity of research data is essential for advancing scientic, engineering, and medical knowledge and for maintaining public trust in the research enterprise. although other stakeholders in the research enterprise have important roles to play, researchers themselves are ultimately responsible for ensuring the integrity of research data.in emphasizing the importance of this principle, the committee is not calling for formal assurances of data integrity. maintaining the quality of research is an essential part of being a responsible and competent researcher. in assigning researchers the ultimate responsibility for data integrity, the committee is asking no more than that researchers adhere to the standards established and held in common by all researchers.this principle may seem apparent, but its application in the digital age leads to several important recommendations.the obligations of researchers to ensure  the integrity of research dataresearchers have a fundamental obligation to their colleagues, to the public, and to themselves to ensure the integrity of research data. members of the research community trust that their colleagues will adhere to the standards of their eld and will be transparent in describing the methods used to generate data. they also assume that colleagues will make available the data on which publicly disseminated research results are based. (chapter 3 discusses issues of data access in detail.) members of the general public may be unfamiliar with the standards of a research eld, but they, too, trust that researchers will gather, analyze, and review data accurately, honestly, and without unstated bias. if trust among colleagues or the public is misplaced and research data are shown to be inaccurate (or, even worse, fabricated), the consequences can be severe both within science and in the broader society.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.52 ensuring the integrity, accessibility, and stewardship of datatable 22 federal agency policies on research data intramuralnihnasaepanistdoeaare data subject to outside peer review?byesyesyesyesyesare data sets required to be made available or deposited into appropriate repositories?yesyesyesyesyesdoes training of new scientists include scientific misconduct training?yesnot statedcnot statednot statedyesa includes fulltime employees of doe national laboratories owned by the federal government but operated by management and operating (m&o) contractors. b presumes work will be published in a peerreviewed publication. c scientic misconduct training information available for the jet propulsion lab, but not for other facilities.extramural grantsanihbnsfusdacdoc afosronrdoeddoehhsdepanasaare grantees required to share data with other researchers?eyesyesfnognognotstatednotstatednonogyeshyesyesare grantees required to deposit data sets in appropriate repositories? yesyesinognognotstatednotstatednotapplicablenogyeshnoyesare grantees required to submit all information regarding computer programs developed or used during the time frame of the grant?notstatedencour agednognognotstatednotstatednonogyeshyesnotstatedare printed ﬁresearch misconductﬂ statements in effect, or a link provided to the federal policy?yesyesyesyesyesyesyesyesyesyesyesa as a baseline, federal agencies follow omb circular a110, uniform administrative requirements for grants and agreements with institutions of higher education, hospitals, and other nonprot organizations, which species that the federal government has the right to obtain, reproduce, publish or use the data rst produced under an award, and to authorize others to receive, reproduce, publish or use data. the provisions of the data access act, described in chapter 3, also apply.b nih™s policy covers ﬁnalresearchdata.ﬂapplicationsseekingmorethan$500,000indirectﬁnal research data.ﬂ applications seeking more than $500,000indirect in direct costs in any single budget period are expected to include a plan for data sharing or state why data sharing is not possible. c entries for this column apply to usda™s cooperative state research, education, and extension service, and may not apply to other parts of usda. d includes nonnih grants. e privacy and national securityrelated exceptions are assumed. f sharing is ﬁexpected.ﬂ the policy also provides for some exceptions in addition to privacy.g no agencywide written requirement, but sharing is often informally encouraged, and written requirements may cover some specic programs, grants or categories of data (e.g. requirements that genomic data be submitted to genbank). h hhs ﬁexpects and supportsﬂ sharing of data and tools, including deposit of data into appropriate repositories. i sharing is expected, however, the nsf policy permits necessary ˚exibility to account for programmatic differences.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 53table 22 federal agency policies on research data intramuralnihnasaepanistdoeaare data subject to outside peer review?byesyesyesyesyesare data sets required to be made available or deposited into appropriate repositories?yesyesyesyesyesdoes training of new scientists include scientific misconduct training?yesnot statedcnot statednot statedyesa includes fulltime employees of doe national laboratories owned by the federal government but operated by management and operating (m&o) contractors. b presumes work will be published in a peerreviewed publication. c scientic misconduct training information available for the jet propulsion lab, but not for other facilities.extramural grantsanihbnsfusdacdoc afosronrdoeddoehhsdepanasaare grantees required to share data with other researchers?eyesyesfnognognotstatednotstatednonogyeshyesyesare grantees required to deposit data sets in appropriate repositories? yesyesinognognotstatednotstatednotapplicablenogyeshnoyesare grantees required to submit all information regarding computer programs developed or used during the time frame of the grant?notstatedencour agednognognotstatednotstatednonogyeshyesnotstatedare printed ﬁresearch misconductﬂ statements in effect, or a link provided to the federal policy?yesyesyesyesyesyesyesyesyesyesyesa as a baseline, federal agencies follow omb circular a110, uniform administrative requirements for grants and agreements with institutions of higher education, hospitals, and other nonprot organizations, which species that the federal government has the right to obtain, reproduce, publish or use the data rst produced under an award, and to authorize others to receive, reproduce, publish or use data. the provisions of the data access act, described in chapter 3, also apply.b nih™s policy covers ﬁnalresearchdata.ﬂapplicationsseekingmorethan$500,000indirectﬁnal research data.ﬂ applications seeking more than $500,000indirect in direct costs in any single budget period are expected to include a plan for data sharing or state why data sharing is not possible. c entries for this column apply to usda™s cooperative state research, education, and extension service, and may not apply to other parts of usda. d includes nonnih grants. e privacy and national securityrelated exceptions are assumed. f sharing is ﬁexpected.ﬂ the policy also provides for some exceptions in addition to privacy.g no agencywide written requirement, but sharing is often informally encouraged, and written requirements may cover some specic programs, grants or categories of data (e.g. requirements that genomic data be submitted to genbank). h hhs ﬁexpects and supportsﬂ sharing of data and tools, including deposit of data into appropriate repositories. i sharing is expected, however, the nsf policy permits necessary ˚exibility to account for programmatic differences.sources: the table assumes, as a baseline, that agencies have or will implement john h.  marburger, iii. 2008. ﬁprinciples for the release of scientic research results.ﬂ memorandum. may 28. available at: www.arl.org/bm~doc/ostpscienticresearch28may08.pdf. also see web sites for nih (http://www1.od.nih.gov/oir/sourcebook/ethicconduct/ethicalconducttoc.htm) and jpl (http://ethics.jpl.nasa.gov/index.html).sources: agency web sites checked december 2008, and communications from agencies 2009.nih:  http://grants.nih.gov/grants/policy/nihgps2003/nihgpspart7.htmnsf:  http://www.nsf.gov/pubs/policydocs/pappguide/nsf091/aagindex.jspusda:  http://www.nsf.gov/pubs/policydocs/rtc/csrees708.pdfdoc:  http://oamweb.osec.doc.gov/gmdgrantspolicy.htmlafosr:  http://www.wpafb.af.mil/library/factsheets/factsheet.asp?id=9447onr: http://www.onr.navy.mil/02/terms.aspdoed:  http://www.ed.gov/fund/landing.jhtml?src=lndoe:  http://www.sc.doe.gov/grants/grants.html#grantruleshhs: http://www.hhs.gov/grantsnet/docs/hhsgps107.docepa:  http://www.epa.gov/ogd/grants/regulations.htm http://epa.gov/ncer/guidance/nasa:  http://www.hq.nasa.gov/ofce/procurement/nraguidebook/ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.54 ensuring the integrity, accessibility, and stewardship of datathe twin ideals of trust and transparency lead to our rst recommendation:recommendation 1: researchers should design and manage their projects so as to ensure the integrity of research data, adhering to the professional standards that distinguish scientic, engineering, and medical research both as a whole and as their particular elds of specialization.some professional standards apply throughout research, such as the injunction never to falsify or fabricate data or plagiarize research results. these are fundamental to research, and have been conrmed by leading organizations and codied in regulations.23 others are relevant only within specic elds, such as requirements to conduct doubleblind clinical trials. researchers must adhere to both sets of standards if they are to maintain the integrity of research data.the importance of trainingthe integrity of research data can suffer if researchers inadvertently or willfully ignore the professional standards of their eld. data integrity also can be negatively affected if researchers are unaware of these standards or are unaware of their importance. recommendation 2: research institutions should ensure that every researcher receives appropriate training in the responsible conduct of research, including the proper management of research data in general and within the researcher™s eld of specialization. some research sponsors provide support for this training and for the development of training programs. the training that is appropriate for researchers varies by eld. while every researcher should be familiar with the standards common to all research, other standards may be unique to a particular eld. much of this knowledge is handed down from senior researchers to junior researchers during the course of a person™s education and research apprenticeship. in at least some elds, a more formal statement of accepted practices, combined with more explicit instruction in those practices, could enhance the quality and utility of the data produced by those elds. given the rapid pace of change in many research elds, research focused specically on methods to ensure the integrity of research data may be necessary.today, the actual implementation of training varies greatly from eld to eld and institution to institution. the national institutes of health (nih) 23 national academy of sciences, national academy of engineering, and institute of medicine. 1992. responsible science: ensuring the integrity of the research process. washington, dc: national academy press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 55requires that graduate and postdoctoral students who are supported by nih training grants receive instruction in the responsible conduct of research. the ofce of research integrity at the department of health and human services supports programs undertaken by the council of graduate schools, the national postdoctoral association, and the laboratory management institute at the university of california at davis to develop education and training programs in the responsible conduct of research.24 many research institutions also require such training of students or beginning researchers, often in the form of seminars, workshops, or webbased modules. (box 24 describes one such program.) a 2002 institute of medicine report examined how institutions can create environments that foster research integrity.25 the report points out that although education and training can be helpful, not much is currently known about which approaches are most effective. institutional selfassessment and external peer review can be valuable tools in developing and improving education and training. smaller institutions may need to take advantage of consortia or electronic communications to provide their researchers with adequate education and training.the leaders of research groups have a particular responsibility to see that professional standards are observed in the conduct of research. they should ensure that the members of their groups have opportunities to learn about the proper management of data. research leaders also have an obligation to set a standard for responsible behavior and to monitor and guide the actions of the members of their groups. implementing institutional policies at the group level, holding regular meetings to discuss data issues, and providing careful  supervision all help to create a research environment in which the integrity of data is understood, valued, and ensured.26as described earlier, the need for training in the standards of research has been made more urgent by the advance of the digital age. the application of digital technologies in research has fundamentally altered the daily practices and interpersonal interactions of everyone involved in the research enterprise. researchers need to become familiar with complex and rapidly changing systems to review, visualize, store, summarize, and search for information. they need to understand the technologies and methods they apply to the collection, analysis, storage, and dissemination of data in sufcient detail to have condence in the integrity of those data. unless they understand the procedures used to generate, process, represent, and document data, they risk wasting 24 ofce of research integrity. 2008. annual report 2007. washington, dc: department of health and human services.25 institute of medicine. 2002. integrity in scientic research: creating an environment that promotes responsible conduct. washington, dc: the national academies press.26 chris b. pascal. 2006. ﬁmanaging data for integrity: policies and procedures for ensuring the accuracy and quality of the data in the laboratory.ﬂ science and engineering ethics 2:23œ39.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.56 ensuring the integrity, accessibility, and stewardship of databox 24 training in data management the program fostering integrity in research, scholarship, and teaching (first) at the university of minnesota includes an online workshop in research data management. new faculty members, postdoctoral fellows, and graduate students who are acting as principal investigators or otherwise have responsibility for the management of data are required to take the workshop, which takes about an hour to complete. the workshop is organized around four online case studies in the following areas: ensuring data reliability, controlling access to data, maintaining data integrity, and following retention guidelines. the case study on data retention, for example, is the following:a group of scientists gathered new research data and published their ˚ndings. this exciting research led to a rethinking of some fundamental aspects of superconductivity, and generated a signi˚cant amount of discussion. about 3 years after the original publication date, however, a suggestion for a different interpretation of the data was made. to prove that the initial interpretation was correct, the principal investigator (pi) from the project decided to reevaluate the data taken 5 years earlier. unfortunately, the raw data had been destroyed after they were entered into the computer, and the computer ˚les were thrown out with the computer 1 year ago.each case study is followed by a series of questions to answer and links to additional information. pages that provide answers to frequently asked questions and an opportunity to send additional questions to experts in the responsible conduct of research provide additional resources.for more information, see http://www.research.umn.edu/datamgtq1/index.htm.resources or reducing the quality of their data and research conclusions. in a profession so dependent on advanced computing and communications, every researcher needs to understand not only how to use computers but how computing affects research.producing clear, uptodate  standards for data integrity:  a shared responsibility of the research enterpriseresearchers, research institutions, research sponsors, professional societies, and journals all are responsible for creating and sustaining an environment that supports the efforts of researchers to ensure the integrity of research data. in some cases, digital technologies are having such a dramatic effect on ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity of research data 57research practices that professional standards either have not yet been established or are in ˚ux.27 the research enterprise needs to redouble efforts to set clear expectations for appropriate behavior and effectively communicate those expectations. recommendation 3: the research enterprise and its stakeholdersšresearch institutions, research sponsors, professional societies, journals, and individual researchersšshould develop and disseminate professional standards for ensuring the integrity of research data and for ensuring adherence to these standards. in areas where standards differ between elds, it is important that differences be clearly dened and explained. specic guidelines for data management may require reexamination and updating as technologies and research practices evolve. to date, research communities have responded to the new challenges of the digital age in a largely decentralized fashion, adapting traditional ethical standards to new circumstances. this decentralized approach is appropriate in that data management practices are so varied across research elds that a ﬁone size ts allﬂ approach would not address important issues, and the imposition of detailed standards from outside a eld is unlikely to be effective. in some cases, elds of research within and across disciplines may be able to cooperate in developing standards for ensuring the integrity of research data.the application of professional standards can be complicated in the case of interdisciplinary research, where investigators in different elds bring different practices to joint projects. in this case, familiarity with the standards and expectations of all the elds represented by that research is preferable to the blanket imposition of overly broad standards. better education and training in data management for investigators, combined with expanded access to research data across disciplines (which is the subject of the next chapter), will best serve the advance of knowledge and other public interests.the roles of data professionalsalthough all researchers should understand digital technologies well enough to be condent in the integrity of the data they generate, they cannot always be expected to be able to take full advantage of new capabilities. instead, they may have to rely on collaborations with colleagues who have specialized training in applying digital technologies in research. through their indepth knowledge of digital technologies and how those technologies can advance 27 the quality standards applied to microarray data in proteomics provide a good example of ongoing efforts to improve the data generated by a rapidly evolving technology. see s. rogers and a. cambrosio. 2007. making a new technology work: the standardization and regulation of microarrays. yale journal of biology and medicine 80:165œ178.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.58 ensuring the integrity, accessibility, and stewardship of dataknowledge in a particular eld, data professionals can make key intellectual contributions to the progress of research.data professionals have a wide range of backgrounds, levels of training, and roles in research. some serve in a support role for research groups; others make substantial intellectual or other contributions to research that warrant professional rewards such as inclusion in a list of authors. the roles of data professionals vary from eld to eld, but in an increasing number of elds, data professionals are assuming a shared professional responsibility with researchers for maintaining the integrity of research data. chapters 3 and 4 return to the roles of data professionals in enabling access to and preserving research data. the following recommendation re˚ects their importance in ensuring data integrity.recommendation 4: research institutions, professional societies, and journals should ensure that the contributions of data professionals to research are appropriately recognized. in addition, research sponsors should acknowledge that nancial support for data professionals is an appropriate research cost in an increasing number of elds.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.3ensuring access to research datathe advance of knowledge is based on the open ˚ow of information. only when a researcher shares data and results with other researchers can the accuracy of the data, analyses, and conclusions be veried. different researchers apply their own perspectives to the same body of information, which reduces the bias inherent in individual perspectives. unrestricted access to the data used to derive conclusions also builds public condence in the processes and outcomes of research.furthermore, scientic, engineering, and medical research is a cumulative process. new ideas build on earlier knowledge, so that the frontiers of human understanding continually move outward. researchers use each other™s data and conclusions to extend their own ideas, making the total effort much greater than the sum of the individual efforts. openness speeds and strengthens the advance of human knowledge. as an example, box 31 describes how the sharing of genomic data has advanced life sciences research.finally, only by sharing research data and the results of research can new knowledge be transformed into socially benecial goods and services. when research information is readily accessible, researchers and other innovators can use that information to create products and services that meet human needs and expand human capabilities. the organisation for economic cooperation and development (oecd) describes a new effort to enhance public access to research data (see box 32). according to this approach, ﬁopenness means access on equal terms for the international research community at the lowest possible cost, preferably at no more than the marginal cost of dissemination. open access to research data from public funding should be easy, timely, userfriendly and preferably internetbased.ﬂ1 as the national research council™s 1 ﬁoecd principles for access to research data from public funding,ﬂ available at http://www.oecd.org/dataoecd/9/61/38500813.pdf.59ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.60 ensuring the integrity, accessibility, and stewardship of databox 31 access to genomic data in biology, the culture of research and the applications of digital technologies have traditionally been heterogeneous, independent, and dispersed. however, the growth of interdisciplinary research, the advent of projects that have generated large volumes of data, and the invention of dataintensive devices such as dna microarrays and highthroughput sequencers have highlighted the increasing importance of digitization of the biomedical sciences.a in the ˚eld of genomics, strong forces have pushed in the direction of unrestricted access to data, including directives from funding agencies, requirements from journals that researchers submit data to public repositories, community expectations, and the development of powerful datasharing systems such as pubmed. in the case of the human genome, for example, the desire by funding agencies, researchers, and the general public for public access to research data led the genomics research community to develop an ethic of unrestricted access. this ethic was formally adopted as the ﬁbermuda statementﬂ in february 1996: all human genomic information produced at largescale sequencing centres should be freely available and in the public domain, in order to encourage research and development and to maximize its bene˚t to society.b at the same time, other forces have had the effect of restricting access to genomics data, including:the need to protect patient or individual privacy;the principal investigator™s desire to maintain research advantage;the danger of misuse (e.g., of virus sequences);a pro˚t motive (for data with potential commercial value);the tendency to ﬁpublish and forgetﬂ used data, especially supplementary data. the generation of complete genome sequences for a growing number of organisms has intensi˚ed the digitization of biomedical research. these data have many applications in both basic and applied research, with the lines between the two often being dif˚cult to discern. for example, computational processing and reference to information and knowledge bases about organisms and disease processes allow researchers to reach faster conclusions about the likely results of a therapy.c the combination of cellular data, genomic pro˚ling, and biological simulation may reduce the failure rate of drug candidates and the cost of testing. in the near future, it will even be possible, given suf˚cient computing and storage resources, to record the genotype of each person in a secure database. variations in genes may indicate speci˚c disease susceptibility or responses to known drug types. this information could enable physicians to prescribe a personal immunization and screening schedule or to recommend speci˚c preventive measures for each patient. further integration of the biomedical sciences using digital technologies could allow independent investigators to remain the engine of innovative research by participating in ﬁvirtual team science.ﬂ early examples of such ﬁcyberinfrastructureﬂš including the biomedical informatics research network, mygrid, and the cancer biomedical informatics gridšindicate that it is technically feasible, if not easy, to integrate the many threads of biomedicine. the challenge is to ensure that new ﬁcybersilosﬂ do not replace existing disciplinary and institutional silos.da ﬁthe race to computerize biology.ﬂ 2002. economist, dec. 12, 2002.b david r. bentley. 1996. ﬁgenomic sequence information should be released immediately and freely in the public domain.ﬂ science 274:533œ534. this statement was written on behalf of the sanger institute at the wellcome trust genome campus and the genome sequencing center at washington university in st. louis.c chris sander. 2000. ﬁgenomic medicine and the future of health care.ﬂ science 287:1977œ1978.d kenneth h. buetow. 2005. ﬁcyberinfrastructure: empowering a ‚third way™ in biomedical research.ﬂ science 308: 821œ824.committee on issues in the transborder flow of scientic data stated in its report bits of power: issues in global access to scientic data, ﬁthe value of data lies in their use.ﬂ2the norms and traditions of research re˚ect the value of openness. researchers receive intellectual credit for their work and recognition from their peersšand perhaps from the broader community of researchers and the publicšwhen they publish their results and share the data on which those results are based. some 2 national research council. 1997. bits of power: issues in global access to scientic data. washington, dc: national academy press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 61box 31 access to genomic data in biology, the culture of research and the applications of digital technologies have traditionally been heterogeneous, independent, and dispersed. however, the growth of interdisciplinary research, the advent of projects that have generated large volumes of data, and the invention of dataintensive devices such as dna microarrays and highthroughput sequencers have highlighted the increasing importance of digitization of the biomedical sciences.a in the ˚eld of genomics, strong forces have pushed in the direction of unrestricted access to data, including directives from funding agencies, requirements from journals that researchers submit data to public repositories, community expectations, and the development of powerful datasharing systems such as pubmed. in the case of the human genome, for example, the desire by funding agencies, researchers, and the general public for public access to research data led the genomics research community to develop an ethic of unrestricted access. this ethic was formally adopted as the ﬁbermuda statementﬂ in february 1996: all human genomic information produced at largescale sequencing centres should be freely available and in the public domain, in order to encourage research and development and to maximize its bene˚t to society.b at the same time, other forces have had the effect of restricting access to genomics data, including:the need to protect patient or individual privacy;the principal investigator™s desire to maintain research advantage;the danger of misuse (e.g., of virus sequences);a pro˚t motive (for data with potential commercial value);the tendency to ﬁpublish and forgetﬂ used data, especially supplementary data. the generation of complete genome sequences for a growing number of organisms has intensi˚ed the digitization of biomedical research. these data have many applications in both basic and applied research, with the lines between the two often being dif˚cult to discern. for example, computational processing and reference to information and knowledge bases about organisms and disease processes allow researchers to reach faster conclusions about the likely results of a therapy.c the combination of cellular data, genomic pro˚ling, and biological simulation may reduce the failure rate of drug candidates and the cost of testing. in the near future, it will even be possible, given suf˚cient computing and storage resources, to record the genotype of each person in a secure database. variations in genes may indicate speci˚c disease susceptibility or responses to known drug types. this information could enable physicians to prescribe a personal immunization and screening schedule or to recommend speci˚c preventive measures for each patient. further integration of the biomedical sciences using digital technologies could allow independent investigators to remain the engine of innovative research by participating in ﬁvirtual team science.ﬂ early examples of such ﬁcyberinfrastructureﬂš including the biomedical informatics research network, mygrid, and the cancer biomedical informatics gridšindicate that it is technically feasible, if not easy, to integrate the many threads of biomedicine. the challenge is to ensure that new ﬁcybersilosﬂ do not replace existing disciplinary and institutional silos.da ﬁthe race to computerize biology.ﬂ 2002. economist, dec. 12, 2002.b david r. bentley. 1996. ﬁgenomic sequence information should be released immediately and freely in the public domain.ﬂ science 274:533œ534. this statement was written on behalf of the sanger institute at the wellcome trust genome campus and the genome sequencing center at washington university in st. louis.c chris sander. 2000. ﬁgenomic medicine and the future of health care.ﬂ science 287:1977œ1978.d kenneth h. buetow. 2005. ﬁcyberinfrastructure: empowering a ‚third way™ in biomedical research.ﬂ science 308: 821œ824.journals require the submission and public dissemination of the data supporting an accepted manuscript. funding agencies and research institutions also have policies that require the open sharing of the data on which research conclusions are based. codes of conduct in a research community, whether explicit or tacit, can exert a powerful in˚uence on researchers to make data accessible.advances in information technologyšfor instance, the advent of grid computing and cloud computing3šwill continue to transform the environment for 3 in grid computing, distributed computing resources link experimental apparatus, processing, analysis, and storage; cloud computing involves largescale, dataintensive, internethosted applications and related infrastructure.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.62 ensuring the integrity, accessibility, and stewardship of databox 32 oecd principles and guidelines for access to  research data from public funding from 2004 to 2006 the 30nation organisation for economic cooperation and development (oecd) developed a set of guidelines based on commonly agreed principles to facilitate costeffective access to digital research data generated through public funding. endorsed by the oecd council on december 14, 2006, the ﬁoecd principles and guidelines for access to research data from public fundingﬂ serve as objectives for each member country to achieve given its own legal, cultural, economic, and social context. the principles and guidelines cover 13 broad areas: openness flexibility transparency legal conformity protection of intellectual property formal responsibility professionalism interoperability quality security ef˚ciency accountability sustainability the principles and guidelines call ﬁfor a exible approach to data accessﬂ under a default principle of openness and recognize ﬁthat one size does not ˚t all.ﬂ they also state that ﬁwhatever differences there may be between practices of, and policies on, data sharing, and whatever legitimate restrictions may be put on data access, practically all research could bene˚t from more systematic sharing.ﬂnote: for more information, see organisation for economic cooperation and development. 2007. oecd principles and guidelines for access to research data from public funding. available at http://www.oecd.org/dataoecd/9/61/38500813.pdf.research and lower the technical barriers to sharing data. as this transformation occurs, researchers are organizing their work in new ways to take advantage of new possibilities. an innovative example is the conduct of research in what can be called an openknowledge environment.4 building on the methodology pioneered by the opensource software movement, this approach begins with 4 economist. 2004. ﬁan opensource shot in the arm?ﬂ june 10.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 63the identication of a problem that is to be examined in a public forum on the internet. researchers from different disciplines, organizations, and countries then can all contribute to solving the problem, with the open sharing of data and ideas that might bear on that problem. an openknowledge environment allows people with many different backgrounds and viewpoints to interact in a relatively unstructured way while moving toward a common objective. the free ˚ow of information speeds progress, while the global reach of the internet greatly expands the number and breadth of researchers who can contribute to a project. another approach to sharing is opennotebook science.5 similarly, blogs, wikis, and other forms of electronic interaction are tools that enable collaborative work on common problems in a generally open research environment.in the context of this report, sharing research data enhances the data™s integrity by allowing other researchers to scrutinize and verify them (as described in the chapter 2). sharing also increases the likelihood that data will be preserved for longterm uses, although the stewardship of data requires more than that the data be accessible (as described in the chapter 4). thus, the three themes of this reportšintegrity, accessibility, and stewardshipšare intertwined.barriers to sharing datadespite the many benets to be gained by the sharing of research data and results, even a cursory survey of research activity reveals many circumstances in which access to data is limited.because researchers require time to verify data, analyze their data, and derive research conclusions, individual researchers generally are not expected to make all their data public immediately. individual researchers need latitude to follow hunches, experiment with methods, explore conjectures, and make mistakes. new tools for automatically assessing the quality of data and sharing them with others can facilitate the rapid sharing of digital data, although verifying the reliability of these tools presents its own set of challenges. once a research result is published, the norms of sciencešand often the terms of the research grant or contractšcall for the supporting data to be accessible. researchers may nevertheless try to keep the data private, perhaps to derive additional results without competition from others, for the exclusive use of a student or postdoctoral fellow whose career would be advanced by generating further papers, or just to avoid the effort to put the data in usable form for others. in the worst cases, they may retain data to hide acts of research misconduct or to conceal defects in the dataset.the norms of a research community may allow keeping data private for a certain period. these norms can be formalized through the terms of a grant 5 katherine sanderson. 2008. ﬁdata on display.ﬂ nature. 455:273. ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.64 ensuring the integrity, accessibility, and stewardship of datagiving the investigator a dened period of exclusive use of the data, with the exclusivity ending upon the publication of results, after a particular length of time, or when data are deposited in a data center or archive. there is great variation among research elds in their datasharing norms, to such an extent that different elds can be said to have different data cultures. (box 33 describes aspects of the data culture in economics.) a recent report commissioned by the research information network of the united kingdom examined datasharing practices and expectations across a number of elds (table 31).6 the report highlights the global importance and relevance of data accessibility in research, as well as the fact that differences between elds are often more important than national differences in determining datasharing practices. the international aspects of data access and sharing are discussed in more detail below.observational astronomy offers a good example of the datasharing norms that can characterize a eld of research. astronomical data often can be used for multiple purposes and are usually made public, but proprietary periods in which only the members of a research team have access to data are common. the european southern observatory (europe™s large optical observatory) and the national aeronautics and space administration have 12month proprietary periods. the u.s. national optical astronomy observatory has an 18month proprietary time. these periods provide researchers with an opportunity to make discoveries as a reward for dedicating signicant periods of their careers to creating new facilities and developing new techniques. they also provide an opportunity for critical evaluation of the data before they are released.in the highenergy physics community, collaborations are so large and the experiments so complexšwith hundreds of scientists involved with the operation of a single detectoršthat it could take years for an independent scientist to learn enough to reanalyze the data. the data of each collaboration are treated as proprietary. other groups that want to undertake the same measurement must form their own large collaboration and repeat the experiment. as explained in box 21, large collaborations in highenergy physics involve elaborate procedures for internal scrutiny of and validation of data.cultural norms and expectations in research elds regarding data can change over time. for example, as data sharing has proven increasingly valuable to the advancement of research in many areas of the life sciences, researchers, sponsors, research institutions, and other stakeholders have built new infrastructure and established guidelines to facilitate data sharing. a 2003 national research council study (box 34) recommended guidelines for the sharing of 6 alma swan and sheridan brown. 2008. to share or not to share: publication and quality assurance of research data outputs. report commissioned by the research information network. june. available at: http://www.rin.ac.uk/datapublication.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 65box 33 data sharing within economics economists rely on an enormous variety of research datašfor instance, administrative data from government records, datasets provided by companies to the federal government, or data provided directly to researchers by companies. some economists rely on methods similar to those used by anthropologists, in which large quantities of data are collected and analyzed. often the datasets are subject to con˚dentiality agreements because individuals could be identi˚ed from the data. use of the data may even be restricted to ﬁenclaves,ﬂ where a researcher has to work on a nonnetworked computer in a secure room from which materials cannot be removed. analysis of economic data may depend critically on highly complex computer programs. these programs, rather than the actual data, can be the most valuable part of an economist™s research, because many datasets are available publicly, whereas a computer program could embody months or years of individual effort. thus, to assess the original analysis, other researchers often need access to the computer programs as well as to the original data. as in other sciences, the social sciences have an expectation of reproducibilityšthat if the data are available and analyzed with the same assumptions, the same results will emerge. but without considerable assistance from the original researchers, actual replication of published results in economics can be timeconsuming, tedious, and subject to many errors. furthermore, journals are reluctant to publish studies that are con˚rmatory rather than groundbreaking. social scientists, like other scientists, are more interested in doing their own studies and getting credit for something new than in repeating work that has already been done. even if replication is not common, the data should be available to enable replication, but in economics this often is not the case.a several years ago two economists wrote to the authors of every paper in the march 2004 issue of the american economic review, a leading journal in the ˚eld, and requested the data to replicate the research. although the journal has a statement saying ﬁauthors are required to maintain their data and supply it to other researchers upon request,ﬂ 14 of the 15 sets of authors to whom the economists wrote said that they did not have the data or would not share them. the authors summarized their ˚ndings in an article and submitted it to the american economic review, which published their paper. as a result of this and other cases, the american economic review adopted a new policy. for published articles, the authors must provide both the data and the programs suf˚cient for the articles™ ˚ndings to be replicated. these data and programs are then posted on the journal™s web site. if the use of the data is restricted, the authors must provide instructions on how to obtain permission to use the data. if some of the data are proprietary, the editors try to work out ways for other researchers to use the data. in addition, the journal is encouraging studies to reanalyze data and replicate results. the american economic review is supported by dues from 20,000 members and has the resources to institute such a policy, whereas journals with fewer resources could have dif˚culty adopting and enforcing the same or similar policies. also, the data and programs are not requested at the time of submission of an articlešonly upon acceptancešso that the 92 percent of the papers submitted to the journal that are rejected do not fall under the new guidelines. some economists have decided not to submit a paper to the american economic review because they do not want to release their data or software. nevertheless, because authors want to publish their papers in the journal, it has considerable inuence over their actions.a robert a. mof˚tt, american economic review, presentation to the committee, april 17, 2007.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.66 table 31 summary of the datasharing environment in various fields in the united kingdomculture of sharing datainfrastructurerelated barriers to publishing dataeffect of policy initiatives to encourage data publishingoverall propensity to publish datasets (with appropriate metadata and contextual documentation)astronomystrong culture of sharinglow level of barrierspolicy has medium positive effectstrong propensity to publish datasetschemical crystallographymedium culture of sharinglow level of barrierspolicy has little positive effectstrong propensity to publish datasetsgenomicsstrong culture of sharinglow level of barrierspolicy has strong positive effectstrong propensity to publish datasetssystems biologymedium culture of sharingmoderate level of barrierspolicy has strong positive effectmedium propensity to publish datasetsclassics (humanities)strong culture of sharinghigh level of barriersapolicy has medium positive effectmedium propensity to publish datasetssocial and public health sciencesweak culture of sharinglow level of barrierspolicy has little positive effectlow propensity to publish datasetsbrelucmedium culture of sharinglow level of barrierspolicy has medium positive effectmedium propensity to publish datasetsclimate scienceweak culture of sharinglow level of barriersdpolicy has medium positive effectlow to medium propensity to publish datasetsa the arts and humanities data service was established in 1995 to provide a national service to collect, preserve, and promote electronic resources in the arts and humanities; its funding was eliminated in 2008. b this descriptor covers researchers not directly connected with a national data collection. c the rural economy and land use program is a collaborative research program among several uk research councils. d the natural environment research council provides data centers.source: © research information network. 2008. to share or not to share: publication and quality assurance of research data outputs. june. http://www.rin.ac.uk/datapublication.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 67box 34 sharing publicationrelated data and materials in 2003 the national research council committee on responsibilities of authorship in the biological sciences released a report that focused directly on the issues discussed in this chapter. in that report, the committee established what it called ﬁthe uniform principle for sharing integral data and materials expeditiouslyﬂ (upside). they described this principle as follows:community standards for sharing publicationrelated data and materials should ow from the general principle that the publication of scienti˚c information is intended to move science forward. more speci˚cally, the act of publishing is a quid pro quo in which authors receive credit and acknowledgment in exchange for disclosure of their scienti˚c ˚ndings. an author™s obligation is not only to release data and materials to enable others to verify or replicate published ˚ndings (as journals already implicitly or explicitly require) but also to provide them in a form on which other scientists can build with further research. all members of the scienti˚c communityšwhether working in academia, government, or a commercial enterprisešhave equal responsibility for upholding community standards as participants in the publication system, and all should be equally able to derive bene˚ts from it. the committee also identi˚ed ˚ve corollary principles associated with sharing publicationrelated data, software, and materials. for example, the committee stated that ﬁauthors should include in their publications the data, algorithms, or other information that is central or integral to the publicationšthat is, whatever is necessary to support the major claims of the paper and would enable one skilled in the art to verify or replicate the claims.ﬂ the committee noted that its purview extended only to the biological sciences. it also stated, however, that ﬁin the committee™s view, there should be a single scienti˚c community that operates under a single set of principles regarding the pursuit of knowledge. this includes a common ethic with regard to the integrity of the scienti˚c process and a longheld commitment to the validation of concepts of experimentation and later veri˚cation or refutation of published observations.ﬂsource: national research council. 2003. sharing publicationrelated data and materials: responsibilities of authorship in the life sciences. washington, dc: the national academies press.data and other information supporting research results that emphasize openness and expanded access, including research performed by companies.7 although the charge to our committee excluded privacy and other issues 7 national research council. 2003. sharing publicationrelated data and materials: responsibilities of authorship in the life sciences. washington, dc: the national academies press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.68 ensuring the integrity, accessibility, and stewardship of datarelated to human subjects from our study, it is important to note that these issues can act as barriers to data access. some data are not released because of condentiality or privacy considerations, such as data related to biomedical research or the social sciences. for example, the 1996 health insurance portability and accountability act established rules for disclosure of individually identiable health information (known as protected health information, or phi).8 if phi is used in research, the researcher must comply with regulations regarding its use and storage in the project. there are instances where phi may be disclosed, but the need to support published research is not among them. for phi to be made publicly available, a subject must agree to the disclosure of the information.for some medical research data, privacy and condentiality obstacles can be overcome by removing identiers prior to the private sharing of data or the public release of data. however, this remains an area of ongoing concern and investigation. efforts are now under way to make medical research data available while ensuring that the data cannot be used to identify individuals.research data also can be kept private because they pertain to intelligence, military, or terrorist activities.9 examples include research related to nuclear, radiological, and biological threats; human and agricultural health systems; chemicals and explosives; and information technology infrastructure. national security decision directive 189 (nsdd 189), which was issued by president ronald reagan in 1985, states that the policy of the u.s. government is not to restrict, to the maximum extent possible, the products of unclassied fundamental research.10 the challenge to policy makers and researchers is where to draw the line between classied and unclassied information and how to balance restrictions on access to sensitive information with the potential costs of such restrictions.our committee was not asked to examine national security issues in depth. other national research council committees, including the committee on scientic communication and national security (cscans), are directly focused on issues such as classied information, export controls, and nonimmigrant visa policies. a recent cscans report points out that many federal government policies and practices since the september 11 attacks have effectively reversed nsdd 189.11 the report calls for a standing entity to review policies in order to 8 institute of medicine. 2006. effect of the hipaa privacy rule on health research: proceedings of a workshop presented to the national cancer policy forum. washington, dc: the national academies press.9 national research council. 2007. science and security in a post 9/11 world: a report based on regional discussions between the science and security communities. washington, dc: the national academies press.10 national policy on the transfer of scientic, technical and engineering information. september 21, 1985. 11 ibid.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 69ensure that the small risks of basic research being misused are balanced with the enormous benets that accrue from the free exchange of information. another national research council committee examined the national security implications of access to genomic databases and found that unrestricted access, combined with the development of education programs by professional societies, is the best approach to balancing the advancement of knowledge with protecting the public from misuse of genomic data for bioterrorism threats.12 the federal government™s creation in 2008 of a new categoryšﬁcontrolled unclassied informationﬂšillustrates that restrictions on the sharing of research based on national security concerns will continue to pose challenges to the research enterprise.13when research is carried out or sponsored by public agencies, the general presumption in the united states is that data generated as part of that research should be publicly available.14 different considerations apply for research funded by a private company, whether that research occurs within a company or in the academic sector. though some companies have been experimenting with the benets of freely sharing results from proprietary research,15 many companies carefully guard this information as a trade secret and a potential source of commercial advantage. similarly, an academic researcher may temporarily withhold data in order to le a patent or develop a commercial product, even when the research is publicly funded. these issues are discussed later in this chapter.the cost of disseminating data can be a barrier to its use. circular a130 from the ofce of management and budget (omb) stipulates that governmentgenerated data should be available to users at cost sufcient to recover the expense of dissemination but not higher.16 however, data from private sources, even when purchased by the federal government for research purposes, frequently have high distribution costs and restrictions on redistribution. these costs can be a signicant problem for academic researchers who need access to large databases for modeling or data analysis.finally, research data may be kept private because the resources are lacking to make data collections available to the public. a project might generate data that could be valuable to researchers in the same or other elds, but the 12 national research council. 2004. seeking security: pathogens, open access, and genome databases. washington, dc: the national academies press.13 george w. bush. 2008. ﬁdesignation and sharing of controlled unclassied information (cui).ﬂ memorandum for the heads of executive departments and agencies. may 9.14 paul f. uhlir and peter schröder. 2007. ﬁopen data for global science.ﬂ data science journal 6:od36œod53.15 bernard munos. 2006. ﬁcan opensource r&d reinvigorate drug research?ﬂ nature reviews drug discovery 5:723œ729.16 ofce of management and budget. no date. management of federal information resources. circular a130. memorandum for heads of executive departments and agencies. available at http://www.whitehouse.gov/omb/circulars/a130/a130trans4.html.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.70 ensuring the integrity, accessibility, and stewardship of datainvestigators who generated those data may not have the resources or capabilities needed to make them available. this is frequently the case in smallscale research that does not have funding set aside for such functions or does not have a robust data management component in place. alternatively, the data may be available, but the essential metadata needed to understand and use those data may be missing, making the data useless for anyone outside the immediate research team.in general, researchers have a strong incentive to release the results of research. their own recognition and advancement in their eld generally depend on public dissemination of those results. in contrast, researchers have traditionally had few incentives to make publicly available the data they generate in the course of research. however, those data may have great value for other researchers, and making data publicly accessible can speed the advance of knowledge.the costs of limiting access to databarriers that restrict access to data, such as withholding data or delaying their release, can result in substantial costs.17 once data have been gathered from an instrument or compiled from other sources, it is obviously more costeffective to share the data than to reconstruct or recompile them. furthermore, resources spent accessing data then are not available for other research uses.limitations on research data also can be barriers to innovation, which incurs costs in the broader society.18 in today™s economy, the creation of new goods and services often depends on access to research data. when access is withheld, economic innovation slows, reducing the returns to investments in research.limiting access to research data also hinders the kinds of interdisciplinary and international cooperation that has proven so productive in recent research. when data are restricted to a particular research team or eld, other researchers not only cannot use the data but often cannot even ascertain the value of those data to their own research. similarly, if students are unable to work with new research data, their education and training may be adversely affected.limitations on the accessibility of data invariably retard, and can even block, the process of verifying the accuracy of those data. as a result, the quality of the data could be lower than would be the case if they were freely available, again reducing the return on the investment in producing the data.finally, researchers who are deprived of access to data are disadvantaged in conducting research and possibly seeking support to do research. this 17 uhlir and schröder, op. cit., pp. od42œod43.18 national research council. 1999. a question of balance: private rights and the public interest in scientic and technical databases. washington, dc: national academy press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 71problem can be particularly acute in developing countries, where lack of access to data from developed countries can stymie not only the development of research capacity but advances in economic productivity, public health, and wellbeing.data access issues in research affecting  public policy or private interestsrestricting access to data can be costly and wasteful, but there also are circumstances in which providing access to data can entail substantial costs and waste. there are situations in which responding to requests for data could actually slow the progress of research, and there have been instances in which requests for data have been intended to inhibit research.it is not uncommon for a small research group to lack the resources to make data readily accessible. especially as data collections grow in size and complexity, small groups may have difculty providing data to other researchers in the same eld, much less making data readily accessible to researchers in elds less directly connected to the research, or to the public.access to data can also become an issue of contention in cases where research has important implications for public policy or has a potential for affecting private interests in such areas as the environment or health. an early example was the case of paul fischer, who was subpoenaed in the early 1990s by a tobacco company after publication of his research showing widespread recognition among young children of the ﬁjoe camelﬂ character used in cigarette advertising.19 fischer initially was subpoenaed in a lawsuit to which he was not subject. in addition to requesting details about the research that would be considered reasonable and necessary to replicate the results, the subpoena contained more problematic demands, such as personal details about the subjects. according to his own account, fischer™s institution, the medical college of georgia, refused to provide legal support. after fischer, using his own attorney, had quashed the subpoena, the medical college of georgia™s counsel wrote an article that had the effect of alerting r.j. reynolds to an alternative legal mechanism, the georgia open records act. under this act, fischer ultimately was compelled to turn over all the information except the children™s names.perhaps the most famous recent example involved a research project to reconstruct global temperature trends over the last two millennia. a 1998 paper by michael mann of pennsylvania state university and two coauthors made extensive use of proxy studies in which paleoclimatic conditions were inferred from measurements of tree rings, sediments, coral, glaciers, oxygen isotopes, and other phenomena, concluding that global surface temperatures 19 paul m. fischer. 1996. ﬁscience and subpoenas: when do the courts become instruments of manipulation?ﬂ law & contemporary problems 29:159œ167.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.72 ensuring the integrity, accessibility, and stewardship of datawere relatively stable for 900 years and then rose rapidly between 1900 and 2000, providing a ngerprint for humancaused climate change.20 after the release of the third assessment report of the intergovernmental panel on climate change that cited this nding in 2001, it became a point of contention in debates over the reality and causes of global warming. mann resisted when researchers skeptical of his work requested access to the underlying data and computer programs used in the reconstruction, and controversy ensued.21 two members of the u.s. house of representatives issued a letter requesting a wide variety of information from each of the three coauthors of the paper, giving them 18 days to provide, among other things, a curriculum vitae with a list of all studies they authored on climate change and the specic sources of funding; a list of all nancial support received from private, state and federal sources for climaterelated work; the location of all underlying data archives related to such research and its specic availability; correspondence regarding requests for such data from other researchers, responses to such requests and the researchers™ reasons for their decisions, and indepth responses to inquiries about their work on bristlecone pines and the intergovernmental panel on climate change.22 this request was viewed by some as intimidation.23 the national research council released a study in 2006 that examined the rapidly emerging eld of multiproxy paleoclimate studies.24 the report ultimately afrmed some, but not all, of the key results of mann™s work, while stating that ﬁall research benets from full and open access to published datasets and . . . a clear explanation of analytical methods is mandatory.ﬂ the report also points to the need for researchers, professional societies, journals, and research sponsors involved in paleoclimate research to improve access to data and methods.25 this is not an isolated example of a research eld with highly charged policy implications. research data and ndings have a substantial in˚uence on a growing number of issues, ranging from arms control to air quality, endangered species, environmental toxins, and school vouchers.26 in many of these cases, researchers are being asked to contribute information in areas 20 mann, michael e., raymond s. bradley, and malcolm k. hughes. 1998. ﬁglobalscale temperature patterns and climate forcing over the past six centuries.ﬂ nature 392: 779œ787.21 geoff brumel. 2006. ﬁacademy afrms hockeystick graph.ﬂ nature 441:1032. the researchers requesting the data and other information were stephen mcintyre and ross mckitrick.22 letter from representatives joe barton and ed whiteld to dr. raymond s. bradley, june 23, 2005. available at http://republicans.energycommerce.house.gov/108/letters/062305bradley.pdf.23 letter from dr. alan i. leshner to representative joe barton, july 13, 205. available at http://www.aaas.org/spp/cstc/docs/057œ13climatebarton.pdf.24 national research council. 2006. surface temperature reconstructions for the last 2,000 years. washington, dc: the national academies press.25 the wording in this paragraph has been changed to correct some factual errors.26 see the list of ﬁexamples of political interference in scienceﬂ maintained by the union of concerned scientists at http://www.ucsusa.org/scienticintegrity/interference/atozalphabetical.html.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 73where government has responsibility for public health and wellbeing, such as environmental quality regulations or the legal responsibility of manufacturers for product harms. in these areas, the role of research is increasingly being challenged by those who oppose particular regulations, laws, or legal rulings.27 these cases raise important and difcult questions: when are researchers justied in withholding underlying data and methods? what recourse do colleagues, policy makers, and the public have when data or methods underlying research on important policy issues are withheld? what is the line between harassment that unreasonably slows the pace of research and justied requests for information? these trends point to the need for clearer standards and understandings between researchers, their employers, and the public about the overarching value of openness, as well as the circumstances under which requests or demands for data are reasonable and when they cross the line into the realm of harassment that can slow the advance of knowledge. there are important and complex questions about how to balance the need for important data to be widely accessible, with fundamental issues of academic freedom, condentiality, and the need for researchers to carry out their studies free of harassment, intimidation, or outside pressure.ownership of research data and related productsaddressing the question of ﬁwho owns research dataﬂ is a key element of the authoring committee™s charge. there is a range of possible answers, including the researcher, the institution, the sponsor, or nobody, depending on the particular meaning of ﬁownershipﬂ and the context. this section will review the laws and policies relevant to the ownership of research data and related rights to control its dissemination and use. the next section will cover other laws and policies related to research data, focusing on obligations to keep or share data.to begin with, general principles of property law apply to the media on which data are stored and may also apply to the bits themselves in the case of digital data. one analogy is to the master recording in the music business when analog technology dominated. the owner of the master tape has a property right in the object but does not necessarily own the copyright that controls the copying and distribution of the data stored in the recording. similarly, the researcher, his or her institution, or the sponsor (depending on the terms of the research grant or contract) may own the medium on which the data are stored. more important, for the purposes of this discussion, than ownership of the physical storage media are intellectual property rights in a database (some 27 wendy wagner and rena steinzor, eds. 2006. rescuing science from politics: regulation and the distortion of scientic research. new york: cambridge university press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.74 ensuring the integrity, accessibility, and stewardship of dataspecic arrangement or organization of the data), in a publication whose central ideas are based on the data, or in an invention that is based on the data. we will consider each of these related issues in turn.copyright, database protections, and licensingin the united states, copyright protection is extended to ﬁoriginal works of authorship xed in any tangible medium of expression. . . .ﬂ28 copyright holders enjoy the exclusive right to disseminate their creations and to earn a prot by selling or licensing them. raw data and other facts, however, are not protected as copyrightable subject matter. databases are copyrightable if the selections or arrangement are original; the mere compilation of facts or data into a collection does not entitle them to protection. these provisions were reinforced by the 1991 supreme court ruling in feist publications, inc. v. rural telephone service co., which limited copyright protection for databases to those arranged and selected in an original manner.29 in addition, the federal government is prohibited from exerting copyright protection over its own publications, including data generated by government entities. finally, copyright law includes provisions for ﬁfair useﬂ exceptions in which portions of a copyrighted work may be used without permission in teaching, research, and other specied pursuits. this basic framework has served to support the open ˚ow of research data. federal agencies have been central in sustaining a strong public domain in data.30 with regard to research data, private companies and nonprot entities play an important role in creating databases and information services that are utilized by researchers. the existence of copyright protection for creative and original data collections provides an incentive for investments in valuable products and services in the private sector. digital technologies have introduced new considerations into copyright laws and enforcement.31 technological barriers to violating copyrights have fallen, posing challenges to copyrightbased industries such as music, newspapers, and motion pictures. before the digital age, the trigger for a copyright violation of a printed document was the act of copying. a photocopy of a document for personal use falls under the fairuse provisions, but copying now can be done almost effortlessly. if a document is made into a pdf le that can be circulated on the internet, the distinction between private use and publication vanishes.28 u.s. code, title 17, chapter 1, section 102. available at http://www4.law.cornell.edu/uscode/html/uscode17/uscsec1700000102000.html.29 499 u.s. 340 (1991).available at http://laws.ndlaw.com/us/499/340.html.30 national research council. 2003. the role of scientic and technical data and information in the public domain: proceedings of a symposium. washington, dc: the national academies press.31 national research council. 2000. the digital dilemma: intellectual property in the information age. washington, dc: national academy press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 75digital technologies have also made possible new approaches to commercializing the provision of data and data services.32 several legal and policy changes of recent years have strengthened the position of copyright holders. these include lengthening of the term of copyright protection and the passage of the digital millennium copyright act of 1998 (dmca). the dmca implemented the world intellectual property organization treaty on copyrights, and criminalized the circumvention of technical measures to prevent copying of digital materials, even in the absence of actual copying. these technical measures include hardware and softwarebased access controls, increasingly effective forms of encryption, and other forms of digital rights management that limit access to or copying of data.in addition, in 1996 the european community enacted a directive on the legal protection of databases that established a framework for new proprietary rights specic to databases.33 experts have warned that a combination of expanded copyright protections, advances in technological means of restricting access to digital content, and database protections of the type that europe has adopted could enable the assertion and enforcement of proprietary claims to factual matter that previously entered the public domain as soon as it was disclosed.34 the united states and many other countries have not followed the european union in establishing a new intellectual property regime for databases. an area where advancing technology and the increased use of contracts and licensing have changed the environment for access is remote sensing and geographic data and services.35 federal agencies have traditionally acquired full ownership rights to geographic data (such as maps and books) from private entities and have allowed that information to enter the public domain so as to be accessible without restrictions to other uses. however, as digital media have become more prevalent, private data providers have moved to business models focused on selling multiple licenses and access subscriptions to databases. a 2004 national research council report recommended approaches agencies should take to licensing geographic data and services in order to maximize their utility, including a recommendation that the federal government should foster 32 national research council. 2004. licensing geographic data and services. washington, dc: the national academies press.33 commission of the european communities. 2005. first evaluation of directive 96/9/ec on the legal protection of databases. dg internal market and services working paper. december 12. available at http://ec.europa.eu/internalmarket/copyright/docs/databases/evaluation reporten.pdf.34 j. h. reichman and paul f. uhlir. 2003. ﬁa contractually reconstructed research commons for scientic data in a highly protectionist intellectual property environment.ﬂ law and contemporary problems 66:315œ462.35 see national research council. 2002. toward new partnerships in remote sensing: government, the private sector, and earth science research. washington, dc: the national academies press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.76 ensuring the integrity, accessibility, and stewardship of datathe creation of a national commons and marketplace in geographic information.36 such an approach might be relevant to other elds where commercial entities play a major role in data collection and dissemination. certainly, copyright protection, licensing, and an active commercial database market can coexist with a strong public domain in digital data. in recent years, efforts have been undertaken to utilize licensing to actively foster an expanded public domain. although, as noted above, data are not subject to copyright protection, uncertainties about what data users are legally allowed to do with them can inhibit sharing and reuse. for example, it may not be clear whether a particular data collection is copyrightable or whether the creator intends to assert copyright. the fact that copyright persists for many yearsšwhether it is asserted or notšmeans that a database may need to be actively placed into the public domain in order for users to be certain that it is free from copyright restrictions and any type of reuse is permitted. creative commons and its offshoot, science commons, have developed a number of innovations in the area of licensing aimed at facilitating open dissemination, sharing, and use of a wide  variety of information, including data. for example, creative commons recently launched its cc0 (ﬁcczeroﬂ) protocol that allows creators of copyrightable work, including database generators, to waive all rights they may have to a given work, to the extent possible in the applicable jurisdiction.37 patentspatents give researchers, nonprot organizations, companies, and other entities the right to prot from an innovation. in return, the property owner must make the innovation public, which enables others to build on it. once intellectual property is patented, it can be freely disseminated while still maintaining its commercial value to a company or research institution.the bayhdole act of 1980 has had a major in˚uence on the development of products from publicly funded research. the act granted the rights to inventions with the university, smallbusiness, or nonprot institution that accepted the research grant supporting the work. to accept this ownership, the university, small business, or nonprot institution must:report each disclosed invention to the funding agency;elect to retain title in writing within a statutorily prescribed time frame;file for patent protection;grant the federal government a nonexclusive, nontransferable, irrevocable, paidup license to the invention;36 national research council, licensing geographic data and services.37 http://wiki.creativecommons.org/cczero.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 77actively promote and attempt to commercialize the invention;not assign the rights to the technology, with a few exceptions;share royalties with the inventor;use any remaining income for education and research;give preference to u.s. industry and small business.for research that is supported exclusively by nonfederal money, the title to any inventions resulting from those data is owned according to the conditions established by the funder. for instance, corporate employees must assign their intellectual property rights to their employer, even sometimes for work done outside the scope of their employment. when research in an academic institution is supported by corporate money, the conditions of ownership must be clearly specied. the conditions often include proprietary control over the outputs of that research. in the case of academic research that is supported by nonprot organizations, control is established by the granting organization. one example is the howard hughes medical institute, which retains title to all inventions arising from its support but frequently assigns its rights to the associated university or nonprot institution. trade secrecy may be used as an alternative to patenting. in some cases, inventions and underlying data have been held as proprietary trade secrets by companies and even universities and thus are treated as protected information as long as reasonable efforts are made to maintain secrecy. researchers and their employers have this option, particularly if they do not plan to seek credit for the ndings by reporting or publishing the results. also, in cases where research at a university is supported by a private company, a research contract may provide for a short delay in publication or sharing data until the patentability of the research ndings can be evaluated and, if appropriate, patent applications are led.as noted above, academic researchers may have incentives to transfer their research ndings to the private sector. these include the desire to see their discoveries translated into useful products or to prot themselves from commercial opportunities made possible by research. if these incentives cause researchers to withhold data, the net effect can be for research data to become less available.in 2006, a national research council committee examined whether changes in patenting and licensing practices by companies and research institutions pose a threat to continued progress in the rapidly advancing areas of genomics and proteomics research.38 the committee found that although difculties in accessing proprietary research materials are clearly burdening research 38 national research council. 2006. reaping the benets of genomic and proteomic research: intellectual property rights, innovation, and public health. washington, dc: the national academies press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.78 ensuring the integrity, accessibility, and stewardship of dataefforts, limited access to data is currently not a serious problem. the committee recommended that the national institutes of health (nih) continue efforts to encourage the free exchange of data and materials through mechanisms such as requiring grantees to develop and adhere to datasharing plans. the committee also called for efforts on the part of the u.s. patent and trademark ofce to improve understanding of rapidly emerging technologies in order to avoid the extension of patent protection to inventions that do not meet the patentability standards of novelty, utility, and nonobviousness. journals and access to datathe interest of scientic, technical, and medical (stm) journals in the integrity of research data, and their role in ensuring it, was discussed in chapter 2. because journal articles are the primary means of communicating the results of research, and rely on data to support their ndings, journals also play an important role in facilitating access to data. although research data are not copyrightable, papers incorporating those data are. the conventional arrangement in traditional stm publishing has been for authors to transfer their copyright in the article they have written to the publisher, generally with some retention of rights to use the article.39 the environment for stm journal publishing has changed considerably in recent years, as it has for nearly all publishing and media businesses.40 traditional subscriptionaccess stm journals are published by both commercial and nonprot entities. commercial stm publishing has seen signicant consolidation, with fewer companies publishing larger numbers of journals. subscription prices for traditional stm journals have seen steep increases, putting severe pressure on research library budgets.41 concurrently, open access stm journals have emerged as a signicant part of the scholarly publishing world.42 one prominent example of an open access publisher is public library of science (plos), which publishes several highimpact journals in the life sciences.43 39 some universities assert copyright in selected categories of work by faculty, but often grant rights back to faculty for the purpose of traditional academic scholarship. see national academy of sciences, national academy of engineering, and institute of medicine. 2004. electronic scientic, technical, and medical journal publishing and its implications. washington, dc: the national academies press.40 ibid.41 judith m. panitch and sarah michalak. 2005. the serials crisis: a white paper for the uncchapel hill scholarly communications convocation. january. available at http://www.unc.edu/scholcomdig/whitepapers/panitchmichalak.html.42 ﬁopen accessﬂ refers to publications, data collections, and other digital resources that are available to anyone without charge, and to the scholarly movement that advocates for policies and  practices supporting such digital resources. the advocacy movement is referred to in the report as ﬁopen access,ﬂ and the publications, data collections, and other digital resources as ﬁopen access.ﬂ43 see the plos homepage at www.plos.org.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 79another relevant trend is the growth in open access mandates for published research that have been initiated by research sponsors and research institutions. the most signicant of these was adopted in early 2008 by nih, having been mandated by congress in the consolidated appropriations act of 2008 and made permanent in the omnibus appropriations act of 2009.44 the nih policy provides that: the director of the national institutes of health (ﬁnihﬂ) shall require in the current scal year and thereafter that all investigators funded by the nih submit or have submitted for them to the national library of medicine™s pubmed central an electronic version of their nal, peerreviewed manuscripts upon acceptance for publication, to be made publicly available no later than 12 months after the ofcial date of publication: provided, that the nih shall implement the public access policy in a manner consistent with copyright law.ﬂ 45research institutions are also adopting open access recommendations for faculty research, encouraging faculty to provide electronic copies of their articles for submission to an institutional or other open access repository, generally with an embargo period of 6 to 12 months. this is an international trend, with research institutions or sponsors (both public and private) adopting open access publication recommendations in europe, canada, australia, and india.46 the issues raised by the changing environment for scholarly publishing are the subject of continued, vigorous debate. although they are not within the task statement of this study, it is necessary to review them in this context because access to scholarly publications is related to access to research data at several levels. for example, institutional and governmental repositories that support access to, and stewardship of, faculty articles may serve the same function for data (the data stewardship function of repositories is discussed in chapter 4). it is also important to note the distinctions between open access to data and open access to publications. traditional access stm publishers that might look unfavorably on open access publication mandates might support practices and guidelines encouraging open access to data.47 open access mandates for data, to be discussed in the next section, are distinct from open access mandates for publications. 44 national institutes of health. 2009. the omnibus appropriations act of 2009 makes the nih public access policy permanent: notod09071. march 19. available at http://grants.nih.gov/grants/guide/noticeles/notod09071.html.45 ibid.46 a continuously updated list of open access publication mandates is available at http://www.eprints.org/openaccess/policysignup/.47 see international association of scientic, technical & medical publishers. 2009. briefing document (for publishing executives) on institutional repositories and mandated deposit policies. january; international association of scientic, technical & medical publishers. 2006. databases, datasets, and data accessibilityšviews and practices of scholarly publishers. june. available at http://www.stmassoc.org/documentsstatementspublicco/.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.80 ensuring the integrity, accessibility, and stewardship of datalegal and policy requirements for access to datathe data access act and the information quality actvarious government laws, regulations, and policies in˚uence the accessibility of research data. among these are the data access act (daa) of 1999 and the information quality act (iqa) of 2001, also known as the data quality act.48the daa is also known as the ﬁshelby amendment,ﬂ after its sponsor, senator richard shelby of alabama. it was passed as a rider to an appropriations bill in 1999. the daa requires that data from federally funded research be made available to requesting parties under freedom of information act procedures if the research is: (1) used to support an agency action, and (2) performed by a university or other nonprot institution.49 in response, omb modied its circular a110 to read as follows: [i]n response to a foia [freedom of information act] request for research data relating to published research ndings under an award that were used by the federal government in developing an agency action that has the force and effect of law, the federal awarding agency shall request, and the recipient will provide within a reasonable amount of time, the research data so that they can be made available to the public under foia.the provision established which types of research data are subject to disclosure and the procedures, standards, and exemptions that apply in requesting and disclosing those data. before the provision was published, persons could only obtain raw data that were in possession of a federal agency, whereas the revised provision provided access to data that are in possession of a grantee institution. if even a small amount of public money was used to produce data, those data may be subject to daa requests. however, studies conducted by industry or by others without the use of public funds are not covered by the datasharing requirements, even if the studies are employed in the formulation of public policy or regulations. also, as interpreted by omb, the provision applies only to data supporting regulations with a ﬁmajorﬂ impact on the economy and is prospective, covering studies launched after the omb guidelines were put into effect.the daa was controversial at the time the legislation passed and when omb was developing the specic changes to circular a110. participants in a 2001 national research council workshop pointed out future problems that 48 national research council. 2002. access to research data in the 21st century: an ongoing dialogue among interested parties: report of a workshop. washington, dc: the national academies press.49 wendy wagner and david michaels. 2004. ﬁequal treatment for regulatory science: extending the controls governing the quality of public research to private research.ﬂ american journal of law & medicine 30:119œ154.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 81might be encountered in implementing the daa, suggesting that this approach might not be an ideal way to ensure public access to data underlying federal policies and regulations.50 at the same time, the daa does not appear to have led to any contentious cases during the decade since it went into effect. for example, a 2003 general accounting ofce report found that two agencies had received a total of 42 requests under the daa up to that time, and that none of the requests had actually met the circular a110 criteria.51the iqa was passed as a twosentence rider to the 2001 consolidated appropriations act. the iqa called on omb to issue regulations for ﬁensuring and maximizing the quality, objectivity, utility, and integrity of information (including statistical information) disseminated by federal agencies.ﬂ in response, omb issued guidelines that all agencies ﬁmust embrace a basic standard of quality as a performance goal, and agencies must incorporate quality into their information dissemination practices.ﬂ52 the guidelines state that ﬁif an agency is responsible for disseminating in˚uential scientic, nancial, or statistical information, agency guidelines shall include a high degree of transparency about data and methods to facilitate the reproducibility of such information by qualied third parties.ﬂ53 for ﬁoriginal and supporting data,ﬂ agencies are to consult with ﬁrelevant scientic and technical communitiesﬂ and determine which data are subject to the reproducibility requirement.54 ﬁreproducibilityﬂ here means a high level of transparency about research design and methods, which is meant to negate any need to replicate work before dissemination. for ﬁanalytic resultsﬂ there must be ﬁsufcient transparency about data and methods that an independent reanalysis could be undertaken.ﬂ55 this means that ﬁindependent analysis of the original or supporting data using identical methods would generate similar analytic results, subject to an acceptable degree of imprecision or error.ﬂ56 in cases where the public does not have access to data and methods (privacy, security, trade 50 see national research council, access to research data in the 21st century. in particular, chapter 6, which reports on workshop chair richard merrill™s summary remarks, is a concise statement of the longerterm shortcomings of daa.51 general accounting ofce. 2003. university research: most federal agencies need to better protect against financial con˚icts of interest. gao0431. november. washington, dc: general accounting ofce.52 ofce of management and budget. 2002. ﬁguidelines for ensuring and maximizing the  quality, objectivity, utility, and integrity of information disseminated by federal agencies; notice;  republication.ﬂ federal register 67(36):8451œ8460. available at http://www.noaanews.noaa.gov/stories/feb22.pdf. this federal register entry includes the nal guidelines as well as a discussion of the comments received.53 ibid., p. 8455.54 ibid.55 ibid., p. 8456.56 ibid.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.82 ensuring the integrity, accessibility, and stewardship of datasecrets), ﬁagencies shall apply especially rigorous robustness checks to analytic results and document what checks were undertaken.ﬂ57a committee organized by the national research council™s committee on science, technology, and law held several workshops in 2002 to discuss omb™s iqa guidance and the agency responses that were being developed. the summary of those workshops reviews a number of the issues agencies faced in developing their own implementing guidelines.58federal and journal policies affecting the availability of datatable 22 shows federal agency policies toward availability of data generated directly by agencies as well as data generated by external grantees. in 2008 the federal government released its principles for the release of scientic research results in response to the america competes act of 2007.59 these principles promote sharing of data from research undertaken by federal civilian agency employees. for federally sponsored research performed by external organizations, the grants guides of agencies vary in how strongly data sharing is encouraged or required. a 2007 government accountability ofce (gao) assessment of agency policies toward grantees in climate science found that although agencies encouraged data sharing, the specic requirements varied from program to program.60 for example, the national science foundation (nsf) grants guide states the expectation that grantees make their data ﬁwidely available and usefulﬂ within a ﬁreasonable time.ﬂ specic nsf programs might require that data be deposited in a specic repository within a set time period following data collection. the gao report also found that agencies generally do not monitor whether datasharing requirements are being met and have not overcome barriers to sharing, such as the lack of appropriate data archives in some subelds of climate science.although specic federally sponsored research programs include a range of datasharing mandates, no federal agency has yet adopted an agencywide open access data mandate, analogous to nih™s open access publication mandate. nih does require that grant proposals above a certain size include a data management plan consistent with nih™s data sharing policy, which is discussed further below in the section on ﬁresponsibilities of research institu57 ibid., p. 8457.58 national research council. 2003. ensuring the quality of data disseminated by the federal government: workshop report. washington, dc: the national academies press.59 john h. marburger, iii. 2008. principles for the release of scientic research results. memorandum. may 28. available at www.arl.org/bm~doc/ostpscienticresearch28may08.pdf.60 government accountability ofce. 2007. climate change research: agencies have datasharing policies but could do more to enhance the availability of data from federally funded research. september. available at http://www.gao.gov/new.items/d071172.pdf.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 83tions, research sponsors, professional societies, and journals.ﬂ federal agencies are creating new open access data resources, such as the department of energy™s data explorer program, an open access repository of data from doesponsored research, and national library of medicine efforts such as genbank, which is discussed elsewhere in the report.61 some private research sponsors such as the wellcome trust have adopted open access data mandates for their grantees.62 as shown in table 21, an increasing number of stm journals have adopted open access data mandates for authors.63the international dimensions of  access to research datathe advent of digital networks has enabled and stimulated global access to all types of digital information, including research data. access to research data online means that researchers can use the data on a global basis, enhancing the universal progress of science to solve common problems and develop new knowledge. both the benets and the costs of unrestricted and restricted access are thus amplied in the international context.the united states has been a leader in promoting openness to public  sector information, as well as to publicly funded research data. despite the trends in elds with commercial potential toward more proprietary treatment of academic research and the postseptember 11 increase in national security restrictions on some sensitive data sources and types, the overall policy trend may be seen as moving toward greater access to both governmental and academic research data sources. the international dimensions of access to research data are being shaped both from the bottom up and the top down.at the informal working level of the individual investigator, data are now shared across geographic boundaries as easily as they once were with the colleague next door. countless international data exchanges are made among scientists on a daily basis, or through the posting of datasets on individual researchers™ web sites.at a more formal level, international research projects establish datasharing protocols that re˚ect the norms of the elds in which they are operating. some of the larger research or infrastructure programs are establishing data centers or federated networks for sharing of data resources. the rst international network of such data centers, the world data center system, was formed following the 1957 international geophysical year to help bridge the gap in cooperation and data exchanges during the cold war.61 see http://www.osti.gov/dataexplorer/.62 see http://www.wellcome.ac.uk/aboutus/policy/policyandpositionstatements/wtx035043.htm.63 see, for example, http://www.nature.com/authors/editorialpolicies/availability.html.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.84 ensuring the integrity, accessibility, and stewardship of datawith the advent of global digital networks over the past two decades, both international cooperation in research and the formation of networked data resources on regional and global levels have become commonplace. examples include the global biodiversity information facility, the international federation of digital seismograph networks, the international nucleotide sequence database collaboration, the international virtual observatory alliance, and the global earth observation system of systems, to name but a few. almost all elds of inquiry have some data centers or networks designed to provide access to data. in most cases, the u.s. research community has been the organizing force for the collaborative datasharing networks.greater access to research data from public funding also is receiving more attention at the national policy levels of many countries, in part because such data resources are now seen as being major research infrastructure components. for example, the research councils of the united kingdom adopted a more open policy for their data holdings in 2006. the ministry of science and technology in china initiated the scientic data sharing project in 2002, in recognition of the fact that ﬁ[t]he insufcient use of china™s massive data holdings has been an urgent problem.ﬂ64 many other countries are similarly reviewing or revising their national policies and myriad institutional ones to make better use of their data resources.finally, some international scientic, engineering, and medical organizations at both the intergovernmental and nongovernmental levels, such as the international council of scientic unions, the committee on data for science and technology, and the oecd, are developing datasharing policies and guidelines for adoption by members and the international research community. for example, the oecd in 2007 published its principles and guidelines for access to research data from public funding, which are summarized in box 32. the interacademy panel, an organization of national science academies, supports a program to expand access to digital scientic information to researchers in developing countries.65general principle for enhancing  access to research databecause of the huge increase in the quantity of research data being generated, it is possible to say both that more data are being publicly disseminated than have ever been before and that more data are being withheld from public 64 jinpei cheng. 2006. the development of china™s scientic data sharing policy. in national research council. strategies for preservation of and open access to scientic data in china: summary of a workshop. washington, dc: the national academies press. available at: http://www.nap.edu/catalog.php?recordid=11710.65 see the program™s web site: http://www.interacademies.net/cms/programmes/4704.aspx.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 85access today than have ever been before. many elds of research have moved toward more open datasharing policies as the value of data has increased and as digital technologies have enabled information to be disseminated more broadly. at the same time, heightened interest in the commercial applications of research data has caused some forms of data to be more restricted.as described earlier in this chapter, there are legitimate reasons why some research data are not made publicly available, ranging from privacy concerns to technical barriers. yet the basic principle that should guide decisions involving research data supporting publicly reported research results is clear:data access and sharing principle: research data, methods, and other information integral to publicly reported results should be publicly accessible.this principle applies throughout research, but in some cases the open dissemination of research data may not be possible or advisable when viewed from the perspective of enhancing research in science, engineering, or medicine. access to research data prior to reporting results based on those data might undermine the incentives to pursue the research. there might also be technical barriers, such as the sheer size of datasets, that make sharing problematic, or legal restrictions on sharing as discussed in the section on ﬁlegal and policy requirements for access to data.ﬂ also, ﬁaccessibleﬂ does not necessarily imply that data should be disseminated for free, though free or marginally priced distribution is the ideal. nor are researchers responsible for providing data users with instruction or training in the use of their data, though they do have a responsibility to provide metadata, analysis software, models (including code and input data) and other information necessary for practitioners to validate and build on the results. where researchers have proprietary interests in such tools, they have the option of protecting those interests through applying for patents and/or asserting copyright, as appropriate, in advance of publicly reporting results.this principle is a standard that is not currently being met in some areas of research. yet it provides a yardstick against which to measure current initiatives and future plans. researchers know that the information they generate should be available to others to advance the frontiers of knowledge. the objective therefore must be to implement policies and promote practices that allow this principle to be realized as fully as possible. this principle may seem to apply only to publicly funded research, but a strong case can be made that much data from privately funded research should be made publicly available as well. in many cases, making such data available can produce societal benets while not threatening the commercial opportunities that led to the data™s generation. note that this principle covers data underlying publicly reported results. when a researcher working at a corporate lab seeks to publish results, patent applications can be led in advance ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.86 ensuring the integrity, accessibility, and stewardship of dataof publication, so that making data accessible at the time of publication will not compromise commercialization of the invention in question. if a company decides to protect an invention as a trade secret, it might be assumed that researchers will not publish papers about the invention and the question of providing access to data will not arise. in the past few years we have also seen private companies announce plans to make signicant data resources available on an open access basis. for example, merck has spun off a nonprot, open access platform known as sage.66 sage is aimed at helping researchers to build new databases aimed at more effectively modeling disease. where possible, public policies should encourage the release of such data, and privately funded researchers and their managers should explore possible means of making data available.the access and sharing principle is consistent with recommendations from national academies committees that have previously addressed data access. a 2003 report, sharing publicationrelated data and materials: responsibilities of authorship in the life sciences, puts forward the ﬁuniform principle for sharing integral data and materials expeditiously (upside).ﬂ67 the upside principle calls on researchers employed in the academic, government, and commercial sectors to provide data and materials needed to support published ndings, and to ﬁprovide them in a form on which other scientists can build with further research.ﬂ the 1997 report bits of power: issues in global access to scientic data states that ﬁfull and open access to scientic data should be adopted as the international norm for the exchange of scientic data derived from publicly funded research.ﬂ68responsibilities of researchersas with the integrity of research data, the primary responsibility for sharing data lies with the researchers who produced them. (in addition, other parts of the research enterprise have responsibilities for sharing data, as described later in this chapter and in the next chapter.) only researchers know their data well enough to ascertain what information must be publicly available to allow others to verify their results and build on their work. only researchers are in a position to work with research institutions, research sponsors, and journals to make data available in a way that they can be understood and used effectively by others. thus, our committee recommends that:66 bryn nelson. 2009. ﬁsomething wiki this way comes.ﬂ nature 458(13, march 4). doi:10.1038/458013a.67 national research council. 2003. sharing publicationrelated data and materials: responsibilities of authorship in the life sciences. washington, d.c: the national academies press.68 national research council. 1997. bits of power: issues in global access to scientic data. washington, dc: national academy press.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 87recommendation 5: all researchers should make research data, methods, and other information integral to their publicly reported results publicly accessible in a timely manner to allow verication of published ndings and to enable other researchers to build on published results, except in unusual cases in which there are compelling reasons for not releasing data. in these cases, researchers should explain in a publicly accessible manner why the data are being withheld from release.making data available does not necessarily mean providing them at no cost. the next chapter discusses the need for research projects to develop plans for the management and sharing of data from the initial stages of a research program. chapter 4 also describes the evolving infrastructure for providing data access and stewardship, whose components include institutional and disciplinary repositories. fullling this recommendation also requires that researchers be familiar with any possible constraints on the release of data. although this information is usually known to researchers and their managers from the outset of a research project, agreements may be informal, may be understood differently by different parties (such as principal investigators and graduate students), or may change during the course of a research project. requiring that researchers clarify and agree to these arrangements places the responsibility on researchers to oversee the accessibility of research data and to decide whether to participate in research where data accessibility is limited. researchers who are considering becoming involved in a project where data accessibility is restricted need to ask themselves whether the benets of participating in that project outweigh the benets of transparency in generating and disseminating data.research thrives under conditions where data are available to others. if data are not available, there should be a clear and public reason why those data are being withheld from dissemination. indeed, justications for not making data available should be understood by the researcher, sponsor, and institution. dissemination of the reasons why data are being withheld could be published with journal articles, posted on web sites, stated in the publicly accessible award statements of research sponsors or research institutions, or made available by some other means. the important point is that the reasons should be publicly available so that others can review and comment on the grounds for withholding data. as discussed in the following section, the committee believes that research elds, research sponsors, research institutions, and journals have considerable ability to set appropriate standards and expectations regarding data access and sharing, and to develop the necessary incentives. some are taking leadership roles in setting standards and instituting incentives. the committee believes that continued efforts taken by these stakeholders can create an environment in which the data access and sharing principle is widely followed in the research enterprise, and in which a bureaucratic framework of regulations and enforcement will not need to be imposed.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.88 ensuring the integrity, accessibility, and stewardship of dataresponsibilities of research fieldsas emphasized earlier, there are major differences between research elds in the handling of data, including technological infrastructure, publication practices, and datasharing expectations. in some elds, aspects of their data culture act as barriers to access and sharing of data. because of the growing importance of research data and the rate at which practices are changing in research, it is important for various elds and disciplines to examine their standards and practices regarding data and to make these explicit.the development of plans for data management and sharing is greatly facilitated when a eld of research has standards and institutions in place designed to promote the accessibility of data. recommendation 6: in research elds that currently lack standards for the sharing of research data, such standards should be developed through a process that involves researchers, research institutions, research sponsors, professional societies, journals, representatives of other research elds, and representatives of public interest organizations, as appropriate for each particular eld.the development of standards and institutions can occur in different ways depending partly on the eld of research in which it occurs. the process can be led by journal editors, professional societies, ad hoc bodies of researchers established to solve particular problems, or permanent institutions charged with overseeing data management issues. national academies committees and advisory committees to federal agencies can play constructive roles. in large, complex elds, multiple initiatives may be undertaken to address various aspects of standard setting. input and participation from international stakeholders will often be needed.the life sciences provide useful examples of the standardssetting process. as described in box 34, a national academies committee developed broad standards for the sharing of research data in the life sciences. similarly, as described in box 35, a journalled effort incorporating community input developed the paris guidelines for the management of protein data. both examples demonstrate how standards can be put in place to deal with existing or new issues affecting the management of research data.the principles for the release of scientic research results, released in 2008 and discussed in the earlier section on ﬁfederal and journal policies affecting the availability of data,ﬂ establish datasharing standards for research conducted by employees of federal civilian agencies.69 one section of the principles states: 69 john h. marburger, iii. 2008. principles for the release of scientic research results. memorandum. may 28. available at www.arl.org/bm~doc/ostpscienticresearch28may08.pdf.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 89box 35 the paris guidelines in some ˚elds, journals have played a major role in developing standards for data collection, sharing, and preservation. in 2004, for example, the journal molecular and cellular proteomics (mcp) developed standards for the management of protein data.a these standards were revised 1 year later based on community input, resulting in the ﬁparis guidelines.ﬂb these guidelines were made available in a checklist format, in a tutorial, and in mcphosted workshops to educate researchers about the details of the requirements for publication and data submission.c mcp™s standard requires all relevant quantitative data to be made available at a level in which it is possible to reproduce the reported results. methods can reference previously published standards but any deviations must be explained. in  particular, authors must submit along with the manuscript the data that have the greatest potential for misinterpretationšfor instance, mass spectrographic spectra for posttranslationally modi˚ed proteinsšfor the journal to publish. data considered less important but worthy of access are recommended for submission to the journal as supplementary material to be deposited in a nonjournal repository, which therefore may not be archival.d in addition, an institutionally based governmentfunded data depository was recommended (ﬁtrancheﬂ) that has a distributed storage system similar to bit torrent, thereby lessening costly bandwidth problems caused by downloading large amounts of data over the internet. in this way the paris guidelines ensure that the most important data are deposited for perpetual and accessible storage while secondtier data also are accessible without placing too large a burden on the journal as the sole repository for data.a steven carr, ruedi aebersold, michael baldwin, al burlingame, karl clauser, and alexey  nesvizhskii. 2004. ﬁthe need for guidelines in publication of peptide and protein identi˚cation data: working group on publication guidelines for peptide and protein identi˚cation data.ﬂ molecular and cellular proteomics 3:531œ533.b ralph a. bradshaw, alma l. burlingame, steven carr, and ruedi aebersold. 2006. ﬁreporting protein identi˚cation data: the next generation of guidelines.ﬂ molecular and cellular proteomics 5:787œ788.c see http://www.mcponline.org/misc/tutorialmcp˚nal.pdf.d for an example of supplementary data, see http://www.mcponline.org/cgi/content/abstract/6/7/1123.research data produced by scientists working within federal agencies should, to the maximum extent possible and consistent with existing federal law, regulations, and presidential directives and orders, be made publicly available consistent with established practices in the relevant elds of research.this principle is consistent with the data sharing and access principle stated above. this report advocates that the principle apply not just to federal scientists but to all research where results are publicly reported.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.90 ensuring the integrity, accessibility, and stewardship of dataa wide range of issues must be considered in setting data standards, including dissemination, usage restrictions, periods of exclusive use, documentation requirements, nancial provisions, ownership, licensing terms, infrastructure needs, technological compatibility, and sustainable preservation. these issues vary greatly from eld to eld, depending on particular traditions and requirements. although it is not impossible to prescribe a standard set of practices to which all researchers should adherešindeed, the general principles stated in this report apply to all researchersševery eld collectively and every researcher individually must address issues of data accessibility.responsibilities of research institutions, research sponsors, professional societies, and journalsfor researchers to make their data accessible, they need to work in an environment that promotes data sharing and openness. recommendation 7: research institutions, research sponsors, professional societies, and journals should promote the sharing of research data through such means as publication policies, public recognition of outstanding datasharing efforts, and funding as noted earlier in this chapter, research institutions, research sponsors, professional societies, and journals are undertaking a range of initiatives to promote the sharing of research data. in taking the next steps, research institutions and research sponsors need to create incentives for researchers to share data, just as they have incentives to maintain the integrity of research data and to publish their ndings. researchers need both formal and informal ways of being acknowledged and rewarded for making research data accessible and usable. for example, in some cases tenure and promotion decisions could take into account efforts to promote the accessibility of data, the creation of  publicationbased metrics, or service to a community or institution. data professionals also have an important role to play in ensuring the accessibility of research data. in close cooperation with researchers in a eld, data professionals can anticipate the needs of data users and establish data management systems that meet those needs. their contributions to making data accessible, as well as ensuring the integrity of data, need to be recognized.one way for research sponsors and journals to promote data accessibility is to establish the terms of access and sharing expected of institutions and investigators. for example, nih explicitly requires that all grant applications for more than $500,000 in direct costs in a single year must include a data management plan that embodies the principles of the nih data sharing policy. this policy says that ﬁdata should be made as widely and freely available as possible while safeguarding the privacy of participants, and protecting condential and ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 91proprietary data.ﬂ the data management plan becomes part of the proposal, and ﬁnih expects that plan to be enacted. . . . in the case of noncompliance (depending on its severity and duration) nih can take various actions to protect the federal government™s interests.ﬂ70 these actions are not specied but may affect the review of future proposals.as discussed above, research institutions, research sponsors, and journals have considerable leverage in encouraging data access and sharing on the part of researchers. several leading research institutions have announced open access publication recommendations, which encourage faculty to deposit their publications in their institutional repository. such recommendations could be extended to data. some federal research programs and journals have adopted open access data policies that require or encourage researchers to deposit underlying data in a disciplinary or institutional repository (see tables 21 and 22). depending on the program or discipline, adopting and effectively enforcing such open access data policies may be an appropriate way for research institutions, research sponsors, and journals to implement this recommendation. the council on government relations points out that ﬁfew institutions have formal policies and procedures for access to and retention of research data.ﬂ71 as described above, the terms of research contracts and grants and other regulations often specify that research institutions are responsible for retaining data and providing access. given the current lack of formal policies and procedures, we make the following recommendation.recommendation 8: research institutions should establish clear policies regarding the management of and access to research data and ensure that these policies are communicated to researchers. institutional policies should cover the mutual responsibilities of researchers and the institution in cases in which access to data is requested or demanded by outside organizations or individuals. the knowledge needed to develop data access policies is not widespread or fully developed. research institutions and sponsors may need to come together to identify best practices and policy models. organizations such as the association of american universities, the association of public and landgrant universities, the association of research libraries, and the council on government relations can contribute to this process. disputes between researchers and their institutions regarding control of data are not unusual. for example, faculty members may be denied tenure and seek to take their research data with them, while the institution may seek 70 national institutes of health ofce of extramural research. 2003. nih data sharing policy and implementation guidance.71 council on government relations. 2006. access to and retention of research data: rights and responsibilities. march. washington, dc: council on government relations.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.92 ensuring the integrity, accessibility, and stewardship of datato keep it. or researchers and institutions may have different perspectives on how to respond to outside requests for access to data, including requests made under the auspices of the daa or in connection with litigation. as described earlier in this chapter, requests for information can go beyond research data to information about a researcher™s personal life.procedures for handling requests for data that either intentionally or inadvertently hamper the progress of research need special attention. although the data from publicly funded research should be accessible in general, exploiting the norms of science to slow or stop the progress of research harms society. for example, institutional policies might stipulate that an institution will come to the aid of researchers in disputes with third parties, but researchers also must comply with institutional policies.many journals play a critical role in ensuring access to the data that support the publications appearing in those journals (see box 36 for an example). access to those data may be lost as journals evolve under the pressures of dramatic changes being catalyzed by digital technologies. the following chapter covers the responsibilities of journals to make data accessible in the context of the longterm preservation of research data.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring access to research data 93box 36 promoting reproducibility in medical research as of april 1, 2007, the annals of internal medicine instituted a new policy designed to help the research community evaluate and build on published results. authors of original research articles in the annals are required to include a statement indicating whether the study protocol, data, and statistical code are available to readers and under what terms the authors will share this information. sharing is not mandatory, but authors are required to state whether they are willing to share the protocol, data, and statistical code. authors are not asked whether they are willing to make this information available until after a manuscript is accepted for publication. according to an article announcing the new policy, the goal of the new requirement is to promote ﬁreproducible researchﬂ in which independent researchers can reproduce results using the same procedures and data as the original investigators. reproducible research does not require unlimited access to data and methods, but it requires access to as much of the dataset and statistical procedures as is necessary to reproduce the published results. as the article states:major cultural shifts in research must occur before a world of completely reproducible research can exist. these shifts include increasing the technical  capacity of many research teams, further developing acceptable datasharing mechanisms, and supportingšboth professionally and ˚nanciallyšthe publishing of reproducible research. . . . we hope that shining a spotlight on the availability of the study protocol, data, and statistical code for every annals research report will be seen as a small but important step toward biomedical research that the public can really trust. at the same time, it will enhance what is perhaps the main function of a journal: to provide a transparent medium for a conversation about science.aafor more information, see christine laine, steven n. goodman, michael e. griswold, and harold c. sox. 2007. ﬁreproducible research: moving toward research the public can really trust.ﬂ annals of internal medicine 146:450œ453.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.4promoting the stewardship of  research datarealizing the full value of research data requires that the data be accessible to the community of researchers and others who might be able to use them. the data need to be accompanied by sufcient metadata for them to be found easily, understood in context, and used appropriately. data need to be stored in repositories using uptodate technologies until a decision is made that the information is no longer needed. data useful for ongoing research or historical purposes may need to be stored indenitely. these issues of useful accessibility, annotation, curation, and preservation are the heart of what we term in this report the stewardship of research data.digital technologies are having a revolutionary effect on every aspect of data stewardship. the internet provides a mechanism for making data available to anyone anywhere in the world. powerful new computers and sophisticated software can automate part of the process of annotating data. data repositories offer a means for preserving digital data for the indenite future. though the infrastructure necessary for data stewardship is still taking shape, much of the technological capability needed to realize the full value of research data already exists.secondary use of data is of growing importance in an increasing number of elds. in astronomy, for example, the sloan digital sky survey, a project for which the open provision of both processed and raw data over the internet is central, is the facility responsible for the most highimpact papers in astronomy in recent years.1 repositories of genomic data, such as the trace archive of the national center for biotechnology information (ncbi), have become essential components of the national and global infrastructure for life sciences research 1 juan p. madrid and f. duccio macchetto. 2006. highimpact astronomical observatories.  bulletin of the american astronomical society electronic edition 38(4). available at http://www.aas.org/publications/baas/v38n4/baasv38n4madrid.pdf.95ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.96 ensuring the integrity, accessibility, and stewardship of data(see figure 41). in other areas, such as clinical data, the potential gains from data reuse are clear, even though technical and other barriers stand in the way of realizing that potential.2this technological capability has given rise to a powerful new vision of how some areas of research can be conducted.3 known as escience or cyberinfrastructure, this approach to research involves decentralized collaborations of researchers who draw on remote sensors and facilities, very large data collections, and powerful computing resources. these distributed resources are interconnected so that they can be shared in a ˚exible, secure, and coordinated manner. individuals and groups can build and make available services and tools that extend across research elds.4 in an interconnected grid of facilities, instruments, and computers, the collective knowledge of scientic, engineering, and medical research resides not just in published books and articles but in the grid itself.the loss and underutilization of research dataescience has been partially implemented in a number of research elds, but in others information technology is not being used to advantage.today, much research data that could be of value in the future are lost because of the lack of provisions for preserving them: research notebooks are discarded; computer hard disks crash, destroying unique data; an investigator changes elds, retires, or dies and leaves behind data that are poorly organized, haphazardly stored, or otherwise unusable.digital data are often stored in formats that rapidly become technologically obsolete. data stored on paper can survive for decades or centuries before the paper breaks down and becomes unreadable. in the digital age, however, the longevity of storage media sometimes seems to conform to an inverse moore™s law, with accelerating technological advances hastening the demise of superseded media. many scientists have data on ˚oppy disks, hard drives, or zip drives that new generations of computers cannot read. one expert raises the possibility of a ﬁdigital dark age,ﬂ in which large amounts of digital data stored in a variety of proprietary le formats are permanently lost.5 digital media also decay over time, a phenomenon known as ﬁbit rot.ﬂ many old magnetic tapes molder in boxes and are now essentially worthless. 2 james j. cimino. 2007. ﬁcollect once, use many: enabling the reuse of clinical data through controlled terminologies.ﬂ journal of ahima 78(2):24œ29.3 national science foundation cyberinfrastructure council. 2007. cyberinfrastructure vision for 21st century discovery. arlington, va: national science foundation. available at http://www.nsf.gov/pubs/2007/nsf0728/index.jsp.4 ian foster. 2005. ﬁserviceoriented science.ﬂ science 308:814œ817.5 phil ciciora. 2008. ﬁ‚digital dark age™ may doom some data.ﬂ university of illinois at urbanachampaign news bureau. october 27. available at news.illinois.edu/news/08/1027data.html.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.promoting the stewardship of research data 97figure 41 national center for biotechnology information trace archive through september 2008source: national center for biotechnology information (http://www.ncbi.nlm.nih.gov/traces/trace.cgi?cmd=show&f=graphquery&m=stat&s=graph).figure 41.eps25,684,81351,259,96387,453,129113,982,301132,229,420152,104,611226,192,298273,980,038340,339,353423,767,008531,589,248627,469,034740,913,078893,707,0381,060,193,8091,214,395,8981,368,844,5841,505,242,3431,718,037,6191,813,980,6481,895,402,0561,952,502,3517/0111/013/027/0211/023/037/0311/033/047/0411/043/057/0511/053/067/0611/063/077/0711/073/087/08data stored on cd disk drives begin to degrade within a few years. unless provisions are made to move data from one storage medium to another, the data are lost relatively quickly. of course, if data are judged to be valuable to a research community, resources can be devoted to replication so as to minimize the risk of digital media decay. as generations of applications, data formats, operating systems, and digital archives interoperate and succeed one another, multiple locations and systems for data access and sharing might be engaged to preserve a given data collection. ensuring that archived data are not altered due to human error or intentional mischief is an additional challenge for large data repositories, particularly those utilizing automated processes to ingest large datasets.6 table 41 shows the various risks to longterm digital data reliability and the time frames in which they might be expected to occur.6 national research council. 2005. building an electronic records archive at the national archives and records administration. washington, dc: the national academies press. see chapter 4 in particular.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.98 ensuring the integrity, accessibility, and stewardship of datathe loss of valuable data is especially a problem in small research projects. large projects often have data management plans and funds set aside for data storage and dissemination. individual investigators, however, typically face much greater challenges in deciding which data may be useful in the future, in documenting those data thoroughly, and in nding funds from limited budgets for adequate data curation and preservation. furthermore, although large projects can generate immense quantities of data, small research projects can themselves produce substantial quantities and varied kinds of data.some research elds that formerly consisted almost exclusively of small projects, such as molecular biology or ecology, have moved in part toward larger and more dataintensive programs. some of these elds have groups that oversee the collection and annotation of data for use by others. the social sciences, for example, have long sponsored a specialized institution that has data stewardship as part of its mission (see box 41). other elds, despite generating much larger quantities of data, continue to be characterized by largely disparate and often inadequate data management efforts.not all research data should be preserved, but deciding what to save and what to discard becomes increasingly difcult as ever larger quantities of data are generated. furthermore, there is a nancial tradeoff between creating new data and preserving old data. while the cost of storage per bit is declining rapidly, as described in chapter 1, data stewardship requires a longterm commitment of attention and resources. as the secondary use of data becomes more important for elds and disciplines, they need to develop guidance for researchers, research sponsors, and research institutions on what data should be preserved, and whether new organizations or capabilities are needed to perform stewardship functions. a 2002 national research council report on geosciences data and collections is a useful example of how research elds can develop criteria for prioritizing the data and collections that should be preserved, and for making the tradeoffs between creating new data and preserving existing data.7 7 national research council. 2002. geoscience data and collections: national resources in peril. washington, dc: the national academies press.table 41 longterm data reliability issuesentity at riskwhat can go wrong?frequencyfilecorrupted media, disk failure1 yeardisk simultaneous failure of two copies5 yearssystemsystematic errors in vendor software; malicious user; operator error that deletes multiple copies15 yearsarchivenatural disaster, obsolescence of standards50100 yearssource: francine berman, sdsc, presentation to the committee, september 2007.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.promoting the stewardship of research data 99the discussion of neuroscience data issues in box 13 illustrates the challenges facing dataintensive elds that need to develop policies, standards, and new organizational approaches to data stewardship. ownership considerations in˚uence the stewardship of research data, just as they do access to the data. as discussed in chapter 3, the institutions that receive research grants are generally acknowledged to be the owners of the data and other ﬁintangible propertyﬂ resulting from that research.8 however, for practical reasons, researchers may retain possession of the data on behalf of the institution, and institutions may specify in policies or contracts that investigators are to serve as the custodian of data and as the responsible party for preserving and retaining data.9 indeed, investigators often assume that they are the owners of the research data that they produce, which can create problems when they move to a different institution and their original institution exerts its ownership rights over the data.infrastructure and incentives for the  stewardship of dataeach group associated with the generation, use, and preservation of research data has different incentives and expertise with respect to the stewardship of those data.researchersalthough the researchers who generate the data have the greatest stake in their use, they do not necessarily have a strong interest or incentive in preserving data, especially in smallscale projects. most researchers prefer to pursue new goals rather than devote effort to making their existing and past data useful for others. figure 42 shows the results of a survey by the interuniversity consortium for political and social research (icpsr). many national science foundation (nsf) and nihsponsored projects that promised to create social science data have not followed through. investigators typically have little expertise in data annotation or longterm database management. this resistance to sharing on the part of faculty is changing over time, and this can be expected to accelerate as the value of publicly accessible data becomes more apparent in a wider range of disciplines, and as infrastructure for 8 council on government relations. 2006. access to and retention of research data: rights and responsibilities. washington, dc: council on government relations.9 for example, the national institutes of health (nih) requires that primary research data be retained for at least 3 years after the closeout of a grant or contract agreement. see http://grants.nih.gov/grants/policy/datasharing/datasharingguidance.htm.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.100 ensuring the integrity, accessibility, and stewardship of databox 41 data stewardship and accessibility in the  social sciences the interuniversity consortium for political and social research (icpsr) is an interdisciplinary institution established in 1962 to provide data stewardship and access for a wide range of datasets from the social sciences. part of a global network of social science data archives, icpsr is the world™s largest archive of digital social science data and is hosted by the university of michigan.a it is supported by dues from more than 600 member institutions, plus support from government agencies and other research sponsors. icpsr, which currently houses 7,500 studies and 500,000 data ˚les, has recommended guidelines, but not requirements, for submission of data. as part of its mission, icpsr proactively seeks out data at risk of being lost. it also emphasizes the importance of preparing good documentation, or metadata, which are critical to data interpretation and to successful data sharing and preservation. these metadata include project summaries, descriptions of data collection instruments, summary  statistics, database dictionaries, and bibliographies. as technology progresses, icpsr migrates data to new storage media and maintains sets of redundant copies in various locations.  ownership and access to data in the social sciences is determined by funding, with contractfunded data belonging to the sponsor and grantfunded data belonging to the grantee (typically a university). icpsr does not acquire copyright to databases but instead requests permission to redistribute. barriers to data access and sharing in the social sciences include generally weak federal requirements to archive and provide access to research data and the heterogeneity of expectations across ˚elds (with economics, demography, sociology, and criminology having a stronger tradition of data sharing than anthropology and epidemiology). in a recent icpsr study on datasharing and archiving practices, researchers surveyed principal investigators from nih and nsffunded projects and asked whether their projects had produced data and, if so, whether the data had been archived (see figure 42). of the 1,599 responses received as of late 2008, 327 studies had been archived, 876 studies were still in the hands of researchers, and 396 studies had been ﬁlost.ﬂ preserving and sharing social sciences data involves the risk of violating an individual™s privacy. each data collection is reviewed to see if it could reveal individual identities. if such information is found, it is removed, masked, or collapsed in the publicuse version. icpsr staff are trained and certi˚ed in disclosure risk limitation procedures. original restricted data can be requested under terms of a contract, and the most sensitive data can be viewed onsite in a nonnetworked ﬁdata enclaveﬂ with signi˚cant security checks. icpsr also has a strong educational component. workshops and courses on research methods in the quantitative social sciences are offered to graduate students and faculty from around the world, mainly in the summer. icpsr also provides datadriven instructional modules at the undergraduate level to enable teachers to integrate data into the curriculum. over time, icpsr™s archival model has proven to be an effective approach to ensuring data integrity, facilitating data sharing, and providing data stewardship across a range of ˚elds and many institutions. because many social science data are used for secondary analysis, and because the social sciences reward academic producers of generalpurpose data, universities see the value of icpsr, which makes the membership funding model sustainable. the emerging world of massively complex and voluminous data raises new challenges. there will be no single repository and no single harmonization scheme. unrestricted access is needed to realize the full value of data, which may lead to greater risk of disclosure and con˚dentiality breaches. new tools need to be developed to enable the merging of disparate data and communication across disciplines. building new, dynamic communities around data and cuttingedge research questions will require the collaborative efforts of technologists and domain scientists. a greater focus by institutions and federal sponsors on data preservation and access also will be needed.a http://www.icpsr.umich.edu.making data available on a longterm basis diffuses more widely and becomes easier to use.research institutions, research libraries, and repositoriesinstitutional and disciplinary digital data repositories have been growing steadily. the emergence of open access software tools for building repositories (such as dspace, eprints, and fedora), external repository hosting services, ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.promoting the stewardship of research data 101box 41 data stewardship and accessibility in the  social sciences the interuniversity consortium for political and social research (icpsr) is an interdisciplinary institution established in 1962 to provide data stewardship and access for a wide range of datasets from the social sciences. part of a global network of social science data archives, icpsr is the world™s largest archive of digital social science data and is hosted by the university of michigan.a it is supported by dues from more than 600 member institutions, plus support from government agencies and other research sponsors. icpsr, which currently houses 7,500 studies and 500,000 data ˚les, has recommended guidelines, but not requirements, for submission of data. as part of its mission, icpsr proactively seeks out data at risk of being lost. it also emphasizes the importance of preparing good documentation, or metadata, which are critical to data interpretation and to successful data sharing and preservation. these metadata include project summaries, descriptions of data collection instruments, summary  statistics, database dictionaries, and bibliographies. as technology progresses, icpsr migrates data to new storage media and maintains sets of redundant copies in various locations.  ownership and access to data in the social sciences is determined by funding, with contractfunded data belonging to the sponsor and grantfunded data belonging to the grantee (typically a university). icpsr does not acquire copyright to databases but instead requests permission to redistribute. barriers to data access and sharing in the social sciences include generally weak federal requirements to archive and provide access to research data and the heterogeneity of expectations across ˚elds (with economics, demography, sociology, and criminology having a stronger tradition of data sharing than anthropology and epidemiology). in a recent icpsr study on datasharing and archiving practices, researchers surveyed principal investigators from nih and nsffunded projects and asked whether their projects had produced data and, if so, whether the data had been archived (see figure 42). of the 1,599 responses received as of late 2008, 327 studies had been archived, 876 studies were still in the hands of researchers, and 396 studies had been ﬁlost.ﬂ preserving and sharing social sciences data involves the risk of violating an individual™s privacy. each data collection is reviewed to see if it could reveal individual identities. if such information is found, it is removed, masked, or collapsed in the publicuse version. icpsr staff are trained and certi˚ed in disclosure risk limitation procedures. original restricted data can be requested under terms of a contract, and the most sensitive data can be viewed onsite in a nonnetworked ﬁdata enclaveﬂ with signi˚cant security checks. icpsr also has a strong educational component. workshops and courses on research methods in the quantitative social sciences are offered to graduate students and faculty from around the world, mainly in the summer. icpsr also provides datadriven instructional modules at the undergraduate level to enable teachers to integrate data into the curriculum. over time, icpsr™s archival model has proven to be an effective approach to ensuring data integrity, facilitating data sharing, and providing data stewardship across a range of ˚elds and many institutions. because many social science data are used for secondary analysis, and because the social sciences reward academic producers of generalpurpose data, universities see the value of icpsr, which makes the membership funding model sustainable. the emerging world of massively complex and voluminous data raises new challenges. there will be no single repository and no single harmonization scheme. unrestricted access is needed to realize the full value of data, which may lead to greater risk of disclosure and con˚dentiality breaches. new tools need to be developed to enable the merging of disparate data and communication across disciplines. building new, dynamic communities around data and cuttingedge research questions will require the collaborative efforts of technologists and domain scientists. a greater focus by institutions and federal sponsors on data preservation and access also will be needed.a http://www.icpsr.umich.edu.and advances in the cost performance of storage technologies have enabled a proliferation of repository efforts. private foundations such as the andrew w. mellon foundation have played an important role in supporting repository software development, and continue to invest in new capabilities for the digital stewardship of scholarly work.10 10 see the description of the mellon foundation™s research in information technology program: http://www.mellon.org/grantprograms/programs/rit.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.102 ensuring the integrity, accessibility, and stewardship of datafigure 42 icpsr leads project ndings of nsf and nihsponsored awards that created social science datanote: this gure re˚ects survey results through november 2008 of principal investigators of 1,599 nih and nsf awards that indicated social science data creation. source: interuniversity consortium for political and social research (icpsr). we would like to acknowledge the national digital information infrastructure and preservation partnership program at the library of congress for supporting this work (ndiipp cooperative agreement 8/04). disciplinary repositories accept data and publication submissions regardless of the institutional afliation of the researcher. one longstanding example is the arxiv publication repository at cornell university, which focuses on physics and related elds.11 research institutions typically have more experience with the longterm preservation of data than do individual researchers, especially since many institutions are accustomed to running libraries or archiving ofces. in recent years, many research institutions have created their own repositories to house data and publications resulting from research at the institution. one example is the ideals repository at the university of illinois at urbanachampaign.12 uiuc faculty, staff, and students can deposit materials into ideals, which 11 http://arxiv.org/.12 http://www.ideals.uiuc.edu/.figure 42.epsnih (n=661)574611432704152535004003002001000nsf (n=938)archivedavailablelostensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.promoting the stewardship of research data 103can then be accessed by anyone over the internet. many repository efforts are led by university libraries, which have begun exploring the new issues posed by research data and other digital information as increasingly central components of the scholarly record.13 these efforts are part of a trend in which some research institutions, large research universities in particular, are reassessing their institutional role in the dissemination and stewardship of scholarship, both that of their own faculty and more broadly.14 during the time when the scholarly record was primarily printbased, a relatively small number of research libraries, most connected with research institutions, saw comprehensive stewardship of scholarship as part of their missions. likewise, in the digital age, some research institutions and their libraries are likely to play leadership roles in the stewardship of research data.institutional repositories naturally face challengesšfor instance, building faculty awareness and participationševen at large institutions.15 a recent report on the role of research libraries in providing repository services identies several key issues as repositories develop and grow.16 the issues include building new services (as the focus expands from publications, theses, and dissertations to research data, courseware, images, and other content), engaging with the larger networked environment (as the demand grows for higherlevel, crossrepository services), attending to the ﬁdemand sideﬂ (meeting the needs of heterogeneous user groups), and sustainability (going beyond money to organizational commitment). smaller institutions that seek to fulll a stewardship mission face even greater challenges. the size and complexity of digital datasets can overwhelm small institutional libraries or archives, which traditionally have dealt with  analog textual information. yet new partnerships and approaches hold the promise of overcoming many of these barriers. for example, the national institute for technology and liberal education now offers institutional repository services to member institutions for an annual fee.1713 anna gold. 2007. ﬁcyberinfrastructure, data, and libraries.ﬂ dlib magazine 13(9/10). available at http://www.dlib.org/dlib/september07/gold/09goldpt1.html.14 clifford a. lynch. 2008. a matter of mission: information technology and the future of higher education. pp. 43œ50 in the tower and the cloud, ed. richard katz. boulder, co: educause. available at http://www.educause.edu/thetowerandthecloud.15 philip m. davis and matthew j. l. connolly. 2007. institutional repositories: evaluating the reasons for nonuse of cornell university™s installation of dspace. dlib magazine 13(3/4). available at http://www.dlib.org/dlib/march07/davis/03davis.html.16 arl digital repository issues task force. 2009. the research library™s role in digital repository services. washington, dc: association of research libraries. available at http://www.arl.org/bm~doc/repositoryservicesreport.pdf.17 http://www.nitle.org/index.php/nitle/informationservices/dspaceservices.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.104 ensuring the integrity, accessibility, and stewardship of datafederal agencies, data centers, and digital archivesfederal agencies and other funding organizations can play key roles in preserving research data. in some elds, such as the earth and environmental sciences, federal agencies play a central role in the collection and stewardship of research data. for example, the national oceanographic and atmospheric administration (noaa) collects, manages, and disseminates a wide range of climate, weather, ecosystem and other environmental data used by scientists, engineers, resource managers, policy makers, and others in the united states and around the world. noaa must deal with the challenges of an increasing volume and diversity of its data holdingsšwhich include everything from satellite images of clouds to the stomach contents of shšas well as a large number of users. a recent national research council report offered nine general principles for effective environmental data management, along with a number of guidelines on how the principles could be applied at noaa.18 the principles and guidelines developed for noaa are consistent with the principles laid out in this study, and represent an example of how they apply to an agency with signicant data management responsibilities in the earth sciences. the description of noaa™s data management challenges also illustrates the challenges of providing access and stewardship for large, heterogeneous datasets.in some elds, federal agencies have established large digital archives that house important collections of data provided by grantees and other external researchers. ncbi at the national library of medicine is perhaps the best example. ncbi houses several data and literature collections, provides education, and develops software for various computational biology applications. genbank, which has been discussed previously, is a large database of nucleotide sequences that has become an essential national and global resource in the life sciences.19federal agencies have traditionally supported the data management needs of the research elds with which they work most closely. nsf is undertaking a large initiative explicitly focused on developing capabilities to meet longerterm data stewardship needs across science and engineering elds.20 the sustainable digital data preservation and access network (datanet) program intends to make about ve awards totaling $100 million over 5 years to organizations that will ﬁprovide reliable digital preservation, access, integration, and analysis capabilities for science and/or engineering data over a decadeslong timeline.ﬂ by adapting to and driving technological changes in serving their given domains, 18 national research council. 2007. environmental data management at noaa: archiving, stewardship, and access. washington, dc: the national academies press.19 dennis a. benson, ilene karschmizrachi, david j. lipman, james ostell, and david l. wheeler. 2006. ﬁgenbank.ﬂ nucleic acids research 34(database):d16œd20. available at http://nar.oxfordjournals.org/cgi/content/abstract/34/suppl1/d16.20 see http://www.nsf.gov/pubs/2007/nsf07601/nsf07601.pdf.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.promoting the stewardship of research data 105the awardees would be helping to demonstrate the feasibility of longterm digital stewardship. in other elds where federal agencies themselves are not as central to data collection and stewardship efforts, federal capabilities may be more limited. in these cases, nonfederal research sponsors need the support and active participation of research institutions and communities if they are to help ensure the longterm preservation and availability of data. also, sponsors may be more interested in the initial development of data collections than in maintaining those collections over long periods as an openended commitment.the federal government can also foster data exchange among research institutions and companies in specic, highly applied areas. for example, the governmentindustry data exchange program (gidep) is a joint activity of the military services, other federal agencies such as the national aeronautics and space administration and the department of energy, defense and space contractors such as lockheed martin, boeing, and raytheon, and even the canadian department of national defence.21 gidep has existed since the 1950s, and is a mechanism for sharing research, development, design, testing, acquisition, and logistics information among government and industry participants in order to reduce or eliminate expenditures.in recent years, other organizations and networks, including data centers, have taken on important roles in the stewardship of research data. the san diego supercomputer center (sdsc), managed by the university of california at san diego, is a highperformance computing center and a national data hosting facility, providing an integrated set of data services (access, manipulation, management, and storage).22 sdsc is a data services provider for the protein data bank and the national virtual observatory (nvo). for nvo, sdsc stores two replicants of the sloan digital sky survey as well as other sky surveys, over 88 terabytes in all. sdsc datacentral also hosts over 100 community data collections, including molecular dynamics simulation data (chemistry), human brain dynamics resource data (neuroscience), and employment responses to global markets data (economics). sdsc™s agreements with research communities vary substantially with regard to standards, sharing, formats and ontologies, usage scenarios, and intellectual property. sdsc utilizes multiple levels of data reliability and data integrity mechanisms.research communities and data centers such as sdsc need to develop common understanding on key issues such as trust, expectations, incentives/penalties, and privacy/security/condentiality. good longterm stewardship requires resources for increased capacity, uptodate reliability tools, and skilled people. developing sustainable economic models for longterm stewardship is 21 http://www.gidep.org/.22 francine berman, director, sdsc, presentation to the committee, september 17, 2007.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.106 ensuring the integrity, accessibility, and stewardship of dataa challenge. in some very highpriority areas, federal support on an ﬁinnite mortgageﬂ basis might be sustainable. in other cases, some combination of relay funding, user fees, endowments, and other mechanisms may need to be employed.companies and journalsopportunities for new publicprivate partnerships for data stewardship also exist. for example google had announced a free service named palimpsest that would make massive datasets accessible to researchers, but canceled the ofcial launch of the project in late 2008.23 at the same time, amazon has launched a service to host large public datasets, allowing researchers to upload their own data.24 researchers would be charged fees for online data storage and data analysis capability. many datasets have become so large that they are impossible to download over the internet in a reasonable time. some journals play a role in maintaining the data submitted to support published articles. journals are also participating in initiatives such as portico, an archive of electronic scholarly literature.25 however, many journals lack the nancial resources for maintaining databases for extended periods. and many journals face nancial constraints, especially as they make the transition to electronic publication, which could threaten their ability to preserve and supply data either now or in the future.annotating data for longterm useas noted in chapter 2, raw data are typically of use only to the research group that generated them. to be useful to others, data must be accompanied by metadata that describe the content, structure, processing, access conditions, and source of the data in a form that permits the data to be used by researchers, educators, policy makers, and others. for computational data, for example, annotation might mean preserving the software used to generate the data along with a simulation of the hardware on which the software ran (or, in some cases, the hardware itself). for observational data, the documentation of the hardware, instrumental calibrations, preprocessing of data, and other circumstances of the observation are generally essential for using the data. in some cases, these metadata can be generated automatically, but annotation can be a laborintensive process.23 alexis madrigal. 2008. google shutters its science data service. wired science. december 18. available at http://blog.wired.com/wiredscience/2008/12/googlescienceda.html.24 aaron rowe. 2008. amazon hosting, crunching massive public databases. wired science. december 5. available at http://blog.wired.com/wiredscience/2008/12/massiveamounts.html.25 see the portico web site: http://www.portico.org/.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.promoting the stewardship of research data 107different types of users of data generally have different needs for annotation. researchers in the same eld can be expected to need less metadata than a researcher in a quite different eld or a nonresearcher. making data usable in the latter case can be difcult and involved, and researchers do not have a responsibility to make data understandable to a nonexpert. however, guidelines should exist for the degree of expertise required to use a dataset.escience that ranges widely across research elds requires standardized interfaces and protocols to enable useful communication across widely separated research elds. however, there is a tradeoff between the demands of  interoperability between research elds and detailed annotation within a eld.26fostering data stewardship for  the broad research enterprisemost of the discussion in this chapter involves overseeing and promoting data stewardship in individual elds of research. there is also the question of how the broad research enterprise should develop data management standards and longterm strategies across all elds of research, both within and outside government. many issues are common to multiple elds. in late 2007, the blue ribbon task force on sustainable digital preservation and access was created to ﬁanalyze previous and current models for sustainable digital preservation, and identify current best practices among existing collections, repositories and analogous enterprises.ﬂ27 the task force is developing recommendations and a research agenda aimed at catalyzing and supporting sustainable economic models for stewardship of digital information, including research data. the task force is supported by nsf, the andrew w. mellon foundation, and several other organizations. nsf™s datanet program, described earlier in this chapter, is seeking to develop technologies and organizational capabilities that would be broadly applicable to longterm data stewardship in science and engineering.within the u.s. federal government, the interagency working group on digital data under the national science and technology council has been examining the needs for preservation and dissemination of publicly funded research data. in january 2009 the working group released its report, harnessing the power of digital data for science and society. the report provided goals and implementation plans for the federal government to work, as both leader and partner, with other sectors to enable reliable and effective digital data preservation and access. the working group noted, as we have in this report, that ﬁcommunities of practice are an essential feature of the digital landscapeﬂ 26 christine l. borgman. 2007. scholarship in the digital age: information, infrastructure, and the internet. cambridge, ma: mit press.27 see blueribbontaskforce.sdsc.edu.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.108 ensuring the integrity, accessibility, and stewardship of dataand that ﬁpreservation of digital scientic data is both a government and private sector responsibility and benets society as a whole.ﬂ to provide reliable management of digital scientic data, the working group calls for ﬁa comprehensive framework of transparent, evolvable, extensible policies and management and organizational structures that provide reliable, effective access to the full spectrum of public digital scientic data.ﬂthe goals and recommendations of the working group are complementary to those of our committee. the working group recommends that federal agencies ﬁpromote a data management planning process for projects that generate preservation data.ﬂ these plans should identify the types of data and their expected impact, specify relevant standards, and outline provisions for protection, access, and continuing preservation. the working group™s report points out that not all digital scientic data need to be preserved and not all preserved data need to be preserved indenitely. stakeholders that should be involved in decisions about which data to preserve include research communities, data professionals, data users, entities such as professional organizations and governments, and preservation organizations.in addition, the working group calls for the creation of a subcommittee on digital scientic data preservation, access, and interoperability under the national science and technology council that would track and recommend policies on such issues as national and international coordination; education and workforce development; interoperability; data systems implementation and deployment; and data assurance, quality, discovery, and dissemination.at the nongovernmental level, in fall 2008 the national research council established a new board on research data and information. the board is engaged in planning, program development, and administrative oversight of projects dealing with the management, policy, and use of digital data and information for science and the broader society. the board™s primary objectives are to:1. address emerging issues in the management, policy, and use of research data and information at the national and international levels.2. through studies and reports of the national research council, provide independent and objective advice, reviews of programs, and assessment of priorities concerning research data and information activities and interests of its sponsors.3. encourage and facilitate collaboration across disciplines, sectors, and nations with regard to common interests in research data and information activities.4. initiate or respond to requests for consensus studies, workshops, conferences, and other activities within the board™s mission, and provide oversight for the activities performed under the board™s auspices.5. broadly disseminate and communicate the results of the board™s activities to its stakeholders and to the general public. ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.promoting the stewardship of research data 109general principle for enhancing  the stewardship of research datadata are a critical part of the research infrastructure, with an importance comparable to that of laboratories, research facilities, and computing devices and networks. researchers need to access data quickly and from multiple sources. data need to be annotated so that they can be used by researchers in a wide variety of elds. data need to be migrated to successive storage platforms as technologies evolve. these observations lead to the committee™s third general principle.data stewardship principle: research data should be retained to serve future uses. data that may have longterm value should be documented, referenced, and indexed so that others can nd and use them accurately and appropriately.as with the two previous broad principles, this principle is not a recommendation but a general statement of intent that can guide specic actions. also, as with the data access and sharing principle, the data stewardship principle™s reference to future uses should be seen as limiting rather than broadening the scope of the principle. decisions must continually be made about which data to save and which data to discard. general heuristics offer some guidance on these decisions.28 observational data that cannot be recollected are candidates for being archived indenitely. experimental data may or may not be saved depending on whether the experimental conditions can be reproduced precisely at minimal cost. in general, decisions about data retention require focused attention within each research group and eld.many critical questions involving the retention of data are not directly addressed by the data stewardship principle. for how long should data be retained? in what format and by whom? who should pay for the preservation of data? these questions can be answered only by the researchers, research institutions, research sponsors, and policy makers who have responsibility for data stewardship.responsibilities of researchersas with ensuring the integrity and accessibility of data, researchers have unique responsibilities for data stewardship. as stated in an editorial for its issue on ﬁpetabyte science,ﬂ which appeared in september 2008, the journal nature states that ﬁresearchers need to be obliged to document and manage 28 national science board. 2005. longlived data collections: enabling research and education in the 21st century. arlington, va: national science foundation.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.110 ensuring the integrity, accessibility, and stewardship of datatheir data with as much professionalism as they devote to their experiments. and they should receive greater support in this endeavor than they are afforded at present.ﬂ29through their planning and actions, researchers facilitate or complicate the retention of data. researchers need to provide much of the metadata that can allow data to be used in the future by colleagues who may be in quite different elds. only the researchers and data professionals directly involved in a project know their data well enough to judge what should be preserved and what should be discarded. the heterogeneity of data and the variety of possible needs argue that policies and strategies be set by those within a eld, not outside it.among the most important tasks for researchers establishing a data management plan is to arrange for preserved data to be annotated in such a way that they retain their longterm value. annotation might include computer codes, algorithms, or other processing techniques used in the course of research. furthermore, this information should be sufcient to allow other researchers not only to verify previous results but to extend those results into new areas. data stewardship must start at the beginning of a project, not partway through or at the end of a project. recommendation 9: researchers should establish data management plans at the beginning of each research project that include appropriate provisions for the stewardship of research data.at a minimum, data management plans for research projects should provide for compliance with the relevant legal and policy requirements covering research data. these would include institutional policies, sponsor requirements, federal law (e.g. the 1996 health insurance portability and accountability act), and state law as appropriate. under certain circumstances (e.g., when the data can be reproduced cheaply, no secondary use is anticipated), provisions for stewardship of the data beyond what is legally required may not be necessary. in other cases, the data management plan would specify whether the data would be deposited in an institutional and/or disciplinary repositories, annotation and metadata specications, and other elements. this recommendation does not imply that individual researchers are responsible for ensuring indenite preservation of their own data, only that they ensure that it is prepared and transferred to the appropriate archives or repositories. also, researchers should be working in partnership with their institutions, sponsors, and elds in formulating and implementing their plans. researchers need to participate in the development of policies and standards for data access, annotation, and preservation, including standards regard29 editorial. 2008. ﬁcommunity cleverness required.ﬂ nature 455(7209). available at http://www.nature.com/nature/journal/v455/n7209/pdf/455001a.pdf.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.promoting the stewardship of research data 111ing the degree of expertise needed to use the data. establishing such policies is the collective responsibility of the researchers in each eld, given the potential value of data to future researchers in that eld and others.recommendation 10: as part of the development of standards for the management of digital data, research elds should develop guidelines for assessing the data being produced in that eld and establish criteria for researchers about which data should be retained.as research data become more voluminous, complex, and valuable, a need may arise to formalize the process of making data management decisions within research elds. as with data access and data integrity, international participation may be needed in the development of data management standards, or international organizations might take the lead role. often ad hoc groups can provide guidance, such as national research council committees, federal agency advisory groups, or collaborative efforts such as the one undertaken by the ecological society of america and described in box 42. in some elds it might become desirable to charge a data oversight board with this responsibility. such a board could serve many functions including the following:make recommendations about whether data should be stored in special repositories or by individuals.determine how long particular kinds of data need to be preserved and who is responsible for the quality of the data as they move from one storage platform to another.inventory and publicize good practices for data management.conduct assessments of which datasets offer the most potential future value and which can be sacriced.organize interactions with specialized support organizations, either nonprot or commercial, to store and distribute data.evaluate access and preservation to identify problems and ensure that data with the greatest potential utility are being preserved.as was discussed in chapter 3, science, engineering, and medical research is a global enterprise. a wide range of governmental and private entities around the world have developed expertise in areas related to data stewardship, many working at the level of disciplines and elds.30 professional societies and indi30 raivo ruusalepp. 2008. infrastructure planning and data curation: a comparative study of international approaches to enabling the sharing of research data. data curation centre and joint information systems committee (uk). november. available at http://www.dcc.ac.uk/docs/publications/reports/datasharingreport.pdf ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.112 ensuring the integrity, accessibility, and stewardship of databox 42 the ecological society of america™s  datasharing initiative the ecological society of america (esa), which was founded in 1912, consists of more than 10,000 scientists from diverse ˚elds studying ecological restoration, biotechnology, ozone depletion, species extinction, and many other topics.a all of the esa journals archive their electronic publications using portico, which preserves ﬁscholarly literature published in electronic form and ensure[s] that these materials remain accessible to future scholars, researchers, and students.ﬂb funded by the andrew w. mellon foundation, ithaka, the library of congress, and jstor, portico was launched in 2005 and has almost 6 million journal articles archived. the esa requires that data and information on methods and materials needed to verify conclusions be made available to editors of its journals on request, and strongly encourages authors to register their data in esa™s of˚cial registry (data.esa.org). esa also has devoted considerable attention to making unpublished foundational data accessible. in 2004 it formed a joint working group to promote data sharing and archiving. representatives of the working group came from many organizations and a wide range of ˚elds. over the course of three meetings, the working group discussed the promotion and design of data registries,c the role of data centers,d and obstacles to data sharing.e in addition, esa is working to establish a national ecological data center (nedc), which would be a repository for metadata and datasets. the nedc would feature a directory of connected data centers, an online manual, training, and free access.fa http://www.esa.org/aboutesa/.b http://www.portico.org/about/porticobrochure.pdf.c http://www.esa.org/scienceresources/documentfiles/dataregistryworkshopreportfinal.pdf.d http://www.esa.org/scienceresources/documentfiles/esadatacenterswkshpnotes.pdf.e http://www.esa.org/scienceresources/documentfiles/dataobstacleswkshpnotesfinall.pdf.f http://esa.org/scienceresources/documentfiles/visionstatementnedc.pdf.vidual u.s. researchers should be encouraged to participate in and lead international efforts to improve research data stewardship. responsibilities of research institutions,  research sponsors, and journalsresearchers need a supportive institutional environment to fulll their responsibilities toward the stewardship of data. recommendation 11: research institutions and research sponsors should study the needs for data stewardship by the researchers they employ and support. working ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.promoting the stewardship of research data 113with researchers and data professionals, they should develop, support, and implement plans for meeting those needs. research institutions and research sponsors have an interest in seeing data used to full advantage. research data represent a sizable investment of human and nancial resources, and preserving those data typically costs less than generating them in the rst place. nevertheless, maintaining highquality and reliable databases can have signicant costs. because future uses of data are difcult to predict, the return on those costs can be uncertain. in many elds, there still is no consensus as to who should maintain large databases or who should bear the costs.depending on the eld, data management plans might include incentives for proper data stewardship (including research sponsor policies and conditions for grants and contracts), investments in technological and institutional tools, standardization of interfaces, and the support of data centers. the examples of the ecological society of america and icpsr (boxes 41 and 42) show how elds and coalitions of elds can develop policies and capacity for data stewardship over time.research institutions, including research libraries, can play leadership roles in the stewardship of research data, both those produced by their own faculties and more broadly. as with the preservation of scholarship in the print era, not every institution will be positioned to develop comprehensive capabilities by itself. coalitions and partnerships among institutions and between institutions and agencies can accomplish much of this work. it is important that requirements for improved data management practices not be imposed as unfunded mandates. they need to be integrated into research program funding as an essential component of the conduct of research. where possible, grant applications should include costs for data stewardship.the questions of who pays, how much, and for how long are at the heart of the problem of how to ensure longterm stewardship of research data. it has been suggested that only the federal government is positioned to guarantee the preservation of research data, and that a federal data archive or system of archives analogous to the library of congress should be established to undertake this mission. this chapter discusses the variety of federal resources and programs related to research data stewardship that already exist, many of which involve partnerships of various types with research elds and research institutions. many of them are relatively new. this committee was not in a position to comprehensively evaluate whether the current, largely decentralized, approach is likely to meet the needs of the research enterprise. the relevant communities are actively engaged in addressing these issues, through groups such as the blue ribbon task force for sustainable digital preservation and access mentioned earlier. ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.5dening roles and responsibilitiesassigning roles and responsibilitiesperiods of rapid technological change offer strong incentives as well as unique opportunities for examining current policies and instituting new policies to address changing circumstances. every part of the research enterprise is being affected by the changes in how research is being planned, conducted, and used, and each has responsibilities for ensuring the integrity, accessibility, and stewardship of research data. however, shared responsibilities can create problems. when responsibility is shared, each group can assume that the other groups should be the ones taking action. as a speaker at one of the committee™s meetings memorably described the problem, ﬁif two people are responsible for feeding a dog, that dog™s going to starve.ﬂthe remainder of this chapter revisits the recommendations made in the three preceding chapters by brie˚y describing the roles and responsibilities of the major sectors of the research enterprise in ensuring the integrity, accessibility, and stewardship of research data. in that regard, it functions as a summary of the report™s recommendations, though the recommendations are resorted according to the groups responsible for each action (see table 51). it also discusses some of the particular responsibilities incumbent on parts of the research enterprise to avoid inaction caused by an overly diffuse allocation of responsibilities.researchersresearchers have particular obligations in each of the three areas discussed in this report. as data producers, providers, and users, they know best how to generate data of high quality, disseminate data to others so that the data are useful, and preserve the data for future uses. in some elds they may need to work in close association with data professionals. they might also carry out 115ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.116 table 51 responsibilities of groups within the research enterpriserecommendationresearchersresearch institutions and research librariesresearch sponsorsprofessional societiesjournalspublicdata integritymanage projects to ensure data integrityreceive appropriate training for data managementparticipate in development of professional standards for management of dataprovide support for training in data managementrecognize appropriateness of financial support for data professionalshelp ensure that contributions of data professionals are recognized and rewardeddata access and sharingmake data and other information integral to reported results accessible in a timely mannerascertain whether data are publicly accessible and, if not, whether restrictions are appropriateif data are not accessible, explain why publiclyif necessary, develop standards for data accessibility (with parties appropriate for field)except where restrictions are justified, require that data be made availablepromote sharing of data through public recognition of outstanding datasharing efforts, funding, and publication policiesestablish clear policies for management of and access to research data ensure availability of data in short and long termdata stewardshipinclude provisions for stewardship of data in data management plansdocument, reference, and index data with longterm valuedevelop process to generate guidance for researchers about data retentiondevelop and implement plans with researchers to meet needs for data stewardshipdevelop incentives and tools for data stewardshippublicize and promote proper data stewardshipconsider supporting data centers and archives, and stewardship toolsensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved. 117table 51 responsibilities of groups within the research enterpriserecommendationresearchersresearch institutions and research librariesresearch sponsorsprofessional societiesjournalspublicdata integritymanage projects to ensure data integrityreceive appropriate training for data managementparticipate in development of professional standards for management of dataprovide support for training in data managementrecognize appropriateness of financial support for data professionalshelp ensure that contributions of data professionals are recognized and rewardeddata access and sharingmake data and other information integral to reported results accessible in a timely mannerascertain whether data are publicly accessible and, if not, whether restrictions are appropriateif data are not accessible, explain why publiclyif necessary, develop standards for data accessibility (with parties appropriate for field)except where restrictions are justified, require that data be made availablepromote sharing of data through public recognition of outstanding datasharing efforts, funding, and publication policiesestablish clear policies for management of and access to research data ensure availability of data in short and long termdata stewardshipinclude provisions for stewardship of data in data management plansdocument, reference, and index data with longterm valuedevelop process to generate guidance for researchers about data retentiondevelop and implement plans with researchers to meet needs for data stewardshipdevelop incentives and tools for data stewardshippublicize and promote proper data stewardshipconsider supporting data centers and archives, and stewardship toolsensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.118 ensuring the integrity, accessibility, and stewardship of datatheir responsibilities through informal groups or formal organizations created with the involvement of funding agencies or professional societies.in a period of rapid technological change, researchers can be challenged to master all of the information they need to fulll their responsibilities toward data. training in the responsible conduct of research that includes guidance on the management of data can clarify and emphasize researchers™ responsibilities (chapter 2). many research data have potential uses and users that may not be obvious from the perspective of a single research eld. courses, seminars, or webbased modules in data management can list and describe these potential uses and users, providing researchers with a more comprehensive set of factors to consider in making decisions about data accessibility and stewardship.researchers also need to be aware of the many considerations surrounding data when they are considering possible restrictions on data and the appropriateness of any such restrictions (chapter 3). restrictions may be necessary, yet most restrictions on the accessibility of data have costs for the research community. because of these costs, researchers have a responsibility to provide compelling reasons for any limitations on the accessibility of data, which requires that they fully understand and are able to justify these limits.finally, researchers are the ones best positioned to plan both how data will be made available and how they will be preserved and curated for longterm use (chapter 4). when standards for data accessibility and stewardship do not exist in a eld, researchers need to be involved inšand most likely will leadšthe process of developing such standards.the integrity, accessibility, and stewardship of research data are too important to be secondary considerations or afterthoughts in the development of a research plan. provisions for maintaining these three qualities of research data should be part of every research plan, whether a sponsor requires such provisions or not.research institutionsresearch institutions, including colleges, universities, medical schools, and other nonprot organizations, have a major in˚uence on the policy environment in which research is conducted. their supportšor lack of supportšfor data integrity, accessibility, and stewardship can have a major effect on the quality and usability of research data. research institutions need to have clear  written policies regarding data management and communicate these policies to researchers. organizations such as the national association of state universities and landgrant colleges, the american association of universities, the committee on government relations, the committee on institutional cooperation, and others can help formulate and disseminate these policies.research institutions need to support training in data management (chapter 2). they should establish an expectation that researchers will undertake ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.defining roles and responsibilities 119such training and provide the nancial support for researchers to be able to do so. research institutions and sponsors also facilitate the development of data professionals by providing career paths for these individuals, supporting their training, and recognizing and rewarding their contributions.researchers have many incentives for maintaining the integrity of the data they generate. they have fewer incentives, in general, for making their data widely available, and fewer still to invest the time and resources needed to ensure the stewardship of data. policy initiatives are therefore essential if research data are to achieve their maximum value.research institutions have a special responsibility to be proactive in making research data accessible (chapter 3). research grants and contracts typically give research institutions ownership rights in research data, and so those institutions have a particular interest in seeing that research data are available, that restrictions on the accessibility of research data are justied, and that procedures exist for responding to requests for research data. both formal policies and informal expectations help to avoid con˚icts over data accessibility.research institutions also can and should play the leading role in stewardship of its scholarship and knowledge resources (chapter 4).research sponsorsresearch sponsors, including government agencies, philanthropies, private companies, and other funders, also have an interest in all three of the qualities discussed in this report. but they have a particular responsibility toward data stewardship (chapter 4). the infrastructure needed for data stewardship is much less developed than is the infrastructure for publishing research conclusions. also, the longterm preservation of data in a usable form can be costly, and research data are so varied across elds that different systems are needed for different elds.funders can maximize the value of the research they fund by also taking steps to support the stewardship of data. they need to work with researchers in the elds they sponsor to develop incentives for researchers to invest in data stewardship, and they need to consider support for the data centers and tools that facilitate stewardship.professional societies and journalsfinally, professional societies and journals have important roles to play in all three of the areas explored in this report. they can help develop and disseminate guidelines for a research eld and then help monitor and enforce compliance with those guidelines. journals are directly responsible for the longterm preservation of the articles they publish, and an increasing number of journals are assuming responsibility for maintaining the data on which research concluensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.120 ensuring the integrity, accessibility, and stewardship of datasions are based. and journals and professional societies can help ensure that the contributions of data professionals are recognized and rewarded through such mechanisms as prizes, publication, and recognition at disciplinary meetings.in general, more dialog is needed among researchers, research institutions, and research sponsors about the need for education and training, how sponsors should support the stewardship of data, the role of data professionals, and how institutions and sponsors should respond to reasonable and unreasonable requests for research data. professional societies and journals can catalyze these dialogues within research elds, providing a base of knowledge that can then be applied across disciplines.conclusionduring periods of rapid change, an emphasis on specic policies may be less useful than reiterating and reemphasizing the fundamental principles that should guide action. thus, we close by restating three general principles that have motivated our recommendations in the areas of data integrity, accessibility, and stewardship.data integrity principle: ensuring the integrity of research data is essential for advancing scientic, engineering, and medical knowledge and for maintaining public trust in the research enterprise. although other stakeholders in the research enterprise have important roles to play, researchers themselves are ultimately responsible for ensuring the integrity of research data.data access and sharing principle: research data, methods, and other information integral to publicly reported results should be publicly accessible. data stewardship principle: research data should be retained to serve future uses. data that may have longterm value should be documented, referenced, and indexed so that others can nd and use them accurately and appropriately.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix abiographical information on the  members of the committee on  ensuring the utility and integrity of research data in a digital agecommittee membersdaniel kleppner, cochair, is professor emeritus at the massachusetts institute of technology (mit) and codirector of the mitharvard center for ultracold atoms. he has made fundamental contributions to atomic physics and quantum optics. his research encompasses spectroscopic tests of extreme precision and novel quantum phenomena. he was director of the mitharvard center for utracold atoms from 2000 to 2006, and from 1987 to 2000 he was associate director of the mit research laboratory of electronics. in 1960, along with norman ramsey, he developed the hydrogen maser, later used as an atomic clock of unprecedented stability. applications of this early work range from coordination of radio signals in longbaseline radio astronomy, to satellitebased global positioning systems.  in the 1970s, dr. kleppner was a pioneer in the physics of rydberg atoms, demonstrating the inhibition of spontaneous emission from them. this was a pioneering step in the development of cavity quantum electrodynamics, the study of the radiative properties of atoms in conned spaces. kleppner™s investigations of rydberg atom spectra in high electric and magnetic elds provided deep physical insight into the implications of classical chaos for quantum systems.  professor kleppner and mit colleague professor thomas greytak were among the rst to search for quantum degeneracy effects in ultracold gases. after a 20yearlong quest, in 1998, they achieved boseeinstein condensation (bec) in hydrogen. in the meanwhile, they developed tools instrumental to the 1995 discovery of bec in alkali atoms by mit alumni eric cornell and carl wieman, and mit™s wolfgang ketterle. these include the technique of evaporative cooling, developed in collaboration with harald hess. boseeinstein 121ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.122 appendix acondensates and fermionic degenerate samples of cold atoms represent a new form of matter at the lowest temperatures ever achieved. these species are now the subject of intense investigation in laboratories around the world. in addition to these research achievements, dr. kleppner has been a dedicated teacher at the undergraduate and graduate levels, and has served on numerous national committees charged with investigating key scientic or social issues. his honors include election to the national academy of sciences, the american academy of arts and sciences, the american philosophical society, and the academies of science (paris), and the davissongermer prize, leo szilard lectureship award and lilienfeld prize of the american physical society, the oersted medal of the american association of physics teachers, the frederick ives medal of the optical society of america, the wolf prize, and the 2006 national medal of science. phillip a. sharp, cochair, is institute professor at the massachusetts institute of technology. much of dr. sharp™s scientic work has been conducted at mit™s center for cancer research (now the koch institute), which he joined in 1974 and directed from 1985 to 1991. he subsequently led the department of biology from 1991 to 1999 and the mcgovern institute from 2000 to 2004. his research interests have centered on the molecular biology of gene expression relevant to cancer and the mechanisms of rna splicing; his landmark achievement was the discovery of rna splicing in 1977. this work provided one of the rst indications of the startling phenomenon of ﬁdiscontinuous genesﬂ in mammalian cells. the discovery that genes contain nonsense segments that are edited out by cells in the course of utilizing genetic information is important in understanding the genetic causes of cancer and other diseases. dr. sharp™s research opened an entirely new area in molecular biology and forever changed the eld. for this work he shared the 1993 nobel prize in physiology or medicine with dr. richard roberts who did work in parallel at cold spring harbor. dr. sharp has authored more than 350 scientic papers and serves on many scientic committees, including the national cancer institute™s advisory board, which he chaired for two years (2000œ2002). his work has been honored with numerous awards including the gairdner foundation international award, general motors research foundation alfred p. sloan, jr. prize for cancer research, louisa gross horwitz prize, and albert lasker basic medical research award. he is an elected member of the national academy of sciences, the institute of medicine, the american academy of arts and sciences, and the american philosophical society. a native of kentucky, dr. sharp earned a b.a. degree from union college, kentucky, and a ph.d. in chemistry from the university of illinois at champaignurbana in 1969. he did his postdoctoral training at the california institute of technology, where he studied the molecular biology of plasmids from bacteria ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix a 123in professor norman davidson™s laboratory. prior to joining mit, he was senior scientist at cold spring harbor laboratory. dr. sharp is cofounder of biogen, inc., 1978, chairman of the scientic board (to 2002) and member of the board of directors. he is also cofounder of alnylam pharmaceuticals (2002), where he serves as chairman of the scientic board and as a member of the company™s board of directors. margaret a. berger is widely recognized as one of the nation™s leading authorities on scientic evidentiary issues, in particular dna evidence, and is a frequent lecturer across the country on these topics. she is a recipient of the francis rawle award for outstanding contributions to the eld of postadmission legal education by the american law institute/american bar association for her role in developing new approaches to judicial treatment of scientic evidence and in educating the legal and science communities about ways to implement these approaches. professor berger serves as a member of the national academy of sciences committee on science, technology, and law. she recently completed her service as a member of the national commission on the future of dna evidence in which she served as the reporter for the working group on postconviction issues. she has been called on as a consultant to the carnegie commission on science, technology, and government, and has served as the reporter to the advisory committee on the federal rules of evidence. she is the author of numerous amicus briefs, including the brief written for the carnegie commission on the admissibility of scientic evidence in the landmark case of daubert v. merrell dow pharmaceuticals, inc. she has also contributed a chapter on ﬁthe supreme court™s trilogy on the admissibility of expert testimonyﬂ to the reference manual on scientic evidence (2nd ed. 2000). her textbook, evidence: cases and materials (9th ed. 1997) (with weinstein, manseld, and abrams), is the leading evidence casebook. professor berger has been a member of the faculty of brooklyn law school in new york since 1973, and holds the suzanne j. and norman miles chair.norman m. bradburn, the tiffany and margaret blake distinguished service professor emeritus of the university of chicago, serves on the faculties of the irving b. harris graduate school of public policy studies, the department of psychology, the graduate school of business, and the college. he is a former provost of the university (1984œ1989), chairman of the department of behavioral sciences (1973œ1979), and associate dean of the division of the social sciences (1971œ1973). from 2000 to 2004 he was the assistant director for social, behavioral and economic sciences at the national science foundation. bradburn is currently a senior fellow at the national opinion research center (norc). associated with norc since 1961, he has been director of norc and president of its board of trustees. a social psychologist, bradburn has been at the forefront in developing ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.124 appendix atheory and practice in the eld of sample survey research. he has focused on psychological wellbeing and assessing the quality of life, particularly through the use of largescale sample surveys; nonsampling errors in sample surveys; and research on cognitive processes in responses to sample surveys. his book, thinking about answers: the application of cognitive process to survey methodology (with seymour sudman and norbert schwarz; josseybass, 1996), follows three other publications on the methodology of designing and constructing questionnaires: polls and surveys: understanding what they tell us (with seymour sudman; josseybass, 1988); asking questions: a practical guide to questionnaire construction (with seymour sudman; josseybass, 1982; 2nd edition with brian wansink, 2004) and improving interviewing method and questionnaire design (josseybass, 1979). bradburn serves on the board of directors of the chapin hall center for children. he was chair of the committee on national statistics of the national research council/national academy of sciences (nrc/nas) from 1993 to 1998, and is past president of the american association of public opinion research (1991œ1992). bradburn chaired the nrc/nas panel to advise the census bureau on alternative methods for conducting the census in the year 2000. the report, published as counting people in the information age, was presented to the census bureau in october 1994. he was a member of the nrc/nas panel to review the national assessment of educational progress and the panel to assess the 2000 census. he is currently one of the domain chairs for the key national indicators initiative at the national academy of sciences. bradburn was elected to the american academy of arts and sciences in 1994. in 1996 he was named the rst wildenmann guest professor at the zentrum fur umfragen, methoden und analyse in mannheim, germany.john brauman was born in pittsburgh, pennsylvania, in 1937. he attended massachusetts institute of technology (s.b., 1959) and the university of california at berkeley (ph.d., 1963). he was a national science foundation postdoctoral fellow at university of california at los angeles, and then took a position at stanford university where he is j. g. jacksonœc. j. wood professor of chemistry emeritus. he was department chair, associate dean for natural sciences, and has been associate dean of research since 2005. he also currently serves as the home secretary of the national academy of sciences.  dr. brauman has received a number of awards including the american chemical society award in pure chemistry, harrison howe award, guggenheim fellowship, r. c. fuson award, arthur c. cope scholar award, james flack norris award in physical organic chemistry, national academy of sciences award in chemical sciences, linus pauling medal, willard gibbs medal, and national medal of science. he is a member of the national academy of sciences, the american academy of arts and sciences, the american philosophical society, a fellow of the american association for the advancement of science, ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix a 125and an honorary fellow of the california academy of sciences. he received the dean™s award for distinguished teaching from stanford university in 1976. dr. brauman has served on many national committees and advisory boards. he was deputy editor for physical sciences for science from 1985 to 2000 and is currently the chair of the senior editorial board.  dr. brauman™s research has centered on structure and reactivity. he has studied ionic reactions in the gas phase, including acidbase chemistry, the mechanisms of proton transfers, nucleophilic displacement, and addition elimination reactions. his work includes inferences about the shape of the potential surfaces and the dynamics of reactions on these surfaces. he has made contributions to the eld of electron photodetachment spectroscopy of negative ions, measurements of electron afnities, the study of dipole supported electronic states, and multiple photon infrared activation of ions. he has also studied mechanisms of solution and gasphase organic reactions as well as organometallic reactions and the behavior of biomimetic organometallic species. jennifer t. chayes is managing director of the new microsoft research new england lab in cambridge, massachusetts which opened in july 2008. before this, she was research area manager for mathematics, theoretical  computer science and cryptography at microsoft research redmond. chayes joined microsoft research in 1997, when she cofounded the theory group. her research areas include phase transitions in discrete mathematics and computer science, structural and dynamical properties of selfengineered networks, and algorithmic game theory. she is the coauthor of almost 100 scientic papers and the coinventor of more than 20 patents.  chayes has many ties to the academic community. she is afliate professor of mathematics and physics at the university of washington, and was for many years professor of mathematics at ucla. she serves on numerous institute boards, advisory committees and editorial boards, including the turing award selection committee of the association for computing machinery, the board of trustees of the mathematical sciences research institute, the advisory boards of the center for discrete mathematics and computer science and the miller institute for basic research in science, the u.s. national committee for mathematics and the committee on assuring the integrity of research data of the national academies, the advisory committee on women in computing of the association for computing machinery, the leadership advisory council of the anita borg institute for women and technology, and the selection committee for the anita borg award for technical leadership. chayes is a past chair of the mathematics section of the american association for the advancement of science, and a past vice president of the american mathematical society. chayes received her b.a. in biology and physics at wesleyan university, where she graduated rst in her class, and her ph.d. in mathematical physics ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.126 appendix aat princeton. she did her postdoctoral work in the mathematics and physics departments at harvard and cornell. she is the recipient of a national science foundation postdoctoral fellowship, a sloan fellowship, and the ucla distinguished teaching award. she has twice been a member of the institute for advanced study in princeton. chayes is a fellow of the american association for the advancement of science, and a national associate of the national academies. chayes is best known for her work on phase transitions, in particular for laying the foundation for the study of phase transitions in problems in discrete mathematics and theoretical computer science; this study is now giving rise to some of the fastest known algorithms for fundamental problems in combinatorial optimization. she is also one of the world™s experts in the modeling and analysis of random, dynamically growing graphsšwhich are used to model the internet, the world wide web and a host of other technological and social networks. among chayes™ contributions to microsoft technologies are the development of methods to analyze the structure and behavior of various networks, the design of auction algorithms, and the design and analysis of various business models for the online world. chayes lives with her husband, christian borgs, who also happens to be her principal scientic collaborator. in her spare time, she enjoys overworking.anita k. jones is a university professor and the lawrence r. quarles professor of engineering and applied science at the university of virginia. she came to the university in 1988 to serve as chair of the department of computer science. professor jones served as the director of defense research and engineering for the u.s. department of defense from 1993 to 1997, where she managed the department™s science and technology program. she has served on the boards of several government organizations including as the vice chair of the national science board. she is a member of the national academy of engineering, the defense science board, the charles starke draper foundation, the board of trustees of inqtel, the governing board of science foundation arizona, and the mit corporation executive committee. professor jones is a fellow of several professional societies and she has been awarded honorary doctorate degrees by carnegie mellon university and duke university. she has been awarded the department of defense award for distinguished public service, the ada lovelace award from the association of women in computing, and the founder™s award of the institute of electrical and electronics engineers. the u.s. navy named a seamount in the north pacic ocean (51° 25 n and 159° 10 w) for her. linda p. b. katehi is the provost and vice chancellor for academic affairs at the university of illinois at urbanacampaign and professor of electrical and computer engineering. she holds a joint appointment with the program of ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix a 127gender and women studies at the university of illinois. as a faculty member, professor katehi has focused her research on the development and characterization of threedimensional integration and packaging of highfrequency circuits with particular emphasis on mems devices, highq passives, and embedded lters. she pioneered the development of onwafer packaging for highdensity, highfrequency monolithic sibased circuit and antenna architectures that led to lowcost, highperformance integrated circuits for radar, satellite, and wireless applications. her work in this area has led to numerous national and international technical awards and to distinctions as an educator. professor katehi holds 13 u.s. patents and has authored more 500 papers published in refereed journals and symposia proceedings.  professor katehi is a member of the national academy of engineering, a fellow of american association ofr the advancement of science (aaas), and a fellow of ieee. she serves on many scientic committees including the nominations committee for the national medal of technology, the board of aaas, the kauffman national panel for entrepreneurship, the national science foundation (nsf) advisory committee to the engineering directorate, the national research council (nrc) telecommunications board, the nrc army research lab advisory committee on sensors and electronics division, the nsf advisory committee to cise, the national aeronautics and space administration aeronautics technical advisory committee, and the department of defense advisory group on electron devices.  professor katehi earned her diploma degree from the national technical university of athens, greece, in 1977 from the school of mechanical and electrical engineering. following her undergraduate studies, she worked for 2 years as a senior engineer in the naval research lab and joined the university of california at los angeles as a graduate student in fall 1979, completing an m.s.e.e. in december 1981 and a ph.d. in electrical engineering in 1984. from 1984 to 2002 she was a faculty member of the electrical engineering and  computer science department of the university of michigan in ann arbor, where she served as the associate dean for academic affairs from 1998 to 2002. from 2002 until 2004 she served as the dean of engineering and as faculty member of the electrical and computer engineering department at purdue university. neal f. lane is the malcolm gillis university professor at rice university. he also holds appointments as a senior fellow of the james a. baker iii institute for public policy, where he is engaged in matters of science and technology policy, and in the department of physics and astronomy. prior to returning to rice university, dr. lane served in the federal government as assistant to the president for science and technology and director of the white house ofce of science and techology policy from august 1998 to january 2001, and as director of the national science foundation (nsf) and member (ex ofcio) of the ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.128 appendix anational science board. prior to joining nsf, dr. lane was provost and professor of physics at rice university in houston, texas, a position he had held since 1986. he rst came to rice as an assistant professor in the department of physics and later became professor of physics and space physics and astronomy. he left rice from mid1984 to 1986 to serve as chancellor of the university of colorado at colorado springs. in addition, from 1979 to 1980, while on leave from rice, he worked at the nsf as director of the division of physics. dr. lane™s many writings and presentations include topics in theoretical atomic and molecular physics and science and technology policy. dr. lane has received numerous prizes and awards. he is a fellow of the american academy of arts and sciences. he also serves on several boards and advisory committees. born in oklahoma city in 1938, dr. lane earned his b.s., m.s., and ph.d. degrees in physics from the university of oklahoma.w. carl lineberger is currently serving as professor of chemistry at the university of colorado. he was elected to the national academy of sciences in 1983. his work is primarily experimental, using a wide variety of laserbased techniques to study structure and reactivity of gasphase ions. recent studies have been directed toward elucidating the structure of transient reaction intermediates, to developing understanding of the gradual evolution of physical properties from an isolated molecule to a solvated species, and to realtime investigations of reaction dynamics. richard luce is vice provost and director of libraries at emory university. he is responsible for managing the main libraryšincluding specialist libraries in business, chemistry, music and media, as well as the manuscript, archives, and rare books libraryšand coordinating universitywide library policy with the directors of the health, law, theology, and oxford college libraries. prior to joining emory, mr. luce was the research library director at los alamos national laboratory (1991œ2006). known as an information technology pioneer and organizational innovator, he managed a worldclass scientic research library and forged regional, national, and international public information and technology collaborations. in 1999 he was a cofounder of the open archives initiative to develop interoperable standards for author selfarchiving systems. in october 2003 he coorganized the berlin declaration on open access to knowledge in the sciences and humanities, and in 2004, the brazilian declaration on open access. he holds numerous advisory and consultative positions supporting digital library development, electronic publishing, and scholarly communication. he was the senior advisor to the max planck society™s center for information management (2000œ2006) and an executive board member of the national information standards organization (1998œ2004). he was the recipient of the 2005 fellows™ prize for leadership at los alamos national laboratory, the rst ever awarded to a nonscientist. ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix a 129mr. luce was the course director of the international spring school on the digital library and epublishing for science and technology in geneva and a founding member and chair of the alliance for innovation in science and technology information. he received a distinguished performance award from los alamos for his contributions supporting science and technology. prior to los alamos, mr. luce held positions as the rst executive director of the southeast florida library information network, director of colorado™s irving library network, and assistant director of the boulder public library in colorado. he speaks extensively in the areas of digital libraries and scientic communication, quality and change management, and strategic planning. luce holds a bachelor™s degree in political science from the university of san diego, a master™s degree in public administration from san diego state university, and a master™s degree in library and information science from the university of south florida.thomas o. mcgarity is joe r. and teresa lozano long endowed chair at the university of texas at austin school of law. he was articles editor of the texas law review. thomas mcgarity has studied both administrative law and environmental law. he also teaches torts. he is currently serving as coreporter for rulemaking on the american bar association™s restatement project of the administrative procedures act and related statutes. he received his j.d. from the university of texas. he has written three in˚uential books: workers at risk (praeger, 1993) (coauthor), the law of environmental protection (west, 2nd ed., 1991) (coauthor), and reinventing rationality: the role of regulatory analysis in the federal bureaucracy (cambridge university press, 1991). his recent articles include ﬁon the prospect of daubertizing judicial review of risk assessmentﬂ (law & contemporary problems 2003). he currently serves as president of the center for progressive reform. steven m. paul is the executive vice president for science and technology and president of lilly research laboratories (lrl), a division of eli lilly and company. he also is a member of the corporate policy and strategy and operations committees and the company™s senior management council, a group of top lilly executives who implement corporate strategies, ensure corporate performance, and identify corporate issues and opportunities. in 2005, dr. paul was named chief scientic ofcer of the year at one of the annual pharmaceutical achievement awards. he joined lilly in april 1993 as vice president of central nervous system discovery and decision phase medical research in lrl and was named vice president, therapeutic area discovery research and clinical investigation, in 1996. dr. paul became group vice president of therapeutic area discovery research and clinical investigation for lrl in 1998. paul received a b.a. degree, magna cum laude with honors, in biology and psychology from tulane university in 1972. he received an m.sc. degree in anatomy and neuroanatomy ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.130 appendix aand his doctor of medicine degree, both in 1975, from the tulane university school of medicine. prior to joining lilly, paul served as scientic director of the intramural research program of the national institute of mental health (nimh); professor of psychiatry at tulane university school of medicine; and chief of the clinical neuroscience branch, as well as chief of the section on preclinical studies at nimh. dr. paul is a member of various professional societies, and he was listed as one of the most highly cited neuroscientists in the world (1980œ2000) by the institute for scientic information. dr. paul serves on the editorial boards of numerous scientic journals and on several nih extramural and intramural committees. paul serves on the board of directors of the lilly foundation, the foundation of the nih, butler university and the indianapolis zoological society. he is a member of the institute of medicine.teresa a. sullivan became provost and executive vice president for academic affairs at the university of michigan in 2006. she is also professor of sociology in the college of literature, science, and the arts. prior to coming to the university of michigan, dr. sullivan was executive vice chancellor for academic affairs for the university of texas system, a position she held from 2002 until may 2006. in that role, she was the chief academic ofcer for the nine academic campuses within the university of texas system. her responsibilities included developing tuitionsetting procedures, initiating and supporting educational and research collaborations among the various campuses, and developing external collaborations. dr. sullivan rst joined the university of texas at austin in 1975 as an instructor and then assistant professor in the department of sociology. from 1977 to 1981, she was a faculty member at the university of chicago. dr. sullivan returned to texas in 1981 as a faculty member in sociology. in 1986, she was named to the law school faculty as well. dr. sullivan also held several administrative positions at texas including vice president and graduate dean (1995œ2002), vice provost (1994œ1995), chair of the department of sociology (1990œ1992), and director of women™s studies (1985œ1987). dr. sullivan™s research focuses on labor force demography, with particular emphasis on economic marginality and consumer debt. the author or coauthor of six books and more than 50 scholarly articles; her most recent work explores the question of who les for bankruptcy and why. dr. sullivan has served as chair of the u.s. census advisory committee. she is past secretary of the american sociological association and a fellow of the american association for the advancement of science. a graduate of james madison college at michigan state university, dr. sullivan received her doctoral degree in sociology from the university of chicago.michael s. turner is the bruce v. and diana m. rauner distinguished service professor at the university of chicago. he was born in los angeles, california, attended university high school, received his b.s. in physics from ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix a 131the california institute of technology (1971) and his ph.d. in physics from stanford university (1978). he came to the university of chicago in 1978 as an enrico fermi fellow and joined the faculty in 1980. from 2003 to 2006, turner served as the assistant director of the national science foundation for the mathematical and physical sciences, and from 2006 to 2008 as chief scientist at argonne national laboratory. from 1997 to 2003 turner was chair of the department of astronomy & astrophysics at chicago, and from 1998 to 2001 he was the rst scientic spokesperson for the sloan digital sky survey. he was instrumental in establishing the kavli institute for cosmological physics at the university of chicago in 2001. in 1983, with edward kolb, he established the theoretical astrophysics group at fermilab, which today is part of the larger center for particle astrophysics at fermilab. turner is currently a member of the board of directors and the executive committee of the fermi research alliance, which manages fermilab for the department of energy. since 1984 he has been on the board of trustees of the aspen center for physics and from 1989 to 1993 served as its president. turner is a fellow of the american physical society, the american association for the advancement of science, and the american academy of arts and sciences, and he is a member of the national academy of sciences. turner has been honored with the helen b. warner prize of the american astronomical society, the julius edgar lilienfeld prize of the american physical society, the halley lectureship at oxford university, the klopsteg lecture award of the american association of physics teachers, the quantrell award for excellence in undergraduate teaching at the university of chicago and an honorary doctor of science degree from michigan state university. in 2006, he received the distinguished alumnus award from caltech, and in 2009 he will give the biermann lectures at the max planck institute for astrophysics in garching. turner helped to pioneer the interdisciplinary eld that has brought together cosmologists and elementary particle physicists to unravel the origin and evolution of the universe and to understand the unication of the fundamental forces and particles of nature. his research focuses on the earliest moments of creation, and he has made seminal contributions to in˚ationary cosmology, particle dark matter and structure formation, the theory of bigbang nucleosynthesis, and the nature of dark energy that is causing the expansion of the universe to speed up. he believes that cosmic acceleration is the most profound mystery in all of science today, and he coined the term ﬁdark energy.ﬂ dark energy is the focus of his current research.  turner has served on and chaired numerous committees for the department of energy, the national aeronautics and space administration, national science foundation, the american physical society, and the national academies. the national academy study connecting quarks with the cosmos, which he led, identied opportunities at the intersection of astronomy and physics and ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.132 appendix ahas shaped the science investment in the united states and elsewhere around the world. turner is currently the chair of the physics section of the national academy of sciences and the chairelect of the division of astrophysics within the american physical society.j. anthony (tony) tyson is distinguished professor of physics at the university of california at davis and the director of the large synoptic survey telescope (lsst). lsst will look wide, fast, and deep, scanning the entire night sky every three nights for 10 years. its mission will be to map the mysterious ﬁdark matterﬂ and ﬁdark energyﬂ that physicists say make up 95 percent of the universe. his research interests are in cosmology, dark matter, dark energy, observational optical astronomy, experimental gravitational physics, and new instrumentation. he received his ph.d. from university of wisconsin in 1967 and was a member of the technical staff at bell laboratories from 1969 to 2003. his honors include election to the american philosophical society and the national academy of sciences, the aaronson memorial prize, and fellowships in the american academy of arts and sciences and the american physical society. steven c. wofsy is the abbott lawrence rotch professor of atmospheric and environmental sciences in the department of earth and planetary sciences at harvard university. dr. wofsy holds a ph.d. in chemistry from harvard university. he studies a variety of atmospheric gases using instruments aboard aircraft and also on the ground at longterm measurement sites. his research interests include undertaking theoretical and modeling studies to understand depletion of stratospheric ozone in polar regions, to assess future impacts of pollutants injected into the stratosphere, and to examine ecological and historical factors affecting atmospheric concentrations of co2. in 2001, dr. wofsy received the distinguished public service medal from the national aeronautics and space administration. he is a fellow of the american geophysical union and the american association for the advancement of science.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix brelevant national academy of sciences, national academy of engineering, institute of medicine, and national research council reports third edition (2009)committee on science, engineering, and public policysynopsis: describes the ethical responsibilities of researchers, using case studies. treatment of data is one of the topics covered. provides an overall framework for responsible research practices that underlies this study™s discussion on ensuring the integrity of data. (2007)committee on models in the regulatory decision process, national research councilsynopsis: examines the use of models by the environmental protection agency in the regulatory process, and recommends a lifecycle management approach to developing, testing, and revising models. developing environmental regulations relies on both data and models. principles outlined in the report, such as the importance of peer review and of providing accurate descriptions of a model™s assumptions, are analogous to this study™s principles for providing access to data and metadata.  (2007)committee on archiving and accessing environmental and geospatial data at noaa, national research councilsynopsis: the national oceanographic and atmospheric administration (noaa) collects, manages, and disseminates a wide range of climate, weather, ecosystem, and other environmental data used by scientists, engineers, resource managers, policy makers, and others in the united states and around the world. the increasing volume and diversity of noaa™s data holdingsšwhich 133ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.134 appendix binclude everything from satellite images of clouds to the stomach contents of shšand a large number of users present noaa with substantial data management challenges. the report offers nine general principles for effective environmental data management, along with a number of guidelines on how the principles could be applied at noaa. the principles and guidelines developed for noaa are consistent with the accessibility and stewardship principles laid out in this study, and represent an example of how they apply to an agency with signicant data management responsibilities in the earth sciences. the description of noaa™s data management challenges also illustrates the challenges of providing access and stewardship for large, heterogeneous datasets. (2007)committee on a new governmentuniversity partnership for science and securitysynopsis: explores various aspects of science and security, including access to data and movement of students and researchers across borders. upholds the principle that the results of unclassied basic research should not be restricted.  (2006)committee on surface temperature reconstructions for the last 2,000 years, national research councilsynopsis: examines the use of proxy evidence from multiple sources to reconstruct surface temperatures. in addition to its main conclusions about the reliability of multiproxy reconstructions, the report points out the differences in approaches to data availability in the elds covered, and that open access to data and methods will improve public condence in the results of this research. (2006)committee on intellectual property rights in genomic and protein research and innovation, national research councilsynopsis: explores intellectual property (ip) issues related to genomic and protein research, identies areas where emerging practices in patenting and sharing data or research resources might impede research, and recommends steps that federal agencies, research institutions, and companies should take to prevent ip protections from impeding future breakthroughs. access to and sharing of research data are addressed in several recommendations. (2006)caryn kuebler and christopher mackie, rapporteurs, steering committee for the workshop on the benets of interagency business data sharing, national research councilensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix b 135synopsis: describes the benets of greater sharing of business and other data among federal agencies, the barriers (mainly the need to maintain condentiality), and possible approaches. covers issues of data access relevant to economics and other social sciences. (2005)panel on data access for research purposes, national research councilsynopsis: focuses on expanded access to microdata from studies conducted by federal statistical agencies under pledges of condentiality. describes barriers to data access that are common in the social sciences, and develops approaches to overcoming them. (2005) committee on digital archiving and the nara, national research councilsynopsis: develops a comprehensive longterm strategy for how the nara should approach archiving digital data. many of the issues and barriers identied in the report, and the recommended strategies for addressing them, are relevant to a wide range of research elds and organizations charged with stewardship of research data.  (2005)panel on enhancing the data infrastructure in support of food and nutrition programs, research, and decision making, national research councilsynopsis: examines existing data sources used to support policy making and policy evaluation in food and nutrition programs. recommends steps to strengthen the data infrastructure in this area. a good example of an endusemotivated inventory of open and proprietary data sources. (2004)committee on electronic scientic, technical, and medical journal publishing and its implications and committee on science, engineering and public policy, the national academiessynopsis: summarizes a symposium that considered the changing digital environment for scholarly publishing.  (2004)committee on licensing geographic data and services, national research councilsynopsis: addresses the growing practice whereby federal agencies license geographic data from private vendors for their own use and for the use of outside researchers. provides guidelines for when and under what circumstances agenensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.136 appendix bcies should enter such agreements, and describes complementary strategies, such as creation of a national commons and marketplace in geographic data, to maximize access to data for research and other uses. a careful examination of a eld where access to private data is necessary for the advance of research. these guidelines may become applicable to other elds in the future. (2004)committee on genomics databases for bioterrorism threat agents, national research councilsynopsis: examines the security implications of access to genomic data, concluding that continued open access to genomic data is the best approach. recommends that professional societies educate researchers about the risks of research results being misused. an example of a eld in which open access is the best approach to ensuring security.  (2003)committee on responsibilities of authorship in the biological sciences, national research councilsynopsis: the publication of experimental results and sharing of research  materials related to those results have long been key elements of the life sciences. over time, standard practices have emerged from communities of life scientists to facilitate the presentation and sharing of different types of data and materials. but recently a concern has emerged that, in practice, publicationrelated data and materials are not always readily available to the research community. this report nds that the life sciences community does possess commonly held ideas and values about the role of publication in the scientic process. those ideas dene the responsibilities of authors and underpin the development of community standards: practices for sharing data, software, and materials adopted by different disciplines of the life sciences to facilitate the use of scientic information and ensure its quality. the report is a very clear and thorough exploration of standards and expectations for making data accessible in an important eld. the principles developedšthat authors are required to make data available as a quid pro quo for publication, that authors are obligated to provide data and other materials in a form on which scientists can build further with research, and that all members of the scientic community have equal responsibility for upholding community standardsšare consistent with those recommended by this study, and represent something of a ﬁgold standardﬂ that other elds might try to emulate. ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix b 137 (2003)committee on coping with increasing demands on government data centers, national research councilsynopsis: describes the increasing demands on government data centers that store and provide access to environmental data, and technical approaches to ensure effective operation in the future. in the earth and environmental sciences, the federal government has a major responsibility for the stewardship of data. provides an overview of the issues and makes recommendations for technical approaches that might be used by the centers and users. these approaches might have relevance to other elds.(2003)committee on ensuring the quality of government information, national research councilsynopsis: summarizes discussion at a series of workshops involving agencies and researchers to discuss implementation of the data quality act. provides background on the data quality act, which is an important part of the policy context for this study™s discussion of the integrity and accessibility of data.  (2003)julie m. esanu and paul f. uhlir, editors, national research councilsynopsis: papers from a symposium on how the scientic community can maintain and expand the public domain for scientic and technical data and information. the papers explore many aspects of the intellectual property environment for research. (2002)science, technology, and law panel, national research councilsynopsis: a workshop on issues related to the data access act (the shelby amendment) which was adopted in 2000. points out that peer review does not detect fraud or substitute for the judgment of the scientic community as a whole; it provides advice to a journal editor about the importance of the ndings and whether the reported evidence supports the author™s claims. illustrates the barriers to making data available, particularly in elds where data can be used to identify individuals. also illustrates the pros and cons of various approaches to ensuring the accessibility of data, including that of the data access act, which is modeled on the freedom of information act. ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.138 appendix b (2002)steering committee on space applications and commercialization, national research councilsynopsis: much of the remote sensing data needed for earth sciences research are now provided by private sector entities, and are made available to the federal government and university researchers through various licensing agreements and partnership arrangements. the report evaluates these arrangements and makes recommendations for how they should be structured in order to best advance science. the report explores intellectual property issues involved when private sector data is obtained for use in government and university environments. the principles developed might be useful for other elds where data generated by the private sector might be utilized to advance research. (2002)committee on assessing integrity in research environments, national research council, institute of medicinesynopsis: provides a highlevel view on research integrity and how it can be promoted. much of the focus is on institutional approaches to education and selfassessment. consistent with this study™s ndings and recommendations on institutional responsibility.(2002)committee on the preservation of geoscience data and collections, national research councilsynopsis: describes the importance of geoscience data and collections and the challenges of stewardship. develops criteria for prioritizing geoscience data and collections to be preserved, and recommends a specic strategy for doing so. a case study of the tension between devoting resources to creating new data and preserving existing data. a good example of how criteria can be developed on a disciplinary basis for making these judgments. (2002)task group on the usefulness and availability of nasa™s space mission data, national research councilsynopsis: calls on nasa to devote more resources and management attention to data stewardship, including ensuring compatibility with parallel data efforts such as the national virtual observatory. earth and space science examples illustrating the importance of data reuse. ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix b 139 (2002)panel on the impact of information technology on the future of the research university, national research councilsynopsis: broad overview of information technology changes and their implications for the research university. calls attention to the institutional role in preserving and disseminating knowledge, including data. (2001)steering committee on space applications and commercialization, national research councilsynopsis: examines possibilities for applying remotesensing data to new applications and the implications for policy. illustrates the value of data reuse while also recognizing that developing new applications may carry considerable costs. points out the lack of standard data protocols and formats as a barrier to using data for new applications. (2001)ofce of special projects, national research councilsynopsis: a broad overview of how information technology is transforming science and engineering research, and the implications for researchers. highlights the importance of ensuring the quality of digital data and the challenges of stewardship. (2001)committee on geophysical and environmental data, national research councilsynopsis: denes appropriate spheres for the public and private sectors in the growing eld of environmental data. recommends that the public sector should continue to collect and synthesize data, and to provide such data at no more than the marginal cost of reproduction with no usage restrictions. the private sector would focus on valueadded distribution and specic observational systems.(2000)ocean studies board, national research councilsynopsis: describes the current system of data collection, management, and use in the marine sheries eld, and recommends improvements. illustrates the growing need to work across sectors to improve data quality and stewardship in a ﬁsmall scienceﬂ eld that is highly relevant to policy.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.140 appendix b (2000)a workshop summary by robert pool and joan esnayra, board on biology, national research councilsynopsis: summary of a workshop on data issues related to bioinformatics. illustrates how the growing availability of data is transforming science and engineering. (2000)christopher mackie and norman bradburn, editors, national research councilsynopsis: explores the challenges of improving access to data with condentiality restrictions. the challenge of improving access to data with condentiality restrictions goes across several elds.  (2000)committee on intellectual property rights in the emerging information infrastructure, national research councilsynopsis: indepth examination of copyright issues, including those related to digital archiving, in the wake of the digital millennium copyright act. relevant to the changing environment for scientic publishing, an important aspect of the context for this study, as well as the role of libraries.(1999)committee for a study on promoting access to scientic and technical data for the public interest, national research councilsynopsis: describes the importance of scientic and technical databases in research, and standard practices for production, dissemination, and use of data in federal, nonprot, and commercial contexts. develops principles and guidelines for agencies, research institutions, and investigators. explores various proposals for creating new intellectual property protection for noncopyrightable databases current at the time of the study, along with the pros and cons of these proposals. the european union had recently created such protection. several of the principles and guidelines are consistent with this study, including: (1) scientic and technical data owned or controlled by the government should be made available for use by notforprot and commercial entities alike on a nonexclusive basis and should be disseminated to all users at no more than the marginal cost of reproduction and distribution, whenever possible; (2) federal funding agencies should require university and other notfor prot researchers or their employing institutions that use federal funds, wholly or in substantial part, in creating databases not to grant exclusive rights to such databases when ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix b 141submitting them for publication or for incorporation into other databases. also provides a good overview of intellectual property issues related to data. data itself is not copyrightable, and there are signicant limitations on copywriting databases. the policy context has not changed much since the time of this report, as the united states and other nations have not followed the european union to create new intellectual property protection for databases.  (1999)committee on federal policy for access to research, resources, national research councilsynopsis: this conference summary describes issues affecting access to a variety of research resources in the life sciences, including data and databases,  materials, software, and so forth. provides background on data access issues in the life sciences. the recommendations are largely superseded by sharing publicationrelated data and materials (2003). (1999)jonathan r. davis, vivian p. nolan, janet woodcock, and ronald w. estabrook, editors, institute of medicinesynopsis: describes the process for assuring the integrity of clinical trial data and suggests improvements. background to the issues of clinical trials data discussed in this study.(1997)committee on issues in the transborder flow of scientic data, national research councilsynopsis: outlines the needs for access to data in the physical, astronomical, geological, and biological sciences. characterizes the legal, economic, policy, and technical factors and trends that have an in˚uence on access to data by the scientic community. identies and analyzes the barriers to international access to scientic data. recommends approaches that could help overcome those barriers. the two key challenges are the increasing quantities, varieties, dissemination modes, and interdisciplinary relevance of data, and increasing legal and economic restrictions on publicly funded data. states the principle that ﬁfull and open access to scientic data should be adopted as the international norm for the exchange of scientic data derived from publicly funded research. the publicgood interests in the full and open access to and use of scientic data need to be balanced against legitimate concerns for the protection of national security, individual privacy, and intellectual property.ﬂ this study would extend this principle somewhat, to include privatesectorfunded data on which published research results are based.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.142 appendix b (1992)committee on science, engineering, and public policysynopsis: broad overview and guidance on how the research enterprise should ensure research integrity. the principles and approaches developed in this study still underlie the denitions, standards, and policies related to ensuring responsible research and dealing with misconduct. (1985)stephen e. fienberg, margaret e. martin, and miron l. straf, editors, committee on national statistics, national research councilsynopsis: explores advantages of and barriers to sharing social sciences data. early exploration of the idea of asking researchers to provide a data dissemination plan in their proposals, including ﬁthe time of release of data, the means by which the data would be made available and preserved for longterm use, the technical form in which data would be released, the supporting documentation that would accompany the data, what forms of access to condential or other sensitive data would be provided, and an assessment of the policy relevance and broad research value of the data.ﬂensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix cletters from scientic journals  requesting the study143ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.144 appendix censuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix c 145ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.146 appendix censuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix c 147ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.148 appendix censuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix c 149ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.150 appendix censuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix c 151ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.152 appendix censuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.appendix c 153ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.aaccess to research data. see also open; sharing data bermuda statement, 60 condentiality or privacy considerations, 5, 67 costs of limiting access, 7071, 7778 crossdiscipline diversity in, 5, 27, 6364, 88, 90, 136 cyberinfrastructure and, 6162, 8384, 87, 135 data mining tools, 2021 data professional™s role, 90 denition of accessibility, 26 economic considerations, 26, 59, 6970, 7172, 85, 87, 89, 141 educational considerations, 70 federal policies, 4849, 6061, 62, 6869, 74, 7879, 8283, 9192, 116117 geographic data and services, 7576, 133134, 135136, 138 institutional and research sponsor responsibilities, 7, 87, 9091, 116117, 119 and integrity of data, 5, 26, 42, 4647, 63, 64, 70, 8182, 89, 137 international dimensions, 17, 35, 64, 66, 70, 75, 7677, 79, 8384 journal policies, 21, 38, 43, 61, 65, 7879, 8283, 87, 89, 90, 91, 92, 93, 116117, 135 legal issues, 67, 71, 75, 8082, 85, 141 metadata and, 25, 26, 70, 85 methods or programs used to derive data, 6, 6364, 81, 85, 89 national security issues, 5, 6869, 83, 134, 136 oecd principles and guidelines, 59, 62 ownership issues, 56, 21, 7379, 8586, 134, 135136, 137, 138 paris guidelines, 88, 89 principles for enhancing access, 6, 82, 8486, 87, 8890, 120 private/commercial interests, 6, 19, 26, 48, 69, 7173, 86, 134135 professional organizations and, 91, 116117 public policy interests, 18, 7173, 135, 141 publicly funded research, 6, 74, 7677, 78, 80, 82, 83, 84, 85, 9293, 141 raw data, 80 recommendations, 67, 87, 88, 90, 91 and reproducibility, 81, 93 research eld responsibilities, 87, 8890, 136 researcher responsibilities, 7, 85, 8687, 116117, 136air force ofce of scientic research, 5253amazon, 106america competes act of 2007, 82american association for the advancement of science, 144145american association of universities, 118american chemical society, 39american economic review, 39, 65american geophysical union, 38, 39index155ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.156 indexandrew w. mellon foundation, 101, 107, 112annals of internal medicine, 93arabidopsis information resource, 30arts and humanities data service (uk), 66arxiv publication repository, 102association of american universities, 91association of public and landgrant universities, 91association of research libraries, 91astrobiology, 28astronomical sciences, 1415, 16, 17, 64, 66, 95, 141automatic plate measuring facility, 14bbayhdole act of 1980, 76bell laboratories, 45biomedical informatics grid, 61biomedical informatics research network, 20, 61biomedical research, 68, 86, 93. see also clinicalbit torrent, 89blue ribbon task force on sustainable digital preservation and access, 107, 113boeing, 105boomerang (balloonborne millimeterwave telescope), 14ccanadian department of national defence, 105cc0 protocol, 76cell centered database, 20center for astrophysics, 14cern (european center for nuclear research), 13, 16, 34chaotic motion, 41chargecoupled devices, 11chemical crystallography, 66china, scientic data sharing project, 84climate sciences, 66, 7172, 82, 96, 134clinical research, 2, 4, 47, 4849, 141. see also biomedicalcloud computing, 61collaborative datasharing networks, 15, 1718, 64, 84, 111 research, 1718, 20, 35, 63, 64, 66, 96, 101 stewardship, 103, 113committee on data for science and technology, 84committee on government relations, 118committee on institutional cooperation, 118condensedmatter physics, 45condentiality or privacy considerations, 5, 67, 140consolidated appropriations act of 2001, 82 of 2008, 79copyrights, 73, 7475, 76, 78, 79, 85, 100, 140141cornell university, 102cosmic background explorer, 14cosmic background imager, 14council of graduate schools, 55council of science editors, 37council on government relations, 91creative commons, 76cyberinfrastructure and access to data, 6162, 8384, 87, 135 and stewardship, 9, 95, 96, 99106, 113ddata, dened, 23data access act of 1999, 8081, 92data collections. see databasesdata explorer program, 83data management. see also stewardship institutional plans, 9293, 98, 110 principles and guidelines, 8890, 133134 training in, 56data mining tools, 2021data producers. see also researchers dened, 40 integrityrelated responsibilities, 40, 42data professionals and access to data, 92 and integrity of data, 5, 50, 5758 researcher collaborations with, 5758 responsibilities, 3, 50, 58data providers dened, 41 integrityrelated responsibilities, 41, 42data users dened, 41 and integrity of research results, 41, 42ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.index 157databases and repositories. see also stewardship; individual databases access to, 73, 83 dened, 29 developmental questions about, 21 disciplinary depositories, 27, 100, 102 integrity of data, 21, 46, 50 ownership issues, 7374, 140141 reference collections, 29, 30 research collections, 29, 30 resource collections, 29, 30 for supporting data, 89 tools for building, 100101digital data. see also research data; individual disciplines ownership, 73 projected growth, 12, 13 quantity, 1, 1112, 13, 29, 8485 risks to reliability, 9699 transfer rates, 11 trends, 1415 units of size, 11, 12digital millennium copyright act of 1998, 75, 140digital networks, 8384digital technology in astronomy, 1415 challenges posed by, 12, 19, 22, 7475 computing power, 1112, 20 and copyrights, 7475 education impacts, 18 and integrity of data, 1, 34, 21, 3334, 37, 44, 4650 in neurosciences, 2021 public policy implications, 18 research impacts, 1, 1218, 2021, 3435, 44, 51, 5556, 5758, 85, 139, 140 sensors and sensor networks, 11, 1617 simulations and mathematical modeling, 1, 17, 20 and stewardship, 12, 19, 22, 27 storage devices, 11diversity of data in collection types, 29, 30 crossdisciplinary, 2728 in origins, 2829dna. see also genomic data ﬁjunk,ﬂ 41eearth observing system, 17ecological society of america, 39, 111, 112, 113economic issues, 21, 22, 26, 43, 44, 59, 6970, 7172, 85, 87, 89, 9899, 105106, 113economics research, 47, 50, 64, 65, 105106educational considerations, 70employment responses to global markets data, 105106environmental sciences, 17, 104, 133134, 137, 139european community directive on the legal protection of databases, 75european southern observatory, 64experimental data, 1, 13, 16, 17, 20, 22, 23, 26, 27, 29, 35, 40, 42, 45, 64, 67, 109, 136extramural grants, federal policies on, 5253ffederal policies on access, 4849, 6061, 62, 6869, 74, 7879, 8283, 9192 on integrity, 5253 on stewardship, 79, 104106, 113, 133134, 137federation of american societies for experimental biology, 38, 39fischer, paul, 7172fluxes over snow surfaces project, 30food and drug administration, 48fostering integrity in research, scholarship, and teaching, 56freedom of information act, 80ggalaxy redshift surveys, 14galaxy surveys, 14genbank, 3, 46, 47, 52, 83, 104gene expression data, 20general accounting ofce, 81genomic data, 16, 20, 6061, 69, 7778, 95, 96, 134, 136geographic data and services, 7576, 133134, 135136georgia open records act, 71geosciences, 98, 138ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.158 indexglaxosmithkline clinical trial register, 48global biodiversity information facility, 84global earth observation system of systems, 84google, 106government accountability ofce, 82governmentindustry data exchange program, 105grid computing, 61hhealth insurance portability and accountability act, 68, 110health records data, 49, 68highenergy physics. see particle physicshoward hughes medical institute, 77human brain dynamics resource data, 105humanities research, 66hwang, woo suk, 44iideals repository, 102103information quality act of 2001, 80, 81, 82, 137institute of electrical and electronics engineers, 39institute of medicine, 55integrity of research data accessibility and, 5, 26, 42, 4647, 63, 64, 70, 8182, 137 in clinical research, 2, 4, 47, 4849, 141 collective scrutiny of data and results, 4143, 47 contextual documentation, 3, 4243, 45, 4647, 6364 data professionals™ responsibilities and roles, 5, 50, 5758, 116 decentralized approach, 57 dened, 2, 2526 digital technology to enhance reliability, 1, 34, 21, 3334, 37, 44, 4650 economic issues, 43, 44 economics research, 47, 50 federal policies, 5253, 116, 137 inappropriate manipulation, 3, 5, 3536, 37, 3839, 40, 44 journal policies, 3, 5, 3537, 38, 39, 40, 43, 116 metadata and, 42, 46, 50 open and public reviews, 46 in particle physics, 3435, 47 peer review, 2, 3, 7, 22 n.17, 24, 33, 35, 39, 42, 4344, 4647, 52, 55, 79, 133, 137 principle, 4, 51, 120 producer™s role, 40, 42, 116 provider™s role, 41, 42, 116 quality control measures, 35, 4450, 138 recommendations, 45, 54, 57, 58 and reproducibility of research results, 2, 26, 29, 33, 45 researchers™ obligations, 26, 3940, 45, 5154, 116, 119, 133 standards, 25, 3536, 44, 45, 50, 5455, 5657, 138, 142 threats to, 23, 19, 3334, 3940, 9699 training for researchers, 45, 44, 5456 user™s role, 41, 42, 116interagency working group on digital data, 9, 107108interdisciplinary research, 1, 67, 9, 17, 28, 44, 57, 60, 70, 141intergovernmental panel on climate change, 72international council of scientic unions, 84international dimensions of access, 17, 35, 64, 66, 70, 75, 7677, 79, 8384international federation of digital seismograph networks, 84international geophysical year, 83international nucleotide sequence database collaboration, 84international virtual observatory alliance, 84interuniversity consortium for political and social research, 99101, 102, 113intramural research, federal policies, 5253invisible colleges, 28ithaka, 112jjournal of cell biology, 3537, 39, 40, 150153journals access policies, 21, 38, 43, 61, 65, 7879, 8283, 87, 89, 90, 91, 92, 93, 135 conrmatory studies in, 65 copyrights, 7879 data manipulation policies, 3, 5, 3537, 38, 39, 40, 43 as data providers, 41ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.index 159 ethics and scientic misconduct policies, 38 integrity policies, 3537, 38, 39, 40, 43, 56, 65 letters requesting this study, 143153 open access, 46 n.16, 7879, 83 peerreviewed, 43 responsibilities of, 119120 stewardship role, 21, 106, 113, 117jstor, 112llaboratory management institute, 55large hadron collider, 13, 16, 3435large synoptic survey telescope, 13, 14, 15las campanas redshift survey, 14legal issues, 67, 71, 75, 8082, 85library of congress, 112, 113licensing, 7576, 7778, 135136lick observatory, 14life sciences, 23 n.18, 59, 6061, 64, 66, 69, 7778, 88, 9596, 134, 136, 141lockheed martin, 105mmanipulation of data, inappropriate, 3, 5, 3536, 37, 3839, 40, 44mann, michael, 7172marine sheries data, 139medical college of georgia, 71merck, 86metadata access issues, 25, 26, 70, 85 dened, 24 importance, 42 and integrity of research data, 42, 46, 50 providers, 21 standards, 24 stewardship, 95, 110misconduct. see research misconductmolecular and cellular proteomics, 89molecular dynamics simulation data, 105moore, gordon, 11moore™s law, 11, 96multidisciplinary research, 28mygrid, 61nnational aeronautics and space administration, 17, 5253, 64, 105, 138national archives and records administration, 135national association of state universities and landgrant colleges, 118national center for biotechnology information, 9596, 104national commons and marketplace in geographic information, 76national ecological data center, 112national ecological observatory network, 1617national institute for technology and liberal education, 103national institute of standards and technology, 5253national institutes of health, 5253, 5455, 78, 79, 8283, 9091, 99, 100, 102national library of medicine, 79, 83, 104national oceanographic and atmospheric administration, 104, 133134national optical astronomy observatory, 64national postdoctoral association, 55national research council, 9, 5960, 64, 6769, 72, 7576, 7778, 8081, 82, 98, 104, 108, 111national science and technology council, 107108national science board, 29, 30national science foundation, 1617, 24, 52, 82, 99, 100, 102, 104, 107national security decision directive 189, 6869national security issues, 5, 6869, 83, 134, 136national virtual observatory, 15, 105, 138natural environment research council (uk), 66nature, 37, 38, 46, 109110network for earthquake engineering simulation, 1617neurosciences, 13, 2021, 99, 105new england journal of medicine, 39oobservational data, 2, 17, 22, 23, 26, 28, 33, 40, 42, 48, 64, 67, 106, 109ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.160 indexofce of management and budget, 22 n.17, 52, 69, 80, 81, 82ofce of naval research, 5253ofce of science and technology policy, 3637omnibus appropriations act of 2009, 79openaccess academic policies, 91 corporate/private platforms, 86 journals, 7879, 91 public policies, 8283, 85, 91 repositories, 83openknowledge environments, 6263opennotebook science, 63open reviews, 46opensource software, 6263organisation for economic cooperation and development (oecd), 59, 62, 84ownership issues academic research, 69, 77 copyrights, 73, 7475, 76, 78, 79, 85, 100, 140141 database protections, 7374, 75, 76, 140141 digital technologies and, 7475 fair use exceptions, 74 journals, 7879 licensing, 7576, 7778, 135136 patents, 6, 25, 69, 7678, 8586, 134 publicly funded research, 74, 7677, 78 trade secrecy, 77ppalimpsest, 106paris guidelines, 88, 89particle physics, 1213, 3435, 42, 47, 64, 131patents, 6, 25, 69, 7678, 8586, 134peer review, 2, 3, 7, 22 n.17, 24, 33, 35, 39, 42, 4344, 4647, 52, 55, 79, 133, 137pennsylvania state university, 71physics, 27, 45, 102. see also particle physicsplanck survey, 14plate tectonics, 41portico, 106principles access to data, 6, 82, 120 integrity of data, 4, 51, 120 stewardship, 8, 109, 120private/commercial interests, 6, 19, 26, 48, 69, 7173, 86, 106, 134135proceedings of the national academy of sciences, 37, 38processed data dened, 25 integrity, 1, 25, 3334professional organizations, 91, 111112, 117, 119120. see also individual organizationsprotein data bank, 30, 105proteomics research, 7778, 89, 134public library of science (plos), 7879public policies on access, 5253, 66, 7879, 8283, 133134public policy interests, 18, 7173, 135publicly funded research, 6, 74, 7677, 78, 80, 82, 83, 84, 85, 9293pubmed, 60qquality control and quality assurance, 35, 4450. see also integrity of research datarraw data access to, 15, 74, 80 dened, 25 stewardship, 25, 45, 106raytheon, 105reagan, ronald, 68recommendations access to data, 67, 87, 88, 90, 91 integrity of research data, 45, 54, 57, 58 stewardship, 89, 110, 111, 113remote sensing data, 40, 75, 138, 139reproducibility of research results access to data and, 81, 93 dened, 81 integrity of data and, 2, 26, 29, 33, 45research councils of the united kingdom, 84research data. see also digital data; individual disciplines denitions, 2224research information network (uk), 64, 66research institutions and sponsors, responsibilities of, 7, 9, 5657, 87, 9091, 100103, 110, 112113, 117, 118119, 139ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.index 161research misconduct access to supporting data and, 63 dened, 3637 examples, 44, 45 training, 52researchers accessrelated responsibilities, 7, 85, 8687, 116117, 118, 136 collaborations with data professionals, 5758 integrityrelated obligations, 26, 3940, 45, 5154, 116, 133 professional standards, 54, 5657 stewardship role, 89, 45, 99100, 109112, 117 training in conduct of research, 45, 44, 5456, 118r.j. reynolds co., 71rockefeller university press, 35, 38roles and responsibilities assigning, 115 journals, 119120 professional societies, 119120 research institutions, 118119 research sponsors, 119 researchers, 115118rural economy and land use program (uk), 66ssage, 86san diego supercomputer center, 105schön, jan hendrik, 45science, 38, 44, 144149science commons, 76seoul national university, 44sharing data. see also access; databases, open in astronomy, 15, 64, 66 barriers to, 1, 57, 19, 26, 28, 60, 6370, 76, 85, 88, 135, 137, 139, 141, 142 benets, 5, 20, 5962, 70, 142 in biomedical research, 68, 86, 93 in chemical crystallography, 66 in climate sciences, 66, 7172, 82, 134 collaborative efforts, 15, 1718, 64, 84, 111 contextual documentation, 65, 66, 67 in economics, 64, 65 in humanities, 66 incentives for, 9091 in life sciences, 23 n.18, 59, 6061, 64, 66, 69, 7778, 88, 134, 136, 141 norm differences of research elds, 67, 6364, 66, 88, 90 in particle physics, 64 protocols and standards, 7, 83, 87, 8890, 92, 139 public policies, 5253, 66, 7879, 8283, 133134 in social sciences, 65, 66, 68, 100101, 135 upside principle, 64, 6768, 86shelby, richard, 80simulations and mathematical modeling, 1, 17, 20, 22, 23, 28, 40, 42, 46, 61, 105, 106skyserver web site, 14sloan digital sky survey, 3, 1415, 46, 47, 95, 105social network modeling, 17social sciences, 22, 27, 65, 66, 68, 98, 100101, 135, 142standards for access, 7, 83, 87, 8890, 92 for integrity of research data, 25, 3536, 44, 45, 50, 5455, 5657 for stewardship, 89, 111stewardship of research data. see also databases annotating data for longterm use, 8, 21, 22, 25, 95, 99, 106107, 110 in astronomy, 95 for broad research enterprise, 107108 challenges, 8, 103 collaborations, 103, 113 companies, 106 dened, 27, 95 disciplinary depositories, 27, 100, 102 economic issues, 78, 21, 22, 9899, 105106, 113, 119 esa initiative, 112 exchanges of data, 105 federal agencies, data centers, and digital archives, 79, 104106, 113, 117, 133134, 135, 137 in geosciences, 98, 138 infrastructure and incentives, 9, 95, 96, 99106, 113 institutions and research sponsors, 9, 100103, 110, 112113, 117, 119, 139 international participation, 111 journals, 21, 106, 113, 117 in life sciences, 9596 loss and underutilization problems, 9699ensuring the integrity, accessibility, and stewardship of research data in the digital agecopyright national academy of sciences. all rights reserved.162 index metadata, 95, 110 old vs. new data, 98, 138 oversight board, 111 ownership issues, 9, 99 principle for enhancing, 8, 109, 120 professional societies and, 111112, 117 raw data, 25, 45, 106 recommendations, 89, 110, 111, 113 researchers and, 89, 45, 99100, 109112, 117 simulationrelated models and software tools, 28 in social sciences, 98, 100101 standards development, 89, 111 technology changes and, 12, 19, 22, 27 training in, 119sumsdb, 2021sustainable digital data preservation and access network (datanet) program, 104105tterminology accessibility, 26 integrity, 2526 metadata, 24 processed data, 25 raw data, 25 research data, 2224 standardization of, 49 stewardship, 27trace archive, 95, 96training for researchers, 5456tranche, 89twodegreeœfield (2df) galaxy redshift survey, 14uuniversity of california at davis, 55university of california at san diego, 105university of illinois at urbanachampaign, 102103university of konstanz, 45university of minnesota, 56utility of research data, dened, 27. see also access; integrity; stewardshipu.s. department of agriculture, 5253u.s. department of commerce, 5253u.s. department of energy, 5253, 83, 105u.s. department of health and human services, 52, 55u.s. department of veterans™ affairs, 49u.s. environmental protection agency, 5253, 133u.s. patent and trademark ofce, 78upside principle, 64, 6768, 86vvirtual team science, 61visible and infrared telescope for astronomy, 14wwebcaret, 2021wellcome trust, 61, 83wikis, 46, 63wilkinson microwave anisotropy probe, 14world data center system, 83world intellectual property organization treaty, 75yyale university, 150153