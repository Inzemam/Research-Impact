detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/10235broadband: bringing home the bits336 pages | 6 x 9 | paperbackisbn 9780309082730 | doi 10.17226/10235committee on broadband last mile technology, computer science andtelecommunications board, national research councilbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.committee on broadband last mile technologycomputer science and telecommunications boarddivision on engineering and physical sciencesnational research councilnational academy presswashington, d.c.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.national academy press 2101 constitution avenue, nw washington, dc 20418notice: the project that is the subject of this report was approved by the governing boardof the national research council, whose members are drawn from the councils of thenational academy of sciences, the national academy of engineering, and the institute ofmedicine. the members of the committee responsible for the report were chosen for theirspecial competences and with regard for appropriate balance.the majority of the support for this project was provided by the defense advanced research projects agency under contract no. n0017499c0052 and the national science foundation under grant no. ani9908155. additional support was provided by the associationfor computing machineryõs special interest group on data communication, hewlettpackard, intel corporation, interval research corporation, worldcom, sun microsystems,texas instruments, and qwest. any opinions, findings, conclusions, or recommendationsexpressed in this material are those of the authors and do not necessarily reflect the views ofthe sponsors.international standard book number 0309082730additional copies of this report are available from:national academy press2101 constitution ave., n.w.box 285washington, dc 2041880062462422023343313 (in the washington metropolitan area)http://www.nap.educopyright 2002 by the national academy of sciences. all rights reserved.printed in the united states of americabroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific and engineering research, dedicated to the furtherance of science and technology and to their use for the generalwelfare. upon the authority of the charter granted to it by the congress in 1863,the academy has a mandate that requires it to advise the federal government onscientific and technical matters. dr. bruce m. alberts is president of the nationalacademy of sciences.the national academy of engineering was established in 1964, under the charterof the national academy of sciences, as a parallel organization of outstandingengineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsorsengineering programs aimed at meeting national needs, encourages educationand research, and recognizes the superior achievements of engineers. dr. wm. a.wulf is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy ofsciences to secure the services of eminent members of appropriate professions inthe examination of policy matters pertaining to the health of the public. theinstitute acts under the responsibility given to the national academy of sciencesby its congressional charter to be an adviser to the federal government and, uponits own initiative, to identify issues of medical care, research, and education.dr. kenneth i. shine is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology withthe academyõs purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both the nationalacademy of sciences and the national academy of engineering in providingservices to the government, the public, and the scientific and engineering communities. the council is administered jointly by both academies and the institute ofmedicine. dr. bruce m. alberts and dr. wm. a. wulf are chairman and vicechairman, respectively, of the national research council.national academy of sciencesnational academy of engineeringinstitute of medicinenational research councilbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.vcommittee on broadband last mile technologynikil jayant, georgia institute of technology, chairjames a. chiddix, aol time warnerjohn m. cioffi, stanford universitydavid d. clark, massachusetts institute of technologypaul green, tellabs (retired)kevin kahn, intel corporationrichard lowenberg, davis community networkclifford lynch, coalition for networked informationrichard metzger, lawler, metzger & milkman llcelizabeth mynatt, georgia institute of technologyeli m. noam, columbia universitydipankar raychaudhuri, rutgers universitybob rowe, montana public service commissionsteven s. wildman, michigan state universitystaffmarjory s. blumenthal, directorjon eisenberg, senior program officerdavid drake, project assistantdavid padgham, research assistantbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.vicomputer science and telecommunications boarddavid d. clark, massachusetts institute of technology, chairdavid borth, motorola labsjames a. chiddix, aol time warnerjohn m. cioffi, stanford universityelaine cohen, university of utahw. bruce croft, university of massachusetts at amherstthomas e. darcie, at&t labs researchjoseph farrell, university of california at berkeleyjeffrey m. jaffe, bell laboratories, lucent technologiesanna karlin, university of washingtonbutler w. lampson, microsoft corporationedward d. lazowska, university of washingtondavid liddle, u.s. venture partnerstom m. mitchell, whizbang! labs, inc.donald norman, nielsen norman groupdavid a. patterson, university of california at berkeleyhenry (hank) perritt, chicagokent college of lawburton smith, cray inc.terry smith, university of california at santa barbaralee sproull, new york universityjeannette m. wing, carnegie mellon universitymarjory s. blumenthal, directorherbert s. lin, senior scientistalan s. inouye, senior program officerjon eisenberg, senior program officerlynette i. millett, program officercynthia patterson, program officersteven woo, program officerjanet briscoe, administrative officermargaret huynh, senior project assistantdavid drake, senior project assistantjanice sabuda, senior project assistantjennifer bishop, senior project assistantdavid padgham, research assistantbrandye williams, staff assistantbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.viisince its inception, the computer science and telecommunicationsboard (cstb) has examined how the nationõs networked infrastructurehas been evolving. at the close of the past decade, the popular appeal ofthe internet was evident and growing, and with it the range and richnessof the uses to which the internet might be put. the vision of a popularinternet leads inevitably to thoughts about how people use it in theirhomesñand then to the arresting observation that most people get thebest possible access to the internet from outside their homes, if they canget it at all. that observation led cstb to frame an assessment of broadband technologies in what the telecommunications industry has traditionally called the last mileñthe link to homes (and small offices). thisproject complements prior cstb studies of the core of the networkñthebackbone, the architecture, broad categories of applications, and specificcategories of networking technologyñin its concern to (literally) bringnetworking home.the key questions about broadband technology in the last mile aredeceptively simple. first, what is feasible, technically and economically?but feasibility is a nuanced quality: it is in the eye of the beholder, andbeholders differ considerably in terms of their assumptions and preferences. those same conditions confound answering the second key question: how can public policy foster dissemination of broadband in the lastmile? many industries are involved in supplying broadband technology,and their existence and strategies are already shaped by public policy.and many outside those industries, trying to figure out what is going on,broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.viiiprefacehave their own views of what policy is or should be. moreover, recentindustry trends, from mergers to business failures, feed speculation of allkindsñexcept for an expectation that broadband deployment will accelerate. thus, to have any claim to completeness, an assessment of broadband in the last mile must combine consideration of technology, economics, and law and policy.accordingly, cstb convened a committee of 14 people with expertisein the following areas: the different kinds of technology that could beused in the last mile; the economics, law, and policy of the telecommunications and networked content industries; and trends in the home andlocal use of various kinds of networks and their applications.1 the committee combined people with academic, other nonprofit, and commercialexperience, and it embraced both supply and demandoriented perspectives. the committee met five times in plenary session and received extensive input through briefings, a workshop, and solicited white papers. inaddition, it had two plenary conference calls and made extensive use of email and a private web site for electronic exchange and deliberation.the committee thanks the many people who helped to make thisreport possible, although of course the responsibility for the final result isits own.a number of individuals provided valuable information throughbriefings to committee meetings. aubrey bush and rodger ziemer of thenational science foundation (nsf) presented the charge to the committee. dale hatfield, then chief of the federal communications commission(fcc) office of engineering and technology, and john berresford, fccantitrust attorney, presented the range of telecommunications policy concerns from a regulatorõs perspective. jeffrey chester, executive director,center for media education; eugene kimmelman, codirector, consumers union; and mark cooper, director of research, consumer federationof america, discussed concerns emerging from consumer advocates. andrew sharpless, then senior vice president of interactive media at discovery communications, described the perspective of an online content provider; david kettler, then executive director and vice president of scienceand technology with bellsouth, and c. lincoln (òlinkó) hoewing, assistant vice president, internet and technology, verizon, presented incumbent telephone company perspectives; william st. arnaud, canarie,inc., described the canadian experience and the larger opportunities inlocal investment in deploying optical fiber; milo medin, chief technologyofficer and senior vice president of engineering, excite@home network,discussed the cable industryõs approach to internet service and broad1david butler, who had recently retired from aol at the time the study started, resignedfrom the committee for personal reasons in 2000.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.prefaceixband deployment; jorge reina schement, professor of telecommunications and codirector of the institute for information policy, pennsylvaniastate university, provided context for considering universal service issues by describing the big picture of communications and informationconsumption across different population segments; ted darcie, director,at&t labs research, analyzed the merits of different broadband technologies and explained at&tõs thinking about its choices; douglas sicker,fcc office of engineering and technology, discussed perspectives ondsl and hfc technologies; james hannan, vice president of networktechnology, sprint broadband wireless, discussed wireless broadband;james stratigos, vice president and general manager of echostar datanetworks, discussed satellite broadband; kevin lu, executive director ofthe integrated access and operations department, telcordia, discussedfiber in the last mile; george abe, venture partner, palomar ventures,characterized venture capitalistsõ view of investment opportunities; thomas g. krattenmaker, senior counsel at mintz levin, outlined challengesin thinking about regulatory options; glenn woroch, a university of california at berkeley economist, presented an economic model of asymmetric regulation of the broadband race; andrew cohill, director of the virginia tech communications network services and director of theblacksburg electronic village, outlined concepts for a comprehensivemunicipal fiber plan; richard esposto, director of market activation, western integrated networks, discussed conditions and options confrontinglocal government, drawing on his immediately previous work of manyyears with the sacramento cable commission; joseph van eaton, principalpartner with miller & van eaton, discussed local franchises and licensing;and richard civille, washington director for the center for civic networking, discussed economic development and aggregating demand forrural telecommunications. some of these individuals and a number ofother people provided white papers to the committee (these are availableonline at <http://www.cstb.org> and are listed in appendix c).this project owes its existence to the support of its sponsors, in thisinstance an unusually large and diverse group, reflecting combined public and private interest in the topic. the majority of funds came fromgovernment or nonprofit sources: the national science foundation, thedefense advanced research projects agency, and the special interestgroup on data communication of the association for computing machinery. small contributionsñfrom hewlettpackard, intel corporation,interval research corporation, worldcom, sun microsystems, texas instruments, and qwestñwere developed by members of the computerscience and telecommunications board, who recognized that withoutthose resources the project could not be undertaken. in view of the politics of broadband, it is important to note and emphasize that as is typicalbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.xprefaceof cstb projects, the sponsors enabled but did not influence the outcomeof the project. from among these, the consistent encouragement of nsfõsaubrey bush and members of cstb are especially noted.cstb committees are often assembled with experts from very different backgrounds, and this committee was certainly no exception. it is tothe credit of our distinguished members that they constantly derivedstrength from the diversity in their team and realized an end result characterized by a substantial, and in some ways unexpected, degree of consensus. my thanks to each and every member of the team for their diligence and commitment. on behalf of the team and myself, i extend specialthanks to david clark, who played a major role in launching this studyand served as its òvirtual cochair,ó contributing to and inspiring thework of the committee on many occasions. the cstb staff, by now wellknown for its standards of broad excellence, performed once again withsupreme distinction. thanks to d.c. drake for facilitating our work inevery way possible and to marjory blumenthal for relentlessly challenging the committee to be comprehensive as well as creative, and finally,many thanks to jon eisenberg for his role in anchoring the report of thecommittee and for representing its work with remarkable timeliness andsophistication.nikil jayant, chaircommittee on broadband last mile technologybroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.xi˘ˇthis report has been reviewed in draft form by individuals chosen fortheir diverse perspectives and technical expertise, in accordance with procedures approved by the nrcõs report review committee. the purposeof this independent review is to provide candid and critical commentsthat will assist the institution in making its published report as sound aspossible and to ensure that the report meets institutional standards forobjectivity, evidence, and responsiveness to the study charge. the reviewcomments and draft manuscript remain confidential to protect the integrity of the deliberative process. we wish to thank the following individuals for their review of this report:robert broderson, university of california at berkeley,eugene cacciamani, hughes network systems,vincent chan, massachusetts institute of technology,andrew cohill, blacksburg electronic village and virginiapolytechnic institute,david kettler, h.i.g. capital,tom krattenmaker, mintz, levin, cohn, ferris, glovsky and popeo,p.c.,milo medin, excite@home,sharon l. nelson, university of washington law school,andrew odlyzko, university of minnesota,paul w. shumate, ieee lasers and electrooptics society,marvin sirbu, carnegie mellon university, anddavid waterman, indiana university.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the final draft of the reportbefore its release. the review of this report was overseen by lewisbranscomb, harvard university (emeritus). appointed by the nationalresearch council, he was responsible for making certain that an independent examination of this report was carried out in accordance with institutional procedures and that all review comments were carefully considered. responsibility for the final content of this report rests entirely withthe authoring committee and the institution.xiiacknowledgment of reviewersbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.xiii!abstract1summary and recommendations51setting the stage43the broadband challenge, 43perspectives on broadband, 45a brief history of the communications infrastructure, 47from promise to broad deployment: what has changedsince the mid1990s?, 50broadband deployment trends, 52reaching all americans, 54access economics and evolving applications, 57scope of this report, 602what is broadband?62why define òbroadbandó?, 62overview of the technical characteristics of broadband, 65speed, 65latency and jitter, 67symmetry between upstream and downstream capacity, 67alwayson, 69connectivity sharing and home networks, 71addressability, 74broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.xivcontentscontrols on applications and content, 75implications of network design/architecture, 77approaches to defining broadband, 783broadband applications and content82broadband applications: promise and reality, 82classes of broadband applications, 83faster general internet access and general internetapplications, 84browsing and related activities, 84messaging, 85fast file downloading, 85games, 87speed and responsetimesensitive internetapplications, 87application rental, 87network storage, 88static image delivery, 88audio, 89audio delivery, 89compressionquality tradeoffs, 91specific audio applications, 93video, 98the mechanics of video delivery, 102telepresence, 103telemetry, 105new kinds of publishing, 105peertopeer applications, 105òlocal interestó content, including video, 107home content hosting, 107push content, 109multiplexing applications demand in homes, 109internet appliances, 111distributed work and education, 112òtelewebbing,ó 113communities and community networks, 113social factors and impacts of broadband, 114availability of content, 114broadband impacts, 116broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.contentsxv4technology options and economic factors120local access technologies in context, 120essential features of the local access technology options, 121wireline options, 122hybrid fiber coax, 123digital subscriber line, 125advanced wireline offeringsñfiber opticsin the loop, 129powerline, 135wireline roadmap, 136wireless options, 139fixed terrestrial wireless, 139mobile wireless, 142satellite, 144wireless roadmap, 146the diverse technology landscape, 148layering and unbundling, 149economics of infrastructure investment, 152understanding costs, 152takerate tyranny, 153paying for broadband, 155focus on the consumer, 156the pace of investment, 158investment, risk taking, and timelines, 160uncertain investment prospects in the privatesector, 161investment options for the public sector, 162mooreõs law and broadband, 163economics of scaling up capacity: congestion andtraffic management, 1635broadband policy and regulation167the context for broadband policy, 167policy implications of technological change, 171regulation in the face of rapid change, 171asymmetrical regulation and achieving technologyneutrality, 174competition, 177unbundling and resale mandates, 180when unbundling works, 182implications for investments by incumbents, 184facilitiesbased competition, 184structural separation, 185broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.xvicontentshow much competition is enough?, 186assessing the degree of competition, 188open access and evolving complements to facilitiesbasedcompetition, 189access issues in multidwelling units, 192access to poles, conduit, and rightsofway, 193expanding access and universal service policies, 194rationales for intervention, 194implicit transfer mechanisms used for universaltelephone service, 197other mechanisms for increasing access to broadband, 200loans and grants, 200tax incentives, 202vouchers, 203research to develop technology alternatives, 204looking forward, 205the local role in broadband, 206bibliography216appendixesabroadband technologies245ba brief history of telecommunications regulation296clist of white papers received307dbiographies of committee members309elist of acronyms318broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.1this report examines the technologies, economics, policies, and strategies associated with the broadband challenge (the òfirst mileó or òlastmileó highspeed connectivity problem, depending on oneõs perspective)and makes recommendations aimed at fostering broadbandõs deploymentand use. following roughly a decade of development and experimentation and a recent period of rapid growth, firstgeneration broadband services, using primarily cable modems and digital subscriber line (dsl), areavailable in many markets. this progress is offset by recent business failures and uncertainty about the pace of future investmentñfactors that inpart reflect slow growth in subscriptions for broadband services. today,dialup connections over the public telephone network remain the dominant way homes and small businesses connect to the internet or otheronline services. broadband, though, not only provides higherperformance options for connecting to familiar internet and other online services, but its capacity and òalwaysonó nature also enable new networkbased activities. together, these capabilities promise significant social andeconomic benefits. the computer science and telecommunications boardinitiated this study in an effort to understand the hows and whys ofbroadband deployment and use.the committee on broadband last mile technology found thatbroadband should be defined in a dynamic and multidimensional fashion, and it offers two complementary approaches to characterizing whatconstitutes broadband service: (1) local access link performance shouldnot be the limiting factor in a userõs capability for running todayõs applications, and (2) broadband services should provide sufficient perforbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.2abstractmanceñand wide enough penetration of services reaching that performance levelñto encourage the development of new applications. thesedefinitions reflect the central òchickenandeggó conundrum: an application will not be made available unless a sufficient number of subscribershave broadband connections with performance high enough to supportthe application, yet service providers will not invest in higherperformance broadband until they know that there will be sufficient demandfor the service. residential broadband capabilities today, with speeds typically ranging from several hundred kilobits per second to several megabits per second downstream and several hundreds of kilobits per secondupstream, support familiar applications such as web browsing, email,messaging, interactive games, and audio download and streaming. thenext performance plateau, which is not widely available at present, provides downstream speeds of several tens of megabits per second, thusenabling new applications such as highquality streaming video or rapiddownload of fulllength audiovisual files. with the addition of comparable upstream speeds, computermediated multimedia communicationsñto enable more effective telecommuting and distance education, forexampleñbecome possible. fibertothehome (ftth) would offer thehighest performanceñgigabit speeds both up and downstream. investment in ftth has lagged other options because of costs and uncertaintyabout demand for its capabilities. some investment currently is providingopportunities for experimenting with technology alternatives and applications and for learning about demand. at the same time, a variety ofwireless options provide either costeffective alternatives (especially forremote locations) to wireline or mobility and ubiquity that complementwireline technologies.development, deployment, and adoption will be an ongoing processthat works through several mechanisms: incremental upgrades andreallocation of capacity in existing broadband infrastructure, improvedend equipment that permits faster performance over the existing infrastructure, and installation of new infrastructure. these improvements mayor may not require new technology, but all require investment premisedon market demand and willingness to pay. indeed, many factorsñnotsimply technologyñwill shape the pace and distribution of broadbanddeployment.while broadband is sometimes characterized in terms of a horse racebetween dsl and cable and between the incumbents that use these technologies, the committee believes that the long term will be technologicallydiverse, reflecting geographical and market variation, the maturity of andexperience with different technologies, topography, and the condition ofexisting infrastructure. because local conditions vary, broadbandõs availability will be quite uneven, especially in the earlier stages. the naturebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.abstract3and number of competitors will vary considerably by geographical location: from areas able to attract noñor only oneñincumbent terrestrialprovider (likely an incumbent local exchange carrier or cable operator) toeasiertoserve, higherdemand areas likely to attract one or more facilitiesbased providers in addition to the incumbents. this variability andflux will be troublesome to industry, regulators, and policy makers alike,implying that provider strategy and government intervention will haveto change over time as the market and services evolve.the present policy framework for broadband, which revolves aroundthe telecommunications act of 1996, is problematic and is unsuited inseveral respects to the new era of broadband services. although it doesnot explicitly recommend revision of the act (or comment on contemporary legislative proposals), the committee anticipates such examinationand is cognizant that implementation of some of its recommendationswould require revisions to either legislation or implementing regulation.the committeeõs recommendations, outlined and condensed below (complete versions are presented in the summary and recommendations chapter of this report), are intended as principles to guide broadband policyover the next several years:¥prioritize widespread deployment and defer new regulation in the earlystages. presupposing how broadband services and markets will evolverisks misjudgment regarding outcomes and strategies. wider broadbandavailability (in the context of other recommended measures) will helpstimulate new applications, which will help increase demand, which willin turn make deployment, upgrade, and new market entry more attractive. at the same time, government should enhance its monitoring ofdeployment, investment, use patterns, and market outcomes to provide afirmer foundation for any future action. the familiar goals of universalaccess to important capabilities and consumer satisfaction remain, but theknowledge of how best to achieve them in a broadband world must bedeveloped. there is sufficient time to observe and analyze as deploymentand use unfold and to defer measures that could result in a prematurestall in investment.¥structure regulation to emphasize facilitiesbased competition and encourage new entrants. the policy goal, simply put, should be to increase theextent of competition through facilities ownership (and voluntary business arrangements to open facilities) rather than through longterm reliance on mandated unbundling. it is reasonable to maintain existing rulesfor unbundling existing telephone copper plant facilities. but unbundlingrules should be relaxed in exchange for investment in new facilities thatcan broaden service availability and/or increase performanceñsubject toappropriate mechanisms to address extensions of market power. somebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.4abstractlocales will not see facilitiesbased competition, and competition in someareas will change; both situations present policy challenges. where unbundling is warranted, particularly with respect to new facilities, logicallayer unbundlingñunbundling at a higher servicelevel of communication, as in cable open accessñshould be preferred in the long run tophysical unbundling because it promises technical advantages and administrative ease.¥take active steps to promote deployment and facilitiesbased competition,including at the local level. the degree of competition and prevalence oftechnology options will vary by region, state, and municipality. federalrules should continue to bound the range of outcomes, but in many cases,local decision making based on local conditions and needs is appropriate.various sorts of incentives and local arrangements, detailed in this report,can encourage broadband deployment. while a few communities havealready undertaken broadband initiatives, the majority have not andcould benefit from efforts to enhance local capacity. the committee recommends supporting planning grants for localities to explore options;providing costsharing for field trials, including localgovernmentsponsored initiatives; and establishing a national clearinghouse to raise awareness, provide technical assistance, and disseminate best practices for localand regional efforts to accelerate broadband deployment.¥support research and experimentation. government should supportresearch and experimentation that would foster the emergence of newcompetitors; increase understanding of economic, social, and regulatoryfactors; and spur the development of new content and applications thatwould make broadband more compelling and useful and foster growth indemand and use. many of the conditions evident today reflect currenttechnologies, business models, and policy interventionñall of which aresubject to change. research is valuable for creating new options and lowering costs, and it should be pursued vigorously across both technical andnontechnical arenas.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.5introductionbroadband is a means to multiple, diverse ends encompassing family,work, and society generally. in addition to enabling entertainment andecommerce applications, broadband can enrich the internetõs exploitation as a public space, making electronic government, education, andhealth care applications richer and more compelling and useful, and itcan provide new modalities for communication, notably within communities or families. broadband commands attention because it enables dramatically different patterns of use that offer the potential for significantchanges in lifestyle and business.this report from the computer science and telecommunicationsboardõs committee on broadband last mile technology examines thetechnologies, policies, and strategies associated with broadband local access connectivity (often referred to as the òfirst mileó or òlast mileó problem, depending on oneõs perspective) and makes recommendations aimedat fostering its deployment. the committeeõs findings and recommendations are confined to broadband in the united states and focus largely onbroadband for residences (with some discussion of broadband for smallbusinesses and broader connectivity issues for communities).broadband service to the home depends on highspeed data transmission across local access facilitiesñthe communications links and related hardware that connect the premises and the rest of a telecommunications network, most notably between the home or small business andthe set of interlinked data networks that make up the internet. thesebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.6summary and recommendationsfacilities fall into two categories: (1) existing facilities built by an incumbent telephone or cable company for the purpose of delivering voice orcable tv service and (2) new facilitiesñsuch as fiber optic cable, wireless,or satelliteñconstructed specifically for the purpose of delivering broadband. before broadband, dialup connections over the public telephonenetwork were the dominant way in which homes were connected to theinternet or other online services. the performance of these modem connections has reached a plateau defined by the bandwidth of telephonecircuit switches (more than 50 kilobits per second [kbps] under optimalconditions, but possibly less depending on factors such as line, interiorwiring, and modem quality), and further improvements have requirednew technology approaches.at present, two access technologies that leverage existing infrastructureñdigital subscriber line (dsl) and hybrid fiber coax (hfc; or cablemodem)ñare maturing, as evidenced by wide availability, industry standards, multiple product vendors, volume pricing, and deployment experience; othersñsuch as terrestrial wireless and fibertothehome (ftth)ñare being developed and deployed on a smaller scale. the range oftechnology options captures part of what makes broadband vexingñfiber promises maximum bandwidth; wireless offers pervasiveness, flexibility, and potentially faster deployment; and satellite offers nationwidecoverage (albeit with some gaps and limited total capacity). today, dsland hfc are most prominent, shape consumer experience, and fuel muchof the politics that surrounds broadband. looking forward, as other technologies such as fiber and wireless surmount cost and other deploymentbarriers and become more pervasive in residential broadband, providers,consumers, and policy makers alike will face new issues.the committeeõs work started in late 1999 and was completed in fall2001, a period encompassing significant broadband deployment and bothboom and bust in the telecommunications and internet markets. untilrecently, only universities and large businesses and organizations hadhighspeed internet access, reflecting a favorable economic return on investment in providing service to these customers. in contrast, residencesand small businesses (and smaller offices of larger organizations) havebeen less likely to attract investment. also, many homes are relativelydistant from neighboring homes or are connected today by hardtoupgrade telecommunications infrastructure, and some are in remote locationsñall factors that entail higher perpremises costs and inhibit deployment.following roughly a decade of development and experimentation,residential (and small business) broadband services have been availablein selected markets for several years and more recently have becomemassmarket. cable operators, incumbent local exchange carriers (ilecs),broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations7and competitive local exchange carriers offering data services (dataclecs) have been the largest players, complemented by overbuilders(using hfc, wireless, or fiber) and satellitebased providers. the pastcouple of years have been a period of dramatic growth in broadbanddeploymentñby summer 2001, more than 8 percent of u.s. householdswere subscribers to broadband service (only a comparative handful hadservice in 1999). mid2001 data also indicate that broadbandcapable cablesystems reach roughly 60 million households and that a substantial fraction of telephone company central offices support dsl (dsl availabilityfor individual customers is subject to linetoline variability). at the sametime, many communities, especially smaller or more remote ones, lackbroadband today, and some households in communities with generalavailability cannot obtain service owing to particular conditions (e.g., telephone line condition or length, or residence in a multidwelling unit without broadband).the study period has also been marked by deployment difficulties.there have been numerous reports of poor customer service in terms ofboth installation delays and poor operational reliability, with charges andcountercharges as to whether the data clecs or incumbents were responsible for reported difficulties and delays in establishing dsl service.the 2001 wave of clec bankruptcies and shutdowns called into questionthe unbundling strategy contemplated in the telecommunications act of1996.if the committee had completed its work in mid2000, it might wellhave done so with a rosier assessment of prospects for investment, thestrength of broadband overbuilders and competitive local exchange carriers, and so forth. in formulating its recommendations, the committee wasmindful of how much the situation had changed just during the course ofits work and of how these changes underscore the perils of basing policyon shortterm trends (either positive or negative).broadband deployment has been the subject of scrutiny by legislators, regulators, communities, the computing industry, and the public atlarge, and a number of potential barriers have been noted by these groups.political attention has escalated along with that devoted to the internet;like the internet, broadband is linked to social and economic benefits.with sustained improvements in the internetõs core and in network connectivity within many businesses and other organizations, the last mile toresidences and small enterprises has come to be viewed by some as acritical bottleneck. key questions include these:¥what is broadband?¥why do people need it?¥how much demand is there for broadband?broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.8summary and recommendations¥how important and urgent is deployment of broadband?¥what is the likely shape of broadband deployment in the comingyears?¥is the pace of deployment reasonable and adequate, or are therefailures that necessitate intervention?¥how will broadband deployment be paid for?¥how might the present policy regime for broadband be made moreeffective?the multifaceted and dynamic future anticipated by the committee inthe findings and recommendations below will be troublesome to regulators and policy makers. this future implies that different forms of intervention will be required in different geographical regions; that intervention should change over time as players enter and leave the market and asthe working definition of broadband changes (which could change thenumber of real options); and that problems will arise, given the typicalslow pace of the policymaking process. finally, the ebb and flow of competition will inevitably lead to claims and recriminations of predatorypricing, obstructionist incumbents, partial regulation, and so on. the remainder of this summary presents the committeeõs key findings and recommendations with respect to these vexing questions.while implementing some of the committeeõs recommendationswould require changes to the telecommunications act of 1996, manywould not. viewing the actõs provisions as only one of a number of factorsshaping broadband deployment, the committee believes that revision ofthe act or associated regulation is not critical at present, but that changesin light of the realities of broadband will become increasingly importantover time. at the same time, the committee has not shied away frommaking recommendations simply because they would be inconsistentwith the provisions of the present act. further, the committee anticipatesthat in view of the public spotlight enjoyed by broadband, there will bemultiple efforts to change the act itself as well as to undertake moreevolutionary changes within the actõs framework. rather than commenton the merits of any particular pending legislation (the committee is explicitly not doing this), the committee offers its recommendations asguidelines, as broadband policy evolves over the next several years.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations9findingsfinding 1. broadband is a convergent platform capable ofsupporting a multitude of applications and services.although the term òbroadbandó can be used to refer to other services,such as digital television, that are not necessarily carried using internettechnology, the main focus of this reportñand the issue of most interestto service providers, consumers, and policy makers alikeñis broadbandinternet connectivity. although broadband is often associated with particular facilities or transmission technologies used for its implementation,it is a more general concept. with convergence, everythingñvideo, audio, text, and so forthñhas become a digital stream that can be transported across the internet. taken together with the internetõs layereddesign, this phenomenon makes broadband internet a platform that iscapable of supporting many different types of applicationsñthe familiaremail, world wide web, games, audio, and video; new applications notyet in widespread use; and applications yet to be invented. the internetõsdesign also permits broadband internet to be run over many differenttypes of communications linksñdsl, hfc, fiber, wireless, and so forth.at present, however, such services as television and telephony are different products employing distinct facilities.the convergent nature of broadband will permit, if not foster, industry convergence and consolidation across traditional industry linesñcabletelevision and telephone service are viewed today as separate markets,but the distinction will make less sense over time. convergence is a potential enabler of competition: with multiple broadband providers that compete in terms of performance and services, users can switch providers tofind the most attractive combination of price and performance. a stovepiped policy environmentñin which different rules apply to broadbandservices depending on whether they are provided using cable, publictelephone network, wireless, or other technologiesñwill come under increasing pressure. technology trends suggest another mismatch betweenpresent policy and the nature of broadband services. to obtain greaterperformance, access networks will likely converge on similar architectures in which fiber reaches close to premises, and highspeed coax, upgraded dsl, or wireless links connect to the premises themselves. another option is for fiber to be run all the way to the premises. in eithercase, treating different òflavorsó of broadband under disparate regulatoryregimes becomes more problematic.while the similarities are more important than the differences, thereis a complicating factor: the capabilities of broadband services based ondifferent access technologies will vary somewhatñemail is possible overbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.10summary and recommendationsalmost any sort of link (though the experience will be better over a fasterlink), while highquality video streaming demands a high minimumspeed. the higher ultimate capacity and lower cost associated with providing high downstream capacity mean that the cable operators usinghfc would have an easier time entering the telephone market than ilecswould have delivering highquality video over presentgeneration dsl,and the latency inherent in geosynchronous satellite services makes themless suitable for telephony, videoconferencing, or games that require lowtransmission delays. more generally, access technologies have cost andperformance tradeoffs that vary across different deployment scenarios.finding 2. broadband should be defined in adynamic and multidimensional fashion.policy makers and others have struggled to come up with reasonabledefinitions of broadband (versus narrowband), and many groups have aninterest in such definitions. broadband definitions are important for monitoring progress in deployment at the national, state, or local level. definitions are also an important component of specific policies, such as eligibility for tax credits or compliance of providers with buildout mandates.broadband development, deployment, and adoption should beviewed as an ongoing process that works through several mechanisms:incremental upgrades in the broadband infrastructure, reallocation of existing capacity to broadband, improved end equipment that permits fasterperformance over the existing infrastructure, and installation of new infrastructure. todayõs firstgeneration broadband technology is not theend point in terms of performanceñwhat is considered broadband todaywill not be viewed as broadband in the future, much as 300baud modemsappear inadequate compared with todayõs 56kbps modems. upgradesmay or may not require the development of new technologies, but allrequire investment premised on market demand and willingness to pay.much like dialup, which went through a succession of upgrades until itreached the limits imposed by the capacity of telephone switches, broadband has launched a new cycle of incremental upgrades and opportunities for yet more new infrastructure deployment. unlike dialup, for whichthe carrier and the internet service provider (isp) were distinct and upgrades required only new modems at each end, broadband requires moreextensive upgrades to facilities and terminal equipment.an examination of local access technologies on the horizon, othercomputing and communications capabilities, and potential applicationsmakes apparent several quantitative performance and application clusters. todayõs residential broadband capabilities, which are typified bybroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations11several hundred kilobits per second to several megabits per second downstream and several hundreds of kilobits per second upstream, supportsuch applications as web browsing, email, messaging, games, and audiodownload and streaming. at downstream speeds of several tens of megabits per second, new applications are enabled, including streaming ofhighquality video, download of fulllength (70 to 90minute) audiovisual files in tens of minutes rather than hours, and rapid download ofother large data files. reaching this plateau would enable true televisionðpersonal computing convergence. with comparable upstream speeds,computermediated multimedia communications become possible, including distance education, telecommuting, and so forth. with ftth, anew performance plateau with gigabit speeds both up and downstreamwould be reached; what applications would take full advantage of thiscapacity remains to be seen.this interplay between technology capabilities and application requirements is captured in a more general fashion by the two complementary approaches to defining broadband presented below.¥broadband definition 1. local access link performance should not be thelimiting factor in a userõs capability for running todayõs applications.for example, todayõs typical web browsing is not significantly improved by speeds in excess of 1 megabit per second (mbps) because ofspeedoflight limits on roundtrip travel time across the internet. in otherwords, upgrading a userõs 1mbps link with one 10 times faster would notspeed up the transfer of a typical web page. to take another example: forstreaming media, increasing local access performance significantly abovethe rate at which such content is typically streamed today would notimprove the userõs experience (though, per definition 2, increased capabilities would help spur higherquality streams).¥broadband definition 2. broadband services should provide sufficientperformanceñand wide enough penetration of services reaching that performancelevelñto encourage the development of new applications.capacity improvement and application innovation are tightly coupledin a òchickenandeggó fashion: an application will not be made availableuntil a critical fraction of subscribers receives a high enough level of performance to support it, yet service providers will not deploy higherperformance broadband until there is sufficient demand for it. the performance of a broadband service should, therefore, be good enough andimprove sufficiently to facilitate this cycle and not impede it. definition 2broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.12summary and recommendationsalso implies a broadband penetration threshold effect: enough users musthave a higherperformance service to create a sufficiently large market toattract application developers.two different notions underlie these definitions. under definition 1,the presumption is that existing applications and capabilities of the rest ofthe network will be unleashed by improvements in the local access segment. the presumption of definition 2 is that application innovation willmaterialize if performance constraints are eased. the implications of definition 2 are familiar todayñcurrent broadband service offerings do notprovide high enough performance to support applications such as highquality video, while investment in higher performance awaits demonstration of demand and willingness to pay. the parties demanding improvedperformance include, along with segments of the public, applications developers and content suppliers that see the potential for new markets thatthey might serve (but for the availability of more bandwidth) and policymakers who project potential social and economic benefits that wouldresult from deployment of higherperformance service.while bandwidth is the most significant performance parameter interms of enabling new applications, others are also important. òalwaysonóña characteristic of almost all broadband services todayñis important to enabling certain types of applications. it changes the way in whichpeople experience broadband as a service. symmetry, which refers to therelative down and upstream bandwidths, also has implications for thetypes of applications that are supported. some applications, such as webbrowsing, make modest demands on the upstream channel as they require receipt of much less data than they transmit, while others, such asvideoconferencing, require more symmetric bandwidth. delay affects theperformance of timesensitive applications, notably, applications such astelephony and online games that involve realtime interactions withpeople.finding 3. demand for broadband is evident.in the united states, some form of broadband is reportedly now available to more than half of u.s. households, and subscription rates grewrapidly during the period from 1999 to 2001. penetration has been muchhigher than the average in markets where broadband has been availablefor several years. for example, in portland, maine, an early test market fortime warner cable, about onequarter of households are cable modemsubscribersña mass market that illustrates the appeal of broadband wellbeyond a handful of early adopters. similarly, in the current worldwideleader, korea, where favorable conditions have already made broadbandavailable to much of the population, broadband subscription rates arebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations13reported to be even higher: more than onequarter of households. in theunited states, numerous anecdotal reports of frustration about delays inobtaining broadband service, reliability problems, and nonavailability allsupport a view of a rising tide of demand and use (as well as problems).these developments indicate that broadband access is valued by a broadbase of internet users, not just a small group of technology lovers, andthat broadband is viewed as an important communications service. atpresent, it is difficult to forecast what the ultimate total òtakerateó willbe, though the 1990s penetration of personal computers (pcs) and internetservice to roughly half of u.s. households suggests growth at least up tothis level.notably, todayõs demand level has been based mainly on a limited setof applications (email, web browsing, file sharing, and limited audio andvideo streaming). indeed, there is a significant gap between the capabilities of current broadband services and some of the cuttingedge applications that have been touted but are not generally available to the public.continued growth in demand for higherspeed services can be foreseenbased on applications being used or tested by early adopters in enterpriseand campus networks, experimental initiatives in both industry and academia, and the possibilities afforded by increasingly cheap home networks and specialized consumer electronics. with new applications,wider penetration, and broadbandõs use as a convergent platform formultimedia content delivery, much wider demand and use can occur.finding 4. deployment as a national and local imperativetoday, broadband is for the most part an adjunct to home pc use anda means of faster web browsing, and narrowband alternatives providesome measure of access to commonly used content and services. thus,one cannot say with confidence today that broadband access in the homeis critical to being a functioning member of society. but in light of robustdemand and the likelihood that with growing use, new content and applications will make use of broadband capabilities, it is reasonable to projectthat broadband will take on increasing socioeconomic importance in thefuture.there are several principal arguments for taking steps to foster broadband deployment:¥spillover benefits. because broadband can support many differenttypes of applications and services, its full potential is unlikely to be apparent from scrutiny of any one category. when one looks at a promisingindividual application today, such as telework, it is easy to see that whatexistsñin terms of capabilities, use, or benefitsñfalls short of what somebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.14summary and recommendationshave forecast. but what broadband promises, because of its capacity andgeneralpurpose nature, is the chance to try multiple applications of different types and to provide various mixes that can be valuable to differentusers. the economic and social benefits in the aggregate will, therefore,exceed those of one application, giving rise to spillover benefits not readilycaptured by any one stakeholder. for example, broadband deployed formass entertainment can also carry noncommercial content. to the extentthat broadband providers themselves are not able to fully capture thebenefits of investment in performance enhancements, a broader societalinterest in promoting broadband performance improvements arises fromthese spillover benefits. the willingness of broadband providers to investwill be less than that implied by the broader societal interest arising fromthese spillover effects.¥the link between performance and applications innovation and ties toother hightechnology sectors. if broadband is to support new, rich multimedia applications, the gap between computing and deployed last mile communications performance will have to be closed. in the short term, thiswould translate into upgrading from todayõs hundreds of kilobits persecond to tens of megabits per secondñwhich all of the present generation of wireline broadband technologies can support, with appropriateinvestment (shorter loop lengths in the case of dsl and smaller clustersizes and/or more spectrum dedicated to broadband in the case of hfc),and which is well within the capabilities of ftth. although the performance of broadband services today nearly always exceeds that availablethrough dialup access, the firstgeneration systems frequently provideonly modest improvements in speed over older technology, and sustainedupgrades would be needed to satisfy both broadband definitions 1 and 2.¥perpassing costs of initial investment. some infrastructure costs mustbe borne regardless of how many customers in a given area actually subscribe to a service. because of the major, even dominant, role of theseperpassing costs for wireline infrastructure, investment becomes, in essence, a decision contingent on a finding of collective demand. for wireless, the penalty can be somewhat but not fully offset via a strategywhereby the cluster size served by a common feed is decreased as rates ofsubscription and demand increase. (a similar principle also applies towireline technologies that permit such clustering, such as hfc, but withless impact on the perpassing costs than is the case for wireless.) also,early adopters will not be able to obtain broadband service until a serviceprovider decides to make an investment deemed capable of attracting abroad subscriber base. as a service provided over a network, broadbandstands in marked contrast with computers, which individual consumerscan purchase as the need arises, and which providers produce for a marbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations15ket not tied to a geographic area. similarly, an individual can upgrade to ahigherperformance computer to meet individual demand, whereas broadband services will tend to have capabilities aimed at the average user.the committee took note of the fact that other countries, recognizingthese arguments and the potential societal importance of broadband, haveopted for more active strategies than those of present u.s. policy or thosethat the committeeõs recommendations below would contemplate, especially at the national level. these national strategies in other countries donot match the u.s. context, in terms of political system, the historicalprivate sector role in telecommunications, geographic diversity and population dispersion, or the nature of the existing telecommunications infrastructure. that is not to say that the goals and means of these strategiesare not appropriate in their own contexts.finding 5. many factors pace deployment.there is a sense in some quarters that something is òbrokenó withrespect to broadband rollout. there are several areas of frustration: concerns over an insufficient rate of penetration of some form of broadband;associated concerns that some areas will end up being left out; concernsthat the process of upgrading broadband service could stall, leaving consumers with only the performance offered by firstgeneration technology;concerns about business failures leaving customers with no broadbandalternative; and concerns that the quality of what is being deployed willbe inadequate in terms of performance, reliability, or customer service.given the realities of the situation, what is reasonable to expect withrespect to deployment?finding 5.1. broadband deployment will not occur overnight.the rapid evolution of some aspects of the internet can lead observersto think that if something does not happen within 18 months, it will nothappen. but the phenomena associated with deployment cycles measuredin months have generally been in the noncapitalintensive software arena(even here, real change may lag perception), in a sector unconstrained byregulatory uncertainty. in contrast, even with a conservative estimate of$1,000 as the average cost of wiring an individual residence, the total costof building new broadband infrastructureñsuch as rewiring to provideftth to all of the roughly 100 million u.s. householdsñwould be $100billion. a major portion of this figure is in construction costs that are notamenable to dramatic cost reductions. even for cable and dsl, wheredelivering broadband is a matter of upgrading existing infrastructure,broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.16summary and recommendationseconomics constrain the pace of deployment. some broadband deployment will be accomplished as part of the conventional replacement andupgrade cycles associated with telephone and cable systems, but providing broadband also requires additional investment in infrastructure upgrades and broadbandspecific equipment. in either new builds or incremental improvements, an accelerated pace of deployment and installationwill be associated with an economic opportunity cost.the bottom line is that broadband deployment and upgrading aregated by a complex policy and economic context, not justñor even mainlyñby technology. furthermore, it is early in the diffusion process, and toosoon to judge the final outcome. thus, todayõs frustrations do not necessarily justify heavyhanded intervention.finding 5.2. the investment rate depends critically on theperspective and time horizon of the wouldbe investor.for an owner of existing facilitiesñthe incumbent local exchange carriers and cable multiple system operatorsñrealistic investment is incremental, builds on the installed base, and must provide return on a relatively short timescale. an incremental strategy also reflects the view thatthere is not sufficient demand for the added bandwidth of allfiber replacement to justify its greater capital costs compared with those for anupgrade of existing plant.once a provider has a broadbandcapable system, that provider willspend on upgrades only enough to continue to attract subscribers andretain existing customers by providing a sufficiently valuable service. anincumbent will also naturally weigh the benefits of investment in newservices against the costs of cannibalizing from existing ones. for example, an ilecõs incentive to invest in broadband upgrades may be diminished by the prospect that the new technology may be used to provideservices that compete with the ilecõs existing voice and data services.viewing an incumbentõs incentives to invest in upgrades from the perspective of the two broadband definitions provided above, it may be hardfor the incumbent to justify spending so that the local access link is not theperformance bottleneck, or to be in front of the demand so as to stimulatenew applications. facilitiesbased competition, and associated pressuresto attract and retain customers, could help propel performance upgrades.two types of nonincumbent investor have also entered the broadband market, tapping into venture capital that seeks significant returnsñand generally seeks a faster investment pace. one is the competitive localexchange carrier (clec), which obtains access to incumbent local exchange carrier facilities (central office colocation space and the lines running from there to each subscriber) to provide broadband using dsl. thebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations17other is the overbuilder, which enters a market by building its own, newfacilities (most commonly, hfc for residential subscribers, but also terrestrial wireless or fiber). companies may also combine these strategies.satellite broadband providers in essence overbuild the entire country (orregions thereof through spot beams), although with the capacity to serveonly a fraction of the total number of households, and with a cost structure different from that of terrestrial providers. the drying up of internetrelated venture capital that occurred in 20002001ñand the associatedfailure of several clecsñsignals difficulties in sustaining deploymentefforts.in addition to providing financial incentives for private sector investment, the public sector can complement and stimulate private sector efforts by making longterm investments in infrastructure that ease marketentry and foster competition among broadband providers. such investment is most likely to occur at the state, regional, or local level, althoughfederal support can play an important role. but decision making for suchinvestments is not a simple matter, and, if present trends are any indication, such investments will be confined to those locales that project thegreatest returns from accelerated access to broadband, possess a greaterinclination for a public sector role in entrepreneurship, and are bestequipped to navigate a complex set of choices.finding 6. the shape of broadband deploymentwhile the longterm outcome of broadband deployment is certainlynot clear, the characteristics of the technologies and related economicfactors do permit the overall shape of deployment to be predicted withsome confidence in the short term.finding 6.1. the broadband vision is rapidly evolvingand is linked to the internet and computing.broadband is related to several classes of telecommunications servicesñsome stable (telephony), some somewhat stable (entertainmenttelevision), and one that is evolving rapidly (the internet and associateddevelopments in computing, embedded information technology, andwireless communications). telephony and television exist in useful formstoday without the need for a new generation of access technology, whichsuggests that the real driver of the broadband vision is the internet andthe associated computing milieu. the future form of the internet itself isquite uncertain, with the current market downturn injecting possible uncertainty into the overall cycle of investment and the perception of overallvalue and utility, which suggests a need for caution when making predictions. broadbandõs linkage to the internet suggests that broadband willbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.18summary and recommendationschange more rapidlyñand less predictablyñthan what was experiencedas telephony and television developed.finding 6.2. current trends appear to be able to sustaindeployment over the next several years, but beyond that pointthe outcome is less evident.substantial deployment of broadband has already taken place, andboth cable operators and ilecs appear to have a commitment to continuealong this path (though the pace may be affected by the investment climate, consumer demand, and competitive forces). significant cost reductions in equipment as mature broadband technologies have reached themass market are another positive indicator. these factors suggest thatinfrastructure and business may be robust enough to permit widespreaddeployment and sustained performance improvements. however, penetration may fall short of universal access, investment in additional facilities may or may not occur, and investment in performance improvementsmay stall.finding 6.3. broadband is not a horse race among technologies.while popular accounts tend to focus on which technology or playersare òaheadó in broadband deployment, broadband is not a horse raceamong technologies, with an eventual winner. the longterm outcomewill be diversity in technology options, for several reasons:¥location matters. the united states is very heterogeneous in manydimensionsñdensity and dispersion of population, demographics, topography, and condition and age of infrastructureñand it is not reasonableto expect òone size to fit all.ó technology diversity promotes greater ubiquity of service, as cable systems fill in where dsl cannot reach today, forexample.¥continuing incremental investment in existing infrastructure. becauseof investor expectations for shortterm return on investment, incumbentswill continue to make use of existing equipment and plant and the incumbentsõ deployment will be based on incremental upgrades.¥continued exploitation of technology skills. companies possessing particular expertise will exploit opportunities where these skills give them anadvantage. for example, designing, launching, and operating a satellitesystem all require knowhow very different from that required to upgrade a cable or telephone system.¥varying levels of technology maturity. before widescale deployment,technologies must undergo an extensive development process to reducethe costs of components, installation, and management. more mature techbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations19nologies will see wider deployment at the same time that less maturetechnologies are being developed in test markets.looking forward, the following trends are apparent for the varioustechnology options:cable and dsl. incremental investment building on existing technologybases will continue, together with some investment in new facilities whenthe right conditions exist. particularly in denser urban and suburban areas, wireline broadbandñhfc and dslñis being utilized successfully,albeit with some growing pains. the incumbents (both ilecs and cablesystem operators) have considerable advantage, because wireline technologies have in common that the labor of installing the line is a significant cost component. since there is no obvious way to decrease these costsdramatically, options that require investment in new wireline infrastructure are at a disadvantage. also favoring the incumbents are their existingcustomer base and other revenue sources. there have, nonetheless, beenefforts in more attractive markets to overbuild the incumbents to permitnew players to enter the broadband (and associated cable tv or telephone) markets.fibertothehome. given its potentially enormous capacity, format versatility, and long lifetime, ftth is a logical technology end point (complemented by wireless where mobility is desired). already, fiber is beingdriven closer to user premises as part of routine improvements to thepublic telephone network, cable systems, and wireless basestation feeds,and the technology evolution paths for both dsl and hfc rely on fiberoptic links that reach closer and closer to the premises. for new installations, the total lifecycle costs of a fiberbased infrastructure are, generallyspeaking, lower than those for other wireline alternatives because offiberõs long life and because it lends itself to architectures that have nointermediate electronics (which would require periodic maintenance and/or upgrade) in the path between premises and point of presence. theadvantages of ftth are offset by two cost penalties: (1) instead of leveraging existing wireline plant, a provider incurs the cost of installing newfiber optic cables (and, depending on the architecture, splicing the cable)and (2) at present, the terminating equipment is more expensive, reflecting the cost of the optoelectronics and todayõs lower product volumes.the costs of terminating equipment can be expected to drop as the technology is engineered for mass deployment and production volumes increase. because they ultimately are tied to the cost of labor, fiber installation costs are less susceptible to cost reduction, but there have beenadvances in splicing equipment, and a variety of techniques have beenbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.20summary and recommendationsproposed to reduce fiber installation costs in particular situations (including creative ways of exploiting existing rightsofway).meanwhile, there is considerable scope for incremental gain from allaccess technologies and a great deal of inherent capacity in hfc (becauseof coaxial cableõs very large theoretical bandwidth). also, a gap currentlyexists between the capacity of ftth links and the capacity of typical linksto the internet core, which means that with ftth deployment, the capacity bottleneck is simply pushed upstream (except for applications thatrely only on local bandwidth). pervasive deployment of fiber to the premises thus awaits investor belief that the necessary demand exists, a leapof faith that the demand will emerge once very bandwidthintensive applications take hold, or a longterm investment horizon. ftth will bemore attractive where there is either no existing infrastructure or where aprovider opts to compete with the incumbents by providing a veryhighcapacity alternative. ftth is being used in greenfields developments, insome communitybased initiatives, and by a few overbuilders in smallscale deployments. as a general rule, ftth will be deployed when acombination of economics, demand, and capabilities (compared to alternatives, including the infrastructure already in place) justifies the investment.wireless. wireless technology offers mobility and the most flexible deployment scenarios. in the shorter term, satellite and fixed wireless arebeing used to support market entry by providers that lack wireline assets.fixed wireless may also offer a longerterm residential broadband option,especially in less densely populated areas or areas able to support a largernumber of facilitiesbased competitors, and satellite has an obvious nichein reaching remote areas. to reach the most remote few percent of u.s.households, the high fixed cost of building and launching satellites isoffset by low perpassing costs. while socalled thirdgeneration (3g)wireless will provide more capabilities than present systems do, thethroughput per user falls short of a reasonable definition of broadband.wireless local area networking technology using the ieee 802.11b standard is beginning to emerge as an alternative model for untethered broadband access in public places (using both commercial and noncommercialmodels). looking forward, advances such as robust multicarrier modulation and spacetime processing with antenna arrays will benefit wirelessacross the boardñnot only higherperformance fixed wireless, but alsoenhanced mobile cellular systems, which offer ubiquity and mobility, andwireless local area networks (lans), which provide complementary òlastmetersó access. wireless is expected to continue to lag wireline in bandwidth, but its greater flexibility, anticipated performance improvementsthat would make it ògood enoughó for many applications, and the equipbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations21ment cost reductions that come from reaching massmarket volumes canmake it a longterm competitor.finding 6.4. there will be substantial geographicalvariation in the nature of competition.diversity in technology will be accompanied by diversity in the competitive landscape, with different degrees of ònaturaló competitionñcompetition that is facilitiesbased or that occurs through voluntary businessarrangements with facilities owners. with broadband, local conditionsare very important, and the distribution of broadband availability will bequite uneven, especially in the earlier stages. no matter what regulatoryapproaches are applied (short of policy embracing a single monopolyprovider), all of the following outcomes are likely to occur in one oranother region of the united states:¥type 0ñno terrestrial providers of broadband. this situation is notuncommon today despite significant deployment, but it can be expectedto become less common as the nearubiquitous public telephone and cablenetworks are upgraded to support broadband. there is no region of thelower 48 states that entirely lacks service today, because some form ofsatellitebased broadband is possible wherever the user is able to installan antenna dish with lineofsight view of the satellite (albeit with costand performance inferior to what would be possible with access throughalternative technologies if they were to be available).¥type 1ñone terrestrial facilitiesbased provider in the area (e.g., cable butnot dsl, or vice versa). this common circumstance will diminish to theextent that the incumbent telephone companies and cable operators bothexpand their broadband coverage. it will persist where the market isperceived to be large enough to support the first entrant but not largeenough to attract a second incumbent provider.¥type 2ñtwo terrestrial facilitiesbased providers. this will be a common longterm outcome. the incumbent telephone and cable providerwill both upgrade to support broadband, but no other provider will enterthe market. one or both may choose to support multiple higherlevelservice providers such as internet service providers. alternatively, one ofthe incumbents and an overbuilder (using wireline or wireless technology) could provide broadband service.¥type 3ñone or more facilitiesbased providers that install new infrastructure to compete with the incumbents. this has occurred in limited fashion so far, with companies such as rcn overbuilding with hfc, andsprint and worldcom overbuilding with terrestrial wireless in selectedmarkets. the financial viability of type 3 competitionñand prospects forbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.22summary and recommendationscompetition beyond that offered by the incumbent telephone and cablecompaniesñwill be tested over the next few years.finding 6.5. the vitality of the clec industry is in doubt,but the source of apparent troubles is uncertain.in 2001, the vitality of the data clec industry, which has providedbroadband retail competition in a number of markets, came into doubt.charges and countercharges were made as to whether the clecs or incumbents were responsible for reported difficulties and delays in establishing service, a number of federal communications commission (fcc)proceedings were held on the matter, and fines were assessed againstilecs. the possibility that incumbentdeployed technology (such as fiberfed remote terminals) might complicate or preclude copper loop unbundling added an element of uncertainty. a wave of clec bankruptciesand outright shutdowns disrupted service and left some consumers without any broadband alternative. it is unclear whether the clecsõ apparentwoes were due to the better engineering and operational practices of theincumbents, to unrealistic undercapitalization, intrinsically flawed business models, poor management, anticompetitive practices, failures of theirbusiness partners, or insufficient added value relative to the incumbent,or to some combination of these factors. where this alternative no longerexists, there is less price pressure on ilecs offering broadband and oneless option for access to alternative isps.finding 6.6. unlike the underlying communicationstechnologies, the capabilities of deployed broadbandare not on a mooreõs lawlike curve.unfavorable comparisons are sometimes made between sustained improvements in the performancetoprice ratio of computing and laggingimprovements in the capacity of broadband local access links. from thisperspective, and consistent with broadband definition 1 above, local access links are a bottleneck. the communications technologies themselvesñmost notably, ongoing improvements in fiber optic transmission speedsñhave in fact kept pace with or surpassed improvements in computing.the gap that exists is between deployed access technology and computingtechnology, reflecting economic considerations rather than an inherentmismatch.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations23finding 7. the relationship between broadband and content andapplications businesses is critical and is in flux.todayõs debate over isp access to cable broadband systems puts aspotlight on a more general possibility that is motivated by a range offactorsñthat increased ties between communications technologies andthe content and applications that run over them could result in an internetthat is balkanized (even as the industry consolidates), is less open incharacter, or is less supportive of application and service innovation. pastexperience with contentconduit relationships suggests a range of possible longterm outcomes for broadband. telephony has long followed acommon carrier model in which content and conduit have been cleanlyseparated. cable operators today have considerable control over the content carried by their systems. such contentconduit ties are cited as asource of financial strength; cableunique services helped fuel theindustryõs growth beyond its community antenna television roots. theseties are also associated with business and regulatory complications.with dialup internet access, the isp and phone carrier are separateentities; customers are free to select from among a wide array of isps.internet connectivity is usually understood to mean access to the fullrange of content and applications available via the internet, though thereare isps offering services ranging from full connectivity to delivery ofcomprehensive, proprietary content and services. the availability of services offering full connectivity, together with isp diversity, has been anenabler of experimentation with new applications and services. goingforward, broadband internet service providers have a choice of offeringfull, unrestricted connections to the internet or evolving toward a moredefined package of services (using internet technology). in the early days,when the business side was still developing and the user base was smallerand generally more sophisticated, users expected to be able to do anything with their internet connection, services were geared more towardthese users, and with a few exceptions, the isps were not strongly differentiated in terms of the content or services they provided. when cableoperators started offering broadband, they opted to do so through exclusive isps, more recently evolving to offer a set of isp choices.today, the provider industry is more mature (and more consolidated,especially in broadband), users are not all technologysavvy, and providers are becoming more sophisticated about consumer behavior and abouthow to make money. isps are seeking opportunities for additional revenue streams by bundling additional services, establishing preferred content and services (even restricting access to particular content and services), and defining tiered services. these factors all suggest the rise ofalternatives to traditional internet access that offer a more limited, debroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.24summary and recommendationsfined set of content and services that could change the fundamental nature of the internet as experienced by consumers. while consumers maydiffer in their preference for one type of service or another, it wouldrepresent a significant shift in the communications landscape if they wereto lose the option of full, open internet broadband connectivity. voluntary measuresñand those adopted in order to obtain permission for mergersñhave given cable broadband customers some choice of isp and thusdecreased restrictions on access to internet content. these responses tocritics may address concerns about the potential market power of facilities owners, but their effectiveness remains unproven.recommendationsthe present policy framework for broadband, which revolves aroundthe telecommunications act of 1996, is problematic and is unsuited inseveral respects to the new era of broadband services. the significance ofbroadband data communications was appreciated in general terms bysome of the key players that shaped the act (and is reflected in multiplesections of the act dealing with advanced services), but the central role ofthe internet (and the rapid rise in popularity of applications running overthe internet, such as the world wide web) in the communications landscape was not fully anticipated. framed before the internet was fullycommercial, the telecommunications act of 1996 devotes much of itsattention to the voice telephony market and maintains distinct rules forthe various communications networks (telephone, cable, cellular, broadcasting, and so on). to stimulate competition, the act employs both facilitiesbased competition, in which providers compete headtohead usingtheir own facilities, and unbundling, in which incumbent telephone companies are required to provide network elementsñmost notably, the copper lines that run from the central office to each subscriberñto competitors at regulated prices.recommendation 1. prioritize widespread deployment and defernew regulation in the early stages.the committee is mindful that there is a tension between permittingprivate sector deployment of broadband to proceed without any hindrance from government intervention and societyõs desire to guide theoutcome. decision makers will have to balance the inevitable calls toshape broadband toward some particular end against the ònaturaló trajectory defined by user preferences, private sector investment, and themarket. the committeeõs specific, pragmatic strategic preference is to probroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations25mote broad deployment relatively quickly and to foster facilitiesbasedcompetition.recommendation 1.1. avoid presentday policy making that is basedon presumptions about the final form of broadband markets.some forms of intervention to expand access could deter investmentfrom taking place at all, which suggests prioritizing widespread thoughnot universal deployment over addressing access gaps early on. becausegovernment intervention may affect private sector investment decisions,it should be undertaken with great care in this nascent area in order toavoid unintended consequences. also, resolving the chickenandegg dilemma depends on broadband reaching some critical level of penetrationif new content and applications are to take off. once a mass market isachievedñwhich brings with it prospects of new applications and business opportunitiesñthere is a likelihood that demand and willingness topay will increase, which in turn may attract new players to provide competition, and decrease the need for regulation. also, learning more aboutthe nature of consumer desires and the shape that the technology andassociated markets ònaturallyó take will help inform the policy debate. itis, for example, premature to conclude that facilitiesbased competition isor is not feasible in many locations. as the shape of broadband deployment starts to become clearer, a firmer basis for broadband policy will bein place.recommendation 1.2. complementary to favoring policiesfacilitating rapid deployment over intervention, develop andimplement enhanced monitoring of deployment, investment,and market outcomes and develop metrics to permit independentevaluation and rating of performance.the committee acknowledges that the approach reflected in recommendation 1.1 is different from that of others who advocate increasedearly attention to ensuring access to all or who argue that it is essential toshape the behavior of incumbents (telephone or cable) or to otherwiseregulate the competitive environment early on. there is, indeed, somerisk that if facilitiesbased competition does not materialize, the committeeõs recommendations could lead to a stagnant scenario in which incumbents face little competition and deploy and upgrade broadband servicesslowly. thus, attention should be paid to distribution and performancevariations as well as to overall rates of deployment. it is also essential forregulators to watch for undesirable outcomes that would have longtermconsequencesñmost notably, abuse of market power. monitoring wouldbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.26summary and recommendationsprovide a basis for distinguishing between unrealized concerns and actual provider behavior, and would help inform public debate about theneed for possible regulatory intervention.detailed data on market penetration are hard to gather, inconsistentlydescribed, and often proprietary. likewise, it is difficult to acquire soliddata or assess commercial claims about costs and markets. to monitor theshape of broadband deployment and refine policy responses, government at all levels needs a consistent picture of data on total market penetration, the extent of competition, and other key indicators of futuretrajectories. since national averages tell very little about variation in levelsof local competition, these data must be gathered at a fine grainñevencommunity by communityñand they must be updated on a regular basis.at this point in the deployment of broadband, when the mature formof the market has not emerged, it is more important to watch for signs thatthe market is not serving important policy goals than to predict the finaloutcome now. these concerns suggest the following as key indicators totrack:¥what percent of the population is situated in what sorts of competitivecontextñregions of type 0 through 3? which of these regions are expandingand contracting over time?¥for different applications, is the performance perceived by the consumerimproving or deteriorating? this is a measure of whether, by broadbanddefinition 1, services available are actually broadband. sound metrics ofperformance and means of monitoring their trends would have to bedeveloped and agreed to.¥are new applications that depend on high bandwidth emerging? if theydo not, it would be an indication that by broadband definition 2, theservices being deployed are not broadband.¥how effective are emerging alternatives to formal regulation? open access policies aim to limit the market power of incumbents (both localexchange carriers and cable operators) in providing broadband services,reflecting concerns that facilitiesbased competition may not provide arobust alternative in all circumstances and that incumbentsõ ability toleverage past monopoly status should be bounded. existing unbundlingand resale rules require incumbent local exchange carriers to providewouldbe competitors with access to the local loop, so public attention toopen access has focused mainly on cable system operators. the year 2001saw the development of a potential template for the industry as a whole:conditions on the aoltime warner merger, which were agreed to by thefederal trade commission, were developed in the face of significant pressures to block the merger. ongoing scrutiny of that industry, such as thatto be carried out by the appointed monitor of the aoltime warnerbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations27merger, is needed, to determine if emerging alternatives to formal regulation will prove adequate.¥is subscriber access to certain internet content or services being blockedor impaired (as compared with other content)? the open access issue is onemanifestation of a broader question of the extent to which nondiscriminatory access to internet content and services will continue with a shift tobroadband. impairment of subscriber access in any industry segmentwould be an indication of undesirable consequences arising from verticalintegration of content and broadband communications businesses.recommendation 2. structure regulation to emphasizefacilitiesbased competition and to encourage new entrants.recommendation 2.1. in the long term and in the case ofinvestment in new facilities, policies should favor facilitiesbasedcompetition over mandated unbundling.current regulation of the ilecs contemplates three forms of competitionñ(1) facilitiesbased competition, (2) competition enabled via unbundling of ilec network elements, and (3) competition through resale ofilec services. in facilitiesbased competition, providers rely substantiallyon their own local access facilities rather than on local access facilitiesowned and operated by other providers (a facilitiesbased provider mightmake use of backhaul links from other providers). unbundling, in whichilec network elements are made available to wouldbe competitors atregulated prices, was initiated as part of the 1996 telecommunicationsactõs attempt to stimulate competition in both the local and longdistancemarkets and to reflect the advantages of scale and scope enjoyed by ilecs.for cable operators, the only access requirements have arisen in the context of mergers and acquisitions. current regulation is ambivalent andsometimes ambiguous as to which is the preferred approach.per the taxonomy presented in finding 6.4, the policy goal with respect to competition, simply put, should be to increase the prevalence oftype 3 conditions in place of type 2, shift type 1 conditions to type 2, andso on. increasing the extent of competition through facilities ownership(and voluntary business arrangements to open facilities) rather than relying on regulation that mandates unbundling is important for severalreasons:¥it reduces the need for persistent regulatory intervention. until there areeffectively competitive facilitiesbased alternatives to the incumbent monopolist, full deregulation is very unlikely to come about, and there willbe a continued need to regulate such things as the terms and conditions ofaccess to incumbent unbundled elements.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.28summary and recommendations¥it permits the natural (i.e., competitionshaped) character of broadbandservice and industry structure to be discerned. this helps define an endpointgoal for regulation in those regions where competition is less robust.otherwise, since broadband cannot be precisely defined without learningmuch more about consumer preferences and the shape of the marketwhere consumers have a real choice, regulators could strive toward thewrong outcomes.¥it promotes diversity. facilitiesbased competition better supportsdiversity in both the technology base (which makes broadband moreadaptable to changing user needs and circumstances) and more diversityin types of cost structures (which makes broadband more robust in theface of changing business circumstances).¥it avoids deterring competitors from investing in their own infrastructure. while unbundling is often offered as a steppingstone to facilitiesbased competition by providing a revenue stream to a startup firm, it canalso inhibit facilitiesbased competition by reducing the incentives forcompetitors to build new facilities (or upgrade existing ones).¥it removes a disincentive to new investment by incumbents. to the extent that the unbundling requirements are extended to new network elements deployed by incumbents to offer advanced services, such as fiberconnected remote terminals, it is a disincentive for investment by theincumbent in such enhanced facilities, because the incumbent cannot capture all of the benefits of its investment. in making this observation, thecommittee is not necessarily accepting at face value ilecsõ assertions thattheir investment decisions are driven chiefly by unbundling requirementswhen there are other plausible explanations (such as the benefits of nothaving to face the threat of clec competition or pressures for financialresults). nonetheless, the incentive level is critical, especially if investment is to occur in lowerdensity or poorer areas where the business casemay be less attractive.¥it avoids costs and organizational complications associated with coordination between incumbents and competitors. organizational coordinationproblems arise because the incumbentõs and competitorõs interests are notaligned, a difficulty manifested in delays and confusion in provisioningdsl service. the coordination issues give rise to extended regulatoryproceedings, with the associated delays and expenditure of resources.¥it facilitates technical optimization of total bandwidth. crosstalk amongtelephone lines constrains dsl performance. bit rates and correspondingranges can be improved when transmissions can be coordinated so as tominimize interference. logicallayer unbundling (see below) is anotherway to facilitate this.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations29in its focus on investment in new facilities and the long term, thecommittee distinguishes between how to treat the existing telephone copper plant facilities and new facilities. the case for the present unbundlingof the copper plant rests on the premise that the public should benefitfrom past investment made when the telephone companies enjoyed a(regulated) monopoly position. also, changing present policy would severely disrupt the business plans of todayõs clec industry. thus, it isreasonable to maintain unbundling rules for the present copper plant.it is when looking to the future, to investment in new facilities, thatreconsideration of unbundling is most important. because the objective isto minimize disincentives for new investment, existing unbundling rulesshould be relaxed only where the incumbent makes significant investment to extend service to areas not served by existing infrastructure or infacilities constructed to enable new capabilities. investment for routinemaintenance or minor upgrades should not be sufficient to result in exemption from unbundling requirements. that assessment must also takeinto account the extent to which an incumbentõs control over the existingplant can be leveraged to gain an anticompetitive advantage in offeringbroadband over new facilities.at least in more densely populated, more affluent areas, facilitiesbased competition appears to be possible. that is not to say that sustaining facilitiesbased competition will be easy, and policy should reflect thisreality. if more facilitiesbased entrants in an area are successful, eachprovider will have a lower takerate and increased facilities competitionmay be accompanied by higher prices. but the policy objective of competition is not simply lower prices; the aim is also to increase quality, stimulate investment in upgrades, and provide meaningful consumer choiceñand consumer education about these other factors may be necessary.facilitiesbased competition can be stimulated by reducing barriers toentry. certain forms of accessñsuch as access to rightsofway and (possibly incumbentcontrolled) poles and conduitsñstem from privilegesgranted or property controlled by governments and are not a direct product of the innovative activities of a competitive firm. governments shoulddevote increasing attention to this type of access so as to reduce obstaclesto new facilitiesbased entrants.recommendation 2.2. favor alternatives to physical unbundling.in cases where facilitiesbased competition is found to be insufficient,the most common regulatory alternative is some form of mandated unbundling. an example is the currently debated opening up of cable systems to unaffiliated isps. when policy objectives call for the opening upbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.30summary and recommendationsof incumbentsõ facilities, this goal can be achieved in several ways, eitherat a low level, by unbundling the physical links of the provider, or byunbundling some higherlevel service. in physicallayer unbundling, acompetitor to the incumbent gains direct access to the electronic signalson the wire (or light on a fiber) running from the subscriber to a centraloffice or remote terminal; can adopt whatever transmission scheme itchooses to; and is free to compete on speed, quality, and other transmission characteristics. however, the ultimate performance and reach of thephysical links may be impaired by such lowlevel sharing. options forenhancing dsl, such as coordinated assignment of copper pairs and coordination of transmitted signals among pairs, cannot be implemented ifcompetitors are free to implement their own technology. similarly, lowlevel unbundling of cable, for example, allocation of different frequencybands to different providers, raises the risk of interference among signalsand overall loss of quality and operational stability. no individual purchaser of unbundled access has an incentive to internalize the interferenceproblems its traffic causes for others.logicallayer unbundling exploits the layered way in which broadband services are implemented. it is the basis of todayõs cable open accessinitiatives. higherlayer services concerned with transmitting bits areimplemented on top of protocols concerned with transmitting electricalsignals across the wire, which means that they can be implemented independent of the particulars of the physical layer connection. that is, acompetitor need not control the actual signals running over the wires if itcan implement its service using bit transport capabilities provided by theincumbent. in addition to facilitating measures to address the crosstalkproblem, logicallayer unbundling may be a more practical way of providing unbundling as fiber is pushed deeper into the telephone networkand the termination point shifts from the central office to remote terminals.a principal disadvantage of logicallayer unbundling for the competitor is that the performance characteristics of the link implemented bythe incumbent may restrict the types of services the competitor may offerand limit the competitorõs ability to differentiate itself from the incumbent. nonetheless, in the long term, particularly with respect to new facilities, logicallayer unbundling would provide a better foundation fortechnologyneutral broadband regulation, provided that facilities ownersare not permitted to exercise market power with respect to transport.the current situations of the ilecs and the cable providers differsomewhat. the physical links of the ilecs, specifically the local loopsand subloops, are currently subject to physicallayer unbundling requirements, which has allowed a number of data clecs to enter markets. thebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations31cable debate about open access has, in contrast, been centered at a higherservice level. in the long run, a convergence toward a uniform open access policy based on logicallayer unbundling may be the best outcome.the cable industry claims that it will implement logicallayer unbundlingvoluntarily. if this outcome does not occur, mandated open access maywell be the regulatory response (unless a much more competitive landscape appears). in the case of ilecs, regulators should consider whetherthe goal of robust competition among different services offered by different providers could be better achieved in the long run through logicallayer unbundling rather than physicallayer unbundling, especially as thetelephone plant evolves to make increased use of remote terminals.recommendation 2.3. anticipate that facilitiesbasedcompetition will not occur in all places, and fashionappropriate policies to address these gaps.while their boundaries are difficult to forecast and will likely changeover time, it is reasonable to anticipate areas where there is a single terrestrial provider. these type 1 areas will generally exist where populationdensity is lowest and the perpassing cost burden is highest, making thebusiness case for entry by a second facility owner unattractive. in theseareas, policy makers will face the challenge of how to address a noncompetitive broadband market. questions that must be addressed in fashioning such policy include whether and how to intervene, how long to waitbefore assuming that a rough equilibrium situation of only a single facilitiesbased carrier has been reached, what impact either mandated unbundling or voluntary facilitiessharing has on the competitive landscape,and to what extent satellitedelivered broadband (with less attractive priceor performance) provides sufficient competition to the terrestrial facilityowner.local conditions may also change over timeñespecially early onñand thus the extent of and approach to intervention will have to change.this flexibility will challenge traditional regulatory approaches, whichmove more slowly. consider the most complex case: a competitor withdraws (transforming a type 3 region into a type 2 region, for example). aresult may be a need to increase regulation of the survivor. this outcomewould certainly be characterized by the provider as unfair afterthefactrule changing, but this sort of eventuality must be anticipated. thus providers might face a changing and nonuniform set of business conditionsña situation that, while potentially confusing for providers, reflects therealities of their operating environment.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.32summary and recommendationsrecommendation 2.4. ensure appropriate radio spectrum forbroadband and associated capabilities.wireless is well suited for certain less densely populated regions,offers an additional path for entry by new facilitiesbased competitors,and, if suitably configured, is unique in its support for mobile use. bothlicensed and unlicensed spectrum plays a role in enabling various wireless broadband alternatives as well as local area and mobile capabilitiesthat complement and supplement wireline broadband access. the committee did not examine in detail whether current spectrum allocations aresufficient or appropriate, but notes that spectrum availability is a precondition to any wireless deployment. nor did the committee evaluate themerits of various allocation schemes or the tradeoffs between allocationsfor fixed versus mobile, licensed versus unlicensed, or unshared versusshared uses. efforts to examine spectrum policy to support broadbandand related services (both current and contemplated), such as those beingundertaken by the federal communications commission, should be continued.recommendation 3. reflect the convergent nature of broadbandand target policy at the appropriate layer.the telecommunications act of 1996, which for the most part assumes the continued existence of a number of distinct services that runover distinct communications technologies and separate infrastructure,does not fully reflect the convergent nature of broadband (different communications infrastructures are able to deliver a similar set of servicesusing a common platform, the internet) nor the evolution toward a common technology end point (deep penetration of fiber, complemented byshort runs to the premises).recommendation 3.1. move toward a more coherent,consistent policy framework for broadband.failure to move toward a more coherent, consistent policy frameworkcould lead to policyinduced distortions in technology deployment. forexample, even as several major cable operators have entered into openaccess agreements, the industry has considerably greater control overaccess and content than do the telephone companies, which fall underindustrywide common carrier rules. a more coherent policy would alsobetter accommodate technological innovation beyond todayõs hfc anddsl systems. progress in rationalizing the overall regulatory framework(which would require revision of the telecommunications act of 1996)ñbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations33to address the mismatch between convergent services and stovepipedregulationñwould also help reduce uncertainty and thus could stimulateinvestment. in the process of reconciling policy across technologies (andassociated industries), policy should emphasize broad deployment andfacilitiesbased competition (recommendations 1 and 2) and not simplyapply existing regulations that were designed to deal with circumstancesparticular to individual technologies (or associated business). also, technology convergence notwithstanding, policy should be able to accommodate a diversity of business models as incumbents and entrants alikeexperiment with different business strategies. these realities are generally appreciated by the federal communications commission as well asby the regulated industries themselves; the issue today is how and whenthe regulatory framework should be reformulated.recommendation 3.2. if regulation of a broadbanddeliveredservice is contemplated, it should be done in a service ratherthan a technologycentric fashion.reflecting political or social interests, various communications servicesñsuch as todayõs broadcasting and telephonyñare subject to regulation. it is reasonable to anticipate that services delivered over broadband will be subject to similar scrutiny, and thus it is prudent to identifythe most appropriate means of regulating them. formulation of any future regulation should focus on the service rather than on the particulartransmission technology.flexible servicecentric approaches that tolerate technology diversityare essential, because broadbanddelivered services are subject to fasterchange and greater variationñbecause of the generalpurpose nature ofthe broadband infrastructure over which they runñthan are conventionalservices. for example, if broadband is to be used to provide telephoneservice intended to substitute for conventional telephone service, regulators should focus on the marketing of the service to ensure that the promised reliability and 911 service are in fact delivered, rather than on thetechnical means by which the service is provided (whether over theinternet or otherwise). defining regulated services this way not only encourages convergence by relying on a technologyindependent way ofdescribing the service, but it also tolerates service diversity by permittingdifferent types of services to be defined. one might, for the purposes ofregulation, define two classes of telephone service: (1) a service intendedto substitute for conventional phone service (providing high reliabilityand 911 service) and (2) a less costly service for more discretionary uses.another reason to move toward a servicecentric approach is that thebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.34summary and recommendationsassumptions underlying regulation of services are frequently tied to thecharacteristics of particular technologies. for example, regulation ofbroadcasting has been fashioned in an environment of overtheair channel scarcity, a condition that need not apply to broadbanddelivered services.recommendation 4. take active steps to promote increased oraccelerated deployment, including at the local level.as described above, the economics associated with investment inbroadband suggest that, absent some additional impetus, achieving nationwide broadband deployment may be a protracted process. in at leastsome parts of the countryñtype 0 and 1 regionsñthere may be little or nobroadband deployment or facilitiesbased competition, and interventionmay be required. type 2 areas, in which the telephone and cable incumbents constitute a duopoly, are also places for government at all levels toexplore intervention that would encourage new entrants where the market appears to be capable of supporting more participants. many of theseincentives should be locally based, because there is considerable localdiversity in the conditions for broadband deployment.recommendation 4.1. establish a federal and state policyframework supportive of local initiatives that ease marketentry and foster competition.current broadband policy is largely federal in scope, and it assumes,at least implicitly, a uniform national approach. but the degree of naturalcompetition and prevalence of technology will vary by region, state, andmunicipality, and policy at all levels will have to accommodate this diversity. federal rules should continue to bound the range of outcomesñforexample, by preventing local governments from raising unreasonable barriers to entry or from discriminating in providing access to public facilities, and by preventing a proliferation of inconsistent local rules that cancomplicate and deter investment. but because it is communities themselves that have the most at stake in regard to broadband service, thereare appropriate forms of local decision making, based on local conditionsand needs. particularly at the municipal level, various sorts of incentivesand local arrangements can encourage and even shape the form of broadband deployment that occurs (e.g., localities may target their communications purchases as a way to encourage an entrant).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations35recommendation 4.2. explore public sector initiativesthat foster market entry.initiatives involving public sector actors may provide an alternativeto imposing unbundling requirements on incumbents in order to provideincreased competition in type 0, 1, and 2 circumstances. these initiativesshould be articulated, researched, and evaluated with a focus specificallyon reducing barriers to entering competitors by building or facilitatingenabling infrastructure.a decision to provide a publicly funded broadband serviceñwhichmight be done in an attempt to introduce service where there currently isnoneñcan affect the number of broadband providers in a given area. incases where a market is capable of supporting only one private provider,the introduction of a public network to compete with it could have theeffect of driving the private sector network out of operation. similarly, thecreation of a public network could deter future entry into a market capable of supporting only a very limited total number of players. also,where government bodies enter into exclusive arrangements with a singlecompany, there is the risk of regulatory capture. these factors all arguethat local governments should concentrate on taking steps to encourageand facilitate competition among private sector players, rather than creating new quasimonopolistic entities. options include these:¥fiber condominium arrangements with public participation. a localitydeclares its intention to build out fiber along its streets and invites anyinterested parties to purchase some share of the fibers installed (and possibly installs additional dark fiber for future use).¥customerowned condominium arrangements. customers own links toa suitable aggregation point. this option would most likely take the formof a condominium arrangement in which a group of households wouldcoinvest in new wireline infrastructureñprobably fiberñthat serves aneighborhood or community; this arrangement might be facilitated bylocal governments.¥partnerships with the private sector to install (and possibly maintain)fiber. the town itself, the schools and municipal departments, businessesand other private sector players in the town, the citizens themselves, andany interested broadband providers can sign up.¥municipal investment in wholesale secondmile fiber facilities, or fiberconduit. secondmile fiber facilities provide connectivity to neighborhoodsthat can be shared by competing broadband providers who in turn provide broadband to individual homes and shared conduit that decreaseseach providerõs installation costs. municipal investment in either wouldbe analogous to the investment in streets as an enabler for local combroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.36summary and recommendationsmerceñhere enabling the valueadded flow of bits instead of the flow ofcars and trucks.in each case, the locality provides motivation, coordination, and resources for joint action. it may share in the cost of the common construction and may also prohibit the digging up of the streets again for someperiod after the construction. typically, some provision would also bemade to lease colocation space to service providers at the fiber termination points to facilitate internet interconnection. by avoiding the extracost of uncoordinated overbuildingñkeeping down the perpassing costsñthis approach attempts to provide competition at perpassing costs comparable to those of a single provider. local and regional government orquasigovernmental agencies can also act in effect as anchor tenants thatunderwrite some of the cost of installing infrastructure, reducing the costsfor other government agencies, private sector firms, or even individualcustomers.recommendation 4.3. relax federal, state, and local rulesto ease market entry or to stimulate investment.local governments can also relax rules that deter or preclude overbuilders from entering a market, such as by providing access to rightsofway, forms of relief for opening of facilities to competitive higherlevelservice providers, and so on. local policies that tend to protect the incumbents from facilitiesbased entrants should be strongly discouraged oreven preempted at the state or federal level.various forms of regulatory reliefñsuch as a relaxation of franchisefees or obligationsñcould be granted in return for infrastructure buildoutor upgrade commitments. one option would be to provide relief fromcertain forms of regulation, such as mandated access in exchange forspecified deployments of new or upgraded facilities. another optionwould be to reduce the business risk associated with facilities construction by providing assurances that compensation would be provided forfuture regulatory imposition of unbundling requirements. regulatorsmight also provide a òsafe harboró (exceptions from heavy regulation) forproviders in a type 1 situation if they behave comparably (in terms ofprices and service quality) to providers in a type 3 situation. finally, incases where broadband providers fail, governments at all levels can takesteps to expedite a transfer of assets to ensure continuity of service foraffected customers.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations37recommendation 4.4. provide financial incentives forinvestment in underserved and highcost areas.examples of financial incentives would include tax credits given forbuilding out infrastructure in underserved areas, or incentivesñincluding tax credits and changes in permitting and zoning rulesñgiven toproviders that invest in infrastructure upgrades exceeding specified buildout or performance targets or that make investments in training and support of developers and users. another option would be to provide governmentguaranteed loans for infrastructure upgrades and buildout inhighcost areas.recommendation 5. increase local capacity to promotebroadband deployment.the recommendations above point to a number of specific measuresthat local or regional governments might pursue to promote broadbanddeployment in their communities. these opportunities also represent aconsiderable challenge for many communities that lack experience andknowledge in managing the complex legal, regulatory, and economic issues these options encompass. a few communities have already takensignificant initiative with respect to broadband, but the majority are justnow exploring the options before them. therefore, mechanisms to enhance local capacity can play a critical role. because one of the motivatorsfor broadband is demand for work and businessrelated applications andassociated applications such as continuing education, in some circumstances it will be appropriate to link broadband initiatives with broadereconomic development efforts.recommendation 5.1. support planning grants forlocalities to explore options.because an exploration of the complex set of issues confronting eachcommunity requires expertise, the engagement of various sectors withinthe community, and input from the public at large, federal and stategovernments should support planning grants to communities that demonstrate serious interest in taking steps to advance broadband deployment.recommendation 5.2. provide cost sharing for field trials,including localgovernmentsponsored initiatives.costsharing grants or subsidies for communities that have limitedbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.38summary and recommendationsperformance or no broadband would support experimentation with premarket technologies and alternative organizational models. such trialswould permit governments and private sector firms to obtain more realistic experience with the performance of technology alternatives, help industry move up the learning curve of emerging technologies, test alternative organizational approaches and access models (such as municipallyowned fiber or conduit available to multiple providers), and test demandstimulation strategies (e.g., locally developed content and applications).while there may be municipalities that have existing public utilities capable of embarking on such a program, a more likely mode is throughpartnership with private firms.recommendation 5.3. establish a national clearinghouseto raise awareness, provide technical assistance, anddisseminate best practices for local and regional effortsto accelerate broadband deployment.a mechanism for sharing best practices for local and regional policies,regulation, and planning would help communities that are facing complex decisions. for instance, model regulatory frameworks would illustrate the range of possible outcomes, provide regional and local governments a starting point in negotiating with providers, and help overcomethe knowledge and experience imbalance that local and regional governments may experience. efforts by the national association of telecommunications officers and advisors and the association for communitynetworking are promising first steps. indepth, authoritative informationwill be needed if best practices are to be useful to communities across thecapability spectrum. a national clearinghouse would permit maximalsharing of best practices but would not necessarily supplant state or regional efforts, which may be better positioned to focus on local circumstances and needs.recommendation 6. defer development of a universal service policyfor broadband until the nature of broadband services, pace ofdeployment, distribution of access, andsocial significance become clearer.the telecommunications act of 1996 devotes considerable attentionto measures that continue support for nearuniversal telephone service.existing universal access programs such as the highcost fund support(which, by helping to expand or upgrade rural public telephone networks,can also provide a foundation for dsl deployment, as well as extend orimprove dialup service) and the erate program (which funds internetbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations39access in many schools, libraries, and health care institutions) have helpedto increase broadband access. the 1996 act has instigated efforts to develop policy for expanding broadband access (such as the federalstatejoint board on universal service).a number of the committeeõs recommendations aim to increase thebreadth of deployment. while the committee anticipates demands thatuniversal service programs be extended to residential broadband, its viewis that it would be premature to embark on a comprehensive new universal service program until the overall shape of residential deployment andthe nature of broadband services are better understood. the committeedoes not believe that, at least at present, a social contract analogous to thatdeveloped for telephony would be appropriate for broadband.it is already apparent that broadband is a desirable and useful service, and it is reasonable to presume that it will take on increasing socialimportance in the future. but there is a difference between a serviceõsbeing useful and showing great promise, which has motivated the recommendations in this report aimed at widening deployment, and a serviceõsbeing critical to meaningful participation in society (as telephone servicehas come to be understood). in the early stages of deployment and acceptance, policies aimed at fostering rapid, widespread deployment, complemented by broadband access through schools, libraries, and other publiccenters, are appropriate.further, defining an appropriate universal service policy will be complicated. for voice, the shared understanding of what society should expect from the telephone industry, which became the goal of federal andstate regulators, has been that a more or less uniform telephone serviceshould be available to residential customers at a roughly uniform price.however, broadband is not a uniform service. different users have different needs, and different technologies deliver different variants with different features as well as cost and performance characteristics. also, asthe two definitions for broadband advanced by this committee indicate,as technology and use evolve, what is broadband today will not be considered so in the future. one cannot employ a simple universal definitionfor broadband such as òfaster than 200 kilobits per second.ó the costcould be made uniform only through substantial transfer payments withinthe systemñan approach that was possible in the simple, more staticworld of telephony but that is very hard to carry out in the less welldefined, changing, competitive world of broadband. this suggests thatnatural cost and service variations must be accepted (which must be distinguished from exercise of market power). for instance, satellitebasedservice is capable of reaching essentially all parts of the country. as aresult, there will be relatively few people who will literally be unable toobtain some form of broadband (assuming these services are marketed tobroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.40summary and recommendationsthem). thus, the geographical access divide is much smaller if the requirements are relaxed for what must be the same across regions, and ifsuch tradeoffs as lower reliability (e.g., satellites are susceptible to rainfade), higher latency, lower data rates, or higher upfront and monthlycosts are permitted.recommendation 7. support research and experimentation.recommendation 7.1. support research and development on accesstechnologies, especially targeting the needs of nonincumbent playersand other areas that are not targets of stable, private sector funding.much of current research has reflected the interests of incumbents.research that looks at the needs of nonincumbent overbuilders should bespecifically encouraged. such systems will in all likelihood make use ofless mature technology alternatives. and as overbuilds, they have lowerlevels of subscription (lower takerates) and need to be costengineered toanticipate this outcome. particular research targets include these:¥architectural options and other means of cost reduction in fiber accessnetworks, including new techniques for using coarse wavelengthdivisionmultiplexing and lowcost inhome receivers and/or transmitters.¥enhanced wireless capabilities, including capacity and other enhancements for wireless that provide robust, spectrally efficient, and scalablebroadband wireless access to homes; architectures for synergistic coexistence of various wireless access technologies (fixed, mobile, inhome,ultrashortrange, and so on); technologies for true mobile broadband wireless services beyond 3g; convergence of fixed and mobile internet architectures and protocols; and new informationdelivery paradigms forbroadband mobile internet services.¥technologies that foster the accommodation of multiple competitive service providers over facilities. such open accessready systems might not be anatural research and development target of large incumbent providersbut will be the preferred form for a variety of public sector or publicprivate deployments.¥quality of service for homogeneous and heterogeneous access scenarios inthe local access link and home, including for applications that make intensiveuse of the upstream channel.¥system robustness and reliability, reflecting the increasing importanceof broadband services to individuals and organizations.because the primary objective is to develop technologies that can bepractically implemented by a broadband provider, research and development programs should encompass systems and economic perspectives,broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.summary and recommendations41not just individual technologies or components. doing this sort of research requires overcoming several institutional problems. much of thecomputer science community traditionally has viewed cost reduction asan engineering topic for industry to pursue rather than as a legitimateresearch topic. further, few academic research centers devote attention tosystems engineering issues, which have generally been addressed by incumbents and their equipment suppliers.recommendation 7.2. support research on economic,social, and regulatory factors.with broadband a nascent service, now is an especially opportunetime to study potential social and economic implications and to developan understanding of these factors so as to inform government policy making and industry strategies. areas for further research include these:¥social and economic impacts of broadband connectivity and availability.such understanding will help localities assess the case for local broadband initiatives and help fashion any future broadband universal accessprograms.¥alternative business models and better understanding of consumer behavior and its relationship to currently available and prospective applications and services.¥economic and regulatory barriers that may hinder the nonincumbentfacilities provider. for example, the cost of the first mile is not the onlybarrier to deployment. small neighborhoods (new construction, pocketsof dense development, and so on) may be able to justify the constructionof new facilities. but this construction cannot occur unless there is somelarger network to connect to that serves to aggregate traffic from theseneighborhoods. this is what might be called the òsecondmileó problemñaggregation of traffic to the point where it is economically viable toconnect to the rest of the broadband world.¥improving our understanding of why local access performance has laggedthat in other computing and communications sectors and what strategies mighthelp to close that gap.¥comparing u.s. progress with that in other countries, and evaluatinghow progress abroad relates to national broadband policies and strategies.historically, a substantial fraction of funding for telecommunications economics research has come from industry itself. the increasing politicization of broadband (and telecommunications more broadly) argues forincreased support from less directly interested parties, such as the federalgovernment and foundations.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.42summary and recommendationsrecommendation 7.3. support development of alternativebroadband content and services.more diverse content and applicationsñbeyond mass entertainmentand more commercially oriented contentñcould create new sources ofdemand and help attract individuals and communities to make furtherinvestments in broadband. examples of such content include informationof local interest; enhanced access to government information and services; and materials related to education, health, and culture. not all suchservices require broadband (narrowband may be sufficient, and a way ofreaching a wider audience in the short term), but broadband supportsmuch richer content. traditional means of providing such content, suchas cable public, educational, and government channels or public radioand television broadcasting, do not obviously translate to broadband, sofurther consideration about how to achieve such ends will be required.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.43the broadband challengebroadband, the darling of technosophisticates and an object of interest to a growing number of politicians and government officials, as wellas to the general public, is often misunderstood. the term itself, originating in the characterization of a communications channelõs capacity (incontrast to narrowband), has come to be used as, among other things, amarketerõs label for advanced cable television service, the 21stcenturyincarnation of the early 1990s òinformation superhighway,ó and one element of the next stage in the development of the internet. broadband hasbeen a beacon for investors and a stimulus for entrepreneurs and mainstream businesses, and it has intensified debates about the public interestin information and communications infrastructure. it is as an enhancedmeans of access to the internet that broadband has begun to have realtraction in terms of actual deployment and use, and it is in this sense thatthe term has become commonly understood. years of assertions by technology gurus, business executives, and marketers about the potentialpromise of broadband have given way to a small but rapidly growingu.s. population who are using a first generation of broadband for fasterinternet access from their homes.today, people are asking about when most, if not all, of the population will partake of it. basic questions about who pays for and whobenefits from broadband are being discussed in communities, state andregional government entities, and in the federal communications combroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.44broadbandmission and congress at the national level1ñas well as in trade associations, consumer advocacy and other public interest groups, and by civicorganizations, telecommunications and internet policy scholarship forums, and groups concerned with international economic development.that such a diversity of organizations share a common interest in broadband underscores how much the internet has become accepted as important to the u.s. economy and society, a marked contrast to the early andmid1990s when the federal information infrastructure task force workedhard to proselytize the internet and related services.2 various factionspoint to broadband as a compelling reason for shifts in telecommunications policy; these include proponents of both more and less governmentintervention. understanding the nature of broadband and what is involved in getting it to more consumers is one of the major goals of thisreport.broadband, in the sense of highcapacity communications channels,is already present throughout much of the communications infrastructure. fiber optic links with very large capacity are already commonplacewithin the networks of telecommunications carriers and are available forlocal access in many locations, albeit at high costs affordable by onlylarger businesses or organizations. the broadband challenge on mostpeopleõs minds today is how to make highercapacity connections available on a more pervasive, affordable basis. in particular, how can one bestextend highspeed connectivity to users in homes, small businesses andsmaller offices of larger organizations, local governments, and so forth?widespread useñmarked by new patterns of information flowñnot onlywould benefit the individuals connected, but also could lead to qualitative changes in how people interact with family, community, and theworkplace, with potentially profound social and economic implications.broadband is viewed by some as a doubleedged sword: networkingcould promote economic development, yet electronic commerce also hasthe potential to displace local businesses. (present and potential applications and impacts are considered in chapter 3 in this report.)extending the reach of broadband generally implies building on theexisting communications infrastructure base, either incrementally orthrough significant investment in new infrastructure. it is an expensive1broadbandrelated bills introduced in the 107th congress include s. 1056 (communitytelecommunications planning act of 2001), h.r. 2139 (rural america broadband deployment act), h.r. 1542 (internet freedom and broadband deployment act of 2001), h.r. 267(broadband internet access act of 2001), s. 150 (broadband deployment act of 2001), ands. 88 (broadband internet access act of 2001).2for the flavor of that period, see cstbõs 1996 report the unpredictable certainty and its1994 report realizing the information future, national academy press, washington, d.c.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.setting the stage45undertaking to deploy broadband to households and to small businessesand other small organizations. each of these is a small economic unit, andmost premises are located a significant distance from a socalled point ofpresenceñwhich is a location where a communications service providercan get economies of scale by aggregating traffic from many customersonto its core, highcapacity links that connect to other parts of the network, including access to the internet. (in the telephone network, thesepoints generally are located at central offices, while in hybrid fiber coaxcable systems, these points are known as head ends.)the link between the point of presence and the customerñusingeither existing communications infrastructure or new facilitiesñis frequently referred to as the òlast mile,ó because it represents a bottleneckthat constrains the benefits the consumer gets from the rest of a network,which is literally at some distance. greater difficulty and cost are associated with dispersed populations, whether they have low density, withhomes being far apart and farther from the local point of presence, or areremote, with an entire community, whatever its density, being many milesfrom the nearest existing aggregation point.perspectives on broadbanda major goal of this report is to examine whether broadband deployment is working and what, if anything, needs fixing. there are very different perspectives on what is happening and how well the process isworking. in the course of its work, the committee on broadband lastmile technology learned about several different views described below,all of which shaped its thinking:¥incumbents (incumbent local exchange carriers [ilecs] and cable systemoperators). deployment of consumer broadband is very costly, and dreamsof òovernightó nationwide deployment are not realistic. there is goodevidence of market demand, and capital is being expended at substantialrates. sustained demand is expected to justify the continued investment.the current round of failures in certain sectors, most notably the troublesof a number of nonincumbent digital subscriber line (dsl) providersñand the associated shift in investment climateñwill slow progress to someextent but do not represent a fundamental problem. private sector investment is healthy. fundamentally, nothing is òbrokenó; it is simply early inthe process.¥consumers. consumers with access to broadband are experiencingmuchimproved internet service compared with what dialup provided.some highend, demanding users may be disappointed with the qualityor predictability of their service. many consumers are being told eitherbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.46broadbandthat broadband is coming òvery soon nowó or that they should not expectservice to be available for a long time; both groups are very unhappy.some consumers find that their neighbors can receive service but theycannot. further, for many the installation process has been a nightmare,and there seems to be no consistent way to navigate these problems.inconsistent coverage and quality leave many concerned about whetherthey will ever be adequately served. already, some consumers viewbroadband as an important service, not a luxury, and believe that moreneeds to be done to ensure that it is available to them.¥observers of market structure. in most locations, the number of broadband providers with their own facilities is not greater than two. this is aninadequate level of competition, giving rise to fears that the longtermoutcome, if not shaped by regulatory intervention now, will fall short ofthe desired competitive market. there is a risk of vertical integration thatleads to restricted access to certain content, seemingly arbitrary restrictions on what consumers are permitted to do with their broadband service, and so on. the basic concern is that we may be making progress withdeployment but advancing toward a very undesirable longterm outcome.some observers cite the substantial and still ongoing struggle to òbreakóincumbent narrowband and video monopolies, and worry that withoutfirm measures to discipline the market now, we will repeat this historywith broadband.¥societal visionaries. there are possible benefits to society, some asyet unvisualized, that would reach beyond the returns anticipated by theprivate sector. opportunities cited include regional economic development, better education, improved health care, and a more informed citizenry. simply depending on private sector investment to fund broadbanddeployment does not reflect the complementary economic and socialpolicy objectives that would justify the commitment of public resources topromote it. in terms of what is actually available at present, the publicpolicy case for universal broadband is weakñthe òbetó is that publicinvestment could help realize social objectives and stimulate demand andprivatesector investment. the circumstances are somewhat like thosethat confronted the builders of the u.s. highway systemñit certainly hadsome obvious foreseeable impacts, but it would have been hard to predictall of the transformations that resulted from public investment. similarly,one might have been able to justify building parts of the highway systemprivately based on constructing toll roads and predicting commercial use,but that would likely have left the country short of a national system. inthe case of broadband, noncommercial investment in content and servicescould start to shift the picture.¥communications technology visionaries. in the long term, two lastmile technologies will dominate: fiber for maximum performance andbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.setting the stage47wireless for coverage and mobility. pervasive deployment of fibertothehome (ftth) and ultimately òfibertothedesktopó are inevitable. fiberõsbenefits include not only enormous potential bandwidth but also longerservice lifetime, upgradability and ability for rapid turnon of new services that any formattransparent medium provides. in addition, unlikewireless, ftth solutions are not constrained by spectrum availability orthe rate at which regulatory processes can make spectrum available.completion of the last mile bottleneck using these two technologies wouldalso provide a remedy to the current economic levelingoff of both thetelecommunications and computer industries.¥computer industry. the ratio of performance to cost of computerscontinues to grow rapidly (a phenomenon closely related to mooreõs law,which says that the number of transistors on an integrated circuit doublesevery 18 months), and communications rates should grow at a similarpace. to keep pace with processor speed, disk size, and so on, communications should become 10 times faster every 5 years. in some situations,such as local area networks or longhaul fiber optic circuits, speed improvements have been consistent with processor improvements. but inthe residential market, it has taken a very long time to surpass dialupspeeds, and there are fears that motivation will be lacking for the serviceproviders to invest in a way that will provide ongoing improvements inspeed. broadband deployment may stall at a speed that is an improvement over dialup but which does not keep pace with what is needed,thus acting as a brake on the computer industry. similarly, operators ofother segments of the network (i.e., backbone internet service providers[isps] and longhaul data carriers) may view the last mile is a potentialbottleneck to growth in their traffic volume and revenue.finally, a note on perspective as it influences terminology. while òlastmileó is the more commonly used term for the local access network, thechallenge is frequently put in terms of building the òfirst mileóñthat is,building out from end users to the network. from this perspective, thelast mile might be thought of as a more supplydriven concept, while firstmile refers to a more usercentered view that emphasizes social and economic benefits at the local level. this report uses these terms interchangeably.a brief history of thecommunications infrastructurethe character and evolution of the existing communications infrastructure provide lessons applicable to todayõs broadband deploymentchallenge. some options for broadband decrease costs by using existinginfrastructure for new purposes. and the business models, policy, andbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.48broadbandregulation developed in the contexts of older communications infrastructure continue to be applied to the new technology. that base has manyfaces: there are multiple communications networks, which have emerged,evolved, and coexisted in largely selfcontained fashion. thus, it is helpful to briefly review the communications past and its evolution over recent decades to a digital infrastructure capable of supporting broadband.traditional circuitswitched telephony is, with the exception of highcapacity lines leased by large customers, a way of providing analognarrowband last mile access. the public telephone network was originally built for voice communications but for some four decades has beenused increasingly for data communications. at its coreñin the channelsthat aggregate communications from many usersñthe telephone networkhas long had large, and growing, bandwidths. at the edges, with theexception of a few customers (chiefly larger organizations) that have beenable to lease highbandwidth private lines, customers have historicallybeen connected through relatively low capacity twisted pair links (this isoften referred to as the òlocal loopó). analog telephony has evolved todigital, with highspeed digital signal transmission commonplacethroughout the public telephone network except in the last mile segment.digital transmission over the last mile has been possible for many yearswith the addition of dialup modems. integrated services digital network (isdn) never took off in the consumer market, and more recently,dsl technologies add equipment at both the customer premises and thecentral office to leverage the existing last mile twisted pair infrastructurein order to provide higher data rates.twoway wireless networks, which originated as consumer servicesto provide analog cellular telephony, complement these other infrastructures. digital transmission also extends into the last mile in the currentgeneration of cellular telephony (although analog cellular networks continue to be used). in recent years, a second generation of digital serviceshas been deployed in more populated areas; these services support verylimited data communications, including access to some internet services.secondgeneration services have grown dramatically in popularity as service prices have dropped and handsets have improved in size and batterylife. socalled thirdgeneration service, which will offer greater bandwidth(though less than the hype would suggest), inspires considerable speculation. even with todayõs generation of technology, various forms of accessto internetlike servicesñmost notably text messenging, but also including access to information and commerceñhave proved popular in countries other than the united states, fueling speculation about their potential in the u.s. market.broadcasting in the form of radio and television has been in place formany decades. while radio and tv have very large bandwidths and maybroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.setting the stage49make use of digital signal transmission, none of these services fits todayõscommon understanding of broadband. this is in part because, unlike themore general purpose, generally internetbased broadband offerings oftoday, they integrate physical and higherlayer functionality. that is, theservices are aimed at particular types of communication or content (e.g.,broadcast radio or television), much as the public telephone network hasbeen designed to support a particular set of voice communications services, and they have emerged, evolved, and coexisted in selfcontainedfashion. some proposed applications are datacentric, however, and mayplay a role complementary to the digital communications services discussed in this report. since the 1980s, direct broadcast satellite has usedsatellite transmission to provide many channels of service over very wideareas, and this technology has been further developed to provide twoway broadband service delivery.cable television networks started out as a way of extending the reachof the broadcast networks. as this analog, oneway infrastructure grew, itbegan to distinguish itself from broadcasting through development of itsown content. in more recent years, cable networks have joined telephonynetworks in the public debates about broadband because recent and ongoing upgrades have added support for twoway communication at comparatively high bandwidths.the widespread use of computers in the homeñmost notably andvisibly today in the form of the generalpurpose personal computer, orpcñhas helped to transform expectations for consumer electronics,which historically focused on entertainment and specific personal services. computers in the home provide a broader base of support for work,education, and other nonentertainment activities within the home. thegeneralpurpose nature of pcs implies both breadth and a multitude ofoptions for future use. the home pc, in turn, has proliferated in partbecause of its potential for connectivity outside the home (today chieflythrough the internet). capability (e.g., storage, processing speed, andsupport for audio and video) in home pcs and the richness of the contentavailable through the internetñand therefore the bandwidth needed toaccess it easilyñhave increased in tandem. these trends have been themost obvious drivers of those seeking broadband in the last mile. forecasts of future demand involve extrapolations from the rapid growth inadoption and speed that has been experienced thus far. an importantcaveat is that these figures derive from the early adopters: home penetration by pcs, which grew relatively quickly in the 1990s, has been levelingoff, and there is reason to believe that the explanation goes beyond simplecosts.in each of these instances, there have been welldefined roles for regulators at all levels of government. in the case of broadcasting, the airbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.50broadbandwaves were declared public property and the federal communicationscommission (fcc) was assigned the task of standardizing frequencybands and interference masks for terrestrial transmission, and it licensedthe use of spectrum segments for particular welldefined services. in telephony, geographical boundaries served as a foundation for defining therespective roles of state and federal regulators.3 cable franchising wasdeemed to be largely a local responsibility.4 in a series of fcc proceedings known as the computer inquiries, computers and related data processing functions were deemed to be an area that would be largely unregulated.from promise to broad deployment:what has changed since the mid1990s?todayõs debates about broadband have their roots in the 1990s, whenthe growth of the internet and increasing experience with conventionalapproaches to data communications triggered broad discussions aboutnational (or global) information infrastructure (nii). these general concepts, as well as development of the first generation of broadband localaccess technologies, set the stage for considerable speculation about abroadband future and invoked a vision of rewiring america to take advantage of these new capabilities. although the 1980s and 1990s saw thedeployment of a series of experimental broadband trials, it was not until1998 that deployment began in earnest.while not all of the original nii visions have not come to pass, whathas been proved since the mid1990s is the impact of the internetñasingle, generalpurpose communications platform capable of delivering awide range of content and applications. but interest in internet access hasnot been enough to resolve other uncertainties, and incremental approaches have been successful. so the wholesale rewiring of america thathad been hoped for by many in the early and mid1990s did not come topass. instead, leveraging of existing wiring has dominated the broadbandscene, accompanied by limited investment in wireless infrastructure andonly spotty investment in new wireline infrastructure deployment.3in broad terms, federal regulators have primary responsibility for longdistance service,while state regulators have primary responsibility for local service. state commissions alsoregulate intrastate longdistance service, and the fcc regulates local telephone companiesinsofar as they provide origination and termination services for longdistance calls. thedivision of responsibilities between state and federal regulators is determined by the communications act of 1934, as amended.4cable franchising authorities are local (municipal or county), except in states where astatewide authority has this power.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.setting the stage51a major change since the mid1990s is the nature of the regulatoryenvironment, occasioned primarily by the telecommunications act of1996. the 1996 act asserts the goal of marketplace competition, but earlyexperience has shown problems in achieving competition and raises questions about how much competition is realistic to expect (see chapters 3and 4 in this report). an important question today is whether the framework established in the act deserves rethinking in light of the subsequentevolution of communications technologies and services.still, despite these changes in the environment, many contemporaryissues related to broadband are, in fact, not new, as demonstrated by areview of three earlier reports by the national research councilõs computer science and telecommunications board (cstb) (see box 1.1). formore than a decade, broadband in the last mile has been understood to bea key to maximizing the benefits of the communications and informationbox 1.1review of past cstb reports related to broadbandthe computer science and telecommunications boardõs (cstbõs) 1994 reportrealizing the information future (itself preceded by a 1988 cstb report, toward anational research network, which validated the concept of nationwide networkingin support of research and higher education) articulated both the potential benefitsfrom broadening access to a flexible and general infrastructure such as the internetand the challenge of spreading those benefits across the economy in a commercialcontext. the 1994 report observed that there were multiple visions for informationinfrastructure, reflecting different values and objectives among stakeholders, and itflagged differing orientations of nonprofit and forprofit sectors, noting a concern thathas continued to grow in some quarters about the role of the entertainment industriesin financing, and therefore in shaping, the evolving infrastructure. the report arguedfor a particular vision: an integrated approach to communications and informationinfrastructure. it pointed to the economics of the last mile as a determinant of howbroadly the benefits would be experienced and as the most important factor inachieving a unified infrastructure.the unpredictable certainty, a cstb report published in 1996, examined howthe vision of an integrated, versatile infrastructure might be implemented. that reportwas more direct in emphasizing the importance of the internet, describing its role infostering progress in different communications and information industries. it examined issues and options confronting multiple industries, characterized the differentbusiness models, and reported on some of the technical and business experimentation that was beginning to accelerate. that report balanced affirmation of the economic challenge presented by the last mile with observations about the potentialwithin the homeñand within sectors such as education and health care that canachieve a certain synergy with homes in leveraging infrastructureñif only more capacity were deployed in the last mile. the report was commissioned with the hopethat it would produce a road map of technology deployment. its message is that toomany factors militate against that happening.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.52broadbandinfrastructure. now, as then, there are multiple technologies and industries that can advance the infrastructure in general and broadband inparticular. optical fiber systems continue to promise the most bandwidth,but at the highest cost and risk. private investment is still viewed as anessential ingredient, but it continues to be inhibited by uncertainty aboutwhat consumers will buy and what business models will succeed. today,as then, it is understood that government action (or inaction) has thepotential to both inhibit and promote investment.broadband deployment trendsfcc data based on reports from carriers show rapid growth in broadband subscriptions by residential and small business customers, with thetotal growing from roughly 1.8 million in december 1999 to 5.2 millionsubscribers in december 2000 (see figure 1.1).5 looking specifically atresidential users, an october 2000 report from the national telecommufigure 1.1 penetration of broadband to residential and small business customers, december 1999 to december 2000. note: (1) òtotaló includes wireless, satellite, and fiber subscribers. (2) adsl = asymmetric digital subscriber line. (3) òother wirelineó includes symmetric dsl services. source: federal communicationscommission (fcc). 2001. highspeed services for internet access: subscribership as ofdecember 31, 2000. industry analysis division, common carrier bureau, fcc,washington, d.c.0123456dec 99mar00jun00oct00jan01subscribers, milliontotal linescoaxial cableadslother wireline june 2000dec 20005interpretation is complicated because the figure includes small business as well as residential customers and because adsl is separated from other forms of dsl, which arelumped under òother wireline.óbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.setting the stage53nications and information administration (ntia) indicates that 4.4 percent of all u.s. households, or 10.7 percent of households with internetaccess, had broadband access as of august 2000.6 market research reportsfrom 2000 provide consistent figures; for example, a november 2000 studyby the cahners instat group found that roughly 9 percent of u.s. households that access the internet use a form of broadband internet access.7reports from mid2001 show further growth: a total of more than 5 million cable modem subscribers and more than 3 million dsl subscribers.8there have, however, been hints that growth has been slowing, at least insome market segments: secondquarter 2001 reports from verizon andat&t broadband show growth below the 2000 rate, and early 2001 alsosaw contraction in the competitive local exchange carrier (clec) business.9 penetration rates can be much higher than the average in marketswhere broadband has been available for several years. for example, inportland, maine, an early test market for timewarner cable, about onequarter of households have become cable modem subscribers.access ratesñthe fraction of households that could subscribe to broadband if they chose toñare substantially higher than current subscriptionrates. a survey of internet users commissioned by the general accounting office indicated that some form of wireline broadband access wasavailable to 52.4 percent of internet usersñ25.4 percent via both cable anddsl, 16.9 percent via cable only, and 10.1 percent via dsl onlyñas ofmay 2000.10 as of mid2001, approximately 60 million homes reportedlyhad cable modem service available, and 52 million homes had dsl service available.11 availability and use of broadband are both correlatedwith town size. nielsen/netratings found that broadband users in the6national telecommunications and information administration (ntia). 2000. fallingthrough the net: toward digital inclusion. ntia, washington, d.c., october. available onlineat <http://www.ntia.doc.gov/ntiahome/digitaldivide/index.html>.7cahners instat group. 2000. broadband consumersñprofiles and strategies, report no.bbwis0005sp. see also òbroadband subscriptions will rise 77% through 2004,ó broadbandweek, available online at <http://www.instat.com/rh/bbw/is0005spstory.htm>.8the national cable & telecommunications association (ncta) estimates 5.5 millionsubscribers as of august 2001. see <http://www.ncta.com>.9at&t broadband reportedly signed up 259,000 customers during the fourth quarter of2000, but only 131,000 during the second quarter of 2001. verizon signed up 90,000 customers in the fourth quarter of 2000 and 120,000 during the second quarter of 2001 (christopherstern, 2000, òbroadband market growth slows,ó washington post, august 28, p. e01).10determining the fraction of homes with dsl service available is more complicated thanin the case of cable. dsl availability depends on central office equipment, line length, andthe characteristics of the specific loop, while availability of cable modem service for themost part depends only on whether the subscriberõs system has been upgraded.11remarks of robert sachs, ncta, june 11, 2001; cablevision blue book, cahners business information, new york, june 2001.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.54broadbandtop 25 local markets (by size) constituted nearly twothirds of all broadband users in the united states.12reaching all americanspast communications infrastructure has been the subject of efforts byindustry and governments to extend benefits to everlarger segments ofthe population. in the case of telephony, the effort has been in the form ofinterventions expressly aimed at reaching all americans regardless oflocation or income level. at the same time that broadband services havereached many, the differences in access to bandwidth among segments ofthe population are becoming pronouncedñincluding bandwidth disparities between work and home or between urban and rural areas.the economic challenges in extending communications services tohouseholds can be seen in the history that led to todayõs baseline. thepenetration of communications technologies takes time, reflecting the timeit takes to build the necessary infrastructure and attract subscribers. asfigure 1.2 shows in displaying the penetration of several communicationstechnologies over the period 19702000, broadband is in the early stagesof this process. for example, broadcast radio and television allows a network service provider to reach wide areas using relatively few transmission facilities (terrestrial or satellite). yet even this kind of infrastructuredoes not reach quite all households and areas, reflecting broadcasterchoices about where and in what to invest (decisions that benefit from therights to a service area associated with a government license). broadcasttelevision reaches many households, though reception is of varying quality. broadcasting has been largely dependent on advertising support,13and expanding access has depended in part on consumer electronics advancing so that radios and television sets became increasingly affordable(in the precabletv era). cable service grew faster. it is available toroughly 97 percent of homes, and 68 percent of households subscribe.14direct broadcast satellite service covers the full continental united states(assuming the household has an unobstructed view of the satellite). itbenefited from attractive economics: high capacity meant that it couldoffer a wide range of content via a subscription model, and once the very12nielsen/netratings. 2001. ònew york local market dominates broadband usage, according to nielsen/netratingsó (press release). nielsen/netratings, new york. may 15.13while public broadcasting has increasingly relied on commercial sponsorship, it stillrelies on tax subsidies, charitable support, and listener donations.14cable tv financial databook, 2000, p. 10, as cited in national cable & telecommunications association, 2001, industry statistics, available online at <http://www.ncta.com/industryoverview/indstat.cfm>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.setting the stage55high fixed cost of the satellites and other transmission facilities was paid,an unlimited number of receivers could be added within the satellitefootprint with minimal incremental investment.it took decades to achieve a reach to over 94 percent of households,15using copper wiring in the last mile, but the technical path to deploymentñpervasive copper wiring backed by a centralized circuit switchñwas, at least in retrospect, straightforward compared with what one observes with broadband today. this nearuniversal reach reflects both coststo network service providers and regulatory programs that promoted socalled universal service and provided financial support to providers tohelp realize that objective (regulatory history is briefly described in chapter 5 in this report). the web of internal support flows that historicallyhave characterized universal service policies has been complex; it evolvedover time, notwithstanding the relatively homogeneous and slowly evolving technology that was the subject of these policies.figure 1.2 penetration of communications technologies, 19702000. note:broadband data include residential and small business subscribers. source:dbs data from yankee group (1999); computer and internet data from ntia(19982000); cable data, 19952000, from nielsen media researchnti (2000); andbroadband data from federal communications commission (2001).01020304050607080901001970198019902000households, milliontelephonecable tvcomputerinternetdbsbroadbandyear15alexander belinfante. 2001. òtelephone penetration by income by stateó (data through2000). industry analysis division, common carrier bureau, federal communications commission. july. available online at <http://www.fcc.gov/bureaus/commoncarrier/reports/fccstatelink/iad/pntris00.pdf>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.56broadbandthe oftcited penetration numbers for different communications services can mask considerable variations in the nature or quality of theservice. both basic and higher tiers of capabilities have arisen in all of thetraditional or conventional communications infrastructures. for example,touchtone and multiparty capability emerged as options in telephony,fm emerged as a òhigherqualityó option compared with am in radio,and color emerged as a òhigherqualityó option compared with blackandwhite tv. cable came along to provide yet another tv option, butover a different infrastructure, with service tiers determined by the natureand amount of the programming content. even dialup internet access issubject to variation. the speed ceiling is limited by the audio bandwidthof the public telephone network, but the floor depends on the quality ofthe individual telephone line. as a practical matter, what has been universally available is a lowestcommondenominator service, although upgrades in provider networks tend to raise that floor over time (for example, touchtone service has become the norm in telephony, and partylines have gone by the wayside).as is seen in many markets, saturationñor at least high and slowlygrowing levels of penetrationñtends to prompt the introduction of enhanced, highervalue and higherpriced offerings in the hopes of increasing provider revenues. sometimes this is in the form of new content orapplications, and at other times it reflects upgrades to the hardware andsoftware of the communications network itself. and, over time, new communications technologies arise that complement the existing ones, offering new or significantly enhanced capabilities. the experiences of the20th century suggest that few new technologies completely replace earlierones, and that whatever substitution occurs does so over a long timescale.as demonstrated by the rapid rise of direct broadcast tv, new technologies can, however, pose a significant challenge to the existing players.complicating an understanding of broadband in the last mile is theevolution of the community context. on the one hand, the community cancompensate in part for a lack of home access by providing access to broadband capabilities in publicly owned spaces (e.g., schools and libraries)and through private organizations (e.g., businesses as employers). on theother hand, the community can stimulate home access demand by generating content and opportunities for civic interactionsñas well as supporting organizational use of the internet, telecommuting and distancelearning, public awareness and education about how to benefit frombroadband, and so on. the lowestcommondenominator level of communications infrastructureñbasic telephone service; television via broadcast, cable, or satellite; and dialup internet accessñmay have been takenfor granted in all but the areas hardest to serve. however, differencesamong communities raise questions about how broadband relates to localbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.setting the stage57economic development for purposes of attracting broader economic opportunities (and a higher quality of life) for citizens (through access inhomes as well as schools, hospitals, and libraries). there is, of course, atension between the wellconnected home as a place from which its residents can access people, information, and economic activity that may bebased physically quite far awayñand that same home as an entity with aspecific physical location, which drives needs to access people, information, and economic activity locally. todayõs islands of broadband havethe potential to intensify other differentiators of home and communityexperience, which has led to the invocation of broadband in the evolvingconsideration of a òdigital divide.ó communities compose the social levelwhere interhome (and intercommunity) differences in access, burden, andbenefit are most apparent, and they are on the frontlines of the integrationof business and nonprofit influences on local activity. although 1990spublic debates over information and communications infrastructure tooka national perspective, communities may play a larger role in movingforward in the new century.access economics and evolving applicationsbecause many costs are perhousepassed rather than percustomerserved and because of economies of scale, individual or isolated consumers cannot induce providers to deploy expensive infrastructure at areasonable price. thus, investors and industries search for clusters ofconsumers who will pay for service before the investors and industrieswill commit to upgrade or deploy infrastructure. one key recurring question is what types of service the customer will pay for and at what levels.both the reach of different services and their enhancement paths reflectdifferences in industry and provider business models. consumers usually pay for the inhome hardware (and software) required to use a communications service, but it varies as to whether they purchase it directlyor lease it from a service provider. cable television reflects consumerwillingness to pay for access to programming content, in contrast to broadcast content, which is for the most part paid for by advertising. consumers who place a telephone call to an internet service provider (isp) paythat provider for internet access service, in addition to what they pay fortelephone service and for the equipment they use, and in addition to whatthey may pay to access certain kinds of content or services through theinternet. what people will pay regularly for information and communication services remains an open question as the choices proliferate. providers of traditional services approach this question with concerns aboutpreserving traditional revenue streams as well as cultivating new ones.providers of new content and services have been struggling to find thebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.58broadbandright mix of advertising and subscription revenue models. related questions arise about who owns and/or manages the technology and contentused in the homeñconsumer or service providerñand what are the lifecycle costs and benefits from the perspective of consumer and provider.thus, debates continue about the role of information and contentñnotably entertainmentñas a stimulus to broadband deployment. the version in the late 1990s and early 2000s has centered on open access: whatdoes it take to ensure that consumers can access information from anysource available through the internet? do preferential arrangements between isps and entertainment programming providers undesirably constrain consumer choice? do such arrangements play an important role instimulating investment? the entertainment industries have proven business models for serving consumers (e.g., broadcasting or cable television),but the questions revolve around how and with what consumers areserved in a more complex world. these issues have brought consumeradvocates and internetrelated public interest groups into the discussionas well.the unpredictable certainty16 had challenged the conventional wisdomof the time that called for a òkiller app,ó a single use of communicationsinfrastructure significant enough in scaleñthat is, generating enough revenue from customersñto bring down the risk in infrastructure investments. the experience of the late 1990s confirmed the absence of a newkiller application, and the experience of the early 2000sñthe recognitionof weak performance or nonviability among many dotcom venturesñshowed that even broad categories of seemingly successful applications(such as various instances of electronic commerce) are not, in isolation,sufficient to drive investment in last mile technologies. only two provenòkiller appsó have emerged. one, email, is the same application thatproved of enduring value in the data networks that preceded the commercial internet. the other, world wide web access, is in fact not really asingle application, but rather a generalpurpose platform supporting awide variety of content and services. while isps have been able to deriveconsiderable revenue (if not always profitability) from providing webaccess, few companies have demonstrated success in deriving substantialrevenue or profits from webdelivered content and services themselves.although popular discussions of broadband tend to focus on pc applications, typically uses of the web, these are only one of many possibleapplications of broadband. the growing trend toward digital storage and16computer science and telecommunications board, national research council. 1996.the unpredictable certainty: information infrastructure through 2000. national academy press,washington, d.c.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.setting the stage59communicationsñone facet of what is frequently termed convergenceñis also stimulating interactions with other kinds of equipment and services. today, as described in chapter 2 in this report, home networks arelargely about connecting pcs together and sharing a link to the outsidebut will increasingly also involve interactions among computers, entertainment devices, and other appliances.recent developments have underscored the political aspects of business and policy decisions related to broadband and have added to already significant regulatory and financial uncertainty, except in instanceswhen court decisions and administrative decision making have been clarifying. the popular debates over open access illustrate how politics canhave influence, but future, especially longterm, policy making relating tobroadband should have more solid analytical foundations. providingthem is one mission of this report.recent developments also raise questions about how future information and communications infrastructures may deviate from the classicinternet as experienced in the mid to late1990s. certain wireless technologies and certain approaches to the isp business provide illustrationsof something that falls short of a òfullserviceó internet. viewed as aòhalffull glass,ó such offerings may expand internet access and otheractivities to new groups of consumers; viewed as a òhalfempty glass,óthey may deprive consumers of choices with various economic and socialbenefits associated with unfettered access to all internet content. the longterm implications are unknown, but it is important to understand thenature of the technical alternatives and their economic and other consequences.in the meantime, the investment climate for major telecommunications infrastructure upgrades is uncertain. company and investor disappointment over some previously touted technologies may be one factor.for example, isdn, which was implemented slowly and was perceivedas having significant shortcomings, has been adopted by only a modestnumber of users. the failure of the muchanticipated iridium satellitetelephone service underscored concerns about the financial risk of boldcommunications infrastructure investments. many of the internet startups that captured attention in the late 1990s tended to leverage more thanadd to the infrastructure. the optical networking startups tended to focus on the core of the network and access for very large business users.startups that focused on local access, primarily dslbased competitorsenabled by regulatory developments, found themselves foundering in20002001, and a more general slowdown in the telecommunications sector was apparent in mid2001. even in the face of this uncertainty, incumbents have invested in infrastructure upgrades to meet what they see ascontinued demand for broadband, and a new player in the form of geobroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.60broadbandsynchronous satellites has introduced a new option for broadband. it isunclear at present to what extent uncertainty in some segments of thebusiness could contribute to an overall slowdown in investment, andcaution should be exercised in projecting longterm prospects for broadband based on the present downturn.scope of this reportthe world of broadband is significantly more complex than that ofthe traditional or conventional communications infrastructures. this report is designed to assess the nature of broadband, its deployment andacceptance, expectations about future deployment, and the potentiallongerterm technical and social implications of broadband access. thechallenging and sometimes necessarily speculative nature of this analysismakes it inherently imperfect. notwithstanding these limitations, an additional goal of this report is to make useful recommendations about howbest to maximize the potential impact and rewards of broadband, generally exploring what will be required to achieve ubiquitous broadbandaccess, in the sense of both expanding the geographical reach of broadband facilities and addressing affordability issues.the focus of this report is on providing access to fixed (i.e., nonmobile)users, but the label òlast mileó also applies to mobile applications, and thereport touches on mobile issues as appropriate. for example, to the extentthat one wishes to support nearseamless communications across fixedand mobile locations, the two are coupled.broadband poses many analytical challenges that go beyond thecomplex technical and economic landscape. one problem is the lack of acommon information base: detailed information is often proprietary; information presented in governmental proceedings is tailored to those proceedings; and systematic detailed data on deployment are hard to comeby. perhaps an even bigger challenge relates to the generally poor trackrecord of both those within industry and outside observers in forecastinginformation technology (it) developments or its economic parameters.finally, basic assumptions will continue to shift. for example, changesunderway include the nature of installation (doityourself/offtheshelfversus professional installer) and the specification of what can be shared(e.g., a shift from built to leased wireless towers or from singleuser toshared conduit or fiber bundles). the future may well see change in licensing requirements (e.g., persite versus persystem licensing of wireless service). finally, the roles of the key playersñconsumer, community,communicationsindustry sectors, and all levels of government from townto federalñcontinue to be in flux.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.setting the stage61notwithstanding these and other challenges, the committee onbroadband last mile technology has attempted to put forth, by consensus, views about the broadband last mile that seek to have value in the 2to 10year time frame. while such a time frame might seem to be dauntingin the face of the rate at which some of the basic technologies are advancing (mooreõs law and its kin), the processes of deployment and acceptance have always proceeded much more slowly, and there seems to beno particular reason to expect a significant change in these time constantsgoing forward.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.62why define òbroadbandó?the term òbroadbandó has become commonplace for describing thefuture of digital communications. it is widely used to refer to a range oftechnologies being offered or developed for the delivery of data communications services. broadband refers most commonly to a new generationof highspeed transmission services aimed at residential and small business users. on its face, the term refers to the substantial bandwidth that ahighspeed connection can provide to a user.1 but is there a welldefinedthreshold that marks the boundary between broadband and narrowbandservices above which one can say a service is broadband? this chapterexplores this and other dimensions of how one defines and characterizesbroadband.there is an obvious lower bound of broadbandñthat is, whether theservice offers higher capacity than dialup access (which is limited to 56kilobits per second [kbps] per phone line) or even isdn service (the basicservice offers two 64kbps channels; experienced service can be at 128kbps or higher), which was introduced with the promise of providinghigherspeed service but was never widely adopted in the u.s. residentialmarket. the speeds offered by broadband local access services, such ascable modem and dsl, generally start well above this threshold (in the1greater communications capacity translates into the ability to deliver a given amount ofinformation faster, so òspeedó is often used synonymously with òcapacityó in this context.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?63hundreds of kilobits per second effective bandwidth or better), but theyspan a wide range of speeds, with consequences for the types of applications they are able to support. a service may, for example, be fast enoughto support rapid web browsing or a few channels of telephony, but tooslow to support even a single tvquality video stream.various groups have struggled to develop appropriate definitions ofbroadband, and these definitions have changed over time. in the 1980sand early 1990s, broadband referred to rates greater than 45 megabits persecond (mbps), and òwidebandó referred to rates between 1.5 and 45mbps. then, circa 1995, broadband commonly referred to anything 1.5mbps and higher in most circles; thus, it was an order of magnitudegreater in capacity than isdn service.2 mandated to report to congresson deployment, the fcc, in its 2000 report on broadband deployment,3defined an òadvanced telecommunications serviceó as one that is at least200 kbps in each direction. the speed and twoway requirement attempted to capture the intent expressed in the telecommunications act of1996ñthat the speeds of what the act terms òadvanced telecommunications servicesó should exceed the rates offered by the technologies available to residential customers at the time of the actõs passage.4 at the timeof the actõs passage, residential customers were generally limited to dialup service (then typically no more than 33.6 kbps). hinting that a definition should also be, at least in part, driven by the requirements of userapplications, the fcc report also observed that the 200kbps threshold itselected is roughly the threshold above which the time it takes to load aweb page becomes comparable to the time it takes to turn the page of abook. but a 200kbps service would be inadequate to support even asingle tvquality video stream to each house, let alone the multiple suchstreams that a family might reasonably use, which would require multiple megabits per second. nor do tvquality video streams represent themost bandwidthdemanding application one could imagine in the future.these definitional questions also arise in an international context asother countries explore policy options concerning broadband. for ex2for a historical view of prospective services, see ieee network special issue on the northcarolina information highway, november/december 8(6), 1994.3federal communications commission. 2000. inquiry concerning the deployment of advanced telecommunications capability to all americans in a reasonable and timely fashion, andpossible steps to accelerate such deployment pursuant to section 706 of the telecommunicationsact of 1996 (second 706 report). cc docket no. 98146, second report, fcc 0290 (rel.august 21). available online at <http://www.fcc.gov/bureaus/commoncarrier/orders/2000/fcc00290.pdf>.4the fcc report defines a broader class of servicesñòhighspeed services,ó defined asservices that exceed 200 kbps in at least one directionñof which advanced telecommunications services are a subset.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.64broadbandample, two recent swedish governmental commissions took a look at thissame question (but without having to factor in the u.s. statutory language, as did the fcc) and adopted substantially higherspeed thresholds: symmetric 2 mbps and 5 mbps.5 in the end, neither the definitions ofthe fcc or those of the swedish commissions are entirely satisfactory(indeed, fcc staff speaking at the committeeõs 2000 workshop acknowledged difficulties associated with the fcc definition).defining broadband is more than an academic exercise. numerousgroups would stand to benefit from workable definitions of what constitutes broadband. they include:¥consumers, who would like to be able to evaluate service offeringsto see if the offerings are likely to meet their needs;¥service providers, who would like to develop, invest in, and deployservices that consumers will need and want;¥application and content developers, who would like to understandand track the connectivity performance options available to consumers;¥policy makers or regulators, who seek to monitor broadband servicedeployment and measure the impact of policy or regulatory decisions ondeployment, define the characteristics of services eligible for tax credits orloans, or define the characteristics of services required in buildout commitments associated with regulatory relief; and¥public interest groups, which seek to evaluate capabilities availableto consumers and to understand the implications of alternative policyapproaches that influence those capabilities.framed in this way, defining the term òbroadbandó in some sensealso involves (1) identifying the kinds of applications that consumers arelikely to find useful and desirable and (2) determining the benefits thatdifferent segments of the public anticipate from access to broadband services. the definition of broadband used by each of these groups willreflect that groupõs expectations and, consequently, can have a significanteffect on decision making. too limited a definition, such as establishingtoo low a data transmission rate as the broadband threshold, could resultin a mismatch between expectations and capabilities, while a definitionthat is unrealistic in terms of technological capabilities, costs, or consumerdemand could prompt inappropriate or poorly aimed policy interventions. the absence of a consensus on definitions will confuse political5swedish special infrastructure commission (june 1999): broadband should be definedas at least 2 mbps (symmetrical) to the user. swedish it commission (november 1999):minimum 5 mbps to the user.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?65debate on the subject and require ongoing debates about what definitionsto use.overview of the technical characteristicsof broadbandcommunications capacity, or speed, is only one of a set of performance characteristics of a service. that it is not the whole picture is easilyseen in the contrast between dialup access, where the modem must placea telephone call and negotiate a connection with the ispõs modem, and theservices available today that are generally considered broadbandñwhichfrequently offer òalwaysonó connectivity as well as high speed. alongwith speed and alwayson are additional parameters such as bandwidthsymmetry and addressability that are important components of a definition of broadband. each of these is considered in the sections that follow.speedthe speed or bandwidth of a serviceñthe rate at which one can transfer data to and/or from the homeñis a function of multiple factors. because the effective bandwidth reflects the capacity of the endtoend connection between sender and receiver, the speed seen by a user can beconstrained at any one of a number of points between the userõs computerand the computer providing a particular service. however, speeds withinthe core network have been rising, at least in the united states and otherdeveloped nations, and the capacity of the network link between the userand the broadband providerõs network is one of the crucial factors thatdetermines how the broadband service can be used.the betterthandialup criterion for broadband assures that a serviceis at least a little better than what was available before, but it does notaddress the question of whether the service is good enough. and while a2 or 5mbps threshold would seem ample for most applications envisioned today, it might, on the one hand, prove inadequate in the future,or, on the other, raise questions about whether its costs today wouldexceed what customers are willing to pay for today. later, this chapterexplores several approaches to answering the fundamental question, howfast is fast enough?as indicated earlier, the effective speed for interacting with an internethost is not merely a function of the performance of the broadband localaccess linkñit depends on the entire path between the host and the user,and also on the loading on the host computer. as a result, depending onthe circumstances, improvements in the performance of one link does notnecessarily improve overall performanceñit may only shift the bottlebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.66broadbandneck. network infrastructure such as caching and content hosting withinthe local isp access networks also has a substantial effect on perceivedperformance to the end user and loading on the connections to the coreinternet.where are the bottlenecks, and how might they shift as broadbandaccess technologies are upgraded? today, for dialup users interactingwith most commercial hosts, the bottleneck is the last mile dialup connection. with the current generation of deployed broadbandñcable modems, dsl, or wireless servicesñthe location of the typical bottleneck, atleast for routine web access, is less clear. it may be in the last mile, withinthe local isp network, at the upstream linkage between the cablemodemor dsl isp and the internet core, closer to the host, or even in the userõspc.from an applications perspective, dsl and cable modem broadbandofferings today remove barriers to many applications. advanced fibertothehome (ftth) networks with very high capacities (such as gigabitethernet) enable additional applications, but they also illuminate a newset of barriersñsuch as the cost of core internet connectivity at extremelyhigh speedsñwhich present an obstacle to the widespread deployment ofthese applications. an ftth network offers enormous amounts of bandwidth (e.g., gigabit ethernet speeds) within the service area, but the fibernetworkõs connection to the core internet service providers may in fact beconcentrated into a much slower link (say t1, 1.544 mbps) that is sharedby all users of the network. in this regard, residential fiber broadbandnetworks will come to resemble the networking situation on university orcorporate campuses, where local bandwidth is plentiful, but connectivitybeyond the local campus is a comparatively constrained shared resource.6the link to core internet service providers is typically going to be paid foron a leased basis, and its costs rise as the bandwidth of the link increases.in contrast, high local bandwidth within the community incurs mainlythe fixed capital costs of installing and lighting the fiber network (whichcan be financed for a long period of time). thus, where very fast ftthnetworks are deployed, they can have the property that access to hostswithin the community served is very fast, but that more general access tointernet sites is much slower; it may thus be possible to exchangehighdefinition video with a neighbor or a local community center, butdifficult in the short term to extend this level of performance beyond amodest geographical region.6this phenomenon has been experienced by universities that saw new bandwidthintensive applications such as napster clog their backbone internet connections.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?67latency and jitterwhile the net throughput is the most significant enabler of manyapplications, two additional parameters are crucial for applications thatdepend on realtime delivery of information or interaction, such as telephone or interactive game playing. òlatency,ó or delay, is a measure ofhow long it takes to deliver a packet across the network to its destination.latency is a function of the distance the packet travels (speed of light,which is of particular significance for traffic carried over geosynchronoussatellites), the length of time the packet waits in queues within the network, and the delay that results from retransmission when a packet isdropped due to congestion within the network. latency especially affectsapplications that depend on interaction, such as humantohuman conversations, games, and the like. òjitteró measures the variation in latency,resulting from such factors as variations in the path taken by each packet,variable queue lengths, or variations in the level of congestion within thenetwork. even if the average latency is acceptable, high jitter may makethe application unusable nonetheless.symmetry between upstream and downstream capacitytoday, telecommunications services, including broadband, do notnecessarily provide the same capacity up and downstream. at one extreme, digital cable television service and direct broadcast satellite serviceprovide a very high data rate digital connection into the home. theseservices may also provide a low data rate return pathñover the same linkor over an alternative return link using a phone lineñto enable enhancedservices such as payperview. however, most users probably would notthink of these services as broadbandñthey expect broadband to includehighspeed internet access (perhaps along with these predominantly oneway services). on the other hand, broadband does not necessarily implythat one must have anything close to symmetric bandwidth to and fromthe premisesñthough some would argue that it will, over time, as a consequence of the minimum bandwidth particular applications require.the asymmetric services typically found in todayõs residential broadband services were designed with one of two asymmetrical applicationclasses in mind. one class is web browsing, where a lowbandwidthupstream connection serves to carry a userõs requests for web pages, andthe higher downstream connection returns the content the user has requested; ecommerce or other applications in which users interact viaentering information in web forms involve a similarly asymmetric communications model. the other class, audio or video delivery, in which asmall amount of data is sent upstream to select and direct delivery of abroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.68broadbandparticular stream (delivery of packets for playback in nearreal time), iseven more asymmetric.while web browsing has been a dominant application of residentialbroadband, accompanied by more limited audio/video streaming, peertopeer applications have surged recently. these applications, which usemany individual computers instead of a central server to distribute content, require significant upstream capacity for each computer. they have,as a result, presented isps with traffic loads that are at odds with the ispsõassumptions about asymmetric traffic7 and have raised questions aboutwhat shape user demand will take in the long term. similar pressuresresult from other applications in which users host content on their localmachines, creating upstream demand whenever this content is requested.these pressures, at odds with the capabilities of todayõs networks, havealso led some broadband isps to prohibit customers who subscribe toconsumer/residential services from running servers on their computers.it is not clear at this point how traffic patterns will evolve as applications mature and as the population of broadband network users movesbeyond early adopters. there is at least some reason to believe that thetraffic patterns will in fact be asymmetric, though perhaps not as stronglyas some of the broadband isps initially assumed in their network designand pricing models. but it is also important to recognize that some of thedemand for symmetric bandwidth is a political rather than a business orengineering proposition. if the networks are designed to make it impossible, or very expensive, for individuals to originate the kind of trafficassociated with the provision of services or content to significant audiences, it would foreclose the possibility that hightraffic upstream services will emerge on a highly distributed, grassroots basis. this prospectpoints toward a model of the future broadbandenabled internet as anenvironment dominated by commercially provided services connectingto customersñan outcome that in the view of some would fall short ofbroadbandõs full potential.more generally, while much of the focus on broadband has been onits potential as a channel for delivering information, broadband also provides a more general communications channel (into and out of the premises). on the one hand, email and instant messaging are prominentexamples of communications applications that do not depend on largeamounts of upstream bandwidth (or downstream, for that matter), but7for example, according to jim hannan of sprint wireless at the committeeõs june 2000workshop, òas a point of data, in our experience, we would love it if [the ratio of downstream to upstream] were 10 to 1. you know, our network model said worst case: 8 to 1.unfortunately, our experience is 2 1/2 or 3 to 1, downstream to upstream.óbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?69that provide evidence of demand for convenient, internetbased communication. on the other hand, as consumers start transmitting video clips(produced using increasingly inexpensive digital video cameras), bandwidth requirements could increase significantly. on the horizon are anumber of communications applicationsñtelephony being the most obviousñthat place increasing demand on the upstream channel.the detailed discussion of application classes below suggests that thejury is still out on the longterm implications of such applications forsymmetry demands in broadband services. nevertheless, a number ofpressures for increased upstream capacity are evident.alwaysonin addition to higher bandwidth, a broadband connection also generally provides an alwaysavailable connection to the internet. one principal implication of alwayson broadband service is that, for the first time,residential users have nearly instant access to web or other internet services on demand. before the advent of broadband services, residentialand many small business internet users were confined to using a dialupline to access the internet. with dialup, the user faces a noticeable delayñthe sum of the time it takes to place a call between the user and ispmodems, the time it takes for the two modems to negotiate a connection,and the time it takes to log in (generally by authenticating the user via apassword) to the isp. the delay is increased if the user makes a habit ofturning off the pc between sessions, since the time it takes the computerto boot up must also be added to the time it takes before a user can accessthe internet. by eliminating the need to place a telephone call, broadbandservices greatly reduce the time required. while there is some delay associated with negotiating communications parameters when the customerõsmodem is powered up, these devices are designed to be left on all of thetime, meaning that there is continuous connectivity between the modemand the network to which it is attached. laptop computers have hadpower management features for some years; more recently this capabilityhas been added to desktop computers. power management capabilitiesmake it possible to have computers òsleepó (quickly switched to a lowpower state) and then be reawakened whenever the user wishes to accessinternet resources.the term òalwaysonó might conjure up visions of some sort of compelled use in which computers or applications must be left running all ofthe time. alwayson does not imply this; it refers merely to a characteristic of broadband networks that enables network communications to beinitiated at any time. users remain free to close software programs or shutdown computers as they wish. of course, some applications and combroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.70broadbandputer devices will be designed to work best when they are always connected, and many users may choose to keep some computers or applications in an alwaysconnected state.research has shown that removing the startup delay changes theway that users perceive and use the internet. because the overhead associated with accessing the internet becomes very small, there is more casual use of the network for very short tasksñsending a short message orlooking up a piece of information. this change also has the effect of significantly reducing the length of a typical òsession,ó as users begin toregard the network as an alwaysavailable utility, even though total usemay stay the same or increase. users also may change their behavior toleave their pcs on more of the time, either fully powered up or in sleepmode.8the popularity of instant messaging (and chat rooms) despite the factthat the majority of household internet users connect via dialup servicedemonstrates the high level of user interest in using the internet for communications applications with a realtime dimension (in contrast to thedelays associated with email). however, because dialup users are unlikely to be connected to the internet at any given time, it is generally notassumed in todayõs applications that they are always connected. in analwaysconnected broadband environment, these applications becomemuch more powerful. for example, the value of an internet telephonyapplication is limited if calls can only be placed if the person being calledhappens to have an active dialup internet connection at the time the callis placed. many other applications are most useful when the equivalentsof telephony ringing and signaling capabilities are available.bandwidth aside, the combination of quick access and new applications is compelling. indeed, one sees this value reflected in valuestratification practices of several dsl service providers. they provide two tiersof residential serviceña cheaper one that requires users to go through alogin screen when they wish to connect and a more expensive one thatprovides continuous connectivity. results from the index project at theuniversity of california, berkeley, which was designed to learn how muchpeople are willing to pay for various levels of bandwidth on demand,provide further support for the proposition that a considerable fraction ofthe value that users attach to broadband may stem from its alwaysonquality. in that experiment, users tended to keep a basic 8kbps service,which was provided free and was on all the time, but on average theyplaced a surprisingly low value on their waiting time, which in the ex8ken anderson and anne page mcclard. 1998. always on: broadband living enabled. technical report, broadband innovation group, mediaonelabs. october.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?71periment could be avoided by purchasing a higherbandwidth capabilityon demand.9there will be important new applicationsñhealth monitoring, security, and the likeñwhich will be possible only with the alwayson characteristic, but users will choose whether they want to use those applications.the notion is familiarñtelephones are generally left connected, ready torespond to a ring signal. what alwayson should conjure up, however, areconcerns about security. todayõs enduser computing devices are vulnerable to a variety of network attacks.10 alwayson connectivity increasestheir exposure to these threats (see below).connectivity sharing and home networksanother attribute that users sometimes associate with broadband access is that of a premises network. dialup access is generally done from asingle machine. the speed of the dialup connection is slow even for asingle machine, so trying to share that bandwidth among multiple machines is not generally very desirable. moreover, it is common for each pcto have an analog modem. thus, users have generally arranged to timeshare the household phone lines sequentially among a number of machines in a home (though quite possibly not without disharmony resultingfrom contention over access to the phone lines). a broadband connection,however, by virtue of its alwayson nature and greater capacity, makes itreasonable to support multiple machines concurrently. thus, broadbandinternet access and use of home networks will increasingly be interrelated.11spurred in large part by the initial deployments of broadband services to the home, a variety of home networking technologies are available in the consumer market (box 2.1). the year 2000 represented something of a turning point for the massmarketing of these devices, seen inthe increasing number of vendors offering products and in falling prices.9hal r. varian. 2000. estimating the demand for bandwidth. technical report, university ofcalifornia at berkeley. august 1999, revised august 29, 2000. available online at <http://www.index.berkeley.edu>.10see cstb, nrc. 1998. trust in cyberspace. national academy press, washington, d.c.11another possibility, most plausible with wireless access in which each device has itsown antenna, is that the devices within the home would each have their own connection tothe network infrastructure. while this configuration, in which there is no home network,may have advantages for the consumer in terms of ease of management, it also has thelimitation that interdevice communications would have to be routed through the local access link to the core network and then return through another local access link. such anarchitecture would likely preclude such applications as having a dvd player transmit aprogram to a remotely located video display.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.72broadbandbox 2.1inhome networking technologieswired ethernetthis is the industrystandard networking technology commonly used in office andbusiness settings. ethernet today routinely runs at 100 mbps, which provides adequateperformance for many applications, even video applications. (qualityofservice management, which is not provided by standard ethernet, may, however, be required for veryhighend applications.) the primary difficulty with using wired ethernet is that most homesare not wired with the requisite category 5 wiring. there are longterm efforts aimed atpromoting the installation of networkingcompatible wiring in new construction;1 rewiring of existing dwellings is generally restricted to early technology adopters who are willing to deal with the cost and disruption associated with installing new wires within ahouse. with a wired infrastructure in place, ethernet is a very inexpensive solution, withinterface hardware available from many vendors and frequently incorporated into computers. it also offers ample headroom for future speed upgrades (1 gigabit per second[gbps]s has been demonstrated over four category 5 twisted pairs of 150 feet). for theslowly growing set of users that have the requisite wiring, ethernet is a likely technology ofchoice.phone line networkingphone line networking operates by using a highfrequency carrier superimposed overa homeõs existing analog voice telephone wiring, allowing any standard phone jack withinthe house to become a network port. for homes that have phone jacks already installed inlocations where networked devices are likely to be located, as is the case in many u.s.homes, this is an attractive solution. an industry standards group, the home phonelinenetworking alliance (hpna), has defined two standards: hpna 1, which provides a1mbps data rate, and hpna 2, which increases the data rate to 10 mbps while maintaining backward compatibility with the first version. the hpna specification does not interfere with the normal voice operation of the phone line, and it operates in a different bandfrom a g.992.2 asymmetric digital subscriber line (adsl) (g.lite) so that it can coexistwith that standard as well. hpna products are currently offered by a number of vendorsfor attachment to existing computers via parallel port, universal serial bus (usb), or via aperipheral component interconnect (pci) addin card. additionally, a number of pc vendors are shipping home pcs with hpna integrated into the system directly. the technology is relatively inexpensive and hpna is being bundled with home computers today,much as most home pcs include analog modems. hpna has the drawback of interferingwith broadcast radio and some, but not all, types of dsl.1wiring americaõs homes, sponsored by the home automation association.see <http://www.homeautomation.org/wah.html>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?73wireless networkingwireless solutions are very attractive in that they require no wires to be installed. theyallow networked computers to be located anywhere within the home, and they supportmobility within the house. in the past, wireless technologies suffered from being too expensive for broad consumer acceptance, had lackluster performance, and were toopowerhungry for use in batterypowered devices. more recently, two standards using theunlicensed 2.4gigahertz (ghz) band that overcome these shortcomings have emerged:802.11b and homerf. 802.11b has been defined by the institute of electrical and electronics engineers (ieee) and supported by the wireless ethernet compatibility allianceindustry consortium. it uses direct sequence spread spectrum rather than frequency hopping, and operates at up to 11 mbps for data. a number of vendors have announced802.11b products. 802.11b is also being widely supported in business environments andpublic access points and is also being used in a number of community access initiatives.with both standards, there are issues of interference with other uses and other technologies that make use of the same radio spectrum.products using a new standard from ieee (802.11a), which use the 5ghz band andpromise data rates of 54 mbps, are under development. another wireless lan standardoperating in the 2.4ghz band, 802.11g, would boost speeds to as much as 54m bit/secwhile proving backward compatibility with the 802.11b. another relevant wireless standard is bluetooth. currently bluetooth targets data rates of less than 1 mbps, althoughwork is ongoing to define higherspeed versions. however, it focuses now and probably inthe future on shortrange òpersonal area networking,ó at less than 10 meters (m). whilebluetooth will likely have applications in the home, the range may restrict it from being ageneralpurpose solution for home networking. also, because both bluetooth and thecurrent generation of wireless lans use the same spectrum, there are still unresolvedissues of how to efficiently share the spectrum and avoid interference.powerline networkingbecause power outlets are ubiquitous in homes, there has been longstanding interestin technology that would provide highspeed networking over household ac power wiring. however, there is a great deal of interference present on power wiring, because thesewires are used to supply power to motors and other very electrically noisy devices. inaddition, many homes utilize both phases of the supply power in different circuits withinthe home; communicating across outlets connected to different phases requires installation of bridges between the phases, which may be difficult for consumers themselves toinstall.in multidwelling units there are also potential interference problems, analogous tothose faced in wireless networking, associated with multiple users using common lines. todate, the most common use of networking over the powerlines has been for x10 homecontrol devices that permit remote operation of lights and the like. in the year 2000,several companies began shipping, or announced, powerlinebased data networking products, with claims of data rates up to 10 mbps. the homeplug powerline alliance availableonline at <www.homeplug.org> has been formed and is promoting its 10mbps baselinestandard. field trials and certification lab are reportedly approaching.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.74broadbandin 2001, a number of products that integrate home networking technologyhave been announced. gateways connect to dsl or cable modems andprovide home networking via a variety of technologiesñthe range aloneindicates progress in standardssetting and growing technology maturityin this arena. vendors also are integrating these functions into the modems themselves, aided by the minimal cost of adding home networkingfunctionality to the silicon that implements the modem. such integrationextends to computers and internet appliances as well, with these devicesincorporating one or more home networking technologies. these trendswork toward making broadband installation a simpler process for theconsumer, eliminating the need for additional wiring, and lessening theneed for visits by installers.finally, even for a single computer on a broadband connection, usersoften have an expectation of being able to multiplex among a number ofapplications. dialup access, in contrast, often constrains a user to bedoing one thing at a time with the system. this may be because it issimply too slow to have multiple activities sharing the connection, or itmay even be because the resulting effective slowdown of the connectionsimply renders one of the applications unusable. for example, listening tointernet audio while also downloading files is likely to make the audiodrop out over a dialup connection, whereas simultaneously listening tointernet radio, downloading files, and surfing the web is quite feasibleover a highspeed connection. although rooted in what is enabled by thespeed of the connection, this change is as much a change in user behavioras it is about a new technological capability.addressabilitya critical requirement of many applications is that a userõs computerbe addressable in some fashion by software running on computers elsewhere on the internet. this means that someone on the internet can initiate communications with the user, much as a telephone caller can placea call to a subscriber by dialing the subscriberõs telephone number. addressability also enables such functionality as a user being able to run aserver that other internet users can access (a capability demonstratedwith napster and gnutella).while addressability is commonplace in the business use of the internet, it is the exception for residential users today. one reason is providerpolicyñnot all service providers allow inbound connections in their policies. another reason is the technical means of connecting the user to theinternet: addressability is most easily provided when each computer device within the home has its own globally addressable internet protocol(ip) address. many residential customers are provided dynamically asbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?75signed addresses, and even if they have a static address, they may onlyhave one or a fewñmeaning that each computer within the home maynot have a globally routable address as a result of the use of networkaddress translation by either the isp or within the home gateway used toprovide connectivity to multiple computers within the home.addressability is a doubleedged sword. being able to address homecomputers from other computers attached to the internet enables powerful new applications, but it carries with it issues of security and privacythat will need to be solved. for example, exposing computers to theinternet on a continuous basis makes them more attractive and potentially vulnerable targets for attacks aimed at destroying data stored onthem or otherwise disrupting their operation, viewing information storedon them, or manipulating them for use in launching attacks on otherinternet services. isps may take some steps to help protect users, such asfiltering out possibly hostile traffic (e.g., blocking transmission of netbiospackets, which could be used to alter or delete files and are generally onlyintended for use within local area networks), but the security of homecomputers depends in large part on the security of the computers orgateways installed within the home. that security depends, in turn, onthe adequacy of addon devices such as firewalls, which users have toconfigure to filter traffic and deliver warnings appropriately, and on thequality of typical homesystem software, which tends to be low from theperspective of security.12 another risk is posed by alwaysconnected, addressable sensor devices such as cameras. breaches of security could enable outsiders to read or take control of these devices, allowing them toview or otherwise monitor what happens within peopleõs homes. andtampering with control devices could cause direct physical harmñforinstance, someone with access to a householdõs networked climate controls might maliciously turn off the heat during a cold spell. in a development that signals increased awareness of security issues and suggests awillingness to trade off flexibility for additional security (despite arguments in favor of the endtoend principle in technical communities), consumers have been purchasing gateways that incorporate firewalls as wellas installing softwarebased firewalls on individual computers.controls on applications and contentquestions about potential limitations on the content and applicationsthat will be available to the typical consumer of a broadband service havefigured in the cable open access debate, which features a conflating of12see cstb, trust in cyberspace, 1998.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.76broadbandpractice, motivation, and perceived impacts that varies with point of view.the issues are outlined here because they contribute to both perceptionsand realities of commercial broadband offerings, which will be implemented based on choices made by providers that must decide amongtechnological and strategy options. given the newness of the marketplace, it is easy for critics to assume intent based on experience withtraditional media, especially cable, and it is hard to predict what practiceswill succeed in the broadband marketplace, regardless of their fate withtraditional media. about the only certainties at this point are that theservice providers are trying to make money, that content providers seekaccess to users, and that provider policies and practices are evolving atthe same time as the technologies and businesses.already, there are various models for internet service, ranging fromthe isp that provides only basic ip connectivity to the isp that provides amodest bundle of services and content, to isps such as america online(aol) and microsoft network (msn) that aim to provide a wide range ofproducts and services. providers can seek various degrees of control overparticular applications that run over their service or restrict access toparticular content, perhaps simply by making it much easier to accesspreferred content. this may happen for various reasons, and the effectsmay be either primary (to promote use of certain content) or secondary (tomake use of certain content less convenient).if some content (e.g., from sources with business relationships withproviders) is cached and easily accessed, other content may appear to beharder to get to. uncached web content will, for example, be slower toloadñespecially if the source is far from the user and/or on a networkwith poor connectivity to the userõs. in the extreme case, access to noncached content might be poor enough to make it seem effectively filtered;consumer advocates express this concern about the fate of content fromnonprofit sources, but the concern remains hypothetical.service providers provision bandwidth, especially upstream, basedon a particular business modelñwhich makes assumptions about who issending how much of what to whomñor on the assumption that a certainfraction of traffic can be cached. or, providers might use restrictionsñsuch as restrictions on virtual private networks or on operating householdbased serversñas a means of value stratification, charging more tothose who value, use, and will pay for more flexibility or capacity.actions that restrict upstream communication raise concerns aboutinnovation enabled by end usersõ being able to originate content or applications. a targeted approach by isps might alleviate some concerns. forexample, a provider that is concerned with upstream bandwidth scarcitymight more effectively deal with excessive bandwidth use (relative toprovisioning assumptions) by applying measures that monitor or restrictbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?77bandwidth consumption rather than by prohibiting all users from, say,running servers. while some legacy equipment might not support bandwidth monitoring or control, most isp equipment today would permitthis. opinions will differ as to whether restrictions reflect legitimate operational considerations; valid business decisions to differentiate customers; or unreasonable attempts to limit customer access to applications,content, and services.assessment of provider conduct should distinguish between the useof caching and similar techniques, which are aimed at improving accessto some content by moving it (via distributed copies) to locations closer tousers, and the use of filtering, which limits access to some content entirely. steering or restricting customers to certain content runs counter tothe traditional internet model, in which internet service is deemed synonymous with access to all internet content. the success of these òwalledgardenó models depends on whether consumers want the preferred content (or, in the view of critics, have no alternative). actual consumerpreferences and reactions to their experiences as users confronting differential ease of access to content are an important but unknown factor.implications of network design/architectureanother parameter that deserves consideration is whether òbroadbandó refers exclusively to internet service or is a more inclusive termthat refers to a set of data communications services. is the point of broadband to bring the internet to the home or small business at much higherspeed and with characteristics such as alwayson, or is broadband reallyabout delivering to the home a bundle of digital services, which includeip service, that are demultiplexed at a gateway? cable television systemstoday deliver both ip data and digital television signals. higherqualitypictures and greater system capacity than analog cable systems coulddeliver were the original motivation for deploying hybrid fiber coax (hfc)in cable systemsñip data capabilities were added later. this video viampeg (a standard for video compression from the motion picture experts group) streams is largely oneway (possibly with a lowcapacityreturn channel to allow the selection of content or other interactive features), and the content is offered through various service bundles andpayperview options defined by the service provider. looking forward,to what extent will services be delivered using plainvanilla ip versusmore specialized protocols and architectures? running video and audioover plain ip, for example, is not without problems today, and these,together with business considerations, may well lead providers to deviseother network protocols and systems to deliver audio and video alongside ip (for other applications), perhaps coming out of the settop box intobroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.78broadbandproprietary or consumerelectronicsoriented interfaces that feed tvs andother appliancesñpossibly with additional features such as intellectualproperty protection engineered in at a very low level.another characteristic of broadband networks is the increasing sophistication of network monitoring capabilities. usually discussed in thecontext of quality of service, commercial broadband providers are motivated to track individual (perhome) usage patterns to accurately assessand supply different levels of broadband capabilities. for example, userscould pay for larger upstream bandwidth to support a home business.approaches to defining broadbandthe discussion above suggests the pitfalls of picking a specific bandwidth threshold as defining broadband, and chapter 3 displays the widevariety of requirements posed by different classes of applications. a better approach may be to define a broadband service as one that meets acertain set of objectivesñobjectives that will change over time.one important task in engineering any system is to examine thetradeoffs between the performance of different components. the firstdefinition offered here takes into account the multiple performance parameters that affect the overall performance of a broadband service. forexample, one can compensate for limited bandwidth by compressing thedata being transmitted, a technique that is widely relied on today. or, onecan take advantage of ample local storage capacity as might be found ontodayõs computer hard drives to store content so that it does not have tobe transmitted over the connection at the time it is needed.13 this perspective motivates one definition of broadband:broadband definition 1. local access link performance should not be the limitingfactor in a userõs capability for running todayõs applications.to illustrate how this definition could be used in practice, considerhow this applies to web browsing. speed here is inherently limited byfactors independent from those imposed by the bandwidth of the localaccess connection. the speedoflight transit time poses a fundamentallimit to the rate at which data can be sent across the network using thedata transmission protocols on which the web is based. for todayõs typical web page, a user òcruising the webó will not see any material performance improvement once his or her access link has a capacity of about13one local storage strategy, caching, keeps local copies of frequently used items. another strategy, replication, preloads information so that it is available for later use.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?791 mbps.14 in other words, upgrading an individual userõs 1mbps linkwith one 10 times faster would not speed up the transfer of a typical webpage. so for this application and at this point in time, an access linkprovides broadband service when it provides a capacity approaching 1mbps. it is important to realize that this is a statement about todayõs webcontent and protocols and todayõs network. the availability ofhigherperformance links would likely give rise to richer content thatwould take advantage of that availability and would also provide incentives to colocate caches or streaming servers close to the broadband accesspoint, leading to an improved user experience as a result of the faster localaccess link.this viewpoint can also be useful in identifying where to make investments to alleviate potential bandwidth bottlenecks within the network. with a major source of congestion residing in the transit circuitsthat connect broadband providers to the internet, improving local accessperformance above that bound will not improve the net performance seenby the user accessing the internet. everywhere in the internet (exceptpossibly on the access link), the average traffic of a sufficiently large number of users aggregated together on a given link will be constant on average, even if the traffic demands of individual users varies considerably.however, the guarantee is statistical in nature, meaning that there is always the potential for fluctuations that result in congestion somewhere inthe network. in contrast, an individual access link is subject to much morepredictability. an unshared link (e.g., a dsl connection to the centraloffice) will be a bottleneck only if it is simply too slow (has too littlebandwidth). even for local access technologies with a shared local medium (e.g., an hfc system or the feeder to a dsl remote terminal), theimplications of sharing can be understood fairly easily, because one knows(based on provisioning and traffic engineering) how many potential usersthere are on any given segment. thus, where there is a compelling application for which the access link bandwidth is identified as the limitingfactor, a welldefined investment in upgrading the capacity of the link cansolve the problem. but for most other links within the network, whereloading can only be addressed on a statistical basis and where there aremany options for making investments that might improve matters, it maybe less clear where to investñwhich in turn may mean that making an14the transfer of a òtypicaló web page (one used by the world wide web consortium asa benchmark for performance) from a server for which the network latency is a typical 100milliseconds. if one varies the bottleneck bandwidth and plots the total page transfer time,the curve approaches an asymptote of about 6 seconds when the transfer speed reachesabout 1 mbps.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.80broadbandinvestment in the local access link will not improve application performance. (other strategies may be used in such circumstances, such as caching or replication within the network of the access provider.)broadband definition 1, however, gives an answer that is only correctfor a given set of applications at one point in time. what happens whennew applications come along? in fact, the performance of broadband access will be a key factor influencing the emergence of new applications,since new applications that demand higher transfer speeds cannot takeoff until there is a critical mass of users with the access capacity to usethem. this motivates an alternative definition of broadband:broadband definition 2. broadband services should provide sufficient performanceñand wide enough penetration of services reaching that performancelevelñto encourage the development of new applications.this definition implies that a broadband access system is definedboth by a technical evolution path and an economic evolution path thatwill allow it to play its part in the chickenandegg application cycle. thesubscriber link is viewed as a potential bottleneck that inhibits innovationand constrains the development of new services elsewhere in the network. those providing services over the internet who feel constrained bythe premiseslink bottleneck may not be able to fully incorporate the benefits of relaxing this bottleneck in their own investment decisions (i.e.,their incentives to òsubsidizeó broader deployment fall short of the truecollective benefits)ñbecause they are unable to internalize the benefitsrealized by other service providers.one example of how this view comes into play is the asymmetry ofbroadband services. anticipating a number of new applications that require greater upstream capacity, one can project increasing demand forupstream bandwidth arising from new applications. yet, if connectionsremain highly asymmetric over the long run, then applications that needsignificant upstream capacity will be slower to appear. because it takesinto account the dynamic interplay between deployed technology andapplications as well as the interplay between technology and economicdevelopments, this second definition is likely to be the more useful one inplanning and policy making.whichever of these definitions one adopts, it is quite apparent that asingle numberñbe it 200 kbps or 2 mbpsñis not a useful definition ofbroadband (even if one focuses only on the bandwidth issue). however,not all values (from zero to infinity) will be equally meaningful. applications such as those discussed in chapter 3 tend to cluster into classescharacterized by bandwidth and other performance requirements. thissuggests that there will be a series of milestones along the way, withbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.what is broadband?81multiple peaks that may well correspond to, or catalyze, application andinfrastructure deployment milestones.todayõs residential broadband capabilities, which are typified by several hundred kilobits per second to several megabits per second downstream and several hundreds of kilobits per second upstream, supportsuch applications as web browsing, email, messaging, games, and audiodownload and streaming. these are possible with dialup, but their performance and convenience are significantly improved with broadband.at downstream speeds of several tens of megabits per second, new applications are enabled, including streaming of highquality video, such asmpeg2 (a standard defined by the moving picture experts group) orhighdefinition television (hdtv), download of fulllength (70 to 90minute) audiovisual files in tens of minutes rather than hours, and rapiddownload of other large data files. reaching this plateau would enabletrue televisionpersonal computing convergence. with comparable upstream speeds, computermediated multimedia communications becomepossible, including distance education, telecommuting, and so forth. withftth, a new performance plateau with gigabit speeds both up anddownstream would be reached. the applications that would take fulladvantage of this capacity remain to be seen.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.82broadband applications: promise and realitybroadband is a means to an end: it refers to capabilities that peoplewill use, but the question is, how and why? there is much excitement insome quarters, but many consumers who are unsophisticated about information technology and networks and do not yet have experience withbroadband connectivity have expectations that are very much at oddswith current reality. indeed, as the discussion below suggests, there ismuch potential for future applications that enrich or complement traditional content and communications channels, but excitement about themshould be tempered by an appraisal of the time frame in which theseapplications could be realized.in practice, what broadband customers see today is largely a betterversion of the internet access that they enjoyed with dialup isp service,featuring webpage viewing, email access, messaging, and the like. thisexperience is enriched by improved access to audio materials (most notably, music and internet radio) and, albeit less frequently today, video. afew new broadbandonly applications are available today, such as network backup and storage. this incrementalism may be inevitable for economic reasons, but it also disconnects the application experience of todayfrom that anticipated as a result of enhancements to familiar applications,the introduction of new applications, and the integration of diverse broadbandbased activities into everyday life.as the examples in this chapter illustrate, technology capabilities areone constraint on new applications. currentgeneration dsl and cablebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content83modem technology are unable to provide large quantities of highqualityvideoondemand. and distributing content within the home in a usefulwayñi.e., at least as well as do todayõs conventional consumer electronics(television, radio, and stereo systems)ñremains a significant òsystemsintegrationó problem involving broadband hardware and software, inhome networking, and consumer appliance design.there are, nonetheless, a number of places with experience in newbroadband applications. the limited pool of users with broadband athome today, together with a larger set of users who access the internet athigh speeds in the workplace or through the networks of academic institutions, provides some indication of the sorts of applications that couldemerge on a massmarket basis. experimentation in industry and academic laboratories provides another source of indications of potentialapplications. these early adopters and their applications may not generalize completely, and not all of these services will necessarily succeedfrom a business standpoint, but they do illustrate how people respond tothe availability of broadband and integrate it into their activities at large.this chapter explores the characteristics of a variety of present and futureapplications and examines some of their technical and related socioeconomic features.classes of broadband applicationskey technical characteristicsñthe bandwidth (upstream and downstream), latency, jitter, addressability, and òonnessó (alwayson), as defined in chapter 2ñdistinguish several currently deployed or potentialclasses of applications. this section outlines the overall characteristics ofeach class and provides one or more specific examples of applicationswithin each class. notwithstanding their seeming variety, possible applications by and large depend on a few core, or primitive, signal or traffictypes and connection characteristics, such as alwayson. these core traffictypes are characterized by their basic data rates, by whether they rely onfile download or streaming (which in turn may have particular latencyand jitter requirements), and the like. performance and quality tradeoffsreflect the interaction between the broadband link and other capabilitiessuch as coding and compression and local storage.although there is no rigorous taxonomy of broadband applications, itis useful to draw associations between key characteristics of broadbandand major application classes. for example, videoondemand and othermedia streaming applications rely on the availability of downstreambandwidth, while information appliances require alwayson service eventhough the bandwidth requirements may be low (see table 3.1). also ofinterest are òcompositeó applications that rely on a set of capabilities. forbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.84broadbandexample, shared sports viewing requires substantial upstream and downstream bandwidth simultaneously. furthermore, the composite broadband use in a home may be made up of multiple applications being usedsimultaneously by different family members.faster general internet access and general internet applicationsbrowsing and related activitiesthe primary motivation today for residential broadband access issimply to improve the performance of the overall web browsing experience. while many factors actually influence the perceived speed of webbrowsingñincluding, most notably, the performance of the server itselfand the performance of the serverõs connection to the rest of the internetñmoving from dialup speeds to broadband speeds on a consumerõs internet access link will almost always provide dramatic perceived speed improvements in general internet usage.in addition to making the general web experience more enjoyable,this speed improvement can also mean that new types of content becomeusable by the consumer. there is, for example, a widely held belief amongcommerce site operators that it is essential to minimize pageload times.1commerce sites thus depend on network performance in designing theirpages, and any increase in that performance (either on average or forspecific users that they can identify) means that they can increase therichness (and hence possibly the value) of their pages. for example, smallimages might be replaced by higherresolution pictures that more closelyapproximate the quality available in print catalogs.1one rule of thumb, the ò8second rule,ó states that if it takes longer than 8 seconds for apage to appear on the consumerõs screen, there is a high likelihood that the consumer willabandon the site. see, for example, zona research, 1999, the economic impacts of unacceptable web site download speeds, available online at <http://www.zonaresearch.com/deliverables/whitepapers/wp17/>.table 3.1mapping between broadband service capabilities andapplication classesbroadband capabilityapplication classlarge downstream bandwidthstreaming content (e.g., video)large upstream bandwidthhome publishingalwaysoninformation applianceslow latencyinteractive gamesbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content85other web usage, such as simply reading long articles (for example,from online news sources), becomes more enjoyable with greater bandwidth, and hence the web is a more attractive medium when the effectivespeed of information display approaches that experienced in physicalpage turning. finally, certain types of realtime applications, such asstreaming stock quotes, depend upon speed and timeliness to be valuable. such applications can often run continuously in a part of the screenand attract user attention intermittently. however, to be effective, bandwidth must be sufficient for the performance of these applications andthat of whatever other network interactions the user may be involvedwith.messagingmessaging of various kinds continues to show up in surveys as animportant application. for example, a jupiter mediametrix assessment ofaol usage for january 2001 reported that of 22 billion minutes spent onaolõs online service, 4.7 billion were spent on aol email, 2.8 billion oninternal instant messaging, and 6.2 billion minutes on aol instant messaging with users outside of aolõs online service; this contrasts with 2.1billion inside all aol content channels.2 although many saw it as anapplication geared toward entertainment, messaging is also seeing increased use in a variety of business environments. while not demandingin terms of bandwidth (dialup bandwidths are sufficient), broadbandenhances messaging because it is always on.fast file downloadingmany users are familiar with downloading email attachments or software upgrades. but many bulk file transfers are simply not practical without broadband. for example, downloading an entire application thatmight otherwise be delivered on a cd would require many hours overeven the best dialup connectionña 60megabyte (mb) file would takeabout 4 hours on a link with a sustained 35kbps transfer rate. for mostpeople, this length of time is simply impractical, particularly if the dialupline is also used for voice communications or is subject to periodic disconnection. on the other hand, a constant connection to the network at evenmodest broadband speeds may make such transfers reasonable.it is important not to underestimate the impact of fast filedownloading capability on a very wide range of applications, including audio andvideo. streaming is complicated compared with file downloading, and2see òaolõs minutes.ó 2001. the washington post, march 8, p. e11.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.86broadbandthe main reasons that people do it, other than for realtime delivery, isbecause the files are so large that users do not want to wait while the filesdownload; the files are too big to store locally conveniently (althoughstorage space is rapidly becoming very inexpensive); and/or there areintellectual property protection concerns (but application of digital rightsmanagement technologies to stored files can provide protection comparable to that of encrypted streams). if one can move music files in a fewseconds, videos in a minute or two, or an entire newspaper or book in aminute, many applications become practical. in addition, the economicsare becoming more appealing with the spread of very large, cheap storageunits. downloading is of particular value when one wants the content forportable appliancesñsuch as ebook readers or music playersñthoughmaking this easy for consumers depends on addressing the inhome connectivity issues discussed below. some typical figures for media bit rateand data file size, together with useroriented parameters such as download time and the size of the data file acquired give a practical sense of therelationships between media type, broadband link capacity, and download times (see table 3.2). already, surveys correlate audio and videodownloading with broadband,3 while indicating that (as of early 2001)fewer than half of home computer users used a media player.43òsurvey says: dsl users addicted to broadband,ó april 3, 2001, available onlineat <http://www.sbc.com/newscenter/1,3950,31,00.html?query=200104031>. pierrebouvard and warren kurtzman. 2000. the broadband revolution: how superfast internet access changes media habits in american households. arbitron company, new york. availableonline at <www.arbitron.com> and <www.colemanresearch.com>.4òreality bytes.ó 2001. the wall street journal, january 29, p. b8, using figures fromjupiter research and media metrix.table 3.2time (in seconds) to download various media types fordifferent access speedsaccess speedmediatypical file size, mb64 kbps288 kbps640 kbps64 mbpsimage0.112.52.781.250.0125audio single1.923852.823.80.238audio album34.64,3309614334.33video album1,000.0125,00027,80012,500125note: assumptionsñ¥bit rates after compression are 64 kbps (audio) and 1.85 mbps (video).¥single song (audio single) is 4 minutes; music album is 72 minutes; image is 1,000 by1,000 pixels, compressed to 0.8 bits per pixel.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content87gamesthe interactivity demands of some games were alluded to above.multiplayer games are of considerable interest because they connect growing numbers of people in a shared activity (òmassivelymultiplayer roleplaying gamesó), providing both social and demandstimulating dimensions. as of fall 2000, for example, everquest involved up to 100,000simultaneous users out of more than 300,000 paying subscribers. of thosesubscribers, 30 percent had broadband connections. according to sony,which provides everquest, availability and reliability are key requirements; latency is less important in this game than in the shooter variety;and bandwidth demand is moderated by a design that presents graphicson the client software and transmits only changes in graphics and in gameand character state.5speed and responsetimesensitive internet applicationswhile activities based on web browsing are generally improved byfaster network connectivity, a small number of internetbased applications are particularly sensitive to connection speed, latency, and responsetime. the two most prominent are day trading and some forms of multiplayer games (in which delays of as little as 50 milliseconds can impairgame play). note that these activities are not generally done through webbrowsers, but rather through specialpurpose interface software. both ofthese call for functionality not easily achievable through any other means,suggesting they will continue to drive interest in broadband.application rentalthe most common model for consumer software distribution is one inwhich consumers purchase applications on cdrom or for internetdownload. these are onetime purchases; except for upgrades, there is norecurring cost. in many cases, software vendors choose to sell their software in large bundles, of which the officeapplication suites are the mostcommon instance. an alternative model is being explored by softwarevendors is the rental of particular applications on a byuse basis. simpleexamples include financial planners and simple taxpreparation softwarebuilt out of web forms. while greater bandwidth would offer faster download times, it is unclear to what extent acceptance of this model depends5robert gehorsam, personal communication, briefing to cstb committee on it and creativity, november 9, 2000.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.88broadbandon bandwidth or on consumer acceptance of a model in which the individual does not own the software. in many cases (for example, tax preparation software), users may want to control the data locally for privacyand security reasons. other applications, such as games, could be obtained through rental, and there would be no such concerns.network storagenetwork storage applications provide users with an alternative tostoring data on local hard drives or on removable storage media such asfloppy disks or cdrom. there are two major advantages to this service.first, people use networkbased storage rather than run their own localservers to do such things as sharing photos. it is hard to know whetherstorage will migrate into the home or out of the home when material canbe stored in either placeñmuch undoubtedly depends on pricing, confidence about access controls for outofthehome storage for certain kindsof materials, and so forth. second, networkbased storage provides redundant offsite storage. this is likely to be attractive to small and homebusinesses and to people who require disaster recovery (which mightwell include anyone with a pc who has had a disk crash). privacy issuescan be handled by only placing encrypted data on the remote store. forsmall business it seems likely, for reasons of performance, management,and support, that content will be hosted remotely by commercial webhosting services rather than at the small business site.the requirements depend on what sort of data is being stored. forexample, photo (or video) storage may require relatively high upstreamcapacity to permit uploading in a reasonable time (and not tie up theconnection). but filesystem backups, which normally need to transferonly periodic, incremental updates, depend more on the alwayson nature of the connection rather than the bandwidth (unless the volume ofmodified data is very large). one can imagine the emergence of a generation of operating systems with automatic continuous backup across thenetwork as an optionñgreatly reducing the likelihood of data loss due todisk crashes or other computer failures.static image deliveryseveral interesting video applications depend on the ability to deliverstill photos or short video clips. the emergence of inexpensiveñalbeitmore expensive than their analog counterpartsñdigital still and videocameras enables easy capture of photos.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content89audiobecause many audio applications do not demand especially highbandwidth, in notable contrast to video applications, they often workwith at least some level of functionality over a fast dialup connection. allof the currently deployed broadband technologies are fast enough to support the key audio applications that have emerged to date. these includeconventional voice similar to telephony; voice as a complement to gamesand other interactive applications; and a full range of sound applications,beginning with music but including other types of content (e.g., news andother spoken word). as a result, some experience has been gained withthe delivery of audio applications over the internet in general, and viaresidential broadband in particular. this experience supports a key themeof this chapterñfor many applications, the bandwidth provided by broadband services is a necessary but not a sufficient condition by itself to makean application work effectively. factors such as which home networkingtechnologies are used, the availability of specialpurpose appliances, andthe nature of user interfaces are also critical enablers of widespread use ofaudio applications. while there is much interest in broadband for videodelivery, this chapter devotes considerable attention to audio as well,both because it is an important application and because understanding ofaudio applications is better grounded than that of video applications,given early efforts to deploy various audio applications.audio deliveryfundamentally, there are two ways to approach audio deliveryñafile can be downloaded to a local computer and then played, or the datacan be streamed from a remote computer to the local computer, playedmore or less as it is received. clearly, the file transfer model is appropriateonly for distributing prerecorded material; conversations by their verynature have to be conducted in a streaming mode, and streaming is alsoessential for òliveó content that has high time value (such as commentaryon a sporting event). the use of streaming delivery does mean that theaudio is necessarily listened to in real time. while some streaming applications use encryption to make it difficult to keep a copy, some streamingapplications permit a copy to be saved to a file for replay or other lateruse.streaming audio requires an endtoend network connection that isfast enough to handle the actual encoded size of the audio file on a secondbysecond basis (one end may be at a content server located somebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.90broadbandwhere within the broadband providerõs network). in some applications, atechnique known as buffering can be used to prevent transient networkdelays from interrupting playback. audio is played from the end of thebuffer as newly received audio is added to the start of the buffer. still,network delay and jitter must be kept within bounds so that the buffereddata are sufficient to imperceptibly smooth over these delays. the acceptable buffer size depends on human factors that vary according to theapplication. a fewsecond pause between when a request is made to playa song and when the song starts playing is probably acceptable, but asignificantly longer delay is likely to be annoying. delays of anywherenear this magnitude in a voice conversation are very distracting, however, as is familiar to anyone who has contended with even the halfsecond roundtrip delay on a geosynchronous satellite circuit.there are other circumstances in which the length of the delay affectsacceptability. if one is streaming a live event, the sensation of being live isdependent on the stream delay. if users have access to the event throughother media, they may notice even relatively small delays. for example,there are data streams that deliver information on sporting events. if auser runs one of these concurrently with an audio streaming feed of thesporting event, the inconsistencies may be noticeableñfor example, a playis reported on the data feed before it is heard over the audio feed.another parameter affecting the performance of streaming audio isthe packet loss rate. typically, lost packets are not retransmitted becausethe resulting delays (the sum of the time it takes to determine that apacket is lost, the time it takes to transmit a request across the network,and the time it takes for the replacement packet to be delivered) wouldmake the playback jerky.6 for typical audio applications, occasionalpacket loss turns into distortion and sound disruption and causes variable quality as the sound is reproduced. depending on what the audio isand how often packet loss happens, this effect can be very annoying,though it may not be enough to make the application unsatisfactory.people do accept a certain degree of impairment due to interference whenlistening to the radio and tolerate brief dropouts when using cell phonesor wireless handsets for wireline phones.in the file download model, the key question is how long the user iswilling to wait to receive the file. simple calculation of the transfer times6with a lowlatency network connection and a sufficiently large buffer, limited retransmission may be tenable, but this is not the typical practice in streaming protocols. indeed,lower performance is observed in applications where a transmission control protocol (tcp)connection (which builds in retransmission of lost data) is used in place of the raw userdatagram protocol (udp)based transport. the time taken by the tcp algorithm to handlepacket loss translates into much higher delay and jitter figures.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content91required for a 5minute musical recording at different bandwidths yieldsan indication of the timescales involved (table 3.3). note that these timesassume that the server transmitting the music has sufficient capacity tosupport the transfer rate offered by the last mile link and that there is nobackbone network congestion that would reduce the effective transferrate. in many realworld applications, either or both of these may turn outto be the actual limiting factors.the acceptable download time depends considerably on the details ofthe application. for example, in a downloadfirst and listenlater application, it may not be satisfactory if it takes more than a few seconds to cueup a song (and streaming may be a more appropriate approach). if theapplication downloads a collection of music in the background for laterlistening, however, this transfer time may be acceptable. but if the goal isto download a compilation of music and immediately listen to it òofflineó on a portable device, taking more than a few seconds to downloadeach song is probably unacceptable.compressionquality tradeoffscompression is a key determinant of the network performance requirements for an application such as audio. compression algorithms formedia rely on two basic principlesñthe removal of redundancy and thereduction of irrelevancy in the input signal. while mathematically losslesscompressionñin which the original signal can be completely restoredupon decompressionñis used in some archival, legal, and medical applications, the pragmatic goal in most media applications is some degree ofperceptual losslessness.table 3.3download times (in seconds) for a 5minute musicselectionnetwork capacity (kbps)low fidelity (3 mb)high fidelity (30 mb)504804,8001002402,4002001201,20050048480800303001,000242401,500161605,0004.848note: a file size of 3 mb at low fidelity and 30 mb at cdquality encoding is assumed. thesustained file transfer rate is assumed to be the same as the network bandwidth.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.92broadbandwhile acceptable spoken voice quality is provided by a data rate aslow as 4 kbps, music playback covers a wider range of data rates. presentstorage and transmission costs generally mean that the maximum practical compressed signal data rate for many applications is 32 to 64 kbps.mp3type encoding is commonly used today to compress audio at a variety of compression ratios. mp3 at 64 kbps provides a quality roughlyanalogous to (analog) fm radio qualityñacceptable in some applications,particularly if it is to be played back through a lowquality system, butnot as good as a cd played using highquality equipment. compact disk(cd) quality using todayõs compression algorithms requires 128 kpbs.7the gap may also be growing between what generally available bandwidth supports and stateoftheart audio. consumer electronics companies are currently beginning to promote a series of superhighfidelityrecording schemes using highercapacity dvd (digital versatile disk)media that provide a much higher quality than that of cd audio. multichannel sound proposed for future hdtvclass applications would require a higher bit rate, with 320 kbps being a conservative figure for 5channel sound.8the wide range of bandwidthquality tradeoffs for sound is illustrated by radio broadcasting that is being streamed across the internet. atthe low end, services such as spinner.com stream subfm radio qualitymusic at roughly 20 kbps. much content is streamed at rates in the rangeof 20 to 100 kbps, with the low end serving dialup users and the high endaimed at users in the workplace or with residential broadband. towardthe high end of that range, the quality lies somewhere between fm radioand cd quality. and at the high end lies uncompressed fullfidelity radiobroadcasting at a data rate of 1.4 mbps, as was demonstrated at the october 2000 meeting of the internet 2 consortium. the majority of applications moving audio over the network today, however, operate toward thelower end of the qualitybandwidth curve.the range of technology options today supports the observation thatthere are very different thresholds for what constitutes òminimally acceptableó music quality and what constitutes òhighó quality. this is avery subjective matterñmany people are willing to listen to am radio, alarge number find fm radio acceptable, and some significantly prefercds over fm because of the quality difference. in addition, acceptabilityvaries from one recording to another; some lossy algorithms work reason7released in 1980, the cd audio specification (the socalled red book standard) makes useof an inefficient compression scheme that requires about 1.5 mbps. today, considerablybetter compression algorithms are available.8fortunately, the bit rate grows less than linearly with the number of channels.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content93ably well most of the time, but occasionally, particularly for certain typesof music, they produce artifacts that are very audible and annoying tosome minority of listeners, who will reject the compression strategy onthis basis.applications such as telephony also require twoway delivery to andfrom the home. the same coding issues that arise for other audio alsoarise here, and there are tighter constraints posed by the more limitedupstream bandwidths in todayõs broadband technologies. however, datarates alone will not compensate for inexpensive or poorly positioned microphones or for ambient noise. if one is to use a broadband connection tothe internet to substitute for conventional voice telephony conversations,a good handset will still be needed. it will, for example, be problematic tohold conversations having good sound quality using the pc analog of aspeakerphone that is not close to the speakerõs mouth, just as it is withconventional telephony.specific audio applicationsto better understand the requirements of audiobased applicationsover broadband, it is important to examine a set of specific applicationsand practicalities of each application, including what consumers are likelyto expect.playback of music. todayõs musicplayback applications are attractive topeople who like the convenience of playing music on their computers,who want free music via peertopeer applications, who want to listen toradio stations that do not broadcast in their geographic region, or whowant to listen to events that they cannot get access to in other ways. thiscontent is often not reproduced on highfidelity equipment. as notedabove, options for music content distribution available today are alsogenerally inferior in quality to that of a wellproduced audio cd. in orderfor networkdelivered audio to substitute for audio cds, at least for peoplewho are particular about sound quality, it will be necessary to move upthe qualitybandwidth curve somewhat from where typical applicationsare today.while a number of pcbased audio applications have enjoyed widespread use, it is unlikely that consumers will want to be forced to sit neara pc whenever they listen to music. the configuration of a home willdepend on household income, personal preference, and the like, but mosthomes have devices in various locations. for example, the average number of radios per u.s. household in 1998 was 5.6.9 multiple audio cdplayers are also commonplace, and many homes have one or more highperformance stereo systems. normally, each of these is controlled locallybroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.94broadbandby selecting radio stations or inserting cds and selecting tracks. if thesedevices are to be replaced by networkbased playback, one of two configurations will be required: (1) specialized appliances in each room thatare connected to a computer that is in turn connected to the broadbandnetwork or (2) specialized appliances that directly connect to the broadband network, probably through a home network. endtoend streamingaudio also depends on the performance of the inhome networkõs beingroughly as good as that of the wide area network. this is generally not aproblem with todayõs technologies; the slowest on the market now run atabout 1 mbps (hpna 1.0 and homerf), and the trend in home networksis to support roughly 10 mbps (hpna 2.0, 802.11b, and homerf), withhigher rates possible in the future (see box 2.1 in chapter 2). dependingon whether the desired content is stored locally or not, supporting multiple devices throughout a house may require delivery of multiple channels of sound. currenttechnology broadband may be adequate to support two such connections with appropriate coding, but the presence ofmultiple radios suggests that audio could support demand for higherbandwidths.audio applications place considerable demands on the distributionnetworks within the home. if audio playback is to be available in all theplaces where people are likely to want the broadband equivalent of radiosor cd players, the home network has to be nearubiquitous. in somehomes, this may require wireless, powerline networking or the additionof ethernet cabling and jacks. in other homes, many rooms already have atelephone jack, and phoneline networking is a reasonable option. another option is to distribute the audio signal itself using radio frequencytransmitters and receivers. indeed, appliances are beginning to appearthat use radio connections to a òbase stationó for listening to radio ormusic that comes over a network. one could also imagine base stationtechnology that does very low power broadcasting on fm radio frequencies (assuming that fcc spectrum use issues can be resolved) in order toleverage the existing installed base of radio receivers within the homeñalthough this does not address the control interface issue.audio applications also require a control interface to select programs,switch from one track to another, and so forth. each playback devicerequires some sort of input device, such as a keyboard or touchscreen.with a large collection of digital music, navigation becomes complicated,comparable to choosing selections from several shelves full of audio cds.9u.s. census bureau. 2000. statistical abstract of the united states. u.s. census bureau,department of commerce, washington, d.c., p. 567. available online at <http://www.census.gov/prod/2001pubs/statab/sec18.pdf>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content95there is a variety of architectural options for audio in the home. forexample, audio could be streamed directly to the player or restreamedfrom local storage on the home computer to the listening point. costconsiderations make it unlikely that each playback device would have itsown large store for audio built in, so at least some music is likely to bestored in some sort of household audio library, whether on a generalpurpose computer or on some sort of specialized network device. accesscontrols will also be important; one would not want people outside thehousehold to be able to request music from the home music archive (atleast not through an appliancetype interface). intellectual property issues raise additional accesscontrol issues: presumably, one would expectto be able to play music that one has licensed on any appliance withinoneõs home, but this capability is somewhat at odds with both the digitalrights management systems being proposed by the music industry (suchas the secure digital music initiative, sdmi), which sometimes tie anaudio file to a single device. comparable complications are raised by theprospect of having remote access to central repositories from multipledevices: does one, for instance, maintain a table of repositories and passwords in each device or install digital certificates in each device? standards are also importantñwill consumers be able to select appliancesfrom a variety of vendors or will they be locked into purchasing components (and even content) from a single company?in summary, bandwidth is only one of multiple technology issues.until these challenges are addressed, playing audio music over the internet is likely to be an activity that supplements rather than replaces moreconventional musiclistening options for most people.listening to the radio over the net. fundamentally, listening to radiocalls for the same types of facilities as those for listening to audio, butthere are a few differences and added complications. radio is more likelyto be streamed from the source rather than stored locally in the home inan audio storage server. also, the control interface will be different: aradio service involves selecting channels rather than individual pieces ofmusic (although the rise of videoondemand makes one wonder aboutan audio equivalent). if current products are any guide, the interface maywell resemble radios of today, with buttons used to select preset favoritechannels. some means of access to directories of radio stations on theweb, analogous to tuning in stations by frequency, is probably also required. and, faced with a greater number of choices, people may seek outnew services along the lines of those being introduced in television services, such as tivo and replay. these include program guides and thecapability of scanning program guides automatically for programs of interest. another possible feature would be the capability of saving the last,broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.96broadbandsay, halfhour of a broadcast to permit selecting a particular song or othermaterial for local storage and later playback (there are, of course, interesting intellectual property rights issues to be worked out in this sort ofscenario).networkbased voice telephony. in recent years, there has been growinginterest in running telephony over generalpurpose data networks, including the public internet, instead of over the public telephone network.as an application of dialup internet service, internet telephony arose as aless expensive alternative to conventional telephony. the decreased coststo users are a result of several factors: (1) by utilizing the internet, whichis typically made available to residential users on a flatrate basis, internetprotocol (ip) telephony avoids the perminute charges generally assessedby longdistance carriers; (2) because a longdistance call can be placedwith these services through a local call to an isp, these services allowbypassing the perminute access charges that long distance companies arerequired to pay local exchange carriers to terminate longdistance calls.from an overall industry perspective, there are also players moving toward replacing specialized telephone gear with ipbased equipment, seeking both to reduce costs and to introduce new functionality. there mayalso be efficiencies that result from running data and voice over a common network. ip telephony is being used today by some households andwithin some enterprise networks; it is increasingly also being used internal to the networks of a number of telecommunications carriers. bothdeployments raise a series of complex policy issues.10with residential broadband, which offers much greater bandwidthand alwayson connectivity, ip telephony has the potential to move froma relatively marginal, hardtouse application to a massmarket application. depending on the architecture of a particular service, it might be aservice that consumers run over their internet connections simply by installing additional software and possibly making arrangements with athird party. or, it may be a valueadded service offered by the broadbandservice provider. in either case, ip telephony provides a way to bypass thelocal exchange carrier for telephone service. price may not be the onlyselling point: because ip telephony permits much more rapid innovationin services, the ease with which new features can be added may prove anadditional customer draw.voice telephony applications do not require especially high bandwidth, with 64 kbpsñor less with compressionñin each direction being10see chapter 4 of computer science and telecommunications board, national researchcouncil, 2001, the internetõs coming of age, national academy press, washington, d.c.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content97sufficient to provide the quality that people are used to from the conventional phone system. but these applications are much more sensitive thanthe pure òlisteningó applications in terms of network delay, jitter, andpacket loss. multiway conference calling raises additional architecturaland performance issues. there are several ways that this can be done: as aseries of pointtopoint connections between individual participants anda control unit, or on a distributed basis using multicasting. for multiwayconference calling control of delay and jitter is even more critical becauseof the number of sites involved. whether meeting these requirements isbest done by increasing network capacity or by incorporating qualityofservice mechanisms into networkñand if the latter, which sort of mechanisms at what places in the networkñis an open question.unlike conventional telephony, ip telephony comes in many varieties. in one major class, conversations are transmitted across the internetendtoend. another possibility is to use ipbased voice service part of theway, perhaps only on the local access link, and connect calls to the traditional voice telephone system through a gateway. here again the keybarriers to acceptance are not bandwidth but the integration of networkbased voice telephony with convenient handsets and òdialingó (call setup)devices. given the popularity of cordless phones, it is unlikely that placing and receiving calls from pcs will find massmarket acceptance (although one might speculate about a pc role as a kind of base station).other features that are important enablers of widespread adoption include the integration of ancillary services such as answering machines,voice mail, caller id, and call waiting.a number of companies have deployed ip telephony solutions, and itis a service that some broadband providers have chosen to add to theirservice bundles. but it is also possible that residential ip telephony mayturn out to be a red herring. voice telephony is important enough to mostpeople that they are not willing to replace it with an unreliable serviceunless there is a compelling economic justification. also, the voice telephone system works wellñit is reliable, easy to use, and inexpensive (andgetting more inexpensive every week it seems, at least within the unitedstates). except for people who are tremendously sensitive to the modestcosts of long distance today (with rates of $0.05 to $0.07 per minute available as part of various calling plans) or who often place costly international calls (where ip telephony can effectively skirt the very steep tariffsstill imposed by some countries), ip telephony may not be attractive unless it comes as an absolutely simple and seamless byproduct of a broadband connection.audio filtering and searching. audio, radio, and telephony are, for themost part, translations of existing applications to the network environbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.98broadbandment. this section concludes with a novel audio applicationñaudiosearching and filteringñwhich illustrates the potential for audio applications to pose considerably greater bandwidth requirements. the fundamental idea behind this class of applications is that one can use a computer program to òlistenó for certain keywords in one or more audiostreams using speech recognition technology. when the program recognizes one of the keywords it is looking for, it takes various actions, such assaving a segment of the audio stream, notifying a person, or putting thestream on speaker. (this, of course, presupposes the availability of largevocabulary, speakerindependent keyword recognition software.) keynetworking issues include how many streams need to be monitored andhow large the streams are.a reason for mentioning this particular application is that for all ofthe other applications discussed here, the number of channels is basicallylimited by the ability of a small number (members of a household, forexample) of human beings to pay attention to the audio streams; even ifthe streams are being recorded for later playback rather than for immediate presentation, a household playing different music in each room andwith four people on the phone could only use on the order of 10 concurrent audio channels. with sufficient computing power, one can imagine asearch application consuming dozens of audio streamsñperhaps evenconceivably hundreds. of course, from the point of view of minimizingnetwork traffic, it might be better to push the searching and filteringapplication into the network, nearer the source of the audio, rather thankeeping it close to the edges of the network. but it remains to be seenwhether the infrastructure will appear to make such efficiencies possible.one advantage of filtering and searching in the home, at the edge of thenetwork, is that one can conduct searches privately. it is also the case thatthe amount of computational power available to search and filter wouldscale much better if provided at the edges of the network than in the core.that is, if streams are available to the edges of the network (say, viabroadcast), then the amount of filtering and searching that can be done islimited only by the number of end points that consumers have. if thefiltering must be done within the network, then the capacity can be moredifficult to grow in proportion to the number of users. these are the sortsof tradeoffs between computing, communications, and storage that inevitably arise when new applications are being envisioned.videovideo applicationsñconsidered broadlyñform a useful complementto the audio applications discussed above in terms of understanding whatbroadband connections may enable and what else other than mere conbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content99nectivity must be in place. in the public mind, video applications areperhaps the premier consumer applications for broadband, and they exemplify the gap between consumer expectations and what broadbandtoday can actually deliver. many people have vague ideas that broadband connections will support multiple channels of ondemand, personalized hdtvquality videoñboth commercially produced content andinteractive videoconference or videophone connections to family, friends,offices, and other destinations. it is not unreasonable to imagine the current or next generation of networks delivering hundreds of channels ofbroadcast video (including payperview), and there has been experimentation with videoondemand delivered from broadband providersõ localcaches, but such services have not been deployed on anything approaching a widespread basis. in practice, most of the video that is available overthe internet for normal users today, even those on a commercial broadband connection, is relatively small images at low and often uneven quality, but improvement in quality over time is expected with improvementsin broadband price and performance. improvements in internetbasedvideo would not necessarily mean that tv will migrate completely to theinternet: some observe that existing television is an effective deliverychannel for passive entertainment, while others anticipate an ultimateconvergence (see box 3.1).in addition to sufficient bandwidth and appropriate means of controlling the displays, the growth and multiplication of video applicationswill be driven in large part by the availability of new capabilities. onesuch capability is inexpensive flat panel displays (or other technologiesdelivering the same functionality, such as projectors of some kind) thatcould be spread throughout the home or office. these technologies couldultimately enable a range of currently exotic applications, from immersivevideoconferencing (where one wall of a room simply seems to open intoanother remote room) to social sharedentertainment experiences (imagine people watching a sports event with friends who are immersivelyvideoconferenced in from a remote location, or a group of musiciansplaying with each other across the internet11). cameras are also an important technological enabler, as many of these video applications involve atleast some inhome origination of video signals. current inexpensivevideo cameras (i.e., socalled webcams) offer only a very small, lowquality image, but the costtoperformance ratio of digital cameras continuesto improve. inhome capabilities for storing and manipulating videoñexemplified by incorporation of video capture and editing capabilities11interactive, networked music performances are already being attempted.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.100broadbandbox 3.1internet, television, and the multiple meanings of òinternet tvótrends in both television and internet technologies make clear that the internetand television will become increasingly intertwined in the future. the label òinternettvó has multiple meanings, all of which deal with some form of convergence between conventional television and internet service. following are the definitions offour principal options:1.delivery of conventional television or internetspecific content over the internet.rather than watching television programs broadcast over the air or over cable, television programs would be accessed over the internet and then watched using eitherstreaming for realtime viewing or file transfers for delayed viewing. today, this sortof content would have to be viewed on a computer, but the technology could beincorporated into future television sets (or provided through an external adapter) tofacilitate television access over the internet.2.adoption of an internetlike (e.g., browser) interface for identifying and selectingtelevision content. in this case, the internet would be used to enable a more interactive approach to controlling the television experience and would supplement thetelevision content with additional information.3.internet content that complements television content. subscription servicesñincluding webtv and aol tvñcomplement the traditional television viewing experience by allowing viewers either to interact with tv programs or to accesscomplementary information via the internet. television stations and networks increasingly also have web sites with information that extends, complements, andpromotes their programs and schedules.4.use of a home tv set to view internet sites, as offered by webtv, perhaps inconjunction with conventional television viewing. these kinds of applications of internet tv create an interactive television experience. this technology could be an intermediate stage toward realizing option 1.source: adapted in part from a. michael noll. 2000. òinfrastructure implications of internettv.ó tv over the internet: implications for infrastructure, content, policy, and strategy. columbiainstitute for teleinformation, new york, november 10.into some personal computers and by the advent of digital video recordersñcomplement the capabilities described above.video applications face many of the same issues as audio applicationsin terms of getting video content to the correct appliances through inhome distribution networksñthe computer, the television, or perhapssome type of òvideophoneó applianceñas well as similar issues of integrating control with actual content distribution. but video permits a number of possible variants with interesting implications for both users andthe broadband providers that carry these applications. these include:broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content101¥interactivity. another trend is toward interactivityñtransformingvideo from a passive experience into an active one. interactive televisionis providing exposure to consumer options for, say, selecting a camera ata sporting event. such early experience with interactivity raises questionsabout the locus of control (at the transmitter or the receiver), the relativecosts of bandwidth and the other technology needed to implement theinteraction, and the potential for approximations to interactivity, such asbroadcast of navigable objects.¥video for social communication. another possibility is the combination of traditional entertainment with social communication. the scenariois that people are watching a sporting event, with the traditional livebroadcast coming into the homeñbut also sharing live video with friendswho are watching the same game at the same time in different cities orsimply different homes. this implies fairly high bandwidth peertopeervideo communication in conjunction with passive video delivery. it is avery different conceptñimplying very different behaviorñfrom todayõsscheduled videoconferences.¥home and community video. developments in video capture andediting technology enable new options for usergenerated video.12 oneobvious application is home movies. another is further decreasing thetechnical barriers to community accesstype video production and delivery.¥large numbers of simultaneous video streams. people can interact withvideo content quite differently from how they interact with audio. oneaudio signal per room (or perhaps one per person if headphones areused) at a time is a basic limitñplaying 10 radio channels at once simplycreates cacophony. but with enough display screens, a room or an individual can make use of many video signals at once. people can dividetheir attention by simply looking from one screen to another. one canimagine people receiving a number of different video signals continuously (for example, multiple tvtype feeds) with the sound usually suppressed. another source of multiple video streams could be a new class ofvideo display devicesñvideo picture frame appliances that periodicallydownload images for display from the internet. with the alwayson capabilities of broadband and an inhome network, one can easily see theseevolving into video portals that look out on favorite scenes, into the homesof family and friends, and the likeñperhaps at fairly high resolution, butwith a relatively low frame rate.12hal varian. 2000. òcool media: a new generation is turning the tables on television.ó the industry standard. november 20, p. 293.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.102broadbandthe mechanics of video deliveryas with audio, video can be delivered through two models: streamedvideo and downloadandplay (file transfer). as with audio, interactivevideo applications require a streaming model. with respect to the download model, video is more challenging than audio is, because the multigigabyte size of a typical video file is large enough that local disk storageñeither temporary or permanentñis a challenge, given the capacityof disks today. simply fetching highresolution video from a disk to display it after downloading is challenging for consumergrade personalcomputers today. moving highresolution video around the home fromone device to another is also problematic, owing to bandwidth requirementsñthis calls for inhome networks faster than those typically purchased by consumers today. for streaming, bandwidth requirements forvideo are much more complex and varied than for audio. this is due inpart to the much larger range of quality tradeoffs and to the fact thatvideo is often accompanied by one or more channels of synchronizedaudio.another complication has to do with the way that video scales. whilean audio transmission is always roughly scaled to the frequency range ofhuman hearing, a video transmission defines a òwindow,ó a rectangle ofpixels that are rendered on some sort of display. if the display has morepixels than the video transmission includes, there are various interpolation methods that can be used to òstretchó the video, but these produceartifacts and quality problems that are quite visible to the human eye ifused too liberally. if there are more pixels in the transmission than thedisplay device can render, there are decimation algorithms that can beused to scale the display down; these are less intrusive than the extrapolation/interpolation algorithms if the degree of downsizing is not too great,and they at least permit zooming (magnification) of particular parts of animage. tv screens define one òstandardó window; computer monitorsdefine a few others, but it is often the case that one is putting multiplevideo windows on a single monitor or tv screen (pictureinpicture). if awide range of flat panel displays becomes commonplace around the home,then matters will become even more complex.within a video transmission window, there are issues of pixel depth(i.e., how much color detail each pixel offers) and of compression withinand across video frames. there are very sophisticated algorithms available to reduce bandwidth through lossy compression, but these can produce visually annoying artifacts. another variable is the frame rateñinessence the number of images that are transmitted per secondñwhichwill determine how much resolution the video transmission can providefor rapid movement and how jerky the playback will appear. some applibroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content103cations may call for very low frame rates, while others may require 30frames per second (a common standard for video) or more to provide asatisfactory viewing experience.latency and jitterñand packet loss ratesñare much more seriousissues for streaming video than audio because of the enormously higherdata rates involved. any kind of delay or packet loss snowballs rapidlyinto a very visible problem (presumably because it is hard to have a bigenough buffer in ram and because there is little redundacy when interframe compression algorithms are used). a body of experience suggeststhat, for many applications, reasonable results can be obtained by givingpriority to a goodquality audio signal and simply doing the best that onecan with video, using the remaining bandwidth. this seems to be true ina great deal of talkingheadtype video and videoconferencing.finally, there are some major shortcomings today in protocols andstandards for managing video delivery. ideally, display devices (or display windows mapped onto display devices) would be able to tell a videosource what their capabilities are. the applications that manage thesedisplays would be able to assign priorities to different characteristics ofthe composite video and audio streams being transmitted to them. at ahigher level, there is a need for identifying which of multiple videostreams need to take precedence at a given moment. and all of this iscomplicated by models that stream video signals into the home through asingle gateway that redistributes the signals to appropriate appliancesusing a home network.with all of these variables, it is hard to tabulate simple bandwidthrequirements for various video applications. there is also more room forsubjective judgment about what constitutes acceptable video qualityñajudgment that is more contentdependent than is the case with audio. inthe audio world, it often suffices to differentiate between requirementsfor voicequality and musicquality audio. in contrast, whereas a videotransmission channel with a given set of parameters may be quite satisfactory for a òtalking headó or a concert but completely unacceptable for asporting event, that channel might be reasonable for a videocamerabasedportal to a remote location that is shown in a digital picture frame butunusable for a videoconference between individuals. another variable isthe impact of audio in improving perceived video quality.telepresencewhen video is considered as a personal communications medium,most people probably think of teleconferencing. however, widespreadbroadband may also make practical a more general capability of telepresenceñhaving a continuous video window open into another space.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.104broadbandwhereas teleconferencing brings to mind a fairly formal notion of communication, similar to a telephone call, telepresence can enable muchmore informal interaction. for example, in a business setting it may enable casual interactions between lab spaces that could permit easier collaborations. though early telepresence trials were constrained by technical shortcomings, this work also pointed to the significant role that socialpractices play in their acceptance and usefulness and suggested that it isdifficult to predict when telepresence applications will be successfullyimplemented.13in a personal setting, telepresence may enable a parent to have acontinuous window on a child at a day care facility, thus enabling a closerongoing relationship, even with working parents. telepresence could possibly enable new forms of extendedfamily relationships over distances.an interesting attribute of telepresence is that it potentially poses higherbandwidth demands than one might expect from videoconferencing applications. this is because the premise of telepresence is that the windowis always open, to enable spontaneous observations and interactions. oneexample that is a simple evolution of telephone use today is school children holding shared homework sessions, connecting their respectivehomes for many hours of working, chatting, and collaborating on assignments.telepresence can encompass not only audio and video, but also haptic interaction, force feedback, and control of remote devices (teleoperation). one especially demanding application of telepresence has been seenin experiments with distributed music performances, which require minimal latency and jitter. telepresence for music is under consideration forconcerts, studio production, and master classes.14thus, the bandwidth requirements for telepresence are not limited bythe number of people actively engaged in watching the video stream atany given moment. one can easily hypothesize the need for more videostreams to be maintained to or from a location than the number of users atthat location. ultimately, such casual realtime applications may drivemuch higher bandwidth requirements.13see steve harrison and paul dourish. 1996. òreplaceing space: the roles of place andspace in collaborative systems.ó proceedings of the acm conference on computersupportedcooperative work cscwõ96 (boston, mass.). acm, new york. draft version available onlineat <http://www.parc.xerox.com/csl/members/dourish/papers/placepaper.html>.14chris chafe, stanford university, personal communication, briefing on digital musicmaking to cstb information technology and creativity committee, january 12, 2001.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content105telemetrytelemetry applications involve primarily numerical data streams.they are expected to grow with the proliferation, and networking, ofembedded computing and communications systemsñsmart appliancesand so onñas well as networking capabilities within and from the home.sensors and controls are being developed for a variety of functions in ahousehold, such as temperature and energy management, utility monitoring, appliance operation, and security. more sophisticated healthmonitoring systems are also being developed. for example, it may becomepossible to undertake skin cancer screening from home, which requiresan ability to capture and send highresolution images.there is growing interest in telemedicine services that require broadband access. possible connections include patienttodoctor (e.g., in ruralhealth care, where travel to the doctorõs office is difficult), patienttophysical therapist (e.g., supporting rehabilitation after a patient returnshome following hip surgery), and patienttofamily (e.g., to allow a familyto watch a newborn in neonatal intensive care).telemetry applications rely critically on the alwayson characteristicsof broadband and the ability of broadband to multiplex many data streams(for example, to allow a medical device or an appliance to emit and transmit a data stream regardless of what else is going on over the broadbandconnection), in contrast to dialup connections. in many cases the datastreams involved are low bandwidth. however, some applications, suchas webcams or healthmonitoring devices that transmit images, couldresult in demand for capacity that is higher upstream than downstream.although primarily deployed for planning communication with a medical service, the same broadband connections might also support emergency response capabilities similar to or enhancing todayõs telephonebased systems. such services presume, of course, reliable alwaysavailableconnections.new kinds of publishingpeertopeer applicationspeertopeer communication was the original design premise of theinternet. particularly with the rise of the web, the focus of communications on the internet shifted to the client server as central web serversbecame the primary residence of internet content. recently, however,peertopeer communications among end systems on the internet has undergone a renaissance, owing at least in part to the grassroots movementtoward sharing content.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.106broadbandnapster, developed as a way of exchanging mp3encoded music files,became a widely used peertopeer content distribution application. byoffloading the file transfer to exchanges between individual computers, itrelies much less on thirdparty servers than would be the traditional practice of many users downloading content from a single server. napster stillrelies on a central directory server to provide people with pointers tocontent, but other peertopeer applications have emerged that largelyremove this constraint. gnutella, for example, is a napster offshoot thatallows users to conduct a search among linked, decentralized computersoffering content; however, it still depends on some means for users toobtain the internet address of at least one such linked computer (whetherthrough a web page, email, or instant messaging). although these recreational services have received a lot of attention,15 and their fate rests inpart on the outcome of litigation and negotiations with the publishingindustry, similar technologies have taken off for research activities.16the motivations for deployment of these applications are several.technical arguments include immunity from singlepoint failure and distribution of traffic load throughout the network. much of the interest innapster has, however, stemmed from another factorñthe relative protection that peertopeer models offer from attempts to control the contentdistribution. a central web server is a relatively easy target if one seeks tosuppress undesired or illegal activityñin the case of napster, the distribution of music in violation of copyrightñwhile a distributed network ofcomputers exchanging files is harder to detect and, because it potentiallyinvolves thousands or millions of participants, to take action against.17there are additional compelling arguments for peertopeer applications. by their nature, they do not require the installation of servers orarrangements with businesses that offer hosting services (or other capabilities). thus they offer a speed and ease of deployment applicationsmuch in the spirit of the internetõs pure endtoend modelña new application depends only on software running on the individual computersand adequate network performance, and not on the installation of software on a hosting server. the appeal is twofold: nimbleness that comesfrom not having to coordinate with any other party when rolling out15similar services have also been introduced, such as aimster, which leverages aolõsinstant messenger for file transfer.16intel has been encouraging such applications through the intel philanthropic peer topeer program (see <http://www.intel.com/cure/program.htm>).17for an examination of technical and other factors surrounding intellectual propertyrights in a networked world, see computer science and telecommunications board, national research council. 2000. the digital dilemma. national academy press, washington,d.c.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content107content or applications, and the freedom and control over oneõs owncontent that come from not having to involve a third party. given suchattributes, pilot efforts are underway to use the technology in business,the scientific community, and so forth.18òlocal interestó content, including videoalthough the mass appeal of communityaccess television is debatable, cable has provided a vehicle for communities, organizations, andindividuals to gain some experience and to experiment with video content production. broadband promises to generalize and build on that experience by enabling a more varied menu of content not constrained byfinite studio and broadcast time slots. in the short term, constraints onlonghaul bandwidth may preclude widearea transmission, but most ofthe interest would be local in any event. localinterest video programming requires high bandwidth within a community, suggesting that it ismost likely to take off with fiber and most likely to be linked early tocommunitywide fiber networks. the traveling parent who wants towatch the local little league game will have to settle for very low qualityvideo, or pay very dearly (if that is even possible, since the limiting factors will be community connectivity to the core net, not just the travelingparentõs connectivity). however, the ability for remote family and friendsto see (literally) local activities is socially valuable; the sharing of familyphotos, web sites for children (beginning prenatally in some instances),and other grassroots activity begun with narrowband suggest the potential for growth.home content hostingthere are many applicationsñdistinguished by their not requiringdelivery of information that changes in real timeñthat lend themselves toeither a model of local hosting or a model in which users upload content18the surge of popularity in peertopeer applications also raises speculative questions ofwhether the internet really is evolving toward being the basis of a distributed computer. ifthe answer is yes, then one might think of computer bus speeds as giving some sort of anupper limit to broadband speeds. today, the 32bit bus of a 1.5ghz pentium 4 runs at 48gbps in both directions (peak, or at least half of that speed in both directions). this viewwould support the eventual migration toward a fiber to each home (which, as is discussedelsewhere in this report, is something that may take some time to happen). there may alsobe an accompanying trend that, as speeds increase beyond the human limits of audio andvideo, the bandwidth demands become more symmetric.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.108broadbandto content servers. these include, for example, web page hosting, makingphotos available for others to download, sharing music. (in contrast, thereis no substitute for upstream capacity for applications that depend ontransmission of delaysensitive realtime content out of the home, as isrequired for telephony, videoconferencing, or webcams. also, home control and other applications that access sensor information and then takecontrol actions must access the actual home.) the contenthosting alternative still requires upstream capacity, but it involves the transfer of contentonly once each time it is modified; those accessing the content downloador stream it from one or more thirdparty servers located somewhere inthe internet.19 use of hosting services is a common practice for both business and personal content, and a number of businesses provide servicesin this area. thirdparty hosting offers several advantages. the provider,who specializes in that sort of service, takes on responsibility for appropriate interconnection and colocation arrangements to ensure good performance for users throughout the internet. a thirdparty hosting provider also generally provides other desirable functionality, such asredundant facilities, backup power, and data backup.the choice between these two alternativesñlocal hosting or use of ahosting providerñdepends on many factors. first, there are tradeoffs,depending on how often things change versus how often they are used.for example, a home webcam might change once per minute and have topush a new image to a server at that point, but if the image is only accessed rarely, then most of those server updates will have been pointlessand the network would be less loaded if users directly accessed the camera. consumer preference, including such considerations as wishing tomaintain personal control over content, also plays a role. the emergenceof a ònapster cultureó suggests demand for the local hosting approach,but the future of this model is unclear, as is the future of peertopeeritself, in part because many of todayõs broadband services provide limitedupstream capacity and because isps may discourage or prohibit usersfrom running their own servers or consuming large amounts of upstreambandwidth. the balance might tip as significantly more upstream bandwidth is made available in the local access segment.19note that this model can also be applied to nearrealtime content, such as audio orvideo broadcasts of live events; one copy of a stream can be pushed out to buffers on localcontent servers for multiple users to access, as demonstrated by akamaiõs technology forstreaming video. however, unlike uploaded content, streamed uploading implies a steadystate demand for upstream content.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content109push contentvarious business models assume an ability for different kinds of parties to push content into homesñthat is, rather than await a specific request, alwayson connectivity would enable these parties to transmit content into homes on a variety of schedules. some of these arrangementswould be highly functionalñupdates to device software, regular and automatic updates to databases maintained in the home, diagnostic probes(which would trigger responses), and so on. other arrangements may bepart of the òpriceó of a device or service, such as advertising.multiplexing applications demand in homesunderstanding how demand for networked capabilities and serviceswill evolve is extraordinarily difficult. it is apparent that there are multiple broadband applications of interest and that some sort of compositeof this is likely to typify future broadband use. to complement rampantspeculation, a number of scholarly and corporate entities have begun todevelop model homes of the future, which are laboratories, showcases, orboth, for potential windows into new options for home life. these possibilities leverage many developments, as explained in a variety of speculative media pieces:the fusion of technology and materials is making new forms possible.add the potential of artificial intelligence, biometric sensing, roboticsand mass customization, and itõs little wonder that designers are imagining a new generation of houses in which people rule their environments, rather than submit to them. weblinked companies already arerolling out model homes with all the clickanddrag amenities availabletoday. they trumpet a lifestyle in which work, play and shopping areonly a palmheld device away. itõs the profusion of gadgets, and thedependence on them and the linkages among them, that will define thefuture of this house.20these visions imply bandwidth demand associated with both individualhousehold members and devices; people will use networks to communicate with each other, and devices will communicate with each other (andwith people) directly, too. the descriptions suggest movement towardmore symmetric communication capabilityñin the limit, equal upstreamand downstream capacityñfor homes; but how much remains an openquestion. in the meantime, the descriptions clearly argue for inhome20linda hales. 2001. òblobs, pods and people.ó the washington post magazine, march 25,p. 37.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.110broadbandnetworking and multiple access points in homes, and suggest choices stillto be worked out about how data is managed in the home. how the dataget sent around or through the home becomes a critical factor in a numberof applications, as does the interplay between storage in the home andremote storage. and whether people will have to reboot their homesunder various circumstances raises other questions, from how to containvarious risks to interactions of the information infrastructure with powersupply in the household to disaster recovery options (familiar to businesses and encouraged by commercial insurance).there are perils in scrutinizing any one application too closely. although it is important to appreciate how the technical requirements ofapplications vary, the promise of broadband is simultaneous support fora large number and a wide variety of applications rather than just one ortwo. moreover, the broadband vision involves several people in a household using different applications concurrentlyñperhaps more than oneapplication per individualñas well as more networkbased interactionamong people in multiple locations (from extended family to work orstudy collaborators to fellow hobbyists). at the same time, people arealready experimenting withñand being subjected to more hype aboutñmobile computing and communications devices. the eventual context forbroadband is thus one of anytime, anywhere networking and an information infrastructure that is pervasive and integral to many places and activities. the individual and social implications of this aggregate of activity suggest new behavioral patterns that themselves may stimulate newapplications. the impact on quality of life can be much greater than thatsuggested by any one application, and its full potential hinges on growthin number of users as well as uses, since some applications involve sharing among households (and/or between households and a variety of public and private institutions).the enabling technology remains only a piece of the picture, of course,and it interacts with expectations for how it would be used. in the committeeõs june 2000 workshop, andrew cohill, speaking from the experience of the blacksburg electronic village initiative in blacksburg, virginia, noted that the aggregate bandwidth demand as conventionalapplications (communications such as telephony and entertainment suchas radio and television) migrate to the internet would exceed the bandwidth available from todayõs dsl and cable services. the expectation forsignificant outflow as well as inflow of content opens up the possibility ofnew kinds of connections from the home to points outside. for example, afamilyõs (or friendsõ and familyõs) virtual private network (vpn) could beestablished to promote social sharing, much as corporate vpns enableprotected communication among coworkers and others granted access,regardless of location.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content111internet appliancesthe majority of existing and potential broadband applications assume a person at the end of the pipe actively using the content beingserved, whether he or she is watching a movie, shopping on the web, ortalking to a doctor. with this assumption, there is a potential upper boundon the demand for broadband, as it is limited by the number of people ina typical home. however, some futurists, as well as some commercialappliance vendors, anticipate a demand that is more accurately boundedby the number of information appliances in the homeñautonomous consumers and producers of content that rely on the alwayson capabilities ofa broadband connection.although the scenario of the dishwasher that independently calls therepairman for service has met with appropriate skepticism, there are already information appliances in the marketplace and in peopleõs homes.internet photo frames are a good example. marketed by various companies, these frames are essentially an lcd (liquid crystal display) with aphone connection packaged as a traditional picture frame. in current versions, the frames connect to the internet at offhours (e.g., 3:00 a.m.) anddownload new photos that have been sent to the appropriate web site byfamily members and friends. a simple extension of this idea would bewall art that loads art pieces from various museum collections.connecting these displays to live content (perhaps including a timedelay) offers the ability of viewing, say, the london skyline and bridgesfresh each day. a poster of africa in a childõs bedroom could be replacedwith live webcam images from safari rides and waterholes.21 returning tothe theme of families sharing photos, appliance designers predict aesthetically pleasing (and privacypreserving) representations of the wellbeing of a loved one. in one scenario, opening the portable photo frame ofa family member while traveling triggers switching an art piece in thehome from blackandwhite to color.returning to the dishwasher, while there are sound objections to appliances requesting people to arrive at the ownerõs home, it is less farfetched for an appliance under warranty to preorder new parts upondetecting a failure, or for prescribed medications to directly request refills. although business models for new internet services (e.g., onlinegrocery reordering) may not work, some extensions to existing servicesmay prove to be economical and desirable.21see <http://www.africam.com>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.112broadbanddistributed work and educationdistributed work and educationñwhich depend on email, file transfer, and sometimes on audio and videoconference capabilitiesñhave longbeen touted as applications for information networks; both have alreadybenefited from narrowband internet access. following significant growthin the 1990s, a sizable minority of companies are believed to offer atelecommuting option to some employees, presumably as a result of theproliferation of personal computing and communications options as wellas the impetus provided by a variety of situations (e.g., california earthquakes) that have increased transportation problems.22 at the same time,there have also been reports of dissatisfaction on the part of both employees and employers.forecasts have included expectations of growing use of multiple media (e.g., enabling simultaneous transmission of data and voice or of atleast two streams of data) and of conferencing involving multiple media,including video as well as audio links. one enabler would be availabilityof connectivity comparable to the 10 mbps typical of lowend office localarea networks, with more symmetric bandwidth enabling more symmetrical use.one small study examined reactions of people working at home to atransition to dsl service and found overall satisfaction based on the increase in their productivity attributed to higherspeed connectivity; peoplealso noted that the productivity benefit depended on whether other homebased workers with whom they collaborated also had such connectivity.23that kind of comment underscores the potential for qualitative change inan activity from widespread availability of a capabilityñchange not visible when availability is unevenly distributed among a population, suchas a group of teleworkers.distributed education, like distributed work, involves remote accessto information and communications. discussions of distributed educationare more likely to involve use of still and moving images with broadband;they also involve conferencing for interaction among multiple students.note that distributed education is expected to benefit both adults andchildren.22patricia riley, anu mandavilli, and rebecca heino. 2000. òobserving the impact ofcommunication and information technology on ônetworkõ.ó telework and the new workplace of the 21st century. u.s. department of labor, washington, d.c. available online at<http://www.dol.gov/dol/asp/public/telework/p23.htm>.23riley, òobserving the impact of communication technology,ó 2000.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content113òtelewebbingóa new sort of composite application that some have begun to callòtelewebbing,ó which combines internet access with conventional television viewing, is beginning to appear. simplistically, accessing the webwhile also watching television would qualify for this description, andindeed it is common for people to engage in other activities while alsowatching entertainment television that has low attention demands. thus,the consumer who scans email while watching a sitcom could be said tobe telewebbing. more interesting, however, are cases now emergingwhere the television watching and web access are interrelated. for example, many sports web sites now provide realtime web applicationsthat feed game statistics to a browser. having such a site open whilewatching a televised sports event provides a deeper experience of theevent. for an even more realtime experience, experiments have beendone with making racecar telemetry information available concurrentlywith a race broadcast. this allows a measure of user selectivity in how therace is experienced, since the user can focus attention on a particulardriver. finally, various levels of viewer interactivity have been evaluatedfor making television game shows (which have long elicited vicariousplayalongathome experiences) truly interactive. all of these ideas involve taking advantage of a second screen that the user can selectively usefor added experiences. importantly, all these applications involve constraints on tolerable latency for the data streams relative to the primaryvideo streams. this class of applications may be another example of wherethe total bandwidth demand to a home may exceed what the user canconsume at any instant because the value of these applications lies at leastin part in the userõs ability to instantly shift attention from one video feedto another screen full of information.communities and community networkscommunity networking efforts to date provide a window into theinteractions and synergistic possibilities presented by greater networkingcapabilities among people in a given area, who presumably have at leastsome shared interest in a common set of information or in communicatingwith each other. with disappearance of a number of the pioneering bulletinboardtype community networks, network communications havetended to become less geographically focused. and as dialup internetaccess via commercial isps has become widespread, community networking initiatives have, for the most part, focused less on building local infrastructure and more on content and services. contemporary approaches tocommunity networks are likely to emphasize a variety of service activitiesbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.114broadbandthat accompany deployment and facilitate use, such as information resources and training, economic incubation, pilot and demonstration projects, and development of publicprivate partnerships. but regardless ofhow it is labeled, the attention to local interests has persisted; it is expressed in the various web sites established by local governments,schools, libraries, athletic consortia, religious institutions, and so onñadiverse group of sources that defies the categorization of the more controlled local access cable television or local radio station and that offersthe potential of upgraded offerings where capabilities are available.note that on a small scale, multiunit dwellings (e.g., apartment buildings) can serve as microcommunities: the availability of broadband toindividuals in the component units is constrained by decision making ofthe owner; where the owner is supportive, all units can have this capability, but the reverse tends to be true as well. also, in some communities,special centers have been established that offer broadband capabilitiestogether with the hardware and software to take advantage of themñaphysical portal.24 these communications centers complement the concentrations of demand in such publicinterest (and often publicly supported)facilities as medical and education centers of different kinds. thus, it isimportant to recognize that community networks have both infrastructural and content dimensions.social factors and impacts of broadbandthere is much potential for future applications that enrich or complement traditional content and communications channels, but excitementabout them should be tempered by an appraisal of the time frame inwhich these applications could be realized and the nontechnical obstaclesthat retard their deployment. much of the expectation surrounding broadband involves more than new technologyñit also requires a transformation of societal structures, media, and other institutions. this sectionbriefly discusses some of these factors.availability of contentone obstacle is the availability of content. a recent television commercial from qwest exemplified the expectationsñbeing able to accessevery book ever published in any language and every movie ever made24richard civille, michael gurstein, and kenneth pigg. 2001. òaccess to what? first mileissues for rural broadband,ó white paper; see appendix c.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content115available, on demand over the internet. in reality, we are some time awayfrom widespread videoondemand; thousands of channels of òradioóover the internet; abundant, highquality educational video content; andso forth.25in addition to technical obstacles, the familiar chickenandegg phenomenon comes into play. without a mass market of consumers withbroadband access, it is hard to develop a business model that justifiesinvestment in new content (or translating old content). one new mediabusinessperson, andrew sharpless, addressed the committee from hisvantage at that time of developing new online services for discoverycommunications. he suggested that at least 10 million households wouldneed to use broadband before meaningful content would emerge, and henoted that cable experience shows that serving 50 million customers iskey to lining up advertisers (with online services, a top rating by jupitermedia metrix had become key to advertiser interest by 2000).26intellectual property rights issues are another large factorñthe interests and holdings of broadband providers, users, and rights holders arenot necessarily aligned. the 20002001 rise of internet radio raised a set ofissues related to content use fees, and the popularity of napster and othercontentsharing technologies heightened rights holdersõ concerns aboutcontrol over their intellectual property, making intellectual property moreprominent in the development of business plans.27finally, although content availability affects demand for broadband,one should not underestimate the volume and value of customerprovided content. broadband is not only a mass media technology; it is alsoan interpersonal technology. as noted above, messaging and email areboth very popular applications, illustrating the value of broadband for25unrealistic expectations have been rampant when it comes to home technology, if notthe internet generally. for example, the washington post published an article in 1994 thatsuggested that going online will not support new relationships, online banking, realtimegameplaying, òbaskingó in multimedia, hobnobbing with celebrities, and online shopping,most of which has, in fact, happened, at least to some degree even with low bandwidth. seejim kennelly. 1994. ò9 ways going online can change your life and 6 ways it canõt,óthe washington post: fast forward, september, pp. 913.26andrew sharpless, personal communication, briefing to the committee, november 1999.he discussed how discovery online scaled back its content expectations because of theseconsiderations.27for an indepth exploration of the issues surrounding intellectual property rights in adigital, networked environment, see computer science and telecommunications board,national research council, 2000, the digital dilemma, national academy press, washington, d.c.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.116broadbandcommunication as well as content delivery.28 multiplayer games, one ofthe few profitable internet applications today, rely on userprovided content. telemedicine will rely, in large measure, on userprovided content,plus some professionally prepared patient education materials. familieswill generate and want to distribute pictures and home movies.broadband impactsone category of impact on quality of life derives from broadbandõsinteraction with consumption of media: broadband is associated with theallocation of more time to media consumption overall, in part because itputs internet use on a par with tv and radio use.29 whether the increasein media consumption is transient or long term, and what it may implyfor (or as a result of) other activities that may receive less time than mediaconsumption, remain to be seen. it is not known whether the home istruly an infinite sink for bits over time or whether there is some limit thatone can compute, based on something like human perception or expectations about other things going on in the home. in terms of general information access, one could argue that broadband provides limited contentbeyond that available through dialup. there is little unique content available only to broadband users that is not duplicated on cable televisiontoday (e.g., cspan). in terms of applications, the prominent examplesdeal with entertainmentñaccess to interactive games, or even a broaderassortment of music than one can find on the local radio channels isunlikely to compel public policy support, but these applications, alongwith daytrading tools and ecommerce, exercise the technology (and,sometimes, the law) and build an experience base for the underlyingcapabilities.30 attention to individual categories of information or applications can obscure the larger development, which is a shift to an expectation of ubiquitous access to a variety of information and applications. butubiquity does not imply endless variety: experience with television shows28some argue that the value of communications applications such as messaging isunderappreciated compared to content delivery. see andrew odlyzko. 2001. òcontent isnot king.ó first monday 6(2)(february). available online at <http://www.firstmonday.org/issues/issue62/odlyzko/>.29pierre bouvard and warren kurtzman. 2000. the broadband revolution: how superfastinternet access changes media habits in american households. arbitron company, new york.available online at <www.arbitron.com> and <www.colemanresearch.com>.30one might draw a limited analogy to the supply of simple games with the windowsoperating system and palm devices to help people get used to manipulating a mouse in theformer case and the graffiti writing system in the latter.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content117that consumers limit themselves to seven to nine channels, implying highcost in searching for acceptable contentñand that aids in effecting suchsearch may be an important complement to content innovations per se.the oftmade contrast between children who are exposed to computerbased technology early on and adults who are introduced to it at olderages underscores the potential for cumulative experience to change peopleõs expectations and behavior.several emerging applications described above may be more compelling from a policy perspective. telecommuting can have positive impactson the environment, local economies, and peopleõs ability to earn a goodliving. telemetry and monitoring applications can enhance health caredelivery. basic communications and telepresence applications can helpkeep children and elderly parents connected. and broadband can be usedto deliver more sophisticated (multimedia and interactive) educationalcontent. but many of these applications remain more promise than reality.there is time to consider and act on possible negative impacts (fromthe obvious questions about privacy and security to the more idiosyncratic ones relating to cases of excessive use). for example, public andprivatesector attempts to deal with spam originating in the narrowbandcontext are likely to take on new urgency in the broadband context. if anykind of communications of the past is any guide, people will send information whether there is demand or not, and the prospect of video spammay arouse people even more than fax and email spam have. securityconcerns have arisen, associated with the alwayson nature of broadband.but with anticipated assimilation of broadband into a technologyintensive household, other concerns will arise. for example, just as peoplechange physical locks after, say, a divorced spouse leaves, a kind of virtual door is developing with broadband, and there may be a kind ofvirtual set of keys to change, too. this is also a time to address the implications of technology options for the disabled: some of the envisionedcapabilities will make it easier for people with disabilities to remain intheir homes; some may require appropriate design for effective use bypeople with disabilities. consideration of differences in abilities leadsnaturally to consideration of humancomputer interaction and user interfaces; progress in these areas may facilitate use by all.while the lag in compelling applications may contain growth in demand for broadband, its silver lining may be to limit the impact of disparities in access and use. measurements of the disparity are in flux,given progress in deployment and adoption, but significant differenceshave been noted by region, locality, racial and ethnic groups, income,educational attainment, and age.31 income and educational attainment31see ntiaõs falling through the net series.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.118broadbandtend to drive demographic differences; geographic differences reflect thelarger complex of factors governing deployment discussed in chapter 4.progress implies deeper understanding of differences in media consumption among population groups and options for diminishing disparities.consumer advocates report an overall bimodal pattern, with clusters oflowvolume and extremely highvolume users of media and differencesin terms of what people use communications for. the bottom half pays$60 per month for all services, while the top half pays $200 per month.different business models are needed to serve the lower half, and observable business models for broadband seem to focus on the upper, morelucrative half.32 of course, it is reasonable to expect that during the transition from broadband, even people who could shift will not do so at once,and those who do so first value the capabilities more and will pay more.the picture painted in this chapter, of multidimensional change inhousehold technology and activities, suggests that raising the floor forresidential broadband implies addressing total and lifecycle costs. thatis, the broadbandenabled changes in lifestyle and quality of life thatcould occur presume both network deployment and consumer electronicsand applications (software, services), all of which may impinge on household budgets (for acquisition and operation or regular use costs) andrequirements for knowhow (the aggregate of technologies and activitiesimply new setup, use, and maintenance activities). the full, short andlongterm impacts on household economics deserve further study, perhaps in conjunction with the model homes and communities that havebeen or will be initiated. for example, for connectivity alone, it would beuseful to compare the costs of various scenarios, from current options,such as multiple phone lines plus cable or satellite, to broadband connectivity (with or without additional home connections), with different approaches to inhome networking and customer equipment. business models make different assumptions about demand and willingness to pay.33understanding the implications of alternative approaches is a logical element of public and privatesector planning. the combination of failuresand successes in internetrelated and, more generally, mediarelated services underscores a dearth of social science insight into how people useand respond to new media.32gene kimmelman, consumers union, personal communication, briefing to the committee, november 1999.33for example, time warner cableõs $40 per month charge was based on the recognitionthat consumers were paying $19.95 per month to an isp and more for a second phone line.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband applications and content119finally, there are the uncertainties relating to what people want andwill do. assimilation of these changes, of course, presumes assuring thatthe use of these capabilities is perceived as valuable (appealing and relevant) to multiple categories of people. historically, with television, whichwas fundamentally familiar, the introduction of paytv programmingled to consumers often electing to buy multiple services, which are differentiated. the new, nonincremental and interacting broadband optionsare less familiar than were variations on the tv theme. there is someevidence that willingness to pay increases with consumer control: in thecommitteeõs june 2000 workshop, for example, at&t researcher andrewodlyzko compared peopleõs willingness to pay $40 per month for cablefor 100 mbps consumed 3 hours per day with $70 per month for wirelinephone for 64 kbps used 1 hour per day with $40 to $50 per month forwireless phone for 8 kbps used less than 10 minutes per day. this line ofargument complements that of consumer advocates and others who argue for open access (see chapter 5 in this report), as a counter to a fearthat content coming into the home will be overly controlled by commercial providers. it is not surprising that local efforts that link deployment toeconomic development tend to feature awareness and training programs,34 while various nonprofit and entrepreneurial efforts seek to generate content that is of interest to specific demographic groups. recognizing that socioeconomic context affects willingness and ability to use newtechnology does not necessarily make it easier to devise effective strategies, and trial and error is evident.34glasgow, kentucky, was a pioneer in providing broadband, but the experience showedslow adoption and uncertainty about why the capability should be used, necessitating efforts to generate awareness, interest, and use. see anick jesdanum. 2000. òwiring ruralamerica: just the beginning.ó associated press, september 6. available online at <http://www.msnbc.com:80/news/452691.asp?cp1=1>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.120although great technical and business strides have been made inimproving the data transmission speeds of communications networks,the local access technologies that make up the last (or first) mile connections in the network have mostly lagged far behind. enhancing the localaccess infrastructure to bring highspeed services to residences and smallbusinesses requires upgrading or building infrastructure to each premisesserved. there are a variety of technology options with different characteristics and cost structures and variation in willingness to pay among potential customers. this chapter explores the characteristics of the variouslocal access technologies and the interplay among relevant economic considerations.local access technologies in contextwhile this chapter focuses on local access, the other network elementsthrough which content, applications, and services are provided also contribute to the total cost and performance characteristics of broadbandservice. local access links carry communications to and from points atwhich communications from multiple premises are aggregated and funneled onto highercapacity links that ultimately connect to the internet orother broadband services. the first point of aggregation, also known asthe point of presence, is most commonly located at a telephone companycentral office, cable system head end, or radio tower (which may be at aconsiderable distance from the premises) but may also be in a piece ofbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors121equipment in a vault, pedestal, wireless antenna site, or poletop devicelocated nearby to the premises. circuits installed or leased by the provider in turn run from the point of presence to one or more public orprivate access points for interconnection with the internet. the socalledsecond mile connects local access facilities with upstream points of aggregation. in connecting to the internet, broadband providers either pay fortransit service or establish peering agreements with other isps to exchangetraffic on a settlementfree (barter) basis. caches, email and content servers, and servers supporting specialized services such as videoondemandor voice telephony are located at points of presence and/or data centers.routers located in points of presence and data centers take care of directing data packets on to the next point in the crossnetwork trip to theireventual destination.essential features of the local accesstechnology optionsthe future of broadband is sometimes described as a shootout amongcompeting technologies that will result in a single technology dominatingnationwide. this view, however, is simplistic and unrealistic; there is nosingle superior technology option. broadband is going to be characterizedby diverse technologies for the foreseeable future. there are a number ofreasons for this:¥incremental investment in existing infrastructure. while some firmsmay have access to large amounts of venture capital, the expectations ofinvestors in existing firms is for shortterm payoffs. as a result, the technological approach chosen by an incumbent is likely to make use of existing equipment and plant, and the deployment strategy must be amenableto incremental upgrades. the infrastructures of the various incumbents inthe broadband marketplaceñtelephone local exchange carriers with copper loops, cable television companies with coaxial cable, cellular companies with towers for pointtopoint wireless telephonyñwill continue tomake incremental improvements unique to their respective technologiesto provide and enhance broadband services.¥continued exploitation of skills. technologies require distinctive skillsand knowledgeñthose needed, for example, to design, launch, and operate a satellite. similarly, cable and telephone companies understand thetechnological challenges associated with their respective systems. companies that know how to do one or another thing well will attempt to findmarket opportunities where these skills give them an advantage.¥different demographics and density. the united states (and world)population is very diverse in topography, density, wealth, and demandbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.122broadbandfor communications services. the particular economic and technical characteristics of each broadband technology will provide specific advantagesin serving certain geographical areas or demographic groups. some mayhave an economic advantage in particular locales owing to the nature ofthe infrastructure already in place or to inherent physical attributes of theenvironment. planning should reflect the existence of a diverse set ofsolutions that depend on particular circumstances rather than a technology monoculture.this section discusses the salient characteristics of each technologyoption and provides a brief road map of how existing technology andanticipated research and development will play out in coming years.wireline optionsin rough terms, access technologies are either wireline or wireless.wireline includes telephone network copper pairs and the coaxial cableused for cable television service. incumbent telephone companies andcable operators are both in the process of upgrading their infrastructuresto provide broadband services. wireline infrastructure is also being builtin some areas by socalled overbuilders, who are building new wirelineinfrastructure in competition with the incumbent wireline providers. inthe united states, this has largely been through deployment of hybridfiber coax to provide some mix of television, data, and voice services.there are also a few overbuilders that are using or plan to use fiber.the wireline technologies all share the feature that labor and access toa rightofway are significant components of the cost. these costs aremore significant where infrastructure must be buried than where it can beinstalled on existing poles.1 the other major component is the electronicsat each end of the line, where costs are subject to rapid decreases overtime as a result of mooreõs law improvements in the performancetocostratio and increasing production volumes. labor, on the other hand, is notsubject to mooreõs law, so there is no obvious way within the wirelinecontext for dramatic declines in cost for new installation (though onecannot rule out very clever solutions that significantly reduce the laborrequired for some elements of the installation).1one estimate provided to the committee is that aerial installation is almost twice asinexpensive as when the infrastructure must be buried.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors123hybrid fiber coaxcable systems pass 97 percent of the homes in the united states.2 theolder generation of cable technology uses a branching structure of coaxialcables fanning out from a central point or head end to the buildings in acommunity (see figure 4.1a). the older systems rely on long chains ofcoaxial cables and amplifiers, with each segment feeding into a smallercoaxial segment.hybrid fiber coax (hfc) is the current generation of cable systemtechnology. hfc systems carry analog signals that feed conventional television sets as well as digital signals encoded onto analog signals thatcarry digital video programming and up and downstream data. in thenew architecture, the system is divided into a number of small coaxialsegments with a fiber optic cable used to feed each segment or cluster. byusing fiber instead of coax to feed into neighborhoods, the systemõs performance and reliability is significantly improved.another benefit of an hfc upgrade is that the resulting system cancarry twoway data communications, such as internet access. additionalequipment is installed to permit information to flow both to and from thehome (see figure 4.1b). internet service is provided using a device calleda cable modem in the home and a device known as a cable modem termination system in the head end. the ability to offer competitive video,voice, and highspeed data services using the present generation of technology has attracted several nonincumbent companies to enter a few markets as overbuilders using the hfc technology.over 70 percent of the homes in the united states are now passed bythis upgraded form of cable infrastructure. the fraction of homes servedby hfc is continuing to increase as cable companies upgrade connectionsto all homes in their franchise areas and can, with continued investmentin upgrades, increase until it approaches the 97 percent of householdsthat currently have cable service available at their property lines.a technology standard for cable modems known as docsis has beenadopted industrywide. developed by an industry consortium seeking aquicker alternative to the more traditional standards development process then underway under the auspices of the ieee, the docsis standardis stable, and more than 70 modems have been certified as compliant.standardization has helped modems become a massmarket product. thestandard provides consumers the assurance that if they purchase certifiedmodems at retail, or have them built into pcs or other appliances, cableoperators will support them across the country. further helping pushdown costs, several competing suppliers have developed highly inte2paul kagan associates. 2001. the kagan media index, jan. 31, 2001.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.124broadbandhead endrf amplifiertrunk cable(coax)40+ amplifiercascades commonhead endoptical nodeoptical cable500 homes passedtypically 6 orfewer amplifiersin cascadefigure 4.1evolution of cable systems to support twoway data. source:james chiddix. 1999. òthe evolution of the u.s. telecommunications infrastructure over the next decade. ttg2: hybridfibercoax technologyó (ieee workshop paper).(a) tree and branch architecture(b) hfc architecturebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors125grated silicon, and singlechip docsis solutions are available to modemmanufacturers. with increasing volumes, a single standard, and singlechip solutions, the cost of a cable modem at wholesale has alreadydropped to $150 or less and can be expected to continue to drop as volumes increase.digital subscriber linedigital subscriber line (dsl) is the current method by which twistedcopper pairs (also known as loops), the decadesold technology used bythe telephone companies to reach the residence, can be upgraded to support highspeed data access. in some newer builds, analog transmissionover copper wire is only used between the premises and a remote terminal (which may be at curbside or, more commonly in a pedestal or underground vault within a neighborhood), while a digital loop carrier (dlc)generally using fiber optic cable connects the remote terminal with thecentral office. in a traditional, allcopper plant, the first segment of theloop plant is referred to as the òfeeder plant,ó in which hundreds ofphone lines are bundled in a cable that runs from the central office to asmaller distribution point. from the distribution point, smaller cablescontaining fewer phone lines run to pedestals or cabinets within a neighborhood, where they in turn connect to the twisted pairs that run to thecustomer premises (see figure 4.2).all transmission of data over wire involves coding these data in someway consistent with the carrying capacity and noise conditions of thewire. the familiar dialup modems code (and decode) data in such a waythat the data can pass through the traditional switches and transmissionlinks that were designed to carry voice, which more or less limits speedsto todayõs 56 kbps. dsl uses an advanced coding scheme that is notcompatible with existing switches. consequently, new electronics knownas a dsl access multiplexer (dslam) has to be installed in any centraloffice where dsl is to be offered. the dslam must in turn be connectedto a switched data network that ultimately connects the central office tothe internet (see figure 4.3). dsl service enables the transmission ofpacketswitched traffic over the twisted copper pairs at much higherspeeds than a dialup internet access service can offer. dsl can operate atmegabits per second, depending on the quality and length of the particular cable. it is thus the upgrade of choice to bring copper pairs into thebroadband market.dsl standards have existed since 1998, and new versions of thesestandards, which add enhancements to asynchronous transfer mode(atm), ip, and voice services over dsl, are expected in 2001 or 2002 fromthe international telecommunication union (itu). large interoperabilitybroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.126broadbandprograms with dozens of qualified suppliers have been implemented bythe dsl forum, which has about 400 member companies. the forumdevelops implementation agreements in support of interoperable dslequipment and services and acts as an industry marketing organizationfor dsl services, applications, and technology for dsl in general. also, tohelp reduce the cost of asymmetric dsl (adsl) deployment by specifying a common product and increasing volumes, several companies formeda procurement consortium.the present generation of dsl products can, depending on line lengthand conditions, reach 1.5 to 8 mbps downstream and 150 to 600 kbpsupstream in the near future. the present generation of dsl technologyaimed at residential customers, adsl, currently supports a typical maximum of 8 mbps downstream and 800 kbps upstream (different flavorsdeployed by various providers vary somewhat). a related flavor, g.lite,which makes compromises in order to permit customer selfinstallationon the same line being used for analog voice service, supports up to 1.5mbps downstream. (another variant, symmetric dsl [sdsl], supportsmaindistributingframesaifeederdistributionpedestalsniddrop wireinside wirecustomerpremises20,000 to160,0001,500 to 4,000200 to 8004 to 12number of lines present at a site22,000 ft9,000 ft3,000 ft500 ftwire length to customer (90th percentile) central office equipmentfigure 4.2telephone company copper loop plant. source: adapted from afigure supplied by john cioffi, stanford university.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors127higher, symmetric speeds.) all of these speeds are maximumsñthe actualspeed obtainable over the dsl link depends on line length, noise, andother aspects of the line condition as well as on the maximum speedsupported by the particular service that a customer has subscribed to.higherspeed versions of dsl, known as very high data rate dsl (vdsl),are in development. these depend on investment in new fiber in the loopplant that shortens the copper loop length to enable higher speedsñtensof megabits per second in both directions. figure 4.4 summarizes the rateand distance tradeoffs for the various flavors of dsl.dsl is available to a large fraction of homes and businesses in theunited states over normal phone lines (the exact fraction is hard to determine because of the factors discussed below). however, not all of thehomes that are passed by telephone cables easily support dsl, and somehomes cannot be offered dsl service at all without major upgrades to theinfrastructure. certain pairs are unsuited for such upgrades because ofhow they were engineeredñfor example, using bridge taps or loadingcoils. also, where the loop between central office and premises includes adigital loop carrier, the remote terminal equipment must be upgraded togateway(s)dslammuxordemuxadslmodemadslmodemadslmodeminternetserviceproviderssplitpotsnetworktelephone company officedigitaldigitalfigure 4.3dsl connections at the central office.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.128broadbandsupport dsl. more significantly, dsl does not work over wires longerthan a certain distance (18,000 feet for the primary flavor used for residential service today, adsl). it should be noted that wire lengths are substantially shortened by the deployment of remote terminals.crosstalkñthe coupling of electrical signals between nearby wiresñgives rise to interference that degrades the carrying capacity of each copper pair. the level of crosstalk depends on the number of pairs within thebundle carrying dsl, their proximity, and the power and bandwidthsthey use. it is even possible for dsl signals from adjacent lines to createsignals larger than the intended dsl signal on the line. the interferencehas the effect of reducing the maximum data rate at a particular loopfigure 4.4rate and maximum distances for various flavors of dsl. source:adapted from a figure provided to the committee by ted darcie, at&t research.222018161412108642isdn(duplex)adsl(for 640 kbps upstream)radsl(maximum/ideal conditions)vdslvdslvdsl110100downstream data rate (mbps)distance (1,000 feet)6.144 mbps down640 kbps up broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors129length (or the maximum loop length for a given data rate). in essence, anissue of spectrum sharing within the cable bundles arises. the term òspectrumó is appropriate because the crosstalk and interference effects depend on how the signals on the different pairs make use of the differentfrequencies used for transmission over the lines. today, incumbents andcompetitive providers using unbundled loops are free to choose among anumber of flavors of dsl, without regard to how the spectrum used byone service affects services running over other copper pairs.at the request of the fcc, a working group of carriers and vendorsworked to develop a spectrum management standard for dsl. the present standard, released in 2001, places forwardlooking limits on signalpower, bandwidth, and loop length.3 by establishing thresholds withwhich the current dsl technology is generally compliant, the standardseeks to prevent future escalation (where each dsl product or servicewould try to òoutshoutó the others) and thus place a bound on the levelof crosstalk that will be faced in the future. while the standard is currently voluntary, it is generally expected that it will provide the technicalbasis for future fcc rulemaking. issues that the standard does not addressñwhich are being explored by a network reliability and interoperability council subgroup under american national standards institute (ansi) t1 auspices that is developing guidance to the fcc oncrosstalkñinclude how many dsl lines are permitted per binder group,what standards apply to lines fed from digital loop carriers, how productsshould be certified or selfcertified, and how rule compliance should beenforced.advanced wireline offeringsñfiber optics in the loopoptical fiber has a theoretical capacity of about 25,000 ghz, compared to the roughly 155 megahertz (mhz) possible over short copperpairs, the roughly 10 ghz4 capacity of coaxial cable. (the relationship3working group on digital subscriber line access (t1e1.4). 2001. american national standard for telecommunicationsñspectrum management for loop transmission systems (t1.4172001). standards committee t1. alliance for telecommunications industry solutions, washington, d.c.4the practical upper limit for data transmission over coaxial cable has not been wellexplored. the upper cutoff frequency for a coaxial cable is determined by the diameter ofthe outer copper conductor. smaller cables (1/4inch to 1/2inchdiameter) probably havea cutoff frequency well in excess of 10 ghz. it is unclear what the upper limit is on modulation efficiency. the 256 quadrature amplitude modulation (qam) currently in wide useallows 7 bits per hertz, but in short, passive runs in neighborhoods, much more efficientmodulation schemes are possible, suggesting that hfc could evolve to speeds exceeding100 gbps to small clusters of customers.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.130broadbandbetween hertz and bits per second depends on the modulation scheme;the number of bits per hertz typically ranges from 1 to more than 7.) thisvery high capacity and consequent low cost per unit of bandwidth are theprimary reasons why fiber is preferred wherever individual demand isvery high or demand from multiple users can be aggregated. other considerations in favor of fiber include high reliability, long service lifetime,5protocol transparency, and consequent futureproof upgradability.6 thus,fiber predominates in all of the telecommunications links (voice and data)except the link to the premises, where cost considerations come into playmost, or for untethered devices. because of their large demand for bandwidth, an increasing fraction of large businesses is being served directlyby fiber links. there is also increasing attention to fiber technologies forlocal area and local access networks, as evidenced by recent developmentof new technologies such as gigabit ethernet over fiber.one important use of fiber for broadband is that of increasing theperformance of other wireline technologies through incremental upgrades. both hfc systems and dsl systems benefit from pushing fiberfurther into the system. to increase the performance of dsl, the copperlinks must get shorter. as penetration and the demand for higher speedincrease, the upgrade strategy is to push fiber deeper, with each fiberfeeding smaller service areas in which shorter copper connections run tothe individual premises. so a natural upgrade path for copper infrastructure is to install electronics ever closer to the residence, to a remote terminal located in a pedestal or underground vault or on a telephone pole; torun fibers from the central office to this point; and only to use copper5in the 1970s, researchers worried about the possibility of fiber degradation over time. anumber of experiments were conducted and no degradation effects were found. thusñbarring an accidental cutñthe only reason fiber is replaced is when some new transmissionscheme reveals the old fiber to have too much eccentricity of the core or too much materialdispersion. these factors have only come into play in very particular situations. for example, when oc192 (10 gbps) transmission was introduced, there were concerns that oldfiber with an outofround crosssection would cause problems. but in the end, only alimited amount of fiber required replacement to support the new, higherspeed transmissions.6òprotocol transparencyó refers to the ability to run any communications protocol overthe fiber by changing the end equipment and/or software. other communications mediadisplay some degree of protocol transparency, but with fiber, the large rf spectrum on anindividual fiber is entirely independent of other fibers (in contrast to dsl, which hascrosstalk issues; wireless, which has obvious spectrumsharing; and hfc, which also hasshared spectrum). this transparency property only holds true over the fiber segments thatare unsharedñwhere passive splitting is done, all must agree on at least the time divisionmultiplexing (tdm) or wavelength division multiplexing (wdm) scheme, and where active switching is used, all must agree on the packet protocol. true protocol transparencyñand true futureproofingñis thus greatest in a homerun architecture.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors131between the remote terminal and the home. similarly, to deliver higherperformance over hfc, the number of subscribers in each cluster mustshrink, so that the total capacity of a single coaxial segment is shared by asmaller number of subscribers and the persubscriber performance goesup. this also requires that fiber be installed farther out into the distribution tree.7a basic upgraded architecture is apparent: fiber optic cables radiateout from a central office or head end to local distribution points that servesmall clusters of buildings. at each cluster, a relatively compact set ofelectronics couples the fiber to a local distribution plant. for hfc, a shortsegment of coax runs from this distribution point to feed a cluster ofhomes, while for dsl this is a short copper twisted pair. as the clustersize continues to decrease, from the hundreds of homes commonplace inmuch of the industry today down to tens of homes, hfc and copper pairsystems will come to resemble each other. the networks will not, to besure, be the same in all details. for example, different networks will havedifferent òactive elementsó in different parts; some networks will haveactive switching deep into the network, while cable networks will likelyplace less emphasis on remote switching in favor of carrying traffic backto the head end before aggregation or routing. where active componentsare located has implications for where power must be delivered, and thusimplications for cost, ease of installation, and so forth. but the essentialfeature is a continuing trend toward pushing fiber deeper into networks.fibertothecurb (fttc) is a general term for this class of system.fttc is also a label for a specific class of technology that makes extensiveuse of fiber for local distribution and that local exchange carriers are usingto build or rebuild their telecommunications. a technology being used innew construction today, it will in turn be a basis for incremental upgradesof the telephone infrastructure in the future.whether as the final upgrade step in the incremental path describedabove or for installation by another player, another alternative is to runfiber to the premises themselves, dubbed fibertothehome. the termftth encompasses multiple architectures. the factors that control whatspeeds are actually provided are the technology components that are7deployment of fiber deeper into incumbent telephone networks also raises interestingquestions about how one would implement unbundling, which was originally premised onunbundling a copper loop running from the central office to the subscriber. issues such ascolocation become more complicated when the loop terminates at a curbside pedestal orcontrolled environment vault. colocation is even more complicated if fiber is pushed deepenough that it reaches to the poletop or even into the home. aesthetic and practical concerns limit the size and number of these remote terminal units, which in term complicatesthe provision of colocation space.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.132broadbandinstalled at the end points of the fiberñthe residence and the serviceproviderõs point of presence, which may be located at a head end, centraloffice, or remote terminal. the three principal forms of ftth are these:¥òhome runó systems, where there is a separate fiber or fiber pair thatruns all the way from each residence to the central office or other point ofpresence. because there is no sharing of fibers, this scheme has a highercost of installation, but offers the highest ultimate performance with theappropriate system design and terminal equipment and the most flexibility. providers can deploy the technology of their choice independent ofother providers (there are no spectrumsharing issues, as is the case, forexample, with wireless, and no crosstalk problems, as is the case withdsl). also, the endpoint equipment attached to each fiber (at the centraloffice and home) can be upgraded independently.¥the passive optical network (pon) architecture, in which a singlefiber runs from a central office to a simple optical divider, called a passivesplitter (hence the òpassiveó in pon), which may be quite compact, fromwhich individual fibers in turn run to each of a group of homes. theabsence of active electronics in the field and the overall simplicity yieldlower lifecycle costs.8 the pon architecture also avoids the complications and expense associated with providing robust power at the remoteswitching point. unlike switched fiber or home runs, the format of theinformation on the different paths in a pon system is not totally independent. this implies that there may be some upgrade strategies that are notbackwardcompatible and would require simultaneous upgrades of headend and terminal equipment. just how must flexibility for upgrade andchange is available in a pon system depends on the details of the design.as part of an effort to reduce costs, an atmspecific realization of thepon architecture has been standardized in the itu (the full service access network or atm pon standard).¥ftth systems with fully active (electronic) elements in the path from thecentral office to the residence, in which fiber runs from the central office toone or more stages of remote terminals at which the signals are switchedamong fibers that go on to feed individual premises. two examples of thisapproach are switched ethernet and hfc using active switching.switched ethernet systems are beginning to be used by companies providing fiber to the home and businesses, extending what is normally alocal area network technology over a metropolitan area. hfc systems ofthe future, instead of using a passive splitter, might have a fiber connect8paul shumate provided estimates to the committee of 20 percent lower capital expensesand a $500 lifecycle cost savings.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors133ing to some electronics that serves a small cluster of homes, using fiberinstead of coaxial cable to connect to individual homes. unlike the othertwo architectures, this approach requires special attention to how topower the remote switching points, especially where reliability requirements (and associated regulatory requirements) demand robustness inthe face of power grid failures.these various forms of ftth have different cost structures and presentdifferent opportunities for incremental upgrade.ftth is seen by some as the òholy grailó of residential access. from atechnology perspective, it is a highperformance end point, with enormous headroom for future upgrades. as a result, the sentiment is oftenexpressed that the nation should strive to deploy that solution directly,without spending time and diverting investment dollars in intermediatetechnology of an incremental nature that might, eventually, be obsolete.from a business perspective, a direct move to ftth raises severalissues. there is a significant investment in telephone and cable infrastructure that can meet many of todayõs broadband internet access needs withmodest incremental expense.business choices among the alternatives thus hinge on such factors asthe investment horizon and forecasts for bandwidth demand. while bothdsl and hfc can evolve toward higher performance, it is still unclearwhether the pace of improvement in these technologies will continue tomeet customer needs. a second issue is whether the performance benefitsof ftth over those of other alternatives would be of sufficient value toconsumers to support the prices needed to cover the at least somewhathigher costs. the familiar case of the recent slowdown in new pc salesmay offer a useful illustration of this point. new pcs are faster and havea variety of capabilities that older models do not, but it seems, at least atpresent, that many buyers find the older models more than adequate forwhat they want to do. if this is the case, then some new, compelling set ofapplications that requires those capabilities will have to emerge to reallyboost pc sales.the total cost of deploying ftth is, of course, substantial, involvingboth the basic costs associated with wireline infrastructure deploymentand the premium associated with fiber. areas being newly developed (socalled greenfield areas) offer an especially attractive market for fiber, tothe extent that the additional costs are modest compared with the basicinstallation costs of any local access technology. indeed, the total lifecycle costs for fiber are believed to be lower than the costs of alternativesfor new installations. when new wireline infrastructure is installed (e.g.,in a new housing development), ftth at present costs more to install, byat least several hundred dollars a home, than alternatives. the total costbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.134broadbandincludes the costs of installing the wireline itself (digging trenches, hanging on poles, and so on), which are similar in magnitude for any wirelineoverbuilder whatever the specific technology.unlike copper wires or coaxial cable, however, nonhomerun fiberarchitectures require that fiber be spliced together. splices are more timeconsuming than electrical connections and require specialized expertiseand/or complicated equipment to produce. not surprisingly, this hasbeen an area of considerable attention, and increasingly sophisticatedtechniques and equipment have been entering the market, but costs remain higher. the significant improvements made in splicing technologyand techniques over the past few years mean that this is likely to becomeless of an issue; moreover, homerun ftth systems do not require splicing in the access network. in addition, there are increased costs associatedwith the terminal equipment (the lasers and other electronics that transmit and receive light signals over the fiber). costs here exceed those ofterminal equipment for dsl or hfc, in part because of the higher costsassociated with the optoelectronic components and in part simply because of lower product volumes typical of any new product. there havebeen significant improvements in the cost and performance of fiber distribution technology over the last few years as a result of technical advancesand increased deployments in gigabit ethernet, wavelength division multiplexing (wdm), passive optical networks, and optical switching, butthere is still a good bit of room for cost improvements in terminal equipment, splicing, and trenching.a small number of new private sector entrants are planning or starting to deploy ftth as an overbuild. for them, becoming a facilitiesbasedprovider would require installing infrastructure in any event. in addition,the higher performance potential of fiber and, in light of its longevity andfutureproof quality, a total lifecycle cost not dissimilar to that of alternatives, are viewed as giving these entrants a competitive advantage in themarket.other deployments are taking place in a different economic context;these include, for example, municipal deployment; deployment as a partof new residential construction; or deployment as an offshoot of fiberinstallations for government or business customers. these scenarios alterthe economic calculus and hence the set of technology choices that can bejustified. once the high upfront costs of laying fiber are paid, the incremental costs for upgrades are predominantly persubscriber and not perpassing. in return for the high initial investment comes a measure of futureproofing, as the same fiber can provide decades of useful service.this sort of economic model will make sense for an investor with a longinvestment horizon. for instance, it may be attractive to a municipalitythat has to float a bond issue for a onetime investment, and then live withbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors135the resulting investment for the life of the bond. the technology alsoallows the municipality to place responsibility on the individual consumer to make any future incremental investments. it might also makesense for an individual to finance the fiber installation, much as housesare financed through decadeslong mortgages. this economic modelmakes much less sense to a corporation seeking to make continuous incremental investments with a goal of showing shortterm returns each quarter.in the long run, all the wireline alternatives have the option of converging on ftth, if the market demands it. for those with existing infrastructure, the issues are the incremental costs of getting there and thequestion of whether the intermediate steps are sustainable. for those contemplating installing new infrastructure, the issue is the costeffectiveness of fiber compared with other technology alternatives available tothem, and whether fiber offers them sufficient advantage in the marketplace.powerlinethe pervasiveness of powerlines has led to consideration of usingthem to provide broadband connectivity to the home and within the home,with speeds of 20 mbps and 1 mbps, respectively, typically envisioned.several experiments have been conducted9 and proposals have also beenmade to develop both national and international standards for powerlinecommunications technology. there has been less of a push to use powerline connectivity in the united states, in part because the u.s. powerdistribution system, in which each secondary transformer serves only afew households (on the order of 5), makes the persubscriber capital costsmuch higher. in contrast, this ratio is on the order of 50 in europe, reflecting the higher voltages and lower currents in the european distributionsystems; this difference has tempered continual interest in this technology on the part of u.s. companies such as nortel and intel. from aneconomic viewpoint, powerline communications for the last mile competes against wellestablished multimegabit per second wired and wireless options described in this chapter. in addition to questions about the9one example of recent explorations is a 1999 pilot test by the german company veba(now part of e.on), which demonstrated a 2mbps per customer result in a trial involvingeight households. results were found to be good enough to suggest more extensive testingand plans for commercialization (involving avacon a.g., a regional utility). this serviceuses a device attached at the meter that in turn provides connectivity at each power outletin the household, providing internet data and telephone and other valueadded services.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.136broadbandcosteffectiveness of powerline data transmissions, there is an overarchingand longstanding concern about the interference from powerline communications to wireless applications, including amateur radio, homestereo, and emergency broadcast services. the united kingdom, for example, has discouraged powerline communications for this specific reason. powerline communications will not experience widespread deployment until questions about acceptable operating frequencies andinterference thresholds are resolved. for inhome networking, powerlinetechnology has to compete with more mature wirelessñ802.11b (11 mbpstoday, with aggregate speeds up to 100 mbps possible); ethernet (commonly 10 or 100 mbps, but capable of speeds up to 1 gbps); and phoneline networking (10 mbps). these are difficult technical figures to overcome for the powerline medium, even before considering the cost of deploying it. intel backed out of the homeplug system for home distribution, partly because of an underwhelming nominal aggregate speed of 14mbps but mainly because of the potential interference issues mentionedearlier. in short, powerline communications may yet play some role (lastmile or inhome), but it is too immature compared with alternatives tocharacterize its importance or impact, absolute or relative, as a broadbandtechnology.10wireline roadmaphow can wireline providers offer greater bandwidth in the future?both dsl and cable modem technologies have demonstrated that theycan work in mass deployment and as a business proposition for providers. the existence of standards and interoperation among equipment fromdifferent vendors is a signal of technology that is mature in the marketplace. the cable industry has a roadmap for performance innovation thatdoes not depend on substantial technical innovation, but only on thebusiness decisions to deploy upgrades that have already been tested inthe field. similarly, the dsl industry has a roadmap for performanceimprovements that depends on redesign of the access network to installremote electronics in order to shorten the length of the copper pairs. inboth cases, the technologies are relatively mature, so the rate of actualñasopposed to potentialñperformance improvement will depend mainly on10for more on powerline communications technology, see david essex, 2000, òare powerline nets finally ready?ó mit technology review, june 21, available online at <http://www.technologyreview.com/web/essex/essex062101.asp> and john borland, 2001,òpower lines stumble to market,ó cnet news.com, march 28, available online at<http://news.cnet.com/news/010042005337770.html?tag=tppr>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors137the costs of upgrade, the depreciation cycle of investment, and competition from other providers.improvements to dsl performance will run up against the crosstalkinterference problem. the current ansi standard for dsl spectrum management falls short of addressing the longterm challenge. the problemswill become much more significant as the penetration of dsl grows andas the higher data rates contemplated in the dsl upgrade pathñwhichare more sensitive to interferenceñbegin to be widely implemented. theconcern, looking forward, is that spectrum management problems willcomplicate and curtail installment and progress of dsl if the current linelevel unbundling regime is maintained. on the horizon are methods forcontrolling power levels and bandwidth in ways that mitigate the effectsof crosstalk. these include coordination of spectrum use within a carrierõsdslam (this does not, of course, address intercarrier crosstalk) andadvanced signal processing technology that partially compensates forcrosstalk.while there are many unresolved questions about how one wouldactually implement such a processñespecially given the contentious relationships among incumbent and competitive carriersñfurther aggregateperformance improvements could be gained through some sort of systemwide coordination of spectrum use. indications are that with appropriate coordination, symmetric data rates at least 3 times faster than thefastest asymmetric dsl data rates available today would be possible asfiber moves closer to the home. there are other possible advantages. withcoordination, the dslam and modem equipment could be less complex(and thus less costly), and coordination would permit dynamic partitioning of bandwidth to users on demand that exceeds the factor of 3 indicated above. all of this presumes, of course, some change in the rules ofthe game. making improvements in this area will require new regulatoryapproaches (e.g., how and whether to unbundle), new management strategies, and new technology.while both hfc and dsl share the same general featureñan intrinsic limit to the data rate of the nonfiber portion of their networksñthelimit is much higher for coax, which offers the cable industry more options for incremental investment to obtain incremental performance improvements. companies providing data over cable have upgrade roadmaps that illustrate the cost and performance benefits of various options.in rough terms, the hfc infrastructure is capable of offering the consumer a factorof10 improvement over the next 5 yearsñby decreasingthe number of homes in each cluster and/or increasing the capacity allocated to data servicesñat relatively low incremental cost. the total capacity of a coaxial cable segment, including both the entertainment tv anddata segments, is several gigabits per second. beyond this point, the pobroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.138broadbandtential of hfc to scale is not clear. the incremental deployment of fiber inthe hfc infrastructure would imply that the longterm trend would be toreplace the coaxial link to the home with fiber if performance gains in therange of 100 times current broadband were required. from todayõs vantage point, it would be accompanied by the costs and complications associated with deploying fiber to the home.while one can confidently predict that fiber will increasingly be founddeeper and deeper within access networks, and can foresee that fiber willreach an increasing number of households, it is difficult to predict howfast this will happen. fibertothehome has labor costs that are not likelyto yield fully to technical innovation, but the option of technical relief ofthese costs is very appealing and should justify research in support ofcreative proposals.11 the other major cost component is in optical componentsñfor example, lasers and modulators. right now, there are trendstoward both higher performance (seen in wide area fiber optic networks)and lower cost. the industry speculation is that the costs of lasers forconsumer premises devices can come down markedly when the volumedemand is demonstrated for the specific elements. the presence of verycheap lasers in cd players and the falling cost of lasers in local areanetworks (e.g., gigabit ethernet) illustrate at least the potential for inexpensive components.a significant shift in the costs of fiber would probably require significant architectural innovation, not just improving the individual technology components of present systems. this sort of systems research worksto find new ways of combining components into more costeffective andflexible access systems. pon is an example of an architectural idea introduced in the past that had the effect of significantly reducing costs whileoffering other deployment advantages (it requires no active electronicsand no power supply between the central office or head end and thecustomer premises). further innovation is possible, and there are severalfiber metropolitan area network companies claiming that they have abetter architecture overall based on shared media access, optical switching, ip over sonet, or other innovations. the possibility remains that asufficiently low cost solution will emerge from this sort of work to makefiber viable to the residence in the shorttomedium term.it seems quite likely that within the next 5 to 10 years there will besignificant ftth deployment beyond initial field trials. fiber is also likelyto become an important technology for new installation and major upgrade deployments. whether the amount of fiber deployed will representa significant fraction of the installed base during this period is unclear, as11efforts in this direction include systems that install fiber in existing sewer pipes.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors139it will depend on many factors, both technical and economic. fiber willcome to each part of the network when a combination of economics,demand, and capabilities versus alternatives justifies it. the market willcontinue to test whether or not that time has come, and will continue topush the capabilities of other technologies as far as economically practicalas well. finally, it is worth noting that some caution is in order whenmaking predictions on this subject. some 15 years ago, there were claimsby both infrastructure operators and fiber vendors that ftth was comingsoon, but high costs, uncertain demand, and other factors meant thatthese forecasts did not pan out (though greenfields situations are especially attractive on a total lifecycle cost basis).wireless optionsthere are actually many different systems that make use of wirelesscommunication; they are divided here into fixed terrestrial wireless, mobile wireless, fixed satellite service, and wireless local area networking.fixed wireless service is being readied for direct competition with dsland cable in major markets, while thirdgeneration mobile and wirelesslocal area networking alternatives aim to deliver services to mobile professionals. over time, these seemingly disparate market segments arelikely to overlap and converge, as portable computing devices and hybridpersonal digital assistant (pda) cellphonetype devices proliferate further. in the long run, broadband wireless access may be expected to migrate toward the more unique task of supporting connectivity to the growing proportion of portable enduser devices. the relative roles of thesewireless options will differ depending on marketdemand factors, availability of capital, competitive strategies, and regulatory issues. the focusin this discussion, however, is on shorterterm prospects for broadbandresidential access, which is generally construed to be a fixed service.fixed terrestrial wirelessin contrast to mobile services, fixed wireless services provide connectivity from a base station to a stationary point, such as a home.12 perpassing costs are more favorable, especially because the cell size can bemade large initially, and then decreased as subscription rates increase. asa result, fixed wireless will be an attractive option for providers that do12connectivity may be either to a single gateway within the home (which in turn isconnected through a home network to computers within the home) or directly to individualcomputers within the home. (as home networks become more commonplace, some of whichthemselves use shortrange, lowcost wireless links, the former will likely dominate.)broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.140broadbandnot own last mile infrastructure in a desired service area to become facilitiesbased competitors. firstgeneration, proprietary systems providingdata rates of about 1 to 10 mbps are commercially available. these makeuse of spectrum set aside for and thus referred to as local multipointdistribution service (lmds) and multipoint multichannel distribution service (mmds). the lmds spectrum, located above 20 ghz, is allocated forpointtopoint voice, data, or video transmission. mmds, which uses spectrum in 2.1 and 2.5 to 2.7 ghz bands, was traditionally used to providesocalled wireless cable video services, especially educational/instructional programming; but a rule change by the fcc in 1998 opened thedoor to twoway data service delivery over mmds frequencies, and thechannels have been made available to wireless providers for broadbandservices.13 lmds, which offers very high data rates but has more limitedrange and requires more expensive equipment, is used primarily for highspeed business services. the longer range and lower frequencies of mmdsreduce both infrastructure and customer terminal costs, making it suitable for competing with dsl and cable in the residential market.several operators (including sprint and worldcom) have been deploying firstgeneration broadband fixed wireless networks (using mmdsspectrum) with the objective of providing internet access with speeds ofroughly 1 mbps to homes and small businesses. in these systems, eachantenna serves a large service area, and line of sight between the antennaand receiver is required. coverage in these systems is roughly 50 to 60percent of potential subscribers, with the exact figure depending on thetopography and foliage density. customer premises equipment costs arein the neighborhood of $500 to $1,000. the total cost of a base transceiverstation is roughly $500,000. assuming typical coverage over about an 8to 10mile radius, the perpassing cost is roughly $2,000 per square mile.the actual range that can be achieved will differ significantly dependingon the topography, presence of buildings and trees, and so forth. the areaand number of customers served by a base station (and thus the cost persubscriber) depends on signal range, desired bandwidth per customer,and channel capacity.as of early 2001, service providers are testing secondgeneration products that use smaller cells to increase system capacity and enhanced signal processing to enable nonlineofsight service. these products are ex13in response to a proposal submitted by participants in the old wireless cable industry,the fcc amended the rules to permit licensees to provide highspeed, twoway services,such as highspeed internet access, to a variety of users. with wireless cable distribution ofvideo entertainment programming proving a nonstarter, the commission concluded thattwoway wireless could produce a continuing stream of leased channel revenues for theeducational licensees (viable competition for hardwire cable was also a consideration).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors141pected to bring the coverage rate up to about 80 to 90 percent. the costperpassing will be considerably higher because the cell sizes are smaller(3 to 5 miles), but the systems will have considerably higher overall capacity and coverage. standards for secondgeneration lmds and mmdshave been initiated in standards bodies such as ieee 802.16. the technology of choice for massmarket mmds is being explored in standardsbodies and the marketplace, but it is likely that a variation of orthogonalfrequency division multiplexing (ofdm) will be adopted at the physicallevel. at this point, deployment appears to be gated more by the availability of investment capital and the initial cost and performance of the technology than by the lack of standards, but agreement on a standard wouldpermit component vendors to drive prices down farther and, in turn,could prompt more investment.other technologies (e.g., wideband codedivision multiple access[cdma]derivative radios operating at several megabits per second, ultrawideband radio, and free space laser beams) are also under considerationfor fixed or semimobile highspeed internet access. as of 2001, there areseveral venturefunded companies (e.g., iospan wireless, beamreach, andipwireless using radio frequency transmissions, and terabeam using freespace laser transmissions) developing broadband wireless internet accesstechnologies, and some of these activities may lead to significantly improved cost and performance for fixed wireless.another alternative for broadband wireless is to extend technologiesdeveloped for wireless local area networks, which make use of lowpowertransmitters in unlicensed frequency bands. these have improved substantially in the past few years, with the massmarket ieee 802.11b standard supporting speeds up to 11 mbps in the 2.4ghz band. although thecoverage area for wireless lans is limited to small areas (microcells witha typical radius of less than several hundred feet, though favorable topography and directional antennas can extend this range), rapidly improvingcostperformance makes it a viable option for public services in locationssuch as airports, shopping centers, rural communities, and dense urbanareas. future 802.11 and european telecommunications standards institute (etsi) hiperlan ii standards, which are still under development, areintended for use in the unlicensed 5ghz band to provide speeds ofroughly 50 mbps.there has been a dramatic surge of interest in 802.11b wireless localarea network (wlan) deployment (by individuals, community networking activists, and corporations) during the period of this committeeõswork. much of this investment is driven by the fact that wlans can bereadily deployed at a grassroots level with modest investment: a fewhundred dollars for a home, increasing to a few thousand dollarsfor asmall office building or campus. this investment provides mutimegabitbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.142broadband(nominally 11 mbps for recent 802.11b equipment) access capability toboth fixed and mobile computing devices within the coverage area, aslong as there is an appropriate broadband backhaul service such as ethernet, hfc, or dsl to connect the access point. depending on the numberof users sharing the wlan infrastructure, the costs per user can be relatively low (hundreds of dollars, as compared with thousands of dollarsfor other forms of broadband access), so long as average traffic contributed by each user is not too high. this favorable deployment cost model,along with the strategic advantage of being able to handle both fixed andportable devices with the same access network, seems to be driving agreat deal of commercial interest. most of the activity is of a grassrootsnatureñbuilding, store, and mall operators, individual homeowners, andcommunity networking activists are installing their own wlans thatover time could provide fairly ubiquitous, though not uniform, coveragein populated areas, in a fashion reminiscent of the early deployment ofnetworking within communities and educational institutions. note thatthe use of wlan for òlast 100 metersó access does not eliminate the needfor broadband wired access such as hfc, cable, or fiber, which is stillneeded for backhaul of traffic. wlan may help the overall economics ofeach of these wired solutions by increasing the enduserõs utility andfacilitating sharing of the wired link among multiple devices and/or subscribers. this also applies to rural areas where a single t1 connectionalong with wlan access might be more affordable than dsl or cableservice to each home, depending, of course, on the density of the population cluster.scalable deployment of public unlicensed band services poses additional challenges, such as improvements in spectrum etiquette to preventdestructive interference among multiple operators. the year 2001 alsosaw reports of breaches in the default 802.11b security technology thatwill require attention. looking to the long term, one can anticipate thataccess could be provided by a heterogeneous mix that combines shortrange wireless access points (using technologies such as 802.11, bluetooth,and new higherspeed solutions) with the more traditional dsl/cable/fiber/fixed wireless solutions.14 this scenario becomes of particular interest if a large base of users comes to value mobile devices.mobile wirelesswhile fixed wireless is an important nearterm broadband access alternative, it is generally agreed that over time, wireless technologies and14see, for example, david leeper, òa longterm view of shortrange wireless,ó 2001,ieee computer, june, pp. 3944.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors143the spectrum associated with them will be aimed increasingly at communications for nextgeneration portable and mobile communication andcomputing devices rather than at fixed broadband. users are likely notonly to seek mobile service but also to look for broadband services thatwork in a more seamless fashion between home and mobile environments. as market demand and performance expectations grow, fixedwireless will be at a performance (or costtoperformance ratio) disadvantage compared with wireline alternatives in most areas. at the same time,providers will likely find it more profitable to use spectrum for the mobilemarket, which wireline cannot serve. (this presumes regulatory changesin the licensing rules for that spectrum.) as a result, fixed wireless willhave a longterm niche only in areas of low to medium population density, where wireline options will remain costly and the bandwidth feasible with fixed wireless is sufficient to meet demand.in the mobile arena, solutions for thirdgeneration (3g) digital cellular systems based on wideband cdma have been standardized at theitu, and early deployments are expected in 20012002, particularly injapan and europe. deployment is expensive, requiring that the providerinstall new infrastructure and that the consumer purchase new phones orother receiver equipment. the 3g standard, which provides a theoretical2mbps user bitrate, is in practice limited to medium bitrate services upto hundreds of kilobits per second due to both system capacity constraintsand realistic wireless channel properties. thus, 3g mobile, while a majorstep forward from current digital cellular systems, is unlikely to meet theneeds of the full range of broadband access requirements that might beexpected in the mobile services arena over the next 5 to 10 years. however, given that 3g chipsets will be available in the mass market within 1to 2 years, there are efforts underway to leverage its wideband cdmacore technology to provide severalmegabit fixed wireless access as well.there are also interim ò2.5gó solutions, going by the names edge, gprs,and hdr, which provide packet data services at moderate bitrates (~10to 100 kbps per user) using available ò2gó digital cellular infrastructure.although the speeds of 3g represent a significant improvement oversecondgeneration digital cellular in terms of peak bitrate, the 3g serviceappears likely to fall short of consumer expectations for broadband services when they reach the marketplace. despite the hypeñand their usefulness for certain applications notwithstandingñ3g services may turnout not to meet either the capacity or performance needs of truly scalablemassmarket services that deliver several megabits to each mobile device.this indicates that there will be continued attention to developing broadband mobile technology. one interesting possibility is that derivatives ofwlan technologiesñ802.11, hiperlan, or new standardsñwill be able tosupply high bandwidth more effectively, so long as additional features tobroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.144broadbandsupport mobility, user registration, and the like are gradually added in. incontrast to the 3g model, in which large carriers are using governmentallocated spectrum, the wlan scenario is a bottomup, smalloperatorapproach that leverages unlicensed spectrum. there is the potential forrapid growth owing to the lower capital investment requirements; theability to target service to urban areas, airports, and the like and to expand as needed; and the absence of spectrum licensing costs.satellitebroadband local access via satellite provides another wireless alternative. satellite services have been available for many years, based on geosynchronous earth orbit (geo) satellites. these satellites have been usedfor telephone communications, television distribution, and various military applications. satellite access clearly has significant advantages interms of rapid deployment (once a satellite is launched) and nationalcoverage, but has cost and performance limitations and system capacitylimitations, particularly for uplink traffic. the utility of satelliteõs broadcast capabilities (oneway broadband) has already been seen in digitalvideo via satellite (e.g., direct broadcast satellite [dbs]), which becamepervasive in the 1990s. this has also been leveraged to deliver a mixedtechnology internet access service (e.g., directpc) with satellite downlinkand dial modem uplink. a bidirectional service, in which both the uplinkand the downlink use the satellite, requires the solution of significanttechnical problems at the same time that costs are kept low enough to beattractive to consumers. an example of such a service is the recentlyintroduced starband service, which promises a peak rate of 500 kbpsdownstream and 150 kbps upstream, using a 2 by 3foot antenna, at acurrent price of $70 per month plus $400 initial investment (figures thatmay change as the market grows).while their coverage is very broad, geo satellite systems possess anumber of limitations. power constraints and dish size (which is limitedto a roughly 2ft diameter for massmarket installation) limit the downlink transmission from a geo satellite to about 100 to 200 mbps today(systems under development for launch in the 2003 time frame are beingdesigned to offer at least 400 mbps downstream). statistical multiplexingeffects permit this capacity to be shared over more users than is suggestedby simply dividing this number by the peak load per user, but the totalnumber of customers that can be served per satellite is nonetheless limited. while other performance characteristics of satellites have increasedsignificantly (along mooreõs lawlike curves), the efficiency of power panels on satellites has not increased substantially over recent decades. newfrequency bands can also be used to increase system capacity given abroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors145finite number of orbital spots. spot beams and onboard switching wouldprovide roughly a factorof10 improvement in capacity at the expense ofreduced geographic coverage and a heavier and costlier payload. therehave been several attempts to develop commercial satellites of this sortearlier, but there seem to be various technical and cost problems in eachcase.even though geo satellites may have a limited total capacity forbroadband on a national scale, they may occupy a longterm market nicheif the demand is restricted to a small, bounded set of (mostly rural) subscribers. in this respect, the geo systems clearly provide an illustrationthat the broadband market will be served by a range of technology options, not a single technology winner.geo satellite systems also have a high roundtrip transmission delay.the propagation time (speed of light) up to the satellite and back is about250 milliseconds (ms), so the roundtrip delay is 500 ms. this compareswith a terrestrial crosscountry roundtrip delay over a fiber link of between 75 and 100 ms. this has caused some to conclude that geo satellites are useless for data purposes. in fact, whether this delay mattersdepends on the application being used. for web access the delay may benoticeable, but it does not seriously degrade the experience so long as theendnode software is properly set up. for other applications, the satellitedelay is a more serious issue. for internet telephony, the long delayscause a real degradation in usability, since there are wellknown humanfactors issues that arise when the roundtrip delay in a conversation approaches 200 ms.an alternative that has received a great deal of attention over the lastseveral years is to use low earth orbit (leo) satellites, which in contrast togeo satellites do not occupy a constant position in an assigned orbitalslot, and to rely on multiple satellites to provide coverage. leo satelliteproponents claim that power limitations are less serious than those withgeo satellites, though both types of system are constrained by powerconsiderations. leo satellite technology, while challenging, can befielded, as the pioneering iridium and globalstar deployments have demonstrated. leo satellite deployment for broadband data services requiresthe solution of additional difficult technical problems, such as antennasthat can track a moving satellite at a price point suited for a consumer.however, the feasibility of leo satellites for massmarket broadbandaccess is constrained more by economic considerations than the technology challenges. a leo satellite system requires the launching of manysatellites, because in their low earth orbit, the satellites are in rapid motion overhead, and there must be enough of them that one is always inrange. this means that the system has a very high initial cost to build andlaunch, which in turn implies that there must be a significant user pool tobroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.146broadbandjustify the investment. (even if the perpassing cost is low, there must bea sufficient total customer base.) satellitebased solutions must also compete with terrestrial networks as they expand to reach more customers.15wireless roadmapwhile wireless systems come in multiple flavors, some highlevelobservations are broadly applicable. first, a variety of technology optionsare possible depending on the planned customer density. systems thathave very few towers and more expensive residential equipment havelower perpassing costs and higher persubscriber costs, which may provide a more favorable business case for initial deployment. installing newantennas on existing cellular towers allows the leveraging of past investment in towers and related site costs. thus, for wireless there is at least tosome extent a path that provides incremental performance improvementfor incremental cost. because little or no wireline infrastructure needs tobe installed, deployment can proceed comparatively rapidly, but the capacity for adding more customers is limited.system capacity is limited by the amount of radio spectrum available,which depends on the total amount of radio spectrum suitable (in termsof its propagation characteristics) for broadbandñthe fraction of that spectrum which is allocated through government spectrumlicensing policiesto broadband servicesñand the extent to which clever system design canincrease the performance obtainable from a given amount of bandwidth.one option for increasing performance is to make cell size evensmaller, so that the same frequencies can be reused in more locations (astrategy called spatial reuse). the need to deploy more transceivers (andinstall wireline to connect them to the providerõs network) makes theseimprovements costly, so that systems with very small cell sizes have costs,dominated by labor costs that start to approach those of wireline systems.the relative immaturity of wireless broadband technologies compared with wireline alternatives gives reason to believe that innovativeresearch will yield significant improvements in performance. the totalspectrum available for broadband services is limited by the amount ofspectrum suitable for broadband. mooreõs law decreases in the cost ofprocessing power that can be inserted into broadband transceivers permit15this economic challenge has been seen in the case of satellite voice services, whereterrestrial cellular voice service, which is much cheaper and requires much smaller handsets, was deployed on a more widespread basis than was contemplated when the initialiridium business plans were formulated. if terrestrial broadband services discussed aboveare deployed over enough of the world during the time it takes to design and launch a leosatellite broadband service, the pool of underserved users with the wealth to purchase thisnew satellite service may be too small to recover the high upfront cost.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors147use of more complex coding schemes, which permit increased data ratesto be affordable. some of the nextgeneration technologies under activeconsideration make use of increased signal processing to permit nonlineofsight operation, which is important to increasing both the number ofviable markets and the fraction of customers that can be served. moreprocessing power may also permit more of the basestation functions tobe implemented in software, which would permit new services to beintroduced without a hardware upgrade. another option is to exploitnew wireless innovations such as spacetime processing techniques withmultiple antennas (socalled multiplein, multipleout, or mimo, approaches) or smart antenna beam steering approaches, which hold thepromise of roughly a factorof10 improvement in peruser throughput.these approaches rely heavily on improvements in the processing powerof applicationspecific integrated circuits (asics) or digital signal processors (dsps) that enable the requisite signal processing to be performed inreal time in affordable hardware.even so, the wireless roadmap does not seem to offer performanceimprovements of the same magnitude as are possible with wireline. evenin the best case, wireless cannot match the ultimate transmission capacityof wire or fiberñthough it could surpass the performance of todayõs deployed dsl or cable systems. and in contrast to wireline, wireless does nothave as clear a roadmap regarding the 5year potential of further research. wireless will, however, be an important technology option in viewof several potential advantages, which include rapid deployment, lowerinitial capital investment, and the ability to serve portable or mobile devices.over time, as wireline facilities are built out, it is quite possible thatthe wireless spectrum used by fixed service will, for the most part, beshifted to mobile uses. in this scenario, fixed wireless would shift fromplaying a role as a facilitiesbased alternative in even densely populatedareas to one where it provides niche service in lowerdensity and remoteareas, particularly in newly developed areas where it complements wireline solutions by enabling niche services.note that even though todayõs 3g technology may be immature, it isrelatively safe to predict that there will be a growing demand for broadband wireless service to portable and mobile devices. this is because offundamental trends toward smaller personal computing and communication devices (e.g., laptops, pdas, and cellphones) that in the long term arelikely to account for the majority of enduser devices, in contrast to thefastgrowing minority that they represent today. once tetherless computing devices become ubiqitous, todayõs pccentric broadband access network (hfc, dsl, and so on) will have to evolve toward hybrid wired andwireless networks in which the òlast mile,ó òlast 100 m,ó or even òlast 10broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.148broadbandmó are mostly wireless. the cost and performance of broadband wirelessaccess networks will thus be crucial to the userõs overall experience.in that context, it is worth noting that there are significant challengesassociated with delivering true broadband services, as defined in thisreport, to mobile devices. for example, a 5mhz chunk of 3g spectrumcan support only about 10 simultaneous broadband users per cell, a number that has to increase by orders of magnitude to make the service viablebeyond narrowband uses. research and development (r&d) challengesfaced by developers of ò4gó wireless standards include higher speeds (onthe order of 1 to 10 mbps), maintenance of service quality under mobilefading conditions, integration of mobile and fixed network architectures,and greater spectral efficiency, capacity, and scalability. there has beenrecent interest in mobile web access, media streaming applications aimedat portable devices, and the like, but consumer demand and the shape ofthe market are still evolving. significant r&d investment will be neededto reach the scalability and cost and performance levels appropriate forubiquitous mobile/portable broadband wireless deployment. supportivefcc spectrum regulation policies that encourage efficient spectrum usage and easier access to new spectrum, rapid technology evolution, andmarket competition will also be needed to drive this important scenarioforward.the diverse technology landscapethe different technology optionsñincluding hfc, dsl, fiber, wireless, and satelliteñare different in detail. some have higher delay, somehave lower overall bandwidth, some may have higher prices, and so on.different technology can be deployed to advantage in different circumstances. in dense urban and suburban areas, the present generation ofwireline broadbandñhfc and dslñis being utilized successfully today. fiber will be used in access networks wherever a combination ofeconomics, demand, and capabilities (compared with alternatives, including the infrastructure already in place) justifies it. fixed wireless is beingused to support market entry by providers that do not own or have accessto existing wireline assets. in less densely populated areas, fixed wirelessmay offer a longerterm solution for broadband access. finally, in themost remote areas, a small percentage of the u.s. population may best beserved by satellite where the very high fixed cost of construction andlaunching satellites is offset by the very low perpassing costs, given theenormous area that a satellite system can serve. one of the consequencesone may have to accept for living in rural areas is that the available broadband service has some particular characteristics, such as higher delay andgreater cost per unit of bandwidth. this may be an issue for certain applibroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors149cations, but one should look at this as just one consequence of technologydiversity, not as a fatal flaw of one or another technology.the market will continue to test whether or not the time has come todeploy fiber, and it will also continue to push the capabilities of othertechnologies as far as economically practical. in different parts of thenation (and the world), with different demographics and population distribution, these different technology options will play out in a differentmix, but each will play a role in the diverse world of today.layering and unbundlingthis chapter devotes considerable attention above to the characteristics of different technology options for broadband access. but consumersdo not normally care about the communications technology for its ownsake; they care about the services that can be delivered over itñinternetapplications (web, audio, video), entertainment television, and so on.hiding these details and separating the underlying communications technologies and the applications and services accessible to end users areaccomplished through the engineering practice of layering. communication systems are often designed (and described) in a layered fashion: thatis, with a physical layer at the bottom that differs, depending on theparticular communications technology chosen; a top layer that representsthe specific applications that users run over the network; and some intermediate layers that help organize the engineering of the overall system.as a simple example, consider the problem of sharing the total capacity of a cable system among a number of users and applications. at thephysical layer is a coaxial cable capable of carrying radio frequency signals. the capacity of the cable system is divided into a number of channels of 6mhz bandwidth, each capable of carrying a tv channel or otherinformation. at the layer above that, one or another form of content isassigned to each frequency. most channels are used today to carry a singletv signal, but channels can also be used for the internet or for telephoneservice. also, using new digital representations, multiple tv channels cannow be carried in a single 6mhz channel.the internetõs design is layered so that it works over a wide range ofcommunications technologies, including all of the wireline and wirelessbroadband technologies discussed above. consider internet transmissionover a cable system. first, one or more physical channels are assigned tointernet transmission. then, at the lowest layer of the internetõs design,the data to be transmitted over an individual cable system channel aredivided into a sequence of small messages called packets. multiple usersshare a single channel by sending their own packets one after another.finally, the packets used by each user are assigned to one or anotherbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.150broadbandòapplication,ó such as web access, email, or streaming audio. so thelayers of sharing for the internet over cable are as follows: a physicalcable, which is divided into channels, then divided into packets, whichare each in turn assigned to a particular user and application.to the user of the internet, the details of layering are largely irrelevant. but the detail does matter in the debate about unbundling. theterm òunbundlingó is used to describe the situation in which the owner ofphysical facilities is required to make some portion of that resource available to a competitor. unbundling of the incumbent local telephone company facilities is required by the telecommunications act of 1996. thereare two distinct ways of unbundling the local loop: physically and logically.in the case of the copper infrastructure of the telephone company, oneform of unbundling is physical, where an actual copper pair is assigned toa competitor. in this way, the competitor has direct access to the electronicsignals being carried over the wire (or to the light carried over a fiber) andcan adopt whatever transmission scheme it chooses. for use of the loop,the competitor pays the rate negotiated with the incumbent or, in theabsence of a negotiated agreement, the rate established by regulatorsthrough arbitration, and in turn directly implements the service and billsthe customer. physicallayer unbundling requires that the competitor havethe ability to colocate equipment and upstream connectivity at the network termination point of the loop (typically but not exclusively at thecentral office).physicallayer unbundling offers several potential advantages for thecompetitor. first, it provides the competitor the freedom to select the typeof transmission technology it chooses to implement over the copper loop,independent of whatever decisions the incumbent may make, permittingthe competitor to compete with the incumbent on the basis of a variety ofattributes, including speed, quality, and maximum loop length. second,in the case of a loop running from the central office to the subscriber, it isin some sense a welldefined, easily separable network element.physicallayer unbundling may also impair the ultimate performanceof the copper plant. while it holds true for voice signals, the assumptionthat copper loops are fully separable is not correct for highspeed datatransmission using dsl because of crosstalk among wires within the telephone plant. this means that ultimate performance and reach are hampered because corrective measuresñsuch as coordinated assignment ofcopper pairs and coordination of transmitted signals among pairsñcannot be implemented if competitors are left free to implement the technology of their choosing.unbundling also raises new issues when applied to new facilities. asan initial matter, an unbundling obligation may deter an incumbent localbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors151exchange carrier (ilec) from pushing fiber farther into the neighborhood. in addition, plant access on the network end of the loop today isgenerally at the central office. to improve the performance and reach ofdsl service, it is natural to deploy fiber deeper into the telephone network. then the copper pair terminates at a remote terminal, which maybe a curbside pedestal or even a small box on a telephone pole. issuesraised in this context include these:¥unbundling at remote terminals is problematical because of spacelimitations and because the relatively small number of subscriber linesterminated at each remote terminal make colocation and interconnection(linking the copper loop to the competitorõs network) more difficult toachieve here than was the case at the central office.¥as fiber is pushed deeper into the network, the copper loops become shorter, each remote terminal serves fewer customers, and (if onlythe copper is unbundled) each provider would need to separately provision fiber to interconnect at the remote terminal. the fiber running to theterminals might also be unbundled, which would require some sort oftimedivision multiplexing (i.e., each provider has its own time slots) orwavelength division multiplexing (each provider has its own wavelengths) of the incumbentowned fiber.¥continuation of physicallayer unbundling requirements complicates establishment of technologyneutral rules because unbundling rulesmust take into account the particular details of each new communicationstechnology used by incumbents.the other unbundling option is logicalñabove the physical layer.higherlayer services concerned with transmitting bits are implementedin some fashion on top of protocols concerned with transmitting electricalsignals across the wire, which means that they can be implemented independent of the particulars of the physicallayer connection used to provide the higherlevel service. that is, a competitor need not control theactual signals running over the wires if it can implement its service usingbit transport capabilities provided by the incumbent. with logicallayerunbundling, the incumbent specifies the customerpremises equipmentand operates the termination equipment.logicallayer unbundling offers several advantages. colocation requirements are confined to those necessary for the competitor to interconnect with the incumbentõs network. another advantage to logicallayerunbundling is that it may be easier to verify servicelevel agreementsbetween the incumbent and competing service provider, because data onlogicallayer service (throughput, quality of service, and so on) can becompiled more readily. finally, with logicallayer unbundling, one avoidsbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.152broadbandmuch of the argument over such hardtomeasure issues as whether incumbent personnel òmade life difficultó for clec employees while installing equipment or agreeing on a frequency plan.a principal disadvantage of logicallayer unbundling for the competitor is that the performance characteristics of the link implemented bythe incumbent may restrict the types of services the competitor may offer,and limits the competitorõs ability to differentiate itself from the incumbent. while the motivation of incumbents is certainly a matter of speculation and debate, it is often suggested that one reason incumbents havefavored the lowerspeed, asymmetric dsl technology is that symmetricalhighspeed dsl service for business customers could undercut profits onmore expensive t1 data service. incumbents might also select a transmission technology that accommodates the typical copper loop but whichmay not be optimal for subscribers with longer loops. a competitor restricted to logicallayer unbundling cannot provide a symmetrical serviceor otherwise compete with the incumbent by offering higher performancethan the incumbentõs system permits.the nature of the local access technology affects what unbundlingoptions are viable. in the case of the cable infrastructure, one could propose that different frequencies could be allocated to different providers,or that different providers could be assigned a share of the packets beingsent in a single frequency, and so on. in practice, allocation schemes havenot proved workable, and cable open access is being implemented at thepacket level. so the fact that there are different ways of sharing at different layers, and that different technologies have different layering structure, makes the debate about unbundling complex.economics of infrastructure investmentlike any other business, revenue, at least in the long term, must besufficient for a broadband service provider to be profitable (or at least tobreak even, in the case of a public sector enterprise). as the previousdiscussion suggests, different technologies have different cost structuresthat shape their attractiveness in different market segments. at the sametime, uncertainty about demand for broadband, consumer willingness topay, and the interaction of these factors with different business modelsshapes investment in broadband deployment.understanding costsbroadband deployment costs fall into two broad categories: fixed (orperpassing costs), which are roughly independent of the number of subscribers, and variable (or persubscriber) costs. fixed costs include thosebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors153of upgrading or installing wireline infrastructure within the neighborhood and installing or upgrading central office or headend equipment.for wireless, the costs of acquiring wireless spectrum licenses are anotherperpassing cost. the most significant variable costs are the persubscribercapital costs, including line cards, customerpremises equipment, and thecosts of upgrading or installing connections to individual premises. othervariable costs include installation at the customer premises (which drivesshifts to customerinstalled solutions) and customer support and maintenance. providing upstream connectivity involves both fixed costs, such asinstallation of regional or national transport links, and variable costs associated with provisioning regional and national connectivity to supportthe traffic load imposed by customers.these costs are greatly shaped by density and dispersion. where newwireline infrastructure is installed, more remote or sparsely populatedareas will have significantly higher perpassing costs, reflecting permileconstructions costs, that make investment riskier, and the lower perpassing costs of satellite or other wireless systems will be more attractive.each particular circumstance will involve its own set of cost tradeoffs,however. for instance, because installing remote terminal equipment imposes substantial costs, homerun fiber to the premises could turn out tobe cheaper than a fibertothecabinet strategy in some rural cases.takerate tyrannyperhaps the most important implication of perpassing costs is theòtakerate tyrannyó that dominates investment decisions. because costsare dominated by the dollarspermile cost of installation, investment inwireline infrastructure has a cost structure in which most of the cost isdetermined by the number of houses passed, and a minority of the costs isdetermined by the number of subscribers. (because they lend themselvesto a strategy in which the cell size can be scaled to the takerate, wirelesssystems can have an advantage, though the cost of spectrum must also befactored in.)a very simplified cost model indicates the general shape of the financial dilemma facing those who invest in broadband infrastructure. if thereare two providers instead of oneñassuming no differentiation betweenthe products, no firstmover advantage, and that costs are perpassingñthe costs for each are unchanged but the revenues are halved. as a veryrough example, if a provider makes an incremental investment in thedistribution infrastructure that has a cost of $200 per passing and mustrecover this investment in 3 years, this is approximately $5 per month perpassing. if the provider has the whole market and 50 percent of the homesbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.154broadbandare subscribers, this would imply that $10 per month of the persubscriberpayment would have to be allocated for return on this investment. if,however, there were two providers and each held half of the total 50percent market share, then each provider would have to collect $20 permonth from each subscriber as a return on this investment, in a marketwhere the typical consumer payment is just $40 per month. more generally, when the market is split among multiple providers, some cost andrevenue models for residential broadband become unprofitable. this alsoamplifies the advantages held by a provider that can make incrementalupgrades to existing wireline infrastructure (the advantage depends onthe cost of any required upgrades) over a de novo facilitiesbased competitor.as a result of the takerate impact on persubscriber costs, the provider with the highest penetration rate may have a substantial cost advantage over its competitors if perpassing costs are significant. according torough figures supplied to the committee,16 the present perpassing coststo install fibertothecurb are as follows: $150 per passing if only voice isoffered, an additional $150 per passing if data service is provided as well,plus $300 per passing to provide video. fiber cable installation adds another $350 to $400 per passing if done aerially and $700 to $800 per homepassed if buried. given these figures, consider two providers serving alocal market, each offering voice, data, and video. suppose each passes allhomes, that 50 percent of homes subscribe in aggregate, and that oneprovider, the incumbent, serves 60 percent of all broadband homes, whilea more recent entrant serves 40 percent of broadband homes. both providers use aerial installations that cost $400 per passing. then persubscriber costs for the incumbent would be $1,000/0.30 = $3,333 (plus subscriberspecific installation costs), while for the entrant persubscribercosts would be $1000/0.20 = $5,000 (plus subscriberspecific installationcosts). the entrantõs costs would be 50 percent greater than the incumbentõs. this type of relationship means that competition that truly droveprices to costs would eliminate all but one firm unless markets wereevenly divided among competitors or competitors offered differentiatedservices that appealed to different subsets of subscribers. the risks forentrants inherent in this type of relationship are obvious, especially ifsubscriptions are at all sticky (e.g., where customer loyalty or switchingcosts are significant). unless competitors can find ways to substantiallydifferentiate their services, entry may well be risky and vigorous competition difficult to sustain.16from mark macdonald at marconi.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors155paying for broadbandthe economic challenge of building and upgrading broadband infrastructure has proved daunting. cast simply in terms of consumer willingness to pay and ability to attract investment in terms of that demand, itmay be difficult to sustain high growth in penetration, upgrades, and newfacilities construction. but broadband involves more players than simplythe consumer and the infrastructure owner, and there are various ways inwhich the costs could be allocated among the various players. other industries that share costs include telephony, in which different types ofcustomers (e.g., residential versus business) pay different prices; commercial broadcast radio and television, in which consumers are sold asaudiences to advertisers; and newspaper publishing, in which the subscription price is only a fraction of the cost of production and distribution.such arrangements have been instrumental in building other communications infrastructures. complex arrangements among multiple partiesare possible, as is seen in broadcasting, where both costs and revenue canbe shared between broadcast networks and local affiliates. the criticalrole of content suggests that issues related to copyright protection of digital content will be intertwined with broadband for some time to come.because broadband is a service capable of supporting each of thesetypes of services and many new ones as well, there are potentially manydifferent options for cost sharing. figure 4.5 depicts a cluster of otherplayers that surround the consumer and broadband infrastructurebuilder. notably, broadband subscribers generally are interested in a widerange of content and applications that are not provided directly by thebroadband provider itselfñtoday this is largely the universe of contentand services available through the web. these services have been supported through a combination of ecommerce, transaction and subscription charges, and advertising (both direct, in the form of banner ads andthe like, and indirect, as when a web site is used as to draw the user intoother media channels). one opportunityñand challengeñis to find waysof better aligning the economic interests of content or applications providers and infrastructure owners in order to share the costs of the accesslink with the end users. another is to explore how government incentivesor contributions from employers interested in various flavors of telecommuting or employee education could contribute to the overall investment required. new approaches to financing broadband include homebuilders that include fiber connections in the price of the home (and canthen promote the homes as broadbandready) and municipalities thatprovide mechanisms for amortizing the investment over a relatively longtime period.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.156broadbandfocus on the consumerthe factors discussed in the previous section notwithstanding, theconsumer is the pivot around which all of the economic issues swing.without consumer demand and a (somewhat) predictable willingness topay (or evidence that advertising will be a large source of revenue), thereis no market. evidence from early deployment demonstrates demand.the national average penetration (somewhat more than 8 percent as ofsummer 2001) reflects and masks an uneven pace of deployment. in localities where the service has been available for a reasonable time, cablefigure 4.5paying for broadband.consumerstelecom.infrastructurebuilders/operatorscontent andapplicationprovidersadvertisersemployers(telework andeducation)federal, state,localgovernment(incentives)buildingowners,developersbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors157industry reports on markets that have had cable modem service availablefor several years suggest considerable demand.17although the committee is not aware of definitive studies of consumer willingness to pay for broadband (and the notion proposed in thepast, that consumer willingness to pay for entertainment and/or communications is a fixed percentage of income, is generally discounted byeconomists today), the general shape of the market for communications,entertainment content, and information technology is beginning toemerge. over 50 percent of homes in america have some sort of pc, withprices that averaged near $2,000 in recent years, and which are now dropping below $1,000 for lowerend machines, illustrating that many consumers are willing to make a significant investment in computing hardware and software. in rough terms, a typical $1,200 home computerreplaced after 4 years costs around $25 per month.a majority of the homes that have pcs are going online and connecting to the internet, and it is a reasonable projection that only a very smallfraction of machines will remain offline in the coming years. using theprimary residence phone line, and purchasing a somewhat more limiteddialup internet service, the price approaches the $10 per month (providers have also experimented with service and pcs that are provided free,so long as the consumer will allow advertisements to be displayed duringnetwork sessions, although recent reports from this market segment putin question the longterm viability of this approach). the entry price today for broadband is not dramatically different from that for highenddialup service. a separate phone line costs as much as $20 per month,and unlimitedusage dialup internet service generally runs $20 or moreper month. of course, the market offers a range of price and performancepoints from which the consumer can pick. at the highend, highspeeddsl can cost up to several hundred dollars per month, and businessoriented cable services are offered at a premium over the basic service.the total consumer expenditure for such a computer plus basic broadband service is potentially as much as $90 per month, of which the internetprovider can expect to extract less than half. from this revenue base abusiness must be constructed. if 100 million homes were to purchasebroadband service at $50 per month, this would result in total annualrevenues to broadband internet providers of more than $50 billion, whichis similar in magnitude to current consumer expenditures on longdistance services.17for example, information supplied to the committee by time warner cable is that takerates have reached 17.5 percent of subscribers in boston, massachusetts, and 25 percent ofsubscribers in portland, maine.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.158broadbandone question that the market has not yet explored is whether theconsumer would make a significant capital investment, similar to the$1,000 to $2,000 that a computer costs today, as part of obtaining internetservice. for example, if there were a homerun system with fiber runningto the residence (making it a relatively futureproof investment), but theconsumer had to activate that fiber by purchasing the endpoint equipment, would this be an attractive option if the equipment costs werecomparable? would residents be willing to finance the capital costs ofinstalling that fiber in the first place? while there is no hard evidence,wealthier consumers, who have demonstrated a willingness to make purchases such as multiple upscale multimedia pcs and expensive consumerelectronics, might well be willing to make such investments, and someresidential developers have opted to include fiber.the pace of investmentthe rapid evolution of some aspects of the internet can lead observersinto thinking that if something does not happen within 18 months, it willnot happen. but the phenomena associated with deployment cycles measured in months have generally been in the noncapitalintensive software arena. the cost of entirely new broadband infrastructureñrewiringto provide fibertothehome to all of the roughly 100 million u.s. householdsñwould be some $100 billion, reflecting in considerable part construction costs that are not amenable to dramatic cost reductions. even forcable and dsl, for which delivering broadband is a matter of upgradingexisting infrastructure, simple economics gates the pace of deployment.for both new builds and incremental improvements, an accelerated paceof deployment and installation would bring with it an increased perhousehold cost. some broadband deployment will be accomplished aspart of the conventional replacement and upgrade cycles associated withtelephone and cable systems. in some cases, this process will have dramatic effectsñtwo examples are hfc replacement of allcoaxial cableplants and aerial replacement of copper with fiber as part of a completerehabilitation of old telephone plantñbut in many others cases, the improvements will be incremental. to accelerate beyond this pace meansincreasing and training an everlarger workforce devoted to this task. asmore new people are employed for this purpose, people with increasinglyhigher wages in their current jobs will have to be attracted away fromthose jobs. similar considerations apply to the materials and manufacturing resources needed to make the equipment that is needed.the investment rate also depends critically on the perspective andtime horizon of the wouldbe investor. for an owner of existing facilitiesñthe incumbent local exchange carriers and cable multiple systembroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors159operatorsñrealistic investment is incremental, builds on the installedbase, and must provide return on a relatively short timescale. the tendency to make incremental upgrades to existing telephone and cableplants reflects the view that a replacement of the infrastructure (such aswith fiber) would necessitate installation costs that can be avoided byopting to upgrade. the perception is that users would not be willing topay enough for the added functionality that might be achieved with anallfiber replacement to offset the extra costs of allnew installation.changes in either costs or perceived willingness to pay could, of course,shift the investment strategy.once the provider has a broadbandcapable system, it will only haveincentives to spend enough on upgrades to continue to attract subscribersand retain existing customers by providing a sufficiently valuable service.where facilitiesbased competition exists, these efforts to attract and retain customers will help drive serviceperformance upgrades. from thisperspective, the level of investment associated with building entirely newinfrastructure is very difficult for the incumbents to justify. viewing theincumbentõs incentives to invest in upgrades from the perspective of thetwo broadband definitions provided above, investment to meet definition1 will be easier than that to meet definition 2. that is, it is easier to justifyspending so that the local access link supports todayõs applications, whileit is harder to justify spending enough to be in front of the demand so asto stimulate new applications.two types of nonincumbent investor have also entered the broadband market, tapping into venture capital that seeks significant returnsñand generally seeks a faster investment pace. one is the competitive localexchange carrier, which obtains access to incumbent local exchange carrier facilitiesñprimarily colocation space in central offices and the copperloops that run from the central office to the subscriberñto provide broadband using dsl. the other is the overbuilder, which seeks to gain entryinto a new market by building new facilities, most commonly hybrid fibercoax for residential subscribers, but also fibertothepremises and terrestrial wireless. satellite broadband providers in essence overbuild the entire country, though with the capacity to serve only a fraction of the totalnumber of households. the 20002001 drying up of internetrelated venture capital has presented an obstacle to continued deployment, and theclecs have also reported obstacles in coordinating activities with theilecs that control the facilities they depend on.because public sector infrastructure investment generally is based ona longterm perspective, public sector efforts could both complement andstimulate private sector efforts. the key segment of the public sector forsuch investment is likely to be subfederal (state, local, regional), thoughthe federal sector can provide incentives for these as well as private sectorbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.160broadbandinvestment. but decision making for such investments is not a simplematter, and, if present trends are any indication, such investments will beconfined to those locales that project the greatest returns from acceleratedaccess to broadband or possess a greater inclination for a public sectorrole in entrepreneurship.investment, risk taking, and timelinesthe myth of the òinternet year,ó by analogy to a òdog year,ó is wellknown. where the internet is concerned, people have been conditioned toexpect 1year product cycles, startups that go public in 18 months, andsimilar miracles of instant change. the 20002001 downturn in internetand other computing and communications stocks dampened but did noteliminate such expectations. in fact, some things do happen very rapidlyin the internetñthe rise of napster is a frequently noted example. theseevents are characterized by the relatively small investments required tolaunch them. software can diffuse rapidly once conceived and coded. butthis should not fool the observer into thinking that all internet innovationhappens on this timescale.as noted earlier, broadband infrastructure buildout will be a capitalintensive activity. in rough figures, a modest upgrade that costs $200 perpassing would cost $20 billion to reach all of the approximately 100 million homes in the united states. broadband deployment to households isan extremely expensive transformation of the telecommunications industry, second only to the total investment in longhaul fiber in recent years.in light of these costs, the availability of investment capital, be it privatesector or otherwise, imposes a crucial constraint on broadband deploymentñit is very unlikely that there will be a dramatic onetime, nationwide replacement of todayõs facilities with a new generation of technology. instead, new technology will appear piecemeal, in new developmentsand overbuild situations. old technology will be upgraded and enhanced;a mix of old, evolving, and new should be anticipated. whether nationaldeployment takes the form of upgrades or new infrastructure, the relevant timescale will be òold fashionedóñyears, not days or months.as a consequence, observers who are conditioned to the rapid pace ofsoftware innovation may well lose patience and assume that deploymentefforts are doomed to failñor that policies are not workingñsimply because deployment did not occur instantly. one should not conclude thatthere is something wrongñthat something needs fixingñwhen the onlyissue is incorrectly anticipating faster deployment.much private sector investment, especially by existing firms, is incremental, with additional capital made available as investments in priorquarters show acceptable payoff. as a result, the technological approachbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors161chosen by an incumbent is likely to make use of existing equipment andplant, and the deployment strategy must be amenable to incrementalupgrades. the evolution of cable systems is a good example. the previous generation of oneway cable systems is in the process of being upgraded to hybrid fiber coax systems, and these in turn are being upgradedto provide twoway capability, greater downstream capacity, and packettransport capabilities. the various incumbents now in the broadbandmarketplace have very different technology and business pastsñthe telecommunications providers selling voice service over copper, the cabletelevision companies using coaxial cable to deliver video, the cellularcompanies constructing towers for pointtopoint wireless telephony, andso forth, and each will evolve to support broadband by making incremental improvements to its respective technologies and infrastructure. incumbents seeking to limit regulatorsõ ability to demand unbundling havean incentive to avoid technologies that facilitate such unbundling.because they exist to take greater risks but possibly provide muchgreater returns by identifying new promising areas, venture capitalistsseek to invest in opportunities that offer high payoff, not incrementalimprovements. so it is no surprise that the more mature technologies,such as cable and dsl, have attracted relatively little venture capital inrecent years. another investment consideration for the venture capitalistis the total available market, with niche markets being much less attractive than markets that have the potential to grow very large. finally,because the eventual goal is usually to sell a company (or make an initialpublic offering) once it has been successfully developed, venture capitalists must pay attention to trends in the public equity markets.18uncertain investment prospects in the private sectorover the past few years, broadband infrastructure has to some extentfollowed the overall trend of technologycentered enthusiasm for venturecapital investment and highgrowth planning. broadband may similarlybe affected by the current slowdown in investment and by the more careful assessment of business models to which companies are now beingsubjected. at this time, broadband providers, as well as internet serviceproviders more generally, are facing problems of lack of capital and cashflow. this could lead to consolidation, and perhaps to a slowdown in theoverall rate of progress.18in a white paper written for this project in mid2000, george abe of palomar venturescharacterized venture capital investing as òfaddishó and observed that òthere is a bit of aherd mentality.ó there are hints that with the 2001 market drop, venture capitalists haveadopted a longerterm view and are seeking well thoughtout opportunities rather thanchasing fads.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.162broadbandinvestment options for the public sectorif and when the public sector chooses to intervene financially to encourage service where deployment is not otherwise happening, it willhave a different set of constraints. governments have access to bond issues and other financial vehicles that best match onetime capital investments with payback over a number of years, and they also have access toa tax base that reduces the risk of default. if a major, onetime investmentis to be made, the implication is that this technology must be as futureproof as possible, because it must remain viable for the period of thepayoff. the most defensible technology choice in this case is fibertothehome, with a separate fiber to each residence. fiber has an intrinsic capacity that is huge, but the actual service is determined by the equipment thatis installed at the residence and at the head end. with dark fiber runningto each customer, the end equipment need not be upgraded for all theusers at once but can be upgraded for each consumer at the time of his orher choosing. thus, this technology base permits different consumers touse the fibers in different ways, for different services, and with differentresulting costs for endpoint equipment. the consumer can make thesesubsequent investments, reusing the fiber over the life of the investment.upgrades are not, however, fully independent as they depend on thebackhaul infrastructure. an upgrade will require not only new centraloffice or remote terminal line cards, but also a compatible infrastructurebeyond that; the remote terminal or central office rack itself may not beable to switch or route a higherspeed input due to hardware or softwareconstraints.businesses look at risk as an intrinsic part of doing business andmanage risk as a part of normal planning. some investments pay off;others may not. for residential access, for example, demand may exceedexpectation, or perhaps not, and a business will mitigate these risks byinvestment in a number of situationsñcommunities, services, and so on.in contrast, a municipality serves only its own citizens, so any risk ofbad planning must be carried within that community. further, the voterreaction to miscalculation may amplify the perception of the error, whichcan have very bad personal implications for individual politicians. longterm investment in services that do not bring visible shortterm value tothe citizens may be hard for some politicians to contemplate, because thepayoff from this investment may not occur in a time frame that is helpfulto them. so a planner in the public sector must balance the fact that mostsources of capital imply a longterm investment with the fact that citizensmay not appreciate the present value of longterm investment, and mayassess the impact of investment decisions based on shortterm consequences. this may lead to decision making that is either more or less riskbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors163averse (given the level of knowledge among the citizens and apparentlevel of popular demand) than the decision making of the private sector.mooreõs law and broadbandthis report defines broadband deployment as an ongoing process,not a onetime transition. the first proposed definition of what it meansfor a service to be broadband reflects this reality: access is broadband if itis fast enough on an ongoing basis to not be the limiting factor for todayõsapplications. with that definition in mind, unfavorable comparisons aresometimes made between the sustained improvements in the performancetoprice ratio of computing (which relate to what is known asmooreõs law, the 18month doubling of the number of transistors on anintegrated circuit) and improvements in the capacity of broadband accesslinks. in fact, communications technologies, as exemplified by sustainedimprovements in fiber optic transmission speeds, have by and large keptpace with or surpassed improvements in computing. the gap one sees isbetween deployed services and underlying technology, not an inherent mismatch of technology innovation.this committee spent some time exploring why broadband local access has not kept pace with other areas in computing and communications, and it considered how the economics of broadband service providers, longhaul communications providers, and computer equipmentvendors might differ. in the end, the committee concluded that presentunderstanding is too limited to reach definitive conclusions on this question. why productivity growth in access has not kept pace with othercommunications sectors is an interesting question worthy of further research.economics of scaling up capacity: congestionand traffic managementonce initial systems are deployed, successful broadband providersare almost certain to experience continued demands on their networksowing to increased subscribership and increased traffic per subscriber.these demands have implications both for how the access links themselves are configured and managed and for the network links between theprovider and the rest of the internet. this section provides an overview oftraffic on the internet and discusses some of the common misunderstandings about broadband technology.the term òcongestionó describes the situation in which there is moreoffered traffic than the network can carry. congestion can occur in anyshared system; it leads to queues at emergency rooms, busy signals on thebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.164broadbandtelephone system, inability to book flights at the holidays, and slowdownswithin the internet. as these examples illustrate, congestion may be auniversal phenomenon, but the way it is dealt with differs in differentsystems. in the telephone system, certain calls are just refused, but thiswould seem inhumane if applied to an emergency room (although this issometimes being doneñemergency rooms are closing their doors to newemergencies and sending the patients elsewhere). in the internet, the òbesteffortó response to congestion is that every user is still served, but alltransfers take longer, which has led to the complaints and jokes about theòworld wide wait.ócongestion is not a matter of technology but of business planning andlevel of investment. in other words, it is a choice made by a service provider whether to add new capacity (which presumably has a cost that hasto be recovered from the users) or to subject the users to congestion (whichmay require the provider to offer a lowcost service in order to keepthem).shared links can be viewed as either a benefit or a drawback, depending on oneõs viewpoint. if a link is shared, it represents a potential point ofcongestion: if many users attempt to transmit at once, each of them maysee slow transfer rates and long delays. looked at in another way, sharingof a link among users is a central reason for the internetõs success. sincemost internet traffic is very burstyñtransmissions are not continuous butcome in bursts, as for example when a web page is fetchedña sharedcommunications path means that one can use the total unused capacity ofthe shared link to transfer the burst, which may make it happen faster.in this respect, the internet is quite different from the telephone system. in the telephone system, the capacity to carry each telephone call isdedicated to that one connection for its durationñperformance is established a priori. there is still a form of sharingñat the time the call isplaced, if there is not enough capacity on the links of the telephone system, the call will not go through. callers do not often experience this formof òbusy signal,ó but it is traditionally associated with highusage eventssuch as motherõs day. in contrast, the internet dynamically adjusts therate of each sender on the basis of how many people are transferring data,which can change in a fraction of a second.the links that form the center of the internet carry data from manythousands of users at any one time, and the traffic patterns observed thereare very different from those observed at the edge. while the traffic fromany one user can be very bursty (for a broadband user on the web, a ratioof peak to average receiving rate of 100 to 1 is realistic), in the center of thenetwork, where many such flows are aggregated, the result is muchsmoother. this smoothness results from the natural consequences of aggregating many bursty sources, not because the traffic is òmanaged.óbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.technology options and economic factors165with enough users, the peaks of some users align with the valleys of otherusers with high odds. one of the reasons that the internet is a costeffective way to send data is that it does not set up a separate òcalló withreserved bandwidth for each communicating source, but instead combines the traffic into one aggregate that it manages as a whole.for dialup internet users, the primary bottleneck to high throughputis the modem that connects the user to the rest of the internet. if broadband fulfills its promise to remove that bottleneck, the obvious questionis, where will that bottleneck go? there has a been a great deal of speculation about how traffic patterns on the internet will change as more andmore users upgrade to broadband. some of these speculations have led tomisapprehensions and myths about how the internet will behave in thefuture.cable systems have the feature that the coaxial segment that serves aparticular neighborhood is shared. this has led to the misconception thatbroadband cable systems must slow down and become congested as thenumber of users increases. this may happen, but it need not. indeed,shared media in various forms are quite common in parts of the internet.for example, the dominant local area network standard, ethernet, whichis a shared technology with some of the same features as hfc cablemodems, has proved very popular in the market, even though it, too, canbecome congested if too many people are connected and using it at once.cable systems have the technical means to control congestion. they canallocate more channels to broadband internet, and they can divide theirnetworks into smaller and smaller regions, each fed by a separate fiberlink, so that fewer households share bandwidth in each segment. whetherthey are, in fact, so upgraded is a business decision, relating to costs,demand, and the potential for greater revenue. of course, less sharingwould tend to reduce the cost advantage of hfc relative to other highercapacity solutions such as ftth.dsl is generally thought to suffer from fewer access network congestion problems because the user has a dedicated link from the residence tothe central office. it is true that the user will never see contention fromother users over the dedicated dsl link; however, it also means that theuser can never go faster than the fixed dedicated capacity of this link, incontrast to being able to use the total unused capacity of a shared system.both the cable and dsl systems bring the traffic from all their users toa point of presence (central office or head end), where this traffic is combined and then sent out over a link toward the rest of the internet. thislink from the termination point to the rest of the internet is, in effect,shared by all of the subscribers connected to that point of presence,whether the broadband system behind it is a shared cable system or adedicated dsl system, making the link a common source of congestionbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.166broadbandfor all of the subscribers. the cost of the link depends on both the capacityof the physical link and the compensation that must be paid to otherinternet providers to carry this traffic to the rest of the internet. the costof these links can be a major issue in small communities where it is difficult to provision additional capacity for broadband. so there is an incentive not to oversize that link. the economics and business planning of thiscapacity are similar for a cable or a dsl system.the fact that the links from the point of presence to the rest of theinternet are often a source of congestion illustrates an important point.the number of users whose traffic must be aggregated to make the totaltraffic load smooth is measured in the thousands, not hundreds. so theremay be a natural size below which broadband access systems become lessefficient. for example, if it takes 10,000 active users to achieve goodsmoothing on the path from the rest of the internet, then a provider whogets 10 percent of the market,19 and who can expect half of his users to beactive in a busy hour, needs a total population of 200,000 households as amarket base in a particular region.even if the broadband local access links themselves are adequatelyprovisioned, bottlenecks may still exist, owing to such factors as peeringproblems between the broadband service provider and the rest of theinternet, host loading, or other factors. performance will also be dependent on the performance of elements other than the communications linksthemselves, such as caches and content servers located at various pointswithin the network (or even performance limitations of the userõs computer itself). these problems, which will inevitably occur on occasion,have the potential to confuse consumers, who will be apt to place blameon the local broadband provider, whether rightly or wrongly.19for an examination of the smoothing phenomenon, see david d. clark, william lehr,and ian liu, òprovisioning for bursty internet traffic: implications for industry structure,óto appear in l. mcknight and j. wroclawski, eds., 2002, internet service quality economics,mit press, cambridge, mass.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.167this chapter provides an introduction to the policy context surrounding broadband deployment and discusses specific issues that have shapedthe reasoning of the committee on broadband last mile technology andthat underlie its recommendations. a more detailed history of u.s. regulation related to broadband appears in appendix b, which is recommended for any reader not familiar with the complex regulatory contextwithin which broadband is being deployed. note that this chapter does notcontain the committeeõs policy recommendations, although it lays part ofthe foundation for them. the committeeõs findings and recommendationsare presented in òsummary and recommendationsó at the beginning ofthis volume.the context for broadband policybroadbandñas an extension or phase of the internetñhas been imbued, in media coverage and popular debate, with revolutionary promisethat cuts across traditional policy segmentation. residential broadbandhas ushered in an era of considerable technological innovation and flux.at the same time that a diverse set of technologies, which are characterized by different performance characteristics (bandwidth, symmetry,transparency, and so on), are available for reaching customers, a powerfulconvergent platformñthe internet and its core technologiesñis increasingly favored for delivery of content, applications, and services. enabledby this flexible, generalpurpose delivery platform, a multiplicity of applications and content supported through a variety of business modelsbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.168broadbandhas emerged. the combination of technological and associated businesschanges generates considerable uncertainty and questions about whatregulatory or other approaches are suited to meeting desired goals inlight of this uncertainty.broadband has been targeted by traditional political players in thevarious policy arenas, and it has catalyzed the formation of new politicalalliances. it is subject to past policy developed in part for other telecommunications technologies and is the focus of a number of efforts to shapenew telecommunications policy. the previous chapter explained how thecharacteristics of the different technology options are just a piece of thebroadband puzzle. because the profitability and growth prospects of different kinds of entities are affected by government decisions about whatkind of entity can provide what kind of service, and when and where andhow it can do so, the policy context has a significant impactñthere are nopure investment decisions, and political activity aimed at shaping thecontext is rampant. while many speak of a desire to deregulate, the nature and terms of regulation have become part of the competitive process.moreover, there is something fundamentally highly political in the natureof communications technologies and services, beginning with the importance of communications media in the political process itself.1 the recentintroduction of a number of pieces of legislation aimed at promotingbroadband is another indicator of heightened interest and sometimes intense politicization. proposed measures include tax credits, grants, subsidized loans, and other financial incentives for deployment in underservedor rural areas; support for research on broadband technologies for ruralareas; grants for community planning efforts; changes in the regulation ofincumbent local exchange carriers; and changes in universal service fundrules.2viewed through the lens of telecommunications policy, broadbandinvolves a system with players and rules at federal, state, and local levelsand a long history of political activity that features industry associationsold and new, consumer and issueadvocacy organizations (and consider1for example, the original schemes for allocating radio and television licenses had apolitical connection, with licenses allocated geographically.2bills that would provide financial incentives include h.r. 267, broadband internet access act of 2001; h.r. 1415, technology bond initiative; h.r. 1416, broadband expansiongrant initiative; h.r. 1697, broadband competition and incentives act; h.r. 2139, ruralamerica broadband deployment act; h.r. 2401, rural america digital accessibility act;h.r. 2597, broadband deployment and telework incentive act; h.r. 2669, rural telecommunications enhancement act; s. 88, broadband internet access act; s. 150 broadbanddeployment act; s. 426, technology bond initiative; s. 428, broadband expansion grantbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation169able activity by lawyers and lobbyists for all parties) seeking to influencelegislation, administrative rule making, and court decisions. organizations addressing broadband as part of their lobbying activity have proliferated; they range from mainstream telecommunications trade associations (such as the united states telecom association, the national cableand telecommunications association, and the organization for the promotion and advancement of small telephone companies) to associationsof new telecommunications competitors (e.g., the association for localtelecommunications services and the competitive telecommunicationsassociation) to technologyspecific associations (e.g., dsl forum and thehome phoneline networking alliance), broadband issuesfocused associations (such as the competitive broadband coalition and the opennetcoalition), and consumer advocacy organizations (such as consumersunion, the center for digital democracy, and the consumer federationof america). at issue are considerations such as pricing, service definitions, interconnection terms, and rules for the use of public resources(e.g., radio spectrum and rightsofway) as well as a variety of specialneeds that are usually met outside of normal market action (e.g., universal service and public safety). broadband is also associated with issues ofprivacy, security, and access by law enforcement; the complexity of theseparticular issues necessitates separate examination, and they are not discussed in this report.viewed through the lens of competition policy, the economic regulation associated with telecommunications policy is complemented by antitrust and other matters associated with the structure and conduct of provider industries. the action centers on administrative authorizations (withor without conditions) and legal decisions related to mergers and acquisitions. at issue are basic questions of market power and related conduct,such as interconnection and access to directories.initiative; s. 966, rural broadband enhancement act. bills that would support researchinclude h.r. 2401, rural america digital accessibility act, and s. 430, broadband ruralresearch investment act.bills that would change ilec regulation include h.r. 1542, internet freedom and broadband deployment act; h.r. 1697, broadband competition and incentives act; h.r. 1698,american broadband competition act; h.r. 2120, broadband antitrust restoration andreform act; s. 1126, broadband deployment and competition enhancement act; and s.1127, rural broadband deployment act. s. 500, the universal service support act, wouldextend universal service fund coverage for broadband. s. 1056, the community telecommunications planning act, would provide support for community planning grants. (national journalõs technology daily. 2001. broadband bill status. national journal, washington, d.c. available online at <http://nationaljournal.com/pubs/techdaily/briefroom/billstatus/broadband.htm>.)broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.170broadbandviewed through the lens of consumer protection, legislative and administrative actions focus on consumer experiences. these include pricesand quality of services, fair and clear billing, broadening of access tounderserved areas and populations, linkage to other consumer concerns(e.g., education and health care services), and so on.and there are yet other perspectives. because the greatest deployment uncertainty and expected impact are in the last mile, broadbandpolicy making at state and local levels looms large. it is at these levels thatcommunity and personal impacts are most evident. at state and locallevels, economic development is increasingly linked to communicationsinfrastructure because of expectations about how such infrastructure cancontribute to economic opportunity (e.g., through skills and job development, attraction of employers, and support for telecommuting) and quality of life (e.g., in terms of educational and healthcare resources andcommunity information sharing). many states and a number of localitieshave taken a number of initiatives aimed at broadband deployment.broadband is primarily an issue of domestic policy, but international perspectives arise with respect to competitiveness issues and the international context in which the internet exists.recognizing that a diverse set of actors plays a role in shaping broadband policy is important, because it is too easy to narrow the discussion tostate and federal regulation of the price of communications services, adominant historic concern in telecommunications. state and federal legislators, regulatory agencies, the courts, and local governments all influence policy. decision making takes many different forms: rule making,tariff setting, court cases, and voluntary agreements. the role of cableoperators and companies using terrestrial wireless and satellite meansthat broadband policy encompasses more than traditional telephone rules.relevant policy spheres include regulation of retail and wholesale rates;interconnection and unbundling rules; local cable franchising; access topoles, conduit, and other rightsofway; wireless spectrum licensing; universal service rules; and antitrust law.finally, the committee notes that, much as is the case with other computing and telecommunications sectors, there are often valid conceptualarguments to be made on behalf of a number of different positions andinterests in each policy debate. which position represents the appropriatepolicy choice is a function of circumstances specific to the matter, but onerarely has the empirical evidence required to support one position definitively over others. furthermore, the parties with interests in the outcomeof a policy debate always represent their own positions as unambiguously right and true. thus, at some level, one is ultimately working witheducated guesses, and some mistakes are inevitable.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation171policy implications of technological changethe issues raised by the deployment of broadband technologies andservices are in some ways quite different from the ones that policy makersface in regulating the narrowband telecommunications sector. in narrowband, the principal issues facing policy makers today involve the fashioning of policies that will facilitate the efficient conversion of a mature marketplace dominated by a single provider to a competitive marketplaceserved by different facilitiesbased and nonfacilitiesbased providers. inthe case of broadband, the marketplace is in its infancy and evolving inuncertain directions. although major technological changes in the publicswitched telephone network have occurred, such as the movement frompartyline to singleline service or the development and deployment ofvertical services, the development and deployment of broadband servicesare occurring over a much shorter time. this leads to difficulties in estimated costs. trends in the costs of some elements, such as customer premises equipment, can be estimated on the basis of conventional wisdomabout mooreõs law and the impact of rising production volumes. butevery so often, some kind of component or process innovation can lead toa significant cost change.3 it is not surprising, given this young and evolving marketplace, that the committee found uncertainty in predictions ofpersubscriber costs and takerates. at the same time, infrastructure tendsto be enduring, which implies that errors in planning can have longtermconsequencesña reality that has contributed to a relatively slow pace ofregulatory evolution as well as conservatism in some segments of thetelecommunications industry, even in the face of rapid change.4regulation in the face of rapid changehistorically, even when there was lessrapid technological change intelecommunications, governmental regulators generally have not attempted to control the process of change directly. the federal communications commission can exercise influence over technology for many purposes: to encourage or enable new services, which is the emphasis in thisreport; to assure certain protections (e.g., against radio frequency interference or safety hazards); and to support certain kinds of uses of the infra3for instance, companies have announced a number of innovations in the mechanics ofdeploying fiber, such as vgroup splicing, blowin of fiber into conduits, and robotic installation in sewer pipes.4for an earlier discussion of different industry cultures, see computer science and technology board, national research council. 1996. the unpredictable certainty: information infrastructure through 2000. national academy press, washington, d.c.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.172broadbandstructure that are given priority through public policy decisions (e.g., 911emergency services, law enforcement access capabilities,5 and disabilityaccess). early on, the government posture with respect to the marketdominance of at&t evolved to reflect evidence that at&t devoted, without a government mandate but with protected revenue, considerable resources to improving the efficiency and capabilities of its network throughtechnological advances. later, government efforts to open previouslyclosed markets motivated equipment manufacturers and service providers to develop and deploy equipment and facilities that could take advantage of those commercial opportunities.6 today, for example, literallyscores of firms are deploying fiberoptic cables and advanced switchesand routers in local and long distance networks to provide voice and dataservices, a phenomenon that (along with mobile wireless) has been fueledrecently by tens of billions of dollars in venture capital. rather than mandate particular technological solutions, the fcc has tended in recent yearsto address technology via selected performance requirements againstwhich industry groups could develop specific standards, and even theseactivities seem to have diminished over time.7 in the turbulent wirelessarena, the fcc has been changing its procedures for issuing radio licenses, from adopting auctions for allocation of spectrum to considering asystemwide rather than sitespecific licensing approach.nonetheless, the fcc has been faulted for some of its approaches tonew technologies.8 more generally, both regulators and investors have5communications assistance for law enforcement act, 47 usc 1001, pl 103414.6in the 1950s, for example, advances in microwave technology (originally developed forthe government during world war ii) created an alternative system for transmitting telephone calls over long distances, in lieu of at&tõs embedded system of wires. in 1958, thefcc authorized large businesses to use microwave facilities to construct their own privatenetworks. in 1969, the commission took the next step and permitted firms to compete directly with at&t for certain types of services. and in the 1980s, with divestiture bringingthe realities of competition closer, at&t executives came to revise their own assessment ofthe costs of adding fiber in their longdistance network as competitor actions, such assprintõs òpin dropó advertisements, made the case more compelling.7in the case of ò1+ó access, for example, the fcc did not specify the particular types ofmodifications to existing telephone switching equipment that were required to provideò1+ó access. instead, it mandated the performance requirements that the carriers wouldhave to satisfy and allowed the carriers, working with equipment manufacturers, to develop the specific technical modifications.8some argue that both the fcc and at&t were slow to cultivate cellular telephony,where deployment and commercial service lagged key innovations considerably; that thegranting of licenses for uhf television channels proved to be a costly diversion of resourcesand spectrum; and that the approach taken to standardsetting for advanced (òhighdefinitionó) television serves to slow progress in that arena. see, for example, òa very longdistance: a regulatory call put cell phones on hold,ó technology review, may 2001, p. 110.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation173guessed wrong on many technologies; it has been easy for people to bothover and underestimate the potential of new technology. this point wasemphasized by many participants at the committeeõs june 2000 workshop, which included comments on disappointments in such technologies as integrated services digital network service and multipoint multichannel distribution service (in its video distribution incarnation), amongothers, for which the technology proved limited in practice, penetrationnever reached anticipated levels, and better alternative technology wasultimately adopted. such experiences underscore the fundamental difficulties that regulators have in gauging the coevolution of technologiesand marketsñand their influence on them.9 the problem of understanding the trends and implications of new technology seems especially acutefor the internet, since few regulatory agency staff, at least at the fcc,have been expert in internetrelated technologies.10 the fcc has recentlylaunched several initiatives aimed at increasing its technical capacity inthis and other areas.11one of the most obvious indicators of the difficulty regulators (andother policy makers) have in keeping up with technology change is thedefinitions they develop and use. the telecommunications act of 1996refers in general terms to òadvanced services.ó required to report to congress on deployment of advanced services, the fcc subsequently definedthese to be at least 200 kbps in either direction.12 as discussed in chapter2 in this report, this sort of definition is problematical: 200 kbps willincreasingly be, at best, a lowest common denominator in an environment9at a june 2000 workshop, thomas krattenmaker of mintz, levin (and previously thefcc and academia) observed: òi would say that any regulation or any response you propose to the fcc that is predicated on your ability to predict what technology will prevail,when, will be a useless recommendation . . . . we are just rife with suggestions, too many ofwhich the commission has adopted, that were based on some ability to know when technology and which technology was going to be deployed. i donõt think weõre capable ofknowing that, and i know the commissioners are notñtheyõre not selected on that [basis].ó10casual observation shows that the fcc has engaged a single internetoriented individual in its office of plans and policy since the mid1990s, and beginning in the late 1990sit engaged chief technologists with internet expertise, but there are limits to what a coupleof specialists in staff positions can accomplish.11steps taken include the 1998 establishment of a technical advisory council and the2001 launch of an agencywide òexcellence in engineeringó initiative, including hiring andtraining measures.12broadband second notice of inquiry, federal communications commission (fcc, 2000,òinquiry concerning the deployment of advanced telecommunications capability to allamericans in a reasonable and timely fashion, and possible steps to accelerate suchdeployment pursuant to section 706 of the telecommunications act of 1996: second report,ó cc docket no. 98146, fcc, washington, d.c., august 21).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.174broadbandwhere capabilities of many technologies are growing; it is unclear whetherbandwidth demand will be symmetrical, as the requirement assumes;and, in any event, the committee believes that use of any static definitionis unwise over the long run. the separation, intellectually and culturally,of those setting policy definitions from those developing the technologymay be unavoidable, but it has consequences.thus, broadband is still a very new technology family, as is the internet in general. the great and general potential of the technology seemsclear, but how it might be effectively (and profitably) commercialized isstill unclear. during this stage, one can expect to see much experimentation with different business and service models by both private and public providers. it may be wrong to assume that executives whose publicremarks exude confidence have deep understanding of all dimensions ofthe new approaches to networking that they are developing. for example,several people at the committeeõs june 2000 workshop acknowledged indiscussions that some of their earlier assumptions had proved wrong andthat their views were evolving with experience.13 indeed, the years 19992000 saw the nation in the midst of a dotcom and telecommunicationseuphoria in the financial markets, while 2001 sees the reverse. all theseobservations, therefore, suggest caution in reading too much into the immediate situation and the importance of business strategists and policymakers staying as flexible as possible during this stage.asymmetrical regulation and achieving technology neutralitythe development of internetbased services that can operate overboth cable and telephone networks has accentuated convergence and technology neutrality. cable, dsl, and wireless providers can offer relativelycomparable applications and services. not only do these alternatives eachoffer highspeed access to the internet, but each also has the potential toprovide services that compete directly with the traditional offerings ofother networks (e.g., cable broadband facilities can be used to providevoice services, and dsl can carry streaming video).the unsustainability of competition that may arise with asymmetricalregulation is most severe when two products or services are perfect substitutes for each other. for example, if dsl and cable modem services are13for example, in remarks to the committee, sprintõs jim hannan said of his mmdsoffering, òwe donõt have effective models . . . so we really donõt understand how the network behaves. weõre pushing it every day.ó hannan observed that projected upstreamtodownstream traffic ratios were much higher than what was observed when sprint deployed its network; this was attributed largely to customer use of napster.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation175extremely close substitutes, disparate rule sets are likely to be a significant problem in the long run, unless bundling broadband access withother services (cable television or telephone) creates some differentiation.to the extent they are differentiated in ways that reflect demand heterogeneity, this is less of a problem. still, even if the platforms do not providedirectly compatible services, they may provide services that are nonetheless substitutable for each other.their convergence notwithstanding, these technologies are for historical reasons subject to separate and substantively different regulatoryregimesña situation characterized by some academics, industry representatives, and fcc officials as regulation in òstovepipes.ó at the fcc,stovepipes are embodied in bureausñcable services, common carrier,mass media, and wireless telecommunications. those bureaus, in turn,correspond to focused enabling statutes, which reinforce the traditionallinkage of technologies with industries and specific services. appendix bcontrasts the regulation of telecommunications common carriers (whichaffects dsl provision) with that of cable operators. terrestrial wirelessand satellite are subject to yet another set of distinct regulations. lookingacross the various stovepipes, the greatest constraints appear to apply tothe telephone industry, where rules (retail price regulation and newermarketopening requirements) are intended to inhibit ilecs from takingunfair advantage of their historically dominant position as regulated monopolies in telephony as they enter into other market segments; but onealso sees cable franchising provisions being applied to broadband delivered over cable.the issue of asymmetrical regulation of broadband has been highlighted by the current debate over òopen access,ó discussed in detail below. cable operators have maintained that the internet access serviceoffered over their networks is a cable service and, consequently, that theyare not required to offer unaffiliated isps that wish to reach cable subscribers access to this service. opponents have claimed that cable operators are engaged in the provision of a telecommunications service whenthey offer highspeed access to an isp and, hence, sought to have regulators require cable operators to offer that service on a nondiscriminatorybasis to unaffiliated isps. (this argument has had traction in the courts;one response has been a move by some cable companies, which haveresisted being classified as telecommunications services, to embrace thedesignation as a way of avoiding franchise payments, illustrating themaneuvering that goes on.) other parties have contended that government intervention is unnecessary (and may be harmful), because marketplace forces are sufficient to cause cable operators to make access available to unaffiliated isps as soon as technical problems are addressed andbusiness arrangements supporting access to multiple isps are put in place.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.176broadbandwhile technical development continues, successful demonstrations andavailability of unaffiliated isps in some markets suggest that the technicalproblems of supporting multiple isps in cable systems can be overcome.14business aspectsñsuch as provisioning and troubleshooting systemsñare a focus of current activity.further confounding the question are technology trends suggestingthat fiber will be pushed ever deeper into wireline and terrestrial wirelessbroadband networks, meaning that provider networks will increasinglyresemble each other even in terms of technology, at least in all but the lastsegment of the access link. as the similarity in both product (services) anddelivery technology grows, the distinction between the serviceproducing and servicedelivering industries falls, but whether or how one reconciles the associated regulatory regimes is an open question.regulatory legacy and convergence aside, some regulatory issuesspeak to inherent attributes of a technology, confounding any notion of atechnologyneutral policy. implementing local loop unbundling, for example, involves an intimate understanding of the physical environmentof that plant. policy with respect to public rightsofway involves thedetails of poles and conduit access for wireline systems and tower sitingfor wireless. wireless illustrates another challenge to achieving technology neutrality: with different servicesñincluding fixed terrestrial servicesuch as mmds and mobile servicesñassigned to different frequencybands, allocating scarce spectrum among these would seem to requiremaking technology and servicespecific tradeoffs. in some cases, it isentirely reasonable to make distinctions: one does not have spectrumauctions on fiber, for example. however, when obligations of any kindare imposedñperformance obligations certainlyñit is generally very difficult or impossible to be completely technologically neutral. how canone treat these services on an evenhanded basis despite the differences inthe underlying technology?the committeeõs assessment of technology options (see chapter 4)suggests that broadband will not involve a technological horse race oroverall regulatory or market choice among technological options. thevarious access technologies will fill different niches, and multiple connections will be available in many markets (many already have two connectionsñphone and cable linesñcapable of supporting broadband to the14for example, in june 2001, at&t announced that its boulder, colorado, open accesstrials were successful (richard williamson, òat&t completes first open access cabletrial,ó interactive week. june 7). earthlink subscriber information as of october 2001 indicates that its services are available over time warner cable systems in several markets andthat more markets will be added in the near future.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation177home). this diversity suggests that the issue of technology neutrality willbe around for some time to come. to the extent that neutrality is notachieved, regulatory actions would favor or disfavor options in ways thatcould decrease investment incentives or otherwise distort natural marketforces in ways unfavorable to consumers. decreased choice would reducethe likelihood that facilitiesbased competition emerges or would depriveconsumers of particular cost and performance options.the existence of these asymmetries, as well as the looming contradictions that convergence in the access technologies themselves poses, isrecognized by regulators. what is less clear is how to craft a solution thatimproves the situation. one problem may lie in the concept of neutralityand regulatorsõ goals not to pick winners and losers: neutrality may notbe feasible, given the tight coupling between the subjects of regulationand the details of particular technologies. in avoiding tying regulations totechnologyspecific considerations, one has to find some other spaceñsome more abstract definition of broadbandñin which to regulate. hereone is confounded by such factors as the dynamic nature of broadbandand the twoway link between technologyspecific performance characteristics such as speed and application requirements. also, absent thespecific issues that have been the source of much of telecommunicationsregulation, what would be the goals of regulation of òbroadbandó?competitionthe establishment of robust competition among multiple telecommunications providers, including broadband and other providers, is a basicpremise of the telecommunications act of 1996 (box 5.1). this is viewedby many as the desirable way of making broadband as affordable aspossible, though the view is not universal.15 two principal paths towardcompetition are contemplated in the present policy regimeñ(1) unbundling and resale and (2) facilitiesbased competitionñwhich are discussedin separate subsections below. unbundling arose in the context of policiesaimed at stimulating competition to the ilecs. the 1996 act mandatedunbundling of local loops and other network elements. in contrast tounbundling, facilitiesbased competition involves new entrants using theirown equipment and physical network to compete.15for example, the national telephone cooperative association (ntca) commissioned awhite paper that concluded that the entry of competitors would decrease the takerateachievable by any single carrier, which could substantially undermine the financial case fordsl in rural areas where it is already constrained even without competition. ntca linkedthe issue to its call for only incumbents to be eligible to receive universal service highcostarea support payments (telecommunications reports, january 15, 2001, p. 6).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.178broadbandbox 5.1key provisions of the telecommunications act of 19961related to broadband¥section 251 of the telecommunications act of 1996 establishes a series of obligations that apply to telecommunications carriers. some apply to all telecommunicationscarriers (local as well as long distance and others). some apply only to providers of localtelephone. the most detailed requirements apply to incumbent local telephone companies, such as the bell operating companies. the latterñthose pertaining to incumbentsñconsist of a variety of obligations that collectively are designed to facilitate the entry ofnew providers into local markets and enhance their ability to compete with the incumbents. these include, for example, a requirement that incumbents make available parts oftheir local networks to competing providers on just, reasonable, and nondiscriminatoryterms and conditions. the procedures for implementing these requirements for incumbenttelephone companies are set forth in section 252.¥section 253 generally preempts, with certain limited exceptions relating to universal service and other public policy objectives, any state or local statute or regulation thatprohibits or has the effect of prohibiting the ability of any entity to provide any interstateor intrastate telecommunications service.¥section 254 promotes access to advanced telecommunications and informationservices in all regions of the nation. universal service principles to be implemented by thefederal communications commission include ensuring the following: quality services atreasonable and affordable rates; access to advanced services; access to such services inrural and highcost areas; that all providers of telecommunications services make an equitable and nondiscriminatory contribution to the preservation and advancement of universal service; that specific and predictable support mechanisms are in place to carry outsuch preservation and advancement; that there is access to advanced telecommunicationsservices for schools, health care, and libraries; and that other principles that the joint(federalstate) board and the fcc may determine are necessary and appropriate for theprotection of the public interest are implemented.¥section 255 requires telecommunications products and services to be accessible topeople with disabilities. this is required to the extent that access is òreadily achievable,ómeaning easily accomplishable, without much difficulty or expense. if manufacturers cannot make their products accessible, then they must design products to be compatible withadaptive equipment used by people with disabilities, where readily achievable. what isòreadily achievableó will be different for each manufacturer, depending on the costs ofmaking products accessible or compatible and their resources.¥section 256 sets broad parameters to establish nondiscriminatory access for thebroadest number of users and vendors of communications products and services to thepublic telecommunications networks that are used to provide telecommunications servicethrough joint network planning. it defines òpublic telecommunications network interconnectivityó as the ability of two or more public communications networks used to providetelecommunications service to communicate and exchange information without degeneration, and to interact in concert with one another. this section also regulates coordinationfor interconnectivity and establishes fcc procedures for oversight. it sets out the parame1formally, the communications act of 1934, as amended.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation179ters under which the fcc is to review and eliminate federal regulations that may act asmarketentry barriers for entrepreneurs in providing telecommunications. the fcc wasrequired to conduct such an initial proceeding within 15 months of the lawõs enactmentand thereafter to conduct similar periodic reviews every 3 years.¥section 259 mandates that incumbent local exchange carriers (ilecs) make available to any qualifying carrier any public switched telecommunications equipment or information as should be requested by the qualifying carrier. it excepts situations underwhich it would be economically unreasonable or against the public interest for the ilec tocomply. it permits joint ownership and seeks to ensure that the ilec is not treated as aòcommon carrier for hireó and that the carrier seeking the use of facilities will be allowedthe use of these facilities on just and reasonable terms. finally, section 259 demands atransparent process, requiring the ilec to report the terms and conditions of any facilitiessharing arrangements.¥section 271 requires that the fcc consult with the u.s. department of justice andthe relevant state commissions before ruling on a bell companyõs request to offer inregioninterlata services. upon application by a bell company, the fcc has 90 days to considerwhether the applicant has met a 14point òcompetitive checklistó of marketopening requirements contained in the section and whether the companyõs entry into the interlataservice market is in the public interest.¥section 301 stipulates that the fcc shall review any complaint submitted by afranchising authority concerning an increase in rates for cable programming services andissue a final order within 90 days after it receives such a complaint, unless the partiesagree to extend the period for such review.¥section 302 eliminates the prohibition on local exchange carrier (lec) provision ofvideo programming in the lecs service area. lecs and others may offer video programming under regulations that vary according to the type of video service being provided(radiobased, common carriage, cable tv systems, or open video systems). with the lawõsenactment, regulation was lifted for cable programming for a basic service tier that was theonly service subject to regulation on december 31, 1994, in any franchise area in whichthe operator serves 50,000 or fewer subscribers.acquisitions and joint ventures (section 302 of the bill, section 652 of the act) are to alarge extent prohibited, though there are several exceptions for certain small and ruralsystems. the law also permits a lec to acquire or joint venture under different terms andcondition in cases where the subject market meets the fccõs definition of òcompetitive.óthe fcc may waive the acquisition and joint venture prohibitions if it determines that theeconomic viability of the market merits such or that to do so would otherwise be in thepublic interest, and if the local franchising authority approves.¥section 303 allows cable operators to provide telecommunications services without first obtaining a franchise to provide those services. additionally, no franchising authority may interrupt a cable operatorõs telecommunications services based on that operatorõs lack of a franchise. the section also prohibits franchising authorities from requiringthat any cable operator provide telecommunications services as a condition for granting afranchise.¥section 706 seeks to promote the deployment of òadvanced telecommunicationsservicesó in a reasonable and timely fashion. it attempts to do this by means of pricecontinuesbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.180broadbandunbundling and resale mandatesunbundling refers to the breaking down of an incumbentõs networkinto smaller subcomponents, which can be either technology components(e.g., a phone line) or service components (e.g., switching), so that theseelements can then be sold separately to other service providers. the goalis to permit new competitors to compete with the incumbent withouthaving to incur the costs and the risks of constructing all of these elementsthemselves. an important difference between resale of services and physical unbundling of network elements is how much leeway the competitorhas for differentiation. with simple resale, the competitor is confined toderiving revenue from the differential between the resale and retail rates,whereas unbundling gives the competitor latitude to provide differentiated services that combine unbundled elements with elements providedby the competitor.most prominent in the context of broadband deployment is unbundling of the local loop. the ilec local access facilities have been thesubject of unbundling rules designed to enable clecs to offer voice anddata services without having to build their own local access facilities. thedsl competitor provides the facilities at both ends of the loop (the dslmodem and dslam) and connects them to the actual copper wires thatbox 5.1 (continued)cap regulation, regulatory forbearance, measures that promote competition in thelocal telecommunications market, and other regulating methods that remove barriersto infrastructure investment. this section also required the fcc to follow up withinquiries into the progress of deployment. reports issued in august of 1999 and20002 found deployment reasonable and timely based on subscribership levels, service and technology options, and infrastructure investment at the time of the inquiries. the august 2000 report observed that advanced services may be unevenly distributed owing to differences throughout the country in wealth and populationconcentration.2federal communications commission (fcc), 1999, òinquiry concerning the deployment ofadvanced telecommunications capability to all americans in a reasonable and timely fashion, and possible steps to accelerate such deployment pursuant to section 706 of the telecommunications act of 1996: first report,ó cc docket no. 98146, fcc, washington, d.c., august;and fcc, 2000, òinquiry concerning the deployment of advanced telecommunications capability to all americans in a reasonable and timely fashion, and possible steps to acceleratesuch deployment pursuant to section 706 of the telecommunications act of 1996: secondreport,ó cc docket no. 98146, fcc, washington, d.c., august 21.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation181make up the loop. under present rules, the clec has considerable freedom to select the particular dsl technologies (and thus such parametersas speed, ratio between up and downstream speeds, and the maximumloop length supported), including technologies not offered by the incumbent. clecs have argued that such differentiation is critical, because theincumbents have generally not deployed the highrate, symmetric dslservices favored by small businesses (one argument is that this reflectsincumbent reluctance to cut into the more costly, profitable t1 data services offered by the incumbents). this form of unbundling, in which apassive network elementñthe copper loopñis made available in rawform to the competitor has the additional advantage to the competitor ofhelping to isolate the quality and nature of the competitorõs service frompotential adverse actions of the incumbent (though issues of successfullyprovisioning the loop in the first place and dealing with crosstalk withinthe cable bundles remain). as an alternative to physical unbundling ofcopper loops, the ilec could also be required to provide access to its dslat the packet level (through atm or ip technologies).cable has a different context for unbundling, both legally and technically. owing to the design of todayõs cable systems, most notably theshared communications medium, strict unbundling along the lines of loopunbundling for dsl is not practical. the open access arrangements contemplated by the fccõs order in the aol time warner merger (andsimilar arrangements being explored by other cable operators) lie somewhere closer to resale than to physicallayer unbundling. the cable operator operates the cable system over which the unaffiliated internet providers connect to customers and hands off the packets destined for theunaffiliated providers at the cable system head end. under the terms ofthe aol time warner merger order, the cable operator must not discriminate against the unaffiliated provider on technical quality; by thesame token, the unaffiliated provider does not have latitude to competewith aol time warner on the basis of the technical quality of the lastmile connection.resale and unbundling rules raise a variety of concerns on the part ofthe facilities owner and the competitor. when a competitor is dependenton another for critical inputs, the facilities owner will have the incentiveand perhaps the ability to use its control over the input to disadvantagethe competitor in the downstream market in which the firms compete.further, as discussed above, facilities owners express the concern thatthey will never be fully compensated for their costs under regulatorsetaccess prices, and how such prices should be set is a matter of currentdebate. not surprisingly, these issues have been vigorously debated sinceresale of telephony began, and they account for a significant fraction oftelecommunications regulatory proceedings and related court cases.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.182broadbandwhen unbundling worksunbundling has been playing an important role in broadband competition. clecs have provided service in areas unserved by the incumbents, and some credit the clecs for having stimulated deployment efforts by the ilecs. as discussed above, competitive service providershave entered the wholesale dsl business by leasing local loops andcolocation space from ilecs. however, clecsõ longterm impact on thecompetitive landscape is in doubt. the competitive dsl industry faces anuncertain future at present, reflected in a series of major business failures.these problems reflect the difficulties inherent in forcing an incumbentmonopolist to open its market to competitive entry, the effects of economies of scale and scope on smaller players, and, from the vantage point of2001, the challenges in raising investment capital for any sort of telecommunications investment. these uncertainties raise questions abouthow to think about unbundling in fashioning future policy.unbundling creates an enforced market structure out of the assets ofan incumbent. one should ask how efficient the resulting market couldbeñhow efficient and effective are control and management with markets based on unbundled versus integrated industry structures, and whatfactors facilitate unbundling? the basic thrust of the literature on organizational factors is that, when technologies are easy to understand andsimple, markets are likely to have a comparative advantage as coordination mechanisms owing to the incentive effects of competition.16 in thiscircumstance, unbundling can be effective. but if the interfaces betweenplayers are complex, an integrated business approach will often be moreeffective.the technical complexity associated with unbundling for broadbandaccess has been seen in the case of both dsl and cable. in the case of cablevideo programming, there is a highlevel unbundling today in the form ofcertain channelsõ being set aside for use by local broadcasters; public,educational, and government access; and leased access. these are logicalunbundling variants with simple technical implications. but more recentproposals have focused on an unbundling at the internet protocol layer.(there were also early proposals to provide unbundling through the useof asynchronous transfer mode, or atm, technology.) concerns todaycenter on the optimal technical mechanisms to support shared access andon establishing operational and management mechanisms for coordination (provisioning, troubleshooting, and the like) between the cable company and heretofore unaffiliated isps.16see, for example, oliver e. williamson, 1975, markets and hierarchies, the free press,new york.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation183as discussed above, dsl unbundling can occur at the physical level,which permits variation in the dsl service that the competitor provides,and at the resale level. where ilecs extend fiber closer to customers,replacing a portion of the existing copper plant, copper pairs no longerrun all the way from premises to the central office, making physical unbundling very complex. issues that must be solved include whether andhow clecs should be given access to colocation space in remotely deployed pedestals, equipment vaults, or even equipment located on poletops. the incumbents have claimed that this level of complexity inhibitsinvestment in new facilities and is a barrier to the progress of broadbanddeployment. in turn, clecs are concerned that installation of new facilities such as fiberfed remote terminals would complicate or preclude thephysical loop unbundling on which their businesses depend. in additionto making colocation and unbundling more complex, remote terminalsalter the economics of physicallayer unbundling, because competitorsare able to serve far fewer customers from a single colocation point.a specific example of this debate centers on project pronto, in whichlocal exchange carrier sbc communications has proposed a program offiber deployment that would enable it to provide highspeed digital services to its customers that are being served by long copper loops or withloops fed from digital carrier loops, and that as a result cannot currentlyobtain dsl service. because the program as originally described wouldhave deprived the clecs of the opportunity to select the equipment ateach end of the remaining loop segments, they argued that the programwould make it difficult for them to use the new infrastructure to do anything other than resell sbcõs dsl service, meaning that they would beunable to differentiate their own service in order to compete with sbc.sbc argued that unbundling at a remote terminal in dsl at the physicallayer is so costly and complex as to be impractical, making higherlevelunbundling solutions a better alternative. the fcc preferred physicallayer unbundling, making the planõs approval contingent on sbcõs agreement to increase the size of the remote terminals to permit competitors toinstall termination equipment there rather than simply to resell sbcõsservice. the issue of incumbentsõ unbundling obligations when they deploy remote terminals is currently the subject of a pending fcc rulemaking proceeding.in the case of dsl, another major complication is that the individualwires connecting subscribers to central offices cannot be treated as entirely independent of each other, as physical unbundling would imply.as detailed in chapter 4, crosstalk, the coupling of electrical signals between nearby wires, creates interference that can degrade the carryingcapacity of each copper pair, decreasing the data rates supported by agiven line length and decreasing the maximum line length over whichbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.184broadbanddsl can run. the interference effect depends on how the signals on thedifferent pairs make use of the different frequencies used for transmissionover the lines, which in turn depends on how the ilecs and clecs makeand coordinate decisions about provisioning customers whose twistedpairs share bundles. the problems will grow as the penetration of dslgrows and as the higher data rates contemplated in the dsl upgradepathñwhich are still more sensitive to interferenceñbegin to be widelyimplemented. coordination may be facilitated by technical standards,which are in development, but which would, if adopted on a mandatorybasis, constitute a regulation of operational network technology. such astandard aims to achieve the sort of clean technological interface alludedto above, thus reducing coordination problems. however, the more thecoordination problems are solved, the less the flexibility of the competitorto differentiate its service, so in the end, physicallayer unbundling maybe no more attractive then simple resale, though much more complex.implications for investment by incumbentsthere are major incentive issues that bear on expectations for overallinvestment and innovation. the analytical models used to justify forcingincumbents to unbundle and sell access to network elements implicitlyassume that incumbentsõ networks are based on a static technology andinvolve only facilities already deployed. in reality, networks are constantly being upgraded, and with the upgrades come new capabilitiesand services. competitors argue that incumbents should unbundle newservices and technologies and resell them, as they are required to do withold services and technologies. incumbents argue that they have no incentive to invest in new facilities or otherwise innovate if they are forced tosell their innovations at cost to their competitors. in particular, whereunbundling is mandated at regulated prices, the incumbent bears the riskof investment but cannot fully benefit from it.facilitiesbased competitionunder facilitiesbased competition, competitors go headtohead, using independently built and operated local access infrastructure.17 it iswidely believed by economists, policy officials, and consumer advocates17facilitiesbased competitors may still make use of some facilities such as backhaul circuits that are owned by other telecommunications companies, including the ilecs, and allfacilitiesbased competitors must at some point interconnect with the other isps that makeup the internet.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation185that facilitiesbased competition is the preferred end state (with the proviso that it also results in a reasonably efficient result, which may dependon the characteristics of the technology or market). a principal argumentis that facilitiesbased competition is the only circumstance that will permit complete deregulation of local markets.in this view, competition though local loop unbundling or resale is atransitional approach to be used while facilitiesbased competition is stilldeveloping. as new entrants grow and gain market share, they will find iteconomic to replace facilities leased from incumbents with facilities leasedfrom nonincumbents or selfprovided. (the cost of using an incumbentõsfacilities is not just the price assessed for the network elements used, butthe ongoing difficulties associated with relying on a dominant competitor.) in essence, resale and unbundling rules do not remove the need forregulation, only shifting it from regulation of end customer prices to regulation of prices charged by facilities owners to resellercompetitors. aslong as competitors are dependent on incumbents for some facilities, suchas loops, regulation of the terms and conditions of the competitorsõ accessto those facilities, including price, will be required. competitors are trulyindependent of each other only if they have their own facilities (or accessto comparable facilities that are not controlled by a dominant competitor).there is a fundamental tension between the shortrun static efficiencies ofunbundling or resale and the longerrun dynamic efficiencies of facilitiesbased competition. forced unbundling or resale at regulatormandatedprices may permit competitors to deploy innovative new services. however, such measures also could lock in the current situation, undercuttingthe longerterm goal of full facilitiesbased competition, especially if therule is that competitors will be granted access at controlled prices to anynew facilities that an incumbent puts in place.structural separationunbundling and resale mandates are among a range of interventionsthat could be invoked to address the market power of incumbent telephone companies by facilitating competitorsõ access to upstream inputscontrolled by the incumbent. several options would involve some sort ofseparation of the incumbentõs lines of business. the weakest form, nonstructural separation, involves the use of accounting safeguards to separate wholesale and retail operations. the most extreme mechanism, divestiture, involves the spinoff of a unit into a separate corporate entitythat is under different control. structural separation, between these twoin terms of the level of intervention, involves the separation of businessunits into distinct corporate entities that remain under common control.that is, an ilec would be required to offer access to its facilities andbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.186broadbandservices at nondiscriminatory wholesale rates to nonaffiliated retail service providers as well as to its own affiliated providers.18structural separation does not necessarily reduce the incumbentsõ incentives to discriminate against competitors or crosssubsidize, becausethe two affiliated entities remain under common control. that is, the firmas a whole still benefits if the wholesale entity discriminates in favor of itsretail affiliates and against unaffiliated retail competitors. (the incentiveto discriminate and crosssubsidize is only fully eliminated if retail operations are divested from wholesale.) but structural separation may discourage the incumbent from engaging in such behavior by making thetransactions between the wholesale and retail entities easier for regulatorsand other outsiders to monitor.to the extent that the structural separation approach succeeds, it hasthe potential drawback in the long term of decreasing the incumbentõsincentive to upgrade the telephone plant because its ability to fully capture the benefits of that investment is constrained. another potentialdrawback of structural separation is that, if there are valid reasons forvertical integration (e.g., reduction of transaction and/or coordinationcosts), then separation could result in net higher costs for consumers. pasthistory with unbundling and interconnection rules also suggests that significant regulatory effort could be required to carry out structural separation. finally, application of separation rules to the ilecs would also complicate efforts to reconcile policy across broadband delivered by differenttechnologies or sectors of the telecommunications industry.how much competition is enough?will facilitiesbased competition prove sufficiently robust to permitincreased deregulation of broadband and to forestall the need for futureretail regulation? if robust facilities competition were achieved, it mightbe possible to back away from existing unbundling mandates,19 and itmight remove the impetus for initiating new mandates in the future (suchas those contemplated under the rubric of cable open access).in the case of broadband, technology options that provide a foundation for facilitiesbased competition are at hand. two wireline technolo18this is somewhat analogous to the separation that has occurred with electricity deregulation in a number of states, whereby the electric utilityõs generation and distribution operations are separated and customers can choose which generation company to purchase powerfrom.19the fcc has an unbundled network elements (une) remand process for removingnetwork elements from the list of required elements to be unbundled if they can reasonablybe selfprovisioned or are available in the market.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation187giesñdsl and cable modemsñthat make use of distinct preexisting communications networksñtelephone wires and hybrid fiber coax cable systemsñare being deployed on a wide scale. the networks that they buildon provide access to the vast majority of the u.s. residential population,though the cost and feasibility of upgrading to support data services varyfrom location to location. a limited amount of facilitiesbased competition from new entrants is also visible. companies are investing in òoverbuildó of incumbent cable providers to compete with them, primarilyusing hfc. two wireless technologiesñterrestrial service using microwave transmission and twoway satellite serviceñare being developedand deployed as well. the longterm economic viability of these competitors is uncertain at present.the bottomline issue with respect to evaluating competition is market powerñwhether a company can keep its product price significantlyabove the competitive level. associated with this are concerns that a company facing insufficient competition will let reliability and quality sufferor will fail to deploy new services. market power is assessed in terms ofcharacteristics of the marketñhow many competitors there are, what theirrelative market share is, what the ability of competitors is to expand output rapidly (using either current capacity or capacity that can easily beexpanded), and how easily new firms might enter the marketñand individual firm conduct (whether it is anticompetitive). some guidelines doexist, such as those developed by the u.s. department of justice and thefederal trade commission (ftc) for use in evaluating proposed mergers, but the analysis in a merger situation is potentially different from thatinvolved in regulating an ongoing market. more generally, there is nofirm basis in economic theory to say how many competitors are òenoughóin the abstract or across all markets or in all circumstances, and opinionsvary considerably. for example, in remarks before this committee, representatives of consumer groups argued in the context of cable open accessthat a choice among four providers might well be insufficient.evolution in technology or business strategy could significantlychange the nature and terms of competition. for example, even if broadband access is itself reasonably competitive, a shift toward exclusive bundling of content and search services with broadband access could lead tothe disappearance of standalone isps as broadband becomes the dominant mode of internet access. the supposition today is that the variousbroadband technologies provide a similar service, an internetbased platform. however, both the technologies and associated business models aremalleable, so it will be important to track their evolution and interactionsover time to understand whether the different access technologies continue to be reasonable substitutes for each other, or whether technologicaldevelopment or business strategies have caused them to diverge. suchbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.188broadbandforces have the potential to lead to a more tiered marketñor distinctmarketsñin which different technologies and industries are associatedwith different kinds of service (e.g., different bandwidths, applications, orprices).finally, consumers with only one or two providers may derive spillover benefits from competition in markets with more competitors, because marketing and pricing programs often do not have sufficient granularity to discriminate in terms of price or quality between market type andbecause of negative public reactions to highly differential pricing.assessing the degree of competitionprecise data are limited, but the deployment numbers presented inchapter 1 of this report suggest that facilitiesbased competition in broadband is beginning to occur in the united states, with ilecs and cableoperators undertaking largescale deployments in many locations acrossthe nation, and overbuilders entering a handful of markets. wireless is analternative in several test markets, and satellite services offer anotheroption. however, overall availability masks considerable variability incompetition at a local levelñby state, by community, or even by household.it is a yetunanswered but critical empirical question whether broadband local access will turn out to be a natural monopoly (as telephonywas assumed to be for many years) in some or all markets. if so, it maycontinue to be dominated by the incumbent telephone companies andcable system operators, limiting facilitiesbased competition to at best twoplayers. the fact that facilitiesbased competition has proved difficult toestablish in the voice telephony markets that were the primary focus ofthe 1996 act, especially for residential service, is not encouraging, butthere are differences between entry into a mature, saturated market and anew, evolving one.at this point in time it is hard to conclude what the overall shape ofthe market will be. it is, however, apparent that there are some geographically defined markets that give rise to concerns about whether broadbandservice will be available within several years and whether there will be anadequate level of competition. in hardtoserve areas, the sheer costs orbusiness risks may be great enough to call into question the goal of creating a competitive market. in these areas, the key goal may be providingservice at all. in deep rural areas, where costs are highest, it remains to beseen whether the performance capabilities, costs, and ability to scale up ofthe existing or planned satellite services will be sufficient to keep customers in deep rural areas at rough parity with others with regard to broadband access. both the extent of coverage (in terms of geographical regionsbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation189and households) and the level of competition will be the subjects of continuing scrutiny by public policy makers and other interested parties.this suggests the ongoing importance of solid data, collected on a systematic basis, to identify where and what level of competition is being created.open access and evolving complements tofacilitiesbased competitionwhen cable operators began upgrading their systems to providecablebased broadband services, concerns were raised that they couldleverage their established cable television infrastructure and franchises toexercise market power in broadband services. the position of incumbenttelephone companies could inspire similar concerns, but they have beenrequired to provide wouldbe competitors with access to their facilities(via unbundling or resale), and public attention has been focused on thecable system operators. the open access debate, which began in 1999, hascatalyzed involvement of consumer advocates, who had had a lower profile in early and mid1990s debates about internet policy, and has provided an important complement to traditional regulation in shapingbroadband policy. critical actions were the merger oversight by the ftcas well as the fcc and court decisions reviewing local efforts to requireopen access.one aspect of the open access debate has been implementationñhowto implement open access, what the actual extent of proposed technicaldifficulties is, and how much the additional costs of supporting competitive isp access over cable facilities would be. when cable modem systemswere first developed in the mid1990s, little thought was given to providing outsiders access to the systems or technology to implement such access. the technical specifications were developed through industry standard setting, coordinated by cable laboratories and building on companycontributions of knowhow. cable labs has since evolved those standards, which have become more supportive of open access, but its cableindustry orientationñwhich contrasts with the more open, broad internetengineering task force that developed many of the internetõs core standardsñhas caused it to be viewed with suspicion by competitors andconsumer advocates. in light of the growing attention to open access,cable operators have been exploring technical options for supporting access by multiple isps. the goal of opening up an incumbentõs facilitiescould, in principle, be achieved in several ways, either at a low level byunbundling the physical links of the provider, or by unbundling somehigherlevel service. early on, lowlevel access to cable infrastructureñfor example, allocation of different frequency bands to different providbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.190broadbandersñfell out of favor, and logicallayer access schemes, in which packetswould be routed to and from the appropriate isp at the cable system headend, have been adopted. there is general agreement that open access canbe implemented, and several pilot efforts have been conducted.a central feature in the open access policy debate has been uncertainty about business models for broadbandñhow will cable providersbehave, and what do consumers want? in adding internet services, cableoperators have had to evolve both their infrastructure and business models. at least initially, cable operators have tended to select a single isp toprovide internet service over their facilities, and the service has typicallybeen bundled with at least some content or services aimed specifically attheir own customers. this reflects in part an extension of usual cableindustry business practices to the new technology, but also the greaterease that having a single partner can provide when entering a new, evolving market. in contrast, as critics frequently observe, much of the dialupisp market has emphasized unrestricted access to internet content (aol,which grew out of a closed content model, is the most notable exception,but several others, such as msn, have also based their strategies on a mixof proprietary and internet content).the open access debates have been informed by attitudes (positiveand negative) about entertainment industries in general (which are associated with content generation and delivery) and television in particular.concerns have been expressed that cable operators will seek control overthe internet content available to their subscribers in a fashion analogousto what they exercise with conventional television content.one possibility is that particular content would be favored, to thedisadvantage of content from unaffiliated major content companies, nichesources, or nonprofit organizations, through placement on startupscreens, differentiated quality of service, or other means. another is thatcable operators would go one step farther and create a òwalled gardenóservice in which outside content is difficult or impossible to access.20 the20a cisco white paper (cisco systems, inc. 1999. òcontrolling your networkña mustfor cable operators,ó available online at <http://www.cme.org/access/broadband/ciscomsoswhitepaper.html>) promoted technology for cable companies to control,perhaps preferentially, content flows from different providers. the white paper addressescable operatorsõ concern about bandwidthhogging traffic from other content providersand service quality in a context where the operator has arranged for supply of certainknown content and customer use of other content is unknown but could be large, while inthe short term network capacity is finite. it speaks to cable operatorsõ concerns aboutresource management by noting that internet technology permits network resources to bemanaged. òsustained service quality over the long term requires ip network control, being able to intelligently segment and manage resources by user type, service, destination,or application so that delivery quality does not suffer with growth or the addition of newservicesó (p. 2).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation191term òwalled gardenó arose in the ostensibly benign if parochial contextof cable marketing and of cable literature from the late 1990s. it has beencited by consumer advocates as evidence of adverse intent,21 though thekinds of preferences that may arise from a walled garden strategy canalso be viewed as similar to what has been seen elsewhere in televisionand newspapers, namely, the use of a transaction with a partner to generate revenue that can lower the price charged to consumers and the preselection of a menu of content deemed to be of greatest interest to consumers. a walled garden is not, per se, hostile to consumers, because itmay lead to lower prices and increased content. the concerns about restricted choice or walled gardens stem in part from the contrast with theunfettered, unfiltered access to content throughout the network that hastraditionally characterized internet services. additionally, there are concerns about media concentration and the relative market position ofbroadband providers that also operate content businesses. ultimately,whether and how consumers can access content from other sources willdepend on the industry response to consumer demand (and the conditions attached to industry acquisitions and mergers) unless public interestis deemed important enough to mandate such access.there are also concerns that those cable operators who are in a monopoly position in their market, which is the case in most markets, will beable to charge other isps or content providers access fees that are higherthan the costs charged to isps or content providers affiliated with thecable operator, giving the latter a competitive advantage. concerns aregreatest for those affiliations that involve ownership (e.g., at&tõs interest in @home or the aol time warner combination). the ilecs, whichare required to unbundle their lines to permit resale competition, haveexpressed the view that not imposing such requirements on cable represents an unfair advantage arising from asymmetrical regulation.cable companies respond that open access requirements could deterthem from investing in system upgrades to support broadband if theyperceive the likely returns under open access conditionsñconditions similar to those faced by ilecsñto be insufficient. these business judgmentsare commonly invoked as threats in a political process; they are, of course,impossible to verify ex ante.in 20002001, the nationõs two largest cable system operators agreedto provide customers a limited choice of isps. the rules under which thiswill be done were outlined through conditions placed on the aol timewarner merger by agreement with the ftc in 2001, which will be moni21see, for example, center for media education, 2001, broadband networks and narrowvisions: the internet at risk, cme, washington, d.c., available online at <http://www.cme.org/access/broadband/atrisk.html>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.192broadbandtored by an individual (trustee) appointed to do so. this potential template for the rest of the industry was hammered out under significantpressuresñabove all the threat of the merger being blocked if the ftcõsconcerns were not addressed. meanwhile, in 2001, at&tñprior to awholesale revision of its business planñappeared to be moving towardopen access through its business strategy, influenced by regulatory andlegislative scrutiny as well as a larger transition in business emphasis andstrategy. 22 this change in strategy, ironically, was initiated by aol (as anisp) prior to its cable acquisition. other cable operators may offer similarterms to forestall the longterm threat of federal intervention in the cablebroadband business. in addition, overbuilders have begun constructinghybrid fiber coaxial cable systems in some markets that isps will be ableto use to provide highspeed services.whether this pattern of opening up will prove to be widespread andenduring remains to be seen. already, similar activity has been stimulated in connection with another internet technology, instant messaging,itself a factor in the governmentõs approval of the aol time warnermerger and an emphasis in the fcc investigation into the merger. theevolving open access situation, which illustrates a government role different from regulation per se, underscores the role of political activity in theshaping of telecommunications outcomes. it raises the prospect of ispsmaking appeals to federal and state regulators to seek adjustments inaccess terms and prices and to antitrust authorities. under these circumstances, it is hard to ascertain what facilities operators or isps might do ormight have done òvoluntarilyó as their judgments about business opportunities evolved.access issues in multidwelling unitsmuch of the debate about competition and open access assumed thatbroadband access is arranged at the sole discretion of the actual users. inthe case of multidwelling units (mdus), the establishment of facilitiesbased competition also depends on installation of new inbuilding facilities or working out some form of shared access to this infrastructure.mdus, in which landlords may establish partnerships (including exclusive ones) with broadband providers, have become a new battleground22for example, at&t launched a recently concluded open access trial in boulder, colorado, at the end of october 2000 that connected eight isps: two at&t affiliates(excite@home and worldnet), two dsl providers (winfire, inc., and flashcom, inc.), twonational isps (earthlink, inc., and juno online services, inc.), and two local isps (rmi.net,inc., and friendlyworks, inc.) (òisp offers ôopenaccessõ plan; at&t begins trial in boulder,ó telecommunications reports, november 6, 2000, p. 17).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation193for competitive and incumbent providers in both the residential and commercial markets. mdus are an increasingly attractive and important earlymarket opportunity in university and many urban communities, whichare characterized by highdensity housing, high density of broadbandcustomers, or both. the committee did not explore the multidwelling unitissue at length, but notes that it is an area of ongoing debate over competition and access, particularly because these typically highdensity situations are likely most attractive to wouldbe overbuilders.landlordprovider arrangements can both improve the competitiveness of real estate through improved telecommunications services andprovide an additional revenue stream through business arrangementswith providers. not surprisingly, agreements often include exclusive access provisions, raising concerns on the part of both tenants and otherproviders about infringements on their access. debate relates to access tobuildings by competing service providers, the latitude of building ownersvis‹vis tenants to control providersõ access to their property and therefore services available to tenants, and the role of federal and state regulators. clecs and telecommunications equipment providers, for example,have formed òthe smart buildings policy projectó23 to address relevantissues via lobbying.24 this group appears to be at odds with a new class ofproviders that focuses on building access, blecs (buildingfocused lecs),which may receive some investment by building owners.25 meanwhile,building owners, with their own lobbying arms,26 argue that the issuefalls under a real estate rather than a telecommunications regulation regime. access and service issues also fall under the purview of local governmentsõ new municipal ordinances and cable franchising agreements.the whole area of access in mdus awaits possible direction and clarification from the fcc and the courts.access to poles, conduit, and rightsofwayanother dimension of access is access to utility poles and conduits.facilitiesbased wireline entrants cannot enter a market if they cannotobtain access to the poles and conduits to install their facilities. issues ofconcern include prices, terms of access, processing time for an order, andthe rate at which access is provided. the situation is complex, with varied23see <www.buildingconnections.org>.24 òlawmakers ask fcc to hold off on building access rulemaking,ó telecommunications reports, september 4, 2000, pp. 910.25òbuilding owners, carriers spar over fcc proposal to block service, extend ban onexclusive pacts,ó telecommunications reports, january 29, 2001, pp. 2728.26an example is the real access alliance; see <www.realaccess.org>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.194broadbandownership arrangements (e.g., ownership by the electric utility or sharedownership between the electric utility and the ilec); various costsharingarrangements among users; and circumstances in which different ratesapply to ilecs, clecs, and cable operators.27 the federal pole attachment act28 in effect requires utilities to provide cable companies withnondiscriminatory access to poles, ducts, conduits, and rightsofway. itgives the fcc jurisdiction to ensure reasonable rates and access termsunless a state chooses to regulate these. various state measures aim toincrease access. municipalities also have several options for using theircontrol over rightsofway to ease entry by new providers.expanding access and universal service policiesthe extension of universal service policies to new infrastructure networks has generally enjoyed public support, as seen in the cases of thepostal service, electricity, and the interstate highway system, as well astelephony. because broadband technologies and services will not be deployed everywhere at the same time and some areas will lag in serviceavailability and/or performance, policy makers almost certainly will faceclaims from different sectors that they should intervene to ensure thatbroadband services are available in a shorter time frame throughout thecountry. it is important, therefore, to establish (1) where access is fundamentally constrained without government intervention, (2) who is notlikely to be reached after the broadest likely private sector deployment isachieved, and (3) how and when to intervene.rationales for interventiongenerally speaking, competitive markets are assumed capable of delivering the types and quantities of goods and services that consumersdesire at the prices they are prepared to pay. in some cases, however, acompetitive market may fall short of societal objectives, and governmentsmay act to promote some kind of equity when the efficient outcomesassociated with the market do not. a key premise of universal serviceprograms has been the assumption that access to the service is essentialfor meaningful participation in the social, economic, and political sys27peter blum. 2001. pole attachment rules: establishing a state policy. slides from briefingto national association of regulatory utility commissionersõ summer 2001 telecom committee meeting. available online at <http://www.naruc.org/committees/telecom/poleattachment.ppt>.28section 224 of the communications act of 1934, as amended, 47 usc 224.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation195tems; drawing a similar conclusion with respect to broadband will, ofcourse, involve assessment of how functionality is tied to broadband service and to what extent narrowband alternatives can substitute for broadband in providing socially desired services.the price of a good or service deemed essential or socially importantmay limit its accessibility to significant groups of consumers. for example,the marketplace for food may be competitive, but government nonetheless may decide to intervene in order to ensure that lowincome consumers are able to buy enough to sustain themselves (e.g., through foodstamps).consideration of the rural challenge, and contrasting it to certain urban environments, highlights the fact that lack of deployment may reflecteither lack of demand or insufficient density for profits to motivate investment. concerns about access can be lumped, roughly, into two categories: (1) that broadband services be available ubiquitously at somereasonable price and (2) that broadband services be affordable to most orall of the population. the appropriate interventions in a given locationdepend in part on the regionõs density and demand characteristics (seetable 5.1). an affluent urban neighborhood might be characterized byhigh density and high demand, while a poor urban neighborhood mighthave high density and low demand. a typical rural area would have lowdemand and low density, while a rural community with an active technology user base might have low density but high demand.both of these concerns, together sometimes referred to as the òdigitaldivideó problem, have received national and global attention.29 accessand use disparities are difficult to gauge, because internet access is changing comparatively quickly and because multiple, interdependent factorstable 5.1density and demand factors in universal accesshigh densitylow densityhigh demandcompetition/marketuniversal service mechanisms, demandsolutions adequateaggregation, new technologieslow demandeconomic and communitydevelopment approachesmost challenging29global forums concerned with digital divide issues include the international telecommunications union development forum, the european union, and the g8. u.s. foundations looking at digital divide issues include the markle and the benton foundations.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.196broadband(age, income, education, ethnicity, and so on) are associated with loweruse rates, and geographical disparities in access overlay these other factors. density versus demand is just one possible decomposition of theproblem.òdigital divideó means different things to different people and indifferent situations. there are many òdivides.ó on the technology supplyside, the term may refer to unmet demand for highcapacity longhaultransport facilities, connections to the internet backbone, as well as highspeed local access facilities (dsl, cable, or wireless). to some customers,digital divide means the time it takes to get a highcapacity t1 line installed, or the price to use existing services. to a business customer with abusinesstobusiness web strategy, it means the need for redundantbackup facilities in case one access path is interrupted, for example by acable cut. supplyside problems generally require approaches that encourage building facilities, either directly through application of funds orindirectly by providing incentives or demonstrating or aggregating demand to attract provider investment.on the demand side, digital divide may refer to having less access tocomputers, to internet connections, and to training or content if one is arural resident, senior citizen, native american or other minority, or in afamily with lower income. demandside strategies tend to be best addressed through a different set of strategies, including development oflocally useful content that stimulates increased interest and applicability,creating community networking partnerships or providing public accesspoints or local training in a school, library, community center, or òcybercafeó that provides lowercost alternatives to residential service. suchefforts may also have to face another sort of digital divideñdepending onhow such performanceenhancing elements as caches or content distribution systems are implemented, nonprofit groups may be at a disadvantage compared with commercial producers that are able to pay more toensure quality of access to their content. these considerations may beincorporated in economic development programs, although even expertsin rural technology deployment note that òinfotainmentó may be the mostimportant driver for demand.30of course, supplyside and demandside problems can be related.low density makes it more expensive to build facilities. lack of demandmakes it more difficult to recover the cost of building infrastructure. economic development programs (generally at the state and local levels)naturally treat communications infrastructure, including broadband, asan element of local economic development. being more holistic in nature,30andrew cohill at june 2000 workshop of the committee on broadband last mile technology.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation197programs tend to combine cultivation of demand with provision of access, education, and opportunities; if successful, they increase willingnessto pay.implicit transfer mechanisms used for universal telephone servicein contrast to programs for which support is explicit, such as the foodstamps program, the support schemes in the telephone industry historically relied on implicit mechanisms. the history of the telephone industryshows that government intervention has helped to overcome actual orperceived barriers of substantial cost differences among geographical areas as well as to enable basic telephone service access among qualifyinglowincome individuals (e.g., through lifeline and linkup programs).for context, note that nationwide telephone subscribership is between 94and 95 percent, but the penetration level for households with annualincomes under $5,000 is only 79 percent, as compared with almost 99percent of households with incomes of at least $75,000 (a few of the highincome houses may have opted for wireless service instead).31over the years, although the goal of universal service remained acornerstone of state, and to a lesser extent, federal regulation, the meaning of that term changed as the network evolved. in the 1920s and 1930s,universal service probably meant a single telephone in a geographic territory. in the 1940s and 1950s, universal service may have meant access topartyline service. in the 1960s and 1970s, universal service may havemeant access to singleline service. and, more recently, universal servicehas been interpreted to mean touchtone service and access to more advanced services.stated simply, business long distance customers paid more for service and residential customers paid less for connections to the publicswitched network. similarly, rural customers paid substantially less thandid urban customers compared to the relative cost of their lines. one viewof this situation, commonly held, is that in each case, one group is subsidizing the other. other observers argue that it is natural that differenttypes of customers will make different contributions to the common costof the network.32 whether one characterizes them as natural rate differen31òphone subscribership holds steady at 94.4%,ó telecommunications reports, december18, 2000, p. 21, summarizing the fcc report telephone subscribership in the united states,which is available online at <www.fcc.gov/ccb/stats>.32see j.c. panzar and s.s. wildman. 1995. ònetwork competition and the provision ofuniversal service,ó industrial and corporate change, vol. 4, no. 4, pp. 711719. see also davidgabel. 1999. òrecovering access costs: the debate,ó in b. cherry, s. wildman, and a.hammond iv, eds., making universal service policy: enhancing the process throughmultidisciplinary evaluation. lawrence erlbaum associates, mahwah, n.j.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.198broadbandtials or implicit transfers, the following distinctions have been the subjectof telephone policy and practice:¥business versus residential. business customers typically are chargedhigher rates for local telephone service than residential customers, eventhough the cost of serving business customers frequently is lower (because they are located in areas with higher population densities). theseprice differentials relative to other customers are justified on a variety ofgrounds, including the òpositive externalityó produced by maximizingthe number of customers connected to the telephone network. that is, thevalue of being connected to the telephone network increases as moresubscribers are added. also, because the existence of a business can depend on communication, businesses typically value communicationsmore than residences do (including the value businesses attach to calls toand from residential customers), and it can therefore make sense, even incompetitive markets, to set prices that reflect such different valuations.33¥long distance versus local service. typically, the largest single cost ofproviding telephone service is the cost of the loop that connects a customer to the first point of switching in the telephone network, the òlocalloop,ó the centerpiece of the last mile. the cost of a local loop is fixed (i.e.,it does not vary with the number or duration of calls that are placed orreceived, up to its full capacity). because the local loop is necessary toproviding both long distance and local service (as well as any other telephonedelivered services), its costs are common to both. economists areused to saying that there is no a priori appropriate way of allocatingcommon costs among the different products that are jointly supplied bythe associated assets.34 historically, regulators required incumbent telephone companies to recover part of the local loop costs from the flatrated33while the elasticities of the different customer classes are not well understood, it islikely that this results in a situation where customers with the least elastic demands pay thehighest price, which is the general relationship that one gets with ramsey pricing. aninteresting question is whether this could be a competitive outcome. historical work bygabel and a formal model by panzar and wildman suggest yes, though elasticity was notan issue in the model. furthermore, more traditional models of competition allow for pricediscrimination. baumol and willig have argued in new zealand regulatory proceedingsthat competition will necessarily generate ramsey prices. (see panzar and wildman, ònetwork competition and the provision of universal service,ó and gabel, òrecovering accesscosts: the debate,ó 1999.)34in most economic markets, the various products produced with common assets allmake contributions to the common costs. thus, for motion pictures, the fixed cost of producing a film is covered by earnings from theaters, videocassettes, pay television, and overtheair broadcasting, not to mention foreign markets.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation199monthly charges assessed to end users for local service, part from theshorthaul toll rates paid by end users, and the balance from perminuteaccess charges paid by carriers providing interstate and intrastate longdistance service. the precise manner by which the common costs areallocated will have differentiated impacts on consumers. while it has theeffect of holding down the price of telephone service for those who placefew long distance calls, the practice of recovering part of the fixed cost ofthe local loop from usagebased prices, some observe, has been inefficientand has artificially depressed demand for long distance service.¥urban versus rural. the cost of providing local telephone service tourban customers is generally lower than the cost of serving rural customers. the higher population densities enable a telephone company to servea greater number of customers from a single switch, and the loops connecting an end user to the first point of switching generally are shorter inurban areas. at the same time, this factor may be offset owing to thegreater benefit obtained from technologies that overcome distance anddispersion, and there may be more willingness to pay by rural users,other things equal, given perceived value.35 federal and state regulatorstraditionally have implemented complex cost and price averaging andother policies to maintain prices for basic telephone service in rural andother sparsely populated areas at levels comparable to and often evenlower than those paid by subscribers in urban areas.36 state regulatorshistorically required telephone companies to average their rates over largegeographic areas so that customers in densely and sparsely populatedareas paid the same rates.37 highcost programs transfer funds for thepurpose of providing service in lowdensity, expensivetoserve areas.because they support the upgrade of telephone facilities, highcost fundscan also indirectly contribute to increased dsl availability as well asincreasing dialup modem line speeds.3835as noted by richard civille in his remarks before the committee in june 2000.36full parity is not the goal. for example, rural customers have much smaller local callingareas (the areas in which local calls are covered by the monthly flat rate) and as a result maypay much higher total bills.37some rural states adopted forms of rate deaveraging by, for example, requiring customers in some areas to pay a òzone chargeó in addition to the averaged, basic rate.38an area of current debate is whether the highcost fund should be explicitly expandedto cover broadband (and, a related question, whether caps on these funds should be relaxedto support advanced services buildout). proponents of such changes argue that they arevaluable mechanisms for enhancing rural infrastructure. for example, the federalstatejoint board on universal serviceõs rural task force recommended that the fcc adopt aòno barriers to advanced servicesó policy that would permit highcost funds to be used inways supportive of providing advanced services, including reducing loop lengths, removbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.200broadbandthese support mechanisms have gradually been reformed in variousways following passage of the telecommunications act of 1996 (e.g., ashift from usage rates to flat rate recovery). but they still depend in parton one form or another of implicit transfer and still reflect assumptionsabout technology and the market more rooted in voice than in broadbandservices. the sustainability of implicit support schemes is in questionwhen those services are not provided on an integrated basis by a regulated monopoly. entrants will tend to target the òsubsidizingó customers,since the new entrants are not required to offer service at òsubsidizedórates and, consequently, the price they must offer the existing òsubsidizingó customers need only be lower than the incumbentõs price includingthe subsidy, all other things being equal. similarly, entrants will tend toignore the òsubsidizedó customers because the price they must offer thosecustomers must be less than the incumbentõs price, including the subsidy.a very substantial part of the challenge that the fcc and state regulatorsface in opening local markets to competition is the need to reform thehistorical system of implicit support to make universal service supportcompatible with competition. universal service is not inconsistent withthe introduction of competition, but the historical scheme for maintaininguniversal service is inconsistent with competitive markets for local services. the issue of which firms should contribute (and benefit from) universal service funds is, not surprisingly, a subject of ongoing political andregulatory debate. despite these drawbacks, proponents of implicit support mechanisms note that by virtue of the internal, largely unseen transfers, these mechanisms have the advantage that they may be lesspoliticized and morestable sources of funding.other mechanisms for increasing access to broadbandloans and grantsone avenue being pursued by governments, foundations, corporations, and civic groups is partnering to leverage resources and carry outprograms that expand access for underserved rural and urban populaing bridge taps, and otherwise upgrading the network to support dsl (rural task force,federalstate joint board on universal service, 2000, rural task force recommendation to thefederalstate joint board on universal service, submitted to the federal communications commission under cc docket 9645, sept. 29, available online at <http://www.wutc.wa.gov/rtf/rtfpub.nsf>). critics question whether the program should be expanded beyond traditional telecommunications services, and the impact of any increased transfer of funds fromlowcost to highcost areas.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation201tions. loans or matching grants could be considered for other instances ofcommunityinitiated efforts to develop local broadband networks.programs of telecommunications regulatory agencies are complemented by other kinds of programs that may also contribute to connectivity as part of a broader set of programs that support economic development and quality of life in underserved areas. the federal governmenthas supported community access through the department of housingand urban developmentõs neighborhood networks program39 and theu.s. department of educationõs community technology center grants.40the rural economic development act of 1990 (p.l. 101624) created therural development administration within the u.s. department of agriculture (usda), which has other relevant entities and programs, and therural electrification administration makes loans and provides technicalassistance to rural telecommunications providers. for example, theusdaõs rural utilities service41 supports rural electricity, water, and telecommunications infrastructure through loans, grants, and technical guidance. the rural utilities service launched a 2001 pilot program to provide$100 million in 10year loans to companies building broadband infrastructure in rural areas. the program is targeted to communities with upto 20,000 residents, and following the fcc lead, uses a 200kbps transmission threshold to qualify for broadband status.42 telephone cooperativesprovide telephone service and a range of data services in a number ofrural areas, and rural telephone companies have been active in deployingbroadband services.43 cooperatives can help aggregate demand across awidely distributed set of customers.44 there are also focused cooperative39see <http://www.hud.gov/nnw/nnwindex.html>.40see <http://www.ed.gov/offices/ovae/ctc/factsheet.html>.41according to 7 cfr ¤1735.10 (a), òthe rural utilities service (rus) makes loans tofurnish and improve telephone service in rural areas. loans made or guaranteed by theadministrator of rus will be made in conformance with the rural electrification act of1936 (re act), as amended (7 u.s.c. 901 et seq.), and 7 cfr chapter xvii. rus providesborrowers specialized and technical accounting, engineering, and other managerial assistance in the construction and operation of their facilities when necessary to aid the development of rural telephone service and to protect loan security.ó see <http://www.usda.gov/rus>.42òrus sets $100m for rural broadband rollout,ó telecommunications reports, december11, 2000, p. 7. see also <http://www.usda.gov/rus/telecom/initiatives/initiatives.htm>.43national exchange carrier association (neca). 2000. neca rural broadband cost study:summary of results. neca, whippany, n.j. available online at <http://www.neca.org/broadban.asp>.44richard civille, michael gurstein, and kenneth pigg. 2001. òaccess to what? first mileissues for rural broadband,ó white paper; see appendix c. see also the national telephone cooperative association <www.ntca.org>, which publishes rural telecommunications.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.202broadbandfinancing organizations.45 finally, a variety of corporate initiatives havealso provided support for community network access.the federal government has also intervened in the form of the erateprogram, originating in the telecommunications act of 1996 and launchedin 1998, to provide funds (partial or matching support) for highspeedaccess for schools, libraries, and health care facilities.46 the erate program uses funds raised from taxes levied on particular communicationsservices to expand public access broadband services through these facilities. the program is associated with significant increases in school connectivity, where its influence has been to accelerate, enhance or complement, or enable that connectivity, and there is evidence that it issupporting increases in the bandwidth of connections sought by schools(e.g., movement from òplain old telephone serviceó to t1 and then t3lines).47local points of presence and applications have also been supportedthrough an evolving effort that has been more like a demonstration programñthe technology opportunities program (top) (originally the telecommunications and information infrastructure assistance program)ñatthe u.s. department of commerceõs national telecommunications andinformation administration (ntia). the program began in 1994 and focuses on model uses in public sector and nonprofit contexts. whereassome $2 billion have been awarded under erate, top awards total about$150 million.48 collectively, these programs increase awareness, fosterdeployment and use, and extend broadband beyond those consumersmost likely to go after it on their own.tax incentivesanother option for promoting access is to provide tax incentives forinvestment in highcost areas. tax options to promote broadband deployment in highcost and/or lowincome areas are appealing on two grounds.first, they avoid longrecognized economic distortions associated withfunding universal service goals through revenues raised by taxing certainservices within the specific industry (the approach used for basic tele45see national rural utilities cooperative finance corporation (<www.nrucfc.org>) andits affiliates.46erate involves discounts on eligible facilitiesõ purchases of telecommunications andinternet services plus internal networking, with discounts varying with location (e.g., highcost, lowincome).47òtelcos, system integrators see rising ôerateõ revenues,ó telecommunications reports,september 11, 2000, pp. 4648. òpoorer, larger applicants get more ôerateõ funds, studyfinds,ó telecommunications reports, september 18, 2000, p. 29.48see <http://www.ntia.doc.gov/otiahome/top/grants/briefhistorygf.htm>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation203phone services, and now, through the erate, for broadband connectionsto schools and libraries). such levies applied selectively within an industry can distort relative prices and, thereby, choices made by the users ofcommunications services.49 selective, withinindustry levies of this typealso may create financial incentives for investments in economically inefficient facilities and services that bypass the providers and services subject to the internal tax. thus, ilecs have frequently argued that many ofthe investments in network facilities by clecs were motivated by thefinancial payoff to be realized by providing long distance carriers andlocal businesses with the opportunity to avoid local access charges; similar thinking for plans to use cable plant to offer local service was also oneof the reasons at&t offered for its purchase of cable operator telecommunications, inc. (tci). investments motivated by the avoidance of extracharges created by policy interventions rather than the pursuit of production costdriven competitive advantage are inefficient and a waste of societal resources. tax credits (and other subsidies such as the highcost fundsupport mechanism) still may provide incentives for what is ultimatelyuneconomic activity.second, reliance on tax credits to finance broadband deploymentwould mean that the federal government would have to consider thefinancing of communications policy goals in the context of the larger setof societal tradeoffs that necessarily must be addressed in setting andallocating federal budgets. to the extent that tax credits are used, theywould put the financing of communications policy goals squarely withinthe traditional budgetary process. this might force a better integration ofcommunications policy goals into the larger set of societal goals addressedthrough various types of federal funding, so that the relative merits ofcommunications policy goals might be appropriately assessed in comparison with other social policy goals in the allocation of scarce government resources. because telecommunications spending would competeagainst many other interests, it might also mean lessstable funding fortelecommunications programs.vouchersanother way of putting financing òon the booksó is to issue vouchers,similar to food stamps. as a budget line item, a voucher program is even49for example, contributions to the universal service fund have traditionally been builtinto charges that longdistance carriers pay local exchange carriers for completing theircalls over local networks. because such policydriven charges must necessarily be recovered in the price of longdistance calls, the price of long distance increased relative to theprice of local service and other communications services.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.204broadbandmore evident in the decisionmaking process. broadbandspecific vouchers might be a useful tool for promoting broadband penetration. it isimportant, however, that such vouchers be targeted as narrowly as possible to specific groups of consumers (e.g., lowincome consumers or thoseliving in highcost service areas) who are not likely to subscribe in theabsence of such aid. there is little point in subsidizing purchases thatwould be made without the subsidy. vouchers are especially attractive insituations in which infrastructure deployment is not an issue (serviceproviders already have an incentive to build out an area), but to whichsome subset of potential customers in a builtout service area would notsubscribe at prices that service providers would have to charge to covertheir costs.50 in these circumstances, a voucher can be a highly specificinstrument for encouraging subscriptions that would not happen otherwise. it is less clear that vouchers have advantages over direct paymentsto service providers if the goal is to promote infrastructure deployment inareas that might not otherwise be served. to the extent that providersmight compete to offer services to customers in such areas, there is thedanger that competitive lowering of service prices would transfer someportion of the voucher to consumersõ pocketbooks rather than to coveringinfrastructure expenses. a more efficient approach in these areas mightbe to let providers bid for the right to serve these territories.research to develop technology alternativesfinally, there is the option of supporting research as a means of promoting access. much of the excitement associated with progress in broadband technologies and the diffusion of fiber builds on research and development that has enabled new technological approaches and/or loweredthe costs or increased the performance of existing approaches. the federalgovernment is key in supporting basic research and fostering public dissemination of the results of research. units of the u.s. department ofdefense (notably the defense advanced research projects agency, ordarpa), the national science foundation (nsf), and other federal organizations are key supporters of communications r&d. most of that r&drecently has focused more on technologies and components that enhancenetwork backbones or development of applications that run over highspeed networks than on local access networks. but darpa has had aprogram aimed at fiber in the distribution network, and nsf and darpahave supported a variety of wireless networking research.50note that, from a lifecycle or total cost perspective, decreases in the cost of equipmentassociated with use of broadband, òcpe,ó will also affect willingness to pay for service.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation205looking forwardfor policy makers, the threshold issue is how to determine whethergovernment intervention to accelerate broadband deployment is necessary or desirable. it appears that the problem is not whether most areaswill ultimately have some form of broadband service, but rather that inrural areas deployment will occur well after such services are available inmore densely populated areas or that the technology options and/or performance will be different in rural areas.the leading broadband technologies today (in terms of installed baseand technology maturity) are both wirebased, and it seems likely that forthe near term at least, distance and population density will deter theirrapid deployment in remote or sparsely settled areas. because of theadded perpassing cost of serving rural areas, different kinds of technicalstrategies may need to be sought there as compared with those for other(denser) areas; an example would be greater emphasis on wireless linksfrom residences to a fiber backbone (possibly leveraging local government or electric and water utility rightsofway).51 with broadband satellite servicesñwhich may be able to serve these areas more costeffectivelythan the wireline alternatives couldñhaving recently been introduced tothe market, one finds a situation where there is some form of broadbandavailable in even the most remote areas of the continental united states. itis also encouraging that the initial offering prices of the starband servicesuggest that the òrural penaltyó may be small (recurring charges for satellite service at $60 per month versus the $30 to $50 per month typical ofcable or dsl). however, it is unclear at this point whether these serviceswill be able to achieve and maintain sufficient performance levels to serveas adequate substitutes for the functionality of wireline services, or howtheir cost and price will compare in the long run with wireline service inmore densely populated areas.at todayõs broadband penetration levels, it seems premature to makeconclusions about the shape of deployment. consumer technologies generally display an sshaped adoption curve, which is marked by an initialperiod of slow adoption, followed by more rapid expansion, and, finally,a leveling off of adoption in the later stages. in the case of narrowbandinternet access, ntia data collected over the past halfdecade show thatoverall access has expanded greatly and that some disparitiesñsuch asacross sex and race/ethnicityñhave narrowed over time, primarilythrough expansion of dialup household access and access in the workplace or public facilities. however, this access has largely leveraged near51see civille et al., òaccess to what?,ó 2001.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.206broadbandubiquitous public telephone network lines, and thus, with the exceptionof some instances where line quality is very poor, has not been hamperednearly as much by technological and economic constraints on where andwhen new facilities are deployed as broadband would be. widespreaddialup use suggests that wide segments of the population find internetaccess to be of value, and thus suggests widespread demand for broadband. in the case of residential broadband, deployment has been growingrapidly from a presently small base, from which vantage point it is hardto infer the longterm adoption rate, patterns of availability, or the ultimate level of adoption.to the extent that policy makers are simply uncertain about the paceof broadband deployment, the benefits of government intervention toaccelerate that process would have to be clear and substantial in light ofthe risk that such intervention may have unintended and undesirableconsequences. although government policies likely contributed to thehigh penetration of telephone service in rural areas, application of suchpolicies to broadband could, in theory, deter future entry by competingbroadband providers that cannot match the belowcost rates resultingfrom averaging and other distributional policies. another risk is that bypicking particular technologies or defining particular services, some government programs aimed at bringing a technology to all may end upfreezing the technology deployed. policy makers seeking to promoterapid, efficient broadband deployment should assess the effectiveness ofstrategies that help avoid these risksñincluding demand stimulation andaggregation, grant and loan programs, and municipal initiatives fosteringmarket entry and competition. this analysis would require policy makersto collect and review reliable broadband data on an ongoing and timelybasis. the development of a comprehensive, national universal serviceprogram may well become desirable in the future, once the pace andscope of broadband deployment become clearer.the local role in broadbandseeking to accelerate or enhance the delivery of telecommunicationsservices in their communities, a number of cities, counties, and stateshave considered or launched initiatives aimed at facilitating, encouraging, or directly building infrastructure for broadband. historically, thedirect local role with respect to telecommunications has been limitedlargely to negotiating cable franchises. in addition, local governmentsñabsent preemption from higher levelsñhave control over local features ofthe deployment environment, such as public rightsofway, zoning, permitting, and so on. these practical issues affect decisions about specialfacilities, such as òcarrier hotelsó and data centers. local governmentbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation207influence has been expressed in conflicts over siting for terrestrial wireless towers and satellite dishes. local governments also control access torightsofway and proposals for local investment in conduit that can bedeployed once and that contain cable or wire supporting multiple providers and services. today, communities are exploring how to use thesepoints of leverage as well as other mechanisms and incentives to promotebroadband deployment.local governments have a direct interest in neighborhood, community, municipal, and regional infrastructure, and it is within the community that existing government, corporate, university, and school networksare deployed. local governments may be in a better position than national providers are to collect and verify local marketplace information,such as discovering and/or aggregating latent demand for broadbandservices, and these governments involve people whose jobs involve satisfying local interests. indeed, where local entities have moved to providelocal infrastructure, it has typically been when no commercial firm waswilling to invest in a given community.local initiatives are not without their critics, however. for instance,while local decision makers may see benefits from broadband, it can be ashard for them as for service providers to predict and elicit consumerdemand52 and design sustainable business models for municipal broadband enterprises. telephone and cable incumbents tend to protest localefforts to serve more than government users with services procured orprovided by government entities.53 critics also argue that locally basedefforts are less likely to be commercially sustainable in the long run, suffering regularly from lack of access to capital to support upgrades. localefforts may also have insufficient economies of scale to be viable in thelong run, and risk becoming overly politicized.local and regional broadband initiatives cover a wide range of possibilities, from focusing on local government infrastructure to facilitatingaccess for the community at large. local approaches vary for obviousreasonsñsize, local market desirability, and whether existing providershave been introducing broadband service. this variation may ultimately52civille et al. (òaccess to what?,ó 2001) argue for demand cultivation in combinationwith access promotion through community economic development programs. their acknowledgment that growing demand may take workñthat simple access is not sufficientñimplicitly supports the view that accelerating deployment is risky.53óprivatesector carriers say they shouldnõt have to compete with the entities that regulate their rates, grant them operating certificates and franchises, control their access to vitalrightsofway, and tax themó (òcommunity size: the difference in citiesõ telecomchoices?ó telecommunications reports, december, 4, 2000, pp. 3638).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.208broadbandlimit what can be learned or replicated from any specific instance, but aninformal network of supporters of local efforts has fostered the exchangeof relevant information, including approaches to architecture, contracting, and financing, to maximize opportunities for local officials to learnfrom others.54the examples listed in box 5.2 indicate the sorts of initiatives thathave been undertaken at the local or regional level.55 they include, forexample, public operation of a multiservice network, where a municipalor county agency is the operator, providing retail services to the end user.municipal service monopolies are not unusualñwater or sewer authorities are the dominant model, and public power utilities are found in anumber of localesñbut the high level of complexity and rate of change intelecommunications technology compared with water or electricity supply pose a risk. and as noted above, this approach may raise objectionsfrom private sector providers, who see the public service as being unfairlysubsidized. however, if there is no private sector provider on the horizon,it may be an attractive option.another option is some form of publicprivate partnership. again,this raises concerns about the risk in a government bodyõs entering intowhat may be a longterm relationship with a selected private sector player.if the relationship sours, it may be difficult to replace the private sectorplayer. this sort of approach runs the same risk as that with exclusivecable franchisingñcommunities may derive revenue or other benefitsfrom the arrangement, but the partner may not deliver the level or qualityof service desired. additional complications arise if the public sector hascontributed funding to the venture.the drawbacks of the approaches listed above argue that local governments concentrate on taking steps to encourage and facilitate competition among private sector players rather than creating new quasimonopolistic entities. as a public sector partner with multiple privateproviders, a public agency would not be competing with a private sectorretail service provider. another advantage of this strategy is that it meansthat private sector providers do not have to negotiate with each other to54one ongoing effort that attracted the attention of this committee has been the work ofbill st. arnaud as part of canadaõs canarie program. see <http://www.canarie.ca/>.55the community broadband deployment database, established by the national regulatory research institute at ohio state university for the federal communications commission, lists more than 200 community broadband programs, covering a range of technologies, target user groups, and funding sources. see <http://www.nrri.ohiostate.edu/programs/telcom/broadbandquery.php>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation209obtain access to facilities, which reduces the need to regulate their conduct.easing access to rightsofway is the simplest step, but this may not beenough to induce new entrants. another option is for a local or regionalgovernment agency to install fibers (or conduits through which fibers canlater be pulled) and use this investment to lower the barriers to entry byprivate sector players by making the infrastructure available to them.this approach can be implemented in a number of ways. one is the òfibercondominiumó model, in which a locality declares its intention to buildout fiber along its streets and invites any interested parties to purchasesome share of the fibers installed (and possibly installs additional darkfiber for future use). typically, some provision is made to lease colocationspace for service providers at the fiber termination points. alternatively,the locality may enter into partnerships with one or more private sectorcompanies to install (and possibly maintain) the fiber. the town itself cansign up, as can schools and municipal departments, businesses and otherprivate sector players in the town, citizens themselves, and any interestedbroadband providers. the locality provides the motivation and coordination for joint actionñit shares in the cost of the common construction, butit may also prohibit the digging up of streets again for some period afterthe construction. by avoiding the extra cost of uncoordinated overbuildingñkeeping down the perpassing costsñthis approach attempts to provide competition at perpassing costs comparable with those of a singleprovider. local and regional government or quasigovernmental agencies can also act in effect as anchor tenants that underwrite some of thecost of installing infrastructure, reducing the costs for other governmentagencies, private sector firms, or even individual customers. the consequence of this action is that more providers may be motivated to enter themarket in the town.finally, localities may choose to launch experimental pilot projects toexplore new technologies, system architectures, or business models. stateor federal grants can help support communities exploring options or enable them to purchase facilities that today are more costly than they willbe in the future when suppliers are able to achieve scale economies in theproduction of such equipment. such pilot efforts can demonstrate theviability of systems, demonstrate the extent of demand for them at thelocal level, and support achievement of scale in use, either by closingaccess gaps or increasing interest in use. the state or federal role is appropriate, given that results of the experiment can help inform future privatesector or public sector initiatives using similar systems. new developments can also build in broadband infrastructure, as is beginning to happen (box 5.3).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.210broadbandbox 5.2some examples of municipal and regional broadband initiatives¥blacksburg, virginia. the blacksburg electronic village (bev) initiative began in1991 with a publicprivate agreement between the town of blacksburg, bell atlantic (nowverizon), and virginia polytechnic institute and state university. when service launchedin 1993, bev provided blacksburg residents with dialup access. also, starting in 1994,integrated services digital network (isdn) and ethernet have been made available to anincreasing number of townhomes and apartments. because dialup access became available from commercial providers, bev turned over its modem pool customers to the privatesector in 1995, and similarly transferred its ethernet operations to the private sector in1998. at present, 87 percent of blacksburg residents are online, according to bev information. currently, efforts are under way to develop a townwide allfiber network, to integrate wireless with wireline services, and to develop a broadband switch point and exchange for advanced network services. bev was prevented from extending service tosurrounding areas because, after industry lobbying, a law was passed to preclude thisgovernment service provider role.1¥abingdon, virginia. in december 1995, a group of citizens met to discuss thepotential of providing residents of abingdon with highspeed internet connectivity. theseactivities led ôto the launch of the electronic village abingdon (eva) initiative. in additionto modem and isdn connections, a fiberoptic connection from the town managerõs office to the hospital and the washington county main library was established as a partnership between the town of abingdon and sprint. on the basis of results of early trials, theproject was expanded. during phase i, evaõs fiberoptic service was extended in thedowntown area, providing highspeed connections to every building within 150 feet ofthe fiber backbone. phase ii, under way in 2001, is a collaborative effort with highlandsunion bank to extend the fiberoptic cable toward the west of abingdon. the networkprovides 10mbps connectivity within the town network and internet connectivity at 1.54mbps. subscribers need to purchase a fiberoptic transceiver (about $150) and pay a onetime installation charge of $75. monthly access fees are $35 per month for 10 mbps anda single internet protocol (ip) address. recently, 100mbps service has been added for $70per month.2¥berkshire county, massachusetts. berkshire connect was established through a1997 grant of $250,000 from the berkshire legislative delegation and the berkshire regional planning commission. a project task force committee, with representatives fromcultural institutions, local businesses, public access organizations, and local business consultants, was established to propose a strategy for enhancing berkshire countyõs infrastructure and to reduce the cost of networking government agencies. the original strategycalled for berkshire connect to partner with the private sector and use a mix of public andprivate funds to build the infrastructure, but global crossing/equal access, the winningbidder, agreed to build the infrastructure without using public funds. the agreement establishing the service offers volume pricing, with prices for all members decreasing as moresubscribers sign up. berkshire connect competes with the incumbent lec, verizon, in1blacksburg electronic village (bev). 2001. òabout the bev.ó available online at <http://www.bev.net/project/brochures/about.html#2>.2see the electronic village abingdon home page online at <http://www.eva.org/>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation211both the retail and wholesale markets, though it claims more success in the wholesalemarket (providing backbone services to other providers). berkshire connect does not offerresidential or last mile service at present, but is currently working to define a businessstrategy for last mile service. it is also exploring new business relationships with othermassachusetts regional networks.3¥lagrange, georgia. through the lagrange internet tv initiative, the city oflagrange, georgia, provides web access to all cable television subscribers in this community of 27,000 residents. in 1998, charter communications, inc., and lagrange entered into a leaseback agreement in which the city financed and constructed a twowayhybrid fiber coax network (using city funds, without state or federal support). using worldgateõs internet on every tv service, it allows lagrange cable tv subscribers to haveweb access at no additional cost.4¥glasgow, kentucky. in 1994, as glasgow was being wired for cable, town officialsdecided to facilitate internet traffic via cable as well. the 12yearold glasgow fiberopticsystem, one of the first of its kind, provides relatively inexpensive cable and highspeedinternet services to 8,000 homes and businesses, or twothirds of the local market forcable. according to its managers, it has broken even for the past 4 years. proponents notethat the network has been moderately successful in spurring local economic activity. forexample, franchino mold & engineering co. is cited as having opened a new facility inglasgow in 1998, in part because the cityõs network allowed for an easy exchange of datawith engineers at the companyõs lansing, michigan, headquarters. twothirds of glasgowõs businesses and a quarter of its residences now pay for broadband cable. the townõsnetwork connectivity is also used for a variety of other functions including controllingtraffic lights, coordinating utility repairs, and plotting school bus routes.5¥washington county, ohio. seeing inadequate broadband facilities in the county,the nonprofit washington county community improvement corporation (cic) launched anonprofit corporation, sequelle, to provide terrestrial wireless broadband communications to southeastern ohio and the midohio valley region, targeting business and educational customers. using a mixture of state and federal startup funds, it plans to launchservice in 2001.6¥chicago, illinois. chicagoõs civicnet is a citywide initiative to build a new broadband infrastructure for government, businesses, other institutions, and residents. the cityplans to use the $32 million it spends each year on voice and data communications tobecome an òanchor tenantó for a highspeed fiberoptic network, to be constructed inpartnership by one or more lead technology vendors. the city also plans to make cityowned or controlled conduits and tunnels available to reduce installation costs. the3sources include the berkshire connect home page, which is available online at <http://www.bconnect.org/>; òfcc hearing, may 22, 2000,ó which is available online at <http://www.bconnect.org/fcchearing500.htm>; and a personal communication with bill ennen, donahueinstitute of the university of massachusetts, april 19, 2001.4see <http://www.lagrangega.org>.5see david armstrong and dennis k. berman, 2001, òmunicipal networks become rivals for fiberoptic telecom companies: dissatisfaction spurs competition,ó cnbc and the wall street journal,august 17. available online at <http://www.msnbc.com/news/615215.asp#body>.6for more information, see the sequelle home page online at <http://www.sequelle.com/>.continuesbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.212broadbandultimate goal is for fiber networks to extend to every neighborhood, and ultimately downevery street.7¥lane and klamath counties, oregon. the lane klamath regional fiber consortium, formed by lane and klamath counties and the cities of coburg, chiloquin, klamathfalls, lowell, merrill, oakridge, springfield, and westfir, negotiated joint agreements withpacific fiberlink (now worldwide fiber). in return for assistance with permitting and anexchange in lieu of rightofway fees, the local governments received 12 strands of fiberinstalled in a contiguous strand extending approximately 200 miles from coburg to merrill, with points of access in the cities and significant county points along the route. consortium members plan to use this fiber to increase communication opportunities to all theresidents along the route and in communities adjacent to it.8¥marietta, georgia. in 1996, marietta fibernet became georgiaõs first municipallyowned company to be certified as a competitive local communications carrier. whollyowned and operated by marietta, it is structured as a separate business. the companybegan constructing its network in the spring of 1997. today marietta fibernet provideshighspeed voice and data services to local schools, hospitals, and businesses over 170miles of fiberoptic cables.¥thomasville, georgia. thomasvilleõs community networks services (cns) operates a citywide fiberoptic network capable of supporting highspeed internet access, cable television, and energy management services, as well as a dialup internet access service. cns now has more than 3,000 customers for its rose.net internet service andexpects many of those customers to move up to rose.net express, a broadband internetservice, when it becomes available. thomasville recently entered into an agreement withneighboring tifton through which it will help launch tiftonõs proposed friendly city networkõs internet service.9¥grant county, washington. the grant county public utility district (pud) initiallylaunched its fiber network, zipp, in order to upgrade its electrical substation control. itlater decided that the network could also be used to provide telecommunications servicesin the county. through zipp, independent service providers can provide data, voice, andvideo services to their customers. the pudõs fiber backbone was completed in 2000, andpilot projects aimed at commercial and residential customers are underway. in 2001, thepud began marketing to the general public. major residential fiber construction and buildout are slated to take place between 2001 and 2006 to reach 90,000 homes.10¥muscatine, iowa. muscatine power and water (mp&w), the townõs incumbent,municipally owned public utility, was first to deploy highspeed facilities in muscatine.following a 1996 marketing study and detailed feasibility study, the communications utility was launched following approval by public referendum in 1997. the communicationsutility received $18 million in initial funding from the municipal electric utility and7see department of general services, bureau of telecommunications and information technology,city of chicago. 2000. òrequest for information: chicago civicnetó (specification no. b09189503),november. available online at <http://www.cityofchicago.org/civicnet/civicnetrfi.pdf>. see also tomkontzer. 2001. òchicagoõs civicnet takes a step closer to reality,ó informationweek.com [january 4].available online at <http://www.informationweek.com/story/iwk20010104s0007>.8see <http://www.ruralfiber.net/lkpage.html>.9see georgia municipal association. 1999. òtifton and thomasville enter internet agreement,ó october 7. available online at <http://www.gmanet.com/news/1999/1007.internet.shtml>. see also thomasville utilities community network services (cns). 1999. òpress releases.ó available online at<http://www.tucns.com/press.html>.10see the zipp fiberoptic network home page online at <http://www.gcpud.org/zipp/>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation213completed construction of its fiber network in the spring of 1999. mp&w provides highspeed cable modem internet access to residential customers and a municipal area network for business customers. mp&wõs telecommunications network consists of a hybridfiber coax system with 125 homes per node, which can deliver a maximum of 4 mbpsdownstream and 1 mbps upstream for connected customers. mp&w obtains its connection to the internet backbone through a division of iowa network services, inc. (ins), atelecommunications firm formed by a consortium of 128 independent telephone companies.11¥ashland, oregon. building on ashlandõs earlier fiber network initiative, local internet companies are cooperating with the city to establish a new service, dubbed òashlandunwired.ó in early 2001, the effort began with a demonstration at ashlandõs starbuckscoffee shop. using access points running the ieee 802.11bstandard wireless local areanetwork technology, it aims to provide wireless internet access via the cityõs fiber network.project a and open door networks, citycertified internet service providers, have offeredto provide connectivity through the ashland fiber network and assistance to help anybusiness or organization wishing to provide ashland unwired to their customers.12¥tacoma, washington. the cityõs public utility, tacoma power, began its networking activities with the construction of a fiberoptic network in 1997. in 1998, it launchedcable television service as a competitor to the existing franchisee (tci, now at&t). in1998, it began providing internet service over the cable television network and began fullcable modem service in 1999.13¥san diego county, california. the high performance wireless research and education network (hpwren) project was launched in 2000 to build, demonstrate, andevaluate a noncommercial, prototype, highperformance, widearea, wireless network insan diego county. built by researchers at the university of california at san diego undera $2.3 million grant from the national science foundation, the network includes backbone nodes on the uc san diego campus and a number of rural areas in san diegocounty, including the pala and la jolla tribes in remote san diego county. amonghpwrenõs goals are to explore how scientists can make use of the network for realtimedata collection and how the network can be used by rural native american communitiesfor interactive computer classes and remote tutoring programs. in addition to the researchand education applications, the hpwren team is also investigating ad hoc advancednetwork development and experimentation in collaboration with local crisis managementagencies.1411see <http://www.mpw.org>. case study reported in federal communications commission. 2000.òinquiry concerning the deployment of advanced telecommunications capability to all americans ina reasonable and timely fashion, and possible steps to accelerate such deployment pursuant tosection 706 of the telecommunications act of 1996: second report,ó cc docket no. 98146, august.available online at <http://www.fcc.gov/bureaus/commoncarrier/orders/2000/fcc00290.pdf>.12see ashland fiber network. [undated]. òfrequently asked questions.ó available online at <http://www.ashlandfiber.net/index.asp?page=faq#1>. see also ashland unwired. 2001. òopen door networks and project a unveil wireless internet access in ashlandó [press release], january 29. availableonline at <http://www.ashlandunwired.com/news.htm>.13see tacoma power, click! network. [undated.] òproject history.ó available online at <http://www.clicknetwork.com/news/history.htm>.14see the hpwren home page at <http://hpwren.ucsd.edu/>, as well as hanswerner braunõs testimony before the house science committeeõs subcommittee on research, july 31, washington, d.c.,available online at <http://www.house.gov/science/research/jul31/braun.htm>. see also òwireless internet to native american reservations,ó populartechnologies.com, [undated], available online at<http://www.populartechnologies.com/news/01/02/15/0414200.shtml>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.214broadbandbox 5.3examples of greenfield developmentsnew community and subdivision developments are increasingly incorporatingbroadband fibertothecurb or fibertothehome with other advanced exterior andinterior networking infrastructure and services. these projects are often joint ventures between building developers who own the properties and rightsofway; convergent telecommunications providers; and real estate investors and homeowners.several examples follow:¥centennial, indiana. hfc internet, phone, and cable provided to 900 homesnorth of indianapolis by the builder, estridge company, and first mile technologies.the cost will be repaid through homeownersõ association fees.¥dc ranch, scottsdale, arizona. all homes are being built with structured wiring to support inhome networking.¥celebration, florida. in a disneybuilt new community near orlando, at&t,sprint, and jones communications have formed a joint venture to provide connectivity.1¥summerlin, nevada. in a community outside las vegas, fibertothecurb isbeing installed by the howard hughes corporation and sprint.2¥valencia and newhall ranch, california. in communities developed by newhallland & farming, sbc communications is providing broadband voice, video, anddata to homes through a revenuesharing venture with the developer.¥hatchet ranch, colorado. rye telephone of colorado city is installing fiber to500 homes in an 80squarekilometer new community.31see the celebration, florida, home page online at <http://www.celebrationfl.com/>.2for more information, see òsummerlin: a profile,ó available online at <http://www.therousecompany.com/whoweare/hughes/summprofile.html>.3information from <http://www.fone.net.soco/guide/colocity/rtc/home.html>; robert pease.2000, òrural areas present better business case for fiber to the home,ó lightwave, june,available online at <http://lw.pennnet.com/articles/articledisplay.cfm?section=archives&subsection=display&articleid=73404&keyword=hatchet%20ranch>; and canet3news, 2000, òrural areas better business case for fiber to the home,ó november 2, available online at <http://www.canarie.ca/mlists/news2000/0185.html>.the risk in all of these possibilities is that the local government willnot be equipped with the knowledge or skills to negotiate with a largeprivate sector provider. if the town does not act carefully, there is risk ofindustry capture, an outcome in which a private sector provider manipulates the situation to the point where the town becomes dependent on itand thus loses any power to negotiate or foster competition. with somenotable exceptions, local governments are less likely to be familiar withthe technology and business side of networking than they are with morebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband policy and regulation215traditional government operations, which places them at a disadvantagein planning or acquiring networking infrastructure or services than aprivate sector firm would be. the risk can be minimized if the town sticksto a facilitating role at the infrastructure level and encourages competition from the outset. still, industry is not monolithic, and some companiescan be expected to favor and others to resist local efforts to foster marketentry. local governments, especially in smaller communities, often havelimited capabilities. action at the higher levels of government is an important part of this local approach as well, to coordinate experiences, tocatalog best practices, and to define the playing field with overarchingregulation that prevents the obvious forms of mutual abuse.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.216abramson, norman. 1999. òinternet access using vsatõs.ó san francisco, calif.: alohanetworks, october 5.alvarez, lizette. 2001. òin capitol, at&t and bells fight to control web access.ó new yorktimes. august 29, p. c1.american national standard t1e1.4 working group on digital subscriber line access.2001. òamerican national standard for telecommunicationsñspectrum managementfor loop transmission systems.óanderson, ken, and anne page mcclard. 1998. òalways on: broadband living enabled.óbroadband innovation group, mediaone labs, october.anderson, ken. 1999. òtechnology and convergence of the digerati.ó mediaone labs.june.andersen, william, et al. 1999. òapplying a policy of nondiscriminatory access to highspeed internet access over cable in king county, washington.ó a report to thebudget and fiscal management committee, metropolitan king county council. october.andersson, goete. 2000. òswedenõs broad jump: debate is warming up for universal highspeed service.ó tele.com (501), january 10. available online at <http://www.teledotcom.com/article/tel20000824s0034>.angwin, julia. 2000. òcable alliances prompt some consumers to pay twice for web access,ó wall street journal, november 20, p. b1.angwin, julia. 2000. òthe new media colossus: aoltime warner megamerger createsbehemoth that could dominate web, other media.ó wall street journal, december 15,p. b1.arbitron/coleman (presented by pierre bouvard and warren kurtzman). 2000. òthe broadband revolution: how superfast internet access changes media habits in americanhouseholds,ó october 2. available online at <http://www.arbitron.com/downloads/broadband.pdf>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography217armstrong, david, and dennis k. berman. 2001. òmunicipal networks become rivals forfiberoptic telecom companies: dissatisfaction spurs competition,ó cnbc and thewall street journal, august 17. available online at <http://www.msnbc.com/news/615215.asp#body>.armstrong, david, and dennis k. berman. 2001. òtelecom companies confront new rival: the municipal network.ó wall street journal, august 17, p. a1.arc group. 2000. broadband access: opportunities in fixed wireless. surrey, u.k.: arcgroup.associated press. 1999. òibm offers pc with highspeed dsl internal modem.ó august 23.associated press. 1999. òresearchers seek to untangle effects of internet.ó june 8.association for local telecommunications services (alts). 2000. consumer benefits of the1996 telecommunications act. washington, d.c.: alts, february 2.association for local telecommunications services (alts). 2000. the state of competition inthe u.s. local telecommunications marketplace. washington, d.c.: alts, february.at&t. 2000. òat&t ôcuts the cordõ to provide services into homes; debuts nationõs firstwireless local communications companyó [news release], march 22. available onlineat <http://www.att.com/press/item/0,1354,2706,00.html>.atm forum. 2000. òvoice and multimedia over atm: loop emulation service usingaal2,ó afvmoa0145.000, july. available online at <http://wwwcomm.itsi.disa.mil/atmf/vtoa.html#af145>.austen, ian. 1999. òhighspeed lines leave door ajar for hackers: constant connectionsthrough cable or dsl mean new security headaches for home users.ó new yorktimes, july 8. available online at <http://www.nytimes.com/library/tech/99/07/circuits/articles/08hack.html>.aversa, jeannine. 1999. òfcc wonõt regulate internet. really.ó washington post, march 12,p. e3.bagasao, paula. 1999. òknowing about who has access: a matter of strategy.ó imp, december 22. available online at <http://www.cisp.org/imp/december99/1299bagasao.htm>.baker, jonathan b., and susan p. braman. 1998. òdeployment of wireline services offeringadvanced telecommunications capabilityó [cc docket no. 98147], comment of thestaff of the bureau of economics, federal trade commission (ftc). washington, d.c.:ftc. available online at <http://www.ftc.gov/be/v980030.htm>.bar, francois, et al. 1999. òdefending the internet revolution in the broadband era: whendoing nothing is doing harm,ó august. available online at <http://economy.berkeley.edu/publications/wp/ewp12.html>.barnett, malcolm. 2000. òfibre optic cable: unsung hero.ó telecommunications online,april. available online at <http://www.telecomsmag.com/issues/200004/tci/fibre.html>.bechtolsheim, andreas, and david cheriton. 2000. òethernet broadband networkingó(white paper), cisco systems, august 11. available online at <http://www4. nationalacademies.org/cpsma/cstb.nsf/files/wpbbbechtolsheimcheriton.pdf/$file/wpbbbechtolsheimcheriton.pdf>.belinfante, alexander. 2001. òtelephone penetration by income by state (data through2000).ó industry analysis division, common carrier bureau, federal communications commission. available online at <http://www.fcc.gov/bureaus/commoncarrier/reports/fccstatelink/iad/pntris00.pdf>berkowe, kathleen hawkins. 2000. òopen access to cable systems for internet accessproviders.ó media law and policy viii (2).berman, dennis, and shawn young. 2001. òbells make a highspeed retreat from broadband.ó wall street journal. october 29, p. b1.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.218broadbandberresford, john. 2001. òbroadband is not for everyoneñextending existing universalservice broadband would be a mistake.ó ispworld, may 8. available online at<http://www.boardwatch.com/bw/may01/broadbandnoteveryone.htm>.berst, jesse. 1999. òdr. jesseõs internet checkup: the good and bad news about the healthof the web.ó zdnet, june 25. available online at <http://www4.zdnet.com/anchordesk/story/story3553.html>.berst, jesse. 1999. òinternet mind control.ó zdnet, june 21. available online at <http://www.zdnet.com/anchordesk/story/story3531.html>.blackwell, gerry. 1999. òtaking the voip plunge.ó ispplanet, june 11. available online at<http://www.ispplanet.com/services/voipplunge1.html>.blankenhorn, dana. 2001. òclearing the lastmile hurdle.ó ispworld, may 8. availableonline at <http://www.ispworld.com/bw/apr01/lastmilehurdle.htm>.blumenstein, rebecca, and joann s. lublin. 1999. òamid all the bets, one stands out:at&t ventures into cable.ó wall street journal, november 5, p. a1.blumenstein, rebecca, and stephanie mehta. 1999. òqwest makes bid for us west, frontier.ó wall street journal, june 14, p. a3.blumenstein, rebecca, leslie cauley, and kara swisher. 1999. òinside the tangles of at&tõsweb strategy.ó wall street journal, august 13, p. b1.blumenstein, rebecca. 2000. òat&t filing pledges it wonõt influence programming of amediaone venture.ó wall street journal, april 21, p. b6.blumenstein, rebecca. 2000. òsome wonder if contentless at&t will rue cableonlyplans.ó wall street journal, january 14, p. b6.blumenstein, rebecca, and stephanie mehta. 2000. òas the telecoms merge and cut costs,service is often a casualty.ó wall street journal, january 19, p. a1.blumenstein, rebecca, don clark, and leslie cauley. 2000. òat&t acts to gain control ofexcite from cable firms.ó wall street journal, march 30, p. b6.blumenstein, rebecca. 2001. òhow the fiber barons plunged the nation into a telecomglut.ó wall street journal. june 18, p. a1.blumenstein, rebecca. 2001. òreform act hasnõt delivered promises to customers.ó wallstreet journal. may 3, p. b1.booth, william. 2000. òthe big switch in urban renewal: telecom firms bring shine, polish, wiresñbut few peopleñto old la buildings.ó washington post, january 16, p.a20.borland, john. 2001. òpower lines stumble to market.ó cnet news.com, march 28. available online at <http://news.cnet.com/news/010042005337770.html?tag=tppr>.bouvard, pierre, and warren kurtzman. 2000. the broadband revolution: how superfastinternet access changes media habits in american households. arbitron company, newyork. available online at <www.arbitron.com> and <www.colemanresearch.com>.brdc, ltd. 2001. òthe development of broadband access platforms in europe: technologies, services, markets.ó commissioned by the european commission informationsociety directorate, august. available online at <http://europa.eu.int/informationsociety/eeurope/newslibrary/newdocuments/ broadband/indexen.htm>.breckheimer, veronica, and kevin taglang. 1999. òbroadband and the future of theinternet.ó the digital beat 1(14), august 20. available online at <http://www.benton.org/digitalbeat/db082099.html>.brewin, bob. 2000. òcable creeps into the corporation: users of cable for broadband connectivity cite big savings over telco offerings.ó computerworld, october 16. available online at <http://www.computerworld.com/cwi/story/0,1199,nav47sto52454nltam,00.html>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography219brewin, bob. 2000. òcarriers forge pact to avoid interference in fixed wireless microwavebands.ó computerworld, july 10. available online at <http://www.computerworld.com/cwi/story/0,1199,nav47sto46911,00.html>.brewin, bob. 2000. òtelcos ante up $250 m for ôlast mileõ connection bidding rights.ócomputerworld, april 10. available online at <http://www.computerworld.com/cwi/story/0,1199,nav47sto43814,00.html>.brinkley, joel. 1999. òdespite agreement, snags remain for digital tv.ó new york times,november 22, p. c17.brinkley, joel. 2000. òdo viewers even want to interact with tv?ó new york times, february 7, p. c5.broadband project office, manitoba innovation network. 2000. òaccelerating the deployment of manitobaõs broadband network infrastructureó (white paper), june 6. available online at <http://www.min.mb.ca/calendar/whitepaper.pdf>.burnett, ron. 1999. òcommunications policy and the new public sphere: towards a newresearch agenda.ó community technology review (summerfall). available online at<http://www.civicnet.org/comtechreview/communicationspolicyand thene.htm>.burrows, peter. 1999. òfred wilsonõs $50 million bet on info appliances.ó business week,april 14. available online at <http://www.businessweek.com/ebiz/9904/em0414.htm>.cable datacom news. 2001. òcable modem customer count tops 5.5 million.ó march 1.available online at <http://www.cabledatacomnews.com/mar01/mar011.html>.cablevision bluebook. 2001. òhighspeed havens of modems & dsl.ó june.cahners instat group. 2000. broadband consumersñprofiles and strategies, report no.bbwis0005sp.cahners instat group. 2000. òpercentage of internetconnected households soars to 60%in 2000; instat report reveals results in buying and internet usage trendsó [pressrelease], march 28. available online at <http://www.instat.com/pr/2000/is0001sppr.htm>.cahners instat group. 2000. òmany routes to 3g deploymentñoptions depend on starting pointó [press release], march 27. available online at <http://www.instat.com/pr/2000/gw0003inpr.htm>.canadian radiotelevision and telecommunications commission (crtc). 1999. òcrtcwonõt regulate the internetó [news release], may 17. available online at <http://www.crtc.gc.ca/eng/news/releases/1999/r990517e.htm>.canet3news. 1999. òglass is freedom: optical networks for the rest of us,ó june 9.available online at <http://www.canarie.ca/mlists/news/1282.html>.canet3news. 1999. òshould fiber infrastructure be a public regulated facility?ó july 15.available online at <http://www.canarie.ca/mlists/news/1298.html>.canet3news. 2000. òno more tearing up of streets to install optical fiber,ó april 18.available online at <http://www.canarie.ca/mlists/news2000/0084.html>.carroll, jill. 2000. òfcc will determine isp access to cable.ó wall street journal, august 29,p. b2.caruso, denise. 1999. òa new model for the internet: fees for services.ó new york times,july 19, p. c6.cauley, leslie. 1999. òsony enters market for cabletv boxes with $1 billion order fromcablevision.ó wall street journal, september 17, p. b11.cauley, leslie, and nicole harris. 1999. òfixed wireless is attracting big investments.ówall street journal, june 3, p. b4.cauley, leslie. 2000. òat&t faces challenge over cablephone goal.ó wall street journal,april 28, p. a3.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.220broadbandcauley, leslie, and nick wingfield. 2000. òat&t to test multiple isps on cable lines.ówall street journal, june 8, p. b10.center for democracy and technology (cdt). 2000. broadband backgrounder: public policyissues raised by broadband technology. washington, d.c.: cdt, december. availableonline at <http://www.cdt.org/digiinfra/broadband/backgrounder.shtml>.center for media education (cme). 2001. òbroadband networks and narrow visions: theinternet at risk.ó washington, d.c.: cme. available online at <http://www.cme.org/access/broadband/atrisk.html>.cha, ariana eunjung. 2000. òôfreeõ wireless networks?ó washington post, december 8, p.e1.cha, ariana eunjung. 2001. òbroadbandõs a nice pace if you can get it.ó washington post,february 28, p. g4.chatterjee, samir, cherian s. thachenkary, and joseph l. katz. 1998. òmodeling the economic impacts of broadband residential services.ó computer networks 30(14): 12951310.chen, kathy. 1999. òat&t used carrot and stick lobbying efforts in local debates overaccess to cabletv lines.ó wall street journal, november 24, p. a20.chen, kathy. 1999. òfcc backs away from regulating internet gateway.ó wall streetjournal, january 29, p. b2.chen, kathy. 1999. òfcc chairman calls for national policy on highspeed internet access via cable.ó wall street journal, june 16, p. b4.chen, kathy. 1999. òfccõs kennard to argue against rules on broadband web access atthe local level.ó wall street journal, july 21, p. a4.chen, kathy. 2000. òcomcast hopes to offer in 2002 openaccess policy.ó wall streetjournal, march 27, p. a42.chen, kathy, and leslie cauley. 1999. òoregon ruling could hurt at&t plan to offerinternet access on cable lines.ó wall street journal, june 7, p. b3.chervokas, jason. 1998. òthe new boys network.ó the industry standard, june 12. available online at <http://www.thestandard.com/article/0,1902,649,00.html>.christopher, abby. 1999. òopening the door for home networks.ó upside 11(6): 6670.cioffi, j.m. 2001. òunbundled dsl evolution,ó t1e1.4 contribution 2001088, february,los angeles, calif.. available online at <http://wwwisl.stanford.edu/people/cioffi/dsm/t1e1pap/1e140880.pdf>.cioffi, j.m., g. ginis, w. yu, and s. zeng. 2000. òspectrum management with advancingdsls,ó etsi tm6, monterey td06, november.cisco systems. 1999. òcontrolling your networkña must for cable operatorsó (whitepaper). available online at <http://www.cptech.org/ecom/openaccess/cisco1.html>.cisco systems. 1999. òwhite paper: migrating to a new world business model.ó cisco.civille, richard, michael gurstein, and kenneth pigg. 2000. òrural regional strategies forbroadband demand.ó center for civic networking and the technical university ofbritish columbia, june 15.clark, david d. 1999. òhighspeed data races home.ó scientific american, october. available online at <http://www.sciam.com/1999/1099issue/1099clark.html>.clark, david d. 1999. òimplications of local loop technology for future industry structureó in s. gillette and i. vogelsang, eds., competition, regulation, and convergence:current trends in telecommunications policy research. mahwah, n.j.: lawrence erlbaumassociates.clark, david d., william lehr, and ian liu. 2002. òprovisioning for bursty internet traffic:implications for industry structure,ó to appear in l. mcknight and j. wroclawski,eds., internet service quality economics. cambridge, mass.: mit press.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography221clark, don. 2001. òmicrosoft advances on game, tv fronts.ó wall street journal, january 5,p. b2.claymon, deborah. 1999. ònetõs impact revised upward.ó san jose mercury news, june 9.available online at <http://www0.mercurycenter.com/svtech/news/indepth/docs/econ061099.htm>.clec news. 2000. òcompetitors made gains, still face challenges, alts report says.óclec news, february 3. available online at <http://www.clecplanet.com/news/0002/000203alts.htm>.cleland, scott. 2000. òresidential broadband outlookñinvestment implications of aduopoly?ó washington, d.c.: precursor group, august 11.cleland, scott. 2001. òdatatopiañwhy data transport growth stories may disappoint.ówashington, d.c.: precursor group, february 5.cleland, scott. 2001. òhow broadband deployment skews economic/business growth.ówashington, d.c.: precursor group, february 22.cochrane, peter. 1994. òdark fibre will transform telecommunications.ó ieee spectrum,technology 94, january.cohill, andrew. 2000. òtelecommunications for neighborhoods and communities: fourkey areas of investmentó (paper from blacksburg electronic village). available onlineat <http://www.bev.net/project/digitallibrary/commtel.pdf>.cohill, andrew, and jeffrey crowder. 2000. òcommunitybased broadband telecommunications infrastructure,ó technical report 200101v3. virginia tech. march. availableonline at <http://www.bev.net/project/digitallibrary/broadbandv3.pdf>.cole, jeff. 1999. òboeing, in a strategic shift, to develop its own satellite systems andservices.ó wall street journal, june 14, p. a3.cole, jeff. 1999. òlockheed, partners to develop system of multimedia, internetaccess satellites.ó wall street journal, may 6, p. a3.communications business and finance. 1999. òlarry darby asks ôhow much broadband capacity enough?õó may 3.computer science and telecommunications board (cstb), national research council. 1994.realizing the information future: the internet and beyond. washington, d.c.: nationalacademy press.computer science and telecommunications board (cstb), national research council. 1996.the unpredictable certainty: information infrastructure through 2000. washington, d.c.:national academy press.computer science and telecommunications board (cstb), national research council. 1998.trust in cyberspace. washington, d.c.: national academy press.computer science and telecommunications board (cstb), national research council. 2000.the digital dilemma: intellectual property in the information age. washington, d.c.:national academy press.computer science and telecommunications board (cstb), national research council. 2001.the internetõs coming of age. washington, d.c.: national academy press.conklin, j.c. 1999. òextension cords.ó wall street journal, september 13, p. r13.consumer federation of america (cfa). 1999. òconsumers demand open access to thehigh speed.ó washington, d.c.: cfa.consumer federation of america (cfa) and consumer action. 1999. transforming the information superhighway into a private toll road: the case against closed access broadbandinternet systems. washington, d.c.: cfa and consumer action, september. availableonline at <http://www.consumerfed.org/bbreport.pdf>.consumer federation of america (cfa). 1999. òwhile federal authorities watch and waitfor corporate interests to close the internet, consumers and local governmentsshould demand open access.ó washington, d.c.: cfa.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.222broadbandcooper, mark, and gene kimmelman. 1999. the digital divide confronts the telecommunications act of 1996: economic reality vs. public policy. washington, d.c.: consumersunion, consumer federation of america, february. available online at <http://www.consunion.org/pdf/telecom0299.pdf>.cordella, paul. 2000. òbell atlantic paves the way for inregion interlata long distanceapproval.ó media law and policy viii (2).covad communications company. 1998. òdefining digital loopsñavoiding remonopolization in a digital worldó (working paper series, no. 1), june 4. available online at<http://www.covad.com/pdf/digitalloop.pdf>.crane, david. 2000. òswedenõs broadbandforall shames canada.ó ottawa business journal 5(28): 7, march 27.crandall, robert w., and charles l. jackson. 2001. the $500 billion opportunity: thepotential economic benefit of widespread diffusion of broadband internet access.washington, d.c.: criterion economics, l.l.c., july. available online at <http://www. criterioneconomics.com/documents/crandalljackson500billionopportunity july2001.pdf>.cukier, kenneth neil, and justin hibbard. 2000. òspectrum shortage: giving away 3gspectrum may have more merit than auctions do.ó red herring magazine, october.culver, denise. 2001. ònew homes for broadband.ó net economy, april 2.davidson, paul. 2001. òlove thy neighborõs net link.ó usa today, january 16, p. 8b.department of general services, bureau of telecommunications and information technology, city of chicago. 2000. çrequest for information: chicago civicnetè (specification no. b09189503), november. available online at <http://www.cityofchicago.org/civicnet/civicnetrfi.pdf>.dickson, glen. 1999. òvod servers wait for demand.ó broadcasting and cable, may 31.dodson, sean. 2000. òfree as the air we breathe.ó the guardian, october 12. availableonline at <http://www.guardian.co.uk/online/story/0,3605,380723,00.html>.donovan, aaron. 2001. òfaster data connection waits impatiently in line.ó new york times,march 22, p. g3.dooley, joe. 2000. ònew local loop: make way for the pon.ó telecommunications (september). available online at <http://www.telecomsmag.com/issues/200009/tcs/newlocalloop.html>.dornan, andy. 2000. òwho owns the airwavesó (global watch column). networkmagazine.com (march). available online at <http://www.networkmagazine.com/magazine/current/0003global.htm>.drake, william j. 1999. toward sustainable competition in global telecommunications: fromprinciple to practice. a report of the third annual aspen institute roundtable oninternational telecommunications. washington d.c.: aspen institute. available onlineat <http://www.ceip.org/files/projects/irwp/pdf/aspensustainablecompetition.pdf>.dreazen, yochi. 2001. òverizon plays every angle in broadband battle.ó wall street journal,august 15, p. a16.duttaroy, amitava. 1999. ònetworks for homes.ó ieee spectrum 36(12). available onlineat <http://www.spectrum.ieee.org/pubs/spectrum/9912/hnet.html>.dvorak, john. 2001. òthe future of the isp.ó ispworld boardwatch, may 8.economics and technology, inc. 1999. òbuilding a broadband america: the competitivekeys to the future of the internet.ó boston, mass.: e&t, inc.economist. 1998. òhold the line: connecting american homes to the internet requiresstrong regulatory nerves,ó december 12.economist. 1998. òtelecoms. broadband bottleneck,ó november 7.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography223economist. 2000. òdivide and conquer: spare computing capacity scattered around azillion desktops could soon be worth real money,ó july 29aug. 4.economist. 2001. òcomputing power on tap,ó june 21.eisenach, jeffrey a. 1999. òthe high cost of taxing telecom,ó the progress and freedomfoundation, september 6. available online at <http://www.pff.org/telecomtax.htm>.electric power research institute (epri). 1998. òutilitycustomer communications optionsfor the ôlast mile,õó july.ellis, bob. 1999. òlastmile bandwidth and conference bof, policy survey results andannouncements of second survey.ó public policy committee, siggraph, may.emigh, jacqueline. 1999. òecommerce strategies.ó computerworld, september 16.entman, robert. 1999. residential access to bandwidth: exploring new paradigms. a report ofthe thirteenth annual aspen institute conference on telecommunications policy.washington, d.c.: aspen institute, august. available online at <http://www.aspeninst.org/publications1/pdfs/access.pdf>.essex, david. 2000. òare powerline nets finally ready?ó mit technology review, june 21.available online at <http://www.technologyreview.com/web/essex/essex062101.asp>.excite@home. 2000. òexcite@homeõs principal cable partners extend distribution agreements, at&t assumes more prominent roleó (press release), march 29.fanzke, martia, monika marics, and tom day. (undated). òmaking time for fun: tv consumption and pvr use in the home.ó mediaone labs.farhi, paul. 1999. òfears rise of a digital divide.ó washington post, may 25, p. e1.farhi, paul. 1999. òmicrosoft invests in at&t: firm stakes claim in mingling of phone, tv,computer.ó washington post, may 7, p. e1.faulhaber, g., and c. hogendorn. 2000. òthe market structure of broadband telecommunications.ó journal of industrial economics 45(3): 305329, september.feder, barnaby. 2001. òsatellite venture halts payment on its debts.ó wall street journal,january 17, p. c3.federal communications commission (fcc). 1998. òdeployment of wireline services offering advanced telecommunications capability.ó available online at <http://www.ftc.gov/be/v980030.htm>.federal communications commission (fcc). 1999. òfcc establishes federalstatejoint conference to promote advanced broadband services,ó october 8. availableonline at <http://www.fcc.gov/bureaus/commoncarrier/newsreleases/1999/nrcc9081.html>.federal communications commission (fcc). 1999. òfcc reshapes the futureñestablishes new enforcement and consumer information bureaus to be effective 110899,óoctober 26. available online at <http://www.fcc.gov/bureaus/miscellaneous/newsreleases/1999/nmrc9072.html>.federal communications commission (fcc). 1999. òinquiry concerning the deploymentof advanced telecommunications capability to all americans in a reasonable andtimely fashion, and possible steps to accelerate such deployment pursuant to section 706 of the telecommunications act of 1996.ó january 28.federal communications commission (fcc). 1999. local competition: august 1999 (reportof the industry analysis division, common carrier bureau). washington, d.c.: fcc,august. available online at <http://www.fcc.gov/bureaus/commoncarrier/reports/fccstatelink/iad/lcomp991.pdf>.federal communications commission (fcc). 2000. òdeployment of advanced telecommunications capabilityó (second report), august. available online at <http://www.fcc.gov/bureaus/commoncarrier/orders/2000/fcc00290.pdf>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.224broadbandfederal communications commission (fcc). 2000. òinterim report: spectrum study ofthe 25002690 mhz band: the potential for accommodating third generation mobilesystems.ó november 15.federal communications commission. 2000. òinquiry concerning the deployment of advanced telecommunications capability to all americans in a reasonable and timelyfashion, and possible steps to accelerate such deployment pursuant to section 706 ofthe telecommunications act of 1996.ó cc docket no. 98146, second report, fcc0290 (august 21). available online at <http://www.fcc.gov/bureaus/common carrier/orders/2000/fcc00290.pdf>.federal communications commission (fcc). 2000. ònotice of inquiry on deployment ofadvanced telecommunications services.ó cc docket no. 98146. feb. 18.federal communications commission (fcc). 2001. highspeed services for internet access:subscribership as of december 31, 2001. industry analysis division, common carrierbureau. washington, d.c.: fcc.fitz, jonathan. 2000. òtake this bandwidth and shove it.ó telephony, june 5, p. 170178.flint, joe. 2000. òbroadcasters create iblast to distribute content to pcs via wireless technology.ó wall street journal, march 8, p. b8.flynn, laurie j. 2000. ògeorgia city putting entire community online.ó new york times,march 27, p. c4.flynn, laurie j. 2001. òdays of plenty are over at free internet services.ó new york times,january 1, p. c1.forrester research. 2000. òbroadband misses the mark (a technographics brief),ó september 1.fowler, thomas b. 2000. òoptical networking: a tutorial and outlook.ó the telecommunications review (2000). available online at <http://www.mitretek.org/pubs/telecom/review00/article3.doc>.frieden, rob. 2000. òdoes a hierarchical internet necessitate multilateral intervention?ópresentation given at the 28th annual telecommunications policy research conference, alexandria, virginia, september 2325. available online at <http://www.personal.psu.edu/faculty/r/m/rmf5/tprc1.ppt>.fulton, keith. 1999. òjobs, education, opportunity: why bridging the digital dividethrough communitybased digital campuses will work.ó imp, december.fusco, patricia. 1999. ò106th congress unleashes internet legislation.ó internetnews.com,november 11.fusco, patricia. 1999. òexcite@home cleaves customers from content.ó internetnews.com,november 22.fusco, patricia. 1999. òfcc/at&t policy shifts leave isps out of the game.ó internetnews.com, october 20.fusco, patricia. 1999. òisps form coalition in bid for open access.ó internetnews.com, february 2.fusco, patricia. 1999. òprodigy, gte offer internet call waiting.ó internetnews.com, july19. available online at <http://www.internetnews.com/ispnews/article/0,10878164031,00.html>.fusco, patricia. 1999. òwho killed reciprocal compensation in massachusetts?ó internetnews.com, may 24. available online at <http://www.ispplanet.com/politics/whokilled.html>.fusco, patricia. 2000. òhighspeed competition arrives in oregon.ó internetnews.com, february 9.gabel, david. 1999. òrecovering access costs: the debate,ó in b. cherry, s. wildman, anda. hammond iv, eds., making universal service policy: enhancing the process throughmultidisciplinary evaluation. mahwah, n.j.: lawrence erlbaum associates.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography225gabel, david, and milton mueller. (undated). òhousehold financing of the first 100 feet?óavailable online at <http://ksgwww.harvard.edu/iip/doeconf/gabel.html>.gantz, john. 1999. òinternet2 is on the way: watch for it.ó computerworld, march 1. available online at <http://www.computerworld.com/cwi/story/0,1199,nav4774sto34141,00.html>.garcia, john, and jon wilkins. 2001. òwhich broadband technology will win the race forhomes and offices?ó the mckinsey quarterly, number 1. available online at <http://www.mckinseyquarterly.com/articlepage.asp?articlename=piwa01>.general accounting office (gao). 2000. telecommunications: technological and regulatoryfactors affecting consumer choice of internet providers (report to the subcommittee onantitrust, business rights and competition, committee on the judiciary, u.s. senate)[gao0193]. washington, d.c.: gao, october. available online at <http://www.gao.gov/new.items/d0193.pdf>.georgia municipal association. 1999. çtifton and thomasville enter internet agreement,èoctober 7. available online at <http://www.gmanet.com/news/1999/1007.internet.shtml>.georgia municipal association. 2000. òlagrange internet tvó initiative provides freeinternet access to all cable tv households,ó april. available online at <http://www.gmanet.com/research/resources/telecomm.lagrange.shtml>.gerbrandt, larry. 2001. òthe kagan media index.ó paul kagan associates. january 31.gilder, george, and bret swanson. 2001. òthe broadband economy needs a hero.ó wallstreet journal. february 23.gillet, sharon, and william lehr. 1999. òavailability of broadband internet access: empirical evidence,ó prepared for the telecommunications policy research conference(sponsored by mititcc), september 25.gillis, justin, and jackie spinner. 1999. òa nation plugged in and dug up: streets scarredin race to wire americe.ó washington post, july 15, p. a1.ginty, maura. 1999. òmetromedia expands in europe.ó isp news, nov. 22.gitlin, richard d. 2000. ònext generation networks: the new public network.ó lucenttechnologies.glassman, james k. 2001. òthe fccõs dangerous internet precedent.ó wall street journal,january 17, p. a26.goldsborough, margaret w. 2001. òwill congressional web learning report gather momentum or only gather dust?ó new york times, january 3. available online at <http://www.nytimes.com/2001/01/03/technology/03education.html>.gomes, lee, and lisa bransten. 2000. òventure capital loves ptop: the latest technologyfad.ó wall street journal, july 5, p. b1.goodman, david j. 2000. òthe wireless internet: promises and challenges.ó computer33(7): 36.goodman, peter s. 1999. òat&t plans a big return to local service.ó washington post,nov. 24.goodman, peter s. 1999. òoregon wages a battle over access to internet.ó washington post,nov. 1, p. a1.goodman, peter s. 2000. òdishing up a new link to the internet.ó washington post, november 6, p. a1.goodman, peter s. 2000. òfirms duel over the wired west.ó washington post, april 19.goodman, peter s. 2000. òrooftops loom as a telecom battleground.ó washington post,june 12, p. a01.goodman, peter s. 2000. òteligent expands reach of wireless.ó washington post, may 2, p.e01.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.226broadbandgoodman, peter s., and craig timberg. 2000. òaol ends lobbying for open access.ówashington post, february 12.gotcher, renee, and laura kujubu. 1998. òthe network comes home.ó idg, november 5.available online at <http://www.cnn.com/tech/computing/9811/05/integr8home.idg/>.government of sweden. 2000. òan information society for all: a publication about theswedish it policy,ó december. available online at <http://www.naring.regeringen.se/pressinfo/infomaterial/pdf/n200057.pdf>.government of sweden. 2000. òsummary of the governmentõs proposal in government bill1999/2000:86ó (fact sheet), publication no. n2000:018, march. available online at<http://www.industry.ministry.se/inenglish/pdf/n200018e.pdf >.green, paul. 1999. òwdm as an access technology (cascom).ó tellabs, july 28.green, paul. 2001. òprogress in optical networking.ó ieee communications 39(1): 5461.greenstein, shane. 1999. òon the net: the recent commercialization of access infrastructure.ó imp, december. available online at <http://www.cisp.org/imp/december99/1299greenstein.htm>.greenstein, shane. 2000. òcommercialization of the internet: the interaction of publicpolicy and private choicesó (working paper), wp0011. evanston, illinois: institutefor policy research, northwestern university. available online at <http://www.nwu.edu/ipr/publications/wpabstracts00/wp0011.html>.grenier, melinda patterson. 2001. òweb access extends to over 75% of u.s. public schoolclassrooms.ó wall street journal, june 6, p. b2.grieve, willie a., and stanford l. levin. 1996. òcommon carriers, public utilities andcompetition.ó industrial and corporate change 5(4): 9931012.gruley, bryan. 1999. òaol leads lobbying campaign to gain access to broadband cabletv lines for the internet.ó wall street journal, january 26, p. a20.guernsey, lisa. 2000. òf.c.c. widens radio spectrum for wireless networks.ó new yorktimes, september 1, p. c2.guernsey, lisa. 2000. òthe future is here, and itõs ugly: a spreading technoblight ofwires, cables and towers sparks a revolt.ó new york times, september 7, p. g1.hafner, katie. 2000. òthree rules of dsl: location, location, and confusion.ó new yorktimes, january 13, p. g1.hagerty, james. 2000. òsunbeam introduces ôsmartõ appliances in an effort to set industrystandard.ó wall street journal, january 14, p. b6.hales, linda. 2001. òblobs, pods and people.ó the washington post magazine, march 25, pp.3439.hamilton, david. 1999. òbroadcom to buy epigram to accelerate hookup of highspeeddata in the home.ó wall street journal, april 26, p. b8.hansell, saul. 2000. òtime warner makes access deal with earthlink.ó new york times,november 21, p. c1.harding, james, and peter thal larsen. 2000. òbroadband for all by 2005 is aim.ó financialtimes, august 29, p. 1.hardy, quentin, and scott thurm. 1999. òmotorola, cisco jointly acquire bosch telecom.ówall street journal, june 7, p. b3.harmon, amy. 1999. òsome enter the fast lane to get access to the web.ó new york times,april 28, p. a1.harris, leslie. (undated). òwaiting for broadband.ó civicnet.org. available online at <http://www.civicnet.org/comtechreview/cuspofconvergence.htm>.harris, nicole. 1999. òsprint pieces together wireless cable for home access.ó wall streetjournal, may 6.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography227harris, nicole. 1999. òsprint to tackle the broadband market by selling its ion network toconsumers.ó wall street journal, june 21.harris, nicole. 2000. òat&tõs high wireless act: can it deliver the web and a dial tone?ówall street journal, march 2, p. b1.harris, nicole. 2000. òlucent bets on fiber optics, but faces hurdles.ó wall street journal,february 10, p. b8.harrison, jana, et al. 1998. adsl: prospects and possibilities, prepared for the adsl forum.los angeles: center for telecommunications management, university of southerncalifornia, july. available online at <http://www.adsl.com/mrpexecsummary.html>.harrison, steve, and paul dourish. 1996. òreplaceing space: the roles of place and spacein collaborative systems.ó proceedings of the acm conference on computersupportedcooperative work cscwõ96 (boston, mass.). new york: acm. draft version availableonline at <http://www.parc.xerox.com/csl/members/dourish/papers/placepaper.html>.harroff, edward. 2000. òbredbandsbolaget brings broadband access to europe.ó lightwave,october 11.harrow, jeffrey. 2000. òthe last mile rules.ó the rapidly changing face of computing,march 20. available online at <http://www.compaq.com/rcfoc/20000320.html#toc477760970>.healey, jon. 1999. òvideo cellular phones closer to reality.ó san jose mercury news, august 26.healey, jon. 2000. òmicrosoft, partners introduce ôultimatetvõ.ó san jose mercury news,june 12.hecht, jeff. 2001. òbreaking the metro bottleneck.ó technology review 104(5): 4853. available online at <http://www.technologyreview.com/magazine/jun01/hecht.asp>.hecht, jeff. 2000. òfiber optics to the home.ó technology review 103(2): 4852. availableonline at <http://www.technologyreview.com/magazine/mar00/hecht.asp>.hecht, jeff. 2000. ònew pipelines promise unprecedented speed.ó upside today, august25. available online at <http://www.upside.com/texis/mvm/printit?id=3999b24a0&t=/texis/mvm/ebiz/story>.heinzl, mark. 2000. òas 360networks readies ipo, some see fibercapacity glut.ó wallstreet journal, march 23, p. b6.heinzl, mark. 2000. òoperators of fiberoptic networks face capacity glut, falling prices.ówall street journal, october 19, p. b1.heinzl, mark. 2001. òalloptical telecom network faces slowing economy, excess capacity.ó wall street journal, february 23, p. b1.heinzl, mark. 2001. òbroadband carriers are hunting for ôkiller apps.õó wall street journal,june 14, p. b10.heywood, peter. 2000. òmarconi launches dsl killer.ó light reading, june 5. availableonline at <http://www.lightreading.com/document.asp?docid=832>.heywood, peter. 2000. òthe optical future.ó light reading, march 29. available online at<http://www.lightreading.com/document.asp?docid=335>.hogg, ray. 2000. òatm pon maximizes bandwidth to homes and businesses.ó lightwave16(9), august.holson, laura. 1999. òthe battle for us west and frontier shows how difficult the sectorhas become to analyze.ó new york times, june 21.huber, peter. 1999. òyour virtual desktop.ó forbes, march 8, p. 144.huber, peter. 2000. òthe death of old media.ó wall street journal, january 11, p. a26.idc. 2000. òemail deluge continues with no end in sightó (press release), october 10.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.228broadbandidc. 2000. òhome office use of the internet is growing dramaticallyó (press release), july24.idc. 2000. òhome office households approach 37 million in 2000 as internet turns ôworkanywhereõ into ôwork everywhereõó (press release), september 1.isenberg, david s. 2000. òyou think itõs dsl vs. cable? guess again.ó fortune 142(8): 64.(special issue: the future of the internet).isenberg, david s. 2001. òsmart letter #56: era of customerowned networks.ó isen.com,june 7. available online at <http://www.isen.com/archives/010607.html>.ishida, t., and k. isbister (eds.). 2000. digital cities: technologies, experiences, and futureperspectives. springer. abstracts and chapters available online at <http://link.springer.de/link/service/series/0558/tocs/t1765.htm>.it commission, government of sweden. 1999. a futureproof it infrastructure for sweden:report by the it commission (sou 1999:134), roger tanner, trans. stockholm: ministryof industry. available online at <http://www.itkommissionen.se/pdf/rapp0026.pdf>.it strategy council (japan). 2000. òbasic it strategyó (adopted by the it strategy councilon 27 november 2000). tokyo: ministry of foreign affairs of japan. available onlineat <http://www.mofa.go.jp/policy/economy/it/strategy.html>.international telecommunications union (itu). 2001. òchairõs report,ó regulatory implications of broadband workshop (itu new initiatives programme), geneva, switzerland, may 24. geneva: itu, may. available online at <http://www.itu.int/osg/spu/ni/broadband/workshop/chairfinal.pdf>.jander, mary. 2000. òlast mile lexicon.ó light reading, november 20. available online at<http://www.lightreading.com/document.asp?docid=2476>.jayant, nikil (ed.). 1999. signal compression: coding of speech, audio, text, image and video.singapore: world scientific.jesdanum, anick. 2000. òwiring rural america: just the beginning.ó associated press, september 6.jones, bill. 2000. òa report on the feasibility of internet voting.ó california internet votingtask force. january.joyce, amy. 1999. òbandwidth by demand: telecommunications startup streamlines international networking.ó washington post, september 27.joyce, amy. 2000. òa highspeed disconnection.ó washington post, october 5, p. e4.kelley, daniel. 1999. òderegulation of special access services: timing is everything.ó haiconsulting. june.kende, michael, and douglas sicker. 2000. òrealtime services and the fragmentation ofthe internet.ó proceedings of the 28th research conference on communication, informationand internet policy (tprc 2000), september 2325, 2000. alexandria, va.: telecommunications policy research corporation.kennard, william. 1999. òthe road not taken: building a broadband future for america.óremarks before the national cable television association, chicago, illinois, june 15.available online at <http://www.fcc.gov/speeches/kennard/spwek921.html>.kennard, william. 2000. òthe new york story: ôainõt no stopping us now.õó media lawand policy, new york law school. spring, vol. viii, no. 2.kennelly, jim. 1994. ò9 ways going online can change your life and 6 ways it canõt,óthe washington post: fast forward, september, pp. 913.kettler, david. 1999. òlighting up the last mile: fiberõs future is brightening the localloop.ó americaõs network, july 1. available online at <http://www.americasnetwork.com/issues/99issues/990701/990701light.htm>.kirk, don. 2001. òin korea, broadband is part of the culture.ó new york times, october 29,p. c3.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography229kirstein, mark, cahners instat. 2000. entering the broadband era (report no. bb0000ci),may. available online at <http://www.instat.com/catalog/downloads/broadbandera8uh.pdf>.klein, alec. 2000. òaol restrictions alleged.ó washington post, october 10, p. e1.klein, alec. 2001. òaol signs up 3 more internet providers to use cable system.ó washington post, october 6, p. e8.klein, alec. 2001. òfcc clears way for aol time warner, inc.ó washington post, january12, p. a1.kolko, jed. 2000. òbroadband misses the market.ó forrester research brief. september 1.kontzer, tom. 2001. òchicagoõs civicnet takes a step closer to reality,óinformationweek.com, january 4. available online at <http://www.informationweek.com/story/iwk20010104s0007>.kover, amy. 2000. òthe hot idea of the year [peertopeer].ó fortune 142(1), june 26.krause, jason. 2000. òdsl upstarts canõt compete with phone giants.ó industry standard,december 22. available online at <http://www.thestandard.com/article/display/0,1151,21043,00.html>.krim, jonathan. 2001. ògates calls for a cut in highspeed net costs.ó washington post,september 6, p. e1.kruger, lennard g., and angele a. gilroy. 2000. òib10045: broadband internet access:background and issuesó (crs issue brief for congress), november 28. availableonline at <http://www.cnie.org/nle/st49.html>.kruse, hans, william yurcik, and lawrence lessig. 2000. òthe internat: policy implications of the internet architecture debate.ó proceedings of the 28th research conference oncommunication, information and internet policy (tprc 2000), september 2325, 2000. alexandria, va.: telecommunications policy research corporation. available online at<http://www.csm.ohiou.edu/kruse/publications/internatv4.pdf>.labaton, stephen. 1999. ò$72 billion deal of phone giants clears big hurdle: ameritechsbc would have to expand to new cities and welcome competitors.ó new yorktimes, june 30, p. a1.labaton, stephen. 1999. òfight for internet access creates unusual alliances: former foesfind profits in at&t cable lines.ó new york times, august 13.labaton, stephen. 2000. òan oops in time warnerõs battle for internet.ó new york times,may 24, p. a1.labaton, stephen. 2001. òslew of supreme court cases to focus on õ96 telecom law.ónewyork times, october 1, p. c8.lacter, mark. 2000. òclick flicks (videoondemand).ó forbes. august 7, p. 67.lais, sami. 1999. òbuilding industry braces for it, online onslaught.ó computerworld,august 23, p. 14.landers, peter. 2000. òntt intends to link homes to web with highspeed fiber.ó wallstreet journal, september 27.larson, gary, and jeffrey chester. 1999. òsong of the open road: building a broadbandnetwork for the 21st centuryó (white paper). washington, d.c.: center for mediaeducation. available online at <http://www.cme.org/access/broadband/openroad1.html>.lathen, deborah. 1999. òbroadband today.ó staff report to william kennard, chairman,federal communications commission. october.lathen, deborah. 1999. òthe emergence of convergenceó [speech], july 22. available onlineat <http://www.fcc.gov/speeches/misc/spdal901.html>.latour, almar. 1999. òstandard connecting phones to internet is fueling service providersin europe.ó dow jones newswires, august 9.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.230broadbandlatour, almar. 2001. òhow europe tripped over a wireless phone made for the internet.ówall street journal, june 5, p. a1.laubach, mark. 1999. òcomments on the technical ability to implement open access provisioning via highspeed data over hybrid fibercoaxial cable television systems inthe united states,ó prepared for the white house national economic council, may 30.laver, ross. 1996. òplugging into the future.ó macleanõs, january 29, p. 34.le blanc, jamal. 1999. òresolving the digital divide.ó digital beat 1(19), november 12.available online at <http://www.benton.org/digitalbeat/db111299.html>.leduc, daniel, and craig timberg. 2000. òbattle lines drawn over cable: md., va. legislatures confront issues of internet access.ó washington post, february 7, p. a1.lee, chang hee. 2001. òstate regulatory commission treatment of advanced services:results of a survey.ó national regulatory research institute, february.leeper, david. 2001. òa longterm view of shortrange wireless.ó ieee computer, june,pp. 3944.leibovich, mark. 1999. òfoes place ads hitting at&tmediaone deal.ó washington post,may 7, p. e1.lessig, lawrence. 2000. òclinton versus the internet: end game.ó new republic, june 19.available online at <http://www.thenewrepublic.com/061900/lessig061900.html>.levey, collin. 2001. òbookshelf: commuting by mountain bike and modem.ó wall streetjournal, january 4, p. a16.lewis, michael. 2000. òboom box.ó new york times magazine, august 13, p. 36.li, kenneth. 2000. òkozmo.com, media company.ó the industry standard, may 1. availableonline at <http://www.thestandard.com/article/0,1902,14545,00.html>.lieberman, david. 1999. òweb growth will help most media.ó usa today, november 10,p. 1a.lippman, john, and andy pasztor. 2001. òhughes electronicsõ directv reports a substantial increase in its subscribers.ó wall street journal, january 17, p. a16.loftus, peter. 2001. òdataequipment firms trim views as spending slims.ó wall streetjournal, january 16, p. b6.lohr, steve. 1999. òin at&t deal, microsoft buys itself a stake in postpc era.ó new yorktimes, may 7, p. c1.louderback, jim. 1999. òwireless strikes back.ó zdnet news, june 25. available online at<http://www.zdnet.com/zdnn/stories/comment/0,5859,2283013,00.html>.lu, kevin. 1997. òcost comparisons of fttc and ftth for various demands and densities,ó published at the eighth international workshop on optical/hybrid access networks. paper 2.3, atlanta, georgia, march 25.mack, toni, and mary summers. 1999. òcheap gamble: sprint enters high stakes game towire up america with broadband services.ó forbes, july 5, p. 128.mackiemason, jeffrey k. 1999. investment in cable broadband infrastructure: open access isnot an obstacle. ann arbor, mich.: university of michigan, november 5. availableonline at <http://wwwpersonal.umich.edu/~jmm/papers/broadband.pdf>.macmillan, robert. 2001. òas free isps fade, others raise rates.ó washington post, january26, p. e1.mannion, patrick. 2001. òfibertothehome advocacy group formed.ó ee times, july 3.available online at <http://www.csdmag.com/story/oeg20010703s0028>.marable, leslie. 2001. òbroadbandñitõs a city thing.ó the industry standard, may 18. available online at <http://www.thestandard.com/article/0,1902,24626,00.html>.markoff, john. 1999. òmotorola to offer a chip that can support a variety of cellphonestandards.ó new york times, november 1, p. c4.markoff, john. 2000. òethernet finds a new level.ó new york times, june 5, p. c1.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography231martinez, barbara. 2000. òan internet race nets landlords some rich perks.ó wall streetjournal, march 29, p. b1.masud, abdullah, and brenda neidigh . 2000. òcommonwealth of virginia restrictions onmunicipal telecommunications.ó june.mathews, anna wilde. 2001. òechostarõs loss narrows on growth in subscriptions.ó wallstreet journal, may 4, p. b6.may, randolph. 1999. òon unlevel playing fields: the fccõs broadband schizophrenia.óprogress on point series, progress and freedom foundation, december. available onlineat <http://www.pff.org/pop6.11.htm>.mccarthy, bill. 1999. òintroduction to the directory of internet service providers.óboardwatch magazine (summer).mcclard, anne. (undated). òunleashed: web tablet integration into the home.ómediaone labs.mcdonald, glenn, and cameron crotty. 1999. òthe digital future.ó pcworld.com, november 19. available online at <http://www.pcworld.com/resource/printable/article.asp?aid=13926>.mcfarland, henry b. 2000. òeconomic perspectives on requiring unbundled access tocable broadband networks.ó 2000 annual meeting section of antitrust law, newyork, july 11.mcgee, art. 1999. òculture, class and cyberspace resources.ó civicnet.org. available onlineat <http://www.civicnet.org/comtechreview/culture.htm>.mcguire, david. 2001. òbells, rivals gear up for battle.ó washington post, february 28.available online at <http://www.washtech.com/news/telecom/79151.html>.mckay, jim. 2000. òrural ohio creates its own wireless connectivity.ó government technology (november). available online at <http://www.govtech.net/publications/gt/2000/nov/news/index.phtml>.mcwilliams, brian. 1999. ò@home rolls out upstream rate limit.ó internetnews.com, june24. available online at <http://www.internetnews.com/ispnews/article/0,,8144121,00.html>.mcwilliams, gary. 2000. òbroadjump speeds ôbroadbandõ installations.ó wall street journal, february 3, p. b8.mehta, stephanie. 1999. òavici systems breaks through bandwidth bottleneck.ó wall streetjournal, may 13, p. b6.mehta, stephanie. 2000. òu.s. market for broadband is barely tapped.ó wall street journal,january 12, p. b8.mehta, stephanie, and edward felsenthal. 1999. òsupreme court restores federal rulesaimed at opening localphone markets.ó wall street journal, janurary 26, p. a2.menendez, r.c., et al. 1997. òcost comparisons of fttc and ftth for various demandsand densities,ó eighth international workshop on optical/hybrid access networks,atlanta, georgia, march 25.metropolitan king county council. 1999. òoregon decision against at&t/tci favorscounty council demand for consumer choice through open access.ó june 4.mick, collin, bruce tolley, and willem wery. 1999. òrunning 1000basey gigabit ethernetover copper cabling.ó gigabit ethernet alliance, march 30.milgrom, paul. 1996. òprocuring universal service: putting auction theory to work.ó lecture at the royal swedish academy of sciences, december 9.miller, peter, richard civille, and dirk koning. 1999. òthe emergence of convergence.ócommunity technology review. available online at <http://www.civicnet.org/comtechreview/editorintro.htm>.musgrove, mike. 1999. òthe broadband backlog.ó washington post, december 31, p. e1.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.232broadbandnamioka, aki helen. 1999. ònegotiating open access with at&t.ó community technologyreview. available online at <http://www.civicnet.org/comtechreview/seattleatt.htm>.national association of state information resource executives (nasire) and national association of state telecommunications directors (nastd). 2000. telecommunications:closing the digital divide with broadband internet access. lexington, kentucky: nasire,october. available online at <http://www.nascio.org/publications/telecommreportoct2000.pdf>.national cable and telecommunications association (ncta). 2001. industry statistics.washington, d.c.: ncta. available online at <http://www.ncta.com/industryoverview/indstat.cfm>.national exchange carrier association (neca). 2000. neca rural broadband cost study:summary of results. whippany, n.j.: neca. available online at <http://www.neca.org/broadban.asp>.national science foundation (nsf). 1998. òworkshop on tetherless t3 workshop: interimreport.ó washington, d.c.: nsf, november.national science foundation (nsf). 1999. òdraft/preliminary report: first/last mile workshop.ó washington, d.c.: nsf, april 26.national telecommunications and information administration (ntia). 2000. fallingthrough the net: toward digital inclusion. washington, d.c.: ntia, october. availableonline at <http://www.ntia.doc.gov/ntiahome/digitaldivide/index.html>.national telecommunications and information administration (ntia). 2000. òfederal operations in the 17551850 mhz band: the potential for accommodating thirdgeneration mobile systems,ó interim report (ntia special publication 0141). washington, d.c.: ntia, november 15. available online at <http://www.ntia.doc.gov/osmhome/reports/imt2000/titlepage.html>.national telephone cooperative association. 1999. òdialtone is not enough: serving triballands.ó november.new york times. 2001. òreport counts computers in majority of u.s. homes.ó september 7,p. a15.nickell, joe ashbrook. 2000. òhome on the web.ó industry standard, october 16. availableonline at <http://www.thestandard.com/article/display/0,1151,19290,00.html>.nie, norman, and lutz erbring. 2000. òinternet and society: a preliminary report.óstanford, calif.: stanford institute for the quantitative study of society, february 17.nielsen/netratings. 2001. ònew york local market dominates broadband usage, according to nielsen/netratingsó (press release). new york: nielsen/netratings, may 15.norris, floyd. 2001. òitõs not just at&t: how telecom became a black hole.ó wall streetjournal, february 16, p. c1.national telecommunications and information administration (ntia) and rural utilitiesservice (rus). 2000. advanced telecommunications in rural america: the challenge ofbringing broadband service to all americans. washington, d.c.: ntia, april. availableonline at <http://www.ntia.doc.gov/reports/ruralbb42600.pdf>.oakes, chris. 2000. ònapster not at home with cable.ó wired, april 7. available online at<http://www.wired.com/news/technology/0,1282,35523,00.html>.oõbrien, chris. 1999. òcable internet products draw ire of consumer groups.ó san josemercury news, september 29.odlyzko, andrew. 2000. òthe current state and likely evolution of the internet.ó proc.globecom õ99, ieee, pp. 18691875.odlyzko, andrew. 2001. òcontent is not king.ó first monday 6(2). available online at<http://www.firstmonday.org/issues/issue62/odlyzko/>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography233omoigui, sirbu, eldering, and himayat. 1996. òcomparing integrated broadband architectures from an economic and public policy perspective.ó telecommunications and internetpolicy.ortiz, sixto. 2000. òbroadband fixed wireless travels the last mile.ó computer 33(7): 18.orwall, bruce, and kara swisher. 1999. òdisney discusses buying all of infoseek.ó wallstreet journal, june 8, p. a3.ota, kiyohisa. 1999. òntt: transforming into information distributor.ó merrill lynch indepth report.owen, bruce. 1999. òeconomist says internet use is limited.ó tech law journal, july 9.available online at <http://www.techlawjournal.com/internet/19990709b.htm>.pandey, amit. 1999. òcaching 101: whatõs the roi?ó ispplanet, july 5. available online at<http://www.ispplanet.com/technology/cache1014.html>.papadakis, maria c. 2000. òcomplex picture of computer use in the home emerges.ó issuebrief, national science foundation, directorate for social, behavioral, and economicsciences. march 31.parker, edwin b. 2000. òclosing the digital divide in rural america.ó telecommunicationspolicy 24, may. available online from <http://www.tpeditor.com/contents/2000/parker.htm>.parker, suzi. 2000. ònew economy recasts the rural south.ó christian science monitor, may3, p. 3.pastore, michael. 1999. òconsumer isps giving way to business providers.óinternetnews.com, nov. 11.pasztor, andy. 2000. òhughes electronics agrees to provide satellitebased web serviceacross india.ó wall street journal, march 24, p. b4.pasztor, andy. 2000. òpanamsat, seeking a niche, plans internet video service.ó wallstreet journal, march 29, p. b7.pasztor, andy. 2001. òloral scraps plans to be major operator of twoway satellite broadband systems.ó wall street journal, february 1, p. a4.paul kagan associates. 2001. the kagan media index, january 31.pease, robert. 2000. òrural areas present better business case for fibertothehome.ólightwave 17 (7): 1. june.peterson, andrea. 2000. òtwo brothers bet everything on freebroadband startup.ó wallstreet journal, march 23, p. b8.pine, david. 1999. òlet the feds regulate.ó imp, december. available online at <http://www.cisp.org/imp/december99/1299pine.htm>.piscitello, david m. 2000. òthe true killer application for broadband local access.ó clecplanet. available online at <http://www.clecplanet.com/business/00072piscitello.htm>.plotnikoff, david. 2000. òwiring the rural west.ó san jose mercury news. available onlineat <http://www0.mercurycenter.com/svtech/news/special/ruralwest/>.pollack, andrew. 1999. òamerica online to put $1.5 billion into a hughes alliance.ó newyork times, june 22, p. c6.pomerantz, dorothy. 2001. òif you overbuild it.ó forbes, april 16, p. 144.poulton, ken. 1999. òthe palo alto fiber to home trialó (slide presentation), november 24.available online at <http://alcatraz.labs.agilent.com/kenpoulton/ftth/poultonv10e/>.raikallen, georgie. 2000. òisky shoots for the stars.ó red herring, january 19. availableonline at <http://www.redherring.com/vc/2000/0119/vcisky.html>.ramstand, evan, and dean takahashi. 1999. òsony, tivo set deal on tvrecording device.ó wall street journal, september 9, p. b6.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.234broadbandraymond james and associates. 1999. òhigh speed access . . . working in real time,ódecember 22.raymond james and associates. 2000. òoptical networking: turn on the lights,ó june 13reuters. 1999. òf.c.c. approves line sharing for data carriers.ó new york times, november 19, p. c5.reuters. 1999. òreal estate companies offering data services.ó new york times, oct. 6.reuters. 1999. òten million u.s. homes seen going digital by 2003.ó san jose mercurynews, october 20.reuters. 1999. òu.s. internet users surpass 100 million markñstudy.ó san jose mercurynews. available online at <http://www.sjmercury.com/svtech/news/breaking/internet/docs/1065381i.htm>.reuters. 1999. òvictory for los angeles cable providers.ó new york times, june 19, p. c2.rich, motoko. 2001. òfirms, employees look to home offices again.ó wall street journal,october 3, p. b8.richards, bill. 2001. òfor a montana utility, a gamble on telecom looks like a bad call.ówall street journal, august 22, p. a1.richtel, matt. 1999. òexcite@home to separate cable and content divisions.ó new yorktimes, november 22, p. c2.riley, jason l. 1999. òfaster web access coming (one day) to a home near you.ó wallstreet journal, july 14, p. a23.riley, patricia, anu mandavilli, and rebecca heino. 2000. òobserving the impact of communication and information technology on ônetworkõ.ó telework and the new workplace of the 21st century. u.s. department of labor, washington, d.c. available onlineat <http://www.dol.gov/dol/asp/public/telework/p23.htm>.rohde, david. 1999. òdsl explosion ready to rip.ó network world, july 7. available onlineat <http://www.nwfusion.com/news/1999/0719belldsl.html>.rohde, david. 1999. òmore trouble for at&t cable plan: big rivals enter fight to opencable nets to all.ó network world, june 28. available online at <http://www.nwfusion.com/news/1999/0628opencable.html>.romero, simon. 2001. òshining future of fiber optics loses glimmer.ó new york times,june 18, p. a1.romero, simon. 2001. òweb users left scrambling as big d.s.l. network shuts down.ónew york times, march 30, p. c1.rosenberg, scott. 2000. ògive my regards to broadband.ó salon, march 17. available onlineat <http://www.salon.com/tech/col/rose/2000/03/17/broadband/print.html>.rosenwein, rifka. 2000. òwhy media mergers matter.ó brillõs content, december 1999/january.rowe, bob. 1999. òtelecom and technology issues affecting state utility commissionsó(presentation given at the annual conference of the alliance for public technology,march). available online at <http://www.apt.org/confer/1999/rowe.html>.rowe, bob. 2000. òimplementing a cooperative federalist approach to telecom policy.óspeech presented at federalist society, washington, d.c., september 27.rowe, bob. 2000. òstrategies to promote advanced telecommunications capabilities.ó federal communications law journal 52(2): 381. available online at <http://www.law.indiana.edu/fclj/pubs/v52/no2/rowe.pdf>.rowe, bob. 2000. òsubstance plus process: telecom regulation reforms to protect consumers, preserve universal service, and promote competition.ó university of coloradolaw review 71(4).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography235rural task force (rtf). 2000. rural task force recommendation to the federalstate joint boardon universal service (before the federal communications commission (fcc)). washington, d.c.: fcc, september 29. available online at <http://www.wutc.wa.gov/rtf/rtfpub.nsf/>.saleh, adel a.m., and jane m. simmons. 1999. òarchitectural principles of optical regionaland metropolitan access networks.ó journal of lighwave technology. september.sandberg, jared. 2000. òafter 50 years of effort, interactive tv may be here.ó wall streetjournal, december 7, p. b1.sandberg, jared. 2001. òbroadbandõs chickenandegg bind.ó new york times, april 2, p.b1.sanford c. bernstein & co. and mckinsey & company. 2000. broadband! new york. january.schement, jorge. 1999. òof gaps by which democracy we measure.ó imp, december.schement, jorge. 1999. òof nodes and castles: the changing information environment ofthe home.ó presentation given at òthe role of public service media in the digitaltelecommunications ageó conference, june 21, bethesda, maryland. video archiveavailable online at <http://nc.psu.edu/archive1.html>.schiesel, seth. 1998. òpc companies and bells to petition u.s.ó new york times, december7, p. c1.schiesel, seth. 1999. òat&t conjures up its vision for cable, but can it deliver?ó new yorktimes, may 7, p. a1.schiesel, seth. 1999. òat&tõs embrace of new technology signals next era.ó new yorktimes, march 8, p. c1.schiesel, seth. 1999. òbell atlantic says network is fully open.ó new york times, april 14,p. c11.schiesel, seth. 1999. òjumping off the bandwidth wagon.ó new york times, july 11, p. c1.schiesel, seth. 1999. òmarket place: notes on corporate culture and possibilities as mciworldcom meets two years after its creation.ó new york times, june 7, p. c13.schiesel, seth. 1999. òmerger deal with plenty of intrigue.ó new york times, july 22, p. c1.schiesel, seth. 1999. òstartup leads phone cause in battle for internet access.ó new yorktimes, may 17, p. c1.schiesel, seth. 1999. òthe outlook for cable access.ó new york times, august 9, p. c1.schiesel, seth. 2000. òat&t takes full control of at home cable venture.ó new york times,march 30, p. c1.schiesel, seth. 2000. òfor most local phone users, choice is not yet an option.ó new yorktimes, november 21, p. c1.schiesel, seth. 2000. òu.s. may pressure landlords to allow digital competition.ó newyork times, october 12, p. a1.schiesel, seth. 2001. òhouse to focus on net access and competition.ó new york times,september 3, p. c1.schiesel, seth. 2001. òsitting pretty: how baby bells may conquer their world.ó new yorktimes. april 22, p. c1.schnurr, lewis. 2000. òmedia and telecommunications regulation and the internet: regulate or strangulate?ó media law and policy viii (2).schrader, william l. 1999. òinternet access and the consumer.ó testimony of william l.schrader, chairman & ceo psinet inc., before the senate committee on commerce,science and transportation. april 13.schwartz, john. 1999. òdelivering on promise of convergence.ó washington post, may 7, p.e1.schwartz, john. 1999. òhow much room in the fat pipe?ó washington post, september 19,p. h1.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.236broadbandschwartz, john. 1999. òopenaccess online fight escalates.ó washington post, july 28, p. e1.schwartz, john. 2001. òwiring the city: humans wonõt do.ó new york times, march 8, p.g1.semon, d. 2001. òa brief history of data over cable.ó time warner. january.shannon, victoria. 1999. òwhy itõs slow going on the net,ó washington post, may 24, p. f20.shin luh, shu. 1999. òaol sees future in palms.ó washington post, june 23, p. e1.shin luh, shu. 1999. òphone companies reach pact.ó washington post, august 3, p. e3.shishkin, philip. 2000. òaol, time warner offer open access for five years.ó wall streetjournal, september 25, p. a28.shishkin, philip. 2000. òec scrutinizes microsoftõs telewest plan.ó wall street journal, june13, p. a22.shumate, paul w. 1998. òcomparing the latest highspeed access technologies: fttx,hfc, xdsl, and wireless,ó presented at ieee lasers and electrooptics annual meeting, december 3, orlando, fla.sicker, douglas, et al. 2000. òthe internet interconnection conundrum.ó draft opp working paper. april.siembab, walter. 1999. òpublic transit for the information highway.ó available online at<http://www.civicnet.org/comtechreview/publictransit.htm>.simon, greg, and rich bond. 1999. òfreedom of choice: why local control protects consumersõ choices.ó imp, december. available online at <http://www.cisp.org/imp/december99/1299simon.htm>.sliwa, c. 1999. òjini: promising technology, but will it catch on?,ó computerworld, march15, p. 76.smart, tim. 1999. òlockheed, partners plan system of satellites.ó washington post, may 7,p. e10.smart winnipeg. 2000. òthe case for municipal fiber white paperó (white paper).winnipeg, manitoba: smart winnipeg, august 15. available online at <http://www.smartwinnipeg.mb.ca/municipalfibre.htm>.solomon, deborah. 2000. òamid steep business declines, phone giant calls it splits; cutting the prized dividend.ó wall street journal, october 26, p. b1.speta, james. 2000. òhandicapping the race for the last mile?: a critique of open accessrules for broadband platforms.ó yale journal on regulation, winter.speta, james. 2000. òthe vertical dimension of cable open access.ó university of coloradolaw review 71(4), fall.sprint. 2000. òmmdsñbetter than sliced breadó (white paper). available online at <http://www.sprintbroadband.com/prsite/articles/mmds.html>.staff report. 1999. òpanel rejects ordinance in internet/cabletv case.ó wall street journal, october 20, p. b11.st. arnaud, bill. 2000. ògigabit internet to every canadian school by 2005,ó discussionpaper. ottawa: canet3, february 4. available online at <http://www.canet3.net/library/papers/gigabittohomeby2005.html>.stern, christopher. 2000. òbroadband market growth slows.ó washington post, august 28,p. e01.stern, christopher. 2000. òbroadcasterõs promise of a digital tv age has not been met,and now congress is having second thoughts about its role.ó washington post, december 17, p. h1.stevenson, ted. 1999. òisp valuation: from the horseõs mouth.ó ispplanet.com, november10. available online at <http://www.ispplanet.com/business/ispconvaluation.html>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography237st. sauver, joe. 2000. òa fiber optic primer and tutorial: designing networks for optimum performance.ó computing news [university of oregon]. available online at<http://cc.uoregon.edu/cnews/summer2000/fiber.html>.swisher, kara, and khanh tran. 1999. òhighstakes internet battle erupts in san francisco.ó wall street journal, july 26, p. a24.taglang, kevin. 1999. òcommunity technology centers: closing the digital divide.ó ombwatch, september 29.taschdjian, martin. 2000. òfrom open networks to open markets: how public policy affects infrastructure investment decisions.ó center for information policy research,harvard university, cambridge, mass. november.tech law journal. (undated). òsummary of bills affecting broadband in the 106th congress.ó available online at <http://techlawjournal.com/cong106/broadband/default.htm>.technology review. 2001. òspecial issue: wired and wireless.ó june.technology review. 2001. òa very long distance: a regulatory call put cell phones onhold.ó may, p. 110.tedeschi, bob. 2000. òecommerce report: sites not yet pitching at full speed.ó new yorktimes, december 4.telecommunications reports. 1999. òaig telecomõs bandwidth ôforwards marketõ looks toward rapid growth in telecom minutes.ó august 2.telecommunications reports. 1999. òalts eyes strong enforcement, service integration;kennard urges carriers to go into residential markets.ó may 10.telecommunications reports. 1999. òat&tõs plans are focus of senate hearing.ó february19.telecommunications reports. 1999. òbell atlantic, ibm set home networking venture.ó february 8.telecommunications reports. 1999. òbell atlantic, sbc form new broadband coalition.ó july5.telecommunications reports. 1999. òcanadaõs teleglobe unveils $5 billion global broadbandnetwork.ó may 17.telecommunications reports. 1999. òcanada takes hard line on cable modem access; u.s.court adjusts schedule for portland review.ó july 12.telecommunications reports. 1999. òc & w usa to invest $670 m in fiber internet backbone.ó april 19.telecommunications reports. 1999. òcompetitive carriers set to unveil broadband coalition.ó march 29.telecommunications reports. 1999. òcrtc renounces ônew media servicesõ regulation, reaffirms internet access rules.ó may 24.telecommunications reports. 1999. òdebate over reallocated dtv spectrum exposes ruts ininformation superhighway.ó july 26.telecommunications reports. 1999. òfccõs decision against cable modem probe fails tohinder push for opening networks.ó february 8.telecommunications reports. 1999. ògoodlatte pledges persistence in pushing broadbandbills.ó may 24.telecommuncations reports. 1999. òhome networking alliance eyes broadband synergies.óaugust 2.telecommunications reports. 1999. òlong distance group opposes broadband service measures.ó june 28.telecommunications reports. 1999. òntia wants few changes to fcc unbundling rules.óaugust 9.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.238broadbandtelecommunications reports. 1999. òopen access to cable modems must be national rule,naco says,ó and òcable tv providers challenge broward on open access.ó july 26.telecommunications reports. 1999. òprogramming ôleasedaccessõ rules donõt apply tointernet services, cable tv operators tell fcc.ó july 19.telecommunications reports. 1999. òrhythmsõ hapka wants ilec performance, not promises.ó june 28.telecommunications reports. 1999. òrural senators press fcc, ntia for internet access improvements.ó may 24.telecommunications reports. 1999. òsatellite industry vows to solve reliability puzzle,launches itself into internet, multimedia markets.ó february 8.telecommunications reports. 1999. òservice complaints leveled at at&t wireless, finlandõsnokia.ó march 15.telecommunications reports. 1999. òus west plans to offer ôweb phone,õ cuts dsl rates.ómay 17.telecommunications reports. 2000. ònew senate broadband bills focus on financial incentives.ó april 3.3com corporation. 1999. òbuilding a connected community: a municipal blueprint from3com.ó santa clara, calif.: 3com, august.thurm, scott. 1999. òteledesic ôsky internetõ may start sooner.ó wall street journal, september 27, p. b6.thurm, scott. 2000. òmccaw to fuse satellitephone systems and teledesic.ó wall streetjournal, march 2, p. b8.thurm, scott, and jim carlton. 2000. òa fiberoptics powerhouse is poised to speedtechnologyõs march.ó wall street journal, january 20, p. b1.thurm, scott, and mark heinzl. 2000. òfiber optics becomes latest tech sector to crashand burn.ó wall street journal. october 26, p. c1.thurm, scott, and glenn r. simpson. 2001. òtech industry seeks salvation in highspeedinternet connections.ó wall street journal. june 25, p. b1.trombly, maria. 2000. òwireless data access via cell phone to skyrocket this year, studysays,ó computerworld, april 17. available online at <http://www.computerworld.com/cwi/story/0,1199,nav47sto43885,00.html>.ungerer, herbert. 2000. access issues under eu regulation and antitrust law: the case oftelecommunications and internet markets. center for information policy research,harvard university, july. available online at <http://www.pirp.harvard.edu/pubspdf/ungerer/ungereraccessi003.pdf>.u.s. census bureau. 2000. statistical abstract of the united states. washington, d.c.: u.s.census bureau, department of commerce. available online at <http://www.census.gov/prod/2001pubs/statab/sec18.pdf>.u.s. congress, office of technology assessment. 1991. rural america at the crossroads: networking for the future (otatct471). washington, d.c.: u.s. government printingoffice, april. available online at <http://www.wws.princeton.edu/~ota/disk1/1991/9136n.html>.u.s. congress, office of technology assessment. 1995. telecommunications technology andnative americans: opportunities and challenges, august.u.s. department of commerce, ntia. 2000. òfederal operations in the 17551850 mhzband: the potential for accommodating third generation mobile systems.ó interimreport, november 15 (ntia special publication 0141). available online at <http://www.ntia.doc.gov/osmhome/reports/imt2000/titlepage.html>.u.s. house of representatives (107th congress). 2001. òinternet freedom and broadbanddeployment act of 2001ó (h.r. 1542). available online at <http://thomas.loc.gov>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography239u.s. house of representatives, commerce committee, subcommittee on telecommunications, trade, and consumer protection. 2000. òhearing on the status of deploymentof broadband technologies. april 11. available online at <http://comnotes.house.gov/media/040112000ttcp.ram>.van, jon. 1999. òspeedier internet access on tap: ameritech enters alliance with aol.óchicago tribune, july 22.varian, hal r. 2000. òcool media: a new generation is turning the tables on television.óthe industry standard, november 20, p. 293. available online at <http://www.thestandard.com/article/display/0,1151,20004,00.html>.varian, hal r. 2000. òestimating the demand for bandwidth,ó technical report. berkeley,calif.: university of california, berkeley, august 29. available online at <http://www.sims.berkeley.edu/~hal/papers/wtp/wtp.pdf>.varian, hal r. 2000. òfield of dreams: what if you build broadband and no one comes?óthe industry standard, march 20. available online at <http://www.thestandard.com/article/display/0,1151,12944,00.html>.verhovek, sam. 1999. òat&t fights push to open cable lines to its rivals.ó washingtonpost, november 2, p. a20.veronis suhler media merchant bank. 2000. òcommunications industry forecast: historical and industry projections for 12 industry segments.ó july.veronis suhler media merchant bank. 2000. òcommunications industry forecast: fiveyearhistorical report of publicly reporting companies.ó october.vogelsang, ingo, and bridger m. mitchell. 1997. telecommunications competition: the lastten miles. cambridge, mass.: mit press.vogelsang, ingo, and glenn woroch. 1998. òlocal telephone service: a complex dance oftechnology, regulation and competitionó in larry l. deutsch, ed., industry studies,2nd edition. armonk, n.y.: m.e. sharpe. available online at <http://elsa.berkeley.edu/~woroch/dance.pdf>.waddell, cynthia. 1999. òelectronic curbcuts: universal access for everyone.ó imp, december. available online at <http://www.cisp.org/imp/december99/1299waddell.htm>.walker, leslie. 1999. òclosing the distance: instant messaging is talk of online world.ówashington post, july 6, p. a1.wallace, bob. 1999. òuunet to build, expand data centers for $100m.ó computerworld,august 9, p. 14.wall street journal. 2000. òtown proves online access isnõt enough.ó september 5, p. b13.wall street journal. 2001. òreality bytes.ó january 29, p. b8washington post. 2000. òdsl gaining on cable as the big pipe of choice.ó washington post,february 10, p. e10. available online at <http://www.washingtonpost.com/wpsrv/wplate/200002/10/204l021000idx.html>.washington post. 2001. òaolõs minutes.ó march 8, p. e11.weare, christopher. 1996. òinterconnections: a contractual analysis of the regulation ofbottleneck telephone monopolies.ó annenberg school for communication, university of southern california. oxford university press.weber, thomas. 1999. òaol deal envisions web surfing via satellite.ó wall street journal,may 12, p. b1.weber, thomas, and stephanie n. mehta. 1999. òfast phone lines may help aol trumpcable tv.ó wall street journal, may 7, p. b1.weber, thomas, and stephanie n. mehta. 1999. òweb, telephone prove no match for ôstarwars.õó wall street journal, may 13, p. b1.weil, nancy. 1999. òhome networking group picks next phoneline spec.ó idg.net, idgnews service, boston bureau, july 27.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.240broadbandweller, dennis. 1996. òtransition strategies for regulation,ó idate, communications & strategies, no. 23, 3rd quarter, pp. 99115.weller, dennis. 1999. òobligations for universal service obligations.ó gte, november.available online at <http://www.comslaw.org.au/research/universal/19991101weller.html>.wigfield, mark. 2000. òschoolsõ spectrum rights promise a bonanza, but can they cashin?ó wall street journal, september 6, p. b1.wigfield, mark. 2001. òrural virginia town fights for broadband access.ó wall street journal, june 7, p. b6.wilke, john r. 2000. òaol, time warner pledge cable access.ó wall street journal, december 14, p. a3.williamson, oliver e. 1975. markets and hierarchies. new york: the free press.williamson, richard. 2000. òsatellite net service launches.ó interactive week, november12. available online at <http://www.zdnet.com/zdnn/stories/news/0,4586,2652654,00.html>.williamson, richard. 2001. òat&t completes first open access cable trial.ó zdnet,june 8. available online at <http://www.zdnet.com/filters/printerfriendly/0,6061,27708073500.html>.wingfield, nick. 1999. òfree web services challenge aolõs dominance.ó wall street journal, september 23, p. b8.wingfield, nick. 1999. òsandpiper aims to prevent eventdriven web pileups.ó wall streetjournal, june 17, p. b10.wirbel, laura. 2000. ònew carriers follow alternate broadband route.ó ee times, february 8. available online at <http://www.eetimes.com/story/oeg20000208s0008>.witt, sarah. 1999. òbroadbandõs first beachhead: highspeed internet service for multitenant buildings leads a gradual move to providing fast access for all.ó internetworld, june 14.wolcott, david a. 2001. òan alts analysis: local competition policy & the neweconomy.ó alts, february 2.wolverton, troy, and wylie wong. 2000. òinternet world showcases broadband moves.ócnet news.com, april 7. available online at <http://news.cnet.com/news/010042001661401.html>.woolley, scott. 2000. òfast glass.ó forbes, november 13, p. 322.working group on digital subscriber line access (t1e1.4). 2001. american national standard for telecommunicationsñspectrum management for loop transmission systems(t1.4172001). standards committee t1. washington, d.c.: alliance for telecommunications industry solutions.working party on telecommunications and information services policies; committee forinformation, computer and communications policy. 2001. the development of broadband access in oecd countries. paris: oecd, october.world wide packets. 2000. òlast mile broadband technologiesó (white paper). availableonline at <http://www.worldwidepackets.com/solutions/papers/wplastmile.jsp>.world wide packets. 2000. òworld wide packets deploys first gigabit ethernet broadbandsolution with grant county washington pudó (press release), august 7. availableonline at <http://www.wwp.com/news/pressrelease.jsp?id=17>.woroch, glenn a. 1998. òfacilities competition and local network investment: theory,evidence and policy implications.ó june. available online at <http://elsa.berkeley.edu/~woroch/faccomp.pdf>.xdsl today. 2000. òus west and consortium of 13 competitive local exchange carrierssign nationõs first regionwide ôlinesharingõ agreement.ó may 1. available onlineat <http://www.xdsl.com/newsreleases/xdsl/11151.asp>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.bibliography241young, shawn. 2001. òcovad, one of last dsl competitors, blames troubles on bell tactics.ó wall street journal, august 9, p. b1.young, shawn. 2001. ònorthpoint communications files for chapter 11 creditor protection.ó wall street journal, january 17, p. b10.young, shawn. 2001. òrhythms tells customers it will close.ó wall street journal, august13, p. b3.zelnick, nate. 2000. òpackets from heaven.ó internet world, march 30. available online at<http://www.internetworld.com/news/archive/03302000.jsp#3.30sat>.zerega, blaise, and scott lajoie. 1999. òwill they come? builders of highbandwidth networks may be overestimating their potential market.ó forbes, november 29.zerega, blaise. 2000. òcarriers shift from voice and data transmission to new highbandwidth services.ó red herring, december 4.zigmont, jason. 1999. òpricing your services.ó ispplanet.com, june 25. available online at<http://www.ispplanet.com/business/pricing3a.html>.zona research. 1999. òthe economic impacts of unacceptable web site download speeds.óavailable online at <http://www.zonaresearch.com/deliverables/whitepapers/wp17/>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.245in the course of its work, the committee on broadband last miletechnology developed highly detailed material related to various broadband technologies. the committee decided that this level of detail was notappropriate for the main text of its report, but provides the material,which is not intended to be comprehensive, in this appendix for the readerinterested in learning more about broadband technologies.hybrid fiber coax technology1coaxial cablethe foundation upon hybrid fiber coax (hfc) broadband communications networks are based is coaxial cable (figure a.1), a radio frequency(rf) transmission line capable of transporting a large number of carriers(channels). at the head end, or central signalprocessing center, each carrier is modulated with baseband analog or digital information, and allcarriers are multiplexed together in the frequency domain (figure a.2).spectral separation is accomplished through the use of frequencyselective diplex filters to allow simultaneous transmission of information inopposite directions (figure a.3), commonly called òreverseó (i.e., fromthe home to the head end) and òforwardó (from the head end to the1adapted from james chiddix. 1999. òthe evolution of the u.s. telecommunicationsinfrastructure over the next decade. ttg2: hybridfibercoax technologyó (ieee workshop paper).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.246appendix aa, metallic center conductorb, dielectric (nonconducting)c, metallic outer conductord, plastic jacketed covering (optional)figure a.1coaxial cable (cutaway view).twoway radio216  470 mhztv713fmtv26twowayham79 analog tv channelsrev540 mhz54550 mhzfigure a.2typical rf spectrum for analog cable television.reverse carriersforward carriersrf spectrumdiplex filterheadend equipmentfigure a.3forward and reverse spectra and diplex filter.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a247home). this physical medium provides for the transport of rf energywithin a reasonably secure network with an enormous amount of signalcapacity and flexibility.conceptually, coaxial cable provides cable operators with a privateconduit through which rf signals are transported; in addition, the medium can support multiple signaling channels without regard to the baseband signals or modulation scheme that may be employed. this mediumis generally immune to interfering influences that may exist in free space.from a practical standpoint, coaxial cable supports transmission of signals at frequencies from baseband to more than 1 ghz.transmission losses (attenuation) within these cables can be significant; attenuation increases proportionally with frequency, making it necessary to use rf amplification to cover the long distances encompassedby the cable plant. amplifiers may be spaced from a few hundred feet toone or two thousand feet apart. although the theoretical frequency limitof the cable itself is significantly greater than 1 ghz, and cable systemshave been built using upper frequencies in excess of 1 ghz, practicallimitations are set by the frequency responses of active and passive components (e.g., amplifiers and filters) used in the network.treeandbranch architectureuntil recently, coaxial cable systems have followed a òtreeandbranchó topology (figure a.4), delivering the same rf spectrum of sighead endrf amplifiertrunk cable(coax)40+ amplifiercascades werecommonfigure a.4treeandbranch architecture.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.248appendix anals to every customer within a particular community. this design servedthe cable industry well, but it did have limitations. the most significantrestriction imposed by this topology was the accumulation of noise anddistortions (figure a.5) through the extended cascades of broadband rfamplifiers needed to compensate for transmission losses. this architectural facet affected plant reliability and signal quality at the customerõshome. additionally, for a given design bandwidth, there were practicaland theoretical limits to the number of amplifiers that could be cascaded.in order to maintain acceptable performance levels, it was necessary tolimit the operational bandwidth of such cable systems to a few hundredmegahertz, far below the potential of the cable alone.another limitation was imposed by this topology: every customerreceives the same complement of signals. this is generally acceptable fortv services, but makes the delivery of individually switched or routedservices difficult.fiberoptic transmission technologyby the late 1980s, optical lasers were successfully adapted for use in abroadband environment. optical transmission had been practical for sometime through the mechanism of turning the transmitting laser òonó andnoisecarriertonoiseratiocarriertointermodulationratiocarrier (channel)figure a.5carriertonoise and carriertointermodulation distortion.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a249òoffó in synchronization with the ones and zeros of a digital signal. abreakthrough came when it was determined that a laser could be left òonóand intensitymodulated with the highly complex analog signal representing the broadband rf spectrum (figure a.6).lasers used in this way required characteristics different from theirdigital counterparts. the most critical were very low internal noise and anextremely linear transfer function. such devices had been in developmentfor the digital market in an effort to achieve higher datatransmissionspeeds over optical fibers (in contrast to coaxial cable), but further optimization was required for broadband applications.at the receiving end of an optical link, a relatively simple photodetector was used to convert the optical signals back into an rf spectrumessentially identical to the one presented at the input (transmitting) end.the cable industry quickly adopted this technology for a portion of itstransmission plant, and continues to use it as a way to costeffectivelytransform coaxial treeandbranch systems into something much morepowerfulñhybrid fiber coax (hfc) architecture (figure a.7). in essence,this approach transforms large systems into highly concentrated collections of smaller systems. this is a very important characteristic, as discussed below.current hfc designs are now providing transmission to and fromneighborhood clusters of a few hundred homes or fewer (figure a.8).this arrangement of fiber and coaxial cables allows segmentation of thetraditional coaxonly transmission plant into many localized areas (callednodes), each of which is capable of providing a unique assortment ofinformation to end users (figure a.8). the coaxial network that connectsto homes from each optical node remains a small version of the originaltreeandbranch system (more of a bush than a tree).79 analog tv channelsdigital servicesuhf spectrum470  750 mhztwoway radio216  470 mhz54  550 mhztv7  13fmtv2  654  750 mhz550  750 mhzfigure a.6750mhz forward spectrum.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.250appendix ahead endoptical nodeoptical cable500 homes passedtypically 6 orfewer amplifiersin cascademaster headendsecondaryhubprimaryhubrf ampscoax5002,000home areaopticalnodetaps &passivesfiber1,310 nmbaseband digitaltransport1,550 nmhigh poweropticalnodefigure a.7hfc networks allow smaller serving areas.figure a.8hfc networks allow narrowcasting of content to the customer.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a251design considerationscurrent hfc designs call for fiber nodes serving about 500 homes onaverage, but these nodes can be further segmented into arbitrarily smallcoaxial serving areas. figure a.9 illustrates one way that the spectrumavailable within one node may be used.the ability to assign and reassign spectrum to different uses is animportant benefit of hfc architecture, because it allows for advances indigital services and technologies while continuing to support existingservices. thus, the architecture can simultaneously support many separate virtual networks. this makes the investment to upgrade to hfc asustainable one for most cable companies. at least some cable operatorsplan to build as many as five separate (virtual) networks on the foundation of their upgraded fiber transport plant (figure a.10).the hfc architecture enables great flexibility to segment the servicearea. stepbystep segmentation can match investment with revenuesfrom new, highbandwidth services; in the extreme case, fiber can beextended to the property lines of homes and businesses (not shown in79 analog tv channels(ntsc)rev.qpsk qam16digital services(qam64  qam256)uhf spectrum470  750 mhz2way radio216  470 mhztv7  13fmtv2  62wayham54  550 mhz54  750 mhz5  40mhz550  750 mhzsdtvhdtvhighspeeddatadigital bank (future use)voiceondemandvoiceover ipdigitalservices550  750 mhzfigure a.9forward and reverse spectra at node.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.252appendix afigure a.10), or at least to those with the need for services requiringhundreds of megabits per second of connectivity. only those nodes thathave need of greater data capacity (and the potential for greater revenue)have to be divided; the rest can remain undisturbed.as nodes are divided and fiber is deployed closer to the customer, thetotal amount of usable bandwidth becomes greater; this makes it possiblefor every node division to more than double the available data capacitywhile reducing the number of users who share it.2 similarly, breaking a500home node into four parts, each passing an average of 125 homes,increases the available reverse and forward capacities significantly morethan fourfold and provides more than four times the bandwidth per user.trials within the industry have made use of the spectrum from 900mhz to 1 ghz (as compared with the traditional use of the 5 to 50mhzregion) for reverse signals. because of reduced rf interference at thesehigher frequencies and the resulting highermodulation efficiencies, it ispossible to provide an additional 200 mbps of transmission capability.again, this number can be multiplied through segmentation, as outlinedabove.hfcfiberswitch datampeg videolocated inhead endanalog videohubtransporthfcplantfigure a.10capability to support multiple networks within hfc.2the accompanying reduction in noise over the coaxial portion of the networkñin accordwith shannonõs lawñmeans that the usable bandwidth within each subloop also increasessignificantly.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a253it is possible to push these numbers even farther. if very high speed,truly symmetric capacity is required, frequencies above 1 ghz can beused. some cable plants being constructed today use fiber to feed neighborhoods of 60 homes or fewer with a morethancommensurate increasein the peruser capacity for both switched and routed digital services.in 2001, the latest version of the industry standard, docsis 2.0, embraced two optional refinements that can substantially increase upstreamthroughput by using improved modulation in situations where the noiselevel permits. one is the use of advanced timedivision multiple access(tdma), which allows modulations up to 256 quadrature amplitudemodulation (qam) in upstream bursts (theoretically 8 bits per hertz, realworld about 6.5), compared with the 16 qam (4 bits per hertz theoretically) of the current version. the other is synchronous codedivision multiple access (cdma), which permits much more robust transmissions inthe presence of certain kinds of interference.providing services in year 2010information and entertainment services can be classified in two broadcategoriesñcommon and dedicated. common services include such programming as offair broadcast, peg (public, educational, and government) channels, basic networks (such as espn and cnn), and subscription services (such as hbo, cinemax, and starz). dedicated servicesinclude any number of specialized programs that are delivered to the enduser on an individual basis; videoondemand (vod) and highspeedinternet access are examples of this type of service.the cable television (catv) industry in the united states typicallythinks of a channel as being represented by a contiguous 6mhz portionof the available spectrumñthus, a standard 750mhz hfc plant has approximately 112 such òchannelsó within a total usable spectrum of 672mhz. table a.1 provides some details regarding a hypothetical 750mhzhfc plantõs ability to provide almost unlimited service options for customers, including the following:¥standard analog television. the cable television industry will probably always carry some amount of ntsc signals, perhaps 20 or so rfchannels; but it is anticipated that the number of these signals will decrease as most of them are incorporated into compressed digital formats.¥digital standard definition television (sdtv). this will become theòstandardó signal as 256qam channels are used to distribute some 200simultaneous networks (hbo, espn, cnn, and so on), including most ofthe subscription services.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.254appendix a¥digital hdtv. these networks will be capable of providing adequate bandwidth to support as many as 20 rf channels (each 6 mhzwide) as the transition to broadcast hdtv services continues.¥telephony. more than 300 voice channels can be provided within atypical 6mhz segment of the spectrum, if needed.¥ip data services. this class of service includes voice over ip (voip),video telephony over ip (vtip), streaming video, and highspeed dataservices. higherdatarate services (100 mbps) can be provided, as needed,for workathome or commercial uses.¥videoondemand. even with all of the services listed above, enoughbandwidth remains to handle vod applications in both sdtv and hdtvformats.security considerationssince cable operators have built their plant to provide video and otherservices, and many of those services are available at lower cost, albeitwith lower quality or lacking some other feature, cable operators havehad to find ways to secure their services from unauthorized access. thetable a.1potential services that a 750mhz hfc cable systemcould providechannels and/orchannelsservices providedbandwidth requiredremainingcommon signalsstandard analog television20 channels (120 mhz) for92ntsc signalsdigital sdtv20 channels (120 mhz) for72200+ programs of compresseddigital video formatdigital hdtv10 channels for 20 programs62(60 mhz)dedicated servicestelephony1 channel (6 mhz) for 300 dsos61(voice channels)ip datañstandard service20 channels (120 mhz)ñ4110mbps data ratesip datañvery high speed3 channels (18 mhz)ñ38100mbps data ratesvideoondemand20 channels (120 mhz) for18200+ programs of compresseddigital videofuture18 channels, services as needed0(108 mhz)broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a255typical solution has been to provide a decoder in the customerõs home,then to send commands from a headend controller to the decoder inorder to identify the services for which each subscriber is authorized; thisstrategy also permits the operator to capitalize on its economies of scaleand scope by broadcasting all signals simultaneously over the entire treeandbranch cable plant.the deployment of hfc networks has complicated the traditionalcontrollertodecoder scenario. that is, the network architecture and capacity have both changed, enabling the headend controller to send adiscrete broadband signalñcustomtailored to the consumerõs requirements, preferences, or purchasesñto each home. in many parts of thenetwork, the signals for all customers may pass over the bus and to thehome of each customer, so the settop box would be employed to cull outfor delivery only those signals that are to be received by a specific consumer. when the services are broadcast video programs, there is no interactivity and consequently little need for security beyond the remotescrambling of the video signal. however, when interactivity is a significant portion of the services, the consumer now has access to devices forboth receiving and transmittingñparticularly with the pc connected to acable modem connected to the bus network. the potential exists for bothintentional and accidental spillage of signals, onto and off of the network.conclusionthe existence of ubiquitous, broadband cable television networks inthis country affords an opportunity to see the rapid realization of extremely powerful digital networks. the hybrid fiber coax network offersan excellent highspeed data network solution today and combines thatwith a high degree of scalability to adapt to new technologies or servicesthat may be introduced in the future. the key to the provision of thiscapacity is the ability to increase the penetration of optical distributionequipment as the need arises. this path to progress will eventually lead tofibertothecurb (fttc), and even fibertothehome (ftth). leadinghfc suppliers drive this technology development and deployment inresponse to the cable operatorsõ customer demand and sustaining revenue sources.digital subscriber lineintroductiondigital subscriber line (dsl) service provides highbitrate digital service over ordinary phone lines, allowing from 100 kbps to tens of megabroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.256appendix abits per second to reach a telephone company customer. dsl service mayimplement digital telephone service, fast internet or other data services,and/or digital video and entertainment services. dsl is the phone companyõs alternative for broadband access. this section summarizes the basic concept and architectures of dsl service, provides an overview andprojection of standards and equipment, and envisions dslõs future andultimate broadbandaccess capabilities of telephone companies.there are 500 million voiceband modems in existence today, most ofwhich are used at speeds to 56 kbps to provide digital connection between various service providers and customers or to transfer data andfacsimiles. voiceband modems are limited in speed because the signalsmust traverse telephone company switches that allocate only 64 kbpsmaximum (of which 56 kbps are available) to any voice signal, as shownin figure a.11. these switches can allow aggregation to higher data ratesof several voice channels, but not over a single voice channel through theswitch. these digital highspeed data must follow an alternative paththrough the switch. an additional modem at the telephone company sideof the loop differentiates a dsl connection from a voiceband modemconnection, as in figure a.12. dslõs placement of the extra modem at thetelecommunications company (telco) switch enables the much higherspeeds of dsl to be switched because the switch can now accept thatmodemõs digital output into higherdigitalbandwidth routes through theswitch. thus, the dsl signal returns to digital format when it enters thecentral office, while the voiceband modem signal is effectively embeddedin analog throughout the switch network. the bandwidth of the twistedpair alone is potentially very high, much higher than the 64/56 kbpsfigure a.11voiceband modem reference model.telcotelcococotelcotelcococotrunkuser 1user 1localloopuser 2user 2modem transmission pathmodem transmission pathlocalloopbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a257allowed for digitized voice paths through the switch. however, high digital speed on the copper loop requires sophistication in the design of thedsl modems that attach to the loop. telephone companies originally didnot appreciate the value of their copper asset and considered replacementwith fiber or coaxial systems, but release of dsl standards and availability of lowcost dsl equipment have provided phone companies with anopportunity to leverage their existing plant.below are summarized some of the technical challenges of the dslmodem and the use of existing phone lines for highspeed digital service,as well as some of the challenges for network design and support of dsl.generally, higher dsl data rates occur on shorter phone lines. as phonecompanies can afford the time and money to install fiber into more oftheir network, copper phone lines reduce in length. thus, an incrementalmigration over the next 50 years to fiber, allowing increasing data ratesfor customers and greater and greater connectivity and information ageservice, can occur without need for wholescale network replacement.figure a.13 depicts the growth to date in digital transmission speedson phone lines. several types of digital transmission on phone lines areshown for comparison. generally, dsl today often really means adsl,an asymmetric dsl service that can carry up to 8 mbps downstream froma telephone company central office to a customer and up to 1.5 mbps backupstream. approximately 1 million adsl lines are now deployed, and thenumbers are growing rapidly as early problems and delays with servicetelcocotelcocotrunklocalloopmodem transmission pathmodem transmission pathlocalloopmodem transmission pathmodem transmission pathuser 1user 1user 2user 2modemmodemmodemmodemsplitsplitmodemalt broadband pathalt broadband pathfigure a.12dsl modem reference model.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.258appendix aintroduction have begun to abate, and telephone company personnel areincreasingly trained and fluent in this new service. in a short time, tens ofmillions of customers will be connected. adsl service can now be ordered in nearly onethird of the united states, and telephone companiesplan ubiquitous coverage in the near future. vdsl, the latest of the dsls,can carry up to 60 mbps on a single phone line and is in early trial andstandardization phases. vdsl presumes some use of fiber to shortenphoneline lengths, consistent with eventual migration to fiber by phonecompanies. these are clearly much faster than voiceband modems. isdnand highbitrate dsl (hdsl), some phone company early dsl alternatives, are also shown in figure a.13 for perspective. adsl deployment,though, will soon eclipse the number of isdn and hdsl circuits in service.as fiber penetrates and very large scale integrated circuit (vlsi)technology allows yet further sophistication in the design of copperpairmodems, eventually 100 mbps plus symmetric connection to individualcustomers is possible with dsl, making it by far the broadband accesstechnology of greatest potential individual bandwidth to the customer.1955 1970 1981 1986 1992 1993 1996 1997 1999bell 103modem300 b/sbell 202modem1,200 b/sv.22bismodem2,400 b/sservice introduction datebasicrateisdn144kbpshdsl1.5or2 mbpsv.34modem28.8kbpspcmmodem56kbpsadslup to7mbpsvdslup to52mbpst1carrierlocaldigitalswitch;dlcfiberopticsatmswitchinternetmassmarketfigure a.13data rate increase for phone lines.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a259dsl standardsto establish a dsl connection, two modemsñone owned and operated by a telephone company and the other owned by the customerñmust interoperate, thus mandating standardization of the interface. asdescribed in cioffi et al.,3 standards committees have charted the courseof dsl technology and the architecture for the associated networks. theinternational telecommunication union (itu) has headquarters ingeneva, switzerland, and has a major role in standardization. however,the fundamental dsl standards work has largely been conducted in thet1e1.4 committee of the american national standards institute (ansi),4the european telecommunications standards institute (etsi), and theadsl forum. the earliest dsl standards, all adopted internationally after minor modification, originated in the american group. these standards groups maintain close cooperation with each other and the itu.itu study group 15 (sg15) has recently taken the lead in developing anoffspring of adsl called g.lite (also known as universal adsl) for consumeroriented use at bit rates of 1.5 mbps and below. the g.lite standardwas released in 1999 as g.992.2 along with an international version of theadsl standard called g.dmt (g.992.1). the main difference in the twostandards is speed, with g.lite at 1.5 mbps and g.dmt allowing in excessof 8 mbps. the industry appears to have turned to use of the latter g.dmtmodems at the lower speeds of g.lite with imbedded potential for futurespeed increase as service providers condition and shorten phone lines.(for more on standards bodies and the relationship of the groups fordsls, see chapter 16 in cioffi et al.5)dsl architecturesthere are almost 1 billion phone lines worldwide. the telephone linesare twisted pairs of copper wires, with the twisting invented by a.g. bellhimself, in 1887, along with the phones (1876) to which they are attached.63j. cioffi, t. starr, and p. silverman. 1998. digital subscriber lines. prenticehall, uppersaddle river, n.j.4see american national standard t1.6011992, òintegrated services digital network(isdn) ð basic access interface for use on metallic loops for application on the networkside of the nt (layer 1 specification),ó 1992, new york, n.y., and òvdsl system requirements report,ó ansi document t1e1.4/98043r2, june 1998, huntsville, ala., rev 14a. seealso etsi technical specification ts1012701 (199804), european telecommunications standards institute, sophia antipolis, france.5cioffi et al., digital subscriber lines, 1998.6r.b. bruce. 1973. a.g. bell, and the conquest of solitude. cornell university press, ithaca,n.y.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.260appendix athe phone lines are varied in a great many respects, but the topology ofthe loop plant of a phone company usually follows that of figure a.14.the phone lines are terminated on central office equipment, wherethe dsl modem can reside. the central office (co) equipment is connected to phone lines at a main distribution frame (mdf) that essentiallyallows physical connection (òjumperingó) of switch/dslmodem lines tocustomer linesñas many as 160,000 of which may enter a single centraloffice. the first segment of the loop plant is typically called the òfeederplant,ó where hundreds of phone lines may be bundled in a cable thatruns to a smaller distribution point, labeled as sai in figure a.14. thisfeeder segment is the first that phone companies upgrade to fiber, withapproximately 10 percent of the united states now so upgraded andsmaller percentages in other countries. such fiber is expensive, but thecost of labor, digging, and so on can be shared over a greater number ofcustomers in the feeder segment, making certain upgrades economical.at the distribution point, splicing and connection to smaller cables containing fewer phone lines occurs, and those cables run through the òdistribution plantó to pedestals or cabinets within a neighborhood wheremaindistributingframesaifeederdistributionpedestalsniddrop wireinside wirecustomerpremises20,000 to160,0001,500 to 4,000200 to 8004 to 12number of lines present at a site22,000 ft9,000 ft3,000 ft500 ftwire length to customer (90th percentile) central office equipmentfigure a.14telephone loop plant topology.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a261connection to the actual twisted pair in a specific customer site (home orbusiness) occurs. phone lines may thus be several miles in length. eventually, fiber can run to the pedestal as demand for high bandwidth becomesvery high, and ultimately to the customerõs premises as economics allow.figure a.15 illustrates the distribution of lengths of twisted pairs forthree countries: italy, the united kingdom, and the united states. clearlythe united states has the longest loops, simply because its network wasdeployed the earliest, when phone company practice was to use longerloops. the united kingdom is intermediate in terms of loop demographics, while countries that lagged the united states by several decades, suchas italy, have the shortest loop demographics. one can thus expect theachievable data rates to be the lowest for dsls in the united states. italy,germany, and sweden, for instance, are excellent candidates for higherspeed dsl service because a large fraction of their loops are within akilometer or two of the central office. however, fiber deployment is occurring faster and sooner in the united states in the feeder segment,which will ultimately reverse the relative lengths shown in figure a.15.for instance, the largest u.s. telephone company, southwest bell corporation, recently announced a $6 billion dsl loop renovation program,known as project pronto, that will bring many loops to less than 4 km01020304050607080901000.511.522.533.544.555.566.577.58loop length (km) {1 km = 3.28 ft}percentage within lengthfigure a.15cumulative loop distribution for italy (solid squares), the unitedkingdom (solid circles), and the united states (solid triangles).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.262appendix awithin a few years. project pronto is an example of reversing the trend infigure a.15. deregulation and aggressive dsl and internet use in theunited states have motivated sbc to move quickly, unlike internationaloperators who still have far less competition because unbundling deregulation has lagged that of the united states by a few years at least.central officefigure a.16 illustrates the network architecture of dsl. a dsl accessmultiplexer (dslam) resides at the telephone company side of thetwisted pair. a splitter circuit may precede the dslam termination sothat analog pots signals can be passively separated from the dsl signalsand conveyed to the voice telephone switches. splitters are 3port devicesthat ensure that dsl signals above 30 khz and pots signals below 4 khzare simultaneously passed over the telephone wire without mutual disruption. the dslam houses the modem and processes the customer bitstreams into larger rate fiber transported data streams that usually useatm formatting. various gateway devices can accept the fiber inputs andgateway(s)dslamvideoserviceprovidermuxordemuxadslmodemadslmodemadslmodeminternetserviceprovidersplitpotsnetworktelephone company officedigitalanaloganalogdigitalfigure a.16telephone company central office and dslam.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a263separate the signals into individual applicationsõ provider networks, suchas internet service providers, video and entertainment providers, or voiceservice providers. colocation today involves separate dslams for eachservice provider. an alternate service provider must be given fair andequal access to the phone lines of the service providerõs customers.customer premisesfigure a.17 illustrates the customer premises end of a dsl connection. the customer can be a residential user or a business user. while asplitter can be used at the customer premises also, the cost of installationis often perceived as excessive, and so dsl signals typically enter thecustomerõs premises and terminate on application devices. existingphones often are augmented by a passive lowpass filter known as amicrofilter, which protects the phone from dsl signals and protects dslfrom ringvoltage transients that otherwise would be disruptive to dslservice. the dsl modem may be part of a residential or smallbusinessgateway that either connects to another network in the home or redistributes digital signals to all application devices at frequencies above 5 mhz.(adsl and its latest prot”g”, veryhighdatarate asymmetric dsl[vadsl or vdsllite], exist only below 5 mhz.) the itu sg15/q4 groupalso standardizes this redistribution system, which is known currently asmicrofilteradslg.pntmicrofilterg.pntg.pntg.pntvodslinterfacehome/business wiringcustomerpremisesfigure a.17customer premises (residence or small business) dsl interface.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.264appendix ag.pnt. customer premises wiring alone can carry huge data rates above 5mhz, and sophisticated modem design is less necessary because the actual redistributed data rates are well below fundamental limits. however,the dsl signals that traverse the much longer path from central office tocustomer need a high degree of sophistication to achieve the data ratesdesired in dsl.dsl transmission environmentthe dsl transmission environment is challenging, and should not beunderestimated. this challenge was the first that had to be addressed indeveloping an opportunity for dsl. in fact, in the early days of dsl, therewas little phone company support or interest because it was believed thatthis challenge would be insurmountable. fortunately, an initially small(but now very large) group of transmission experts worked togetherthrough standards groups to derive practical, highspeed dsl modems.challenges continue for yet further increases in dsl speed and capability.this section discusses the salient characteristics of telephone lines fordigital transmission, with the intent of conveying the difficulty of thetransmission problem for dsls.the journey of a bit over a phone line is analogous to a long, arduoustrip with several borders to cross, potentially dangerous trip segments,with various difficulties and costumes imposed upon the traveler, potentially disguising that personõs appearance to all but those who know wellhow to recognize the traveler at the destination. only the best preparedtravelers (bits) can successfully complete the journey, if the receiver alsoknows well how and what to look for. the shorter the journey, the moresuccessful travelers/bits conveyed to the final destination. phone linestypically comprise several segments of wire, characterized by gauges (19,22, 24, or 26 in the united states and equivalent 0.8, 0.6, 0.5, and 0.4millimeter [mm] diameters in the metric system internationally). thehigher the gauge, or more narrow the wire, the more arduous the journey.at the borders between phone line segments, some energy is reflected,meaning that a bit may be harder to recognize as a 1 or 0 by the time itreaches its destination. this energy loss may be equated to an aggressivecustoms officer confiscating some identifying documents from the traveler. some bit energy may also be diverted to unused opencircuitedphone branches (for extension phones or extension phone jacks), furthermarring the appearance of the bit; these branches are known as bridgedtaps. the effect of bridgedtaps is analogous to unnecessary deadendside trips by a traveler to a port that the traveler did not know was closed,but draining their energy with the wasted round trip, making the exhausted traveler yet more difficult to recognize. some standardized phonebroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a265line characteristics and behavior appear in the subsection on looptransfercharacteristics.phone lines endure a lot of noise, which obscures or disguises the bit.the noise is typically electromagnetically coupled into phone lines. theexternal sources of energy that contribute to noise can include signals onother phone lines (known as crosstalk), radio, and ham broadcasts, andvirtually any type of electrical or mechanical equipment within closeproxmity to the phone line. such noise can be severely disguising, andtransmitted bits need to be adequately prepared to avert complete loss ofidentity if they are to negotiate their journey successfully. the subsectionentitled òsources of noise in dsl systemsó below, overviews severaltypes of noises.the energy from a bit may also radiate from a phone line, potentiallydisturbing radios within the vicinity of any portion of the phone line. thisis analogous to a boisterous traveler upsetting all the other travelers, thusrunning the risk of retribution of some sort. the subsection below entitledòemission constraints and psd masksó describes this problem and thelevel of concern.characterization of twistedpair telephone lineschapter 4 of cioffi et al.7 details the calculation of the frequencyresponse of phone lines, which are often described by their òinsertionloss.ó the insertion loss is measured in decibels (10 times the base10logarithm) of the ratio of the power injected into a phone line at any givenfrequency to the power emanating at the end of the phone line at thatsame frequency. the injected power may be measured without the phoneline present, and then measured again after the phone line is òinserted,ówhence the name òinsertion loss.ó some insertion loss plots versus frequency for american standardized 3 and 4mile phone lines appear infigure a.18. these loops were chosen by ansi to represent the top 10percent of worstcase lines in the united states. loops 14 in the left plotrepresent simple gauge changes. the usable bandwidth over the lines,where signals are still distinguishable from noise, may extend to about600 khz. note the large range from as high as ð20 db to ð100 db ininsertion loss for usable frequencies. this means that the largest signalson the line may be 100 million times more powerful than the smallestsignals of interest. by contrast, voiceband modems see a range of only afactor of 100, making dsl transmission a million times more sensitive!7cioffi et al., digital subscriber lines, 1998.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.266appendix aloops 58 on the right have bridgedtaps. notice the rippling of the insertion loss, corresponding to signal energy reflecting from the opencircuited extensions and returning later in time to the main line to add to thecurrent signals there. at some frequencies, the reflected signals are 180degrees out of phase and destroy the current signals, corresponding tothe dips. at other frequencies, energies add, essentially returning thesignal closer to its original unreflected signal level. (a good discussion ofbridgedtap and other effects appears in an article by j.j. werner.8)figure a.19 shows insertion loss characteristics of some shorter standardized loops,9 indicative of what might be used with vdsl over a yetwider bandwidth of 30 mhz. the left plot shows insertion loss for 300mand 500m loops of 26gauge (tp1) and 24gauge (tp2) wire, respectively.as the length increases, the slope also increases. on the right, a short loopvdsl5 with a bridgedtap has very noticeable rippling, but otherwise issimilar in slope to the insertion loss characteristics on the left. as thelength is increased to 1 km and then to about 1.5 km for vdsl6 andvdsl7, respectively, the insertion loss decays much more rapidly withfrequency and still exhibits significant rippling because of the bridgedtaps. the same large dynamic range (now because a greater range offrequencies is used at shorter lengths) is again evident for vdsl.the bridgedtap in vdsl5, 6, and 7 is 10 meters in length, a reasonable and typical number. thus, the notches are an oftenencountered phenomena.012345678910 frequency (hz)frequency (hz)line psd (db)adsl canonical loops # 1, 2, 3, and 4 insertion lossx105x105020406080100120140020406080100120140 adsl canonical loops # 5, 6, 7, and 8 insertion loss012345678910 figure a.18ansi loops 14 (at the left) and 58 (at the right), insertion loss.8werner, j.j. 1991. òthe hdsl environment.ó ieee journal on selected areas in communication 9(6):785800, august.9òvdsl system requirements report,ó ansi document t1e1.4/98043r2, june 1998,huntsville, ala., rev. 14a. see also etsi technical specification ts1012701 (199804), european telecommunication standards institute, sophia antipolis, france.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.267 frequency (hz)frequency (hz)020406080100120magnitude (db)020406080100120insertion loss for "short" vdsl 1, 2, 3insertion loss for vdsl 5, 6, 7vdsl2 500mvdsl3 500mvdsl5vdsl6vdsl7 00.511.52 2.53 00.511.52 2.53x107x107vdsl1 tp1 300mvdsl1 tp2 500mfigure a.19shorter loops for vdsl systems (tp1 = 26 gauge and tp2 = 24 gauge).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.268appendix asources of noise in dsl systemsnoise on a twistedpair transmission system arises from three mechanisms:1.the thermal noise of the twisted pair itself,2.the noise generated internally by the receiving modem, and3.signals electromagnetically coupled into the phone line.thermal or actual medium noise on a twisted pair is extremely small,near the boltzman limit of ð174 decibels per millihertz (db/mhz) at roomtemperature, and essentially can be ignored. the noise generated by terminating equipment depends on the design of the receiver electronics.standards groups often suggest that this noise level should be about ð140dbm/hz,10 but welldesigned modems often generate less, to as low asð160 dbm/hz. this noise is usually flat in spectrum (i.e., òwhiteó) anddetermines the ultimate frequency limits of a dsl. the insertion loss of adsl, as discussed above, and the transmit powerspectral density indbm/hz determine the line output powerspectral density (psd).for instance, an adsl system transmitting at the maximum psd of ð40dbm/hz can tolerate up to about 85 to 90 db of insertion loss beforeresulting in a channel output psd of ð125 to ð130 dbm/hz, 10 db aboveð140 dbm/hz (10db signaltonoise ratio) necessary for adequate detection even in wellcoded and designed dsls). thus if ð140 dbm/hz is thereceiver noise floor, then a dsl using one of the lines on the right infigure a.19 would use bandwidths of up to 600 to 700 khz. adsl systems actually allow use of bandwidths up to 1,104 khz, which would thusoccur on lines that are shorter than those displayed in figure a.19, thushaving less insertion loss at 1 mhz.electromagnetically coupled noise occurs because the twisted pair isoften bathed in radiation from a number of electronic sources. the twistedpair has imperfections that cause this radiation to induce noise voltagesinto the differential signal carried between the two wires of a twisted pair.figure a.20 shows the twisting of a twisted pair and the opposite spatialpolarity of the voltage at adjacent twists. theoretically, this twisting introduced by a.g. bell himself in his 1887 patent should almost cause cancelation of induced voltages. this is because impinging radiation wouldhave different polarities in the adjacent segments and thus cancel itself,the reason for the twisting. of course, the twisting is never perfect, nor isthe cancelation, but twisting is better than no twisting. many phone cus10american national standard t1.4131995, òadsl metallic interface specification,ó 1995,new york, ny. please see issue 2, if available, t1.4131999.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a269tomers are familiar with the òflat pairó they purchase for extending phonelines within their home. this wire is not twisted, and is much more susceptible to noise pickup; nonetheless, fortunately, this flat pair representsonly a small segment of the total length of the phone line. category 3twisted pair, typically used by phone companies, has a few twists perinch. category 5 twisted pair is a higher grade, with tighter twisting andabout 100 times better rejection of noise. category 5 twisted pair findsincreasing use in new buildings (which almost always still use twistedpair wiring) and in local area network connection. flat pair is, of course,the worst for noise pickup.crosstalk noisefigure a.21 illustrates crosstalk noise, which is the noise produced bysignals on other phone lines. as discussed above, several phone linesshare the same cable. typically, 25 to 50 twisted pairs are wrapped tightlyin a binder group. different twisted pairs within the binder group havedifferent numbers of twists per inch (to prevent radiation patterns fromexactly matching and offsetting the twisting pattern on other twisted++figure a.20twistedpair voltage polarities.pair 2pair 1f21nextnextxfh,2xfh,1fextfextxdfh,1nearendreceiverfarendreceivercrosstalkingtransmitterfs2dxfigure a.21crosstalk illustration.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.270appendix apairs), and there is some level of rejection caused by twisting. nonetheless, a signal launched from a nearend transmitter on the right in figurea.21 will enter the cable and begin to couple into the reverse direction onanother twisted pair. this type of oppositedirection crosstalknoise coupling is known as next, or nearend crosstalk. when the insertionloss of the segment of wire between the coupling point in both directionsis considered and the noise problem integrated over the total length ofwire, basic physics leads to the standardized crosstalk coupling functionfor dsls ofpsdfnfpsdfnextnearendxmit(),..,œ491061513(1)which not coincidentally increases with the 1.5 power of frequency matching the decrease in balance of the twisted pair as frequency increases. thefactor of n represents the number of twisted pairs in the binder expectedto carry crosstalking signals. this type of noise often dominates receivernoise when it exists. for instance, the psds of several dsl signals appearin figure a.22, where it is clear that the psd often exceeds ð140 dbm/hz,especially over the frequency range of operation of the offending dsl. 00.10.20.30.40.50.60.70.80.911401351301251201151101051009590frequency (mhz)adsl upstream nexthdsl nextisdn nextpsd (dbm/hz)figure a.22some worstcase crosstalk spectra for various dsl types.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a271the reader should note that while the crosstalk coupling increases withfrequency, the noises plotted in figure a.22 combine the coupling withthe transmit power spectral of each of the signals, and if there is no signalat higher frequencies, then there is no crosstalk. the actual crosstalk intoan individual twisted pair from one of its neighbors is not as bad as themodel at all frequencies. clearly the coupling is heavily frequency dependent and only at worst case exhibits the behavior of the standards modelabove in equation (1). nonetheless, this model is heavily used for conservative dsl design.also in figure a.21 is the coupling of signals from one phone line toanother in the same direction, which is often called fext, for farendcrosstalk. an exercise similar to the one for next finds a standardizedfext coupling function ofpsdfndfhfdpsdffextxmit4991062220.,(),(2)where d is the length of the line in feet and h is the insertion loss of thetwisted pair. the fext model is similarly pessimistic and does not include the highly frequencydependent nature of real crosstalk when onlyone or at best a few other lines interfere in any given frequency band. thelevel of fext is usually well below next and even below ð140 dbm/hzoften, but at higher frequencies above 500 khz begins to become significant and indeed dominant at yet higher frequencies because of the dependency on the square of the frequency. fext is usually of strong concernonly in vdsl.radio noiseas figure a.23 implies, telephone lines are great radio receivers, especially for am radio broadcasts. indeed, am radio signals are deliveredto customers on phone lines in some countries (e.g., switzerland). amradio signals exist in the internationally recognized band from 560 khz to1,600 khz. the doublesidebandwithcarriermodulated am signals are10 khz wide and likely to have psd levels of ð100 to ð120 dbm/hz onphone lines, comparable to crosstalk signals and much larger than internal modem noises. it is common, if not the norm, to see 2 or 3 large amradio signals on a phone line in the metropolitan area of any city. thus,only a small percentage of the transmit band is disturbed, but in thosebands, the disturbance cannot be ignored. the problem is particularlyevident on elevated phone lines (telephone poles), but not insignificanteven on buried phone lines.am radio interference is of concern for both adsl and vdsl butdoes not overlap the transmission bands for highbitrate dsl (hdsl) orisdn.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.272appendix aham radio signals are an even greater problem. while smaller poweris transmitted by ham radio operators, the ham antennae are distributedmassively through residential environments, often being only 10 to 100maway from a phone line. the level of interference is sometimes as large asð35 dbm/hz, and typically on the order of ð50 to ð60 dbm/hz, wellabove the levels of any other noise type. fortunately, ham radio signalsare typically only 2.5 khz wide, and there may likely only be one of themwhen such interference occurs. ham radio signals may be transmitted ininternationally recognized narrowbands from 1.8 to 2 mhz, 3.5 to 4 mhz,7 to 7.1 mhz, 10.1 to 10.15 mhz, 14 to 14.35 mhz, and 18.068 to 18.168mhz that overlap vdsl transmission, but not other dsls.impulse noiseimpulse noise is nonstationary crosstalk from temporary electromagnetic events in the vicinity of phone lines. examples of impulse generatorsare as diverse as the opening of a refrigerator door (the motor turns on/off), control voltages to elevators (phone lines in apartment buildingsoften run through the elevator shafts), and ringing of phones on linessharing the same binder. each of these effects is temporary and results ininjection of noise into the phone line through the same basic mechanismas rf noise ingress, but typically at much lower frequencies.differential (metallic) induced voltages are typically a few millivolts(mv) but can be as high as 100 mv, corresponding to levels of ð50 to ð70dbm/hz. typical impulses last tens to hundreds of microseconds (s) butcan span time intervals as long as 3 s.figure a.23radio interference.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a273emission constraints and psd masksdsls need not only be concerned with noises generated by otherelectronic signals, but also with the radiation they create. the concern forsuch emission exceeds that normally associated with electronic equipment, where the fcc (in the united states) mandates certain maximumlevels of radiation in various frequency bands. in the case of dsl modems, the telephone line itself, while not inside the modem, does radiate,and so this type of radiation is typically limited by limiting the powerspectral density of signals transmitted on phone lines.unbundling and standards solutionsthe american national standards instituteõs t1e1.4 group has takena lead role in discerning problems with crosstalk between various typesof dsls, standardized and nonstandard. the idea is that if all servicescomply with defined spectrum masks, coexistence of different serviceprovidersõ equipment in the same cable of twisted pairs is possible without the transmission technique itself having to be standardized. a voluntary ansi spectrum management standard was issued in 2001 and offered to the fcc for possible use in future rulemaking.evolution possibilities for dsl technologyan enabling event for dsl transmission at high speeds occurred onmarch 10, 1993,11 when ansi selected the discrete multitone transmission(dmt) technology for adsl. the technology offered greater adaptivitythan previous conventional technologies for transmission. the essentialingredient was an ability of the receiver and transmitter to communicatethrough a lowspeed overhead backchannel that allowed the transmitterõsdsl spectrum and information content to adjust to each and every phoneline in an individually optimized manner. the technology outperformedeven the bestoptimized nonadaptive methods in several independenttests (sometimes showing more than a thousandfold improvement innoise immunity), and was selected. while early modems were expensive,the standards groups successfully bet on vlsi improvements eventuallymaking most of the gains of the dmt technology costeffective, which hasnow happened, and dmt is the basis of all adsl standards, includingthe recently released itu standards òg.liteó (g.992.2) and òg.dmt dsló(g.992.1). the additional benefit of standardization allowed economies of11curiously, the 100th anniversary of the invention of the telephone.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.274appendix acompetition, as multiple suppliers are assured of interoperable productsthrough the use of and adherence to standards.good dmt designs gain outstanding performance on telephone lines,and this section enumerates both present performance levels and futureperformance levels. this particular technology will allow a number ofsolutions to the unbundling and crosstalk problems mentioned above;these solutions have yet to be implemented but are simulated here toallow an understanding of future research directions in this dsl area.as phone companies increasingly deploy fiber, telephone line lengthsbecome shorter. it is thus of interest to know the possible data rates versusline length. three such plots are presented in the following subsections.in each, the current stateoftheart methods are plotted, as well as a number of potential enhancements that researchers have suggested will further dsl performance.adsl and projectionsfigure a.24 lists the first set of curves for dmt adsl. the verticalaxis plots data rate, while the horizontal axis plots line length in feet. asline length increases, all data rates decrease. the lowest curve shown isthe performance of a good design that meets current adsl standardizedperformance levels. most current adsl modems will not allow morethan 10 mbps maximum speed, which occurs at about 2,000 feet in thelowest curve. at about 3 miles, 1.5mbps speed is attainable, while a fewhundred kilobits per second are possible beyond that range. adsl usesonly the lower 1.1 mhz of bandwidth on a twisted pair.a first step in improving these curves is to allow the modems to usesophisticated multiuser informationtheorybased detection methods toeliminate crosstalk effects between lines. the next two curves eliminatenext and next/fext, respectively. note that when crosstalk is removed, a huge jump in data rate is attainedñby a factor of about 3.suddenly, 10 mbps is possible even to a 2mile range. a 2mile range is atarget of projects such as sbcõs project pronto. the socalled bitcap isrelated to adc (analogtodigital converter) performance levels, and withimprovements in such technology beyond todayõs stateoftheart conversion devices, additional improvement is possible. finally, a last curveshows the improvement in performance with some of the most powerfulcoding methods yet found (i.e., turbo codes).vadsl and vdsl projectionsfigure a.25 lists the first set of curves for what is known recently asdmt vadsl. this extension of adsl allows up to 5 mhz of bandwidthbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a275to be used on a twisted pair, which allows considerably higher data rateson shorter lines.data rates jump on lines of a few thousand feet, with 20 mbps pluspossible on 3,000ft lines (which characterize the second of the fiber termination pointsñthe socalled distribution node) with current methods.again, with use of more sophisticated methods, another doubling in thedata rate is feasible.figure a.26 is for socalled vdsl, which uses up to 20 mhz of bandwidth on a twisted pair. here, data rates on 1,000ft loops, socalled pedestal drops, can exceed 250 mbps with all possible and/or known improvements included. a last curve, òultra dsl,ó allows an increase oftransmit power to 400 milliwatts, perceived as an analog limit for phonelines with vdsl parameters.network and application interfaces for dslas discussed in the introduction to the major section òdigital subscriber line,ó dsl technologies are able to achieve their high bandwidths02,0004,0006,0008,00010,00012,00014,00016,000length (ft)currentcancel selfxtalkcancel all xtalkincrease bit capimprove coding 010203040506070total rate (mbps)figure a.24current adsl and projections.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.276appendix a02,0004,0006,0008,00010,00012,00014,00016,000length (ft)currentcancel selfxtalkcancel all xtalkincrease bit capimprove coding 0102030405060total rate (mbps)02,0004,0006,0008,00010,00012,00014,00016,000length (ft)currentcancel selfxtalkcancel all xtalkincrease bit capimprove codingultradsl 050100150200250300total rate (mbps)figure a.25vadsl and projections for 5 mhz bandwidth use.figure a.26vdsl performance and projections with 20 mhz of bandwidth.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a277over the copper loop because they avoid the existing telephony networkof switches and transmission channels optimized for voice traffic. in asense, the existing nondsl modem technology òcreatively abusesó thephysical path that is established from point to point for carrying voicetraffic by placing the data on a path designed to carry voice. this has theadvantage of allowing for worldwide switched connectivity of data. however, it also limits the bandwidth of the connection to, at most, 64 kbps.this is the rate supported by the digital voice channels within and between the switches of the worldwide transmission network.providing a dslbased physical path on a copper loop will allow auser to transmit at high data rates over that loop. however, dsl will getthe data only to the end of the copper in the central office. to reachdestinations desired by the dsl user, a highbandwidth data networkmust be provided from the co to these remote sites. telecommunicationscarriers thus face new problems in constructing and managing a networkthat is intimately involved in data networking issues.in the current environment, they need only provide the physicallayer connectivity (using either the switched network or a private dedicated line for higherbandwidth connections). they are isolated from thedetails of their usersõ data networks. in the case of the voice network, it isas if the telco provides trains from place to place and does not care whattype of car is placed on the trains or what is in the boxcars. in providingdsl services, the telephone companies must provide a network that interacts directly with their usersõ networks and protocols. the telco nowneeds not only to operate the tracks and trains but also to provide boxcars, tank cars, and transshipment between trains, ships, and planes.the carrier needs to address the following issues if it is to providedsl services to its customers:¥it must provide a data network connecting the adsl terminatedcopper loops to the service providers desired by customers. examples ofservice providers include the public internet, private corporate networks,interactive video services, or highly interactive games.¥it must provide costeffective interfaces between its network andthe service providers.¥the data protocols that connect the customer to service providersover the adsl network must be compatible with existing technologiesand procedures used by both customers and service providers and mustalso support the highbandwidth services provided by adsl.¥the carrier must develop methods to manage this new network.the carrier must be able to add new customers, repair problems, and billfor the services provided.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.278appendix aalthough there are many potential implementations that can addressthese issues, a discussion of two contrasting environments and potentialsolutions can illustrate the current direction of adsl endtoend architectures:1.the large common carrier environment in which a telecommunications provider offers services to masses of customers and supports manydifferent service providers;2.use of dsl in very specialized environments such as college campuses, military bases, or condominium apartments.the large common carriera large local exchange telephone company may support more than 2million telephone lines in a major metropolitan area. even a 10 percentpenetration of adsl results in 200,000 adsl customers in the area. forboth regulatory and business reasons, the carrier will need to providecommoncarrier access between users and any service provider who paysto connect to the access network. a user of the adsl service may wish toconnect to any service provider it chooses. simultaneous connections froma user to multiple service providers are likely to be required. other usersmay connect to only one service provider but require that the connectionbe physically secure. for example, a remote office might use the adslservice to connect to a central corporate lan.although largescale adsl service has yet to be deployed by anycarrier, many carriers are converging toward a common architecture. eachcentral office is served by one or more dslams,12 which terminate theadsl line in the central office. pots voice traffic is also carried on eachloop. splitters groom the pots traffic, carried at frequencies below 4 khz,before the loop is terminated on a port on the dslam. the pots traffic isplaced on a voice switch in the carrierõs legacy voice network.the adsl connection only provides a physical layer between thecustomerõs adsl modem and the modem in the co within the dslam.in this architecture, atm provides a data link layer endtoend betweenthe usersõ computing environment and the service providerõs network.an atm virtual circuit is established between the userõs adsl modemand the interface between the carrierõs atm network and the serviceproviderõs network.12dslam is an acronym for digital subscriber line access multiplexer. the term is nownever translated but has become a generic term for cobased devices that terminate dslloops.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a279the dslam in the co terminates many adsl lines (typically in therange of 200 to 600 adsl ports per dslam) and concentrates the trafficto and from the customers over ds3 (48mbps) or oc3 (155mbps) trunksthat connect to atm switches in the carrierõs atm data network. theservice providers are also connected to the carrierõs atm network viasimilar highspeed trunks. the use of atm allows for scalability of theservice to support hundreds of thousands of users in a metropolitan areaand a wide range of potential future adsl services.if the service provider and customer communicate using ip, the use ofppp (pointtopoint protocol) over atm, as defined in kwok et al.,13 willallow both the user and the service provider to operate in an environmentthat is similar to that provided by dialup modems today. in that environment, the ip is placed in ppp that is carried over the voice network between the usersõ and service providersõ modems. by using ppp over atm,the carrier can isolate both the service provider and user from the complexities of both adsl and atm.the specialized carrierin contrast to the large public carrier, many specialized deploymentsof adsl are possible. any organization that has access to copper loop candeploy adsl. for example, the owner of a large rental apartment building may install an adsl service to provide highspeed internet access tothe tenants. a competitive local exchange carrier (clec) can, under theterms of the telecommunications act of 1996, lease copper loops from theincumbent phone company (the incumbent local exchange carrier, orilec) and serve customers with adsl.the largest clecs may end up resembling ilecs in both scale andarchitecture of their adsl services. however, in many cases the deployment will be small and will have similar requirements to the small adslimplementation in the apartment building. other examples of small adsldeployments could include college campuses (which typically own theirown copper loop plant), hotels, or military bases.the requirements for these ònicheó deployments of adsl includethese: small scale, that is, from 100 to 1,000 users total; limited need tosupport multiple providers; and the service provider and carrier may beidentical. in the case of an adslequipped apartment building, the customers are connected directly to the isp contracted to provide service to13timothy kwok et al. 1997. òan interoperable endtoend broadband service architecture over adsl systems (version 3.0),ó adsl forum contribution 97215.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.280appendix athe building. in the case of a clec, the clec may itself be an isp. in thecase of a campus, the users will be connected directly to the university orcompanyõs data network.the dslam containing the atucs is either in close proximity to orintegrated with an ip router. the router is connected directly to the ipnetwork of the isp or corporate network. it is managed as an integral partof that network. the adsl connections to the user support ip over hdlcdirectly on the adsl physical layer.14 the adsl user appears as hostdirectly on the service providerõs ip network.wirelessintroductionbroadband wireless access is frequently mentioned as an importantalternative to wired technologies, namely, to dsl, cable, and fiber. wireless has always played an important role in telecommunications networksbecause of its inherent advantages of modest infrastructure investment(no wires!), rapid service deployment, and enduser mobility support.the strategic significance of wireless communication services has increased over the past decade as cellulartelephony subscriber growth continues to outpace all earlier projections. it is now clear that wireless willcontinue to play an important role in emerging telecommunications services, including narrowband data and broadband services because of thesame intrinsic advantages. for both internet and broadband services,wireless services have experienced a largerthanexpected gestation period owing to a combination of factors such as technology cost and performance problems, spectrum regulation barriers, and weak standards. however, wireless data and broadband internet services seem poised fortechnical and market breakthroughs over the next 3 to 5 years, and shouldthus provide an important alternative for facilitation of broadband services in the united states and other parts of the world.service conceptthe concept of a wireless broadband access network is shown in figure a.27. the basic idea is to provide a highspeed wireless link betweensubscriber devices such as pcs, internet appliances, pdas, and new per14adsl forum. 1997. framing and encapsulation standards for adsl: packet mode. adslforum technical recommendation003, june.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a281sonal multimedia devices (both fixed and mobile). it is expected that initial applications of broadband wireless access will start with fixed devicessuch as home pcs connecting to an isp, with a gradual migration towardmobile applications as enduser devices become more and more portable.thus, the initial impetus for wireless access comes from the need to rapidly deploy networks capable of supporting highspeed internet access.with increasing investment in nextgeneration wired networks, it may beexpected that (at least in developed countries), the focus for wireless systems will shift toward semimobile or mobile services, given that an increasing percentage of computing platforms will become inherently portable. it is noted that the wireless access network shown in figure a.27may be expected to interface with both the future public telephony network and the internet, which are themselves experiencing some degree ofconvergence as they migrate toward broadband services. this means thatwireless access networks for future broadband systems are likely to bearchitecturally aligned with protocols used in fixed networks, rather thanbeing designed as custom overlay solutions (as is the case with todayõscellular networks). in the long term, this may be expected to drive convergence between fixed and wireless networks further, where the same service is offered to both wired and wireless devices in a seamless manner.figure a.27broadband wireless network service concept.futureinternetbroadband wirelessaccess network mobile communications devicesfixedpc/wsmobile pda/piasemimobilelaptop, etc.growing proportion ofuser terminals 50% +?future telecomnetworkbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.282appendix atechnology overviewas mentioned above, adoption of wireless data services has beeninhibited by a rather slow improvement in wireless technology cost andperformance during the past decade or so. the previous generation ofwireless data technologies (including cellular modems, widearea data,satellite data, and wireless lans) fell far behind mooreõs law improvements experienced by most computing and telecommunications technologies. while wireless does pose important technical challenges, there appears to be no fundamental reason for this discrepancy, which wasprobably caused by insufficient r&d and/or venture funding needed todrive this area. the situation has been largely corrected during the last 2or 3 years, during which various new broadband wireless technologieshave emerged as competitive options to wired solutions. this is illustrated in figure a.28, which shows the evolution of wireless technologyperformance over the last decade. as shown in the figure, newer commercial or precommercial wireless technologies have reached the mbps+ bitrate levels necessary for viable broadband services, either fixed or mobile.figure a.29 shows the typical bitrate and mobility regimes for various broadband wireless networks currently under consideration. the figure shows the relative roles of fixed wireless access, highspeed wirelesslan, semimobile broadband pcs, and wideband cellular (imt2000).although these services are generally viewed as distinct (and may beworked on by different technical and business communities), changes intechnology are likely to result in new service models that merge one ormore of the existing categories. in the united states, broadband wirelessservices are likely to start out with fixed access to residences and gradually evolve towards portability and mobility. the reverse is likely to happen in europe and japan, where socalled 3g mobile services are expectedto appear on the market within the next few years, and may later beapplied to broadband wireless local loop (wll) scenarios.the generic architecture of a broadband wireless network consists ofthe following major components: radio modem (physical layer), radiolink protocol (rlp), and fixed infrastructure network with capabilities forsupporting wireless/mobile services. the following subsections summarize key technology issues related to each of these major subsystems.physical layerbroadband wireless networks require physicallayer bit rates that areorders of magnitude higher than those for current digital cellular or wllsystems, i.e., 10 to 100 mbps versus the current 10 to 100 kbps. the higherbit rates must be achieved without introducing lineofsight (los) conbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.283figure a.28evolution of wireless technology performance, 19901999.199019951999cpulan/wanlocalaccessmemorywirelesscdpd3g mobileuniiwlan, etc.cablemodemdslgbpsrouteratm56k modemsw ethernet10001000100010001000100100100100100wirelessaccesslocalaccesslan/wanswitchingcpuspeedmemorysize1010101010kbpskbpsmbpsmhzmb11111broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.284appendix astraints, thus indicating a need for robust modulation techniques thatwork well for nonlos channels with fading. at the same time, spectrumlimitations imply the need for significantly higher spectrum usage efficiency (bps/hz/unit area), that is, 5 to 10 bps/hz/cell versus the current0.5 to 1 bps/hz/cell. clearly, if broadband wireless services are to reachsignificant penetration, cell sizes will have to be relatively small (~1 to 5km radius), capable of providing, say, 100 mbps to 1 gbps of data throughput per square kilometer for frequency allocations of a few hundred megahertz.the above orderofmagnitude improvements can indeed be achievedvia a combination of technology improvements, including these:¥highspeed (mbps+) radio modems based on advanced signalprocessingtechniques, such as equalization, spread spectrum, multicarrier modulation, spatial processing, and smart antennas. examples include equalized qam, usedin several firstgeneration fixed wireless systems; equalized vsb in theu.s. terrestrial hdtv standard; wideband directsequence cdma, underconsideration for the 3g mobile (imt2000) standard; and ofdm, proposed for various fixed and semimobile scenarios (including etsi hiperlan ii and several proprietary wll systems, such as clarity wireless/cisco). spatial processing with multiple antennas, mentioned above, is anew dimension for improving modem performance, and has recently beenproposed by several independent groups (bell labs, stanford university,iospan) as a means for dramatically improving both nonlos coverageand spectral efficiency. all of these technologies are maturing rapidly,mobilitycellularpcswirelesslanumts/imt2000broadbandpcshighspeedwlanleos, etc.application regimefor broadbandwireless10mbps+ servicesfixed  moderatemobilitypacket data +voice/videomicrowavebroadband10 kbps100 kbps1 mbps10 mbps100 mbpsfigure a.29broadband wireless service scenarios in terms of mobility versusbit rate.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a285and it may be expected that commercial products will soon deliver10 mps+ services with cellular reuse and spectral efficiency on the orderof 5 bps/hz/sector. with continuing advances in signal processing,achievable bit rates should increase to 100 mbps+ with spectral efficiencyof 10 bps/hz over the next 5 years.¥cellular technology capable of scaling to small cells and multiple sectorsnecessary for effective coverage of areas with higher population density. scalingof broadband wireless services to small cells is inevitable in areas withhigher population density, where throughputs on the order of 100 mbpsto 1 gbps/km2 must be achieved in order to serve even a modest fractionof the population. efficient cellular reuse implies the need for modemtechnology that can operate at relatively low carriertointerference (c/i)ratios. this can be achieved by a suitable combination of time/frequency/space processing. for example, spread spectrum achieves high spatialreuse via timefrequency processing, while multiple antenna spatial processing ofdm modems do so using frequencyspace processing. wideband cdma adopted for imt2000 radio access achieves a spatial reusefactor of 1:1 using spread spectrum and interference cancellation techniques. however, net throughput per square kilometer is limited by therelatively low ~0.5bps/hz efficiency of spread spectrum modulation.spatial processing techniques mentioned earlier have the potential forachieving spectral efficiencies on the order of 5 to 10 bps/hz/cell with~1:3 spatial reuse. further gains can be achieved for both cdma andspatial processing ofdm with directional remote antennas and base station sectorization.¥spectrum regulation and management policies that facilitate rapid deployment of broadband services, while promoting efficient use. the pace ofwireless network deployment is critically dependent on spectrum regulation policies, both international and domestic. historically, the process offrequency allocation has been rather slow, with the united states and tosome extent the european union taking the lead in introducing both spectrum auctions and unlicensed bands in order to stimulate efficient economic usage. while onetime spectrum auctions in the united states havehad their intended effect (e.g., pcs and mmds bands), it may be time toconsider introducing more dynamic market mechanisms that allow spectrum to change hands in timeconstants of minutes or hours rather thanmonths or years. for example, it may be possible to establish an onlinecommodity trading system for spectrum that would permit operatorswith higher economic utility to bid for their peak usage needs withouthaving to go through a lengthy procurement process.rapid deployment of wireless services would be further facilitated bystreamlined approval processes for a wider range of customer equipment,broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.286appendix aincluding those with higherpowered directive antennas. this wouldprobably require further advances in antenna beam and power control,but should be technically feasible in the near term. the broadband wllbusiness model depends to a large extent on userinstallable or selfconfiguring customer premises equipment (cpe), something that would require some relaxation of current rules in mmds and other fixed accessbands. in addition, it may be expected that fixed access will graduallymigrate toward semimobile services as cell sizes become smaller, furtherincreasing the need for simple approval policies.unlicensed spectrum, such as the 5ghz unlicensed national information infrastructure (unii) band in the united states, is an importantfacilitator for broadband access. fccõs allocation of the unii spectrumhas stimulated considerable commercial activity in the highspeed wireless lan area. it is recognized that the same type of technology (perhapswith somewhat higher power levels and larger coverage areas) could beused as a broadband pcs access network for public semimobile servicesin urban and suburban communities. there is, however, one remainingtechnical problemñthat of spectrum etiquetteña decision on which wasdeferred by the fcc in its initial unii ruling. the problem is that existing unlicensed band etiquettes such as listenbeforetalk (lbt) do notwork well for stream services with qualityofservice (qos) requirements.in such cases, the etiquette must be designed for equitable sharing amongcontending stream users, without reducing all of them to an unacceptableqos level. the fcc has invited the industry to propose a suitable etiquette, but a specific scheme has yet to be identified. a possible technicalsolution is to introduce a common spectrum coordination channel at theedge of each unlicensed band and require users to execute mutuallyagreed sharing procedures (priority, dynamic auction, and so on) using astandardized etiquette protocol.radio link protocolbroadband wireless access requires a new type of radio link protocol(rlp) capable of reliably transporting both packets and media streamswith specified qos. the broadband rlp itself may be decomposed into amedium access control (mac) layer for channel sharing among multiplesubscribers, and a data link control (dlc) protocol for error recovery.broadband wireless networks tend to use either a packet cdma, dynamic tdma type, or an extended 802.11 carrier sense, multiple access/collision avoidance (csma/ca) mac protocol. cdma is the basis forthe emerging imt2000 wideband cdma standard for 3g mobile, and isassociated with the choice of spread spectrum modulation believed to beappropriate for vehicular mobile systems. dynamic tdma has generallybroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a287been adopted for broadband applications, as well as for some highspeedlans (such as wireless atm and the european telecommunications standards instituteõs broadband radio access networks) in view of its ability tosupport a combination of packet data and constant bitrate streams (voiceand video). extended 802.11 protocols provide streaming extensions forqos support, and may be suitable for ethernetequivalent wlan scenarios. docsis mac protocols used in cable networks have also beenmodified for wll applications, but will generally incur a performancepenalty owing to large packet sizes.datalinklayer retransmission for error recovery is an essential feature for broadband wireless service, since higherlayer protocols are critically dependent on low packet error rates on each link of the endtoendconnections. dlc involves fragmentation of data packets into relativelysmall units, the optimum for which is typically between 40 and 200 bytes,depending on the channel and traffic model. many current implementations have adopted the atm cell payload of 48 bytes as the basic unit offragmentation on the radio link. this has the advantage of simplifying theinterface to atm backhaul networks, which are often used in carrierbroadband and dsl networks. error control on the radio link involves theaddition of a wireless link header containing a sequence number used foridentifying data units to be retransmitted. implementation results haveshown that significant improvements in endtoend protocol performance(typically 2 orders of magnitude in packet error rate) can be achieved withfragmentation and retransmission on the radio link. this in turn permitswireless systems to operate in a higher c/i environment, thus increasingoverall capacity of cellular networks.infrastructure networkbroadband wireless access links are being designed as òpluginsó toexisting fixed network architectures based on ip and/or atm. in order tofacilitate ubiquitous deployment, it is important that both fixed wll andmobile access be easily integrated with broadband dsl and cable networks currently being deployed. this means that the radio air applicationprogramming interface should be harmonized with both ip and atm tothe extent possible, particularly in terms of providing generic parametersfor service establishment and qos control. for fixed wireless access, interface functions specific to the radio link are performed by the base station,which puts out standard ip and/or atm data and control into the infrastructure network.for mobile scenarios, services (such as location management andhandoff) specific to mobile users may be provided either with a mobilityoverlay, used in current cellular systems, or by integrating mobility supbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.288appendix aport into the core network protocols, such as ip or atm. the latter method(i.e., support integrated mobility in ip or atm) is the preferred methodfor broadband in view of performance and scalability requirements. moreover, as an increasing proportion of user devices becomes portable, thedistinction between fixed and mobile user addresses will become moredifficult to administer (the integrated approach does not require a prioripartitioning of mobile and fixed addresses). protocol specification workaimed at integrating mobility support into ip and atm has been done inboth the internet engineering task force (ietf) (mobile ip) and the atmforum. while much further work remains (3g.ip and so on), it may beexpected that mobility will increasingly be integrated as a standard feature into fixed network infrastructures. ultimately, this technical direction will further accelerate fixed and wireless network convergence, whichhas been predicted for some time.media compressionmedia signals include (digital) data as well as analog information andentertainment signals: speech, audio, image, video, graphics, and otheraudiovisual signals such as hand gestures and handwriting. these signalclasses are universal and are representative of most if not all informationthat needs to traverse the first mile, in either direction.complementary roles of modems andcompression systems (codecs)modem and access technologies have evolved to expand the transmission pipe for conveying digital information. in parallel, compressiontechnology has evolved to compact the amount of digital information thatis needed to convey the information in a signal with a specified level offidelity. access speeds have generally advanced on a faster track than hascompression technology. that said, it is the combination of faster modems and greater levels of compression that has enabled advances andrevolutions in digital communication. this section focuses on the impactof media compression as a direct enabler of digital communication overchannels and networks with limited capacity.computing is an overarching enabler of multimedia communications,whether one is implementing coders or decoders (codecs for short) or isimplementing modulators or demodulators (modems for short). mooreõslaw has direct implications on the rate at which computing technology(memory and arithmetic capability) advances as a function of time. in thisview, advances in computing are much more rapid than are advances inaccess technologies. that said, advances in computing will only helpbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a289speed up advances in access, but these advances are strictly knowledgeor algorithmlimited, as are the advances in compression.the dimensions of performance in media compressionthere are four dimensions of performance in a compression system:(1) quality, (2) bit rate, (3) delay, and (4) complexity. òqualityó refers tothe quality of the signal after compression, measured in absolute terms orin terms of closeness to the original version of it. the òbit rateó is the datarate after compression. the òdelayó is the sum of delays in the encodingand decoding parts of the system: the compression and decompressionalgorithms. (this does not include delay components resulting from specific implementation details or specific transmission latencies in the communication of the encoder bit stream.) finally, òcomplexityó refers to thecomputational effort needed to perform the compression and decompression algorithms, measured for example, in millions of instructions persecond (mips) and kilobytes (the readonly and randomaccess memoriesused in the codec [coderdecoder]). as processing technology improves,the importance of the complexity parameter tends to diminish, but delayremains as a fundamental performance metric. delay is particularly important in interactive, or twoway, communications.the fuzzy fifth dimension: richness of contentin studies of compression efficiency, where one measures quality degradation as a function of increasing levels of compression, one assumesthat the bandwidth, or frequency content in the signal, is a prespecifiedcharacteristic. for example, telephony is always associated with a speechsignal of 4khz bandwidth, and television with a signal whose effectivehorizontal and vertical resolutions are on the order of a few hundredpixels in each case (a total number of pixels per frame on the order of100,000).in table a.2, the notation of pps refers to pixels per second. it is theproduct [h v  f] of horizontal resolution (h pixels per row), verticalresolution (v pixels per column), and temporal resolution (f frames persecond).with the evolution of flexible and scalable communications technology, one often has the option of considering input signals of higher bandwidth, as long as the compression is strong enough to delimit the outputdata rate to a specified number. examples are highbandwidth audio (suchas fmgrade speech with 12 to 15khz bandwidth or cdgrade musicwith 20khz bandwidth, or multichannel sound) and highdefinition television (a total number of pixels on the order of 2 million, 60 frames persecond).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.290appendix ascalability in bandwidth is a somewhat fuzzy situation in that usersare often not conditioned to the continuum in this parameter between, orbeyond, wellestablished anchors. for example, wideband speech is afuzzy term that implies any bandwidth in the range between welldefinedtelephone and cd grades (4 and 20 khz), and firstgeneration internetvideo often is understood to mean anything that is usable, albeit belowtv quality (such as 10,000 to 100,000 pixels per frame). the video situation has the additional dimensions of viewing distance, physical picturesize, and fractionalscreen displays, which further control user appreciation of picture quality or user perception of picture degradation.the algorithms of media compressionthe description of compression algorithms is beyond the scope of thisappendix. it is also not needed for the purposes of this report. what isimportant, however, is to note that all compression algorithms are basedon only two basic principles: removal of redundancy in the input signal,and the reduction of irrelevancy in it. òredundancyó is usually characterized in a statistical fashion, while òirrelevancyó is best linked to a perceptual criterion. compression techniques are also usefully classified intothree types: (1) lossy, (2) lossless, and (3) perceptually lossless. mathematically lossless compression is used in some archival, legal, and medical applications, while perceptual losslessness is a pragmatic criterion fora large class of applications in transmission and storage. most compression standards tend to address this criterion. other characteristics to keepin mind are the delay and complexity of the algorithms, and how they aretable a.2multimedia formatsformatsampling ratefrequency bandtelephone8 khz2003,400 hzteleconference16 khz507,000 hzcompact disk44.1 khz2020,000 hzdigital audio tape48 khz2020,000 hzcif video3 mpps [360  288  30]ccir video12 mpps [720  576  30]hdtv60 mpps [1,280  720  60]note: mpps = megapixels per second.source: nikil jayant, 1993, òhigh quality networking of audiovisual information,óieee communications magazine 31(9).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a291distributed between the compression and decompression parts of the system. for example, interactive and twoway applications look for lowdelay compression, servers can typically afford high complexity, and client systems need to be relatively simple to implement. implementationplatforms can be asic (applicationspecific integrated circuit), dsp (digital signal processor), or nsp (native signal processor, as on a pentium).as a matter of calibration, a pentium ii (400mhz) processor can decodempeg1 video streams in real time, and a pocket pc in 2001 has a processor that works at half the speed (about 200 mhz).compression standardstables a.3 and a.4 provide nonexhaustive lists of compression standards for audiovisual signals. in general, results refer to lossy compression, although these standards include special functions for lossless compression. for example, in jpeg image compression, there is a lossy(perceptually lossless) version with typical bit rates of 0.5 to 2 bits perpixel (bpp), while a mathematically lossless version may use a bit rate of5 to 6 bpp.in figure a.30, the horizontal axis displays bit rates after compressionfor classes of applications that are arranged in clusters that representspeech, audio, and image applications. the bit rates range from 1 kbps to100 mbps. interestingly, the geometric mean of this range is 300 kbps, anumber typical of conservative adsl and cable modem rates in the year2000. the data rates in figure a.30 are strict lower bounds in the sensethat in most applications, the compressed information needs to be supplemented with ancillary data.bit error protectionin a rate k/n error correction code, k information bits are protectedfor transmission over an errorprone channel by adding (nk) redundantbits. the fractional overhead is 1k/n.sophisticated methods of error protection include these:¥unequal error protection, in which different parts of the compressoroutput receive different levels of error protection, depending on modelsof their relative perceptual importance;¥joint source and channel coding, in which, for example, the total bitrate available is shared dynamically between source bits and error protection bits, depending on the model or knowledge of the channel state.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.292appendix atable a.3standards for speech compressionstandard (year)algorithmbit rateapplicationg.722 (1988)subband64, 56, 48 kbpsteleconferencingadpcmmpeg1 (1992)musicam384, 256,twochannel audioaspec128 kbpsw/video on cdmpeg2 (1996)pac320 kbpsfivechannel surround soundfor multimedia recordingdab (1996)pac160 kbpstwochannel audio forterrestrial broadcastjbig (1991)run length0.050.1 bppbinary coded imagescoding(halftone)jpeg (1991)dct0.258 bppstill continuoustone imagesmpeg1/2mddct18 mbpsaddressable video on cd(1991, 1994)p 64 (1991)mcdct641,536 kbpsvideoconferencinghdtv (1996)mddct17 mbpsadvanced tvg.711 (1972)mulaw and5664 kbpsnetwork transmissionalaw pcmg.721 (1984, 1987)adpcm32 kbpsbitrate multiplexers,undersea cableg.723 (1988)adpcm24, 40 kbpsoverload on underseacable, data modemg.726/g.727adpcm16, 24, 32,high overload rate for40 kbpsundersea cableg.728 (1992)ldcelp16 kbpstransmission at low delayg.729 (1995)acelp8 kbpssecondgeneration digitalcellularg.723 (1995)acelp6.3, 5.3 kbpslowbitrate videophonegsm (1987)rpetlp13 kbpseuropean digital cellularfullrateis54 (1989)vselp8 kbpsnorth american digitalcellulartdmais96 (1993)qcelp8.5, 4, 2,north american digital0.8 kbpscellularcdmagsm1/2 (1994)vselp5.6 kbpseuropean digital cellularhalfrateevrc (1996)rcelp8.5, 4, 0.8 kbpsna cdma, 2nd generationis136 (1995)celp8 kbpsna tdma, 2nd generationjdc (1989, 1992)vselp8, 4 kbpsjapanese digital cellularñfull and half ratesfs1016 (1975)celp4.8 kbpssecure telephonyñfull ratefs1015 (1975)lpc10e2.4 kbpssecure telephonyñhalf ratefs1015 (1996)2.4 kbpssecure telephonyñhalf rate,2nd generationsource: after r.v. cox. 1999. òcurrent methods of speech coding,ó in n. jayant (ed.),1999, signal compression: coding of speech, audio, image and video, world scientific,singapore.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a293table a.4standards for audio, image, and video compressionstandard (year)algorithmbit rateapplicationg.722 (1988)subband adpcm64, 56, 48 kbpsteleconferencingmpeg1 (1992)musicam/aspec384, 256, 128 kbpstwochannel audio w/video on cdmpeg2 (1996)pac320 kbpsfivechannel surroundsound for mm recordingdab (1996)pac160 kbpstwochannel audio forterrestrial broadcastjbig (1991)run length coding0.050.1 bppbinary coded images(halftone)jpeg (1991)dct0.258 bppstill continuoustoneimagesmpeg1/2(1991, 1994)mcdct18 mbpsaddressable video on cdp 64 (1991)mcdct641,536 kbpsvideoconferencinghdtv (1996)mcdct17 mbpsadvanced tvnotes: kbps = kilobits per second; bpp = bits per pixel.source: after r.v. cox. 1999. òcurrent methods of speech coding,ó in n. jayant (ed.),1999, signal compression: coding of speech, audio, image and video, world scientific,singapore.figure a.30data rates in digital representations of signals. rates are numbersafter compression. source: after r.v. cox. 1999. òcurrent methods of speechcoding,ó in n. jayant (ed.), 1999, signal compression: coding of speech, audio, image and video, world scientific, singapore.hdtvdigitaltelevisionmovies oncompact diskmusic previewandbroadcastaudioconferencenetworktelephonyvideo conferencecellularradiovoicemailhighresolution facsimilesecurevoiceimagephoneslideshow 1 2 4 8 16 32 64 128 512 1 2 8 32kilobits per secondmegabits per secondbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.294appendix aresiliency to packet lossespacket networks are often limited by packet losses rather than biterrors. packet losses can be addressed by retransmission in delayinsensitive applications. in delaysensitive communications, packet losses can beanticipated by redundancy in the packet generator.in sophisticated algorithms, such as embedded coding and multipledescription coding, this redundancy is contained by unequal protectionof subpackets, depending on models of perceptual importance of thesesubpackets, as in unequal bit error protection.information hiding, steganography, watermarking,and multimedia annotationsincreasingly, digital communications will include ancillary information that may convey a variety of information to the end user that isrelated to authentication (information about sender and intended receiver,for example), and such information is embedded in the main message inan unobtrusive and imperceptible form. these are the techniques of information hiding, with subclasses called steganography and watermarking.multimedia annotations also involve additional data, but not necessarilyin imperceptible or hidden form.the overall effect of all of the above processes is that the data rate fordigital communication is strictly higher than the data rates at the outputof the signal compression stage. while there is no rigorous way of measuring the resulting overhead in data rate without regard to the application and the needs of it, it is useful to use the following guideline:typical overall overheads are in the range of 10 to 100 percent, andthe rates on the horizontal axis of the compression chart in table a.4 needto be increased by factors as high as 2.0, especially in the case of unfriendly access methods such as wireless links that are power and interferencelimited and/or in networks that are operating in situations ofoverload.in scalable media communications, the inherent excursions in datarate in the compression algorithm can well exceed the factor of 2 referredto above. in these cases, the metrics of importance are the average datarate in the scalable compression algorithm, and, where available and usable, more detailed descriptions of the data rate histogram. in fact, assessments of traffic and channel loading depend directly on these difficultand highly variable characterizations of the information source. the leastcomplex nontrivial measure of overall data rate is the average data rateafter compression, multiplied by the overhead mentioned in the guideline above.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix a295mediaspecific examples: access implications and questions¥tollquality telephony versus internet or cable modem telephony.whatare the quality and delay targets in iptelephony and cable telephony?what are the consumer expectations? is there a business case for amradiograde telephony? what is the competitive landscape?¥audio/video streaming at liteadsl, cable modem, and wireless speeds.are user expectations going to be tied to television quality? what is thelongevity of partialscreen solutions? what is the competitive landscape?¥uploading of information from a home.what are the primary casesfor uploadspeed on demand? what are the demands of such applicationsas telemedicine, teleworking, home publishing? is there a case for symmetric uplink and downlink?definitive answers to these questions do not exist, but as applicationsmature, it will be possible to understand and quantify them at least implicitly and qualitatively.research and technology outlookat this time, compression technologies are mature. although it isdifficult to define the fundamental limits in the game, typical data ratesfor specified levels of quality are generally known. increasing compression ratios will become the preoccupation of specialists. likewise, decoders and clients will become pervasive and affordable. new advances infirst mile and first meters multimedia communications will depend increasingly on advances in access speed and on innovations in networking.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.296a large legacy from past policy, dominated by telecommunicationsregulation, shapes the context for broadband policy. that legacy principally concerns regulation of wireline communications through commoncarriers, but it also includes regulation of cable, broadcasting, other wireless communications, and regulations applied to the internet. the legacyõssalient features are briefly reviewed in this appendix.the legacy from past policycommon carriers (telephony)local and long distance telephone companies operate as commoncarriers, which historically have had close regulatory scrutiny by bothfederal and state agencies. the history of common carriage is fundamental to the baseline for broadband deployment, because it shaped whatexists today in the telephone infrastructure as well as expectations innumerous industries and locales about the nature of investment and competition in communications and information infrastructure.a telecommunications òcommon carrieró is the term used to describea provider of telecommunications transmission service that offers its service to the public for a fee and, in contrast to, for example, a televisionstation owner or a cable television operator for most of its channels, doesnot control the content of the information transmitted by its facilities orservices. rather, the carrierõs customer controls the content and the destination of the transmission. criminal or civil responsibility for the contentbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix b297rests (for the most part) with the sender, not the carrier. for most of the20th century, federal and state regulation of common carriers has beenconsidered necessary because telecommunications services in any geographic area have been provided by a single carrier.1 similar thinking andtactics have been applied to providers of other kinds of infrastructureregarded as utilities, such as electric power or water, and historically totransportation, including rail, toll roads, ferries, and the like.while policy goals are established through laws, regulatory agenciesimplement the laws through rulemaking. the federal communicationscommission (fcc) regulates the interstate activities of such carriers,2 andstate commissions regulate their intrastate activities.3 rulemaking andother administrative proceedings follow a set of practices that involveissuing a notice of intent to act, solicitation of comments, and other formalities. these processes have given rise to a cadre of inhouse and privatepractice lawyers, economists, and lobbyists seeking to promote ordiscourage certain kinds of decisions by regulators. depending on oneõsperspective, these processes may reflect an open, fair process for implementing regulations or a drag on the telecommunications marketplace.regulators were persuaded that local and long distance services werenatural monopolies and, consequently, could be provided at the lowestcost through a single firm. economic regulation, not competition, wouldconstrain the prices and practices of the monopoly carriers. under thisregulatory regime, the bell system provided local telephone service invirtually all urban areas and gradually extended its reach to many ruralareas. its long distance network interconnected bell as well as subscribersof the remaining thousandplus independent telephone companies (eacha monopoly in its franchise territory), enabling any subscriber to call anyother telephone subscriber. over time, the bell system became the envy ofthe world because of the breadth, price, and quality of its service offerings.1these monopolies were created initially by at&tõs aggressive acquisition of independent telephone companies in the early 20th century. the regime emerged in the wake of the1913 agreement between the bell telephone system and the u.s. department of justice,known as the kingsbury commitment. in return for certain concessions, bell telephonewas permitted to retain the local telephone companies it had acquired since the turn of thecentury and to maintain its monopoly control over long distance.2under title ii of the communications act of 1934, as amended.3because at&t and the independent local telephone companies were permitted to operate as governmentprotected monopolies, the prices and other terms and conditions of theirservice offerings were subject to close scrutiny by federal and state regulators to prevent thetelephone companies from exercising their market power. if a call originates in one stateand terminates in another state or foreign country, that service is subject to the fccõsjurisdiction. if a call originates and terminates within the same city or within the same state,that service is subject to the state commissionõs jurisdiction.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.298appendix bin the last third of the 20th century, however, technological advancescast increasing doubt on the premise that telephone service, or at leastcertain aspects of it, should be provided on a monopoly basis. in the 1960sand 1970s, the fcc gradually relaxed regulation of telephone terminalequipment (e.g., telephone handsets, private branch exchanges), knownas customer premises equipment (cpe).4 these actions spawned the emergence of an intensely competitive market for handsets, fax machines, private branch exchanges (pbxs), and other terminal equipment.5 in the1970s and 1980s, the fcc followed a similar pattern of phased regulatoryrelaxation in the long distance market. the most significant event in theintroduction of long distance competition involved an antitrust casespawned by such competition and at&tõs response to it. in 1982, at&tand the u.s. department of justice entered into a consent decree, knownas the òmodified final judgmentó (mfj), that required at&t to divest itslocal operating companies.6 by separating at&tõs monopoly segmentsfrom its more competitive long distance operations, the decree went along way toward opening the latter to facilitiesbased competition, because it eliminated the incentive of the local telephone companies to discriminate against mci and other wouldbe at&t competitors throughtheir monopoly control over the local network.the decree removed one of at&tõs most substantial competitive advantages by requiring the bell operating companies to provide equalaccess to other long distance companies.7 as competition in the long distance industry matured, additional technical impediments were eliminated (such as the introduction of 800number portability across longdistance carriers) and new entrants began to make inroads into at&tõs4prior to the fccõs action, telephone equipment was part of the service that the localtelephone company provided to its customers. indeed, customers were prohibited by thecompaniesõ tariffs from attaching other equipment to the network.5in deregulating cpe, the fcc also preempted state commissions from continued regulation of that equipment. the fccõs jurisdiction under the communications act of 1934, asamended, in the 1970s was limited to interstate services. the commission recognized, however, that, as a practical matter, it could not deregulate òinterstateó cpe, since such equipment is used to place and receive both interstate and intrastate communications. hence, itbarred state agencies from continuing to regulate the provision of cpe in order to preventsuch policies from frustrating the fccõs national deregulation policy. see north carolinautils. comm. v. fcc i.6see united states v. american tel. & tel. co., 552 f. supp. 131 (d.d.c. 1982), affõd, 460 u.s.1001 (1983).7the operating companies were required to modify their networks to enable a subscriberto these other providers also to use the ò1+ó prefix to obtain access. prior to the implementation of this òequal accessó requirement, subscribers of long distance companies other thanat&t were required to dial a sevendigit local number, then dial a multidigit personalidentification number, and then dial the long distance number they were calling.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix b299market share, the fcc gradually relaxed price regulation of at&t on aservicebyservice basis.8the latter half of the 1980s and first half of the 1990s were marked bythe continued erosion of at&tõs long distance dominance, as mci, sprint,and scores of other competitors gained significant inroads (althoughat&t remains the largest provider). in light of these changes in the marketplace, the fcc gradually loosened its controls over different segmentsof at&tõs long distance business, culminating in a 1995 decision thateliminated the remaining fcc price controls of at&tõs basic residentialservices.9 although at&t remained subject to price regulation for morethan a decade after it divested its bell operating company subsidiaries,the prices of interstate services offered by new (and accordingly muchsmaller) providers of long distance, such as mci, were not regulated.10 bythe end of the 1990s, at&tõs share of the longdistance market hadslipped below 50 percentin the late 1980s, federal and state regulators also began to take thefirst steps toward opening local telecommunications markets to competition. following several states such as new york and illinois, the fccadopted its expanded interconnection rules, which required incumbenttelephone companies to interconnect their networks with new firms thatwished to provide competing local transport services. these developments raise the possibility of shifts in state regulatory emphasis fromretail rate regulation to wholesale enforcement.11the enactment of the telecommunications act of 1996 marked thecommencement of the most concerted effort by state and federal regula8for example, when 800number portability made it possible for an 800number customerto switch longdistance carriers and retain its 800 number (e.g., 1800flowers), the fccremoved its price regulation of at&tõs 800 service offerings.9because the fccõs jurisdiction is limited to interstate services, it does not regulate therates that local telephone companies charge for local and intrastate services (such as callsfrom los angeles to san francisco). local telephone companies, however, provide origination and termination service to interstate long distance companies. that is, the local telephone companies carry an interstate call from the originating end user to the interstatecarrierõs switch, where it is placed on the long distance carrierõs network. local telephonecompanies also carry calls from the long distance companyõs switch to the called partyõspremises. this origination and termination service is known as interstate access service andis subject to the fccõs jurisdiction.10the fccõs theory was that since the new entrants did not possess market power, therewas no need to regulate their rates. if consumers were dissatisfied with an mci offering,they could always take service from at&t, whose rates were regulated.11bob rowe. 2000. òimplementing a cooperative federalist approach to telecom policy.óspeech presented at federalist society, washington, d.c., september 27.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.300appendix btors to dismantle the monopoly control over local telecommunicationsmarkets exercised by the bell operating companies and other incumbenttelephone companies. the results have yet fallen short of the quick movement to òderegulationó that some had hoped for. armed with new statutory authority, the fcc and state regulatory commissions moved aggressively to require local incumbents to open their markets. incumbenttelephone companies, called ilecs (incumbent local exchange carriers)continue to have overwhelming market shares, particularly among residential customers, thanks to their initial monopoly position and scale andscope economies that are difficult to overcome. to help overcome theseincumbent advantages, the telecommunications act of 1996 mandatedthat incumbents offer competitors (clecs) access to unbundled networkelements at reasonable rates. because ilecs continue to control well over90 percent of local market revenues and customers, they remain subject tocomprehensive price regulation at both the federal and state level. clecs,lacking market power, generally are not.in 1999, the fcc adopted rules for the gradual deregulation of theincumbent telephone companiesõ provision of local service used for interstate communications. prices should be deregulated when there was evidence that the incumbent could not exercise market power.12 meanwhile,there has been horizontal consolidation among telephone companies plusvertical integration of such companies (e.g., qwest acquired uswest;nynex merged with bell atlantic, which merged with gte to becomeverizon; sbc acquired pacific telesis and ameritech; mci merged withworldcom, which also merged with uunet; and at&t acquired tciand other cable interests). thus, although the 1996 act eliminated legalbarriers to entry in those states where they persisted, economic and technical barriers are eroding more slowly. nevertheless, competitors havemade inroads among business customers in urban markets. against thisbackdrop, issues posed by open access in broadband have prompted fccinitiatives.cablethe regulatory regime governing cable television systems is entirelydifferent from the common carrier scheme. it has a much shorter history,12what criteria should be applied remains a controversial subject. the incumbents havechafed at delays to their entry into long distance. competitors to the ilecs have maintained that the criteria used by the fcc do not provide an accurate picture of the availability of alternative providers of local telecommunications services, and that the fcc blueprint would permit the incumbents to preserve their monopoly control over local marketsby granting them substantial pricing flexibility when they continue to wield market power.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix b301and it reflects the fact that following its earliest days, when cable wasused to provide television service in regions not reached by broadcasttelevision, cable grew by providing an alternative to an existing entertainment and information service (broadcast television) and faced initial deployment challenges. cable operators do not have to offer their transmission service to the public on a nondiscriminatory basis, unlike commoncarriers. most important for understanding how regulation was approached, cable systems maintain considerable control over the contentthat is transmitted over their distribution facilities. unlike common carriers, they have asserted first amendment rights with regard to the contentthey carry, a status upheld by the courts. cable operators generally arenot required to offer access to their distribution system to enable other(unaffiliated) content providers to deliver their products to cable subscribers (major multiple system operators that vertically integrate contentproduction and cable service are required to devote a portion of theirsystem capacity to unaffiliated networks). even without any mandate todo so, however, operators offer unaffiliated content channels for two reasons: (1) no single operator has enough highquality content to fill all ofits capacity, and (2) operators generally find that customer demand forthese channels exists. thus, almost every system carries cnn, which is anaol time warner service, and espn, which is owned by disneyabc. inaddition, cable operators, under certain circumstances, are required tooffer access to providers of traditional video services under the socalledleased access provisions of title vi of the communications act of 1934 (asamended). also, there have been local content requirements through public, education, and government channel provisions of franchises. nonetheless, the contrast between the relative freedom to control content andthe obligations placed on common carriersñwhich gives rise to expectations of similar behavior in the futureñis one genesis of todayõs òopenaccessó debate,13 discussed below.cable television is subject to limited federal regulation. under titlevi of the communications act of 1934 (as amended), the òbasic tieró ofservices, encompassing mostly local television signals, is subject to rateregulation. local authorities could regulate the price of the basic tier,pursuant to formulas prescribed by the fcc, unless òeffective competitionó existed, as defined by the cable act of 1992 (such price regulationexpired in 1999). cable television operators also are limited in their abilityto expand horizontally and vertically with content providers. devising,13proponents of open access have argued, among other things, that when a cable systemfurnishes access to an internet service provider, it is engaged in the provision of a commoncarrier service and, consequently, should be required with the same access obligations thatcharacterize common carriage provided by telephone companies.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.302appendix bimplementing, and enforcing regulations for the cable industry under the1992 act was difficult and timeconsuming. a major complication wasthat cable service, like broadband, is multifaceted and varies in capabilityfrom one service area to the next. in the end, it is not clear that the regulation accomplished much in the long run, with the exception of the rulesthat made cable network programming available to overbuild competitors and satellite services at òreasonableó prices, which spurred competition in video delivery.cable systems are also subject to local regulationñthrough the franchise agreements that they execute with municipal, county, or, in a fewcases, state authorities. these agreements typically run one or more decades and are a source of revenue for the municipalities that issue them.as franchise agreements have come up for renewal, the new capabilities of cable systems to deliver advanced video and data services havedominated the negotiations. as discussed in chapter 4 in the report, a keydevelopment beginning in the 1990s was the progressive upgrading ofcable plant to incorporate fiber (hybrid fiber coax), which increased system quality and capacity and more recently facilitated use of cable infrastructure for internet access. however, cable operators are not under alegal obligation to upgrade their plant to be able to offer broadband, cablemodem services. further, if operators complete such an upgrade, theycurrently are not (as a class) required to make access to that transmissionservice available to unaffiliated providers of broadband services. openaccess requirements (discussed in chapter 5) have figured heavily in several franchise negotiations. other elements arising in contemporary franchise negotiations include establishment of minimum data bandwidthand rightsofway (such as joint trenching rules where there are multipleentrants). new considerations analogous to the traditional public, educational, and government (peg) requirements include extensions to nonvideo services and making fiber available to local governments (and possibly for other customers).internetfear of regulation has always haunted the internet, although it isconsidered òunregulated.ó popular misunderstanding has even motivatedthe fcc to issue a fact sheet (last revised in january 1998) to dispel mythsabout charges and taxes it was alleged to have imposed or to be considering imposing on the internet or its use.14 since the late 1990s, fcc com14federal communications commission. 1998. òthe fcc, internet service providers, andaccess charges.ó available online at <http://www.fcc.gov/bureaus/commoncarrier/factsheets/ispfact.html>.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix b303missioners and staff have written and spoken publicly about the benefitsof the commissionõs handsoff approach to the internet.15 but the growthin public interest in the internet and the businesses behind it continues toraise questions about prospects for government intervention, includingregulation, whether direct or indirect.the historic interaction of regulation with the internet was ad hoc,even unintended. anecdotal evidence suggests that the internet was notrecognized as a phenomenon or concern by most regulators until the1990s, when it became commercial, and those circumstances or actionsthat can be identified do not seem to have been framed with the internetin mind.16 for example, a key enabler, in retrospect, was a series of fccdecisions that gave customers the right to attach approved devices directly to the network, which has allowed both isps and users to attachmodems to their phone linesña necessary precondition for dialup access.17 some observers also point to common carriage regulation as animportant internet enabler. entry by isps has been facilitated by commoncarrier rules which mandate nondiscriminatory access and reasonablerates apply to both the dialup lines used by individual customers and thetelephone network dedicated lines used by many isps to connect pointsof presence to the internet.another enabler came in the 1980 second computer inquiry, whenthe fcc ruled that firms that use basic telecommunications services toprovide an enhanced service of some kind (such as information delivery)are not engaged in the provision of a òbasicó common carrier, telecommunications service (such as local telephone service). rather, they are providing an òenhancedó service and, accordingly, are not subject to thedirect jurisdiction of the fcc or state regulatory commissions. that decision served to nurture commercial valueadded networks, bulletin boards,database services, and other data communications services in the 1970s15see, for example, jason oxman. 1999. òthe fcc and the unregulation of the internet.óoffice of plans and policy, federal communications commission, washington, d.c., july.available online at <www.fcc.gov/bureaus/opp/workingpapers/oppwp31.pdf>.16the early development of the internet was motivated in part by a desire to find relieffrom the high costs of dedicated leased line services available from the regulated telecommunications industry of the 1960s, which constrained early applications of data communications for government and the research community. the prevailing telecommunicationsenvironment fed the interest and efforts of the researchers supported by the defense advanced research projects agency, who both developed the early technology and were thefirst to benefit from the economies provided through packetswitching.17the certification scheme in 47 c.f.r. part 68, adopted in the 1970s, enables firms toobtain fcc approval for devices that are attached to the network, permitting third partiesto develop innovative communications equipment while ensuring that attachment of thisequipment does not threaten the integrity of the network.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.304appendix band 1980s. these proved, in retrospect, to be training grounds for themore open internet, as well as isps, in the 1990s.more recently, through section 271 of the telecommunications act of1996, the former regional bell operating companies are prohibited fromoffering interlata servicesñwhich include both long distance telephonyand internet transmission servicesñin states in which they provide localtelephone service, until they have satisfied certain marketopening requirements. as a result, while these companies may operate dialup andbroadband isps, customers must obtain connectivity to the rest of theinternet through a regional or national isp operated by another company.also, although virtually all internet communications cross state lines, in1997 the fcc affirmed18 an earlier ruling that the transmission betweenan end userõs premises and an enhanced service providerõs location in thesame calling area would be treated as a local call, rather than as an interstate call, regardless of whether that transmission carries data, an emailmessage, or even (at least under certain circumstances) a voice call overthe internet.19 finally, differences in internetwork traffic flows have feddebate over socalled reciprocal compensation, a subject of fcc inquiryin 20002001.20the telecommunications act of 1966 had another consequence thathas been important for the deployment of broadband internet access.because the act required the ilecs to unbundle their circuits to clecs, aclass of clecs came into existence that offered data rather than voiceover these circuits, by means of dsl technology. this investment in dslby competitive providers seems to have spurred investment in dsl byilecs, and thus to have driven the overall rate of dsl deployment. at thepresent time, the market downturn has put many of these competitivedsl providers in peril, but this should not cause one to dismiss the contribution of competition in this case.when incumbent telecommunications providers offer dsl, this service comes under the purview of the historical legacy of telecommunica18access reform order, fcc 97158, adopted on may 7, 1997.19precisely which voice transmissions might be subject to access charges is a delicate area.for example, the federal communications commission indicated in a 1998 report to congress that a handset call to an isp that terminated at a handset in another state may beclassified as a basic telecommunication service and hence be subject to access charges.20the concern is that different kinds of providers may terminate traffic out of proportionto that which they hand offñespecially the relative burdens of dialup internet traffic. atpresent, more may be terminated on clec than ilec networks, implying (at least to theilecs) significant reciprocal compensation payments by ilecs to clecs, but the nature ofpotential funds flows depends on actual dialup use in the future, a subject of disagreement(òin ôrecip compõ debate, clecs, telcos rely on varying projects for dialup internettraffic,ó telecommunications reports, january 8, 2001, pp. 910).broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix b305tions regulation. when an incumbent telecommunications provider sellsan enhanced service (which is not regulated) over a òbasicó service, theincumbent provider must provide the basic service to others. dsl is seenas a basic service. thus, at the present time, the ilecs must unbundletheir data services at two levels. they unbundle their physical loops socompetitive dsl providers can implement dsl, and they unbundle theirdsl service so competitive isps can sell internet access over the incumbentõs dsl service.the history presented here, which illustrates indirect regulatory support for the internet that has been largely inadvertent (at least until thelate 1990s), unfolded without consideration of broadband. it focuses onthe presence or absence of regulatory intervention into pricing and market entry. broadband expands the potential space for intervention in atleast two ways: first, it involves different kinds of industries and technologies providing internet access under different regulatory regimes(e.g., some have expressed concern about the implications for isp supportof cablebased internet access in contrast to common carriers). second,distinguishing between information services and telecommunications carriers blurs when facilities owners integrate carrier and information service functions, as is being seen in at least cable and satellitebased broadband offerings.present: the 1996 actmuch of the current policy framework relates to the telecommunications act of 1996, which was framed as a reform effort. since its enactmentand the unfolding of derivative activities, there is increasing awareness ofwhat it does and does not accomplish. this piece of legislation, a majormodification to the communications act of 1934, was shaped during theearly to mid1990s. the language of the act indicates that its primary goalsare to promote competition and reduce regulation as a means of increasing growth in telecommunications services and reducing prices.21 it wasenacted shortly after the 1995 commercialization of the internet backboneand introduction of the browsers that helped to popularize the worldwide web and before such technologies were widely used. even thoughmany of the key actors understood that sweeping change was on thehorizon, full appreciation of the key role of the internet did not exist, insociety or in washington.21the preamble calls it òan act to promote competition and reduce regulation in order tosecure lower prices and higher quality services for american telecommunications consumers and encourage the rapid growth of new telecommunications technologies.ó telecommunications act of 1996, p.l. 104104, 110 stat. 56 (1996), preamble.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.306appendix bthe telecommunications act of 1996 adjusted the relative roles offederal and state regulators, increasing that of the states. whereas thecommunications act of 1934 preserved state authority over intrastaterates and services, the 1996 act specified state roles in interconnection,incumbent telephone company long distance market entry, and promotion of advanced services. it sent mixed signals on federal preemption ofstate regulators, and it reinforced a kind of cooperative federalism.22most directly relevant to broadband, the telecommunications act of1996 calls for the fcc and states to encourage deployment of advancedtechnologies for telecommunications to all americans on a reasonableand timely basis. but what satisfies òadvanced,ó òall,ó òreasonable,ó andòtimelyó? the act, in support of service to òalló americans, calls foraccess to advanced telecommunications and information services in rural and highcost areas to be òreasonably comparableó to that in urbanareas in terms of price and quality. this formulation is interesting because it joins unregulated information services with regulated telecommunications services; what that implies for policy approaches and theirtargets is unclear. specific provisions of the act related to broadband aresummarized in box 5.1, chapter 5.24rowe, òimplementing a cooperative federalist approach to telecom policy,ó 2000.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.307as input to its ongoing study of broadband last mile technology issues and options, the computer science and telecommunications boardissued a call for white papers in summer 2000. the papers (arrangedalphabetically by authorsõ last names) are available for download atcstbõs web site, <www.cstb.org>. please note that circulation of thesewhite papers does not constitute endorsement of them by the committeeon broadband last mile technology, the computer science and telecommunications board, or the national academies.òfactors influencing investment in residential broadband equipment andservicesña venture capital perspectiveógeorge abe, palomar venturesòbroadband satellite networks for last mile technologyóian f. akyildiz, georgia institute of technologyòethernet broadband networkingóandreas bechtolsheim and david cheriton, cisco systemsòbroadband services to rural western massachusettsóedward ciesla, flack & kurtz consulting engineersbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.308appendix còaccess to what? first mile issues for rural broadbandórichard civille, richard civille and associates; michael gurstein,michael gurstein and associates; kenneth pigg, university of missouri atcolumbiaòlast mile connectivity utilizing fiber satellite solutionsótom dennett, harmonic data systemsòhigh bandwidth, applications, and economic development: letõs tie ittogether!ósylvie doucet, planned approach, inc.òbroadband access over inverse multiplexed copperóeinar edvardsen, telenor r&dògetting tele/tech on local government radarórichard esposto, western integrated networksòtechnology developments for quality multimedia delivery for residences: coupling of the broadband and home network technologiesóaura ganz, university of massachusettsòregulatory issues, pricing, and access to public utility rightofwayóhenry kilpatrick and paul baker, georgia institute of technologyòthe use of satellite technology for last mile broadband accessójosemarie montpetit and r. deiningeròdeployment of multimedia services to residential customersójose a. pozas, telefonica i+dòresidential internet ready buildings (irbs)óamnon ptashek, edsl networks, inc.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.309nikil jayant, chair, is the john pippin chair in wireless systems in theelectrical and computer engineering department at georgia institute oftechnology, founding director of the georgia tech broadband institute,and executive director of gcatt, the georgia centers for advanced telecommunications technology. earlier at bell laboratories, dr. jayantcreated and managed the signal processing research department, theadvanced audio technology department, and the multimedia communications research laboratory. contributions from these organizationsinclude the definition of unified structures for signal processing and computing, the invention of new technology for highdensity magnetic recording, the creation of the 16kbps ccitt (consultative committee oninternational telephony and telegraphy) international standard for network telephony, channel equalization and data coding technologies forthe is54 north american digital cellular standard, coding and transmission methodologies for voiceband videotelephony and highdefinitiontelevision, the establishment of perceptual coding as a definitive criterionfor lowbitrate coding of audiovisual signals, and the development of adigital audio broadcast system as potential future technology for cdquality radio broadcasting in the united states. more recent contributionsinclude software for texttospeech synthesis, automatic speech recognition, and natural language dialog; software for internet communication ofspeech, music, and video signals; and multimedia systems for messagingand the humancomputer interface. dr. jayant has published more than100 papers, written a number of books, and has been granted more thanbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.310appendix d20 patents. businesses created by dr. jayantõs research and leadershipspan several segments in audiovisual and data communications. dr.jayant has received several honors, including the alfred hay gold medal(for the best student in communication engineering, indian institute ofscience, 1965), the ieee browder j. thompson memorial prize award (forthe best ieee publication by an author under thirty years of age, 1974),the industry paper award from the institution of electrical and telecommunication engineers (india, 1990), the ieee donald g. fink prize paperaward (for the best tutorial paper in an ieee publication, 1995), and the1997 lucent patent recognition award. dr. jayant was inducted into thenew jersey inventors hall of fame for his contributions to the reductionof noise in communication systems and is a fellow of the ieee and amember of the national academy of engineering. dr. jayant serves onthe advisory board of nttdocomousa and is a cofounder and chiefscientist of egtechnology, which creates software solutions for lastmilemultimedia. dr. jayant received his phd in electrical communicationengineering from the indian institute of science, bangalore, india, in 1970.james a. chiddix is president of the interactive personal video group ataol time warner. the ipv group is headquartered in new york cityand is chartered with the development of a new broadband video serviceto be delivered to the companyõs millions of digital cable subscribers. theservice will provide an array of serverbased products, ranging from access to a large library of video on an ondemand basis, to personal videorecorder access and storage of live programming. it also will providehighly targeted advertising delivery. for the last 15 years, mr. chiddixhas served as senior vice president and chief technical officer for timewarner cable, headquartered in stamford, connecticut, and its predecessor companies. mr. chiddix has been deeply involved in the introductionof virtually every new cable technology since the midseventies. heplayed a pioneering role in exploring the use of broadband optical fibertechnology in cable television systems, which led to the universallyadopted hybrid fiber coax network architecture for cable systems. in1994, he accepted, on behalf of time warner cable, an engineering emmyaward for this work. he led the upgrade of time warnerõs queens, newyork, system to 150 channels (1ghz bandwidth), and was the architect oftime warnerõs full service network interactive television trial in orlando, florida. mr. chiddix has been in the cable television business for30 years. he spent 15 years in a variety of operating positions with twocable companies in hawaii. he was also founder and president of crcelectronics, inc., in honolulu, which manufactured videotape playback,automated delay, and randomaccess commercial insertion systems. crcwas sold to texscan in 1981. in 1986, he joined time warner cableõsbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix d311corporate office. he also served for 8 years on the board of directors ofcv21, a cable television company in fukuoka, japan. mr. chiddix is asenior member and former director of the society of cable televisionengineers, a senior member of the institute of electrical and electronicsengineers, and a member of the cable pioneers. mr. chiddix is a memberof the computer science and telecommunications board. mr. chiddixcurrently serves on the committee studying broadband access and helpedproduce the cstb report the unpredictable certainty: information infrastructure through 2000.john m. cioffi, bsee, 1978, illinois; phdee, 1984, stanford; bell laboratories, 19781984; ibm research, 19841986; ee prof., stanford, 1986present. cioffi founded amati com. corp. in 1991 (purchased by ti in1997) and was officer/director from 1991 to 1997. he currently is on theboards or advisory boards of bigband networks, coppercom, godigital,ikanos, ionospan, ishoni, itex, jubilant, marvell, kestrel, charter ventures, and portview ventures and is a member of the u.s. national research councilõs cstb. cioffiõs specific interests are in the area of highperformance digital transmission. he has received various awards:member, national academy of engineering 2001; ieee kobayashi medal(2001), ieee millennium medal (2000), ieee fellow (1996), iee jj tomsonmedal (2000), 1999 university of illinois oustanding alumnus, 1991 ieeecomm. mag. best paper; 1995 ansi t1 outstanding achievement award;and nsf presidential investigator (19871992). cioffi has published over200 papers and holds over 40 patents, most of which are widely licensed,including basic patents on dmt, vdsl, and vectored transmission.david d. clark is a senior research scientist at mitõs laboratory forcomputer science, where he is currently in charge of the advanced network architecture group. dr. clarkõs research interests include networks,network protocols, operating systems, distributed systems, and computerand communications security. after receiving his ph.d., he worked on theearly stages of the arpanet and on the development of token ring localarea network technology. since the mid1970s, dr. clark has been involved in the development of the internet. in the period 1981 to 1989, heacted as chief protocol architect for this development and chaired theinternet activities board. his current research area is protocols and architectures for very large and very high speed networks. specific activitiesinclude extensions to the internet to support realtime traffic, explicit allocation of service, pricing and new network technologies. in the securityarea, dr. clark participated in the early development of the multilevelsecure multics operating system. he developed an information securitymodel that stresses integrity of data rather than disclosure control.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.312appendix ddr. clark is a fellow of the acm and the ieee and a member of thenational academy of engineering. he received the acm sigcommaward, the ieee award in international communications, and the ieeehamming award for his work on the internet. he is a consultant to anumber of companies and serves on a number of technical advisoryboards. dr. clark is currently the chair of the computer science and telecommunications board. he chaired the committee that produced the cstbreport computers at risk: safe computing in the information age. he alsoserved on the committees that produced the cstb reports toward a national research network, realizing the information future: the internet andbeyond, and the unpredictable certainty: information infrastructure through2000. dr. clark graduated from swarthmore college in 1966 and receivedhis ph.d. from the massachusetts institute of technology (mit) in 1973.paul green recently retired as director of optical networking technology at tellabs in hawthorne, new york. he joined tellabs in january1997 after many years at ibm research, and before that, at mit lincolnlaboratory. at lincoln he developed the first operational spread spectrum system (1953), coinvented the first channeladaptive receiver (rake,1958), invented planetary rangedoppler mapping (1960), and worked onlarge digital seismic arrays for computerized discrimination betweenearthquakes and nuclear explosions. at ibm, his team pioneered peernetworking, which later became standard in ibmõs system network architecture. he initiated the wdm optical networking program there,which is credited with the first operational alloptical network (rainbow1 of 1991) and the first commercial wdm product, the ibm muxmaster(1995). at tellabs, his interests center on alloptical crossconnects, the keybuilding block of alloptical networking. dr. green received the ieeesimon ramo medal in 1991, the association of computing machineryõsannual communication award in 1994, and a number of ibm patentawards. he is a member of the national academy of engineering. he hasbeen president of both the ieee information theory society and the ieeecommunication society.kevin kahn is an intel fellow, the corporationõs highest technical position, and currently the director of the wireless technology lab, a corporate advanced development and research lab in intelõs corporate technology group. additionally, he helps drive communications strategiesand policy for the corporation and coordinates a variety of crosscorporate networking research. some of his primary current focuses are broadband access to the home, home networking, wireless lans, and internetissues bearing on these topics. throughout his 25year career with intel,he has worked in system software development, operating systems, probroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix d313cessor architecture, and various strategic planning roles on programs involving most of the processors intel has developed during the period. hehas held both management and senior individual contributor roles. hewas the cochair of the universal adsl working group, an industryalliance dedicated to accelerating the deployment of consumer adsl services for higher speed internet access, and served as a member of theboard of directors of the dsl forum. he serves on a variety of nsf andnas committees and panels, and is a member of the fcc technical advisory committee. he holds a b.sc. in mathematics from manhattan college, and m.s. and ph.d. degrees in computer science from purdue university.richard lowenberg is a telecommunity planner, environmental designer, media artist, and cultural activist. he has been executive directorof the davis community network and yolo area regional network incalifornia since 1996. in this position he has been a consultant to thecalifornia smart communities project and was principal coordinator ofòwaterworks,ó an online civic decisionsupport project, funded by thecorporation for public broadcasting (civnet program), army corps ofengineers, usgs national spatial data infrastructure program, and esri,inc. he currently serves on the board of the association for communitynetworking, on the steering committee of the global community networking congress, and on computer professionals for social responsibilityõs diac program committee. mr. lowenberg was founding director of the telluride institute and its infozone program, in colorado, from1985 to 1996. he served on the governing board of the colorado advanced technology instituteõs rural telecommunications project from1994 to 1997; web authored the 1995 u.s. economic development administration funded òrural telecommunications investment guide,ó and wasa principal participant on the 1996 ntiatiiap funded òmaps for peopleóproject. he has been and continues to be a presenter, writer, and consultant on òcommunity networking,ó òtelecommunity development,óònetworked economics,ó and òinformation ecologyó in the united states,europe, latin america, and japan; and his telecommunications and community development projects have received federal, state and local government grants; university and corporate support; international mediacoverage and recognition. richard lowenbergõs media, performance, andinstallation art works have pioneered in the integration of art, science,technology and ecology, with a primary focus on the social implicationsof the òinformation revolutions.ó he has received numerous grants andawards, including from the national endowment for the arts, and haspresented exhibitions and performances internationally, including at thewhitney museum, san francisco museum of modern arts, kunstmuseumbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.314appendix ddusseldorf, venice biennale, and mit list center for visual arts. mostrecently he has been òartist in bioregional residence,ó university of california at davis.clifford lynch has been the director of the coalition for networked information (cni) since july 1997. cni, jointly sponsored by the association of research libraries and educause, includes about 200member organizations concerned with the use of information technology andnetworked information to enhance scholarship and intellectual productivity. prior to joining cni, dr. lynch spent 18 years at the university ofcalifornia office of the president, the last 10 as director of library automation. dr. lynch, who holds a ph.d. in computer science from the university of california, berkeley, is an adjunct professor at berkeleyõs schoolof information management and systems. he is a past president of theamerican society for information science and a fellow of the americanassociation for the advancement of science and the national informationstandards organization. dr. lynch currently serves on the internet 2applications council and the national digital preservation strategy advisory board of the library of congress and was a member of the national research council committee that recently published the digitaldilemma: intellectual property in the information infrastructure.richard metzger is partner in the law firm lawler, metzger & milkmanllc in washington, d.c. mr. metzger brings direct insight into federaltelecommunications regulation and policy making, having served asdeputy chief and subsequently chief, of the common carrier bureau ofthe federal communications commission from 1994 to 1998. in thesepositions, mr. metzger was actively involved in the fccõs implementation of the telecommunications act of 1996. in particular, during histenure in the bureau, he supervised the preparation of recommendationsto the commission on a wide range of critical issues, including rulesgoverning interconnection, access charge reform, and universal service.prior to joining the commission, mr. metzger was a member of the lawfirm of rogers and wells, resident in the washington, d.c. office. hisareas of emphasis in private practice included telecommunications, antitrust, and public utility regulation. mr. metzger is a graduate of williamscollege, phi beta kappa. he received a j.d. degree from georgetownuniversity law center.elizabeth mynatt is an assistant professor in the college of computing atthe georgia institute of technology. there she directs the research program in òeveryday computingóñexamining the implications of havingcomputation continuously present in many aspects of everyday life. inbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix d315home environments, dr. mynatt aims to enable older adults to continueliving independently, through the use of future home technologies, asopposed to moving to institutional care settings. dr. mynatt is an internationally recognized expert in the areas of ubiquitous computing andassistive technologies. prior to her current position, she worked for 3years at xerox parcñthe birthplace of ubiquitous computingñalongside its inventor, mark weiser. her research explored how to augmenteveryday places and objects with computational capabilities. she haschaired multiple conferences on computer interface technologies and auditory displays, published numerous articles, and is an active leader inher field. dr. mynatt is a sloan research fellow. her research is supported by multiple grants from the national science foundation including a 5year nsf career award. dr. mynatt is the associate director ofthe georgia tech graphics, visualization and usability (gvu) center,and is responsible for research and educational objectives in humancomputer interaction, including a highly regarded hci masterõs degree program that bridges computing, psychology, design and communication.dr. mynatt received her ph.d. in computer science at georgia tech underthe guidance of dr. james foley. her dissertation work pioneered creating nonspeech auditory interfaces from graphical interfaces to enableblind computer users to work with modern computer applications.eli m. noam has been a professor of economics and finance at columbiabusiness school since 1976. in 1990, after having served for 3 years ascommissioner with the new york state public service commission, hereturned to columbia. he is the director of the columbia institute forteleinformation. citi is an independent universitybased research center focusing on strategy, management, and policy issues in telecommunications, computing, and electronic mass media. in addition to leadingcitiõs research activities, dr. noam initiated the mba concentration inthe management of entertainment, communications, and media at thebusiness school and the virtual institute of information, an independent,webbased research facility. he has also taught at columbia law schooland princeton universityõs economics department and woodrow wilsonschool. noam has published over 19 books and 400 articles in economicjournals, law reviews, and interdisciplinary journals. his books includethe authored, edited, or coauthored volumes telecommunications in europe; television in europe; telecommunications regulation: today and tomorrow; video media competition; services in transition: the impact of information technology in the service industry; the law of internationaltelecommunications in the united states; the international market in film andtelevision programs; telecommunications in the pacific basin; private networks, public objectives; global and local networks; asymmetric deregulabroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.316appendix dtion: the dynamics of telecommunications policies in europe and the unitedstates; telecommunications in western asia and the middle east; telecommunications in latin america; telecommunications in africa; the new investmenttheory of real options and its implications for telecommunications economics;and interconnecting the network of networks (spring 2001). his forthcomingbooks include media concentration in the united states and the dark sides ofthe internet. he has served on the editorial boards of columbia universitypress as well as of several academic journals. he was a member of theadvisory boards for the federal governmentõs fts2000 telecommunications network, the irsõs computer system reorganization, and the national computer systems laboratory. he is a member of the council onforeign relations. he received an ab (phi beta kappa), m.a., ph.d. (economics), and j.d. from harvard university.dipankar raychaudhuri is currently a professor, electrical and computer engineering department, and director, winlab (wireless information network lab), at rutgers university. he has previously held progressively responsible corporate r&d positions in the telecom/networking area, including chief scientist, iospan wireless (2000 to 2001);assistant general manager and department head, systems architecture,nec usa c&c research laboratories (1993 to 1999); and head, broadband communications research, sarnoff corp. (1990 to 1992). during theperiod from 1995 to 1999, his research group at nec usa developed oneof the worldõs first precommercial broadband wireless local area networks (òwatmnetó) for use in the 5ghz band. his research and newtechnology development experience also includes vsat networks (1984to 1987), digital tv/hdtv (1988 to 1991), atm/ip switching and qos(1993 to 1997), multimedia network processor (1993 to 1995), and mimo/ofdm system (2000 to 2001). dr. raychaudhuri obtained his b.tech(hons) from the indian institute of technology, kharagpur, in 1976 andthe m.s. and ph.d degrees from suny, stony brook, in 1978 and 1979. heis a fellow of the ieee.bob rowe has been a commissioner of the montana public service commission since 1993. his educational credentials include a b.a. from lewisand clark college; a j.d. from the university of oregon; and additionalgraduate work in public administration and public policy at harvarduniversityõs kennedy school executive program. mr. rowe is a past president of the national association of regulatory utility commissioners(naruc) and a past chair of the naruc telecommunications committee. he is a member of the national regulatory research instituteõs boardof directors, the michigan state university institute of public utilitiesadvisory committee, and the new mexico state university center forbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix d317public utilities advisory council. he is also a member of the montanafood bank networkõs board of directors and a member of the state bar ofmontana professionalism committee. he is past chair of the regionaloversight committee for us west. before election to the montana publicservice commission, he was in public interest practice; was a vistavolunteer; and was a public interest lawyer, specializing in utility law andpolicy; he also worked for the montana legal service association, a private nonprofit organization, and he represented a variety of communityorganizations in rate cases and other utilityrelated proceedings. he researched and wrote on customeroriented utility policy for the nationalconsumer center, the national center for appropriate technology, andother organizations.steven s. wildman is director of the james h. and mary b. quello centerfor telecommunication management and law and the james h. quellochair of telecommunications studies at michigan state university. thecenter, and through it his chair, is endowed, supporting broadbased andaffiliationdependent research in support of policy making. previously,dr. wildman was an associate professor at northwestern university anddirector of its program in telecommunications science, management, andpolicy. his research interests include determinants of market structureand economic aspects of information and communication. he has servedas a consultant on matters relating to broadcasting, cable television, andvoice and nonvoice telecommunications. his publications include international trade in films and television programs (1988), electronic servicesnetworks: a business and public policy challenge (1991), video economics(1992), and making universal service policy: enhancing the process throughmultidisciplinary evaluation (1999). professor wildman received his ph.d.from stanford university.broadband: bringing home the bitscopyright national academy of sciences. all rights reserved.318adslasymmetric digital subscriber lineansiamerican national standards instituteasicapplication specific integrated circuitatmasynchronous transfer modeblecbuildingfocused local exchange carrierscatvoriginally community antenna television; now synonymouswith cable tvcdmacodedivision multiple accesscdpdcellular digital packet datacleccompetitive local exchange carriercocentral officecpecustomer premises equipmentdarpadefense advanced research projects agencydbsdirect broadcast satellitedhcpdynamic host configuration protocoldlcdigital loop carrierdlecdata local exchange carrierdmtdiscrete multitone transmissiondsldigital subscriber linedslamdsl access multiplexerdspdigital signal processoretsieuropean telecommunications standards institutefccfederal communications commissionfextfar end cross talkfttcfiber to the curbbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.appendix e319ftthfiber to the homegeosgeosynchronous orbit satelliteshdslhighspeed digital subscriber linehdtvhigh definition televisionhfchybrid fiber coaxhpnahome phone networking allianceieeeinstitute of electrical and electronics engineersietfinternet engineering task forceilecincumbent local exchange carrieripinternet protocolisdnintegrated services digital networkispinternet service providerituinternational telecommunication unionlanlocal area networkleclocal exchange carrierleoslow earth orbit satelliteslmdslocal multipoint distribution serviceslosline of sightmacmedium access controlmdusmultidwelling unitsmimomultiple in, multiple outmmdsmultipoint multichannel distribution servicemsomultiple system operatornextnear end cross talkniinational information infrastructurensfnational science foundationnspnative signal processorntianational telecommunications and information administrationofdmorthogonal frequency division multiplexingpcspersonal communications servicepegpublic, educational, and governmentponpassive optical networkpotsplain old telephone serviceppppointtopoint protocolpsdpower spectral densityqamquadrature amplitude modulationqosquality of serviceradslrate adaptive digital subscriber linerfradio frequencyrlpradio link protocolsdmisecure digital music initiativesdslsymmetric digital subscriber linesdtvstandard definition televisionbroadband: bringing home the bitscopyright national academy of sciences. all rights reserved.320appendix esonetsynchronous optical networktdmtime division multiplexingtdmatime division multiple accessudpuser datagram protocolusbuniversal serial busvadslveryhigh data rate asymmetric dslvdslvery high speed digital subscriber linevlsivery large scale integrated circuitvodvideo on demandvodslvoice over dslvoipvoice over internet protocolvpnvirtual private networkvtipvideo telephony over internet protocol (ip)w3cworld wide web consortiumwanwide area networkwdmwavelengthdivision multiplexingwlanwireless local area networkwllwireless local loop