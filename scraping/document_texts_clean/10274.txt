detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/10274cybersecurity today and tomorrow: pay now or pay later50 pages | 6 x 9 | paperbackisbn 9780309083126 | doi 10.17226/10274national research councilcybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.computer science and telecommunications boarddivision on engineering and physical sciencesnational research councilnational academy presswashington, d.c.pay now or pay latertodayandtomorrowcybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.national academy press¥2101 constitution avenue, n.w.¥washington, d.c. 20418notice: the projects that are the basis of this synthesis report were approved bythe governing board of the national research council, whose members are drawnfrom the councils of the national academy of sciences, the national academy ofengineering, and the institute of medicine. the members of the committees responsible for the final reports of these projects and of the board that produced thissynthesis were chosen for their special competences and with regard for appropriate balance.core support for the computer science and telecommunications board(cstb) is provided by its public and private sponsors, which include federalagencies (the air force office of scientific research, defense advanced researchprojects agency, department of energy, national aeronautics and space administration, national institute of standards and technology, national library ofmedicine, national science foundation, and the office of naval research); thevadasz family foundation; and an evolving mix of charitable corporate and individual contributions. sponsors enable but do not influence cstbõs work. anyopinions, findings, conclusions, or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the organizations or agencies that provide support for cstb.international standard book number 0309083125additional copies of this report are available from the computer science andtelecommunications board, national research council, 2101 constitution avenue, n.w., washington, dc 20418. call 2023342605 or email the cstb atcstb@nas.edu. this report is also available online at <http://www.cstb.org>.copyright 2002 by the national academy of sciences. all rights reserved.printed in the united states of americasuggested citation: computer science and telecommunications board, cybersecurity today and tomorrow: pay now or pay later, national academy press, washington, d.c., 2002.the national academies intend for this document to be disseminated as far andas widely as possible, and you are encouraged to do so. to obtain permission toreproduce, reprint, or disseminate this document or portions of it (and it is theintent of the national academies to grant such permission for noncommercialpurposes routinely and promptly), please apply in writing to dick morris, permissions manager, national academy press, by email (dmorris@nas.edu) or fax(2023342793), or phone 2023343335 for further information.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific and engineering research, dedicated to the furtherance of science and technology and to their use for the generalwelfare. upon the authority of the charter granted to it by the congress in 1863,the academy has a mandate that requires it to advise the federal government onscientific and technical matters. dr. bruce m. alberts is president of the nationalacademy of sciences.the national academy of engineering was established in 1964, under the charterof the national academy of sciences, as a parallel organization of outstandingengineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsorsengineering programs aimed at meeting national needs, encourages educationand research, and recognizes the superior achievements of engineers. dr. wm. a.wulf is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy ofsciences to secure the services of eminent members of appropriate professions inthe examination of policy matters pertaining to the health of the public. theinstitute acts under the responsibility given to the national academy of sciencesby its congressional charter to be an adviser to the federal government and, uponits own initiative, to identify issues of medical care, research, and education.dr. kenneth i. shine is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology withthe academyõs purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both the nationalacademy of sciences and the national academy of engineering in providingservices to the government, the public, and the scientific and engineering communities. the council is administered jointly by both academies and the institute ofmedicine. dr. bruce m. alberts and dr. wm. a. wulf are chairman and vicechairman, respectively, of the national research council.national academy of sciencesnational academy of engineeringinstitute of medicinenational research councilcybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.ivcomputer science and telecommunications boarddavid d. clark, massachusetts institute of technology, chairdavid borth, motorola labsjames chiddix, aol time warnerjohn m. cioffi, stanford universityelaine cohen, university of utahw. bruce croft, university of massachusetts at amherstthomas e. darcie, at&t labs researchjoseph farrell, university of california at berkeleyjeffrey m. jaffe, bell laboratories, lucent technologiesanna karlin, university of washingtonbutler w. lampson, microsoft corporationedward d. lazowska, university of washingtondavid liddle, u.s. venture partnerstom m. mitchell, carnegie mellon universitydonald norman, nielsen norman groupdavid a. patterson, university of california at berkeleyhenry (hank) perritt, chicagokent college of lawburton smith, cray inc.terry smith, university of california at santa barbaralee sproull, new york universityjeannette m. wing, carnegie mellon universitymarjory s. blumenthal, directorherbert s. lin, senior scientistalan s. inouye, senior program officerjon eisenberg, senior program officerlynette i. millett, program officercynthia patterson, program officersteven woo, program officerdavid padgham, research associatejanet briscoe, administrative officermargaret huynh, senior project assistantdavid drake, senior project assistantjanice sabuda, senior project assistantjennifer bishop, senior project assistantbrandye williams, staff assistantnote: for more information on cstb, see its web site at <http://www.cstb.org>, orwrite to cstb, national research council, 2101 constitution avenue, n.w., washington,dc 20418, call at (202) 3342605, or email the cstb at cstb@nas.edu.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.vprefacestarting with the publication of the report computers at risk: safe computing in the information age in 1991 (national academy press, washington, d.c.), the computer science and telecommunications board (cstb)has examined the issue of computer and communications security a number of times, from a number of perspectives. while there has beenprogress in security, it is a sad commentary on the state of the world thatwhat cstb wrote more than 10 years ago is still timely and relevant. forthose who work in computer security, there is a deep frustration thatresearch and recommendations do not seem to translate easily into deployment and utilization.the events of september 11, 2001, suggestñindeed demandñthat wetake a renewed look at the security and robustness of our nationõs infrastructure. now, if ever, we see the importance of having critical systemsresistant to attack and serviceable in times of crisis. from our telephonesystem to air traffic control to the internet, we will be greatly harmed ifthese systems fail us just when we need them most.the vulnerabilities are not new, only freshly brought into focus. andthe approaches that will mitigate these threats are not unknown, onlyunderutilized. so cstb has taken the approach of drawing on its pastwork to point out that much of what we need to do is available to us now,if only we choose to act.the staff of the cstb have assembled this report from the broad baseof its existing reports. herb lin deserves special thanks for the effortnecessary to produce this report quickly.david d. clark, chaircomputer science andtelecommunications boardcybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.viiacknowledgment of reviewersthis report was reviewed in draft form by individuals chosen fortheir diverse perspectives and technical expertise, in accordance with procedures approved by the national research councilõs (nrcõs) reportreview committee. the purpose of this independent review is to provide candid and critical comments that will assist the institution in making the published report as sound as possible and to ensure that the reportmeets institutional standards for objectivity, evidence, and responsiveness to the study charge. the review comments and draft manuscriptremain confidential to protect the integrity of the deliberative process.we wish to thank the following individuals for their participation in thereview of this report:steven bellovin, at&t labs research,thomas berson, anagram laboratories,john davis, mitretek systems inc.,carl landwehr, national science foundation,fred schneider, cornell university, andwillis ware, rand corporation.although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the final draft of the reportbefore its release. the review of this report was overseen by gerrydinneen. appointed by the nrcõs report review committee, he wascybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.viiiacknowledgment of reviewersresponsible for making certain that an independent examination of thisreport was carried out in accordance with institutional procedures andthat all review comments were carefully considered. responsibility forthe final content of this report rests entirely with the computer scienceand telecommunications board and the national research council.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.ixcontents1cybersecurity today and tomorrow1background and introduction, 1the nature of cyberthreats, 2causes of system and network problems, 3the harm from breaches of cybersecurity, 6what do we know about cybersecurity?, 7general observations, 7management, 8operational considerations, 10design and architectural considerations, 11what can be done?, 12individual organizations, 13vendors of computer systems, 13policy makers, 142excerpts from earlier cstb reports17computers at risk: safe computing in the information age (1991), 18the cybersecurity challenge, 18fundamentals of cybersecurity, 18the security experience: vulnerability, threat, andcountermeasure, 20the asymmetry between offense and defense, 20confidence in countermeasures, 21cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.on network vulnerabilities, 21market influences on cybersecurity, 22nontechnical dimensions of cybersecurity, 22realizing the potential of c4i: fundamental challenges (1999), 24on what a defense must do, 24on practice in the field, 31trust in cyberspace (1999), 33cybersecurity and other trustworthiness qualitiesinteract, 33on managing risk, 33vulnerabilities in the public telephone networkand the internet, 35on building secure systems and networks, 36on the impact of system homogeneity (òmonocultureó), 37what is cstb?39xcontentscybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.11cybersecurity today and tomorrowbackground and introductionin the wake of the horrific events of september 11, 2001, the nationõsattention has focused heavily on various dimensions of security. securityfor nuclear power plants, shopping malls, sports stadiums, and airports,to name just a few entities, received additional scrutiny in the weeks thatfollowed. computer and telecommunication systems, too, have receivedsignificant attention, and because the computer science and telecommunications board (cstb, described further on the final pages of this report)of the national research council (nrc) has examined various dimensions of computer and network security and vulnerability, it decided torevisit reports relevant to cybersecurity issued over the last decade. insome instances, security issues were the primary focus of a report fromthe start (see, for example, (1) computers at risk, 1991;1 (2) cryptographyõsrole in securing the information society, 1996;2 (3) for the record: protectingelectronic health information, 1997;3 and (4) trust in cyberspace, 19994). in1computer science and telecommunications board, national research council. 1991.computers at risk: safe computing in the information age. national academy press, washington, d.c.2kenneth w. dam and herbert s. lin (eds.), computer science and telecommunicationsboard, national research council. 1996. cryptographyõs role in securing the informationsociety. national academy press, washington, d.c.3computer science and telecommunications board, national research council. 1997.for the record: protecting electronic health information. national academy press, washington, d.c.4computer science and telecommunications board, national research council. 1999.trust in cyberspace. national academy press, washington, d.c.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.2cybersecurity today and tomorrowother instances, security issues emerged as a prominent element of a studyas the study unfolded (see, for example, (5) continued review of the taxsystems modernization of the internal revenue service, 1996;5 (6) realizing thepotential of c4i, 1999;6 and (7) embedded, everywhere, 20017). (hereinafter,these reports are referenced by number.)security issues continue to be an important part of cstbõs portfolio,and cstb recently held workshops that explored how to deal with theinsider threat to security (2000) and various legal issues associated withprotecting critical infrastructure (2001). though the most recent of thecomprehensive reports was issued 2 years ago and the earliest 11 yearsago, not much has changed with respect to security as it is practiced,notwithstanding further evolution of the public policy framework and anincrease in our perception of the risks involved. the unfortunate reality isthat relative to the magnitude of the threat, our ability and willingness todeal with threats have, on balance, changed for the worse (6), makingmany of the analyses, findings, and recommendations of these reports allthe more relevant, timely, and applicable today. this document presentsthe enduring findings and recommendations from that body of work, andit includes excerpts from three of the reports listed above.the nature of cyberthreatsmuch of modern life depends on computers and computer networks.for many people, the most visible interaction they have with computers istyping at the keyboard of the computer. but computers and networks arecritical for key functions such as managing and operating nuclear powerplants, dams, the electric power grid, the air traffic control system, andthe financial infrastructure. computers are also instrumental in the daytoday operations of companies, organizations, and government. companies large and small rely on computers to manage payroll, to track inventory and sales, and to perform research and development. distribution offood and energy from producer to retail consumer relies on computersand networks at every stage. nearly everyone in business or government5computer science and telecommunications board, national research council. 1996.continued review of the tax systems modernization of the internal revenue service: final report.national academy press, washington, d.c.6computer science and telecommunications board, national research council. 1999.realizing the potential of c4i: fundamental challenges. national academy press, washington,d.c.7computer science and telecommunications board, national research council. 2001.embedded, everywhere: a research agenda for networked systems of embedded computers. national academy press, washington, d.c.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.cybersecurity today and tomorrow3relies on electronic communicationsñwhether telephone, fax, email, orinstant messagesñwhich are obviously enabled by computers. many(perhaps even most) computer systems are networked in some fashiontoday (4), most visibly and commonly via the vast collection of globallyinterconnected computer networks known as the internet. a more recenttrend is toward embedding computing capability in all kinds of devicesand environments and networking embedded systems into larger systems (7). these trends make many computing and communications systems critical infrastructure in themselves and components of other kindsof critical infrastructure, from energy to transportation systems.8what can go wrong with a computer system or network?¥it can become unavailable or very slow (1,4,6). that is, using thesystem or network at all becomes impossible, or nearly so. the emaildoes not go through, or the computer simply freezes, with the result thatsomebody is unable to get his or her job done in a timely way, be itservicing a customer or reacting to a crisis.¥it can become corrupted, so that it does the wrong thing or giveswrong answers (17). for example, data stored on the computer maybecome different from what it should be, as would be the case if medicalor financial records were improperly modified. or, freight manifestsmight be altered so that the wrong material is shipped, an obvious problem for any rapid military deployment.¥it can become leaky (17). that is, someone who should not haveaccess to some or all of the information available through the networkobtains such access. for example, a spy who gains access to files stored inan intelligence agency information system may be able to view very sensitive data.causes of system and network problemswhat can cause something to go wrong in a computer system ornetwork? it is useful to distinguish between accidental causes and deliberate causes. in general, accidental causes are natural (e.g., a lightningsurge that destroys a power supply in a network that causes part of thenetwork to fail) or human but nondeliberate (e.g., an accidental program8the presidentõs commission on critical infrastructure protection included under therubric of òcritical infrastructureó telecommunications, electric power systems, gas and oilproduction and storage, banking and finance, transportation, water supply systems, government services, and emergency services. see presidentõs commission on critical infrastructure protection. 1997. critical foundations. washington, d.c.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.4cybersecurity today and tomorrowming error that causes a computer to crash under certain circumstances,or the unintended cutting of a communications cable during excavation).accidental causes figure prominently in many aspects of trustworthinessbeside security, such as safety or reliability (1,3,4,7).deliberate problems are the result of conscious human choice. in thecontext of seeking to understand the laws of physics, einstein once saidthat while nature may be subtle, it is not malicious. but in dealing withdeliberate problems, one is faced with malicious intent. a malicious human may seek to hide his or her tracks, making it difficult to identify thenature of the problem caused (or even to identify that a problem has beencaused).9 a malicious human can, in principle, tailor actions to producea desired effect beyond the damage to the actual system attackedñunlikean accidental problem whose effects are randomly determined. securityexperts often refer to the efforts of these malicious people as òattacks.ó10a central challenge in responding to an information system attack is identifying who the attacker is and distinguishing whether the motive is mischief, terrorism, or attack on the nation. a related challenge is determining whether events that are distant in time or space are relatedñparts ofa given attack (1,4,6).note also that an attackerñwho seeks to cause damage deliberatelyñmay be able to exploit a flaw accidentally introduced into a system. system design and/or implementation that is poor by accident can result inserious security problems that can be deliberately targeted in a penetration attempt by an attacker.11there are many ways to cause problems deliberately. one wayñwhich receives a great deal of attention in the mediañis through an attack9tracing attacks is generally difficult, because serious attackers are likely to launder theirconnections to the target. that is, an attacker will compromise some intermediate targetswhose vulnerabilities are easy to find and exploit, and use them to launch more seriousattacks on the ultimate intended target. this, of course, is what has happened in a numberof distributed denialofservice attacks against web servers of certain u.s. companies andgovernment agencies, in which a number of computers flooded their targets with bogusrequests for service, thus making them unavailable to provide service to legitimate users.10óattackó is a word that has seemed excessive to some (particularly because many attacks have been traced to individuals with motivation more akin to that of a joyrider than astatesupported, wellorganized attacker). recent events suggest that òattackó is increasingly appropriate, insofar as it is analogous to more familiar or conventional forms of attacks on resources of different kinds, in either the military or civilian sector.11a particularly insidious òaccidentaló problem arises because of the fact that the precisesoftware configuration on any operational system (including applications, device drivers,and system patches) has almost certainly not been tested for securityñthere are simply toomany possible configurations to test more than a small fraction explicitly. as new applications and device drivers are installed over time, an operational system is more likely toexhibit additional vulnerabilities that an attacker might exploit.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.cybersecurity today and tomorrow5that arrives òthrough the wires.ó the internet makes it possible to mountsuch an attack remotely, anonymously, and on a large scale (4). oneexample of such òcyberonlyó attacks are computer viruses that infect auserõs computer, take some destructive action such as deleting files on thenetwork or local hard drive, and propagate themselves further, such as byemailing copies of themselves. a second example is a distributed denialofservice attack, described in footnote 9.the damage that a cyberonly attack causes may not be immediately(or ever) apparent. a successful attack may lay a foundation for laterattacks, be set to cause damage well after the initial penetration, or enablethe clandestine transmission of sensitive information stored on the attacked system (1,4,6). for example, a number of recent incidents havecompromised the computers of unsuspecting home computer users byimplanting unauthorized code; these computers were subsequently usedas launch points in a coordinated and distributed denialofservice attack.finally, the fact that the internet connects many of the worldõs computers implies that a cyberonly attack can be launched from locationsaround the world, routed through other countries (perhaps clandestinelyand unknown to anyone in those other countries), and directed againstany u.s. computer on the internet. the availability of a plethora of launchpoints and routes for cyberattack greatly complicates the ability to stop anattack before it reaches the security barriers of the u.s. computers inquestion, as well as to identify its source. the internetõs various intentional or inadvertent links to other communications networks make thempotentially vulnerable to worldwide attacks as well (1,2,4,6).a cyberonly attack is only one way to cause problems in a computersystem or network. other ways include the following:¥the compromise of a trusted insider who can provide system ornetwork access to outsiders or use his or her access for improper purposes(e.g., providing passwords that permit outsiders to gain entry) (1,36).this trusted insider may be recruited covertly by hostile parties, plantedwell in advance of any action associated with an actual attack (the socalled òsleeperó problem), or tricked into taking some action that breachessystem security (e.g., tricked into disclosing a password or installing software that permits access by malicious outsiders).¥physical destruction of some key element of the system or network, such as critical data centers or communications links (4,6,7). examples of physical vulnerabilities are various backhoe incidents in whichaccidental cutting of fiberoptic cables (both primary and backup!) resulted in major network outages, and the severe damage to a verizoncentral office in the world trade center attack on september 11, 2001.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.6cybersecurity today and tomorrowit is useful to distinguish between three important concepts of cybersecurity. a vulnerability is an error or a weakness in the design, implementation, or operation of a system. a threat is an adversary that ismotivated to exploit a system vulnerability and is capable of doing so.risk refers to the likelihood that a vulnerability will be exploited, or that athreat may become harmful. in this lexicon, a system that allows computer viruses to replicate or unauthorized users to gain access exhibitsvulnerabilities. the creator of the virus or the unauthorized user is thethreat to the system. operating a system with known vulnerabilities inthe presence of possible threats entails some risk that harm or damagewill result.the harm from breaches of cybersecurityhow do potential cyberdisasters compare with disasters in the physical world? as the catastrophic events of september 11, 2001, demonstrate, disasters in the physical world can involve massive loss of life anddamage to physical infrastructure over a very short period of time. thedamage from most cyberattacks is unlikely to be manifested in such amannerñalthough interference with medical information systems anddevices could affect lives. if undertaken by themselves, cyberattacks couldcompromise systems and networks in ways that could render communications and electric power distribution difficult or impossible, disrupttransportation and shipping, disable financial transactions, and result inthe theft of large amounts of money (1,2,4). economic and associatedsocial harm is a likely consequence of a largescale cyberattack that issuccessful. that harm would involve at least opportunity costsñinterruption of business, forgoing of various activities and associated benefits,and so on.while such results would qualify on any scale as disastrous, additional harm can come from the interactions of cyber and physical systems under attack that endanger human life directly and affect physicalsafety and wellbeing (3,4,7). in particular, a largescale coordinatedcyberattack could occur at the same time as an attack on the physicalinfrastructure. for example, a successful cyberattack launched on the airtraffic control system in coordination with airliner hijackings could resultin a much more catastrophic disaster scenario than was seen on september 11, 2001. or compromising communications channels during a physical attack of that magnitude could prevent government officials fromresponding to the attack, coordinating emergency response efforts, oreven knowing whether the attack was still ongoing.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.cybersecurity today and tomorrow7what do we know about cybersecurity?with the above perspective in mind, here are some of the main messages about cybersecurity that emerge from a review of cstb reports.general observations¥in the united states, information system vulnerabilities, from thestandpoint of both operations and technology, are growing faster than thecountryõs ability (and willingness) to respond (1,2,4,6,7).¥security is expensive, not only in dollars but especially in interference with daily work (1,2,46). it has no value when there is no attack (ornatural/accidental disruption in the system environment).12 consequently, people tend to use as little of it as they think they can get awaywith. exhortations to be more careful may work for a short time, butoperational security can be maintained only by systematic and independently conducted òred teamó attacks and correction of the defects thatthey reveal. moreover, there are no widely accepted metrics for characterizing security, so it is difficult for a decision maker to know how muchsecurity a certain investment buys or whether that investment is enough.¥the overall security of a system is only as strong as its weakest link(17). system security is a holistic problem, in which technological, managerial, organizational, regulatory, economic, and social aspects interact.weaknesses in any of these aspects can be very damaging, since competent attackers seek out weak points in the security of a network or system.¥the best is the enemy of the good. risk management is an essentialelement of any realistic strategy for dealing with security issues (26).experience has demonstratedñsadlyñthat the quest for perfection is theenemy of concrete, actionable steps that can provide improved but notperfect security. it is true that given enough time and effort, almost anysecurity system can be breached. but that does not diminish the value ofsteps that can increase the difficulty of breaching security.¥security is a game of action and reaction (1,4,6). when old vulnerabilities are corrected, attackers look for new paths of attack. on the otherhand, it takes time to find those new paths, and during that time thesystem is more secure.¥systems have many potential points of vulnerability, and an attacker is free to choose any one of them. for example, as antivirus soft12more precisely, designs and architectures and implementation methods that can beused to make a system more secure are often the same as those that enhance system reliability and trustworthiness. however, specific security features often are not valuable againstnatural or accidental disruption.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.8cybersecurity today and tomorrowware came to protect against conventional viruses, virus writers exploiteda new channelñthe macro capabilities of word processorsñthat wasnever intended to provide the capability for implementing viruses. thus,security must be approached on a system level rather than on a piecemealbasis (17).¥because cyberattacks can be conducted without leaving publiclyvisible evidence (unlike, for example, a plane crash), it is easy to coverthem up (1,3,4,6). reporting of attempts, successful and unsuccessful, tobreach securityñthe where, when, and how of attacksñis essential bothfor forensics (to determine who is responsible and whether incidents indifferent places are part of the same attack) and for prevention (to defendagainst future attacks). researchers, developers, and operators need thisinformation to redesign systems and procedures to avoid future incidents, and national security and law enforcement agencies need it todefend the nation as a whole. organizations that are attacked prefer toconceal attacks, because publicity may undermine public confidence, disclose adverse information, and make managers look bad. weighing thesecosts and benefits should be a public policy issue, but so far the commercial and facesaving concerns of targets have dominated, and there is noeffective reporting. the airline industry might be a good model to copy(in the sense that both accidents and nearmisses are reported), and theinformationsharing problem is being explored in the context of criticalinfrastructure protection, a perspective that emerged in the late 1990s.management¥from an operational standpoint, cybersecurity today is far worsethan what known best practices can provide (16). even without any newsecurity technologies, much better security would be possible today iftechnology producers, operators of critical systems, and users took appropriate steps. but new technologies and new operating proceduresñwhich would require additional investment for research and developmentñcould make things even better.¥because a secure system doesnõt allow users to do any more thanan insecure system, system and network operators in the private sectorspend only as much on security as they can justify on business groundsñand this may be much less than the nation needs as a whole (1,36). (thesame is true of government agencies that must work within budget constraints, though the detailed costbenefit calculus may be different.)¥further, because serious cyberattacks are rare, the payoff from security investments is uncertain (and in many cases, it is society ratherthan any individual firm that will capture the benefit of improved security). as a result, system and network operators tend to underinvest incybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.cybersecurity today and tomorrow9security. changing market incentivesñfor example, by adjusting the liability to which business users of technology might be subject or theinsurance implications of good securityñcould have a dramatic impacton the market for security features.13¥for economic reasons, systems are generally built out of commercial offtheshelf components. these are not very secure because thereisnõt much market demand: customers buy features and performancerather than security. the failure of the u.s. governmentõs orange book14program even within the federal marketplace is a striking example. thegovernment demanded secure systems, industry produced them, andthen government agencies refused to buy them because they were slowerand less functional than other nonsecure systems available on the openmarket (1,4).15¥because security measures are disasterpreventing rather than payoffproducing, a central aspect of security must be accountability. that is,users and operators must be held responsible by management for takingall appropriate security measuresñone cannot count on financial andmarket incentives alone to drive appropriate action (1,36). many securityproblems exist not because a fix is unknown but because some responsible party has not implemented a known fix. of course, appropriatesecurity measures are not free. management must be willing to pay thecosts and must demand from vendors the tools needed to minimize thosecosts. (note that costs can include the costs of testing a fix to see if it ruinsthe production environment.) management must resolve the conflict between holding people responsible and full reporting of problems, whichtends to be easier in an environment in which individuals are not fearfulof reporting problems.13for example, under todayõs practices, a party that makes investments to prevent itsown facilities from being used as part of a distributed denialofservice (ddos) attack willreap essentially no benefits from such investments, because such an attack is most likely tobe launched against a different party. but todayõs internetusing society would clearlybenefit if many firms made such investments. making parties liable for not securing theirfacilities against being illicitly used as part of a ddos attack (today there is zero liability)would change the incentives for making such investments. in a current project on criticalinfrastructure protection and the law, cstb is exploring this issue (among others) in greaterdepth.14òthe orange bookó is the nickname for the trusted computer system evaluation criteria, which were intended to guide commercial system production generally and therebyimprove the security of systems in use.15it did not help that systems compliant with orange book criteria also came later tomarket and often had less functionality (e.g., in some cases, a certified system was unable toconnect to a network, because a network connection was not part of the certified configuration).cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.10cybersecurity today and tomorrowoperational considerations¥to promote accountability, frequent and unannounced penetration testing (socalled redteaming) is essential to understand the actualoperational vulnerabilities of deployed systems and networks (6). noother method is as effective at pointing to security problems that must besolved. information about vulnerabilities thus gathered must be madeavailable to those who are in a position to fix themñor to upper management, who can force them to be fixed. note that effective redteaming isundertaken independently of the system or network being testedñthosebeing tested must not know when the test will occur or what aspects ofsecurity will be tested, while those doing the testing must be technicallysavvy and not constrained by operating orders that limit what they arepermitted to do.¥many compromises of an information system or network resultfrom improper configuration (1,3,4,6). for example, a given system on anetwork may have a modem attached to it that is not known to the network administrator, even if it was attached by a legitimate user for legitimate purposes. an installed operating system on a computer may lackcritical òbugó fixes, because they were not applied or because the systemwas restored from a backup tape that did not include those fixes. asystem firewall may be improperly configured in a way that allows webaccess when, in fact, the system should only be able to transmit and receive email. or, a group of users may be given privileges that should, infact, be restricted to one member of that group. because checking operational configurations is very laborintensive if done manually, it is essential to have configuration management tools for both systems and networks that can automatically enforce a desired configuration or alertadministrators when variances from the known configuration are detected. such tools are miserably inadequate today. building them doesnot require research, but it does require a considerable amount of carefulengineering.¥since perfect security is impossible, secure configurations need tobe updated when new attacks are discovered. these updates need to bedelivered automatically to millions of systems (4,7).16¥organizations must have concrete fallback action plans that instruct users and administrators about what they should do under condi16on the other hand, there is a nontrivial chance that updates will diminish existing andneeded functionality, and people are sometimes reluctant to apply updates because theyare reluctant to instigate system instability. thus, the trustworthiness of the updates themselves, as well as the updating process, becomes an issue of concern.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.cybersecurity today and tomorrow11tions of cyberattack (6). admonitions to òbe more carefuló are not actionable, especially since the effects of a cyberattack may not be obvious, norwill they be constant over time. instead, the tradeoffs between vulnerability and functionality must be understood, and appropriate responsesto attacks must be defined. usually these responses involve making thesystems do less in order to make them less vulnerable: fewer authorizedusers, less software running, and less communication between systems.for example, software architects might design a system so that operatorscould close off certain routes of access to it when under attack, therebylosing the useful functionality associated with those routes but preserving critical functions that do not need those routes.design and architectural considerations¥there are often tensions between security and other good things,such as features, ease of use, and interoperability (1,3,4,6). for example, ifusers have different passwords for different systems, it is harder for anunauthorized party to gain access to all of those systems, but users mustbear the burden of remembering multiple passwords. because the benefits of successful security can be seen only in events that usually do nothappen, resources devoted to security are òwastedó in the same sense thatresources devoted to insurance are òwasted.ó in both cases, the systemuser (or the insured party) does not gain additional functionality as theresult of its expenditures. but that does not make investments in securityworthlessñrather, it changes the terms on which such investments shouldbe evaluated, which include the value of being able to continue operationin the face of hostile attacks (and often natural or accidental disruptionsas well).17¥human error is usually not a useful explanation for security problems. usually either operational or management practice is at fault: operational practice that requires people to get too many details right or thatdoes too little redteam testing, and management practice that allows toolittle time for security procedures or fails to ensure that problems uncovered by testing are fixed (1,35).¥while cryptography is not a magic bullet for security problems, it17note that one fundamental difference between risks in the physical world and risks incyberspace is the existence of an extensive actuarial database for the former that enablesorganizations to assess the payoff from investments to deal with those risks. by comparison, operations in cyberspace are new and continually evolving, and risks in cyberspace arenot well understood by the insurance industry. that industry has recently increased itsactivity in this domain, but progress has been slow.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.12cybersecurity today and tomorrowdoes play key roles in system and network security. cryptography hasthree primary uses: authentication, integrity checks, and confidentiality(1,2,4). cryptographic authentication is an important aspect of securitytechniques that deny access or system privileges to unauthorized users.cryptographic integrity checks ensure that data cannot be modified without revealing the fact of modification. cryptographic confidentiality canbe used to keep unauthorized parties from reading data stored in systemsand sent over networks. of course, adversaries can also use cryptography, to the detriment of certain national security and law enforcementpurposes, but its widespread use can promote and enhance crime prevention and national security efforts as well.¥user authentication is essential for access control and for auditing(16). the most common method used today to authenticate users ispasswords, which are known to be insecure compared with other authentication methods. a hardware token (e.g., smart card), supplemented bya personal identification number or biometrics (assuming good implementation), is much better. the user doesnõt have to keep track of passwords, and a lost token is physically obvious and cannot be broadcast toa myriad of unauthorized parties (but the user does have to remember tobring the token to the computer access point).¥a common approach to network security is to surround an insecure network with a defensive perimeter that controls access to the network (1,4,6). once past the perimeter, a user is left unconstrained. aperimeter defense is good as part of a defense in depth, especially becausethe security burden is placed primarily on those who manage the perimeter rather than those who manage systems inside the perimeter. however, it is entirely vulnerable if a hostile party gains access to a systeminside the perimeter or compromises a single authorized user. anotherapproach to network security is mutual suspicion: every system within acritical network regards every other system as a potential source of threat.thus, a hostile party who gains access to one system does not automatically gain access to the whole network. mutual suspicion can providesignificantly higher levels of security, but it requires all system operatorsto pay attention to security rather than just those at the network perimeter. perimeter defense and mutual suspicion can be used together toincrease network security.what can be done?it is helpful to distinguish among actions that can be taken by individual organizations, by vendors, and by makers of public policy. however, the best results for cybersecurity will be obtained through actions byall parties.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.cybersecurity today and tomorrow13individual organizationsindividual organizations should:¥establish and provide adequate resources to an internal entity withresponsibility for providing direct defensive operational support to system administrators throughout the organization (3,5,6). to serve as thefocal point for operational change, such an entity must have the authorityñas well as a person in chargeñto force corrective action.¥ensure that adequate information security tools are available, thateveryone is properly trained in their use, and that enough time is available to use them properly. then hold all personnel accountable for theirinformation system security practices (3,5,6).¥conduct frequent, unannounced redteam penetration testing ofdeployed systems and report the results to responsible management (6).¥promptly fix problems and vulnerabilities that are known or thatare discovered to exist (3,5,6).¥mandate the organizationwide use of currently available network/configuration management tools, and demand better tools fromvendors (3,5,6).¥mandate the use of strong authentication mechanisms to protectsensitive or critical information and systems (3,5,6).¥use defense in depth. in particular, design systems under theassumption that they will be connected to a compromised network or anetwork that is under attack, and practice operating these systems underthis assumption (1,4,6).¥define a fallback plan for more secure operation when under attack and rehearse it regularly. complement that plan with a disasterrecovery program (1,6).vendors of computer systemsvendors of computer systems should:¥drastically improve the user interface to security, which is totallyincomprehensible in nearly all of todayõs systems (1,4,6). users and administrators must be able to easily see the current security state of theirsystems; this means that the state must be expressible in simple terms.¥develop tools to monitor systems automatically for consistencywith defined secure configurations, and enforce these configurations (1,4,6,7). extensive automation is essential to reduce the amount of humanlabor that goes into security. the tools must promptly and automaticallyrespond to changes that result from new attacks.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.14cybersecurity today and tomorrow¥provide wellengineered schemes for user authentication based onhardware tokens (3,4,6). these systems should be both more secure andmore convenient for users than are current password systems.¥develop a few simple and clear blueprints for secure operationthat users can follow, since most organizations lack the expertise to dothis properly on their own. for example, systems should be shipped withsecurity features turned on, so that a conscious effort is needed to disablethem, and with default identifications and passwords turned off, so that aconscious effort is needed to select them (1,3).¥strengthen software development processes and conduct more rigorous testing of software and systems for security flaws, doing so beforereleasing products rather than use customers as implicit beta testers toshake out security flaws (4).18 changing this mindset is one necessaryelement of an improved cybersecurity posture.policy makerspolicy makers should:¥consider legislative responses to the failure of existing incentivesto cause the market to respond adequately to the security challenge. possible options include steps that would increase the exposure of softwareand system vendors and system operators to liability for system breachesand mandated reporting of security breaches that could threaten criticalsocietal functions (1).¥position the federal government as a leader in technology use andpractice by requiring agencies to adhere to the practices recommendedabove and to report on their progress in implementing those measures(1,2,5).19 such a step would also help to grow the market for securitytechnology, training, and other services.¥provide adequate support for research and development on information systems security (1,4,7). research and development on informa18note that securityspecific testing of software goes beyond looking at flaws that emergein the course of ordinary usage in an internetconnected production environment. forexample, securityspecific testing may involve very sophisticated attacks that are not widelyknown in the broader internet hacker community.19this concept has been implicit in a series of laws, beginning with the computer security act of 1987, and administrative guidance (e.g., from the office of management andbudget and more recently from the federal chief information officers council). althoughit has been an elusive goal, movements toward egovernment have provided practical,legal, and administrative impetus.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.cybersecurity today and tomorrow15tion systems security should be construed broadly to include r&d ondefensive technology (including both underlying technologies and architectural issues), organizational and sociological dimensions of such security, forensic and recovery tools, and best policies and practices. giventhe failure of the market to address security challenges adequately, government support for such research is especially important.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.172excerpts from earlier cstb reportsthis chapter contains excerpts from three cstb reports: computers atrisk (1991), realizing the potential of c4i (1999), and trust in cyberspace(1999). while this synthesis report is based on all of the references infootnotes 17 (chapter 1), the excerpts from these three reports are themost general and broad. to keep this report to a reasonable length, nothing was excerpted from the other four reports. readers are encouraged toread all of these reports, which can be found online at <http://www.nap.edu>. for the sake of simplicity and organizational clarity,footnotes appearing in the original text have been omitted from the reprinted material that follows. a gray bar in the margin, rather than indentation, is used to indicate extracted text. subsection heads have beenadded to show the topics addressed.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.18cybersecurity today and tomorrowcomputers at risk:safe computing in the information age (1991)citation: computer science and telecommunications board (cstb),national research council. 1991. computers at risk: safe computing in theinformation age. national academy press, washington, d.c.the cybersecurity challenge(from pp. 78): we are at risk. increasingly, america depends oncomputers. they control power delivery, communications, aviation, andfinancial services. they are used to store vital information, from medicalrecords to business plans to criminal records. although we trust them,they are vulnerableñto the effects of poor design and insufficient qualitycontrol, to accident, and perhaps most alarmingly, to deliberate attack.the modern thief can steal more with a computer than with a gun.tomorrowõs terrorist may be able to do more damage with a keyboardthan with a bomb.to date, we have been remarkably lucky. yes, there has been theft ofmoney and information, although how much has been stolen is impossible to know. yes, lives have been lost because of computer errors. yes,computer failures have disrupted communication and financial systems.but, as far as we can tell, there has been no successful systematic attemptto subvert any of our critical computing systems. unfortunately, there isreason to believe that our luck will soon run out. thus far we have reliedon the absence of malicious people who are both capable and motivated.we can no longer do so. we must instead attempt to build computersystems that are secure and trustworthy.. . .[t]he degree to which a computer system and the information itholds can be protected and preserved . . . , which is referred to here ascomputer security, is a broad concept; security can be compromised bybad system design, imperfect implementation, weak administration ofprocedures, or through accidents, which can facilitate attacks. of course,if we are to trust our systems, they must survive accidents as well asattack. security supports overall trustworthiness, and vice versa.fundamentals of cybersecurity(from p. 2): security refers to protection against unwanted disclosure, modification, or destruction of data in a system and also to thesafeguarding of systems themselves. security, safety, and reliability together are elements of system trustworthinessñwhich inspires the confidence that a system will do what it is expected to do.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports19(from pp. 4950): organizations and people that use computers candescribe their needs for information security and trust in systems in termsof three major requirements:¥confidentiality: controlling who gets to read information;¥integrity: assuring that information and programs are changedonly in a specified and authorized manner; and¥availability: assuring that authorized users have continued accessto information and resources.these three requirements may be emphasized differently in variousapplications. for a national defense system, the chief concern may beensuring the confidentiality of classified information, whereas a fundstransfer system may require strong integrity controls. the requirementsfor applications that are connected to external systems will differ fromthose for applications without such interconnection. thus the specificrequirements and controls for information security can vary.the framework within which an organization strives to meet its needsfor information security is codified as security policy. a security policy isa concise statement, by those responsible for a system (e.g., senior management), of information values, protection responsibilities, and organizational commitment. one can implement that policy by taking specificactions guided by management control principles and utilizing specificsecurity standards, procedures, and mechanisms. conversely, the selection of standards, procedures, and mechanisms should be guided bypolicy to be most effective.to be useful, a security policy must not only state the security need(e.g., for confidentialityñthat data shall be disclosed only to authorizedindividuals), but also address the range of circumstances under whichthat need must be met and the associated operating standards. withoutthis second part, a security policy is so general as to be useless (althoughthe second part may be realized through procedures and standards set toimplement the policy). in any particular circumstance, some threats aremore probable than others, and a prudent policy setter must assess thethreats, assign a level of concern to each, and state a policy in terms ofwhich threats are to be resisted. for example, until recently most policiesfor security did not require that security needs be met in the face of a virusattack, because that form of attack was uncommon and not widely understood. as viruses have escalated from a hypothetical to a commonplacethreat, it has become necessary to rethink such policies in regard to methods of distribution and acquisition of software. implicit in this process ismanagementõs choice of a level of residual risk that it will live with, alevel that varies among organizations.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.20cybersecurity today and tomorrowthe security experience: vulnerability, threat, and countermeasure(from pp. 1314): the field of security has its own language and modeof thought, which focus on the processes of attack and on preventing,detecting, and recovering from attacks. in practice, similar thinking isaccorded to the possibility of accidents that, like attacks, could result indisclosure, modification, or destruction of information or systems or adelay in system use. security is traditionally discussed in terms of vulnerabilities, threats, and countermeasures. a vulnerability is an aspect ofsome system that leaves it open to attack. a threat is a hostile party withthe potential to exploit that vulnerability and cause damage. a countermeasure or safeguard is an added step or improved design that eliminates the vulnerability and renders the threat impotent.a safe containing valuables, for example, may have a noisy combination lockña vulnerabilityñwhose clicking can be recorded and analyzedto recover the combination. it is surmised that safecrackers can makecontact with experts in illegal eavesdroppingña threat. a policy is therefore instituted that recordings of random clicking must be played at loudvolume when the safe is openedña countermeasure.threats and countermeasures interact in intricate and often counterintuitive ways: a threat leads to a countermeasure, and the countermeasure spawns a new threat. few countermeasures are so effective that theyactually eliminate a threat. new means of attack are devised (e.g., computerized signal processing to separate òliveó clicks from recorded ones),and the result is a more sophisticated threat.the asymmetry between offense and defense(from p. 14): the interaction of threat and countermeasure poses distinctive problems for security specialists: the attacker must find but oneof possibly multiple vulnerabilities in order to succeed; the security specialist must develop countermeasures for all. the advantage is thereforeheavily to the attacker until very late in the mutual evolution of threat andcountermeasure.if one waits until a threat is manifest through a successful attack, thensignificant damage can be done before an effective countermeasure can bedeveloped and deployed. therefore countermeasure engineering mustbe based on speculation. effort may be expended in countering attacksthat are never attempted. the need to speculate and to budget resourcesfor countermeasures also implies a need to understand what it is thatshould be protected, and why; such understanding should drive thechoice of a protection strategy and countermeasures. this thinking shouldbe captured in security policies generated by management; poor securityoften reflects both weak policy and inadequate forethought.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports21confidence in countermeasures(from p. 15): confidence in countermeasures is generally achieved bysubmitting them for evaluation by an independent team; this processincreases the lead times and costs of producing secure systems. theexistence of a successful attack can be demonstrated by an experiment,but the adequacy of a set of countermeasures cannot. security specialistsmust resort to analysis, yet mathematical proofs in the face of constantlychanging systems are impossible.in practice, the effectiveness of a countermeasure often depends onhow it is used; the best safe in the world is worthless if no one remembersto close the door. the possibility of legitimate users being hoodwinkedinto doing what an attacker cannot do for himself cautions against placing too much faith in purely technological countermeasures.the evolution of countermeasures is a dynamic process. securityrequires ongoing attention and planning, because yesterdayõs safeguardsmay not be effective tomorrow, or even today.on network vulnerabilities(from p. 17): interconnection gives an almost ecological flavor to security; it creates dependencies that can harm as well as benefit the community of those who are interconnected. an analogy can be made topollution: the pollution generated as a byproduct of legitimate activitycauses damage external to the polluter. a recognized public interest ineliminating the damage may compel the installation of pollution controlequipment for the benefit of the community, although the installationmay not be justified by the narrow selfinterest of the polluter. just asaverage citizens have only a limited technical understanding of their vulnerability to pollution, so also individuals and organizations today havelittle understanding of the extent to which their computer systems are putat risk by those systems to which they are connected, or vice versa. thepublic interest in the safety of networks may require some assurancesabout the quality of security as a prerequisite for some kinds of networkconnection.(from p. 8): the threats to u.s. computer systems are international,and sometimes also political. the international nature of military andintelligence threats has always been recognized and addressed by theu.s. government. but a broader international threat to u.s. informationresources is emerging with the proliferation of international computernetworkingñinvolving systems for researchers, companies, and otherorganizations and individualsñand a shift from conventional militarycybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.22cybersecurity today and tomorrowconflict to economic competition. the concentration of information andeconomic activity in computer systems makes those systems an attractivetarget to hostile entities. this prospect raises questions about the intersection of economic and national security interests and the design of appropriate security strategies for the public and private sectors. finally, politically motivated attacks may also target a new class of system that isneither commercial nor military: computerized voting systems.market influences on cybersecurity(from pp. 159161): even the best product will not be sold if theconsumer does not see a need for it. consumer awareness and willingness to pay are limited because people simply do not know enough aboutthe likelihood or the consequences of attacks on computer systems orabout more benign factors that can result in system failure or compromise. consumer appreciation of system quality focuses on features thataffect normal operationsñspeed, ease of use, functionality, and so on.this situation feeds a market for inappropriate or incomplete securitysolutions, such as antiviral software that is effective only against certainviruses but may be believed to provide broader protection, or passwordidentification systems that are easily subverted in ordinary use. . . .enhancing security requires changes in attitudes and behavior thatare difficult because most people consider computer security to be abstract and concerned more with hypothetical rather than likely events.very few individuals not professionally concerned with security, fromtop management through the lowestlevel employee, have ever been directly involved in or affected by a computer security incident. such incidents are reported infrequently, and then often in specialized media, andthey are comprehensible only in broadest outline. further, most peoplehave difficulty relating to the intricacies of malicious computer actions.yet it is understood that installing computer security safeguards has negative aspects such as added cost, diminished performance (e.g., slowerresponse times), inconvenience in use, and the awkwardness of monitoring and enforcement, not to mention objections from the work force toany of the above. the internet worm experience showed that even individuals and organizations that understand the threats may not act toprotect against them.nontechnical dimensions of cybersecurity(from p. 17): computer security does not stop or start at the computer. it is not a single feature, like memory size, nor can it be guaranteedby a single feature or even a set of features. it comprises at a minimumcybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports23computer hardware, software, networks, and other equipment to whichthe computers are connected, facilities in which the computer is housed,and persons who use or otherwise come into contact with the computer.serious security exposures may result from any weak technical or humanlink in the entire complex. for this reason, security is only partly a technical problem: it has significant procedural, administrative, physical facility, and personnel components as well.(from pp. 5051): technical measures alone cannot prevent violations of the trust people place in individuals, violations that have been thesource of much of the computer security problem in industry to date . . . .technical measures may prevent people from doing unauthorized thingsbut cannot prevent them from doing things that their job functions entitlethem to do. thus, to prevent violations of trust rather than just repair thedamage that results, one must depend primarily on human awareness ofwhat other human beings in an organization are doing. but even a technically sound system with informed and watchful management and userscannot be free of all possible vulnerabilities. the residual risk must bemanaged by auditing, backup, and recovery procedures supported bygeneral alertness and creative responses. moreover, an organization musthave administrative procedures in place to bring peculiar actions to theattention of someone who can legitimately inquire into the appropriateness of such actions, and that person must actually make the inquiry. inmany organizations, these administrative provisions are far less satisfactory than are the technical provisions for security.(from p. 10): it is important to balance technical and nontechnicalapproaches to enhancing system security and trust. accordingly, thecommittee is concerned that the development of legislation and case lawis being outpaced by the growth of technology and changes in our society.in particular, although law can be used to encourage good practice, it isdifficult to match law to the circumstances of computer system use. nevertheless, attacks on computer and communication systems are coming tobe seen as punishable and often criminal acts . . . within countries, andthere is a movement toward international coordination of investigationand prosecution. however, there is by no means a consensus about whatuses of computers are legitimate and socially acceptable. free speechquestions have been raised in connection with recent criminal investigations into dissemination of certain computerrelated information. thereare also controversies surrounding the privacy impacts of new and proposed computer systems, including some proposed security safeguards.disagreement on these fundamental questions exists not only within society at large but also within the community of computer specialists.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.24cybersecurity today and tomorrow realizing the potential of c4i:fundamental challenges (1999)citation: computer science and telecommunications board (cstb),national research council. 1999. realizing the potential of c4i: fundamental challenges. national academy press, washington, d.c.c4i is a department of defense (dod) acronym for command, control, communications, computers, and intelligence. while many of theinformation systems described in realizing the potential of c4i: fundamental challenges are owned or operated by the department of defense, essentially all of the implications and lessons for dod systems are valid fornondod government systems, and for systems in the private sector.20furthermore, the description of dod practices in the field should not betaken as an exoneration of practices in nondod systemsñindeed, it ishighly likely that the same observations would apply to most such systems.on what a defense must do(from pp. 144152): effective information systems security is basedon a number of functions described below. this list of functions is notcomplete; nevertheless, evidence that all these functions are being performed in an effective and coordinated fashion will be evidence that information systems security is being taken seriously and conducted effectively.20in 1991, computers at risk (at pp. 1819) cast this point in the following terms:there has been much debate about the difference between military and commercial needs in the security area. . . . this distinction is both superficial andmisleading. national security activities, such as military operations, rely heavilyon the integrity of data in such contexts as intelligence reports, targeting information, and command and control systems, as well as in more mundane applications such as payroll systems. private sector organizations are concerned aboutprotecting the confidentiality of merger and divestiture plans, personnel data,trade secrets, sales and marketing data and plans, and so on. thus there aremany common needs in the defense and civilian worlds.commonalities are especially strong when one compares the military to whatcould be called infrastructural industriesñbanking, the telephone system, powergeneration and distribution, airline scheduling and maintenance, and securitiesand commodities exchanges. such industries both rely on computers and havestrong security programs because of the linkage between security and reliability.nonsecure systems are also potentially unreliable systems, and unreliability isanathema to infrastructure.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports25some of these functions were also noted in the military context by thedefense science board, and some by the presidentõs commission on critical infrastructure protection in its report. these functions are listed herebecause they are important, and because the committee believes that theyhave not yet been addressed by the dod in an effective fashion (as described in the committeeõs findings below).function 1. collect, analyze, and disseminate strategic intelligence aboutthreats to systems.any good defense attempts to learn as much as possible about thethreats that it may face, both the tools that an adversary may use and theidentity and motivations of likely attackers. in the information systemssecurity world, it is difficult to collect information about attackers (thoughsuch intelligence information should be sought). it is, however, mucheasier to collect and analyze information on technical and proceduralvulnerabilities, to characterize both the nature of these vulnerabilities andtheir frequency at different installations. dissemination of informationabout these vulnerabilities enables administrators of the information systems that may be affected to take remedial action.function 2. monitor indications and warnings.all defensesñphysical and cyberñrely to some extent on indicationsand warning of impending attack. the reason is that if it is known thatattack is impending, the defense can take actions to reduce its vulnerability and to increase the effectiveness of its response. this function calls for:¥monitoring of threat indicators. for example, nearsimultaneous penetration attempts on hundreds of military information systems might reasonably be considered an indication of an orchestrated attack. mobilization of a foreign nationõs key personnel known to have responsibility forinformation attacks might be another indicator. the notion of an òinformation conditionó or òinfocon,ó analogous to the defense condition(defcon) indicator, would be a useful summary device to indicate tocommanders the state of the cyberthreat at any given time. this conceptis being developed by various dod elements but is yet immature.¥assessment and characterization of the information attack (if any).knowledge of the techniques used in an attack on one information systemmay facilitate a judgment of the seriousness of the attack. for example, anattack that involves techniques that are not widely known may indicatethat the perpetrators have a high degree of technical sophistication.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.26cybersecurity today and tomorrow¥dissemination of information about the target(s) of threat. knowledgeof the techniques used in an attack on one information system may enableadministrators responsible for other systems to take preventive actionstailored to that type of attack. this is true even if the first attack is unsuccessful, because security features that may have thwarted the first attackmay not necessarily be installed or operational on other systems.note that dissemination of information about attacks and their targets is required on two distinct time scales. the first time scale is secondsor minutes after the attack is known; such knowledge enables operatorsof other systems not (yet) under attack to take immediate preventiveaction (such as severing some network connections). in this instance,alternative means of secure communication may be necessary to disseminate such information. the second time scale is days after the attack isunderstood; such knowledge allows operators throughout the entire system of systems to implement fixes and patches that they may not yet havefixed, and to request fixes that are needed but not yet developed. . . .function 3. be able to identify intruders.electronic intruders into a system are admittedly hard to identify.attacks are conducted remotely, and a chain of linkages from theattackerõs system to an intermediate node to another and another to theattacked system can easily obscure the identity of the intruder. nevertheless, certain types of informationñif collectedñmay shed some light onthe intruderõs identity. for example, some attackers may preferentiallyuse certain tools or techniques (e.g., the same dictionary to test for passwords), or use certain sites to gain access. attacks that go on over anextended period of time may provide further opportunities to trace theorigin of the attack.function 4. test for security weaknesses in fielded and operational systems.an essential part of a security program is searching for technical andoperational or procedural vulnerabilities. ongoing tests (conducted bygroups often known as òred teamsó or òtiger teamsó) are essential forseveral reasons:¥recognized vulnerabilities are not always corrected, and knownfixes are frequently found not to have been applied as a result of poorconfiguration management.¥security features are often turned off in an effort to improve operational efficiency. such actions may improve operational efficiency, but atcybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports27the potentially high cost of compromising security, sometimes with theprimary damage occurring in some distant part of the system.¥some security measures rely on procedural measures and thusdepend on proper training and ongoing vigilance on the part of commanders and system managers.¥security flaws that are not apparent to the defender undergoing aninspection may be uncovered by a committed attacker (as they would beuncovered in an actual attack).thus, it is essential to use available tools and conduct red team ortiger team probes often and without warning to test security defenses. inorder to maximize the impact of these tests, reports should be disseminated widely. release of such information may risk embarrassment ofcertain parties or possible release of information that can be used byadversaries to attack, but especially in the case of vulnerabilities uncovered for which fixes are available, the benefits of releasing such informationñallowing others to learn from it and motivating fixes to be installedñoutweigh these costs.tiger team attacks launched without the knowledge of the attackedsystems also allow estimates to be made of the frequency of attacks. specifically, the fraction of tiger team attacks that are detected is a reasonableestimate of the fraction of adversary attacks that are made. thus, thefrequency of adversary attacks can be estimated from the number of adversary attacks that are detected.function 5. plan a range of responses.any organization relying on information systems should have a number of routine information systems security activities (e.g., security features that are turned on, security procedures that are followed). butwhen attack is imminent (or in process), an organization could prudentlyadopt additional security measures that during times of nonattack mightnot be in effect because of their negative impact on operations. tailoringin advance a range of information systems security actions to be takenunder different threat conditions would help an organization plan itsresponse to any given attack.for example, a common response under attack is to drop nonessential functions from a system connected to the network so as to reduce thenumber of routes for penetration. a determination in advance of whatfunctions count as nonessential and under what circumstances such adetermination is valid would help facilitate an orderly transition to different threat conditions, and would be much better than an approach thatcalls for dropping all functionality and restoring only those functions thatcybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.28cybersecurity today and tomorrowpeople using the system at the time complain about losing. note thatsuch determinations can be made only from an operational perspectiverather than a technical one, a fact that points to the essential need for anoperational architecture in the design of c4i systems.the principle underlying response planning should be that of ògraceful degradationó; that is, the system or network should lose functionalitygradually, as a function of the severity of the attack compared to its abilityto defend against it. this principle stands in contrast to a different principle that might call for the maintenance of all functionality until theattack simply overwhelms the defense and the system or network collapses. the latter principle is tempting because reductions in functionality necessitated for security reasons may interfere with operational easeof use, but its adoption risks catastrophic failure.it is particularly important to note that designing a system for graceful degradation depends on system architects who take into account theneeds of security (and more generally, the needs of coping with possiblecomponent failures) from the start. for example, the principle of gracefuldegradation would forbid a system whose continued operation dependedentirely on a single component remaining functional, or on the absence ofa security threat.this principle is often violated in the development of prototypes. it isoften said that òit is necessary for one to crawl before one can run,ó i.e.,that it is acceptable to ignore security or reliability considerations whenone is attempting to demonstrate the feasibility of a particular concept.this argument is superficially plausible, but in practice it does not holdwater. it is reasonable for a prototype to focus only on concept feasibility,ignoring considerations of reliability or security, only if the prototype willbe thrown away and a new architecture is designed and developed fromscratch to implement the concept. budget and schedule constraints usually prevent such new beginnings, and so in practice the prototypeõs architecture is never abandoned, and security or reliability considerationsmust be addressed in the face of an architecture that was never designedor intended to support them.function 6. coordinate defensive activities throughout the enterprise.any large, distributed organization has many information systemsand subnetworks that must be defended. the activities taken to defendeach of these systems and networks must be coordinated because thedistributed parts have interconnections and the security of the wholeorganization depends on the weakest link. furthermore, it is importantfor different parts of organizations to be able to learn from each otherabout vulnerabilities, threats, and effective countermeasures.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports29function 7. ensure the adequacy, availability, and functioning of publicinfrastructure used in systems (a step that will require cooperation withcommercial providers and civilian authorities).few networks are built entirely using systems controlled by the organization that relies on them. therefore organizations (including dod)are required to work cooperatively with the owners of the infrastructurethey rely on and relevant authorities to protect them.function 8. include security requirements in any specification of system ornetwork requirements that is used in the acquisition process.providing information systems security for a network or system thathas not had security features built into it is enormously problematic. retrofits of security features into systems not designed for security invariably leave security holes, and procedural fixes for inherent technical vulnerabilities only go so far.perhaps more importantly, security requirements must be givenprominence from the beginning in any system conceptualization. thereason is that security considerations may affect the design of a system inquite fundamental ways, and a designer who decides on a design thatworks against security should at least be cognizant of the implications ofsuch a choice. this function thus calls for information systems securityexpertise to be integrally represented on design teams, rather than addedlater.note that specification of the òorange bookó security criteria wouldbe an insufficient response to this function. òorange bookó criteria typically drive up development times significantly, and more importantly,are not inherently part of an initial requirements process and do not address the security of networked or distributed systems.function 9. monitor, assess, and understand offensive and defensiveinformation technologies.good information systems security requires an understanding of thetypes of threats and defenses that might be relevant. thus, those responsible for information systems security need a vigorous ongoing programto monitor, assess, and understand offensive and defensive informationtechnologies. such a program would address the technical details ofthese technologies, their capability to threaten or protect friendly systems,and their availability.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.30cybersecurity today and tomorrowfunction 10. advance the state of the art in defensive information technology(and processes) with research.although much can usually be done to improve information systemssecurity simply through the use of known and available technologies,òbug fixes,ó and procedures, better tools to support the information systems security mission are always needed. in general, such improvementsfall into two classes (which may overlap). one class consists of improvements so that tools can deal more effectively with a broader threat spectrum. a second class, equally important, provides tools that providebetter automation and thus can solve problems at lower costs (costs thatinclude direct outlays for personnel and equipment and operational burdens resulting from the hassle imposed by providing security).similar considerations apply to processes for security as well. it isreasonable to conduct organizational research into better processes andorganizations that provide more effective support against informationattacks and/or reduce the impediments to using or implementing goodsecurity practices.function 11. promote information systems security awareness.just as it is dangerous to rely on a defensive system or network architecture that is hard on the outside and soft on the inside, it is also dangerous if any member of an organization fails to take information systemssecurity seriously. because the carelessness of a single individual canseriously compromise the security of an entire organization, educationand training for information systems security must be required for allmembers of the organization. moreover, such education and trainingmust be systematic, regarded as important by the organization (and demonstrated with proper support for such education and training), and undertaken on a regular basis (both to remind people of its importance andto update their knowledge in light of new developments in the area).function 12. set security standards (both technical and procedural).security standards should articulate in welldefined and actionableterms what an organization expects to do in the area of security. they aretherefore prescriptive. for example, a technical standard might be òallpasswords must be eight or more characters long, contain both letters andnumbers, be pronounceable, and not be contained in any dictionary,ó oròall electronic communications containing classified information must beencrypted with a certain algorithm and key length.ó a standard involving both technical and procedural measures might specify how to revokecybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports31cryptographic keys known to have been compromised. furthermore,security standards should be expected to apply to all those within theorganization. (for example, generals should not be allowed to exercisepoorer information systems security discipline than do captains, as theymight be tempted to do in order to make their use of c4i systems easier.)function 13. develop and use criteria for assessing security status.information security is not a oneshot problem, but a continuing one.threats, technology, and organizations are constantly changing in a spiralof measures and countermeasures. organizations must have ways ofmeasuring and evaluating whether they have effective defensive measures in place. thus, once standards are put in place, the organizationmust periodically assess the extent to which members of the organizationcomply with those standards, and characterize the nature of the compliance that does exist.metrics for security could include number of attacks of different types,fraction of attacks detected, fraction of attacks repelled, damage incurred,and time needed to detect and respond to attacks. note that makingmeasurements on such parameters depends on understanding the attacksthat do occurñbecause many attacks are not detected today, continualpenetration testing is required to establish such a baseline.on practice in the field(from pp. 156157): . . .the security in todayõs fielded military systems is weak, and weaker than it need be, as illustrated by the followingexamples of behavior and practices that the committee observed or heard:¥individual nodes are running commercial software with manyknown security problems. operators use little in the way of tools forfinding these problems, to say nothing of fixing them.¥computers attached to sensitive command and control systems arealso used by personnel to surf web sites worldwide, raising the possibility that rogue applets and the like could be introduced into the system.¥units are being blinded by denialofservice attacks, made possiblebecause individual nodes were running commercial software with manyknown security problems.¥ip addresses and other important data about c2 [command andcontrol] systems can be found on postit notes attached to computers inunsecured areas, making denial of service and other attacks much easier.¥some of the networks used by dod to carry classified informationare protected by a perimeter defense. as a result, they exhibit all of thecybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.32cybersecurity today and tomorrowvulnerabilities that characterize networks protected by perimeterdefenses.(from p. 158): many field commanders told the committee that òcyberspace is part of the battlespace,ó and several organizations within thedod assert that they are training òc2/cyber warriors.ó but good intentions have not been matched by serious attention to cyberspace protection. soldiers in the field do not take the protection of their c4i systemsnearly as seriously as they do other aspects of defense. for example,information attack red teams were a part of some exercises observed bythe committee, but their efforts were usually highly constrained for fearthat unconstrained efforts would bring the exercise to a complete halt.while all red teams operate under certain rules of engagement established by the òwhite teamó that oversees each exercise, the informationattack red teams appeared to the committee to be much more constrainedthan appropriate. in one exercise, personnel in an operations centerlaughed and mistakenly took as a joke a graphic demonstration by the redteam that their operations center systems had been penetrated.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports33trust in cyberspace (1999)citation: computer science and telecommunications board (cstb),national research council. 1999. trust in cyberspace. national academypress, washington, d.c.cybersecurity and other trustworthiness qualities interact(from p. 14): the trustworthiness of [a networked information system] encompasses correctness, reliability, security (conventionally including secrecy, confidentiality, integrity, and availability), privacy, safety,and survivability . . . . these dimensions are not independent, and caremust be taken so that one is not obtained at the expense of another. forexample, protection of confidentiality or integrity by denying all accesstrades one aspect of securityñavailabilityñfor others. as another example, replication of components enhances reliability but may increaseexposure to attack owing to the larger number of sites and the vulnerabilities implicit in the protocols to coordinate them. integrating the diversedimensions of trustworthiness and understanding how they interact arecentral challenges in building a trustworthy [networked information system].on managing risk(from pp. 175176): a discussion about consequences must also address the questions of who is affected by the consequences and to whatextent. while catastrophic failure garners the most popular attention,there are many dimensions to trustworthiness and consequences mayinvolve various subsets of them with varying degrees of severity. . . .understanding consequences is essential to forming baseline expectationsof private action and what incentives may be effective for changing private action, but that understanding is often hampered by the difficulty ofquantifying or otherwise specifying the costs and consequences associated with risks.(from p. 175): it is the nature of [a networked information system]that outages and disruptions of service in local areas may have very uneven consequences, even within the area of disruption. failure of a singleinternet service provider (isp) may or may not affect transfer of information outside the area of disruption, depending on how the isp has configured its communications. for example, caching practices intended toreduce network congestion problems helped to limit the scope of a domain name service (dns) outage. corporations that manage their owncybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.34cybersecurity today and tomorrowinterconnection (socalled intranets) may be wholly unaffected. evenwidespread or catastrophic failures may not harm some users, if theyhave intentionally or unconsciously provided redundant storage orbackup facilities. the inability to accurately predict consequences seriously complicates the process of calculating risk and makes it tempting toassume òbest caseó behavior in response to failure.(from pp. 177178): . . . [t]he costs associated with avoiding all risksare prohibitive. thus, risk mitigation is more typical and is generallyencountered when many factors, including security and reliability, determine the success of a system. risk mitigation is especially popular inmarketdriven environments where an attempt is made to provide ògoodenoughó security or reliability or other qualities without severely affecting economic factors such as price and time to market. risk mitigationshould be interpreted not as a license to do a shoddy job in implementingtrustworthiness, but instead as a pragmatic recognition that tradeoffsbetween the dimensions of trustworthiness, economic realities, and otherconstraints will be the norm, not the exception. the risk mitigation strategies that are most relevant to trustworthiness can generally be characterized according to two similar models:¥the insurance model. in this model, the cost of countermeasures isviewed as an òinsurance premiumó paid to prevent (or at least mitigate)loss. the value of the information being protected, or the service beingprovided, is assessed and mechanisms and assurance steps are incorporated up to, but not exceeding, that value.¥the work factor model. a definition in cryptology for the term òworkfactoró is the amount of computation required to break a cipher through abruteforce search of all possible key values. recently, the term has beenbroadened to mean the amount of effort required to locate and exploit aresidual vulnerability. that effort may involve more efficient proceduresrather than exhaustive searches. in the case of fault tolerance, the assumptions made about the types of failures (benign or arbitrary) thatcould arise are analogous to the concept of work factor.the two models are subject to pitfalls distinctive to each and somethat are common to both. in the insurance model, it is possible that thevalue of information (or disruption of service) to an outsider is substantially greater than the value of that information or service to its owners.thus, a òhigh valueó attack could be mounted, succeed, and the òinsurance premiumó lost along with the target data or service. such circumstances often arise in an interconnected or networked world. for example, a local telephone switch might be protected against deliberatecybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports35interruption of service to the degree that is justified by the revenue thatmight be lost from such an interruption. but such an analysis ignores theattacker whose aim is to prevent a physical alarm system from notifyingthe police that an intrusion has been detected into an area containingvaluable items. another example is an instance in which a hacker expends great effort to take over an innocuous machine, not because itcontains interesting data but because it provides computing resourcesand network connectivity that can be used to mount attacks on highervalue targets. in the case of the work factor model, it is notoriouslydifficult to assess the capabilities of a potential adversary in a field asunstructured as that of discovering vulnerabilities, which involves seeingaspects of a system that were overlooked by its designers.vulnerabilities in the public telephone network and the internet(from p. 27): the vulnerabilities of the ptn [public telephone network] and internet are exacerbated by the dependence of each networkon the other. much of the internet uses leased telephone lines as itsphysical transport medium. conversely, telephone companies rely onnetworked computers to manage their own facilities, increasingly employing internet technology, although not necessarily the internet itself.thus, vulnerabilities in the ptn can affect the internet, and vulnerabilities in internet technology can affect the telephone network.(from p. 58): . . . [w]hile in one sense the internet poses no newchallengesña system that can be accessed from outside only through acryptographically protected channel on the internet is at least as secure asthe same system reached through a conventional leased lineñnew dangers arise precisely because of pervasive interconnectivity. the capabilityto interconnect networks gives the internet much of its power; by thesame token, it opens up serious new risks. an attacker who may bedeflected by cryptographic protection of the front door can often attack aless protected administrative system and use its connectivity throughinternal networks to bypass the encryption unit protecting the real target.this often makes a mockery of firewallbased protection.(from p. 50): the general accessibility of the internet makes it a highlyvisible target and within easy reach of attackers. the widespread availability of documentation and actual implementations for internet protocols means that devising attacks for this system can be viewed as anintellectual puzzle (where launching the attacks validates the puzzleõssolution).cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.36cybersecurity today and tomorrowon building secure systems and networks(from p. 2): laudable as a goal, ab initio building of trustworthinessinto an nis [networked information system] has proved to be impractical.it is neither technically nor economically feasible for designers and builders to manage the complexity of such large artifacts or to anticipate all ofthe problems that an nis will confront over its lifetime. experts nowrecognize steps that can be taken to enhance trustworthiness after a system has been deployed. it is no accident that the market for virus detectors and firewalls is thriving. virus detectors identify and eradicate attacks embedded in exchanged files, and firewalls hinder attacks byfiltering messages between a trusted enclave of networked computersand its environment (from which attacks might originate). both of thesemechanisms work in specific contexts and address problems contemplated by their designers; but both are imperfect, with user expectationsoften exceeding what is prudent.(from pp. 1314): networked information systems (niss) integratecomputing systems, communications systems, and people (both as usersand operators). the defining elements are interfaces to other systemsalong with algorithms to coordinate those systems. economics dictatesthe use of commercial offtheshelf (cots) components wherever possible, which means that developers of an nis have neither control overnor detailed information about many system components. the use ofsystem components whose functionality can be changed remotely andwhile the system is running is increasing. users and designers of an nisbuilt from such extensible system components thus cannot know withany certainty what software has entered system components or what actions those components might take.(from p. 3): todayõs climate of deregulation will further increase [networked information system] vulnerability in several ways. the mostobvious is the new cost pressures on what had been regulated monopolies in the electric power and telecommunications industries. one easyway to cut costs is to reduce reserve capacity and eliminate rarely neededemergency systems; a related way is to reduce diversity (a potential contributor to trustworthiness) in the technology or facilities used. producers in these sectors are now competing on the basis of features, too. newfeatures invariably lead to more complex systems, which are liable tobehave in unexpected and undesirable ways. finally, deregulation leadsto new interconnections, as some services are more costeffectively imported from other providers into what once were monolithic systems.apart from the obvious dangers of the increased complexity, the intercybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.excerpts from earlier cstb reports37connections themselves create new weak points and interdependencies.problems could grow beyond the annoyance level that characterizes infrastructure outages today, and the possibility of catastrophic incidents isgrowing.(from p. 15): to be labeled as trustworthy, a system not only mustbehave as expected but also must reinforce the belief that it will continueto produce expected behavior and will not be susceptible to subversion.the question of how to achieve assurance has been the target of severalresearch programs sponsored by the department of defense and others.yet currently practiced and proposed approaches for establishing assurance are still imperfect and/or impractical. testing can demonstrate onlythat a flaw exists, not that all flaws have been found; deductive and analytical methods are practical only for certain small systems or specificproperties. moreover, all existing assurance methods are predicated onan unrealistic assumptionñthat system designers and implementorsknow what it means for a system to be òcorrectó before and during development. the study committee believes that progress in assurance for theforeseeable future will most likely come from figuring out (1) how tocombine multiple approaches and (2) how best to leverage addon technologies and other approaches to enhance existing imperfect systems.improved assurance, without any pretense of establishing a certain or aquantifiable level of assurance, should be the aim.(from p. 247): security research during the past few decades has beenbased on formal policy models that focus on protecting information fromunauthorized access by specifying which users should have access to dataor other system objects. it is time to challenge this paradigm of òabsolutesecurityó and move toward a model built on three axioms of insecurity:insecurity exists; insecurity cannot be destroyed; and insecurity can bemoved around.(from p. 250): improved trustworthiness may be achieved by thecareful organization of untrustworthy components. there are a numberof promising ideas, but few have been vigorously pursued. òtrustworthiness from untrustworthy componentsó is a research area that deservesgreater attention.on the impact of system homogeneity (òmonocultureó)(from pp. 191192): the similarity intrinsic in the component systemsof a homogeneous collection implies that these component systems sharevulnerabilities. a successful attack on one system is then likely to succybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.38cybersecurity today and tomorrowceed on other systems as wellñthe antithesis of what is desired for implementing trustworthiness. moreover, todayõs dominant computing andcommunications environments are based on hardware and software thatwere not designed with security in mind; consequently, these systems arenot difficult to compromise, as discussed in previous chapters.there is, therefore, some tension between homogeneity and trustworthiness. powerful forces make technological homogeneity compelling . . .,but some attributes of trustworthiness benefit from diversity. . . . on theother hand, a widely used trustworthy operating system might be superior to a variety of nontrustworthy operating systems; diversity, per se, isnot equivalent to increased trustworthiness.technological convergence may also be realized through the marketdominance of a few suppliers of key components, with monopoly as thelimit case when technological homogeneity is dictated by the monopolist.however, the number of suppliers could grow as a result of the diffusionof computing into embedded, ubiquitous environments; the diversification and interoperability of communications services; and the continuedintegration of computing and communications into organizations withinvarious market niches.cybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.39what is cstb?as a part of the national research council, the computer science andtelecommunications board (cstb) was established in 1986 to provideindependent advice to the federal government on technical and publicpolicy issues relating to computing and communications. composed ofleaders from industry and academia, cstb conducts studies of criticalnational issues and makes recommendations to government, industry,and academic researchers. cstb also provides a neutral meeting groundfor consideration of complex issues where resolution and action may bepremature. it convenes invitational discussions that bring together principals from the public and private sectors, ensuring consideration of allperspectives. the majority of cstbõs work is requested by federal agencies and congress, consistent with its national academies context.a pioneer in framing and analyzing internet policy issues, cstb isunique in its comprehensive scope and effective, interdisciplinary appraisal of technical, economic, social, and policy issues. beginning withearly work in computer and communications security, cyberassuranceand information systems trustworthiness have been a crosscutting themein cstbõs work. cstb has produced several reports regarded as classicsin the field, and it continues to address these topics as they grow inimportance.to do its work, cstb draws on some of the best minds in the country,inviting experts to participate in its projects as a public service. studiesare conducted by balanced committees without direct financial interestsin the topics they are addressing. those committees meet, confer eleccybersecurity today and tomorrow: pay now or pay latercopyright national academy of sciences. all rights reserved.40cybersecurity today and tomorrowtronically, and build analyses through their deliberations. additional expertise from around the country is tapped in a rigorous process of reviewand critique, further enhancing the quality of cstb reports. by engaginggroups of principals, cstb obtains the facts and insights critical to assessing key issues.the mission of cstb is to:¥respond to requests from the government, nonprofit organizations,and private industry for advice on computer and telecommunicationsissues and from the government for advice on computer and telecommunications systems planning, utilization, and modernization;¥monitor and promote the health of the fields of computer scienceand telecommunications, with attention to issues of human resources,information infrastructure, and societal impacts;¥initiate and conduct studies involving computer science, computertechnology, and telecommunications as critical resources; and¥foster interaction among the disciplines underlying computingand telecommunications technologies and other fields, at large and withinthe national academies.as of february 2002, current cstb activities with a cybersecuritycomponent address privacy in the information age, critical informationinfrastructure protection, authentication technologies and their privacyimplications, information technology for counteracting terrorism, andgeospatial information systems. additional studies examine digital government, the fundamentals of computer science, limiting childrenõs accessto pornography on the internet, information technology and creativity,computing and biology, and internet navigation and the domain namesystem. explorations are under way in the areas of the insider threat,dependable and safe software systems, wireless communications andspectrum management, digital archiving and preservation, open sourcesoftware, digital democracy, the òdigital divide,ó manageable systems,information technology and journalism, and women in computer science.more information about cstb can be obtained online at <http://www.cstb.org>.