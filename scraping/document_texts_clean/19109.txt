detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/19109the impact of supercomputing capabilities on u.s. materialsscience and technology77 pages | 8.5 x 11 | paperbackisbn 9780309319072 | doi 10.17226/19109committee on computer simulation and analysis of complex material phenomena;national materials advisory board; commission on engineering and technicalsystems; national research councilthe impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.national research council commission on engineering and technical systems national materials advisory board the purpose of the national materials advisory board is the advancement of materials science and engineering in the national interest. chairman past chairman bernard h. kear arden l. bement, jr. chairman, department of mechanics and materials science vice president, technological resources science and technology department trw, inc. director. center for materials synthesis college of engineering cleveland, ohio rutgers university piscataway, new jersey members norbert s. baer hagop kevorkian profe11or of conservation new york university conservation center of the institute of fine arte new york, new york frank w. crossman manager mechanics and materials engineering lockheed palo alto research laboratory palo alto, california edward j. dulle president, crucible research center crucible materials corporation pittsburgh, pemaylvanla jamee economy manager, organic polymer research ibm almaden research center san jose, california merton c. flemings professor and chairman, department of materials science and engineering massachusetts institute of technology cambridge, ma11achusetts james a. ford vice president, technology selee corporation hendersonvule, north carolina john k. hulm chief scientist westinghouse research laboratories pittsburgh, pennsylvania memn f. kamlnen institute scientist southwest research institute san antonio, texas robert a. laudlse director, physical and inorganic chemistry research laboratory at&t bel laboratories murray hw, new jersey david l. morrison president llt research institute chicago, iulnols donald r. paul melvin h. gertz regents chair in chemical engineering director, center for polymer research university of texas austin, texas joseph l. pentecost professor school of materials engineering georgia institute of technology atlanta, georgia john p. riggs vice president. r&d research division managing director. mitchell technical center hoechst celanese corporation summit. new jersey maxine l. savitz director garrett ceramic components division torrence, california wiulam p. sllchter at & t beh laboratories (retired) chatham, new jersey dale f. stein president michigan technological university houghton, michigan john e . tiiton coulter profe11or department of mineral economics colorado school of mines golden, colorado james r. weir, jr. associate director metals and ceramics division oak ridge national laboratory oak ridge, tennessee robert m. white vice president, research and engineering control data corporation mlnneapolla, minnesota jamee c. williama dean, carnegie institute of technology carnegie mellon university pittsburgh, pennsylvania nmab staff k. m. zwtlsky, director s. m. barkln, associate director mary brittain, administrative officer 2101 constitution avenue, nw washington, dc 20418 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.reference copy for library use only the !mpact of supercomputing capabilities on u.s. materials science and technology report of the committee on computer simulation and analysis of complex material phenomena national materials advisory board commission on engineering and technical systems national research council łł publication nmab451 national academy press washington, d.c. 1988 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved..; /<//j <'/ notice: the project that is the subject of this report was approved by the governing board of the national search councu, whose members are drawn from the councils of the national academy of sciences. the national academy of enqlneerlng, and the institute of medicine. the members of the committee responsible for the report were chosen for their special competences and with regard for appropriate balance. this report has been reviewed by a group other than the authors according to procedures approved by a report review committee consisting of members of the national academy of sciences. the national academy of engineering, and the institute of medicine. the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific and engineering research, dedicated to the furtherance of science and technology and to their use for the general welfare. upon the authority of the charter granted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientific and technical matters. dr. frank press is president of the national academy of sciences. the national academy of engineering was establshed in 1964, under the charter of the national academy of sciences, as a parallel organization of outstanding engineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responslbluty for advising the federal government. the national academy of engineering also sponsors engineering programs aimed at meeting national needs, encourages education and research, and recognizes the superior achievements of engineers. dr. robert m. white is president of the national academy of engineering. the institute of medicine was establshed in 1970 by the national academy of sciences to secure the services of eminent members of appropriate professions in the examination of poucy matters pertaining to the health of the public. the institute acts under the responslblllty given to the national academy of sciences by its congressional charter to be an advisor to the federal goverrvnent and. upon its own initiative, to identify issues of medical care, research, and education. dr. samuel 0. thier is president of the institute of medicine. the national research councu was organized by the national academy of sciences in 1916 to associate the broad community of science and technology with the academy's p11poses of furthering knowledge and advising the federal government. functioning in accordance with general poucles determined by the academy, the counch has become the principal operating agency of both the national academy of sciences and the national academy of engineering in providing services to the government. the pubffc, and the scientific and engineering communities. the councm is administered jointly by both academies and the institute of medicine. dr. frank press and dr. robert m. white are chairman and vice chairman. respectively. of the national research council. this study by the national materials advisory board was conducted under grant no. asc8610316 from the national science foundation. this report is available from the national technical information service, springfield, va 22161. printed in the united states of america. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.abstract a committee was formed under the auspices of the national emy of sciences to identify areas of materials science and ing where a major impact might be realized, resulting from the gence of supercomputer ogy. the committee was broadly based, representing universities, industry, and national laboratories in the related fields of materials science, chemistry, and physics. a workshop provided experts from a wide variety of disciplines to aid in uncovering possible opportunities. not surprisingly, a great number of examples of exciting individual computational science were easily identified: atomistic and electronic structure calculations on metals, semiconductors, and polymers; statistical mechanical studies of alloy phase diagrams; and mental modeling of fracture and deformation in metals, ceramics, and glasses are among those that are vigorously utilizing puter technology. not so ately obvious were the cases where a hierarchical approach is being applied to solve a complex lem. electronic structure effects on a scale of angstroms are being coupled with microstructural pects on a scale of micrometers, and these are further coupled to continuum effects on a scale of centimeters. these complexities require the multidisciplinary efforts of materials scientists, chemists, physicists, metallurgists, fluid dynamicists, and mathematicians. iii supercomputers are emerging as powerful and costeffective tools, not only for the furtherance of materials science, but also for linking this science with ing, design, and manufacturing. from these examples the tee drew a number of conclusions and made recommendations aimed at improving the state of the art of supercomputing for materials ence and engineering, especially in those areas where an nary approach promises major technological impact. in the report each twopage ple stands alone, with the lefthand page providing a brief technological background and the righthand page the specific supercomputer examples. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.acknowledgments a great many people assisted the committee in conducting the study and preparing the report. we wish to express our genuine appreciation for their efforts. a major forum for discussing perience and directions for using supercomputers in materials science and engineering was a workshop held at the national science foundation's san diego supercomputer center on march 2426, 1987. sidney karin, director of the center. was most generous in allocating staff time and building space needed by the workshop. beverly brown, a ber of his support staff, was thorough and resourceful in handling the logistics for the shop. each workshop participant had an influence on this report and deserves thanks. it is impractical to mention all by name here, so we ask that the workshop program and roster. reproduced at the end of this report. be accepted as our knowledgment to them. in addition, kenneth g. wilson, cornell sity, provided the participants with a thoughtprovoking presentation on needs for supercomputers in the future. critical suggestions and mentary material were obtained from a number of people not able to attend the workshop: d. d. chambliss. cornell university: barbara cooper. cornell university: sam r. coriell, national bureau of standards, gaithersburg, maryland; paul r. dawson, cornell university; tarasankar debroy. pennsylvania state university; anthony g. evans, university of california, santa bara; robert m. fisher, lawrence berkeley laboratory; arthur j. freeman, northwestern university; massimo v. fischetti, ibm research center, yorktown heights, new york; howard heinisch, house hanford company. richland, washington; john hutchinson, vard university; r. v. kasowski, e. i. dupont de nemours & company; alan needleman, brown university; c. paulsonboaz, cornell university; t. n. rhodin, cornell university; s. l. sass, cornell university; s. f. shen, cornell university; subra suresh, brown university; r. h. wagoner, ohio state university; james a. weeks, cornell sity: alex zunger, solar energy research institute, golden. colorado; and nicholas w. winters, lawrence livermore national laboratory. for their substantial contributions we would especially like to thank donald h. avery (history). brown university; fred hausheer maceutical design), johns hopkins university; robert m. mcmeeking (ceramics), university of california, santa barbara; and karl hess (semiconductor devices), university of illinois. additional assistance was ously given by a number of the technical staff at sandia national laboratories: mike baskas, john brooks, ray cline, bruce dale, iv murray daw, brian dodson, steve foiles, joe harris, rudy johnson, mike kanouff, bob kee, terry lowe, terry michalske. jeff nelson, and ron stoltz. we could not have produced this report without several excellent forts. at sandia national ries, livermore, joan bersie and bernie marx coordinated cation among committee members, efficiently arranged the committee meetings, and assisted with the preparation of the manuscript; jack bishop handled the report's design and artwork; sandra simmons and nancy hunt assisted with its position: and robert tucker tended to editing details. at nmab. jennifer tilles handled key aspects of logistics for the workshop, cathryn summers and susanna clarendon provided secretarial port for committee records and sections of this report, and steve montgomery provided extensive editorial assistance. finally, we wish to express our preciation to john w. d. connolly (director, center for computation sciences, university of kentucky, lexington, and formerly director, office of advanced scientific computing, national science dation) and mel ciment (acting director, office of advanced tific computing, national science foundation) for their interest and support in this study. william d. wilson chairman the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.committee on computer simulation and analysis of complex material phenomena chairman william d. wilson computation department sandia national laboratories livermore, california members robert j. asaro division of engineering brown university robert w. dutton center for integrated systems stanford university juan m. sanchez henry krumb school of mines columbia university david j. srolovitz (formerly. los alamos national laboratory) department of materials science and engineering university of michigan liaison representatives melvin ciment office of advanced scientific computing national science foundation eugene farnum los alamos national laboratory thomas a. kitchens scientific computing staff u.s. department of energy alan rosenstein office of scientific research u.s. air force nmab staff stanley m. wolf, senior staff scientist richard h. boyd department of materials science and engineering university of utah william a. goddard, ill arthur amos noyes laboratory of chemical physics california institute of technology john r. smith physics department general motors research laboratories wilhelm g. wolfer theoretical division, physical science department sandia national laboratories livermore, california john connolly (formerly national science foundation) university of kentucky gregory m. haas office of fusion energy u.s. department of energy barry klein condensed matter physics branch naval research laboratory joseph w. serene condensed matter sciences section naval research laboratory cathryn summers, senior secretary v the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.contents executive summary ................................................................... . introduction .........................................ł..ł.............ł................. background: new materials and materials processing national competitiveness and supercomputing ............................................ . page 12 3 45 67 developing metal forming procedures . . . . . . . ł . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ł . ł . . . . 89 predicting polymer properties . . . . . . . . . . . . . . . . . . . . . . . . . . . ł . . . . . . . . . . . . . . . . . . . . . . . . . . ł . ł . . . . . 1011 designing ceramics for hightemperature applications ........................................ 1213 materials technology has launched civilizations ..........................................ł... 1415 developing alloys with supercomputers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ł . . . . . . . . . . . . . . . . . . . . . . . 1617 simulating the growth of sige films ....................................................... 1819 polymeric flow models .................................................................. 2021 computing universal adhesive energy relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2223 designing optoelectronic materials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2425 understanding silicon oxidation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2627 simulating chemical vapor deposition reactors .............................................. 2829 designing revolutionary semiconductor devices .............................................. 3031 vi the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.executive summary the primary task of this study was to identify key opportunities that would make a major impact in materials science and engineering, exploiting the emerging capabilities afforded by largescale puters. the committee applied rigorous criteria: the equations or algorithms should be known well enough that progress can be onstrated today and the future reasonably and credibly predicted. examples of how ''given a puter ten times faster, it will be possible to ... " were discarded if not preceded by "we have shown, in agreement with experiment, that .... łł our committee was selected to represent universities, industry, and national laboratories from a broad geographical base and a wide ety of disciplines. we began by bringing together, at an intense workshop in san diego (march 2124, 1987), experts from the wide variety of disciplines ing materials science and ing (materials scientists, physicists, chemists, metallurgists, engineers, polymer scientists, etc.). papers were solicited before the meeting, presentations were made, and followup discussions pursued. the vast amount of material collected was reduced to a manageable level at a committee meeting in july 1987. we found early on that the tational capability of puters (the largest and most powerful computers in existence at any time) is continuing to increase rapidly at roughly constant cost. cray research has announced the cray3; eta, inc., the eta10. nec and fujitsu appear committed to becoming the world's puter manufacturers, utilizing lel processors to achieve their performance goals. simultaneously, massively parallel processing chines are being designed that are capable of unlimited growth in computing power. it is clear that for the first time in history a tool has emerged that can aid in standing materials processes at the level of complexity required to make an impact. we made a strong distinction tween the capability of computers and the capacity that can be gained by less expensive mainframes and workstations. we recognized that a hierarchy of computing architectures needs to be employed (e.g., workstations are more efficiently used for ics than mainframes are) , but we restricted ourselves to the kinds of problems that cannot be done any other way. the scientific and neering complications are so great that, in many cases, computation is the method of choice over experiment. we found molecular mechanics calculations on polymers being performed that could predict the elastic properties of a complex polypropylene glass or the heat capacity of polyoxymethylene. such calculations are ultimately capable of predicting the constitutive laws necessary to design ing dies by computer, with mous cost savings. we found that supercomputers have become powerful enough to predict phase diagrams of simple alloys from first principles, in agreement with experiment, giving the historic field of alloy ment its first real hope of designing alloys by computer. although it is not possible to design complex alloys by computer today, the nomic impact of being able to sign specialty alloys by computer for a declining steel industry is large enough to drive continuing work in this area. the economic advantages of silicon semiconductor technology are ing exploited by growing layers of germanium on silicon substrates. a nonequilibrium thermodynamic process now capable of being derstood computationally. the layer thickness at which deleterious fit dislocations are introduced in the growth process can be predicted by supercomputer. ''band gap engineering' 'the ability to tailor the band gap of a semiconductor to technological needsis within reach. already electron localization effects in superlattices can be predicted from first principles, in agreement with experiment. an important first step has been made in understanding the plexities of adhesion, a problem that permeates nearly all turing processes. a universal sive energy relation was discovered by extensive computation of the energy required to separate lic surfaces. surface science and engineering is at the heart of many present and future technologies (e.g., semiconductor interfaces and corrosion) and is particularly ripe for computation. quantum chemical (ab lnitio) and solid state (local density functional) niques have impressive successes to report. one area that japan dominates is the manufacture of the equipment for producing semicon.ductors. we found that supercomputing has already been successfully applied by u.s. researchers to the design of chemical vapor deposition ment, specifically to the rotating disk reactor. efforts such as this could enable the united states to regain its processing advantage. fundamental deformation and ture mechanisms in metals, alloys, and ceramics are being studied extensively by supercomputing. the ability to describe the complex deformations of metals can lead to dramatic improvements in the sign of forming processes. the atomistics of dislocation generation 1 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.executive summary (continued) at a crack tip, including the effects of impurity atoms such as gen ("hydrogen embrittlement"), can be calculated using realistic interactions between the atoms. continuum models of microcrack density and propagation have reached a stage where numerical simulations can play a major role in design and performance ments of, for example, tough new ceramics. the supercomputer will make it possible to link methods such as these, thereby significantly changing the way materials design is carried out. pharmaceutical design, although not traditionally a materials lem, is becoming progressively more supercomputeroriented because of the costs and risks associated with human tation. lest it become lost, one example of the enormous strides being made in the design of chemotherapeutic drugs by computer has been included in this report. the list of examples here is by no means exhaustive: we found selves "stopping the presses" a number of times as still another paradigm of supercomputing in materials science came to our attention, and we recognize that some areas of computational materials science and engineering may not be covered. yet we felt convinced by the number and 2 depth of examples to come to several conclusions: 1 . supercomputer simulation will serve as a powerful and effective link between materials science and engineering, sign, and manufacturing. 2. new theoretical methods, rithms, and approaches for analyzing the individual ponents of complex materials systems are rapidly evolving. 3. to exploit opportunities in putational materials science and engineering, the united states must invest heavily in the science underlying the methodologies, in developing software to make these odologies useful to engineers and technicians, and in ing adequate hardware to entists and engineers at sities and in industry. 4. to remain a leader as materials simulation moves out of the laboratory and into the trial plant, the united states must act decisively now to stimulate the development of these methodologies and to velop turnkey simulation tems for industrial plants. 5. simulations can reduce design costs and the time from cept to market. 6. supercomputers allow the use of hierarchical design tools. 7. supercomputer simulation is a powerful design tool that can increase u.s. economic petitiveness today. based on these conclusions, the committee has the following recommendations: 1 . focused multidisciplinary search initiatives in selected areas of materials science and engineering should be started in order to integrate design and manufacturing with the pinning research base. 2. a supercomputing center for materials applications should be created. such a center would provide a better means for conducting pioneering research and moving the results of basic research into turnkey systems suitable for wide use in u.s. dustry. 3. existing supercomputer centers must be kept at the state of the art. 4. multidisciplinary materials lation groups should be formed. 5. the infrastructure of local puting associated with vanced simulation must be strengthened. 6. these initiatives should be plemented in a manner anced to preserve the research strengths that are central to the success of materials ing and processing in the future. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.introduction over the next few decades the use of computer simulation in the design and manufacturing sectors of the u.s. economy will be driven by heightened international nomic competition and rapid creases in computer capability. an enhanced understanding of key technical disciplines such as materials science and engineering will be essential. materials science and engineering have historically provided mental technologies for tion, industrial production, defense, construction, and other areas throughout a nation's economy. the vitality of a nation's industrial base has rested on its materials development capabilities: in ancient china the production of iron ons and tools on a monumental scale enabled that society to expel indigenous barbarians. in the 19th century, british steel processing methods enabled a small nation to dominate the industrial revolution. today, we find another small tion, japan, relying on materials science and process engineering to dominate the steel and electronic industries. in the united states, materials technology has often been seded by that in other advanced industrial nations. although there is hope that concentrated research and development programs will produce significant improvements, it is not clear that traditional methods will move u.s. industry ahead fast enough. an additional tool for attacking today's complex research problems, which could provide the needed edge, is the supercomputer. this study focuses on opportunities for the simulation and modeling of materials behavior made possible by the rapid and continuous creases in supercomputer capability over the past few years. ticated simulation and modeling can now describe complex als phenomena on a physically alistic basis. these phenomena clude deformation and fracture of structural engineering alloys, local chemistry and phases caused by multicomponent diffusion of cal and defect species in alloys, and electronic behavior of metals, ceramics, and semiconductors. in certain areas, it may even be sible to predict material properties. these scientific and engineering advances are made possible by significant developments in the hardware (computing machines), software (theoretical methods and algorithm development) , and strong experimental database underlying the supercomputing environment. several manufacturers have already announced machines, available within the year, with an order of magnitude speedup in the time to perform a calculation and nearly two orders of magnitude increase in central memory. these ments coincide with those in the microelectronics industry in general. mathematical algorithm ment has also been proceeding at a rapid pace. the time needed to solve a typical partial differential equation (such as poisson's tion) with algorithms in common use 30 years ago (such as cramer's rule) on a modern puter would be longer than the time needed to solve the same equation with modern algorithms (such as preconditioned conjugate gradients) on the computers of 30 years ago. the experimental database pinning supercomputer tions is deep enough to allow gress; further experimental work must be incorporated into any lievable simulation. concurrent with these increased technical capabilities has been the increase in international competition in materialsrelated and turing markets. this competition is recognized as critical in the tive markets of electronic and toelectronic devices for computer surveillance, telecommunication, and diagnostic systems, among others. reliable design, ture, and performance of these vices will continue to limit system performance, and materials behavior will be the pacing factor in the rapid development and mercialization of new devices. computer simulation is essential for development and commercialization and may offer the united states the opportunity to restore its petitive position in this arena. a parallel need and opportunity exists for structural materials, where computer simulation can integrate materials processing with ture and design to significantly duce cost and lead time for uct commercialization. what follows is the main substance of this study, the examples. by no means inclusive, they nevertheless represent clear evidence of the emergence of this powerful new tool, the supercomputer, to late a wide range of materials nomena, from the manufacture of automobile components and tronic devices to calculations of fundamental structure and dynamic relations. each twopage example stands alone, with the hand page briefly describing the technology and the righthand page the specifics of the calculations. ancillary information is provided in blue background. the committee's conclusions and recommendations regarding technical and institutional issues are presented following the examples. 3 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.new materials and methods of materials processing are the in the beginning, materials were simply foundpicked up and utilized in their natural state. we do not know when the first stick, stone, or bone was purposefully altered to assist in some task, but the origins of technology certainly date back to long before the evolution of homo sapiens. the earliest surviving examples of materials processing, from east africa, are over 2 million years old. they are river pebbles of a size to fit in the hand, crudely shaped with a few intersecting breaks to form an edge at one end. since that time, the ability to modify materials and grasp the potential usefulness of new material forms has set mankind apart from all other forms of life. moreover, the success of individual groups and in many senses the fullness and success of their societies have been strongly influenced, if not controlled, by their mastery of the materials of technology. early technology was largely characterized by methods for modifying a material's shape without changing its material state. rare flashes of keen empirical perception set standards for tens of thousands of years. a distinctly different technological revolution came about, some 9000 years ago, with the realization that readily deformable clay would harden to oldowan chopper 4 stone when baked. unlimited formability in one state was placed by stability in the final state. at the same time, there was no understanding of the complex chemical changes and tion that take place in forming ceramics at elevated temperatures. an even more significant logical revolution probably nated with the finding of beads of copper in the ashes of fires built against certain brightly colored rocks. experimentation led to the concept of smelting, the intentional reduction of ore to its base metal. this development was of vast economic significance: a new material was not invented; rather, a new, more efficient materials process was discovered. it was then a relatively small step from smelting to alloyingto discovering that the simultaneous smelting of the ores of copper and tin duces bronze, a stronger material than copper and one that is also more easily cast into many able shapes. without any standing of the underlying tions, persistent experimentalists discovered a new material that became the metal of choice. the earliest synthetic materials nologies, then, were metallurgy and ceramics. both contributed to the rise of rich and complex civilizations. the first (unplanned) smelting of iron may have taken place as much as 7000 years ago. any efficient copper smelting operation requires a cosmelting of copper and iron oxides. if iron oxide is not naturally present. it must be added to increase the copper yield. under certain temperature conditions, lumps of iron grow at the slag interface. their value as decorative items probably aged experimentation with this metal, which led to the discovery that iron oxide itself can be smelted. as forged, iron is essentially carbonfree, soft, and ductile. its mechanical properties are generally inferior to a good tinbronze. it was the making of steel, the alloying of iron with small amounts of carbon, that was the crucial materials processing step which made ironbased alloys preferable to those of copper. its preeminence among metalscombining ness. toughness, and response to heat treatment with widespread availability and affordable revolutionized civilizations. by the early 1800s. steel could be made in quantity but only by ruinously expensive methods. in 1856 bessemer (british) introduced a processing technique that volved shooting jets of compressed air into the molten metal and significantly lowered the cost of steel production. a decade later siemens (german) pioneered the openhearth process of making, which was appropriate to a different kind of ore. as a result of these new materials processes, the world output of steel increased tenfold between 1865 and 1880. a new material was not developed, but the means of production, the materials process, was made more efficient and costeffective. the united states became the world's largest steel producer until after the second world war, when japan invested heavily in steel production equipment. by making furnaces twice the size of can counterparts, the japanese were able to produce highquality steel at a lower cost. again, it was not the invention of a new material; rather, it was the investment in the materials processing that gave japan technological leadership. it is not only in the development of the material that technological revolutions have continued to come the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.fuel of technological revolutions ł ł ł about, but also in the forming and shaping of materials into useful end products. the 13th century tilt hammer, for example, was a boon to blacksmiths because it relieved them of much of the heavy labor required to forge metals. today, metals are shaped by compressing them between specially designed dies, modern tools at the heart of materials processing. precision dies are just as important for injection molding and extrusion in the polymer industry. since 1920 modern methods of physical and chemical analysis have created a new industry, which produces billions of pounds of plastics and resins each year. nylon, ene, and polyvinylchloride (pvc)unheard of 60 years agoare now replacing steel and aluminum for many applications. for metals as well as polymers, however, die design is carried out painstakingly by trial and error; it is a materials processing area ripe for revolution. another area that grew out of modern technology is nuclear energy. it is perhaps not nized that the manhattan project was largely a task with unparalleled materials processing problems. one material (plutonium) required a nuclear reactor (which had yet to be constructed). another (uraniumbessemer process 235) required the separation of two of the heaviest isotopes known to man. the invention of the transistor in 194 7 at bell laboratories led to a quantum increase in interest in semiconducting materials, pally silicon and germanium. by the late 1 950s, transistors, resistors, capacitors, and their tions were being incorporated on a single "integrated circuit" ductor "chip." in 1962 another u.s. invention, the laser diode (a lightemitting, solidstate device made of gallium arsenide), gave rise to the photonics industry. we have all felt the effects of the explosion in the electronics industrycommunications, puter technology, information processingbrought about by the invention of these new materials and devices. an unprecedented sophistication in commercial materials processing has been brought about by this latest technological revolution. single atomic layers of silicon are deposited from chemical vapors onto substrates. silicon is doped with ions implanted at precise distances below the silicon surface. "clean rooms" keep metersize particles out of the processing environment. the japanese have not only excelled at applying these techniques in capturing the world market, they have succeeded in dominating in the manufacture of the fabrication equipment necessary to apply these materials processes. this is the ultimate in holding the keys of production in one's hand. most recently, a serendipitous discovery of hightemperature superconductivity in ceramics has excited the materials community with prospects of zeroloss distance electrical energy sion, superconducting computers, and railless trains levitated on magnetic fields. once again, however, it will not be the inventor who profits from this discovery but the materials processor who develops the material and brings it to the marketplace. we have progressed a long way from finding the materials of our culture lying on the ground. fully controlled processing methods are transforming existing materials into precise geometries and microscopic structures. at the same time, materials processing advances still depend largely on experimental development, aided by theoretical insight, although it would appear we have an adequate understanding of the underlying physics and chemistry to carry out development theoretically, aided by a few wellchosen experimental checks. what has been missing is a sufficiently powerful tional tool that will let us define the need and then carry out the design, atom by atom. semiconductor chip "' the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.ł ł ł which create national needs for competitiveness the technological advantage gained with new materials and processes can dramatically hance a nation's competitiveness. historically, such a competitive advantage has often led to market dominance by a single nation. in the mid1850s, britain became the first nation to master the ogy of economical steel production on a large scale. as a result, not only did britain increase the ber of miles of train track linking her industrial centers by a factor of 30 in as many years, but she also became the premier supplier of locomotive technology to the rest of the world. today there is fierce international competition for dominance in materialsintensive areas such as transportation, communications, and information processing. in the area of transportation, for instance, airframe materials technology is being driven to an extreme level of sophistication by economics. the manufacturer who can most ciently produce the lowestweight, higheststrength structural alloy may well dominate the market. alloy development and processing have become highpayoff ors in this arena. metal forming, including the composition and momechanical processing of an 6 alloy, is a highly competitive terials processing problem in the aircraft industry. airframe design in particular is also driven by nomic factors. while the namic shape of an automobile might influence fuel economy to a small extent, on an aircraft the shape of wings and fuselage are vital to performance. dollar wind tunnels have been structed to provide design neers with a tool for optimizing performance parameters before final production. the need to be competitive in communications technology is phasized by the 430 million phones, 364 million television sets, and 100 satellites in use throughout the world. the materials on which this communications explosion is based were invented more than 20 years ago, but the processing techniques have become vastly more sophisticated in recent years. this phenomenon is true not only for the semiconducting materials in integrated circuits but also for the interconnection medium itself. provements in the processing of glass have reduced light sion losses to such an extent that glass fiber has replaced copper as the material of choice for communications. perhaps the most intense area of competition involving materials and materials processing is that of formation processing, which is the circulatory systemthe blood supplyof a modern economy. no industrial nation can hope to be competitive without widespread application of this technology. for the past several years, automated information systems have handled airline reservations, kept business records, executed banking tions, and paid the work force. today, information systems control aircraft traffic patterns, assist with medical diagnosis, help fight crime. and model investment decisions. tomorrow, we will manipulate knowledge on a grand scale, as digital storage media (polymers, alkali halides, etc.) and computer technology integrate online bases with realtime ing capabilitiesopening up cations that are as yet pated. the impact of ducting ceramics on information processing has yet to be realized. the need for new materials and competitive processes to support this information revolution is nized by every developed country. the nation with superiority in edge manipulation will be a able competitor indeed. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.supercomputing can enhance u.s. economic competitiveness ł ł ł the design of new materials and materials processes vital to the tion's economic competitiveness is an immensely complicated cal problem being addressed today as much by art as by science. when a process is too complicated to understand on a fundamental level, we traditionally perform periments or tests on the process, which we then compare to a pothesis or theory. the theory is modified accordingly. this is the essence of the scientific method in use since francis bacon proposed it. on its highest plane, the theory includes fundamental equations such as newton's laws. when the level of complication is beyond our ability to write down the equations, we make suppositions or guesses and gather data. if we can gather enough data in one place, we might be able to make correlations that enable us to make progress. niels bohr studied the 30 years of data on atomic spectral lines and made important correlations that led to his atomic model. theory theory łł computer .! r experiment experiment computerł bring a new methodology to aclence. supercomputers bring a third odology to theory and experiment. when enough knowledge exists, in the form of fundamental equations for example, computers become a tool capable of yielding insight otherwise unobtainable. knowing the equations is not even enough: f = ma does not tell us whether an automobile will be crushed upon impact. for the complicated materials processes addressed here, there are many equations arising from ent scientific and engineering plines. chemical, physical, and metallurgical processes must be coupled to fluid dynamical tions, for example, in order to understand the deposition process used by the semiconductor industry. puters facilitate this multidisciplinary effort by threading together in the same program inputs from the different disciplines. we finally have a tool to help us accomplish the goal of coordinating otherwise splintered efforts. this multidisciplinary approach to largescale computations was ognized early in the nuclear ons program as being essential to making progress in such a cated area. hydrodynamics, tronics, fluid mechanics, chemistry, physics, and transport phenomena are all coupled in elaborate puter codes. designs that formerly required hundreds of expensive and timeconsuming tests are now done better by computer along with a few critical experiments. it is not that nuclear design can be done without experiment, it is simply that computation minimizes the number of those experiments. it is important not to confuse percomputing with other highlevel computation. a supercomputer is the most powerful computer in istence at any time. the computer of the 1950s had the power of a hand calculator today. a factor of 10 increase in computer power every 5 to 10 years has been and continues to be achievable. it is the capability of these supercomputers we wish to exploit: adding together a great many smaller machines will crease our capacity to compute but will not give us what is needed. a vax8800 may have the power of onetenth of a cray, but ten (or even twenty) v ax8800s cannot do the calculations one cray can (see page 50). as in the weapons design program, the knowledge exists to enable us to use supercomputers to enhance our competitive position in the sign of materials and materials processes. there are many illustrations of this, some of which are included in this report. where large, longterm, multidisciplinary efforts have been undertaken, remarkable results have been achieved. it is essential that there be a longterm commitment: the weapons program began its computing effort at the very ning (1943) of nuclear weapon velopment and has led the world, indeed has been the driving force, in the use and development of supercomputing. a national effort is needed in rials science and technology to awaken the research and ment communities in industry and academia to the realization that supercomputers offer a new tool for unprecedented materials sis, development, and processing simulation. to demonstrate that this opportunity is already within reach, our committee has bled in this report a selection of ongoing research and development projects that show the power and future promise of supercomputer siml;jlation in materials technology. each example demonstrates in a particular way that today's computers can synthesize various interrelated phenomena at all els, from the electronic to the macromechanical, and thus scribe material behavior during processing and manufacturing as well as material performance. 7 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.developing metal forming procedures and dies is a dollar industry . . . schematic of a typical die for metal forming. metal coupons with dot patterns such as these are used to measure the strain in a deformed metal sheet up to (top) and including (bottom) ductile tearing. 8 the forming of sheet metal into partsfrom cans to automobile fenders to airplane foilsis a major manufacturing activity. processes involving ing, stretching, and bending of metal sheets, for example, require cisely shaped dies as well as carefully designed sequences of individual steps to achieve the final shape. this procedure costs the automotive dustry alone on the order of a billion dollars annually. the same is true of the legion of other forming processes involving forging, extruding, etc. at present, however, most forming procedures are designed by trial and error, which limits the quality of the finished products and the effectiveness. one of the reasons that designing forming procedures is difficult is that the formability of materials depends not just on the amount of deformation in an operation but also on the history of deformation and on the ability of the material to resist fracture. for decades, forming limit diagrams have been developed to indicate the maximum amount of deformation, under simple deformation histories, that can be sustained by a material before failure. parallel to this effort, constitutive equations based on continuum theories for plasticity have been developed to describe the relationships between stress, strain, and strain rate for metals. these constitutive laws have not. until recently, included descriptions of material failure, nor have they counted for the historydependent material response that is important for predicting failure. what limits the strain to failure is typically the development of failure modes. these may include the formation of bands of intensely trated plastic deformation caused by the confinement of microscopic esses of slip to narrow zones within the individual grains of a metal, or by the development of microscopic damage involving the initiation of cracks or voids. in addition, metals are often highly anisotropic (their properties depend on direction within the material) ; the process of deformation itself results in the development of textures that induce further anisotropy. the figure on the upper left illustrates a typical, but simple, sheetmetal forming process. here the metal sheet is stretched over a die whose mensions and shape are important design parameters. the middle figure illustrates the deformed shape of a similar sheet part formed by a similar process. the lower figure illustrates a typical failure modeductile ingthat limits the ability to successfully form materials in this way. current understanding of metal plasticity, including failure, provides the basis for an unprecedented capability for designing forming procedures. the necessary analyses will, however, require nextgeneration puters so that a complete account is taken of a material's behavior and of the actual threedimensional forming process. simulated forming on a supercomputer will not only save time and money. but also lead to tionary methods of shaping metals. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.we can predict twodimensional material response today .łł there are two phenomena that influence the tearing of a metal sheet during forming: flow tion and microvoid formation. these occur in both two and three dimensions, but today's puter capabilities limit simulations to two dimensions. sional (2d) modeling, however, is well established, as is seen from the following discussion. the development of advanced stitutive theories to describe the detailed behavior of materials pends on models that can simulate the deformation response of microstructures. in metals these microstructures consist of gates of grains and dispersions of particles of other materials that part increased strength and ness. the boundaries of the grains, as well as the secondphase forcing constituents, are typical sites for the initiation of failure modes. detailed simulations are needed that allow for strain patibility between the various phases and incorporate realistic scriptions of the atomistic tion mechanisms. deforming finite element mesh for a polycrystalline metal. nonuniform grain deformation and shear bands are computed along with thł crystal' s stressstrain response. the figure on the left below is a supercomputer simulation of the 2d deformation of a polycrystalline gregate subjected to compression. it illustrates how localized tion, in the form of shear bands, occurs naturally and leads to failure of the material. included are the predictions of material texture so that account is taken of the tion of historydependent anisotropy. the figures on the right illustrate ductile rupture that occurs by microvoid formation. one is a micrograph of the fracture surface of an iron specimen that underwent ductile rupture through the initiation and growth of microvoids. the other is a computed ductile rupture pattern using an advanced tive theory developed for metals that undergo damage through microvoid formation. damage . ··... ; : .. ·. ....;., .. . ł.. . .. łł. 1.\,.. ł.ł ,.. ' ..... ł ............. . . ...... ···.. .ł.. ;··' . . .. . . . . .... . .. . ..... :ł ... . ... . . . . ł.... ł ·ł . . .. . ......... ··· .. .. ·' ·· .. .... .·ł · . .. . .. · 6 !19ł . · łł through the formation of such microcracks can result from the earlier formation of shear bands or can, in turn, induce localized mation that accelerates microvoid growth, leading to complete rupture of the material. in both sets of figures the tions accurately describe the plex events that occur on the microstructural and macroscopic scales. in particular they illustrate how fundamental descriptions of microstructural behavior can now be incorporated into simulations of complex macroscopic behavior and of macroscopic processes. it is clear that enormous capability now exists for making fundamental improvements in the way we design and analyze technological forming processes. all the pieces are in place; we await the next generation of supercomputers. mlcrovolds (left), seen here enlarged in an iron specimen that failed through ductile rupture, reduce the amount of elongation before fracture. when the fects of mlcrovolds are included in the deformation law, then the reduced tlllty and rough fracture surface are reproduced in a 20 finite element analysis (right). 9 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.the importance of polymers is driving us to a more detailed understanding of structure versus properties łł. 10 polymers are the major chemical constituents of plastics, elastomers, hesives, and some fibers and coatings. on a volume basis their tion and utilization in the united states has exceeded that of steel for some time, and their growth rate is 4 times that of steel and nonferrous metals. the design of new polymers and modification of existing ones for new uses are obviously important undertakings. accomplishing these tasks depends not only on understanding the relation between the chemical stitution of a polymer chain and the properties of the ensuing material but also, ultimately, knowing the structureproperty relationships for the bulk materials. in the past much of this understanding was developed qualitatively and through empirical correlations. more progress is needed at the atomistic and molecular levels. for some properties and phenomena better theories are required. however, even where the interactions are well understood, it is difficult to account for the complex assembly of atoms in a bulk meric system. from a structural point of view there are two main classes of solid meric systems: those that have chemical structural regularity (crystals) and those lacking chemical structural regularity (amorphous solids and glasses). both classes are important. designing and modifying polymers will be significantly aided when the static and dynamic properties of talline and amorphous polymeric solids can be accurately calculated. 0 ncethis composltł of łmbłddłd kevlar aromatic polyamldł flbłrł is onł łxample of a strong, llghtwłlght matłrlal madł posslblł by a synthłtlc polymłrlc fiber with stiffness and strength comparablł to that of łtłłi, but with much lowłr specific gravity. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.detailed atomistic simulations can predict polymer properties ł ł ł the calculation of static bulk erties of polymers is largely a lem of complexity, not of principle. the forces between atoms can be modeled by molecular mechanics. the energetics of bond stretching, bending. and twisting, as well as specially dependent interactions between chemical building blocks in the same and different chains, can be represented by empirical tions (such as lennardjones tentials), with parameters able among different polymer chains. while analytical calculations are unable to cope with the full complexity of the problem, supercomputer simulations rating these ideas (see figures below) have constructed energy structures for amorphous polymeric glasses and determined their bulk elastic properties. in the area of crystalline polymers, molecular mechanics simulation techniques have been applied to energy minimization. these niques include the internal molecu90 calculation 80 lar degrees of freedom and lographic packing parameters, allowing a calculation of the chanical and thermodynamic erties of crystals. in the future, supercomputer lations that simulate molecular motions in polymeric solids will lead to an understanding of timeand temperaturedependent properties. coupled with advances in computer technology, these niques will at last allow the tion of new polymeric materials with specifically tailored properties, before painstaking synthesis is actually attempted in the tory. for example, to study the viscoelastic response of a meric material, one needs to carry out a molecular dynamics tion of a few hundred polymer chains comprising a few million atoms over an actual time period of 10 ns. one way to accomplish such a simulation would be through massively parallel processing pled with performance ments in each processor. 60 50 70 £>·20.6 ill 40 cl 0 0 6 n en ·ir+{ + ::r 30 ::::> cj 5 .... ...j ::::> ::? a 820 0 4 :::i; 10 3 x·9.2 20 150 100 so 0 +50 temperature <°cl c.lculated etructure for atactlc polypropylene glah. parent chain ił boldface; othłrł are lmagee. thł culated young'ł moduluł (not ehown) ił in good agreement with periment. note the highly dleordered entangled łtructure, a difficult nomenon to elmulate properly. 100 200 temp <kl calculated 300 400 fiber moduluł of polyoxymethylenł vłrłuł temperature. thł experimental valułł (from xray meaeuremente) at low temperature and high draw ratio (>..) approach the value calculated from molecular mechanicł, indicating that an optimum morphology ił being obtained mentally. thł goal ił to be able to screen candidate terialł for high modulue flben by molecular mechanicł predictions. calculated heat capacity of polyoxymethylene compared with experiment. the calculated valueł are accurate up to the oneet of eerloue anharmonlclty effects. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.ceramics provide hightemperature options to increase efficiency ł.ł ceramics & ceramic composites ·/ thermalw superalloys· ... '..·.'.:·ł.'·.·· a: :::::> 1200 ł. · .··· ffi intermetallic ·. compounds> w 1w 0 it a: :::::> cl) 1000 conventional . supeaalloys year of initial engine use ceramics have been traditionally thought of as materials for housewares and industrial furnace linings. in fact their hightemperature stability and strength, hardness. low thermal conductivity, and wide range of dielectric properties make them desirable for much wider structural and electronic use (see figures below). these applications have not been realized in many instances because ceramics are prone to brittle cracking and failure, especially in residual and thermal stress fields. more recently. researchers have tried a variety of microstructural proaches to enhance the toughness of ceramics. resulting (in some stances) in orderofmagnitude improvements. since such improvements are sensitive to microstructural details based on crackmicrostructure actions. micromechanics models that relate the fracture resistance to microstructural specifics have been the primary contributors to the development of these vastly improved ceramics. our understanding is now at a stage where numerical simulations for crack growth can play a major role; preliminary results are encouraging. further numerical research should allow ceramic designers to conduct optimization studies that take into account the influence of the various known nisms and, more importantly, calculate the synergistic effects of multiple mechanisms. t76 ceramic engine engine goals engine components made from ceramics have im proved properties. power output specific fuel consumption 715 shp (533 kw) 0 60 lb/hphr (0 kgikwhr) 1000 shp (746 kw) 0.5'4 lb/hphr (0 328 kgikwhr) 12 comparison of metal alloy and ceramic aeroenglnes fies the increased interest in ceramics. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.supercomputers are aiding the design and performance of ceramic materials . . . materials scientists are simulating crack growth in ceramics and ramic composites with theoretical models for micromechanical ior. in materials like tetragonal zirconia, phase transformations occur near the crack due to locally high stresses. in others, such as an aluminazirconia composite, microcracks result from induced phase transformations near the macroscopic crack tip. a ber of u.s. researchers have termined the extent to which the crack tip is shielded from damaging stress because of material tion during a phase change. others have developed models for cracking. with these models. microfracturing around the tips of major cracks is being analyzed. below is a supercomputer tion of crack growth in a cracking ceramic, showing contours of microcrack density around a growing macroscopic crack. the microcrack zones shield the macroscopic crack from the applied stress, making it more difficult for the applied stresses to open the crack further. in other words, the material is tougher. increases in toughness are lated in these simulations and related to the material's structure. with such supercomputer tions, ceramics designers can determine the optimum mode of toughening. other simulations can model the effect of reinforcing fibers or whiskers, ductile particles, or microstructural bridges straining a major crack. by ing the complex interactions among such micromechanical features, materials scientists will be able to develop new tough ceramics. recently, researchers have also developed constitutive models for transformationtoughened ceramics such as zirconia partially stabilized with magnesia (mg:psz). the models represent the shear strains and expansion produced by the stressinduced transformation of zirconia from a tetragonal to a monoclinic phase. finite element analyses of fracture behavior based on these models have successfully predicted toughness enhancements and fatigue crack growth from notches subject to cyclic loading. the contour map on the right is a computer simulation of residual ten0.44 ....... =t::.;..;a;..,=...:o. 72 ( /ocl 2 0.28 z ::::i 0 uj n :j c( ::!e er 0 z > 0.28 growing crack tip ....... .32 0.64 0.96 1.28 x <normalized units) contours of mlcrocrack density near a growing crack in a ceramic posite from a supercomputer almulatlon. t.a la the amount of crack growth and ki la the applled stress intensity. sile stresses at the tip of a notch in mgpsz that was loaded and loaded. the photograph beneath it is from a fatigue experiment on mgpsz. the direction of crack growth, predicted by the maximum tensile stress contour a, was perimentally observed. these sults demonstrate how computer simulations derived from physically based models of microscopic deformation can aid in ing and predicting the macroscopic fracture behavior of ceramic materials. contours of a constant normal stress at the notch tip in a mgpsz ceramic after complete unloading. crack growth from a notch tip in a mgpsz ceramic. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.while other animals have oped occasional and specialized uses of materials, man has been unique in his exploration and opment of sophisticated materials and materials processes. with each successive advance in materials technology, largescale political vantagesalong with the spread and flourishing of culture, ideas, and governmenthave accrued to those skilled in their manufacture and use. in the great lakes region of north america, in the third millennium b.c., massive deposits of pure metallic copper were available for arrow points, awls and needles, and artistic objects. despite its plentifulness this new world copper was predominantly used for utilitarian, decorative objects, being too soft to supplant the existing stone age technology for sharp tools and weapons. thus the style and productivity of the gatherer societies were not cantly affected by its presence. in contrast, in the near east the absence of large, easily obtained supplies of native copper led to the development of a new materials process, smelting, about 3500 b.c., which made it possible to produce copper in large quantities. moreover, cosmelting with other ores produced alloys of bronze, tin bronze in particular, the first true technological metal with the strength, ductility, and formability to be vastly superior to polished and chipped stone materials, mitting the production of far more sophisticated weapons and tools, and intricate art. the principal problem with tin bronze lies in the scarcity of tin ores, which are located in only a few parts of the world. hence, early bronze societies became force trading societies, mounting expeditions and making trade con14 materials technology has always been tacts over long distances. an ception was the premier ancient power, egypt, which continued to slumber along, relying on imported goods and looking inward upon itself. as a result, the center of bronze age political power and fluence shifted to sumeria and babylon in the mideast and to the seafaring nations of crete, troy, greece, and phoenicia in the mediterranean. in the middle of the second nium b.c., another power shift curred as industrial production of iron became a reality among the hittites (southeast of the black sea) . iron had been produced lier in small pieces but never ized as a significant industrial terial. the hittite bloomery furnaces changed history as drastically as alamagordo did in our lifetime and marked the commencement of the largescale production of bloomery iron around 1200 b.c. iron was more difficult to produce and work than bronze. iron ore, on the other hand, could be found in large quantities in bogs and croppings. suddenly, metallurgy could tap a vast supply of readily obtained raw material. it allowed the largescale production of metal tools and weapons for an entire population, not just for an elite tocracy as was characteristic of the bronze age. although early iron weapons were cruder and less cient than their bronze parts, they were available in large numbers; entire armies, including peasants as well as the ing aristocracy, could be equipped with metal weapons and armor. perhaps not surprisingly, the rise of the iron age was accompanied by a devastating military ascendancy and expansion of ironproducing barbaric tribes. iron had a dramatic effect on the history of china as well. by the second millennium b.c. the shang and zhou dynasties had developed a largescale capability for making monumental bronze castings, some weighing several tons. during the zhou dynasty, iron development took over on a massive scale. in part this can be attributed to the large blast furnaces developed for bronze castings and probably also to highphosphorus ores in which a lowmelting ledeburite cast iron formed at temperatures well within the range of the furnaces. indeed, estimates are that by the han nasty, every chinese family had in its possession some 5 to 20 grams of iron in agricultural ments and weapons. the chinese also learned that heating chilled iron castings for an extended time converts brittle white cast iron into tough, ductile, able iron for highimpact uses such as plowshares, swords, and armor. they also developed composites in which highwearresistant surfaces (e.g., for plowshares) were made of the hard cast iron backed with a ductile iron support. the chinese developed tal industrial operations that duced iron at the rate of several tons per day per furnace, dwarfing anything in the mediterranean or near east at the time. their iron provided agricultural tools for ducing a large food surplus that sustained a rapid growth in tion. the large population and iron weapons of the han dynasty ported armies which, for two ries, slowly pushed the barbarians out of central china. the disruption dislodged turkish and barbarian tribes and forced them westward across central asia. finding few resources there, these displaced tribes eventually burst into europe and the mideast, laying siege to the roman empire and ultimately overcoming it. thus the vandals, goths, and huns that descended on rome in the 3rd and 4th centuthe impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.at the foundation of thriving civilizations . ł ł ries were the direct result of the metallurgical developments of sive iron production in zhou and han china 200 to 400 years before. roman metallurgical works were also well organized and tal, ranging from the copper mines at rio tinta in spain to the works through the north of the po valley, where adequate fuel and sophisticated mining produced large and massive quantities of iron. perhaps one of the more spectacular finds is a roman nail hoard at the legionary fort of lnchtuthil in scotland, a remote outpost on the fringe of the empire and only occupied a.o. 83 to 87. over 900,000 iron nails, some 5 tons, were found stored as the mal produce of an ironusing ety. indeed, a roman legionnaire, with his irontipped javelin, iron short sword, and ironbanded armor, was invincible for close to 500 years. in the new world, a small number of spanish conquistadors equipped with iron armor and steel swords challenged and overcame the large native societies, which were ized in a military hierarchy but were demoralized by the seemingly cible weapons of the spanish. though lacking iron weapons, the indians did possess large quantities of gold and silver, which had great monetary value in europe. spain became the wealthiest nation in europe. there was little need to develop the industries and sors of the industrial revolution, which were springing to life under harsher conditions in northern europe. the purchase of nary armies made it unnecessary for extensive spanish participation or risk in the military. the spanish empire, owing to its easy access to valuable materials, became a society based on consumption rather than production. spain was eventually eclipsed by the poorer but more industrial nations to the north. again it was iron, and the ability to produce it more efficiently and in large quantities, that provided the driving edge for dutch, english, and british expansions. by the mid1600s crude bloomery furnaces were giving way to blast furnaces, which produced substantial ties of cast iron, and to the chafery refining process, which allowed the cast iron pigs to be refined into a relatively tough wrought iron. made in extensive quantities. it not only supplied the needs of the tants, but produced a substantial surplus for export. the ancient pires of asia and the vast land of africa gave up their ures, luxuries, and even their habitants for the iron and tural tools from sheffield and mingham and the cloth from manchester and the low countries. the possession of materials of great utility and in great demand, mass produced at a low price and made available by efficient sea transport, transformed small, poor, cold, and relatively infertile nations into world powers. in the 20th century, it was can materials and production that dominated the world scene. although the major wars of this century found the united states prepared, the productive capacity and quantity of arms produced overcame, by sheer weight, the professional armies, military ence, and tradition of europe and japan. and now we are in the throes of yet another expansion, which threatens to eclipse the traditional producers of america and europe. the pacific basin nations are ducing highquality materials and products. not only those of tional technology such as steel, plastics. machines tools, cameras. and automobiles but also the newer electronic chips, electronic vices, and computers. inexpensive, educated, and motivated labor is part of the story, but the thrust of development of new materials also appears to be passing to japan. engineering ceramics, advanced electronic materials, ing ceramics, and new chips all seem to be coming from that one nation. with the momentum of materials development and tion, economic and technological dominance may follow. l!fflolent materials processing on one continent has more than once led to a civilization'ł downfall on another continent. 15 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.alloy development is a costly and timeconsuming undertaking ł ł ł the possibility of tailoring material properties by means of alloying stands as one of the oldest principles discovered and effectively exploited by mankind. the emergence of new technologies in, for example, the space and electronic industries creates a constant need for the design of new materials that can operate in·a variety of demanding environments. in some instances it is even desirable to redevelop existing alloys in order to eliminate or minimize the use of strategic materials such as cobalt and chromium. unfortunately, redevelopment is often unattractive because the traditional approaches to alloy design are economically prohibitive. despite its long history, the process of alloy development is still based on gradual improvement by empirically driven trialanderror experimentation and is seldom guided from fundamental physical principles. the starting point for alloy development is knowledge of phase diagrams, which show the composition and amounts of phases formed when ments are mixed to form an alloy. alloy properties (mechanical, electrical, optical) depend critically on the amounts and properties of the constituent phases, among other factors like microstructure. for structural alloys the phase diagrams are usually complex. below, for example, is the binary (twoelement) nickelaluminum diagram. most aircraft engine turbine blades are made of nickelbased alloys. these contain aluminum and chromium for oxidation resistance and other elements such as tungsten, titanium, and carbon for strength. a typical commercial superalloy may contain five elements or more. binary and ternary phase diagrams are traditionally determined tally with great difficulty and with significant investments of time and sources. it is virtually impossible to obtain quinternary phase diagrams or to find an effective mode of representing the data. an ability to calculate such diagrams from first principles would revolutionize the design of new alloys. for example, the recent discoveries of nial intermetallic pounds (see page 34) that are ductile and refractory, and of ordered phases in semiconductor alloys such as those observed in lngap and gasbas, have opened new areas for developing potentially useful als. the challenge will be their optimization for various applications. ....... ....... nlckelalumlnum phase diagram. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.supercomputers and quantum architecture may offer a road map to alloy design . ł ł the last 10 years have witnessed the emergence of powerful retical tools that allow the tion, from first principles, of the total energy of complex crystalline compounds and its dependence on structural parameters. to a great extent these developments have been closely linked to the creased availability of computers. it is now possible to answer, from a strictly tional approach, some of the most fundamental questions raised by alloy designers, such as those garding the relative stability of complex phases in metallic and semiconductor compounds. recently, ab lnitio quantum tions for ordered compounds have been extended to disordered loys. with only the atomic number of the chemical species as input, researchers are studying alloy bility at finite temperatures and computing tion phase diagrams. as an ple, the figure on the left below displays the experimental phase diagram and the calculated stability limit of solidstate phases for the palladiumrhodium system. the agreement between experiment and calculation (based on the ringakohnrostoker approach for disordered alloys) underscores the potential usefulness of quantum calculations in materials ment. the challenge for the future will be to apply these algorithms to multicomponent systems and to compute similar phase diagrams for complex engineering alloys. in order to meet this challenge, and to profit from the benefits of erated alloy development, computers are essential. for ple, based on the binary phase gram calculations, it is estimated that a ternary phase diagram would require several thousand hours of present supercomputer time. alternatives have also been posed for studying alloy phase bility at finite temperatures. for stance, with the increased tational speed and memory rently available it is possible to culate, for a given alloy system, the total energies of a large ber of ordered compounds with ferent compositions and crystal structures. from these total gies effective atomic potentials can palladiumrhodium alloy phase diagram 400 d + /1 600 2000 .... .... 1800 ·:::> :::;.· 1000 ł ł 800 \, w 600 ' a.. ł' 400 ł ' w 200 g 500 ibe obtained for the disordered loys: and with the potentials, the temperaturecomposition phase diagram can be computed. an lustration is the phase diagram for the lnpgap system, shown on the right below, which was obtained ing the cluster variation method and a firstprinciples tial approach to calculate the total energies of five highsymmetry dered compounds. these tions offer convincing evidence for the existence of ordered phases in lngap semiconductor alloys. in the future the ability to compute phase diagrams is also likely to have considerable impact on the development of advanced materials based on metastable phases. though metastable phases are tentially useful, they are particularly difficult to obtain with conventional experimental techniques. in fact, metastable phases are usually tained in the laboratory only through extraordinary processing efforts, such as very rapid cooling or epitaxial growth. puters thus offer a costeffective approach for the systematic gation of these novel materials. d+d /j+y y+d ..... 300 ..... ............ 0 20 40 60 80 100 rh concentration (at.%) supercomputer calculations (triangles) of the phase gram of pdrh alloys are in excellent agreement with periment (solld and dashed curves). 0.0 0.2 0.4 0.6 ob 1.0 lnp composition x gap flrstprlnclples calculations of the phase diagram of lnpgap semiconductor alloys reveal the existence of ordered phases (regions labeled (3, 'y· 8). these found phases are expected to impact the tor industry slgnlflcantiy. 17 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.sige layers offer alternatives with the economic advantages of silicon łłł pure si pure ge germanium fraction (x) the calculated energy band gap for ge(x)sl(1x) semiconductor layers indicates what ge fraction is needed for maximum optical efficiency. per curve: unstrained material; lower curve: strainedlayer epitaxy on con substrates. although silicon is a poor light emitter because of its indirect band gap, it has definite economic advantages over other materials. this fact, together with the advantages of combining optical and electronic functions on the same chip, is currently motivating the "bandgap engineering" techniques being applied to silicon alloys. one concept that shows promise is to form an alloy of si and ge on the surface of a si substrate. for a sige alloy to match. the minimumloss wavelength in optical fibers, its band gap must be below about 0.85 ev. the upper curve in the figure to the left shows the variation in the band gap of pure sige alloys as a function of concentration. it implies concentrations of at least 50% ge are needed. the lattice constant of ge is 4% greater than that of silicon, ever, and even in the 50% concentration range the sige lattice is 2% larger than silicon. when the 5050 sige alloy is grown on a si surface, this mismatch is large enough to produce an enormous number of łmisfit" dislocations at the sigesi interface. this phenomenon is known as mensurate epitaxial growth. although poorly understood, these defects are known to be catastrophic to optical processes. fortunately, sufficiently thin layers of sige can be grown on si as a result of the natural compression of the spacing between atoms along the plane of the interface with si, along with expansion perpendicular to the face (see figure below). this technique produces commensurate or "strainedlayer" epitaxy and eliminates the deleterious dislocations. an important question is whether this higher quality strainedlayer epitaxy can be maintained for thicknesses large enough to be useful in device tronics, and if so, whether these layers remain stable over time. in addition to eliminating misfit dislocations, strainedlayer epitaxy also sults in an even greater shift in the bandgap energy per ge atom added to the sige alloy, as shown by lower curves in the upper figure: a 20% concentration of ge will shift the band gap to the 0.85ev range. the quired lattice mismatch is then reduced to only 0.8%. however, to fulfill the promise of strainlayer superlattices as technologically important for future semiconductor devices, scientists need a better understanding of these materials and novel tools to model them. ffi i r i fe l r epitaxial layer unstrained + substrate crystal 11111111111 strained when a sl(50)ge(50) layer is ordinarily grown on a si substrate, the mismatch in lattice constants produces undealrable misfit dlslocatlona. the aolutlon to this problem is strainedlayer epitaxy. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.computer simulation of the growth of sige films is vital to this technology ł ł ł it a thin film of sige is grown on a si substrate, it begins as an epitaxial layer without misfit dislocations. with continued growth there is a critical thickness beyond which these rious dislocations are spontaneously generated. this thickness depends on the intrinsic lattice mismatch between the si substrate and the alloy, and can be controlled by the alloy sition. various continuum models of solids and dislocations led initially to the concept that misfit dislocations are spontaneously generated whenever the energy expended in their tion equals or exceeds the liberated strain energy in the epitaxial layer. although these continuum models appeared to provide qualitative standing. they differed dramatically in their quantitative results. it was not clear which model should be trusted for very thin layers of atomistic dimensions, and even where one was trusted. if its prediction of absolute layer stability applied to the real strainedlayer superlattice (which could be in a metastable state). progress was made after a sufficiently large layer could be modeled on a supercomputer. the supercomputer simulations vided two important answers. first, only one of the continuum models captures the correct physics, but its predictions become inaccurate at er thicknesses of 2 mm and less (see figure on right). second, epitaxial ers produced by molecularbeam epitaxy are actually metastable to much larger thicknesses than the critical thickness for absolute stability. this latter recognition has evolved to a concept of critical thickness for metastability, which is controlled not only by the lattice mismatch but also by the temperature that determines the thermally activated motion of locations from the substrate material to the epitaxial layer. even though the supercomputer has played a vital role in this research and development effort. further vances will likely make it an pensable tool. atomistic tions of more complicated processes are being pursued with more realistic interatomic tials, and firstprinciples tions for the bandgap structure will have to be done in greater detail. \ ,,  continuum model a . continuum model b 1<>3 \ ł ł ł ł continuum model c ·. atomistic calculation \ \ \0 . 0 experiment <si ge/ as> en ł \ \ experiment ł \ <lngaas/gaas> en . w ł " z ł ł 1()2 . 0 ł . :c ł " ił ··. ł "· ...j ł ł .. ł ""' j:: ł £c ł ....... ... ł .............. '\ 0 ł ł .............. ł 101 ł .....:ł ł ł ł . 0 2 3 4 5 6 mismatch (percent> the crltlcal thickness of a strainedlayer heterostructure is the maximum overlayer thickness for which the resulting structure is thermodynamlcally stable. thinner structures can be confidently assumed to be physically robust in appllcatlons, whereas longterm stability is questionable for thicker overlayers. the figure compares a recent atomistic computer calculation of the crltlcal thickness for siliconilkł strainedlayer structures with mental data and three continuum models. the atomistic calculation confirms one continuum model for large thicknesses and indicates that the structures are considerably less stable than predicted. this destabilization can be significant in considering potential applications. 19 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.the vexing problems with polymeric liquid rows ł ł ł 20 the need to produce fibers and extrude parts is found in almost every sector of the manufacturing industry. for polymers, both operations take place in the liquid state. currently there is no reliable flow model to help design the necessary equipment. ordinary fluids (like water) can be described by a constant viscosity that does not depend on the fluid velocity. such fluids are called newtonian. polymeric fluids are viscoelastic, which means that fluid deformation erns the local stress and viscosity. these fluids are decidedly newtonian and exhibit flow phenomena strikingly different from those countered with ordinary fluids. to predict these unusual phenomena (and thus enable the chemical engineer to control them) has so far been a most vexing problem. there are two fundamental issues at the root of this problem. first, the constitutive law that determines the viscosity as a function of flow velocity gradients is not known a priori for either polymer melts or polymer tions. second, polymer flow problems are highly nonlinear and can only be solved by numerical approximation methods. one such approximation is based on dividing the fluid into many small but finite elements. for most finite element calculations, the finer the mesh, the more accurate the proximation. for polymer flows, however, the computed velocity fields are often uncertain, and it has not been clear whether the uncertainty is due to numerical artifacts or the fact that the constitutive law does not rectly describe the actual flow properties. comparisons between computed and experimentally observed flow patterns have led to inconclusive results. and, as shown on the facing page, they have even led to misconceptions and erroneous beliefs. the causes are just now beginning to be unraveled. polymeric flow through an abrupt contraction has been dlfflcult to model. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.benchmark supercomputer calculations have provided unique guidance to polymeric flow theory ł ł ł in ordinary fluid flow, an instability such as the onset of turbulence is characterized by a dimensionless number called the reynolds ber. in polymeric fluid flow there are also instabilities characterized by reynolds numbers, but there are additional instabilities that are characterized by other critical bers. one such instability occurs when .a polymeric fluid flows through an abrupt constriction. here the crucial quantity izing flow stability is called the weissenberg number. it is a ure of (a) the rate at which stresses in a fluid build up due to flow constriction and (b) the rate by which the viscous flow relaxes these stresses. increase in mass flow raises the weissenberg ber to a critical value, beyond which the flow becomes unstable and irregular. when this flow problem was first solved with an intermediate finite element mesh for a polymeric fluid modeled by the simplest possible extension of newton's flow law, the critical weissenberg numbers 1.0 critical weissenberg 0.5 number cpu time on 0 100 cray xmp 10 cin hours> 1 ....... 0.005 approached an apparent totic value between 0. 5 and 0. 6 (see figure below). this asymptotic value was considered to be real, in particular because it was similar to the value for a newtonian fluid. however, using a supercomputer with a significantly refined mesh, the critical weissenberg number was predicted to approach zero! (an unphysical result). this problem also demonstrates that nary computers are not only ipable of handling nonnewtonian flow, but they can even yield leading answers and misguide search efforts. the discovery of this breakdown of the critical weissenberg numbers initiated much research and sive computer calculations that were only possible with computers. researchers have cluded that the constitutive law does not adequately model the viscoelastic flow properties and the boundary slippage at sharp ners. moreover, the apparent stabilization of the critical weissenberg number at intermediate mesh rei 0.02 0.05 i finements indicates that present finite element techniques are ill suited to deal with abrupt flow discontinuities. there have been two major lenges in this relatively new field of nonnewtonian fluid flow. the first was to derive the actual form of the constitutive law from a lar theory of the polymeric fluid. although this has now been complished, the fundamental theory results in highly dimensional transport equations that require massive parallel computers for their solution. fortunately, such ers are now becoming available. the second challengethe cal solution of actual, sional flow problemsremains. new algorithms and numerical schemes are needed that go far beyond traditional methods; today's supercomputers are already taxed to their limits by twodimensional flow problems. more powerful supercomputers are needed to solve real, threedimensional flows encountered in polymer processing. i i 0.20 0.25 size of corner element by revealing that a newtonian polymeric fluld model ylelda unphyalcal reaulta, supercomputer calculatlona have onstrated their value aa a methodology for evaluating new models in thla fleld. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.the pervasive nature of adhesion. ł ł adhesion is an integral part of diverse technologies, such as those involved with friction and wear, crack formation in materials, the ance of glues and switch contacts, and the integrity and packaging of thinfilm devices like integrated circuits. the photographs below typify the adhesion problems that u.s. industry must solve regularly. despite the widespread character of adhesion phenomena, specific solutions are found primarily by small groups of engineers or scientists working for the industrial firms that encounter adhesive failure. often these solutions are not recorded in the literature. and consequently the detailed mechanisms of basic adhesion are largely missing. some examples of basic questions can be listed. where does an interface fail, and how does this depend on the chemical structure, mechanical behavior and stress levels within the interface? how does the adhesive force depend on interfacial separation? while encouraging progress has been made recently through new experimental probes of interfacial forces, effects such as elastic tion and even interfacial defects are more readily included in computer simulations than isolated in experiment. much of the future progress in adhesion research depends on advances in computer speed and new approaches to computer modeling of adhesion and its failure. vapordeposited chromium films exhibit residual ses that are compressive at the substrate and tensile at the surface. this example shows spontaneous tlon of a 400nm chromium/sonm copper film at the perglass substrate where bonding is poor. from proc. 1987 emsa, ©1987 san francisco press, inc., by sion. oblique deposition results in highly anisotropic stresses in chromium films, causing them to spit and curl into hoops. because chromium bonds very well to glass, fracture ally occurs in the glass substrate rather than at the face. reprinted with permission of the materials research society. 22 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.a universal adhesive energy relation was discovered by supercomputing ł . . when two clean metal surfaces are brought into intimate contact, strong bimetallic interactions can occur. these interactions can be extremely strong because electrons can be exchanged between the two surfaces, forming the kinds of bonds present in bulk metals. this significant electronic rearrangement requires a fully quantum treatment of the bimetallic interface, in which the potential energy is determined by wave functions that are selves solutions to the schroedinger equation, i.e., the calculation must be selfconsistent. that and the loss of symmetry at the interface have limited tions of adhesive interactions. recently, the total energy as a function of separation distance between surfaces was computed for a series of bimetallic contacts. for this calculation two (infinitely thick) solids were "brought" into intimate contact, and a fully consistent calculation of the elect; 0.2 a: w z w w 0.4 > c;; w i c < 0.6 c w ...j cs en 0.8 1.0 1 0 2 3 4 tronic structure and total energy was performed for each interfacial separation of the surfaces. the range of strong adhesive forces was found to be about one planar spacing. in looking for trends, researchers found a simple scaling of the energyseparation curves. the energies were scaled by the energy value at the mum of the curve (the equilibrium point) , and the separation was scaled by a number such that the curvature at the minimum was the same for all scaled curves. results for ten bimetallic contacts are shown on the left below. the adhesive energies scale closely onto a single curve, i.e., there is a universal energy relation for sion. this unexpected result lated a search for universality in other forms of matter; typical sults are seen on the right. there is a single energy relation that describes cohesion in bulk denum, oxygen chemisorbed on aluminum, adhesion of the alumi0.2 ts cc o alal w z o znzn w 0.4 e:,. mgmg (!) z 0 nana i5 7 alzn z ci5 t.. almg c 0.6 d alna w ...j o mgna cs a o znna en 0.8 o znmg 1.0 0 5 6 7 8 numzinc interface, and the getics of the hydrogen molecular ion. this discovery of ·an important characteristic of nature could not have been revealed without the extensive numerical computations possible on a modern puter. nonetheless, these tions are limited to rigid adhesion in which the crystalline structure is not allowed to distort. including distortion requires an nitude increase in computational capability (or large blocks of time on current supercomputers); the next generation of computers will greatly simplify this task. including impurities in the boundaries will require even greater capability although it could also be attempted with present resources. including the effects of lubricants calls for massive computational capabilities that allow electronic structure culations to be coupled with the molecular dynamics of polymer flow. ł h; (molecule) o alzn (interface) a 0 (chemisorbed) t> mo (bulk) 2 4 6 8 scaled separation scaled separation extensive numerlcal computationł on a supercomputer revealed a unlversal scallng relatlon for adhesion. additional computations revealed a unlversal scaling latlon for molecular ion energetics, adhesion. sorptlon, and bulk cohesion. 23 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.optoelectronic materials are key elements . . . superlatiice period microscopic latiice period +i f.ł ł ł ł ł o o o o o o ł ł ł ł łłłł000000łłłłł łłłoooooołłłłło łł000000łłłłł00 łłoooooołłłłłoo< ł000000łłłłł000 000000łłłłł0000 00000łłłłł00000 00000łłłłł00000 00000łłłłł00000 00000łłłłł00000 00000łłłłł00000 00000łłłłł00000 00000łłłłł00000 00000łłłłł00000 00000łłłłł00000 an important new material is the solld state superlattlce. consisting of alternating layers of semiconducting material, it has electronic properties different from those of either of its constituent materials. type i electrons localized vb /in gaas \ silicon is the mainstay of presentday semiconductor technology, but fortunately it cannot efficiently convert electrical signals to light signals cause of its indirect band gap. on the other hand, gallium arsenide (gaas) efficiently emits coherent light at 0.88 µm (nearinfrared). although this initiated a technological revolution, 0.88 µm is not the optimum length for many purposes. for example, optical fibers have their lowest loss per kilometer at 1.55 µm. new materials are being sought where band gaps are tailored to these and other needs. one way of doing n bandgap engineering" of these needed materials is through the use of superlattices. superlattices (see figure on left) consist of alternating layers of ductors with different band gaps, which split the valence band (vb) and conduction band (cb) into minibands separated by minigaps. gaas is often chosen for one layer (because of its directbandgap optical ties), with aias or ga1xalx chosen for the second layer (each has a larger band gap than gaas). the properties of the final composite heterostructure differ from those of either of the component materials. the superlattice band gap can be tailored by varying the concentration of al and the thickness of the layers. when the number of layers in the superlattice period is large (greater than about 10), the band gaps resemble those of the constituents, and a type i superlattice is said to have formed. when the number of layers in the superlattice period is small (less than about 10), the conduction band of the aias substructure is brought down below that of gaas, and a type ii superlattice forms (see figure below). increasingly more complicated heterostructural devices are being signed. ultra thin layer upon ultra thin layer of materials can be formed by chemical vapor deposition or molecular beam epitaxy, making the need to understand these structures on an atomistic scale increasingly more portant. cb vb ,,..,r""'lr., .. j i i ' i i i i . . ' . de localization of electrons i '\ depending on the number of layers in the superlattlce period, a type i or type ii superlattlce forms. the band gaps of properly designed type ii superlattlce should make them ideal optoelectronic materials. 24 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.the electronic properties of a superlattice can be designed by a supercomputer . . . bandstructure engineering can now be done on supercomputers. although some of the properties of superlattices were first predicted from quantum arguments, it was impossible to compute bandgap alignment between two ducting atomic layers before very largescale computers became available. only recently has the full power of quantum theory been applied to the design of these novel materials. selfconsistent calculations (based on local density theory) are being used to study gaasnaiasn lattices. the calculations are formed as a function of n, the number of atomic layers in each minilayer of the superlattice. the lattice mismatch between gaas and aias is known to be only 0.5%, thus eliminating interfacial defects from the calculation (see sion of sige layers on pages 1819). the calculations predict that the qualitative features of the tion of the valence band to the gaas region are not substantially affected by the number of atomic layers in each period. however, the bottom of the conduction band (the lowest unoccupied level an electron must reach in order to conduct electricity) is quantitatively and qualitatively changed by this lattice period. for large n (>10), the band gap lies within the gaas substructure oust as it does for bulk lattices), as depicted by e 1 in the figure at the bottom of the preceding page. the calculations also show that for n < 10, the conduction band of the aias structure is brought down below that of gaas, as depicted by eu. the figure to the right plots the calculated charge density ated with the highest occupied valence band state for 2, 3, and 4 atomic layer superlattices. for n = 2 there is virtually no ence for the electrons on either the gaas or aias sublattice. as n creases. there is significant ization of the electron charge in the gaas region. this localization is consistent with a barrier model for the highest valence band electrons. for large n there is a small w age" across the barrier from the gaas to the aias region, but the leakage accounts for only a small fraction of the total thickness of the layer. for small n, the leakage is across nearly the entire sublattice and hence the localization disappears. similar quantum calculations on sige superlattices must include strain effects because of the mous (4%) lattice mismatch. the results show that the band nuities depend strongly on the specific strain conditions. the calculations have been tended to predict the phase ity to be expected when the atomic layers are formed. molecular berm epitaxy permits the superlattice to be constructed layer by layer, but diffusion of, for example, ga into the aias layer could lead to the formation of a disordered structure, ga1x alxas. the interface tween the two ordered structures would then be removed along with its value as a device. for x = 0.5, the calculations indicate that the ordered heterostructure is ferred by 0.06 ev. the ability to tailor band gaps to technological need has massive economic implications. the consuming and costly error approach can be replaced by supercomputer quantum theoretical calculations that guide the neering of new materials. fl) a: w n i ga al ga ga ga gaas al i ga ga al ga aias charge density calculations for a gaasnaiasn superlattlce, as a tion of the number of layers n, are leading to a new understanding of these novel materials. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.silicon oxidation is a crucial process in advanced microelectronics development ł ł ł 26 in comparison with other semiconductors, silicon is distinguished by the ease with which a chemically stable oxide can be grown on its surface and by the almost perfect nature of the electrical characteristics of si02si terfaces for microelectronics applications. these characteristics have been and continue to be largely responsible for the domination of semiconductor (mos) technology in electronics. in the rapid and highly competitive world of microelectronics development, recent trends toward smaller and highly nonplanar (threedimensional) device structures have made the oxidation of shaped silicon surfaces crucial. many unexpected and critical phenomena have been uncovered in these new device tries, whose precise control in the manufacturing of future microcircuits may well give u.s. industry a competitive edge. it is now clear that the stresses produced by volume expansion during dation will cause viscous flow in the oxide film, influence oxidant diffusion (and thereby film growth), and affect the shape and the electrical properties of the device structure. as the si02 dielectric layer in mos structures becomes less than 50 atomic layers thick, these stress effects must be precisely predicted and controlled in every part of a tronic device, and this can only be accomplished with the help of computers. an example where nonplanar thin oxides are critically important is for namic random access memories (drams). the figure below shows the cross section of one storage cell in a 1megabit dram. the critical area is the corner of oxidesemiconductor interface; its properties determine to a large extent the yield and reliability of the dram. p epilayer polycrystalline si p+ substrate si02 thin insulator details of a cross section of a dynamic random access memory (dram) ing the critical trench capacitor (dark region encased in a thin insulating layer of silicon dioxide). the stresses in this layer are critical to the performance of the device. p, p+, and n indicate the type of doping in the various ductor regions. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.detailed understanding of silicon oxide layer growth is a highly leveraged opportunity for supercomputing ł ł ł the quantitative prediction of planar oxide film growth will enable us to reduce the time and cost for the design of new microcircuits and to better control the manufacturing of these circuits. although plete modeling is beyond the bilities of present supercomputers, software development is already under way. to illustrate the power of present twodimensional models the figures on the left below show computer simulations for two different fabri0.90 cation sequences. the top figure is for a singlestep oxidation process. which results in a thinner corner region with an undesirable high electric field strength of 1200 vi cm. in contrast, a twostep tion process produces a more uniform oxide layer. as shown by the bottom figure, with a cally reduced electric field strength of only 400 v/cm. twodimensional calculations such as these are assisting in the design of isolated structures in present si02 layer 0.95 si substrate 1.00 en 1.00 z 0 a: 0 1.10 >. 0.95 1.00 1.00 1.10 0.3 0.2 0.1 0.0 0.1 x in microns results of computer almulatlona of the thin slllcon dioxide insulator layer in a trench capacitor for a dram. microcircuits. these models are not, however, comprehensive enough for computerassisted design of entire dram cells and the processing steps for their manufacture. for this to be plished, more detailed physical models are required for assisted oxide film growth in three dimensions, including such nomena as oxidationenhanced diffusion and the redistribution of defects and doping atoms. computers will become an pensable tool in this endeavor. x 10 0 w 0.5 n :j < ł 12oo't 0 1100'c 0 .. 1000"c z {; 900uc + soo'"'c tax 2 0 0 1 1/r (µm1) wet oxide thickness grown on a cyllndrlcal slllcon structure, ized to the oxide thickness grown on flat (110) surface (about 0.5 µm), sus the flnal curvature of slllcon face. data points are experimental results and solid curves are model fits. these results show that misfit stresses generated in the oxide layer reduce the oxidation rate at lower temperatures. .. .. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.chemical vapor deposition is critical to semiconductor manufacturing ł ł ł 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 production cvd reactorł come in many geometrical designł. 28 chemical vapor deposition (cvd) is an increasingly important process in the united states and other countries for fabricating electronic nents. much of the emphasis on cvd in the microelectronics industry stems from the fact that it is well suited to producing silicon films, which are essential in highperformance chips. the process begins by passing an active gas, such as silane (sih4), over a substrate maintained at a temperature on the order of 1000 k. as the heat is transported away from the substrate by convection, diffusion, and radiation, the active gas chemically decomposes to form species that are very reactive on the substrate itself. upon reaction at the substrate, a solid (for example, silicon) is deposited and a volatile product (e.g., h2) is released back into the gas. although this process is employed in ductor production today, the understanding of the process is still plete. many reactors are designed by empirical rules and, as a result, are notoriously unreliable. important issues in the fabrication of semiconductors with cvd are tion rate, deposition uniformity, and sharpness of interfaces between cent layers in compound semiconductors. a designer can control the actor geometry, the flow rates of gases through the reactor, the flow rate distributions at the inlet of the reactor, the rotation rate of the heated strate in the case of a rotating disk reactor, the thermal boundary tions on the walls of the reactor, the temperature of the substrate, and the reactant gas mixture and pressure. production reactors employ a ety of geometrical designs (as illustrated on the left and below), further complicating attempts at understanding this important materials process. heated substrate <t 1000 k) in this schematic of a horizontal channel cvd reactor, a cold inlet gas (such as sih4) reactł in the zone above a heated inert material (referred to in industry as the susceptor). surface reactionł result in the depoaltlon of alllcon and the production of volatile gaaes, which exit to the right. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.computer simulation is guiding chemical vapor deposition reactor design ł ł ł a multidisciplinary effort involving quantum chemistry, chemical ics. heat transfer, fluid dynamics, numerical analysis, and computer science is focusing on chemical por deposition. the effort is an growth of research on combustion chemistry in which flow reactors, premixed flames, and diffusion flames are simulated. common to all of these are large systems of gasphase chemical reactions and complex molecular transport. the simulation requires, as input, detailed thermodynamic properties for all the reacting species, ing the source gases and all mediate and product gases. often the thermodynamic properties are not accessible by experiment, but stateoftheart quantum chemical computational techniques can termine properties accurately. rate expressions are also needed for all reaction paths, in the gas phase as well as on the surface. although the most important rate constants must be measured experimentally, rate determinations can often be difficult. fortunately, statistical action rate theory provides the cold source gas tools to make accurate estimates. once the chemical reaction anism is established, conservation principles are used to derive tions that describe the complex terplay of fluid and heat transport with the chemical processes. the exact form of these large systems of partial differential equations pends on the particular reactor configuration. typically, the system of equations is "stiff" (meaning that some of the chemical tions are very rapid, while others are very slow) . such a system quires sophisticated mathematical techniques for its solution. initially this elaborate simulation was applied to the horizontal nel reactor (previous page) where the importance of gasphase istry was first demonstrated and later confirmed by experiment. more recently a rotatingdisk tor was modeled (see below). the heated substrate rotates at 1000 rpm in a cylindrical shroud through which the reactive gases flow. the advantage is that the species and temperature gradients normal to the disk can be made to yield a highly uniform deposition. the simulations show that, at low peratures, the rate of deposition of si from sih4 is determined by the rate of reaction of sih4 on the tating surface. at intermediate peratures the ratelimiting step is the gasphase chemical kinetics, and at high temperatures it is sion. the effect of disk rotation on the rate of deposition was shown to depend on the process controlling the deposition. these simulations have had a stantial impact on commercial actor design through industrial teractions. the simulations are ing used to guide the choice of temperature, total flow, pressure, and rotation speed in a production reactor. they would not be ble without a large number of percomputer calculations, ranging from the solution of basic quantum phenomena to the detailed solution of macroscopic transport. in the future, greater puter capabilities will permit the chemistry and fluid flow to be even more closely coupled in cvd lations. other semiconductor rials processes, such as plasma etching, will also be simulated; and other processing concerns, such as the flow of particulate nants, will be accessible to tion through hierarchical modeling. the fluid flow and heat transfer in a rotating disk cvo actor have been almulated and used by lnduatry to guide growth conditionł and reactor design. 1011 l  0.0 0.1 0.2 0.3 0.4 0.5 0.6 distance above disk (cm) predicted density profileł of varloua chemical species as functionł of height above the aplnnlng disk. 29 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.increased complexity is driving device physics toward supercomputing ł ł ł 30 the continued growth of the electronics industry depends on a continued increase in packing density (number of components on a chip) so that electrons can travel over shorter and shorter distances. this trend in vice miniaturization leads to inherently threedimensional characteristics and to quantum behavior of electron transport in semiconductor materials. the development of a new semiconductor chip is greatly complicated by these effects; each design iteration can cost hundreds of thousands of dollars and take months for engineers to learn the effect of design rameter variations. fortunately, electron transport calculations in semiconductors have evolved to a level of sophistication sufficient to be of value to the device engineer. the area of transport analysis has been greatly affected by the numerical techniques of modern physics. modern monte carlo simulations now porate realistic descriptions of the relationship between an electron's ergy and its momentum (the "band structure" of the solid) instead of sorting to adjustable parameters to calculate electron transport properties in bulk materials. furthermore, the scattering (deflection) of an electron by the vibrating atoms of the solid (phonons) and the ionized impurities in the solid can be meaningfully included. the results of these simulations are in excellent agreement with experiment and have been useful in standing the physics of fast electrons in semiconductors (hot carriers). more recently, monte carlo techniques have been used in the area of real space electron transfer in order to model a number of electronic devices (see example on next page). today, supercomputer simulation can make a major economic impact on semiconductor device design. as the scale of device structures creases, however, the physical methodology must include a more tum description of the electron transport. current studies are limited to quantum calculations on simplified model systems. the inclusion of fully quantum techniques in a device modeling code will require not only an increase in computer power but also improvements in the basic physics of timedependent phenomena. c/) 10.0 a: lu .. lu 0 1.0 a: (.) ::c 0.1 .. (.!) z lu ' lu 0.01 .. c( 1970 1980 1990 2000 (!) year device sizes are approaching the quantum length scale. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.revolutionary devices can be realistically modeled ł ł ł with recent advances in ductor device simulation it is now possible to assess the advantages of novel device structures before incurring hardware development time and costs. the lated transistor concept provides an example. in a typical semiconductor switch, electrons flow from the source (at zero potential) to the drain (biased positive) while the gate is biased positive (see figure below). when the gate is switched to zero, trons no longer flow; the istic switching time is that required for the electrons under the gate to travel a distance of order d (0.5 µm) to the drain. device designers requiring ultrafast switching times have proposed a lated transistor (vmt) , which talizes on the extremely short pendicular transit times between two adjacent channels separated by a much shorter distance, d. +o gate the vmt concept involves ing from a state with both sources at 0 v, both drains at +0.3 v, and both gates at +0.8 v. at t = 0, gate a is switched to 0 and gate b to 0.6 v. electrons flowing in nel a (gaas, doped region) are suddenly accelerated to gate b, an orderofmagnitude smaller tance than that for a traditional transistor switch. such a design volves optimizing such parameters as the alx ga1x as alloy tion, degree of doping of the gaas channel a, heterostructural nesses. geometry, and operating temperature. the results of the monte carlo simulation of this device are shown to the right. the simulation includes complete band structures for the gaas and aigaas regions and the effects of all physically important scattering mechanisms (i.e., polar optical phonon scattering, lent and nonequivalent intervalley scattering, ionized impurity ing, and impact ionization). the source ( 0) ł ł ł ł ł ł ł ł ł ł ł ł ł ł ł ł drain (+) 1d1 t source a (ov) d lsource b <ov> +0.3vov i gate a i alx ga1x as łł ł ł ł łłłłłłłłłłłłłł gaas <doped>: channel a gaas <undoped>: ł channel b i alx ga1xas i gate b i +0.3v+0.6v drain a heterostructure 1 drain b heterostructure 2 electronł in a traditional tranalator (top) muat travel a distance d to turn the device off, whereas in a vmt, electrons need only travel a much shorter tanced. dark areas show how the electron density changes with time following switching. it was found that indeed there is a fast (roughly 0.2 sec) electron transfer between channels a and b but a much slower (roughly 3 picosec) bution of electrons between the channels that dominate the ing process. this redistribution depends on the impurity tions in the channel regions. the switching times for the vmt were 2.0 to 3.0 picosec at 300 kand about 2.4 picosec at 77 k, cantly shorter than for a more ventional highelectron mobility transistor (over 3. 5 picosec at 300 k and about 3. 2 picosec at 77 k) . future semiconductor device eling will rely even more heavily on supercomputing as shorter length scales involve quantum effects not dominant in today's devices. the reduction in the time and cost tween concept and finished product will be a driving force. t =ops s1 s2 t=0.1ps s1 s2 t = 3 ps s1 s2 gate a gate b gate a gate b gate a gate b 01 02 electron transfer from channel a to b in a vmt from 0 to 3 plcoaec. electron density la indicated by the degree of darkneaa in each plot. 31 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.prevention of fracture requires a detailed understanding of materials at all levels ł ł ł it is inconceivable to imagine our technological society functioning without metallic materials. their greatest attribute is that they can be fashioned to have great strength and at the same time an unmatched capacity to resist fracture. the latter property, the fracture toughness. must be carefully balanced against the yield strength, which determines the beginning of plastic deformation. many improvements and advances in the design of parts for the automobile and aircraft industries originated from the proved understanding of the mechanics and physics of fracture and its relationship to the microscopic details of complex alloys. dramatic provements in this class of materials are still to be expected, provided we can bridge the gap between macroscopic fracture mechanics and the atomistic theory of cohesion in solids. ongoing research and progress in metal plasticity and atomistic fracture physics. made possible by supercomputers, provide clear evidence that this gap is closing rapidly and that the improved understanding of all pects of the fracture of metallic materials will be of great technological significance. for a typical surface crack, shown below in the micrograph and schematically in the adjacent drawing, finite element calculations now routinely give the stress intensity factor, which is used in engineering sign. only recently, however, have computations of the plastic zone nating from the crack tip become possible. similarly. atomistic computer simulations at the very tip of a crack are only now becoming a reality. the ability to study all aspects of metal fracture simultaneously awaits a more powerful generation of supercomputers. ,, i i i i i i i i l  j 11 mm i left: micrograph of a typical aurface flaw in atalnleh ateel. right: schematic of the plaatlc zone at the tip of the flaw. the nature and extent of the plaatlc zone determineł a materlal' ł fracture realatance. 32 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.micromechanical and atomistic fracture calculations will lead to improved materials performance ł ł ł what distinguishes ductile from brittle or cleavage failure at the most fundamental level is the eration of dislocations and plastic deformation at the crack tip. ticity on a small scale accompanies even intergranular failures caused by grain boundary embrittlement and other environmentally induced failures. at this small scale, the plasticity near the crack tip is greatly affected by the discrete slip planes of the crystal lattice ture as well as by the ment of the atoms when individual dislocations emanate from the crack tip. these two aspects can now be investigated in detail with the help of supercomputers. the upper figure shows the plastic zone at the crack tip in the crystal lattice of a bodycenteredcubic metal. in these calculations, plasticity is described with the actual discrete slip systems and in accordance with nonlinear. finite deformation theory. at a more fundamental level. the atomistic scale. interatomic sion in metals can now be scribed by formulations such as the embedded atom method. which is firmly based on density functional theory. with this method. molecular dynamics simulations are being carried out on disordered systems containing many atoms and jected to external loads. the panel of three figures below. a simulation of dislocation emission from a crack, illustrates the capabilities of this method. atoms associated with the cores of dislocations are 1'2 a 35° 1'1 shaded for easy visualization. the figures represent a small selection of the sequence of events that company the crack growth during plastic tearing. these two examples represent a hierarchical approach to achieving a more fundamental understanding of fracture. this is clearly an area that will benefit directly from more capable computers. the ability to handle orders of magnitude more atoms is central to the ing of macroscopic plasticity effects. a 0.900 b 0.2000 c 0.1500 d 0.1000 contours of plastic sllp strain at the tip of a crack in a crystalline metal. the lines at 35 deg to the axis of loading are traces of crystallographic sllp tems. simulation of a dislocation (dark circles) created at a crack tip (time increases from left to right). the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.lntermetallic alloys show considerable promise as temperature materials ł . . co a.. :c cj z w a: cj) 0 ....j w >600 500 400 300 200 100 stateoftheart jet engines require materials with considerable strength at elevated temperatures. lntermetallic alloys. in contrast to conventional commercial alloys like stainless steel, often exhibit yield strengths that increase with temperature and hence are prime candidates for such cations. in addition, intermetallic alloys have good creep resistance tance to longtime, hightemperature exposure), oxidation resistance, and corrosion resistance. unfortunately, such materials tend to be brittle. the intermetallic alloy ni3ai is particularly promising since it displays stantial ductility in its single crystal form. such ductility is important in order to form the material into useful shapes and to decrease the chance of fracture in service. although ni3ai is intrinsically ductile, in polycrystalline form it is extremely brittle, which suggests that the grain boundaries are unusually weak. empirical studies have shown that small additions of elements like boron and beryllium restore the material's ductility. while ternary elements such as boron greatly improve the grain boundary properties, there is tially no understanding of how or why it works. until recently, the only viable method of identifying such powerful grain boundary strengtheners (which can be different for each alloy) was the edisonian approach of doping the alloy with every possible impurity and then measuring its erties. in addition to being timeconsuming and expensive, this approach offers relatively little hope of finding those strengtheners that work only over a relatively small composition range or when other elements need to be included. 60 r...... 50 0 z 0 40 c( cj i ' i i i i hastelloyx z 30 0 ....j i i i 316 stainless steel' 200 400 600 800 1000 temperature (°c> w w 20 ....j cj) z w 10 i 9 i i i i 0o 0.04 0.08 0.12 0.16 0.20 boron concentration ( wto/o) unlike most metals, including stainless steel and hastelloyx (a nickelbased superalloy), lntermetalllc nl3ai has a yleld strength that increases with creasing temperature. with the addition of only minute quantities of boron, polycrystalline n13ai changes from a brittle material to one that is more ductile than steel. 34 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.a hierarchy of simulation techniques aids our understanding of dopant effects on alloy brittleness ł ł ł in order to understand a non as complex as the effect of impurities on fracture in ordered alloys like ni3ai, no single tion technique or type of theoretical analysis is sufficient. the inherent difficulty is related to the necessity of treating simultaneously the quantum mechanical interaction between dissimilar atoms, the properties and atomistic structure of defects containing these atoms, and the influence of these defects on the macroscopic fracture behavior of the material. a chical approach combining all of these factors has proved important in understanding the role boron plays in increasing the ductility of ni3ai. in this approach, quantum chanical supercomputer tions provide a wide range of data, which are then employed to develop descriptions of atomic interactions suitable for largescale atomic simulations. these computer simulations yield tion on the change in the cohesive energy of grain boundaries in ni3ai following addition of boron. finally, these results are employed in a continuum description of the fracture process. in toto, this body cj ni of computer simulation and theory demonstrates that boron increases the cohesive strength of grain boundaries in ni3ai by virtue of its strong bonding to nickel atoms and its relatively small size, which allows it to fit into grain boundary interstices with little or no distortion of the grain boundary structure. not only is this simulation approach readily applicable to other types of impurity and interface problems, but it also provides qualitative understanding that will aid alloy designers in choosing appropriate microalloying elements. the left frame shows the calculated atomistic structure of a grain boundary in undoped and unstrained nl:tai. the same grain boundary opens when strained along the vertical axis (center frame). lntergranular fracture occurs; the polycryatal is said to be brittle. the same grain boundary under the same strain does not fracture when small amounts of boron are added (right frame). supercomputer calculatlona reveal that the boron increaseł the cohesive energy of grain boundaries. 35 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.stresscorrosion cracking: a neverending cause of equipment failures in the chemical and power industries ł ł ł stress stress 36 stresscorrosion cracking (scc) is a major and often catastophic failure mode in key engineering systems of modern society. such as in energy and chemical plants. sec costs the united states hundreds of millions of dollars annually, as well as the loss of essential services and products. and occasionally even lives. it is a particularly insidious phenomenon that is caused by a combination of chemical environments and applied chanical load, neither of which alone will cause failure. this phenomenon includes hydrogen embrittlement, caustic cracking. and corrosion fatigue. sec has been documented in almost all classes of structural solids: als. polymers, ceramics, and composites. methods of scc prevention have largely been empirical since the problem is extremely complex and seems to defy complete physical understanding. in metals, scc involves elastic and plastic deformation in a nearsurface region consisting of an oxide film, an interface layer, and the substrate metal. both layers contain a high concentration of defects. additional complications arise because several sec mechanisms exist and often occur simultaneously. a hensive model of sec for metallic materials is not yet possible. but recent modeling of sec in ceramics and glasses (where plastic deformation and defective surface films are absent) is providing important insights. neartip crack plasticity alomistic crack deformation bond stretching and environmental chemistry at crack tip stresscorrosion cracking requireł a hlerarchlcal model for complete understanding. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.quantum chemistry calculations unlock the secrets of slow crack growth in glass ł ł ł g1ass and ceramic oxide materials are playing key roles in the ing technologies of fiber optic works and ceramic heat engines. in many of these new applications, such as optical communication lines across ocean floors, a long service lifetime is required. neers must contend with slow crack growth in glass and ceramic materials, which is exacerbated by mechanical loads and an aqueous environment. in a concerted research effort, combined experimental tions and quantumchemical bond rupture calculations have revealed the causes of slow growth. these computations, performed on supercomputers, indicate that a distorted bond at the crack tip greatly enhances the likelihood that water molecules will bond cally and break, and this cally reduces the force required to break the siliconoxygen bond. the crack advances then by the ter of the broken silicate ring. these computations can also dict the effects of molecules other than water. for example, silicon atoms in the strained ring at the crack tip are calculated to be much more acidic than those in the stressed rings. hence all basic chemical species that the strained ring can bond to chemically will hance crack growth, assuming the site of the reactive molecule fits into the crack tip opening (whose magnitude is loaddependent) . by taking into account the rate of molecular diffusion into the crack tip region and the rate of bond breaking, it is now possible to dict relative rates of crack growth in silica glass exposed to different chemical environments. this fundamental understanding of stresscorrosion cracking in glass lays the groundwork for predicting fracture in other materials after long exposure. in metals, for ple, the local straining and surface chemistry at the crack tip are also affected by nearcracktip plasticity; supercomputing techniques are currently being developed to handle these additional complexities. water can react with glaaa, allowing it to crack more eaally. here a water molecule enters a crack (left panel) and la adsorbed (middle panel). the molecule cauaea a chemical reaction (right panel) which cleaves a alllconoxygen bond at the crack tip aa well aa an oxygenhydrogen bond in the water molecule, producing two allanol groups (hydroxyl groups attached to alllcon). aa a result the length of the crack lncreaaea by one bond rupture .. 37 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.38 using supercomputers, theoretical in 1926 erwin schroedinger wrote down his famous equation, h'i' = e'i', for which he won the nobel prize in 1933. the equation describes the fundamental behavior of electrons in molecules and solids and is ered one of the crowning achievements of the twentieth century. in 1929 p. a. m. dirac, another nobel laureate (for the relativistic equivalent of the schroedinger equation), commented: the underlying physical laws necessary for the mathematical theory of a large part of physics and the whole of chemistry are thus completely known . . . and the difficulty is only that the application of these laws leads to equations much too cated to be soluble. in the schroedinger equation the h, known as the "hamiltonian," consists of a potential energy term (for example, that due to the electrostatic interaction between electrons and protons in a molecule) and a kinetic energy term. the 'if is the "wavefunction," the fundamental solution, and e is the total energy of the system. the equation can only be solved exactly for the simplest of molecules, the hydrogen atom, which has only one electron and one proton. simplifications and approximations were and are therefore required if this fundamental equation is to be solved. theoretical physicists and chemists have approached the solution from different points of view: physicists have tended to approximate the tonian by proposing models of the true system, which are then soluble either analytically or by computer. for example, a metal can be viewed as a "gas" of electrons in a box, a highly successful model that allows insight and intuition to guide progress. quantum chemists, on the other hand, have taken a very different point of view: the hamiltonian is held sacred, and any approximations must be made to the wavefunction. they made use of a theorem that allows expansion of the wavefunction in a series of wellchosen functions, called basis functions. the theorem says they will ultimately get the right answer if they make the series big enough, that is, if they include enough basis functions. the answer is exact for a complete setan infinite numberof these basis functions. in the past, since it was easy to get the wrong answer by not including a large enough set of functions, experimentalists could confidently claim the correctness of their results when disputed by calculation, and theorists had a rug to hide under when their results were disproved. no one was turbed philosophically; after all, francis bacon taught us all to believe experiments. then in 1960, j. m. foster and s. f. boys published a calculation that predicted, in the absence of any experiments, that the ch2 (methylene) molecule is bent by 128 degrees. experimentalists, measuring the tronic spectrum of the molecule, concluded it was linear, not bent. others contended that if such theoretical methods were inadequate for such a small molecule, they were useless indeed. theorists were cowed into submission. even when subsequent calculations in 1966 and 1969 tiated the bent molecule result, theorists themselves blamed weaknesses in the calculation for the discrepancy with experiment. theory was at a low ebb. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.chemistry is outrunning experiment ł ł ł the structure of the methylene cule has been the focus of a tific controversy. theoretical chemistry came alive when, in 1970, c. m. bender and h. f. schaefer went after the ch2 molecule with theoretical techniques ously reserved for diatomic molecules. they used a "doublezeta" basis set and performed a selfconsistentfield calculation followed by what is known as ''configuration interaction,'' a method used to include electron correlation effects. they found the ch2 molecule to be bent at an angle of 135.10 degrees i they concluded that no higher level of theory would change the essential result. new experiment after new experiment began to agree. electron spin measurements first gave 136 degrees; somewhat later, 137. 7 degrees. stateoftheart theory had challenged experiment and had been vindicated. a similar problem arose with the energy difference between the two lowest lying states of the same molecule. carbon has four valence electrons, two of which it shares in covalent bonds with the hydrogens in ch2ł the two nonbonding electrons can have opposite spins, to form a singlet state, or have the same spin, forming a triplet state. everyone agreed that the triplet state was the lower of the two in energy, and the calculations gave the difference as 11.5 kilocalories per mole (a cal tech group) or 13 kilocalories per mole (a berkeley group) while the best pre1976 experiments indirectly gave 8 kilocalories per mole, in reasonable agreement. but then, in 1976, experimentalists formed a beam of ch2 and detached the extra electron with a laser, allowing direct observation of singlet as well as triplet states. they measured 19.4 kilocalories per mole, seriously outside the widest limits set by theory. the "battle lines" were drawn, with several bottles of expensive french champagne at stake. in 1978, theorists calculated the vibrational spectra of the molecule and used the results to reinterpret the measurements themselves. it was not until 1984 that the new direct measurements gave 9.0 kilocalories per mole, and the french champagne exchanged hands. there are numerous other examples in the literature of successes with quantum chemical methods. the approach was able to take extensive advantage of the revolution in supercomputer power over the last two decades and emerge as an equal with experiment, in many cases ing the more accurate result. it has the further advantage of being able to calculate species that are extremely inaccessible to experiment, such as intermediate states that form during a chemical reaction. we have been discussing chemistry here, but it should be recognized that these same techniques are being employed in materials and materials processing studies. the silane (sih4) reaction rates required for vapordeposition calculations, described elsewhere in this report, were obtained with these techniques. the calculations of pharmaceuticals cussed in this report also applied these methods, and researchers are hoping to achieve a breakthrough in understanding hightemperature superconductivity (discussed in brief later in this report) with similar techniques. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.developing new anticancer drugs has been a hitandmiss operation łłł general sequence for new drug development production, formulation, and ogy: acquisition, screening, and phase i clinical trlals clinical trials: phase i phase iv acquisition ł marine & plant ute screening ł teattube culturea mice ł dogs phase i ł human testing ł eight nci centers phase ii ł specific tumors (lung, breast, colon) phase ill ł comparison to standard theory ł statistics phaae iv same as ill but with surgical procedures included the development of more effective drugs for the treatment of cancer and aids is a painstaking process, which has evolved to its present state only in the last 5 years. the figure on the left outlines the current development sequence. in the acquisition phase, tens of thousands of natural products are gathered from a variety of plant and animal life from all over the world. special submarines seek deepsea marine life, and plankton is harvested from the oceans. these products are transformed (crushed, fermented, etc.) into a material suitable for screening. next, in preclinical screening, the collected biological products are tested for their killing effect on a cancerous tumor, e.g., an l1210/leukemia. this screening phase, which culls potentially efficacious drugs, represents a major recent advancement in the history of drug development. substances showing biological activity are tested in living organisms such as rodents to evaluate their activity against a variety of tumors with form size and predictable biologic behavior. since rodents tend to exhibit few łside effects," promising nontoxic (to rodents) substances are tested in larger animals. only 1 in 4000 of the screened compounds strates acceptable degrees of antitumor activity and safety to justify entry into human testing in a phase i trial. there are eight phase i centers in the united states, which are supported by the national cancer institute (nci) . in this phase the toxicity and mum tolerated dose are determined in human patients; some antitumor response may be observed. careful statistical studies involving at least 16 patients are performed (a response in one of the 16 implies that 20% of the general population should have a similar response). in phase ii trials, compounds with acceptable toxicity are evaluated for their effect on specific tumors (lung, breast, colon, etc.). in each study there are a great many pharmacological parameters to be varied, not the least of which are the dose and dose rate of administration. by trial and error it is determined whether treatment once a day, once a week, or continuously is preferred and in what amount. the cost for preclinical development through phase ii testing for each individual agent is more than one dred million dollars per drug. phase ill trials are randomized, controlled studies aimed at learning whether a new drug candidate is statistically better than standard therapy for cure and survival against the disease. in phase iv, surgical procedures are added to phase ill studies. currently, only 1 in 40,000 screened compounds demonstrates clinical utility! since with current intensive efforts it is estimated that about 10,000 natural products (nci figures) can be screened per year, only one new cancer drug can be developed every 4 years by this painstaking procedure. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.computerdesigned pharmaceuticals are now possible ł ł ł there are some 40 clinically useful anttc&ncer drugs presently able. among these are several agents that have demonstrated curative potential for a variety of malignancies. the ultimate nism(s) responsible for the cial and toxic effects for any one agent requires fundamental edge of the specific atomic and molecular interactions between the anticancer agent and the tumor. it is becoming increasingly apparent that supercomputers can facilitate the descriptive study of larger lecular systems such as dna or proteins. including the surrounding cellular environment. the study of lambdadimer protein binding to the dna molecule volves interactions pertaining to fundamental aspects of cancer and aids. a supercomputer simulation of the binding of this large pressor protein to a 28basepair region of dna (total 15,000 atoms) is depicted below. a hierarchy of quantum chemical techniques, from first principles to cal, was employed. allowing plex, minimumenergy molecular rearrangements to be calculated. highresolution threedimensional graphics helped unravel the tailed results. molecular mechanical simulation of the lambda dimer (blue) binding to ona (black). sodium counterlons are shown as blue spheres. an important amino aciddna action, missed by experimentalists working for years on this mental process. was also ered by supercomputer simulation. the calculations demonstrated several molecular interactions that prompted the consideration of viously unrecognized elements of biological significance. supercomputers are thus providing the key to the development of an exciting new approach to cancer therapy. the goal is to design agents that selectively inhibit gets controlling regulated cellular functions in the tumor cell. a tumorspecific "homing device" is sought that should, therefore, duce no side effects. researchers can now derive computerprojected physical properties of specific atomic modifications made to cleic acid basesfuranose and phosphate groups. these ties are coupled with chemical properties of molecular fragments from antitumor drugs with lished clinical efficacy. specific drugs are then designed based on this information and experimentally verified. the figure on the right shows the results of a supercomputer lated interaction between a fied nucleotide strand (part of a typical anticancer drug) binding to a complementary segment of dna, as would be found in a human cancer gene. many fundamental chemical ties of dna are retained in these molecules (i.e., the tary segment) ; uptake and genomic incorporation of these agents is allowed by the tumor cells. resulting in interference with gene function or production of essential proteins unique to tumor cells (the fundamental genetic problem of cancer). the calculated structure assumes a helical mation similar to that of native dna, confirming the essential dictions of the simulation. one of the most important ments in future drug design will be the integration of supercomputers and advanced molecular tional methods with prospective experimental efforts. in this way research efforts will develop more focused multidisciplinary mental approaches based on puterprojected physical properties of molecular systems. as tional methods and the tight pling of theory with experimental approaches improve, reduction in time and resources in future opment of more effective agents should be expected. rate with these developments will be gains in the understanding of atomic and molecular processes critical to normal and abnormal cellular function, along with a broadened perspective. the mate benefit of such efforts will be improved medical therapy, resulting in reduced mortality and morbidity from diseases such as cancer and aids, that will likely impact virtually all other areas of medicine. slmulatlon showing the reactive ment of an anticancer or aids drug forming a stable bond between the two strands of the abnormal ona, preventing their replication. normal cells are not affected since they lack the abnormal ona sequence. this is the essence of "targeted drugs." 41 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.welding procedures are still being determined largely by trial and error ł ł ł ł cross sections of welds in 304 less steel made with ldentlcal weld parameters but differing sulfur tent: top, 30 ppm; bottom, 150 ppm. welding is one of the most widely used industrial techniques for joining metal parts, but it involves so many complex macrostructural and microstructural variables that it remains more of an art than a science. optimum welding parameters for critical welding applications are often difficult to determine, particularly when the parts to be joined have plex shapes and the weld is susceptible to cracking. the welding signer has a number of choices, such as (for fusion welding) a variety of arc welding processes as well as laser and electron beam welding. once this choice is made, variables such as the voltage, current, weld speed, fixturing, surface preparation, and material composition must be optimized for a given weld. these are determined by trial and errorthat is, empiricallyat enormous expense. the figures on the left show one of the sensitivities facing the welding engineer. the two welds shown are in ostensibly the same material, 304 stainless steel, but differ in sulfur content by 120 parts per million (ppm). a broad, shallow weldpool region (poor penetration) is obtained for the 30ppm sample while a deeper, narrower weld zone (higher penetration) occurs for the 150ppm steel. without an understanding of such macroscopic phenomena one cannot hope to predict weld tration depths. there are subtle microscopic effects also. the figures below show, on the left, a high degree of elemental segregation that occurred during cellular solidification of a 14%ni21%cr austenitic (fee fe) alloy of similar composition. the partitioning of alloying elements between the solid and liquid during solidification is a natural occurrence in welds and often out· lines the cellular pattern created during solidification. because scopic weld properties depend on these effects, it is important to be able to understand their causes. metallurgically prepared mlcrographs of welds: left, a 14'lftnl21'lftcr austenltlc (fee fe) alloy, showing a high gree of elemental segregation; right, a ferrltlc (bee fe) alloy of slmllar, but slightly different composition, showing no segregation. the small change in composition is responsible for the large change in elemental segregation. 42 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.cslculational methods can help in all stages of weld development ł ł ł welding phenomena are difficult to study experimentally because the details of what is happening in and near the weld zone are physically inaccessible, occur at high peratures, and change quickly. even attempts at measuring these phenomena can interfere with them. often invalidating the results. numerical modeling is providing the tool needed to understand and control these processes. macroscopic calculations can now include heat conduction and fluid convection in two dimensions; it is only the limitations of today's computers that prevent full dimensional calculations from being done. the figures on the left below show two weld pools calculated using different values of surface tension to simulate the effects of sulfur on weld penetration (see previous page). the results clearly show that a deeply penetrated weld occurs in the material in which the temp conlours surface tension increases with creasing temperature (high sulfur content), in agreement with experiment. calculations are also capable of including microscopic effects such as diffusion during solidification and cooling. the figures on the right are simulations of the cellular solidification discussed on the previous page (these figures are longitudinal views of the weld, whereas the micrographs on the previous page are transverse views). nickel is forced into the liquid and is eventually trapped during the final stages of tion. in the top simulation, an fee system, solidstate diffusion is negligible and the cellular pattern is retained in the weld. in the bottom simulation, a bee system, diffusion in the solid is much more rapid and eliminates the high degree of segregation. simulations such as these are leading to more accurate models streamlines weld pool simulations show that deeper weld penetration (bottom illustration) occurs when the surface tension increases with increasing temperature. of welding phenomena and a better understanding of how to optimize weld properties. further ments will be possible as computer capabilities increase. i ni 11.8% i ni 13.3% i 22.5% i 14.1% slmulatlona of cellular solidification in nicr alloys. the shading cally represents the nickel tion. top (fee system): negligible solid state diffusion has led to a high degree of segregation; bottom (bee system): solid state diffusion has eliminated the segregation. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.forming of plasticsthe challenging search for the constitutive law for polymeric fluids . . ł jiji plastics, fibers, synthetic rubbers, coatings, and adhesives are among the class of materials known as polymers. which are longchain organic stances that have become a common part of our lives since about 1920. they are commonly formed or processed by heating to the liquid state and cooling in the desired form (see figure below). in the liquid state, polymers are both viscous (syrupy or "thick") and elastic (returning to their initial shape after being deformed). furthermore, the properties ciated with their viscoelasticity are anisotropic (different in different tions) and dependent on the flow history (the polymer fluid "remembers" the way it was treated and flowed in the past). these complications make it difficult to measure and formulate a tive law, a law that would describe its flow, for example, as it fills a die to form a plastic part or is extruded into pipe. in particular, a constitutive law relates the stress to the rate of deformation and is analogous to the stressstrain or hooke's law relation so important to solid mechanics. given the constitutive law, the same calculations done for metal forming could be done for polymer forming, thus revolutionizing an industry that designs dies by the "cut and try" method. the determination of this law is also complicated by the fact that the cosity of a polymeric melt rises extremely rapidly with its molecular weight (with the 3.4th power in fact). although in general the higher the lar weight, the better the mechanical properties of the finished product, manufacturability usually forces designers to choose lower viscosity als. consequently. tailoring polymers according to desirable flow properties for processing represents an important activity of the chemical industry. the search for a constitutive law is proceeding through the rigorous lation of a new kinetic theory of polymeric fluids (see page 25). which has led to a system of fundamental equations soluble only by a puter. some researchers are using direct supercomputer simulation to cidate the fundamental molecular mechanisms underlying such complex phenomena. on the facing page we describe simulations of " reptation. ł the slithering. motion of a polymeric chain through the surrounding "jungle" formed by the other molecules. compact and optical discs are exampleł of modern sophisticated plastics ther· moformlng. molten plastic (a polycarbonate) is forced under high pressure into a mold containing a plate inscribed with digital information. the melt must then cool in a stressfree condition to avoid birefringence. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.visualizing the molecular motion in a polymeric fluid by computer simulation ł ł ł the observation of the brownian motion of liquid droplets suspended in air provided a powerful impetus for the formulation of the statistical kinetic theory of gases. similarly, the concept of "reptation" of a polymer chain in its melt has served an important role in the formulation of simple models of polymeric fluids. yet, in contrast to brownian motion, no direct vation exists to affirm the validity of this concept. fortunately. computer simulations have recently offered an alternative for visualizing and validating reptation. although a complete molecular dynamics simulation of a dense system of entangled polymer chains is still beyond the ties of presentday puters, lattice models of densely packed and entangled polymeric chains have been analyzed by namic monte carlo methods. the motion of one particular chain is illustrated below in the sequence of three snapshots. the initial position and configuration of the one chain is indicated by a dashed line, and its subsequent positions by a solid line. for clarity the surrounding polymer chains are not shown. these simulations suggest that "tubes" formed by surrounding chains do not really exist, and that the mental picture of "reptation" is not entirely adequate. significant motion occurs perpendicular to the chain sections, with surrounding chains passing over or under to occupy the space made available. the computersimulated tion predicts a cooperative change of relative positions of neighboring chains such that the polymeric fluid density remains as uniform as possible. in addition to allowing visualization of polymer motion, this type of computer simulation also provides scaling relationships for the dependence of the selfdiffusion coefficient and the shear viscosity on the molecular weight of the polymer molecule. present simulations represent a new method for evaluating novel concepts for more concise matical descriptions of complex collective motions of polymers. such simplified models would vide a computationally simpler proach than complete molecular dynamics simulations or mensional transport equations. more powerful supercomputers will let us add increasing levels of phistication to these models. computer slmulatlon of chain motion in a concentrated polymer solution. shown are three snapshots of one chain tion (solld llnes) at consecutive times (from left to right), compared with the orlglnal chain position (dashed llnes). tensive analysls has shown no evidence for the existence of "tubeł" through which the chain moves by reptatlon. 45 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.semiconductor interfaces are critical to device performance . ł ł the behavior and growth of modern semiconductor devices depend on atomicscale properties. for example, in the layerbylayer growth of semiconductor interfaces, the quality of the junction is determined by the resulting atomic geometries in the interface (see figure below). also, the alignment of the electronic energy levels between the two semiconductors. known to be critical to device performance, is thought to depend on electron density rearrangement in the interface. the understanding and modeling of these kinds of phenomena are at the forefront of current calculational capabilities. yet it is not unrealistic to propose, for multilayer adsorbate systems of interest in microelectronic and optoelectronic device fabrication, processing studies in which atomic geometries and electronic structures would be computed as a function of process parameters. although such a program would require the availability of considerable computer resources, it would provide a predictive capability for the conductor industry. this program could also aid the semiconductor search community by giving experimentalists an online analysis "tool box." qanion qcation zlncblende (110) structure. side view the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.atomic geometry and electronic structure predictions are nearly within our grasp ł ł ł aided by a supercomputer, we can now determine surface atomic geometries for a number of conductor surfaces. this involves, for example, determining all of the geometric progerties labeled on the zincblende structure shown on the preceding page. the figure on the left below shows the results for one of these properties. obtaining these results consists of performing lowenergy electron diffraction (leed) experiments followed by a major computer effort in the form of a multiple scattering intensity analysis. for example, computing a leed intensity profile (14 beams at 100 energy points) for a single atomic configuration of the blende (110) structure requires 5 a0.9 z 5 z iii t!z o.s lnas/ c> v e. lnp / . /. //gasb i / 0.7 / ,,," 0 w gaas t> gap// 5 .... w / a: 0.6 0. q.6 0.7 ob to 15 minutes of central processing unit time on a supercomputer. as the figure shows, the cal tightbinding theory predictions compare well with the measured values across the zincblende series. the calculation of semiconductor electronic structure has been evolving rapidly in the last few years because of the realization that methods typically used with reasonable success for metals fail to give accurate electron excitation energies, such as band gaps, for semiconductors. it has been found necessary to include the electron selfenergy operator, which cates the calculation. however, these calculations can be done, 0 / / / / / / ł in sb ! 1 a: w z w 2 giving accurate band gaps and surfacestate energies as shown in the figure on the right below. shown there is the energy sion of a surface state band for a ge(111) surface with an as layer. this is of interest for studies of growth of gaas on ge. jected bulk energy bands are shaded for reference. these results suggest that methods may be in hand for a predictive ity for semiconductor device design: given sufficient computer capabilities we would be able to predict semiconductor tion energy levels and potentials, quantities that control device behavior. theory ł exp 0.9 ge(111>: as a1 . .l(a) (leed) 3 m r k geometric properties of semiconductors can now be termined with supercomputers. electronic structure calculatlona of semiconductors are evolving rapldly because supercomputerł allow greater phyalcal detall to be included. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.the committee found the field known as materials science to be so vast that, given finite time and resources, it could not hope to properly give an account of all the outstanding computational research and engineering going on in the united states. no group should feel excluded by our not having porated its work here: we found ourselves reducing the number of examples for purely practical, driven reasons. notable among the omissions are entire areas such as catalysis, beam processing, and superconductivity. superconductivitythe flow of electrical current in a material with no resistance lossesis one of the most fascinating displays of body effects in solids. exciting experimental discoveries little more than a year old changed this effect from a laboratory curiosity ble to only a few special alloys to a major technological possibility. efficient superconducting motors could replace conventional units. lossless underground mission lines could transport trical power from economical sources to distant users. larger superconducting magnets could confine plasmas in fusion reactors. with dense superconducting cuitry that would reduce signal transit times, one could build puters 1000 times faster than today's. the economic and technological importance of hightemperature superconducting materials, and the need to develop new material esses in order to utilize this ery, warrant an allencompassing effort to understand how ductivity originates in these als. elaborate quantum mechanical calculations are in progress to try to unravel some of these ies. quantum chemists (see pages 3839) are applying ab lnltlo niques to understand the role of there are a great number of examples oxygen content: in yba2cu30 x the highest transition temperature curs for x = 6. 8 for reasons as yet unexplained. solidstate theorists are using local density techniques in similar pursuits. so far, the culations have led to a possible modela suggestionfor how the electrons might pair to produce the superconducting effect. (the nobel prizewinning schrieffer theory invokes the ing of electrons through tions with lattice vibrations to plain superconductivity.) in the figure below there is a line of cu atoms along the y axis with a cancy at the origin and four ba atoms in the xz plane. the model suggests a binding energy for trons to the vacant site that leads to cooperpair formation. .. ba c::jcu models of superconductors, such as this one, are being explored ously with supercomputing. supercomputing provides a means of obtaining insight into these terials, particularly where mentation is hindered by difficulties in growing single crystals. the field is now moving so rapidly that thing we say today may be dated tomorrow. surface 1clence is ripe for computing. the equations are known, the calculational methods are sophisticated, and the rative experiments are under way using single crystals and vacuum systems. the system of gasphase molecular interactions with surfacestate electrons is highly complex, however, and large computational resources will be required for their solution. with so many fundamental parameters to vary in the costly process of signing a catalyst, supercomputers promise to make a major logical impact. catalytic reactions such as the methanation of gen and carbon monoxide are vital to the production of synthetic ral gas from coal. the formation of liquid fuels such as benzene (by, for example, the dehydrogenation of cyclohexane) depends on lysts (such as copperruthenium) and is only beginning to be understood. there are other areas we were unable to include. beam proce11· ing techniques are central to gratedcircuit device fabrication. ion implantation for introducing dopants into devices and plasma processing for etching and film deposition are excellent examples. to date, monte carlo and boltzmann transport codes have been used successfully to model range and damage butions for implantation as well as complex plasma kinetic effects. vet these particle simulations represent only portions of the problem. more complete thermal and kinetic els are needed to model a host of beam processing phenomena. for example, in ion implantation. the formation, diffusion, and cleation of endofrange defects is a critical and unsolved problem. such computations would be of potential importance for tion in compound semiconductors where defect formation is a major the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.we were unable to include łłł device limitation. plasma deposition and etching techniques involve complex physical and chemical processes. simulating the esses presents a significant lenge, but the payoff could be large in selecting the optimum conditions for damagefree removal or deposition of a wide variety of materials. in addition to extended defect eling. the thermal effects involved in beam processing offer tional opportunities for puting. beam technologies such as implantation produce damage. the damage or defects are removed by an annealing process that must be compatible with the integrity of the other materials in the structure. different annealing strategies (e.g., rapid thermal annealing) are now being used as structures become smaller and more complex. tion of the annealing process. from the atomistic level to basic heat flow. should be possible with supercomputers. at the forefront of the fabrication equipment evolution, assisted processes offer ary potential. yet these processes quantitatively and qualitatively change the nature of the surface reactions: the number of reaction species and their energetics of reaction change. supercomputing offers the only practical means to quantify the complex kinetics so that the processes can be nessed to create manufacturing equipment. nonetheless, the reward fo; this effort is tremendous. the ing of such maskless processes could dramatically reduce the need for other more complex pattern transfer equipment and hence duce overall fabrication cost. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.there is a great deal of confusion concerning the definition of a supercomputer and, more tantly, concerning the use of large and expensive craylike machines if reasonably powerful machines such as vaxes can do the computation at a fraction of the cost. a vax8800, for example, costs der $1 m, while a cray costs $25m. why not buy 10 vaxes and save all that money? the answer seriously depends on the computational requirements and, more specifically, on the gree to which the problem can be solved by independent computers working on pieces of the problem and communicating their results at the end of the calculation. many important scientific and engineering problems can be broken up in this way, and under these conditions, adding multiple independent essors is possible and economically desirable. other problems require the fastest mainframe with the est memory. a useful analogy is found in moving gravel or stones from one place to another: many small wheelbarrows will do the job. and adding more wheelbarrows (increasing capacity) will help, within limits. if, however, there is a requirement to move one large rock, a large truck ing capablllty) is called for, and no number of wheelbarrows will do. (of course, there is research going on in the computer science munity to tie wheelbarrows together to make an inexpensive truck; ers are working to break up the rock.) thus, to suppose that one can ways apply more vaxes to a lem (that is, multiply the power of one vax by the number of vaxes one wishes to use) is to forget that these are separate machines that do not act upon the problem like a single cray would. consider, for example, the series of problems illustrated on the facing page. in problem a, four independent essors only need to communicate their results at the end of the culation. a simple physical example might be the calculation of the pressure on the walls of a box taining an ideal gas such as lium. each molecule (helium atom) creates a force on the wall pendently of the others, the pre... ten vaxes do not sumption being that the individual gas molecules do not interact with one another. problem b is typified by parallelism with some degree of communication during the tion. this might physically be dicative of the helium atoms in the box being allowed to interact via shortrange forces between nearest neighbors. to generalize, there is certainly a (small) class of problems that cially configured machines can be dedicated to in order to avoid quiring more expensive craylike technology. there are even ples where special machines perform supercomputers. on the other hand. dedicated machines are less flexible than puters and may inhibit the testing of new ideas. furthermore, omy is lost if each scientific lem requires a machine with a ferent architecture. adding more vaxlike computers to an existing facility will allow more researchers to use that facility (i.e., its capacity will be increased) but will not address a given lem any better. unless that lem can be broken into small you cannot always do the job by adding more wheelbarrows: sometimes you need a large truck. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.make a cray ... pieces that need to communicate infrequently during execution and the means of interconnecting and synchronizing the machines is in hand. (there is only one strated method of interlinking such machines for a limited class of problems at the time of this ing.) the capability of the facility is therefore not improved by ing the number of vaxes and the solution to the complex problem for which the additional vax was tained is no closer. a tacit, but portant, assumption here is that if a simulation takes more than 10 hours to run on a given computer, a b c it will not generally be considered a researchanddevelopment tool. if there is less than one run per day, projects could take years to plete since many tens and even hundreds of iterations are generally needed. also, engineers and tists prefer to concentrate on a few problems and iterate as fast as they can analyze the results. it is, of course, easier to increase the capacity of a facility by ing more of the same equipment, and the great majority of researchers tend to support this because it gives everyone a little. for the problems addressed here, it is the capability of the facility that needs upgrading: we need to give a lot to a few. several of the calculations scribed in this document were itially set up on smaller machines and trial subsets of the calculations actually needed were performed. but for each of theae calculations, as well as all of the other plea in the document, the tude of the problems soon outran the capablllty of the machines, and the need for a supercomputer became clear for real progre11 to be made. whether or not a problem can be solved in a tlmely fashion by llnked vaxłł depend a on the communication mentł when the problem la divided into parallel subproblems (indicated achematlcally by boxes). in a, each proceaaor can work independently, with results being communicated only at the end. in b, some communication between acra ił required, and independent processorł may be hard pressed to compete with a supercomputer. in c, massive communication la required, and the supercomputer becomes the tool of choice. 51 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.since the early 1960s, scientists and engineers have enjoyed an explosion of supercomputer power: the capability of supercomputers has been increasing and is pected to continue to increase by approximately an order of tude every 5 to 10 years. a puter with 10 times the capability of today's fastest machine is less than a year away. in the early 1960s the workhorse of the day was the ibm, which could integrate a simple differential tion over the weekend; others took many weeks. then came control data corpor'ation's 3600 and 6600. which changed our lives by bling us to simulate, for example, radiation damage in metals and to determine the ground state of the hydrogen molecule from first ples. seymour cray, who invented the cdc 6600. introduced the cray1 in 1976; with its enlarged memory and speed, this supercomputer gave us the order of magnitude needed to calculate more complex molecules and to enter the twodimensional world of modeling. today, supercomputers are enabling us to attack previously intractable problems, a sampling of which are described in this report. moreover, calculations can be formed in minutes that only 20 years ago took 100 hours on the supercomputer of that time; and because of the increased ance of semiconductor chips and the introduction of largescale gration. the cost of the theart mainframes has remained about constant. the cray1 seems to have brought us within an order of magnitude of the maximum capability we can expect from a singleprocessor machine. but. there is no need to compute one process at a time if parts of a problem can be puted independently in parallel. the concept of computing several comcomputers with greater than 1 o times ponents of a total calculation in parallel is not newthe early eniac machine ( 1946) and the illiac (mid1970s) were based on that principle. at that time. however, there were too many other provements that could be made by less expensive means. now, as single processors approach limits set by electron speed and heat dissipation. parallel processing again becomes a viable option. the cray xmp2x series can calculate two processes at a time; the xmp4x series. four processes at a time; and the recently released xmp8x series, eight processes at a time. hence. theoretically, nearly an order of magnitude increase in computing power can be gained without improving single processor speed at all. what all this means to the als science and engineering munity is that enormous advances in an already powerful tool are not only inevitable, they are just around the corner. the cray3 with 16 processors should be available for benchmarking during the first quarter of 1989. the new et a10 features up to eight processors, new chip designs, a very large memory, and faster operation due to immersion in liquid nitrogen. ibm has recently announced a processor system. ibm is also funding steve chen in a largescale parallelprocessing initiative (chen designed the xmp while at cray) , and has a separate supercomputer project in progress; from these initiatives a 64processor machine is to emerge in the early 1990s. japanese manufacturers (nec, fujitsu, hitachi) are providing ther options: for example, nec has an sx2 single processor today that is 5 times faster than the xmp processor. and the fujitsu vp200 is close behind the sx2. the nese also intend to incorporate parallel processing and will offer a machine in serious competition with cray research by the early 1990s. no one denies that parallel essing works, but several unsettled questions remain: what is the mum number of processors, is there even an optimum, and what is the best architecture (shared versus distributed memory)? eral manufacturers are building massively parallel machines which, at the very least, will provide supercomputerlike performance for specialized dedicated projects. it is entirely possible that these sively parallel machines will outrun fewprocessor architectures in raw performance. for some tions these new architectures can provide a costeffective way to compute if the problem is properly matched to the capability. the connection machine made by thinking machines corporation is such a massively parallel machine; it has 65, 000 processors. each processing one bit of information at a time. it is clear that the quality of each processor can be enhanced as well as the number of sors. so that the gains are endless. it is not only largescale computing that has undergone a technological revolution. minicomputers, supercomputers, personal ers. and workstations are growing in power at an enormous rate. today a vaxstation 2000 or sun3, rich in graphics software to permit easy manipulation of input and output information, puts the power of a vax 11 /780 on a desk. such workstations relieve ters of tasks they may not be designed for and create a friendly environment captive to the individual. these stations allow a user to submit jobs to a remote supercomputer. do standalone processing while waiting for a job. and finally postprocess the results. it is important that supercomputers be employed in this way, doing the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.today's capability are 1 year away łłł what they are better at (number crunching) and letting more effective tools be employed for other" tasks. ideally, computers would always be connected with a host of smaller processors in a fast, efficient network. by pushing the limits of gatearray technology, using mobility gaas instead of si, cooling with liquid nitrogen to increase electron mobility, cleverly ing network architectures, and adding more processors per tem, we can expect the ance of supercomputers to tinue its colossal increases. the demand for more detailed tions and analyses of complex phenomena is driving this ogy. as it matures, it will become available to other facets of computing so that ultimately all computer users will benefit. it is impossible to imagine an end to gains in supercomputing formance. never before has there been such a powerful tool to able us to understand material processes and help the united states regain a competitive advantage. /'' // chen/ssi = ee / existing systems cray 4 / e "'ne9'sxxx / . / // \ '/nec sxx· cray / ....... z w ...j eta10 g/ie ' // nec sxx / / hitachi s820/80 <cray ymp8 cray 2 fujitsu vp400e cray xmp4 ... cray 2+ hitachi 8810/20 / " i / / e fujitsu vp400 101 a w / ( ./ e / nec sx2 " / /' e fujitsu vp200 . 100 a: 0 101 " ,,"/ \:// cray xmp2 ,,/" ,,/ cray 1 / / / cdc 7600 // . /" ,,/ / " / . / ,," 3600 / / /,," 1620,1401,1410 /" elecom future systems 1950 1960 1970 year 1980 1990 2000 supercomputing capabllltles are increasing by an order of magnitude every 5 to 10 years. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.the birth of the modern r&d laboratory the value of a multidisciplinary environment to materials research and development has been proved in a number of distinguished stances. the first dates to the late 1870s, after thomas a. edison purchased several acres in menlo park, new jersey, for a laboratory complex. edison signed a contract with western union, which agreed to pay ł 1aboratory penses incurred in perfecting tions applicable to land lines of telegraph or cables within the united states." this sounding arrangement established a significant precedent in the port of technological research and development. an independent ventor was not being paid for a new device, nor was he being asked to make specific ments on a company's apparatus; instead, a laboratory was funded for research in a general field. edison's early track record lated this new direction in rate strategy for managing logical development. as a sional inventor under contract, edison worked on storage and retrieval of telegraph messages and acoustic telegraphy (which used multiple tones sent over one wire to transmit several messages simultaneously) . serendipitously, this research stimulated edison's development of the phonograph and his contributions to the telephone. a number of western union's jor stockholders and officers, ing seen the value of supporting technological innovation in phy and then observing edison's remarkable development of the phonograph, soon committed themselves to even more extensive support for edison and his tory, in particular to pursue incan54 centers of multidisciplinary researct descent lighting. in the fall of 1878 they formed a separate research and development concern, the edison electric lighting company. with its resources edison built an office, library, and a much larger machine shop at menlo park. he also expanded the laboratory staff from around a dozen to between 50 and 70 during 1880. with the extensive support of investors, edison thus established the largest u.s. laboratory for industrial search and development at that time. the menlo park laboratory gave edison considerable advantages over other inventors. with the library, machine shop, and large team of researchers and cians, he could attack many search and development projects at the same time. instead of centrating solely on the ment of an incandescent lamp, edison simultaneously researched all phases of a complete system for electric power and lighting. he was also able to carry out an exhaustive search for the lamp filament. the laboratory mented with elements such as aluminum, boron, chromium, gold, iridium, platinum, ruthenium, silver, titanium, tungsten, tantalum, and nickel; alloys such as iridium; and organic materials such as fish line, cotton, cardboard, tar paper, celluloid, coconut hair, wood shavings, cork, and even visiting cards! success came after the fabrication and testing of some 260 lamps. the decisive advantage of this integrated research and ment approach became apparent on new year's eve 1879, when edison displayed to the public not only the new lamp but also dynamos, switches, regulators, fuses, and conductors. the advent of supercomputing ir research and development so much has been said about the manhattan projectover 10,000 books and articlesthat everyone recognizes the multidisciplinary effort it took to solve what still might be considered the world's most intensive and secret scientific challenge. less known, perhaps, il: that this project (which started what is now the department of energy) also led to the continued development of supercomputing as we know it today. in los alamos in 1943, theorists and numerical analysts formed a group (with about 25 people, some the wives of scientists) equipped with mechanical calculators to form calculations given them by physicists and engineers. a human supercomputer was created. it was recognized early on that a massive computational tool was necessary because experiments were difficult or impossible with the limited ply of nuclear materials and under the cloak of secrecy that prevailed. computation would prove to have a tremendous effect on nuclear weapons design in reducing the number of experiments. today, u.s. national laboratories use the world's largest computers to make progress in weapons design. great effort is expended at improving the design codes; that is, software is created that encompasses all known theoretical and experimental information. physicists and cal analysts improve models and algorithms; experimental data are carefully (and expensively) obtained from aboveand belowground tests and incorporated in the sign codes. all of this takes place the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.have proved their worth ł ł ł at centers where the necessary disciplines are represented and the management clearly understands the mission. crossfertilization of disciplines is maximized and the computer is used as a tool to tain the best design. the recognltlon of the need for supercomputing centers today outside the department of energy, there is increasing recognition of the value of supercomputing in a number of areas. aircraft design, weather forecasting, oil exploration and extraction, pharmaceutical design, and automobilefabrication tool design are among the most common. over 200 puters operate all over the world, 45% of which are outside the united states. the common thread between each of these industries is a multidisciplinary research center with the supercomputer as its most vital tool. nasa has established in galifornia one of the world's largest computer centers for aeronautical designthe national aeronautical simulator. the national center for atmospheric research (ncaa) in boulder, colorado, attracts tists from a variety of disciplines to use their computational facilities. the reason for the success of these centers lies foremost in the crossfertilization of ideas that comes with a multidisciplinary group. computer power itself, of course, can be provided by supercomputer centers like those set up by the national science foundation. they give isolated researchers, less of their location, access to the capabilities of large machines beit at distances that often create communications problems). though such centers provide the necessary cycles for running erful codes, researchers in related chemistry fields of research may not be nearby, a serious detriment when focusing on the most critical rameters of a problem. for ple, improving a materials process like the chemical vapor deposition of silicon from silane gas requires detailed knowledge of the heat transfer from the substrate to the gas, the fluid flow of the gas in the particular composition range of interest, and the chemical interactions of the ionized gas with different material substrates. the velocity of the gas affects the interaction between the ionized gaseous species, which affects the rate of arrival of silicon at the surface that adsorbs ent materials depending on their composition and temperature. an interdisciplinary team of searchers familiar with each other's concerns can best search for the optimum solutions to complex world problems. .. .idi electronics the supercomputer is the pivotal tool of multldlsclplinary research. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.we have come to because of its diversity, materials science has evolved into many subspecialties and splintered disciplines. much progress has been made in understanding the individual aspects of materials behavior under specific environmental and manufacturing conditions. in order to optimize their usage and to exploit their potential, many of these aspects must be integrated and quantitatively described. in general this integration has rarely been achieved, and materials development and applications have been slow endeavors. in applications of materials our inability to precisely tify materials limitations leads to overdesign, adherence to traditional materials, and "proven" methods of usage, rather than tailored and optimal designs. 1. supercomputer simulation has a strong potential to be a ful, costeffective link between materials science and ing, design, and manufacturing. the emerging advanced computers will make possible a new type of materials simulation whose key contribution will be the fostering of interdisciplinary research and opment, not only within the als fields but between these fields and other disciplines. nowhere is this more important than ing the bridge between materials, design, and manufacturing technologies. these methodologies are rapidly developing toward the point where a designer can sit at a graphics terminal and watch the impact of design modifications in real time. indeed, in some areas these bilities have already arrived. for silicon chemical vapor deposition, an engineer or technician can tinuously change the operating conditions for manufacturing using a minicomputer simulator (a tool based on physical models oped using supercomputing over nearly a decade). in the tive industry (where design and tooling cost hundreds of millions of dollars annually) supercomputing aids the design of dies for forming sheet metal for new automobile models. the advanced tions allow physically realistic metal deformation behavior to be applied to forging large, complex parts under production conditions, cantly reducing costs. as supercomputer and graphics hardware also evolve, we see a time just a few years away when computer simulation of materials and processes will play a key role in a majority of u.s. materials technologies. 2. new theoretical methods, rithms, and approaches for lyzing the individual components of complex materials systems are rapidly evolving. this is enabling methodologies for computer ulation of materials and materials processing to emerge. tal electronic structure calculations can predict the behavior of cules and solids to such types of accuracies that in many cases computation has become the method of choice over experiment. nonetheless, it must not be ten that any simulation, however sophisticated, is only as good as its supporting experimental base. even where theory has led experiment, it is experiment that proves the result. fortunately, there is a concurrent deepening of this database as computers come more capable. supercomputer algorithms now allow the simultaneous solution of hundreds of equations necessary to describe a complex process. threedimensional solutions of heat transfer, structural, dynamical, and fluid mechanical equations are possible. these methods may be highly sophisticated, such as by including microstructural evolution during deformation of a metal. transport calculations in conductors can predict electron velocity in high electric fields, properly taking account of the band structure of the solid. leading to the development of revolutionary electronic devices. the time is ripe for these more individual efforts to be synthesized into comprehensive computer ulations of materials and materials processes. 3. to exploit opportunities in computational materials science and engineering we must invest heavily in the science underlying the methodologies, in developing software to make these useful to engineers and technicians, and in providing adequate hardware to scientists and engineers at sities and in industry. fortunately, the supercomputer and performance graphics hardware needed for routine application of such simulations is continuing to become more powerful and plenti· ful while dropping in price. the realization of these benefits will require and stimulate the training of a new breed of scientists and neers, who are equally at home with chemistry, physics, and rials science as well as with model· ing and computational methods. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.several conclusions ł ł ł the unification of materials science for the purpose of improved economic use and for new applications requires supercomputers for explorations and test simulations on shorter time scales and in more costeffective ways than t:itherto practiced. we have demonstrated by the examples in this report that supercomputers are already used for materials research, development, and processing in certain applications and branches of industry. the great nomic benefits from supercomputers in materials science and technology are therefore evident but hardly exploited. this underutilization will only become more acute with the rapid advances in supercomputer development unless decisive steps are taken now. 4. for the united states to remain a leader as materials almulatlon moveł out of the laboratory and into the industrial plant, we must act decisively now to stimulate the development of thłłł odologih and to develop turnkey simulation systems for industrial plantł. although the dawn of this new age for computer simulation in materials processes is just proaching, we can already see arenas where these methodologies are having a major impact. 5. simulations can reduce design cołtł and the time from concept to market. we found two tries, in addition to automobile manufacturing, that are using supercomputers to save millions of dollars and months of design time. first, the polymer industry is designing dies by process tion, resulting in enormous savings relative to the łtrialanderrorł approach. second, the ductor industry is turning to tation as the scale of electronic devices decreases. at present, fundamental understanding of these revolutionary devices can only be achieved through simulation. supercomputing is also being applied to the design of the ment with which to manufacture semiconductor devices and components. 8. supercomputers allow us to build hlerarchlcal design tools. the design of chemical vapor deposition equipment is but one example of the growing use of hierarchical design tools among computational scientists and neers. the hierarchy includes equations and algorithms from different disciplines (i.e., try, physics, materials science, and fluid dynamics) and processes that occur over different scales in time and space. a chemical reaction takes place because electrons that rearrange on the scale of stroms lead to effects on a conductor device that may be felt on a scale of centimeters. this is the first time a tool has emerged that makes it possible to integrate complex phenomena from any number of disciplines into a useful, coherent program or code. the modules of the code can be proved as our understanding and the power of computation increase. furthermore, the designer using the code need not be an expert in the fields of science and ing represented. 7. supercomputer simulation la a powerful design tool that can increase u.s. economic tiveness today. among the most promising areas for further gress are: ł polymer forming and processing ł alloy design and ing ł ceramics design and processing ł electronic devices ł electronic device processing equipment computer hardware technology is rapidly improving; an nitude increase in capability every 5 to 1 o years continues to be the norm, with the immeasurable pects of parallel processing on the horizon. the availability of this evolving stateoftheart hardware to the engineering and scientific community is essential to the velopment and continued growth of the algorithms and methodologies that support the application of simulations to new materials nology. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.1. the committee recommends that focused multidisciplinary search initiatives in selected areas of materials science and neering be started in order to tegrate design and manufacturing with the underpinning research base. supercomputer simulation of materials phenomena is at a stage where rapid new developments in science and technological tions are possible. its early uses have been oriented toward defined applications and to a large extent have been possible only cause of prior investment in term fundamental research. tunities now exist for simulation to address complex materials nomena resulting from the tion of several discrete processes, to provide information that cannot be obtained in any other manner, and to conduct benchmark tations to validate and sometimes guide theoretical modeling, ment, and the design of new rials. thus simulation will play a vital role as an adjunct to theory and experimentation. it is essential that suitable leadership, tion, and resources be extended to mobilize and focus our vast al talent on the challenge of signing new materials and materials processes. some of the initiatives envisioned are: ł integrated alloy design and synthesis: simulation of als microstructure, synthesis, and performance is an able objective now in some elementary cases; it is a vital longrange goal for u.s. nology to retain a forefront position in highvalueadded materials and devices. one goal would be the design of new optoelectronic quantum devices, particularly involving modeling of alloy and ite semiconductor materials. ł materials processing and facturing methods: substantial progress has already been made in this area. many tunities remain to map out operating parameter regimes for producing sound versus defective materials. areas ripe for development include conductor thinfilm deposition and growth associated with integrated circuit technologies, joining methods for metals and ceramics, and forming tionsparticularly shaping and molding complex parts. ł surface and interface ena: examples of promising topics include: (a) initiation of bonding across interfaces and the effects of impurities, inelastic processes, and defects; and (b) nucleation and growth of thin filmsby processes such as molecular beam epitaxy and chemical vapor deposition. ł atomistic simulation of structural evolution: a range effort in this area is essential to learn how to form simulations that involve different time or length scales. microstructural simulations need atomicscale information to understand the molecular and chemical structure of defects. simultaneously, largescale effects (e.g., millions of cations) require shifting tion to the dynamics of defect behavior. simulations are a powerful means of ing nonequilibrium effects such as metastable alloy phases and rapid chemical reactions. we have a number 2. the committee recommends the creation of a supercomputing center for materials applications (scma). the center would vide a much needed means for moving the results of basic search into turnkey systems able for wide use in industry. ł the mission of the center would be to provide a ciplinary environment in which to create software to be ferred to industry to enhance our competitiveness. this must be a "missionoriented" facility whose management stands the role of the computer as a tool at the center. ł the center must be capable of handling proprietary information in order to attract industrial funding and to transfer the technology to an interested community. the center must be able to produce software portable to u.s. industry. smaller machines and chines with a variety of tectures must therefore be included at the center for technological transfer purposes. ł the center should become selfsupporting after an initial, properly funded startup phase. ł the center should have a permanent professional staff for continuity in addition to an extensive visiting faculty gram. projects aimed at ducing software for a given application could bring together a critical mass of talents from around the nation as well as from the site itself. longand shortterm projects would both be addressed. such a center the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.of recommendations łłł should also provide access to novel computer architectures, as required. ł the center should be geously located within an existing supercomputer center. there are significant economies of scale in hardware to be gained by such a colocation. ł the center should be geously located within an organization accustomed to an applicationsoriented, ciplinary approach to supercomputing. ł the center should be geously located near broadly based expertise in materials science and engineering. the daily interactions among a diverse scientific staff (including materials scientists. physicists, chemists, engineers, numerical analysts, and applied ticians) are of most value. 3. the committee recommends that supercomputer centers be kept at the state of the art. the momentum begun with the creation of the national supercomputer ters (for example, the nsf tive) should be accelerated by a longterm commitment to increase the availability of computer sources to a broad scientific munity. access to stateoftheart mainframes must be included as soon as they become available. supercomputer technology is ing ahead at a rate that will render them obsolete in a few short years. hence the retooling of these centers must be carefully coordinated: these are not onetime mentsthey must be continually upgraded. ł the capacity of these centers needs to be expanded as well, but we again caution against the misconception that a puter center's power be ured by the total number of arithmetic operations it can perform (capacity). what really counts is how many operations can be applied to a single problem at the same time (capability). which is measured by the power of its largest (fastest) mainframe. ł the centers should provide the capability for attacking complex computational problems that cannot be solved with less powerful machines. a valuable additional function of the ters would be to make vancedlevel simulation able to researchers not ously members of established simulation groups. ł the centers must include a commitment to upgrade their internal communications work as well as the network with the external user nity. highbandwidth cations are necessary for interactive usage and to take proper advantage of essential graphics. 4. the committee recommends the formation of multidisciplinary materials simulation groups (msgs). the formation of msgs (of several faculty spread over eral departments) will create a ergy of materials scientists with computer scientists, computational mathematicians, and experts in visualization. they will generally work closely with the scma. new ideas in technology will require vanced computational strategies, new algorithms, and unprecedented capability to analyze and visualize results. such groups and ties need to be developed and brought toward more effective tion of important scientific and technological materials research problems. 5. the committee recommends that the infrastructure of local computing ahoclated with vanced simulation be ened. solving current materials problems through simulation quires the capability of the best mainframes. yet the trial of new algorithms, development of codes, and display of results are better accomplished in a local ment. thus there needs to be ognition that the acquisition of vanced local computing capabilities is an important ingredient in the overall structure of advanced computation. 8. these initiatives should be implemented in a manner anced to preserve the research strengths that are central to the success of materials engineering and processing in the future. we can today simulate several als processes only because of the longterm fundamental research vestment in the past. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.bibliography historical background d. l. schroeder and k. c. ruhl, american antiquity 33, 162 (1968). j. needham, the development of iron and steel technology in china, the newcomen society, 1974. r. f. tylecoate, a history of metallurgy, the metals society, london, 1976, p. 2. "history of technology, ł pedia britannica: macropaeclla 18, 15th ed., 1980, pp. 2454. p. clayton, a companion to roman britain, phaidon press, 1980, p. 34. n. j. van der merwe and d. h. avery, am. sci. 70, no. 2, 146155 (1982). "materials, history before 1800, ł encyclopedia of materials science and engineering 4, pergamon press, 1986, pp. 28162839. proceedings of the conferenca on the beginnings of metals and alloys, zhengchou, china, mit press, 1986. birth of the b&o laboratorv r. v. jenkins and p. b. isreal, "thomas a. edison: flamboyant inventor,ł ieee spectrum, ber 1984, p. 74. r. conot, streak of luck, the life and leoend of thomas a. edison, seaview books, new york, 1979. metal deformation v. tvergaard and a. needleman, acta metal/. 32, 157169 (1984). r. becker, j. mech. phys. sol. 35, 577599 (1987). h. deve, s. harren, c. lough, and r. j. asaro, acta metal/. 36, 341366 ( 1988) . s. harren, h. deve, and r. j. asaro, acta metal/., to be published. ceramics d. w. petresek, d. l. mcdaniels, l. j. westfall, and j. r. stephens, metal progress, august 1986, p. 27. j. r. brockenbrough and s. suresh, j. mech. phys. sol. 35, 721742 (1987). polymers c. f. curtis and r. b. bird, phys/ca 188a, 191204 (1983). d. n. theodorou and u. suter, macromol. 18, 1467 (1985). r. keunings, "simulation of coelastic fluid flow,ł in tals of computer simulation for polymer processing, edited by c. l. tucker ill (c. hanser verlag, 1987). a. kolinski, j. skolnick, and r. yaris, j. chem. phys. 86, 1567 (1987). r. a. sorensen, w. b. liau, l. kesner, and r. h. boyd, mol. 21, 200 ( 1988). alloy development m. l. cohen, phys. today 32, no. 7, 4047, july 1979. j. s. faulkner, prag. mater. sci. 27, 1187 (1982). b. l. gyorffy and g. m. stocks, phys. rev. lett. 50, 374 (1984). d. d. johnson, f. j. pinski, and g. m. stocks, phys. rev. b 30, 5508 (1984). m. nastasi et al., j. appl. phys. 58. 10501054 (1985). d. pettifor, new scientist, 4853, may 29, 1986. a. a. mbaye, l. g. ferreira, and alex zunger, phys. rev. lett. 58, 49 (1987). semiconductor technology p. vogl, h. p. hjalmarson, and j. d. dow, j. phys. chem. solids 44, 365 (1983). j. c. bean, science 230, 127131 (1985). c. mailhiot, c. d. duke, and d. j. chadi, surf. sci. 149, 366 (1985). b. w. dodson and p. a. taylor, appl. phys. lett. 49, 15 ( 1986) and 51, 26 (1987). c. g. van de walle and r. m. tin, j. vac. sci. technol. b 4, 1055 (1986). c. b. duke, in surface properties of electronic materials, edited by d. a. king and d. p. woodruff (elsevier, amsterdam, 1987). i. c. kiziliyalli and k. hess, pan. j. appl. phys. 26, 1519 (1987). a. m. glass, science 235, 1003 (1987). v. narayanamurti, science 235, 1023 (1987). j. d. meindl, sc/. am. 257, 78 (1987). m. s. hybertsen and s. g. louie, phys. rev. lett. 58, 1551 (1987). p. sutarja, w. g. oldam, and d. b. kao, in proceedings of the international electron density meeting, washington, dc, decem· ber 69, 1987, ieee (1988), pp. 264267; w. p. noble, a. bryant, and s. h. voldman, ibid., pp. 340343. the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.adhesion r. m. cannon, r. m. fisher, and a. g. evans, mater. res. soc. symp. proc. 54, 799804 (1986). ·panel report on lnterfacial ing and adhesion,ł mater. sci. eng. 83, 169234 (1986). j. ferrante and j. r. smith, phys. rev. b 31, 3427 (1985); see also p. vinet, j. r. smith, j. ferrante, and j. h. ross, phys. rev. 8 35, 1945 ( 1987) , and references therein. r. m. fisher, in proceedings of the 45th annual meeting of the electron microscopy society fo america, g. w. bailey, ed., san francisco press, 1987, pp. 236237. chemical vapor deposition m. e. coltrin, r. j. kee, and j. a. miller, j. electrochem. soc. 131, 425434 (1984), and 133, 12061213 (1986). p. glarborg, j. a. miller, and a. j. kee, combustion and flame 85, no. 2, 177 (1986). a. j. kee, l. a. petzold, m. 0. stnooke, and j. f. grear, in multiple nme scales, academic press (1985). w. g. breiland, m. e. coltrin, and p. ho. j. appl. phys. 59, 32673273 ( 1986) . fundamental fracture mechanisms m. i. baskas and m. s. daw, in computer simulation in materials science, edited by a. j. arsenault, j. r. beeler, jr., and d. m. ling, asm int., metals park, ohio (1988), p.137. lntermetalllc alloys p. h. thornton, a. g. davies, and t. l. johnston, meta//. trans. 1, 207218, january 1970. m nastasi et al., j. appl. phys. 57, 1049 (1985). j. j. eberhardt, p. j. hay, and j. a. carpenter, jr., mater. res. soc. symp. proc. 83, 191 (1985). c. t. liu and v. k. sikka, j. metals 38, 19 (1986). c. t. liu, oak ridge national laboratory review 19, no. 3, 42 (1986). s. p. chen, a. f. voter, and d. j. srolovitz, scripts metal/. 20, 1389 (1986). stress corrosion cracking t. a. michalske and b. c. bunker, sci. am. 257, 122 (1987). welding m. p. kanouff, in proceedings of the 5th international conference on numerical methods and thermal problems, montreal, canada, june 29july 3, 1987, pineridge press, swansea, u.k. (1987), pp. 1526. m. p. kanouff, paper no. aiaa871443, 19th a/aa conference on fluid dynamics, plasma ics, and lasers, honolulu, hawaii, june 810, 1987, aiaa (1987). j. a. brooks and m. i. baskas, in proceedings of the international conference on trends in welding research, edited by s. a. david, asm international, 1987, p. 93. pharmaceuticals s. j. weiner, p. a. kollman, d. t. nguyen, and d. a. case, j. comp. chem. 7, 230252 (1988). j. a. mccammon, science 238, 486491 (1987). p. a. bash, u. c. singh, a. langridge, and p. a. kollmann, science 238, 564568 (1987). the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.workshop on advanced computation and simulation of complex materials phenomenatechnical presentations topic i thermodynamics, structures, and defects m. muthukumar simulation of phase transformations and dynamics in polymers jeffery skolnick current state of computations in polymer physics jorge hirsch simulation of tum manybody phenomena in solids malcolm stocks ab lnitio theory of phase stablllty topic ii materials synthesis and processing thomas stoughton simulation of metal deformation by arbitrary 3d tool surfaces robert brown large scale tation in materials processing michel dupuis recent scientific and engineering research on the lcap parallel supercomputer at ibmkingston david wood first principles ca/cus lations of alloy phase diagrams anthony hopflnger applications of . computeraided molecular modeling and design william johnson amorphous tal/le alloys and crystal stability topic ill electronic and transport properties of materials and devices robert dutton projections and orities for topics in electronic transport and materials thomas mcgill simulations and the design of small structures for applications in electronics william frensley numerical eling of quantum semiconductor devices steven laux selfconsistent /at/on of electron states in narrow channels john poate the next generation of materials and processing for electronic and optoelectronic technologies: role of computation topic iv mechanical properties and mechanics of materials owen richmond dirlchletvoroni space tesselations for ing polyphase and polycrystalline materials and generating finite element meshes for modeling their behavior david parks title unavailable topic v surfaces and lnterfaclal phenomena james chellkowski pseudopotential methods for the total energy of surface structures: metals and insulators charles duke prediction and perimental determination of conductor surface structures topic vi computing aspects sidney karin title unavailable ill? michael finnis the tight binding model and atomistic simulation murray daw semiempirical lations of metal surface and face structures farid abraham supercomputing in physics and chemistry david biegelsen applicability of computational methods to tural, electronic, and transport properties of amorphous semiconductors s. l. phoenix analysis and putation in network models for the time dependent failure of fibrous materials thomas weber hiking through phase space john smith total energies and electronic structures of metal interfaces the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.participants in the workshop on advanced computation and simulation of complex materials phenomena dr. farid abraham ibm almaden research center san jose, ca 951206099 dr. robert j. asaro brown university providence, ri 02912 dr. david biegelson xerox corporation palo alto, ca 94304 dr. richard h. boyd university of utah salt lake city, ut 84112 dr. robert brown massachusetts institute of technology cambridge, ma 02139 dr. james r. chelikowski exxon research & engineering co. annandale, nj 08801 dr. john connolly national science foundation washington, d. c. 20550 dr. murray daw sandia national laboratories livermore, ca 945510969 dr. charles duke xerox webster research center webster, ny 14580 dr. michel dupuis ibm corporation kingston, ny 12401 dr. robert w. dutton stanford university stanford, ca 94305 or. james eberhardt department of energy washington, dc 20585 dr. michael finnis aereharwell oxfordshire, ox 11 ora england dr. william r. frensley texas instruments dallas, tx 75265 dr. william a. goddard, ill (nas) galifomia institute of technology pasadena, ca 91125 dr. jorge e. hirsch university of san diego la jolla, ca 92092 dr. anthony j. hopfinger university of illinois at chicago chicago, il 60680 or. sidney karin san diego supercomputer center san diego, ca 921385408 or. barry klein na·,,al research laboratory washington, dc 20375 dr. norman morse los alamos national laboratory los alamos, nm 87545 dr. william l. johnson galifornia institute of technology pasadena, ca 91125 dr. steven laux ibm thomas j. watson center yorktown heights, ny 10598 dr. thomas c. mcgill california institute of technology pasadena, ca 91125 dr. m. muthukumar university of massachusetts amherst, ma 01003 dr. michael ortiz brown university providence, ri 02912 dr. david parks massachusetts institute of technology cambridge, ma 02139 dr. s. leigh phoenix cornell university ithaca, ny 14853 dr. john poate at&t bell laboratories murray hill, nj 07974 dr. owen richmond aluminum company of america alcoa center, pa 15069 dr. juan m. sanchez columbia university new york, ny 10027 dr. joseph w. serene national science foundation washington, dc 20550 dr. jeffrey skolnick washington university st. louis, mo 63130 dr. john a. smith general motors research warren, ml 48090 dr. david j. srolovitz university of michigan ann arbor, ml 48109 dr. g. malcolm stocks oak ridge national laboratory oak ridge, tn 37830 dr. thomas stoughton general motors research warren, ml 48090 dr. thomas weber at&t bell laboratories murray hill, nj 07974 dr. william d. wilson sandia national laboratories livermore, ca 945510969 dr. stanley m. wolf national research council washington, dc 20418 dr. wilhelm g. wolfer sandia national laboratories livermore, ca 945510969 dr. david wood solar energy research institute golden, co 80401 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.biographical sketches of the committee members william d. wilson earned his b.s. and m.a. degrees at queens college in new york and his ph.d. degree in physics at the city university of new york. he was a research physicist at brookhaven national laboratory until joining sandia national laboratories in 1969. in 1974 he became head of the theoretical division. since 1984 he has been manager of the computation department. he is member of the american physical society. his research interests are in interatomic potentials, defects in solids, hydrogen and helium in metals, and diffusion. robert j. asaro was educated at stanford university, where he earned his b.s, m.s .ł and ph.d. degrees in materials science. he held a postdoctoral fellowship in the department of metallurgy at ohio state university and was a research scientist at ford motor company before he joined brown university, where he is now a professor of engineering. he is a member of asm international. his research interests are in the plasticity and fracture of solids, metal corrosion, environmental effects on material behavior, and theoretical and experimental studies of the mechanics of crystals. richard h. boyd received his b.sc. in chemistry at ohio state university and his ph.d. in physical chemistry from massachusetts institute of technology. he worked as a research chemist at dupont from 1955 until 1962. he was professor of chemistry at utah state university from 1962 until 1967. currently he is professor and chairman of materials science and engineering and a professor of chemical engineering at the sity of utah. he is a member of the american chemical society and the american institute of chemical engineers, and a fellow of the american physical society. his 84 research interests are in plastics, polymers and their properties, relaxation processes in crystalline polymers, and molecular ics simulations of organic cules and of processes in mers. robert w. dutton earned his b.s., m.s., and ph.d. degrees in electrical engineering at the sity of california, berkeley. he was an assistant professor at berkeley before joining the faculty at ford university, where he is a professor and director for design at the center for integrated systems. his research interests are in process device and circuit ing for integrated circuits, grated circuit simulation and characterization using computers, and integrated circuit design optimization. william a. goddard ill received his b.s. degree in engineering from the university of california, los angeles, and his ph.d. in ing science from the california institute of technology. he is currently the charles and mary ferkel professor of chemistry and applied physics at cal tech, where he is also the project director of the materials research group (nsf) . he is a member of the national academy of sciences, a fellow of the american physical society, and a member of the american chemical society and the materials research society. he has carried out research in a broad spectrum of materials, chemical, and biological areas, including catalysis, reaction mechanisms, surface chemistry, biological oxidations, superconductors, and biological and polymer simulations. juan m. sanchez received his b.s. degree in physics at the university of cordoba, argentina, and his m.s. and ph.d. degrees in materials science at the university of california, los angeles. in 1981 he joined the faculty of columbia university, where he is now sor of metallurgy and materials science in the henry krumb school of mines; he is also a staff ber of columbia's center for strategic materials. he is a ber of the metallurgical society of aime, asm international, the materials research society, and the american physical society. his research has been in thin film diffusion, kinetics of phase tion in solids, orderdisorder theory, and statistical namics and modeling of phase diagrams; in recent years one of his major efforts has been to develop and implement theories to compute, from first principles, the phase diagrams of complex neering materials. john r. smith earned his b.s. degree at toledo university and his ph.d. degree in physics at ohio state university. he served in the u.s. army at nasa's lewis search center and then did doctoral work at the university of california, san diego, before joining the general motors search laboratories. where he is now a principal research scientist. he is a fellow of the american physical society, and a member of the american vacuum society and the materials research society. his research interests are in the theory of solid surfaces, electronic and magnetic properties, and sorption; superlattices; adhesion: metalcontact electronic structure: and defects and universal features of bonding in solids. david j. srolovitz was cated at rutgers university, where he received his b.s. degree, and at the university of pennsylvania, where he earned his m.s.e. and ph.d. degrees in metallurgy and materials science. he was a doctoral research associate at the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.exxon research and engineering company before becoming a staff member at los alamos national laboratory in the theoretical division and materials science and technology division. currently he is an associate professor of materials science and engineering and applied physics at the university of michigan. his interests cover theoretical aspects of materials science and physics, including physical metallurgy, mechanics, thin films. condensed matter physics. statistical physics and computer simulation. 'w\lhelm q, wolfer received his b.s. degree in engineering physics trom the institute of technology, vienna. in 1961, his physiker from the university of stuttgart in 1965, and his ph.d. in nuc\ear engineering from the university of florida in 1969. his professional experience includes positions as research assistant in the plasma diagnostics laboratory at the university of florida; senior engineer, westinghouse advanced reactor division; research staff member in the metals and ics division, oak ridge national laboratory; and professor in the nuclear engineering department, university of wisconsin. since 1985 he has been a member of the technical staff at sandia national laboratories. he is a member of the american physical society. his research interests are in radiation effects, chemical reaction kinetics in condensed matter, mechanics of solids and fracture, and hydrogen and helium embrittlement. 65 the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.the impact of supercomputing capabilities on u.s. materials science and technologycopyright national academy of sciences. all rights reserved.