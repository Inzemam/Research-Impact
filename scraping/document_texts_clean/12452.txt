detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/12452protecting individual privacy in the struggle againstterrorists: a framework for program assessment376 pages | 6 x 9 | hardbackisbn 9780309387477 | doi 10.17226/12452committee on technical and privacy dimensions of information for terrorismprevention and other national goals; committee on law and justice; committee onnational statistics; division on behavioral and social sciences and education;computer science and telecommunications board; division on engineering andphysical sciences; national research councilprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.committee on technical and privacy dimensions of information for terrorism prevention and other national goalscommittee on law and justice and committee on national statistics division on behavioral and social sciences and educationcomputer science and telecommunications board division on engineering and physical sciencesprotecting individual  privacy in the struggle against terroristsa framework for program assessmentprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.the national academies press 500 fifth street, n.w. washington, dc 20001notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn from the councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsible for the report were chosen for their special competences and with regard for appropriate balance.support for this project was provided by the bureau of transportation statistics, with assistance from the national science foundation under sponsor award number ses0112521; the department of homeland security, with assistance from the national science foundation under sponsor award number ses0411897; the national center for education statistics, with assistance from the national science foundation under sponsor award number sbr0453930; and the national science foundation under sponsor award numbers srs0632055 and iis0441216. additional funding was provided by the presidents™ circle communications initiative of the national academies.library of congress cataloginginpublication dataprotecting individual privacy in the struggle against terrorists : a framework for program assessment. p. cm. includes bibliographical references. isbn 9780309124881 (pbk.) š isbn 9780309124898 (pdf) 1. terrorismšunited statesšprevention. 2. surveillance detectionšunited states. 3. privacy, right ofšunited states. 4. technological innovationsšlaw and legislationšunited states. hv6432.p76 2008 363.325™163dc22 2008033554this report is available fromcommittee on law and justice orcomputer science and telecommunications boardnational research council500 fifth street, n.w.washington, dc 20001additional copies of this report are available from the national academies press, 500 fifth street, n.w., lockbox 285, washington, dc 20055; (800) 6246242 or (202) 3343313 (in the washington metropolitan area); internet, http://www.nap.edu.copyright 2008 by the national academy of sciences. all rights reserved.printed in the united states of americaprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprot, selfperpetuating society of distinguished scholars engaged in scientic and engineering research, dedicated to the furtherance of science and technology and to their use for the general welfare. upon the authority of the charter granted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientic and technical matters. dr. ralph j. cicerone is president of the national academy of sciences.the national academy of engineering was established in 1964, under the charter of the national academy of sciences, as a parallel organization of outstanding engineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsors engineering programs aimed at meeting national needs, encourages education and research, and recognizes the superior achievements of engineers. dr. charles m. vest is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy of sciences to secure the services of eminent members of appropriate professions in the examination of policy matters pertaining to the health of the public. the institute acts under the responsibility given to the national academy of sciences by its congressional charter to be an adviser to the federal government and, upon its own initiative, to identify issues of medical care, research, and education. dr. harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology with the academy™s purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both the national academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientic and engineering communities. the council is administered jointly by both academies and the institute of medicine. dr. ralph j. cicerone and dr. charles m. vest are chair and vice chair, respectively, of the national research council.www.nationalacademies.orgprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.vcommittee on technical and privacy dimensions of information for terrorism prevention and other national goalswilliam j. perry, stanford university, cochaircharles m. vest, national academy of engineering, cochairw. earl boebert, sandia national laboratoriesmichael l. brodie, verizon communicationsduncan a. brown, johns hopkins universityfred h. cate, indiana universityruth a. david, analytic services, inc.ruth m. davis, pymatuning group, inc.william h. dumouchel, lincoln technologies, inc.cynthia dwork, microsoft researchstephen e. fienberg, carnegie mellon universityrobert j. hermann, global technology partners, llcr. gil kerlikowske, seattle police departmentorin s. kerr, george washington university law schoolrobert w. levenson, university of california, berkeleytom m. mitchell, carnegie mellon universitytara o™toole, university of pittsburgh medical centerdaryl pregibon, google, inc.louise richardson, harvard universityben a. shneiderman, university of marylanddaniel j. weitzner, massachusetts institute of technologystaffbetty m. chemers, committee on law and justicecarol petrie, committee on law and justice julie anne schuck, committee on law and justicemichael l. cohen, committee on national statisticsherbert s. lin, computer science and telecommunications boardjanice m. sabuda, computer science and telecommunications board (through april 2008)protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.vicommittee on law and justice (dbasse)james q. wilson, university of california, los angeles (emeritus), chairphilip j. cook, terry sanford institute of public policy, duke university, vice chairdavid h. bayley, university of albany, state university of new yorkrichard j. bonnie, university of virginia law schoolmartha crenshaw, wesleyan universityrobert d. crutchfield, university of washingtonjohn j. diiulio, jr., university of pennsylvaniasteven n. durlauf, university of wisconsin, madisonjohn a. ferejohn, stanford universityarthur s. goldberger, university of wisconsin, madisonbruce hoffman, rand corporationrobert l. johnson, new jersey medical schooljohn h. laub, university of marylandtracey l. meares, university of chicagoterrie e. moffitt, university of londonmark h. moore, harvard universityruth peterson, ohio state universityrichard rosenfeld, university of missouriœst. louisrobert j. sampson, department of sociology, harvard universityjeremy travis, jay college of criminal justice, new yorkchristy visher, the urban institutecarol petrie, directorbetty chemers, senior program ofcerlinda depugh, program associateprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.viicommittee on national statistics (dbasse)william f. eddy, department of statistics, carnegie mellon university, chairkatharine abraham, university of marylandrobert bell, at&t research laboratorieswilliam dumouchel, lincoln technologies, inc.john haltiwanger, university of marylandv. joseph hotz, university of california, los angeleskaren kafadar, university of colorado, denver, and health sciences centerdouglas massey, princeton universityvijay nair, university of michigan, ann arborjoseph newhouse, harvard universitysamuel h. preston, university of pennsylvaniakenneth prewitt, columbia universitylouise ryan, harvard universitynora cate schaeffer, university of wisconsin, madisonalan zaslavsky, harvard university medical schoolconstance f. citro, directorprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.viiicomputer science and telecommunications board (deps)joseph f. traub, columbia university, chairprithviraj banerjee, hewlett packard companyfrederick r. chang, university of texas, austinwilliam dally, stanford universitymark e. dean, ibm almaden research centerdeborah estrin, university of california, los angeleskevin kahn, intel corporationjames kajiya, microsoft corporationrandy h. katz, university of california, berkeleyjohn e. kelly iii, ibmsara kiesler, carnegie mellon universitypeter lee, carnegie mellon universityteresa h. meng, stanford universitywilliam h. press, university of texas, austinprabhakar raghavan, yahoo! researchalfred z. spector, google, inc.robert f. sproull, sun microsystems, inc.peter szolovits, massachusetts institute of technologyandrew j. viterbi, viterbi group, llcpeter weinberger, google, inc.jon eisenberg, directorkristen r. batch, associate program ofcerrenee hawkins, financial and administrative managerherbert s. lin, chief scientistlynette i. millett, senior program ofcermorgan r. motto, program associateeric whitaker, senior program assistantfor more information on cstb, see its web site at http://www.cstb.org, write to cstb, national research council, 500 fifth street, n.w., washington, dc 20001, call (202) 3342605, or email the cstb at cstb@nas.edu.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.ixprefacein late 2005, the national research council (nrc) convened the committee on technical and privacy dimensions of information for terrorism prevention and other national goals. supported by the u.s. department of homeland security and the national science foundation, the committee was charged with addressing information needs of the government that arise in its deployment of various forms of technology for broad access to and analysis of data as it faces the challenges of terrorism prevention and threats to public health and safety. specically of interest was the nexus between terrorism prevention, technology, privacy, and other policy issues and the implications and issues involved in deploying data mining, information fusion, and behavioral surveillance technologies. the study sought to develop a conceptual framework that policy makers and the public can use to consider the utility, appropriateness, and empirical validity of data generated and analyzed by various forms of technology currently in use or planned in the near future. the committee notes that the development of this framework did not include the development of systems for preventing terrorism. by design and in response to the charge for the study, this report focuses on data mining and behavioral surveillance as the primary techniques of interest.the committee interpreted its charge as helping government policy makers to evaluate and make decisions about informationbased programs to ght terrorism or serve other important national goals, and it thus sought to provide a guide for government ofcials, policy makers, and technology developers as they continue to explore new surveillance protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.x prefacetools in the service of important national security goals. chapter 1 scopes the issues involved and introduces key concepts that are explored in much greater depth in the appendixes. chapter 2 outlines a framework for a systematic assessment of informationbased programs being considered or already in use for counterterrorist purposes (and other important national needs, such as law enforcement and public health) in terms of each program™s effectiveness and its consistency with u.s. laws and values. chapter 3 provides the committee™s conclusions and recommendations. the appendixes elaborate extensively on the scientic and technical foundations that underpin the committee™s work and the legal and organizational context in which informationbased programs necessarily operate. the committee regards the appendixes as essential elements of the report.note that although the committee heard from representatives from many government agencies, this report does not evaluate or critique any specic u.s. government program. rather, it is intended to provide policy makers with a systematic framework for thinking about existing and future operational informationbased programs, especially in a counterterrorist context.nowhere is the need for this study and the framework it proposes more apparent than in the history of the total information awareness (tia) program. indeed, the tia program and the issues it raised loomed large in the background when this committee was appointed, and although the tia program was terminated in september 2003, it is safe to say that the issues raised by this program have not been resolved in any fundamental sense. moreover, many other data mining activities supported by the u.s. government continue to raise the same issues: the potential utility of largescale databases containing personal information for counterterrorist and law enforcement purposes and the potential privacy impact of law enforcement and national security authorities using such databases. a brief history of the tia program is contained in appendix j.the committee consisted of 21 people with a broad range of expertise, including national security and counterterrorism, intelligence and counterintelligence, privacy law and information protection, organizations and organizational structure, law enforcement, statistics, information technology, cognitive psychology, terrorism, database architecture, public health, articial intelligence, databases, cryptography, machine learning and statistics, and information retrieval.from 2005 to 2007, the committee held six meetings, most of which were intended to enable it to explore a wide range of points of view. for example, briengs and other inputs were obtained from government ofcials at all levels, authorities on international law and practice relatprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.preface xiing to policy, social scientists and philosophers concerned with collection of personal data, experts on privacyenhancing technologies, business representatives concerned with the gathering and uses of personal data, and researchers who use personal data in their work. several papers were commissioned and received, as well as a number of contributed white papers.preparation of the report was undertaken on an unclassied basis. although a number of classied programs of the u.s. government make use of data mining, the fundamental principles of data mining themselves are not classied, and these principles apply to both classied and unclassied applications. thus, at the level of analysis presented in this report, the fact that some of the u.s. government™s counterterrorist programs are classied does not materially affect the analysis provided here. in addition, the u.s. government operates a variety of classied programs intended to collect data that may be used for counterterrorist purposes. however, as collection programs, they are out of the scope of this report, and all that need be noted is that they produce data relevant to the counterterrorist mission and that data mining and information fusion technologies must process.this study could not have been undertaken without the support of the government project ofcers, larry willis, u.s. department of homeland security, and larry brandt and brian d. humes, national science foundation, who recognize the complex issues involved in developing and using new technologies to respond to terrorism and other national efforts, such as law enforcement and public health, and the need to think through how this might best be done.given the scope and breath of the study, the committee beneted greatly from the willingness of many individuals to share their perspectives and expertise. we are very grateful to the following individuals for their helpful briengs on technologies for data mining and detection of deception: paul ekman, university of california, san francisco; mark frank, university of buffalo; john hollywood, rand corporation; david jensen, university of massachusetts; jeff jonas, ibm; david scott, rice university; john woodward, rand corporation; and thomas zefro, georgetown university. useful insights on the use of these technologies in the private sector were provided by scott loftnesness, glenbrook partners, and dan schutzer, financial services technical consortium. william winkler, census bureau, helped the committee understand the technologies™ potential impact on federal statistical agencies.background briengs on relevant privacy law and policy were provided by henry greely, stanford university; barry steinhardt, american civil liberties union; kim taipale, center for advanced studies in science and technology policy; and lee tien, electronic frontier foundaprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.xii prefacetion. we also beneted from the expert testimony of whiteld dife, sun microsystems; john pike, global security; and jody westby, global cyber risk, on the role of information technologies in counterterrorism. in addition to counterterrorism, the impact and implications of data mining for law enforcement and public health were important foci of the committee™s work. in the public health area, the following persons contributed to the committee™s understanding: james lawler, homeland security council, white house; farzad mostashari, new york city public health department; patricia quinlisk, state of iowa; and barry rhodes and lynn steele, centers for disease control and prevention. useful insights on the role of law enforcement in counterterrorism were provided in presentations made by roy apseloff, national media exploitation center; michael fedarcyk, federal bureau of investigation (retired); and philip reitinger, microsoft. we found extremely helpful the international perspectives of joe connell, new scotland yard (retired), and ravi ron, former head of israel™s ben gurion airport.this study also beneted considerably from briengs by government ofcials involved on a daily basis with the issues at the heart of the study. we particularly want to thank randy ferryman and admiral scott redd from the national counter terrorism center and clint c. brooks (retired) from the national security agency, who shared their vision of how the nation should conduct its counterterrorism activities while maintaining its democratic ideals. numerous staff members from the department of homeland security (dhs) also shed important light on government activities relating to terrorism prevention, including mel bernstein, timothy keefer, hyon kim, sandy landsberg, john v. lawler, tiffany lightbourn, grace mastalli, allison smith, and lisa j. walby. toby levin was particularly helpful in sharing timely and relevant information on the work of the dhs privacy ofce, and the committee appreciated the interest of the dhs data privacy and integrity advisory committee in its work and their willingness to keep members abreast of their activities and role in protecting privacy.the committee also thanks michael d. larsen of iowa state university and peter swire of ohio state university, who responded to its request for white papers, and amy corning and eleanor singer, university of michigan, who prepared an informative paper on public opinion.this study involved nrc staff from three different nrc units. we would like to thank them for their valuable assistance to this project as well as for their collegiality, which contributed to a far richer experience for all involved. betty chemers of the nrc™s committee on law and justice served as study director and organized and facilitated the meetings, michael cohen of the committee on national statistics provided technical expertise on statistical and data mining issues, and herbert protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.preface xiiilin of the computer science and telecommunications board undertook the difcult job of turning the committee™s writing contributions into a coherent whole and working with the cochairs to mediate and resolve intellectual disagreements within the committee. carol petrie provided guidance and support throughout the study process. we would also like to thank julie schuck and ted schmitt for their research assistance and jennifer bishop, barbara boyd, linda depugh, and janice sabuda for their administrative support. finally, we greatly appreciate the efforts undertaken by eugenia grohman, susan maurizi, kirsten sampson snyder, and yvonne wise to complete the review and editing processes and bring this report to fruition.charles m. vest and william j. perry, cochairscommittee on technical and privacydimensions of information for terrorismprevention and other national goalsprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.xivacknowledgment of reviewersthis report has been reviewed in draft form by individuals chosen for their diverse perspectives and technical expertise, in accordance with procedures approved by the national research council™s report review committee. the purpose of this independent review is to provide candid and critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meets institutional standards for objectivity, evidence, and responsiveness to the study charge. the review comments and draft manuscript remain condential to protect the integrity of the deliberative process. we wish to thank the following individuals for their review of this report:steve m. bellovin, columbia university,r. stephen berry, university of chicago,david l. carter, michigan state university,richard f. celeste, colorado college,hermann habermann, bureau of the u.s. census (retired),david jensen, university of massachusetts, amherst,alan f. karr, national institute of statistical sciences,diane lambert, google, inc.,butler lampson, microsoft corporation,michael d. larsen, iowa state university,lance liebman, columbia law school,patricia quinlisk, state of iowa,jerome reiter, duke university,protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.acknowledgment of reviewers xvandrew p. sage, george mason university,paul schwartz, university of california, berkeley,eugene spafford, purdue university,robert d. sparks, california medical association foundation,william o. studeman, northrop grumman mission systems, andpeter weinberger, google, inc.although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the nal draft of the report before its release. the review of this report was overseen by william h. press, university of texas at austin, and james g. march, stanford university. appointed by the national research council, they were responsible for making certain that an independent examination of this report was carried out in accordance with institutional procedures and that all review comments were carefully considered. responsibility for the nal content of this report rests entirely with the authoring committee and the institution.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.xviicontentsexecutive summary 11 scoping the issue: terrorism, privacy, and technology 7 1.1 the nature of the terrorist threat to the united states, 7 1.2 counterterrorism and privacy as an american value, 8 1.3 the role of information, 11 1.4 organizational models for terrorism and the intelligence process, 15 1.5 activities of the intelligence community and of law enforcement agencies, 17 1.6 technologies of interest in this report, 19 1.6.1 data mining, 20 1.6.2 behavioral surveillance, 24 1.7 the social and organizational context, 26 1.8 key concepts, 27 1.8.1 the meaning of privacy, 27 1.8.2 effectiveness, 29 1.8.3 law and consistency with values, 30 1.8.4 false positives, false negatives, and data quality, 35 1.8.5 oversight and prevention of abuse, 41 1.9 the need for a rational assessment process, 42protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.xviii contents2 a framework for evaluating informationbased programs to fight terrorism or serve other important national goals 44 2.1 the need for a framework for evaluating informationbased programs, 44 2.2 evaluating effectiveness, 47 2.3 evaluating consistency with u.s. law and values, 52 2.3.1 data, 53 2.3.2 programs, 54 2.3.3 administration and oversight, 56 2.4 a note for policy makers: applying the framework in the future, 57 2.5 summary of framework criteria, 59 2.5.1 for evaluating effectiveness, 59 2.5.2 for evaluating consistency with laws and values, 61 2.5.3 for developing new laws and policies, 633 conclusions and recommendations 67 3.1 basic premises, 67 3.2 conclusions regarding privacy, 71 3.2.1 protecting privacy, 71 3.2.2 distinctions between capability and intent, 75 3.3 conclusions regarding the assessment of counterterrorism programs, 75 3.4 conclusions regarding data mining, 76 3.4.1 policy and law regarding data mining, 76 3.4.2 the promise and limitations of data mining, 77 3.5 conclusions regarding deception detection and behavioral surveillance, 82 3.6 conclusions regarding statistical agencies, 84 3.7 recommendations, 86 3.7.1 systematic evaluation of every informationbased counterterrorism program, 86 3.7.2 periodic review of u.s. law, policy, and procedures for protection of privacy, 95appendixesa acronyms 105b terrorism and terrorists 111 b.1 the nature of terrorism, 111protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.contents xix b.2 some tactics of terrorism, 113 b.3 a historical perspective on terrorism, 114 b.4 explaining terrorism, 114 b.5 al qaeda and the terrorist threat to the united states, 115 b.6 terrorists and their supporting technologies, 118 b.7 looking to the future, 119c information and information technology 120 c.1 the information life cycle, 120 c.1.1 information collection, 120 c.1.2 information correction and cleaning, 121 c.1.3 information storage, 122 c.1.4 information analysis and use, 122 c.1.5 information sharing, 122 c.1.6 information monitoring, 123 c.1.7 information retention, 124 c.1.8 issues related to data linkage, 126 c.1.9 connecting the information life cycle to the framework, 126 c.2 the underlying communications and information technology, 128 c.2.1 communications technology, 128 c.2.2 information technology, 129 c.2.3 managing information technology systems and programs, 131d the life cycle of technology, systems, and programs 133e hypothetical and illustrative applications of the framework to various scenarios 137 e.1 airport security, 137 e.1.1 the threat, 137 e.1.2 a possible technological approach to addressing the threat, 138 e.1.3 possible privacy impacts, 139 e.1.4 applying the framework, 140 e.2 syndromic surveillance, 141 e.2.1 the threat, 141 e.2.2 a possible technological approach to addressing the threat, 141 e.2.3 possible privacy impacts, 142 e.2.4 applying the framework, 144protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.xx contentsf privacyrelated law and regulation: the state of the law and outstanding issues 150 f.1 the fourth amendment, 150 f.1.1 basic concepts, 150 f.1.2 machineaided searches, 151 f.1.3 searches and surveillance for national security and intelligence purposes that involve u.s. persons connected to a foreign power or that are conducted wholly outside the united states, 152 f.1.4 the millersmith exclusion of thirdparty records, 153 f.2 the electronic communications privacy act, 154 f.3 the foreign intelligence surveillance act, 155 f.4 the privacy act, 156 f.5 executive order 12333 (u.s. intelligence activities), 159 f.6 the adequacy of today™s electronic surveillance law, 160 f.7 further re˚ections from the technology and privacy advisory committee report, 164g the jurisprudence of privacy law and the need for independent oversight 166 g.1 substantive privacy rules, 167 g.1.1 privacy challenges posed by advanced surveillance and data mining, 167 g.1.2 evolution of regulation of new technologies, 172 g.1.3 new surveillance techniques that raise privacy questions unaddressed by constitutional or statutory privacy rules, 175 g.1.4 new approaches to privacy protection: collection limitation versus use limitation, 175 g.2 procedural privacy rules and the need for oversight, 176 g.2.1 oversight mechanisms of the u.s. government, 177 g.2.2 a framework for independent oversight, 179 g.2.3 applying independent oversight for government agencies to protect privacy, 182 g.2.4 collateral benets of oversight, 184h data mining and information fusion 185 h.1 the need for automated techniques for data analysis, 185 h.2 preparing the data to be mined, 189protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.contents xxi h.3 subjectbased data mining as an extension of standard investigative techniques, 192 h.4 patternbased data mining techniques as illustrations of more sophisticated approaches, 193 h.5 the evaluation of data mining techniques, 198 h.5.1 the essential difculties of evaluation, 199 h.5.2 evaluation considerations, 200 h.6 expert judgment and its role in data mining, 205 h.7 issues concerning the data available for use with data mining and the implications for counterterrorism and privacy, 207 h.8 data mining components in an informationbased counterterrorist system, 208 h.9 information fusion, 209 h.10 an operational note, 211 h.11 assessment of data mining for counterterrorism, 213i illustrative government data mining programs and activity 218 i.1 total/terrorism information awareness (tia), 219 i.2 computerassisted passenger prescreening system ii (capps ii) and secure flight, 219 i.3 multistate antiterrorism information exchange (matrix), 222 i.4 able danger, 224 i.5 analysis, dissemination, visualization, insight, and semantic enhancement (advise), 226 i.6 automated targeting system (ats), 228 i.7 the electronic surveillance program, 229 i.8 novel intelligence from massive data (nimd) program, 230 i.9 enterprise data warehouse (edw), 231 i.10 law enforcement analytic data system (netleads), 232 i.11 ice pattern analysis and information collection system (icepic), 232 i.12 intelligence and information fusion (i2f), 233 i.13 fraud detection and national security data system (fdnsds), 233 i.14 national immigration information sharing ofce (niiso), 234 i.15 financial crimes enforcement network (fincen) and bsa direct, 234 i.16 department of justice programs involving patternbased data mining, 235protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.xxii contentsj the total/terrorist information awareness program 239 j.1 a brief history, 239 j.2 a technical perspective on tia™s approach to protecting privacy, 243 j.3 assessment, 247k behavioralsurveillance techniques and technologies 250 k.1 the rationale for behavioral surveillance, 250 k.2 major behavioraldetection methods, 251 k.2.1 facial expression, 252 k.2.2 vocalization, 254 k.2.3 other muscle activity, 255 k.2.4 autonomic nervous system, 255 k.2.5 central nervous system, 257 k.3 assessing behavioralsurveillance techniques, 258 k.4 behavioral and data mining methods: similarities and differences, 259l the science and technology of privacy protection 263 l.1 the cybersecurity dimension of privacy, 263 l.2 privacypreserving data analysis, 266 l.2.1 basic concepts, 266 l.2.2 some simple ideas that do not work in practice, 268 l.2.3 private computation, 269 l.2.4 the need for rigor, 270 l.2.5 the effect of data errors on privacy, 273 l.3 enhancing privacy through informationsystem design, 275 l.3.1 data and privacy, 275 l.3.2 information systems and privacy, 276 l.4 statistical agency data and approaches, 277 l.4.1 condentiality protection and public data release, 278 l.4.2 record linkage and public use files, 279m public opinion data on u.s. attitudes toward government counterterrorism efforts 281 m.1 introduction, 281 m.2 data and methodology, 284 m.3 organization of this appendix, 287 m.4 general privacy attitudes, 288 m.5 government surveillance, 291protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.contents xxiii m.5.1 trends in attitudes toward surveillance measures, 291 m.5.2 communications monitoring, 294 m.5.3 monitoring of financial transactions, 300 m.5.4 video surveillance, 301 m.5.5 travel security, 302 m.5.6 biometric identication technologies, 303 m.5.7 government use of databases and data mining, 304 m.5.8 public health uses of medical information, 306 m.6 the balance between civil liberties and terrorism investigation, 310 m.6.1 civil liberties versus terrorism prevention, 311 m.6.2 privacy costs of terrorism investigation, 315 m.6.3 personal willingness to sacrice freedoms, 316 m.6.4 concerns about uses of expanded powers, 317 m.7 conclusions, 319 m.8 annex, 322 m.8.1 details of cited surveys, 322 m.8.2 research of organization/sponsor name abbreviations, 322 m.8.3 list of surveys, 324 m.8.4 references, 334n committee and staff biographical information 335o meeting participants and other contributors protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.1executive summaryin a democratic society it is vitally important that citizens and their representatives be able to make an informed judgment on how to appropriately balance privacy with security. this report seeks to contribute to that informed judgment.september 11, 2001, provided vivid proof to americans of the damage that a determined, fanatical terrorist group can in˚ict on our society. based on the available information about groups like al qaeda, most importantly their own statements, it seems clear that they will continue to try to attack us. further attacks by such groups, and indeed by domestic terrorists like timothy mcveigh, could be as serious as, or even more serious than, september 11 and oklahoma city. because future terrorist attacks on the united states could cause major casualties as well as severe economic and social disruption, the danger they pose is real, and it is serious. thus, high priority should be given to developing programs to detect intended attacks before they occur so that there is a chance of preventing them.at the same time, the nation must ensure that its institutions, information systems, and laws together constitute a trustworthy and accountable system that protects u.s. citizens™ rights to privacy.in this report, the committee on technical and privacy dimensions of information for terrorism prevention and other national goals examines the role of data mining and behavioral surveillance technologies in protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.2 protecting individual privacy in the struggle against terroristscounterterrorism programs,1 and it provides a framework for making decisions about deploying and evaluating those and other informationbased programs on the basis of their effectiveness and associated risks to personal privacy.the most serious threat today comes from terrorist groups that are international in scope. these groups make use of the internet to recruit, train, and plan operations, and they use public channels to communicate. therefore, intercepting and analyzing these information streams might provide important clues regarding the nature of the terrorist threat. important clues might also be found in commercial and government databases that record a wide range of information about individuals, organizations, and their transactions, movements, and behavior. but success in such efforts will be extremely difcult to achieve because:ł the information sought by analysts must be ltered out of the huge quantity of data available (the needle in the haystack problem); andł terrorist groups will make calculated efforts to conceal their identity and mask their behaviors, and will use various strategies such as encryption, code words, and multiple identities to obfuscate the data they are generating and exchanging.modern data collection and analysis techniques have had remarkable success in solving informationrelated problems in the commercial sector; for example, they have been successfully applied to detect consumer fraud. but such highly automated tools and techniques cannot be easily applied to the much more difcult problem of detecting and preempting a terrorist attack, and success in doing so may not be possible at all. success, if it is indeed achievable, will require a determined research and development effort focused on this particular problem.detecting indications of ongoing terrorist activity in vast amounts of communications, transactions, and behavioral records will require technologybased counterterrorism tools. but even in wellmanaged programs such tools are likely to return signicant rates of false positives, especially if the tools are highly automated. because the data being analyzed are primarily about ordinary, lawabiding citizens and businesses, false positives can result in invasion of their privacy. such intrusions raise valid concerns about the misuse and abuse of data, about the accuracy 1 in this report, the term ﬁprogramﬂ refers to the system of technical, human, and organizational resources and activities required to execute a specic function. humansšnot computersšare always fully responsible for the actions of a program.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.executive summary 3of data and the manner in which the data are aggregated, and about the possibility that the government could, through its collection and analysis of data, inappropriately in˚uence individuals™ conduct. intruding on privacy also risks ignoring constitutional concerns about general search, as re˚ected in the fourth amendment. the committee strongly believes that such intrusion must be minimized through good management and good design, even if it cannot be totally eliminated.the difculty of detecting the activity of terrorist groups through their communications, transactions, and behaviors is hugely complicated by the ubiquity and enormity of electronic databases maintained by both government agencies and privatesector corporations. retained data and communication streams concern nancial transactions, medical records, travel, communications, legal proceedings, consumer preferences, web searches, and, increasingly, behavioral and biological information. this is the essence of the information agešit provides us with convenience, choice, efciency, knowledge, and entertainment; it supports education, health care, safety, and scientic discovery. everyone leaves personal digital tracks in these systems whenever he or she makes a purchase, takes a trip, uses a bank account, makes a phone call, walks past a security camera, obtains a prescription, sends or receives a package, les income tax forms, applies for a loan, emails a friend, sends a fax, rents a video, or engages in just about any other activity. the proliferation of security cameras and means of tagging and tracking people and objects increases the scope and nature of available data. lawabiding citizens leave extensive digital tracks, and so do criminals and terrorists.gathering and analyzing electronic, behavioral, biological, and other information can play major roles in the prevention, detection, and mitigation of terrorist attacks, just as they do against other criminal threats. in fact the u.s. government has increased its investment in counterterrorism programs based on communications surveillance, data mining, and information fusion. counterterrorism agencies are particularly interested in merging several different databases (information fusion) and then probing the combined data to understand transactions and interactions of specic persons or organizations of interest (data mining). they would also like to identify individuals (through data mining and behavioral surveillance) whose transactions and behavior might indicate possible terrorist links.such techniques often work well in commercial settings, for example for fraud detection, where they are applied to highly structured databases and are honed through constant use and learning. but the problems confronting counterterrorism analysts are vastly more difcult. automated identication of terrorists through data mining (or any other known protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.4 protecting individual privacy in the struggle against terroristsmethodology) is neither feasible as an objective nor desirable as a goal of technology development efforts.one reason is that collecting and examining information to inhibit terrorists inevitably con˚icts with efforts to protect individual privacy. and when privacy is breached, the damage is real. the degree to which privacy is compromised is fundamentally related to the sciences of database technology and statistics as well as to policy and process. for example, there is no way to make personal information in databases fully anonymous. technical, operational, legal, policy, and oversight processes to minimize privacy intrusion and the damage it causes must be established and uniformly applied. even under the pressure of threats as serious as terrorism, the privacy rights and civil liberties that are the cherished core values of our nation must not be destroyed.the quality of the data used in the difcult task of preempting terrorism is also a substantial issue. data of high quality are correct, current, complete, and relevant, and so they can be used effectively, economically, and rapidly to inform and evaluate decisions. data derived by linking highquality data with data of lesser quality will tend to be lowquality data. because data of questionable quality are likely to be the norm in counterterrorism, analysts must be cognizant of their effects, especially in fused or linked databases, and ofcials must carefully consider the consequent likelihood of false positives and privacy intrusions.the preliminary nature of the scientic evidence, the risk of false positives, and operational vulnerability to countermeasures argue for behavioral observation and physiological monitoring being used at most as a preliminary screening method for identifying individuals who merit additional followup investigation. although laboratory research and development of techniques for automated, remote detection and assessment of anomalous behavior, for example deceptive behavior, may be justied, there is not a consensus within the relevant scientic community nor on the committee regarding whether any behavioral surveillance or physiological monitoring techniques are ready for use at all in the counterterrorist context given the present state of the science.the committee has developed and provides in chapter 2 a specic framework for evaluation and operation of informationbased counterterrorism programs to guide deployment decisions and facilitate continual improvement of the programs.national security authorities of course should always adhere to the law, but the committee recognizes that laws will have to be reviewed and revised from time to time to ensure that they are appropriate, up to date, and responsive to real needs and contemporary technologies.with these several concerns and issues in mind, the committee makes the following recommendations.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.executive summary 5recommendation 1. u.s. government agencies should be required to follow a systematic process (such as the one described in the framework proposed in chapter 2) to evaluate the effectiveness, lawfulness, and consistency with u.s. values of every informationbased program, whether classied or unclassied, for detecting and countering terrorists before it can be deployed, and periodically thereafter. under most circumstances, this evaluation should be required as a condition for deployment of informationbased counterterrorism programs, but periodic evaluation and continual improvement should always be required when such programs are in use. the committee believes that the framework presented in chapter 2 denes an appropriate process for this purpose. periodically after a program has been operationally deployed, and in particular before a program enters a new phase in its life cycle, policy makers should apply a framework such as the one proposed in chapter 2 to the program before allowing it to continue operations or to proceed to the next phase. consistency with relevant laws and regulations, and impact on individual privacy and civil libertiesšas well as validity, effectiveness, and technical performancešshould be rigorously assessed. such review is especially necessary given that the committee found little evidence of any effective evaluation performed for current programs intended to detect terrorist activity by automated analysis of databases. (if such evidence does exist, it should be presented in the appropriate oversight forums as part of such review.) periodic review may result in signicant modication of a program or even its cancellation.any informationbased counterterrorism program of the u.s. government should be subjected to robust, independent oversight. all three branches of government have important roles to play to ensure that such programs adhere to relevant laws. all such programs should provide meaningful redress to any individuals inappropriately harmed by their operation.to protect the privacy of innocent people, the research and development of any informationbased counterterrorism program should be conducted with synthetic population data. if and when a program meets the criteria for deployment in the committee™s illustrative framework described in chapter 2, it should be deployed only in a carefully phased manner, e.g., being eld tested and evaluated at a modest number of sites before being scaled up for general use. at all stages of a phased deployment, data about individuals should be rigorously subjected to the full safeguards of the framework.recommendation 2. the u.s. government should periodically review the nation™s laws, policies, and procedures that protect individuals™ private protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.6 protecting individual privacy in the struggle against terroristsinformation for relevance and effectiveness in light of changing technologies and circumstances. in particular, congress should reexamine existing law to consider how privacy should be protected in the context of informationbased programs (e.g., data mining) for counterterrorism. such reviews should consider establishment of restrictions on how personal information can be used. currently, legal restrictions are focused primarily on how records are collected and assessed, rather than on their use.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.71scoping the issue: terrorism, privacy, and technology1.1 the nature of the terrorist threat to the united statessince september 11, 2001, the united states has faced a real and serious threat from terrorist action. although the primary political objectives of terrorist groups vary depending on the group (e.g., the political objectives of al qaeda differ from those of aum shinrikyo), terrorist actions throughout history have nevertheless shared certain common characteristics and objectives. first, they have targeted civilians or noncombatants for political purposes. second, they are usually violent, send a message, and have symbolic signicance. the common objectives of terrorists include seeking revenge, renown, and reaction; that is, terrorists generally seek to ﬁpay backﬂ those they see as repressing them or their people; to gain notoriety or social or spiritual recognition and reward; and to cause those they attack to respond with fear, an escalating spiral of violence, irrational reaction and thus selfin˚icted damage (e.g., reactions that strengthen the hand of the terrorists), or capitulation. third, terrorists often blend with the targeted populationšand in particular, they can exploit the fundamental values of open societies, such as the united states, to cover and conceal their planning and execution.despite these commonalities, today™s terrorist threat is fundamentally different from those of the past. first, the scale of damage to which modern terrorists aspire is much larger than in the past. the terrorist acts of september 11, 2001, took thousands of lives and caused hundreds of billions of dollars in economic damage. second, the potential terrorist protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.8 protecting individual privacy in the struggle against terroristsuse of weapons of mass destruction (e.g., nuclear weapons, biological or chemical agents) poses a threat that is qualitatively different from a threat based on rearms or chemical explosives. third, terrorists operate in a modern environment plentiful in the amount of available information and increasingly ubiquitous in its use of information technology.even as terrorist ambitions and actions have increased in scale, smaller bombings and attacks are also on the rise in many corners of the world. to date, all seem to have been planned and executed by groups or networks and therefore have required some level of interaction and communication to plan and execute.left unaddressed, this terrorist threat will create an environment of fear and anxiety for the nation™s citizens. if people come to believe that they are inltrated by enemies that they cannot identify and that have the power to bring death, destruction, and havoc to their lives, and that preventing that from happening is beyond the capability of their governments, then the quality of national life will be greatly depreciated as citizens refrain from fully participating in their everyday lives. that scenario would constitute a failure to ﬁestablish justice, insure domestic tranquility, provide for the common defense, promote the general welfare, and secure the blessings of liberty to ourselves and our posterity,ﬂ as pledged in the preamble to the constitution.to address this threat, new technologies have been created and are creating dramatic new ways to observe and identify people, keep track of their location, and perhaps even deduce things about their thoughts and behaviors. the task for policy makers now is to determine who should have access to these new data and capabilities and for what purposes they should be used. these new technologies, coupled with the unprecedented nature of the threat, are likely to bring great pressure to apply these technologies and measures, some of which might intrude on the fundamental rights of u.s. citizens.appendix b (ﬁterrorism and terroristsﬂ) addresses the terrorist threat in greater detail.1.2 counterterrorism and privacy as an american valuein response to the mounting terrorist threat, the united states has increased its counterterrorist efforts with the aim of enhancing the ability of the government to prevent terrorist actions before they occur. these efforts have raised concerns about the potential negative impacts of counterterrorism programs on the privacy and other civil liberties of u.s. citizens, as well as the adequacy of relevant civil liberties protections. because terrorists blend into lawabiding society, activities aimed at protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 9detecting and countering their actions before they occur inherently raise concerns that such efforts may damage a free, democratic society through wellintentioned steps intended to protect it. one such concern is that lawabiding citizens who come to believe that their behavior is watched too closely by government agencies and powerful private institutions may be unduly inhibited from participating in the democratic process, may be inhibited from contributing fully to the social and cultural life of their communities, and may even alter their purely private and perfectly legal behavior for fear that discovery of intimate details of their lives will be revealed and used against them in some manner.privacy is, and should continue to be, a fundamental dimension of living in a free, democratic society. an array of laws protect ﬁgovernment, credit, communications, education, bank, cable, video, motor vehicle, health, telecommunications, children™s, and nancial information; generally carve out exceptions for disclosure of personal information; and authorize use of warrants, subpoenas, and court orders to obtain information.ﬂ1 these laws usually create boundaries between individuals and institutions (or sometimes other individuals) that may limit what information is collected (as in the case of wiretapping or other types of surveillance) and how that information is handled (such as the fair information practices that seek care and openness in the management of personal information). they may establish rules governing the ultimate use of information (such as prohibitions on the use of certain health information for making employment decisions), access to the data by specic individuals or organizations, or aggregation of these data with other data sets. the great strength of the american ideal of privacy has been its robustness in the face of new social arrangements, new business practices, and new technologies. as surveillance technologies have expanded the technical capability of the government to intrude into personal lives, the law has sought to maintain a principled balance between the needs of law enforcement and democratic freedoms.public attitudes, as identied in public opinion polls, mirror this delicate balance.2 for example, public support for counterterrorism measures appears to be strongly in˚uenced by perceptions of the terrorist threat, 1 u.s. congressional research service, privacy: total information awareness programs and related information access, collection, and protection laws (rl31730), updated march 21, 2003, by gina marie stevens.2 see appendix m (ﬁpublic opinion data on u.s. attitudes toward government counterterrorism effortsﬂ) for more details. among them are two caveats about the identication of public attitudes through public opinion surveys. the rst one has to do with the framing of survey questions, in terms of both wording and context, which have been shown to strongly in˚uence the opinions elicited. the second has to do with declining response rates to national sample surveys and the inability to detect or estimate nonresponse bias.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.10 protecting individual privacy in the struggle against terroristsan assessment of government effectiveness in dealing with terrorism, and perceptions as to how these measures are affecting civil liberties. thus, one nds that since 9/11, public opinion surveys re˚ect a diminishing acceptance of government surveillance measures, with people less willing to cede privacy and other civil liberties in the course of increased terrorism investigation and personally less willing to give up their freedoms and more pessimistic about protection of the right to privacy. yet recent events, such as the london underground bombings of july 2005 and reports in august 2006 that a major terrorist attack on transatlantic airliners had been averted, appeared to in˚uence public attitudes; support increased for such surveillance measures as expanded camera surveillance, monitoring of chat rooms and other internet forums, and expanded monitoring of cellular phones and emails. however, public attitudes toward recently revealed monitoring programs are mixed, with no clear consensus.public opinion polls also indicate that the public tends to defend civil liberties more vigorously in the abstract than in specic situations. at the same time, people seem to be less concerned about privacy in general (i.e., for others) but rather with protecting the privacy of information about themselves. in addition, most people are more tolerant of surveillance when it is aimed at specic racial or ethnic groups, when it concerns activities they do not engage in, or when they are not focusing on its potential personal impact. thus the perception of threat might explain why passenger screening and searches both immediately after september 11, 2001, and continuing through 2006 consistently receive high levels of support while, at the same time, the possibility of personal impact reduces public support for government collection of personal information about travelers. the public is also ambivalent regarding biometric identication technologies and public health uses, such as prevention of bioterrorism and the sharing of medical information. for these, support increases with assurances of anonymity and personal benets or when they demonstrate a high degree of reliability and are used with consent.legal analysts,3 even courts,4 if not the larger public, have long recognized that innovation in information and communications technologies often moves faster than the protections afforded by legislation, which is usually written without an understanding of new or emerging technologies, unanticipated terrorist tactics, or new analytical capabilities. some of these developing technologies are described in section 1.6 and in greater 3 for example, see r.a. pikowsky, ﬁthe need for revisions to the law of wiretapping and interception of email,ﬂ michigan telecommunications & technology law review 10(1), 2004.4 u.s. court of appeals. (no. 005212; june 28, 2001), p. 10. available at http://www.esp.org/misc/legal/uscadc005212.pdf. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 11detail in appendixes c (ﬁinformation and information technologyﬂ) and h (ﬁdata mining and information fusionﬂ). the state of the law and its limitations are detailed in appendix f (ﬁprivacyrelated law and regulation: the state of the law and outstanding issuesﬂ). as new technologies are brought to bear in national security and counterterrorism efforts, the challenge is no different from what has been faced in the past with respect to potential new surveillance powers: identify those new technologies that can be used effectively and establish specic rules that govern their use in accordance with basic constitutional privacy principles.51.3 the role of informationinformation and information technology are ubiquitous in today™s environment. massive databases are maintained by both governments and privatesector businesses that include information about each person and about his or her activities. for example, public and private entities keep bank and credit card records; tax, health, and census records; and information about individuals™ travel, purchases, viewing habits, web search queries, and telephone calls. merchants record what individuals look at, the books they buy and borrow, the movies they watch, the music they listen to, the games they play, and the places they visit. other kinds of databases include imagery, such as surveillance video, or location information, such as tracking data obtained from bar code readers or rfid (radio frequency identication) tags. through formal and informal relationships between government and privatesector entities, much of the data available to the private sector is also available to governments.in addition, digital devices for paying tolls, computer diagnostic equipment in car engines, and global positioning services are increasingly common on passenger vehicles. cellular telephones and personal digital assistants record not only call and appointment information, but also location, transmitting this information to service providers. internet service providers record online activities, digital cable and satellite systems record what individuals watch and when, alarm systems record when people enter and leave their homes. people back up personal data les online and access online photo, email, and music storage services. global positioning technologies are appearing in more and more products, and rfid tags are beginning to be used to identify consumer goods, identication documents, pets, and even people.modern technology offers myriad options for communication 5 ﬁ[t]he law must advance with the technology to ensure the continued vitality of the fourth amendment,ﬂ senate judiciary committee report on the electronic communications privacy act of 1986 (s. 2575), report 99541, 99th congress, 2nd session, 1986, p. 5.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.12 protecting individual privacy in the struggle against terroristsbetween individuals and among small groups, including cell phones, email, chat rooms, text messaging, and various forms of mass media. with voiceoverip telephone service, digital phone calls are becoming indistinguishable from digital documents: both can be stored and accessed remotely. new sensor technologies enable the tagging and tracking of information about individuals without their permission or awareness.as noted earlier, the terrorists of today are embedded and operate in this environment. it is not unreasonable to believe that terrorists planning an attack might leave ﬁtracksﬂ or ﬁsignaturesﬂ in these digital databases and networks and might make use of the communications channels available to all. extracting terrorist tracks from nonthreat tracks might be the goal, but this is nevertheless not easy. one could imagine that aspects of a terrorist signature may be information that is not easily available or easily linked to other information or that some signatures may garner suspicion but are really not threats. however, with appropriate investigative leads, the potential increases that examining these databases, monitoring the contents of terrorist communications, and using other techniques, such as tagging and tracking, may yield valuable clues to terrorist intentions.these possibilities have not gone unnoticed by the u.s. government, which has increased the number of and investment in counterterrorism programs that collect and analyze information to protect america from terrorism and other threats to public health and safety.6 the government collects information from many industry and government organizations, including telecommunications, electricity, transportation and shipping, law enforcement, customs agents, chemical and biological industries, nance, banking, and air transportation. the u.s. government also has the technical capability and, under some circumstances, the legal right to collect and hold information about u.s. citizens both at home and abroad. to improve the overall counterterrorism effort, the government has mandated interagency and interjurisdictional information sharing.7 in short, the substantial power of the u.s. government™s capability to collect information about individuals in the united states, as well as that of privatesector corporations and organizations, and the many ways that 6 in this report, the term ﬁprogramﬂ refers to the resources required to execute a specic functionšfor example, a counterterrorism program, such as the terrorist information awareness program. a program always involves people executing informationintensive processes. frequently, a program involves an information system and other information systems with which it exchanges information. humans are always fully responsible for the actions of a program.7 intelligence reform and terrorism prevention act of 2004, public law 108458, december 17, 2004.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 13advancing technology is improving that capability necessitate explicit steps to protect against its misuse.if it were possible to automatically nd the digital tracks of terrorists and automatically monitor only the communications of terrorists, public policy choices in this domain would be much simpler. but it is not possible to do so. all of the data contained in databases and on networks must be analyzed to attempt to distinguish between the data associated with terrorist activities and those associated with legitimate activities. much of the analysis can be automated, a fact that provides some degree of protection for most personal information by having data manipulated within the system and restricted from human viewing. however, at some point, the outputs need to be considered and weighed, and some data associated with innocent individuals will necessarily and inevitably be examined by a human analystša fact that leads to some of the privacy concerns raised above. (other privacy concerns, largely rooted in a technical denition of privacy described below, arise from the mere fact that certain individuals are singled out for further attention, regardless of whether a human being sees the data at all.)in conceptualizing how information is used, it is helpful to consider what might be called the information life cycle. addressed in greater detail in appendix c, digital information typically goes through a sevenstep information life cycle:ł collection. information, whether accurate or inaccurate, is collected by some means, whether in an automated manner (e.g., nancial transactions at a point of sale terminal or on the web, call data records in a telecommunications network) or a manual manner (e.g., a federal bureau of investigation (fbi) agent conducting an interview with an informant). information may often be collected or transmitted (or both) without the subject™s awareness. in some instances, the party collecting the information may not be the end user of that information. this is especially relevant in government use of databases compiled by private parties, since laws that regulate government collection of information do not necessarily place comparable restrictions on government use of such information.ł correction. information determined to be erroneous, whether through automated or manual means, may be discarded or corrected. information determined to be incomplete may be augmented with additional information. under some circumstances, the person associated with the collected information can make corrections. information correction is not trivial, especially when large volumes of data are involved. the most efcient and practical means of correcting information may reduce protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.14 protecting individual privacy in the struggle against terroristsuncertainties but is not likely to eliminate them, and indeed error correction may itself sometimes introduce more error.ł storage. information is stored in data repositoriesšdatabases, data warehouses, or simple les.ł analysis and processing. information is used or analyzed, often using query languages, business intelligence tools, or analytical techniques, such as data mining. analysis may require access to multiple data repositories, possibly distributed across the internet.ł dissemination and sharing. results of information analysis and processing are published or shared with the intended customer or user community (which may consist of other analysts). disseminated information may or may not be in a format compatible with users™ applications.ł monitoring. information and analytical results are monitored and evaluated to ensure that technical and procedural requirements have been and are continuing to be met. examples of important requirements include security (are specied security levels being maintained?), authorization (are all access authorized?), service level agreements (is performance within promised levels?), and compliance with applicable government regulations.ł selective retention or deletion. information is retained or deleted on the basis of criteria (explicit or implicit) set for the information repository by the steward or by prevailing laws, regulations, or practices. the decreasing cost of storage and the increasing belief in the potential value to be mined from previously collected data are important factors enabling the increase in typical data retention periods. the benets of retention and enhanced predictive power have to be balanced against the costs of reduced condentiality. data retention policies should therefore be regularly justied through an examination of this tradeoff.as described, these steps in the information life cycle can be regarded as a notional process for the handling of information. however, in practice, one or more of these steps may be omitted, or the sequencing may be altered or iterated. for example, in some instances, it may be that data are rst stored and then corrected. or the data may be stored with no correction at all or processed without being stored, which is what rewalls do.additional issues arise when information is assembled or collected from a variety of storage sources for presentation to an analysis application. assembling such a collection generally entails linking records based on data elds, such as unique identiers if present and available (identication numbers) or less perfect identiers (combinations of name, address, and date of birth). the challenge of accurately linking large databases should not be underestimated. in practice, it is often the case that data may be linked with little or no control for accuracy or ability to corprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 15rect errors in these elds, with the likely outcome that many records will be linked improperly and that many other records that should be linked are not linked. without checks on the accuracy of such linkages, there is no way of understanding how errors resulting from linkage may affect the quality or provenance of the subsequent analysis.finally, different entities handle information differently because of the standards and regulations imposed on them. the types of information that can be collected, corrected, stored, disseminated, and retained and by whom, when, and for how long vary across private industries and government agencies. for example, three different kinds of agencies in the united states have some responsibility for combating terrorism: agencies in the intelligence community (ic), agencies of federal law enforcement (fle), and agencies of state, local, and tribal law enforcement (sltle). the informationhandling policies and practices of these different types of agency are governed by different laws and regulations. for example, the information collection policies and practices of sltle agencies require the existence of a ﬁcriminal predicateﬂ to collect and retain information that identies individuals and organizations; a criminal predicate refers to the possession of ﬁreliable, factbased information that reasonably infers that a particularly described . . . subject has committed, is committing or is about to commit a crime.ﬂ8 no such predicate is required for the collection of similar information by agencies in the intelligence community. some fle agencies (in particular, the fbi and the drug enforcement agency) are also members of the intelligence community, and when (and only when) they are acting in this role, they are not required to have such predicates, either. the rules for information retention and storage are also more restricted for sltle agencies than for ic agencies (or fle agencies acting in an ic role).1.4 organizational models for terrorism and the intelligence processa variety of models exists for how terrorist groups are organized, so it is helpful to consider two ends of a spectrum of organizational practices. at one end is a commandandcontrol model, which also characterizes traditional military organizations and multinational corporations. in this topdown structure, the leaders of the organization are responsible for planning, and they coordinate the activities of operational cells. at the other end of the spectrum is an entrepreneurial model, in which terrorist 8 d.l. carter, civil rights and privacy in the law enforcement intelligence process, intelligence program, school of criminal justice, michigan state university, march 2008.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.16 protecting individual privacy in the struggle against terroristscells form spontaneously and do their planning and execution without asking anybody™s permission or obtaining external support, although they may be loosely coordinated with respect to some overall highlevel objective (such as ﬁkill westerners in large numbersﬂ). in practice, terrorist groups can be found at one end or the other of this spectrum, as well as somewhere in the middle. for example, a terrorist cell might form itself spontaneously but then make contact with a central organization in order to obtain some funding and technical support (such as a visit by a bombmaking expert).the spectrum of organizational practice is important because the nature of the organization in question is closely related to the various information ˚ows among elements of the organization. these ˚ows are important, because they provide opportunities for disruption and exploitation in counterterrorist efforts. exploitation in particular is important because that is what yields information that may be relevant to anticipating an attack.because it originates spontaneously and organically, the decentralized terrorist group, almost by denition, is usually composed of individuals who do blend very well and easily into the society in which they are embedded. thus, their attack planning and preparation activities are likely to be largely invisible when undertaken against the background of normal, innocent activities of the population at large. information on such activities is much more likely to come to the attention of the authorities through tips originating in the relevant neighborhoods or communities or through observations made by local law enforcement authorities. although such tips and observations are also received in the context of many other tips and observations, some useful and others not, the amount of winnowing necessary in this case is very much smaller than the amount required when the full panoply of normal, innocent activities constitutes the background.by contrast, the commandandcontrol terrorist group potentially leaves a more consistent and easily discernible information footprint in the aggregate (although the individual elements may be small, such as a single phone call or email). by denition, a topdown command structure involves regular communication among various elements (e.g., between platoon leaders and company commanders). against the background noise, such regularities are more easily detected and understood than if the communication had no such structure. in addition, such groups typically either ﬁlight upﬂ with increased command trafc or ﬁgo darkﬂ prior to conducting an attack. under these circumstances, there is greater value in a centralized analysis function that assembles the elements together into a mosaic.although data mining techniques are dened and discussed below protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 17in section 1.6.1, it is important to point out here that different kinds of analytical approaches are suitable in each situation. this report focuses on two general types of data mining techniques (described further in appendix h): subjectbased and patternbased data mining. subjectbased data mining uses an initiating individual or other datum that is considered, based on other information, to be of high interest, and the goal is to determine what other persons or nancial transactions or movements, etc., are related to that initiating datum. patternbased data mining looks for patterns (including anomalous data patterns) that might be associated with terrorist activityšthese patterns might be regarded as small signals in a large ocean of noise.in the case of the decentralized group, subjectbased data mining is likely to augment and enhance traditional police investigations by making it possible to access larger volumes of data more quickly. furthermore, communications networks can more easily be identied and mapped if one or a few individuals in the network are known with high condence. by contrast, patternbased data mining may be more useful in nding the larger information footprint that characterizes centrally organized terrorist groups.note that there is also a role for an analytical function after an attack occurs or a planned attack is uncovered and participants captured. under these circumstances, plausible starting points are available to begin an investigation, and this kind of analytical activity follows quite closely the postincident activities in counterespionage: who were these people, who visited them, with whom were they communicating, where did the money come from, and so on. these efforts (often known as ﬁrolling up the networkﬂ) serve both a prosecutorial function in seeking to bring the perpetrators to justice and a prophylactic function in seeking to prevent others in the network from carrying out further terror attacks.1.5 activities of the intelligence community and of law enforcement agenciesthe intelligence community is responsible for protecting u.s. national security from threats that have been dened by the executive branch. when threats are dened, further information is sought (i.e., ﬁintelligence requirementsﬂ) to understand the status and operations of the threat, from which intervention strategies are developed to prevent or mitigate the threat. the information collection and management process for the intelligence community is driven by presidential policy.in contrast, law enforcement agencies identify threats based on behaviors that are specically identied as criminal (i.e., with the fourth amendment requirement of particularity). the law enforcement approach protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.18 protecting individual privacy in the struggle against terroriststo the threat is based on traditional criminal investigation and case building, a problemsolving intervention, or a hybrid of these two. the law enforcement agency information collection and management process is driven by crime. the parameters and policy of law enforcement activity to deal with the threat are stipulated constitutional law (notably the law of criminal evidence and procedure) and civil rights cases (42 usc 1983) particularly based on consent decrees related to the intelligence process in a number of cities. two civil casesšhandschu v. special services division (nypd) and american friends service committee v. denveršhave been major forces in shaping law enforcement policy on information collection for the intelligence process, notably related to first amendment expressive activity and the inferred right to privacy.as a matter of u.s. public policy today, the prevention of terrorist attacks against the u.s. homeland and other u.s. interests is the primary goal of the intelligence community and of federal law enforcement agencies. prevention of terrorist attacks is necessarily a proactive and ongoing role, and thus it is not necessarily carried out in response to any particular external event. countercrime activities are usually focused on investigation and developing the information basis for criminal prosecution. as a practical matter, most such investigations are reactivešthat is, they are initiated in response to a specic occurrence of criminal activity.these comments are not intended to imply that there is no overlap between the counterterrorist and countercrime missions. for example, law enforcement authorities are also concerned about the prevention of crimes through the perhaps difculttodetermine deterrent effect of postattack prosecution of terrorists and their collaborators. in addition, preparation for future criminal acts can themselves be a current criminal violation under the conspiracy or attempt provisions of federal criminal law or other provisions dening preparatory crimes, such as solicitation of a crime of violence or provision of material support in preparation for a terrorist crime. the standard for opening an investigationšand thus for collecting personally identiable informationšis satised when there is not yet a current substantive or preparatory crime but facts or circumstances reasonably indicate that such a crime will occur in the future (i.e., when there is a valid criminal predicate).9although most crimes do not have a direct terrorism nexus, it is not uncommon to nd that terrorists engage in criminal activities that are on the surface unrelated to terrorism. for example, a terrorist group with9 information on investigations and inquiries is derived from the attorney general™s guidelines on general crimes, racketeering enterprise and terrorism enterprise investigations, attorney general john ashcroft, u.s. department of justice, washington, d.c., may 30, 2002, available at http://www.usdoj.gov/olp/generalcrimes2.pdf.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 19out nancial resources provided from an external source may engage in fraud. one wellknown case in 2002 involved cigarette smuggling in support of hezbollah.10in addition, law enforcement agencies are often unable to deploy personnel and other resources if they are not being used to further active criminal investigations, so counterterrorism investigations are often part of an ﬁall crimesﬂ approachšthat is, law enforcement agencies focus on an overall goal of public safety and stay alert for any threats to the public safety, including but not limited to terrorism.finally, both criminals and terrorists (foreign or domestic) operating in the united states are likely to blend very well and easily into the society in which they are embedded. that is, ordinary criminals are likely to be similar in prole to decentralized terrorist groups that also would draw their members from the ranks of disaffected americans (or from individuals who are already familiar with each other or trusted, such as family members). thus, both counterterrorist and countercrime efforts are likely to depend a great deal on information originating in the relevant neighborhoods or communities or observations made by local law enforcement authorities.1.6 technologies of interest in this reportthe counterterrorist activities of the u.s. government depend heavily on many different kinds of technology. a comprehensive assessment of all technologies relevant to these efforts would be extensive and resourceintensive, not to mention highly classied at least in part, and indeed the committee was not charged with conducting such an assessment. instead, the charge directed the committee to focus primarily on two important technologiesšdata mining and behavioral and physiological surveillancešand their relationship to and impact on privacy.11the focus of the committee™s charge does not negate the value of other technologies or programs that generate information relevant to the counterterrorist mission, such as technologies for tagging and track10 a north carolinabased hezbollah cell smuggled untaxed cigarettes into north carolina and michigan and used the proceeds to provide nancial support to terrorists in beirut. see d.e. kaplan, ﬁhomegrown terrorists: how a hezbollah cell made millions in sleepy charlotte, n.c.,ﬂ u.s. news and world report, march 2, 2003, available at http://www.usnews.com/usnews/news/articles/030310/10hez.htm.11 despite the focus on data mining and behavioral surveillance, the committee does recognize that most of the issues related to privacy and these technologies also apply more broadly to other information technologies as they might be used for counterterrorism. nevertheless, this is mostly a report about privacy as it relates to these two specic technologies of interest.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.20 protecting individual privacy in the struggle against terroristsing for identity management, or even for the admittedly controversial use of socalled ﬁnational security lettersﬂ for information gathering. (a national security letter (nsl) is a demand for information from a third party issued by the fbi or by other government agencies with authority to conduct national security investigations. no judicial approval is needed for the issuance of an nsl, and many nsls have been issued pursuant to statutory nondisclosure provisions that prevent the issuance from being made known publicly. both of these provisions have created controversy.) indeed, regardless of whether a given informationgenerating program or technology is or is not classied, it can be said openly that the purpose of the program or technology is to generate information. missiondirected intelligence analysis is an allsource enterprisešthat is, the purpose of the analytical mission is to make sense out of information coming from multiple sources, classied and unclassied. data mining and information fusion are technologies of analysis rather than collection, and thus they are intended to help analysts nd patterns of interest in all of the available data.1.6.1 data miningunder the rubric of data mining techniques fall a diverse set of tools for mathematical modeling, including machine learning, pattern recognition, and information fusion.ł machine learning is the study of computer algorithms that improve automatically through experience.ł pattern recognition addresses a broad class of problems in which a feature extractor is applied to untreated (usually image) input data to produce a reduced data set for use as an input to a classication model, which then classies the treated input data into one of several categories.ł information fusion refers to a class of methods for combining information from different sources in order to make inferences that may not be possible from a single source alone. some information fusion methods use formal probabilistic models, and some include ways of assessing rates of linkage error; others include only one or none of these things.there is a continuum of sophistication in techniques that have been referred to as data mining that may provide assistance in counterterrorism. on the more routine end of the spectrum (sometimes called subjectbased data mining and often so routine as to not be included in the portfolio of techniques referred to as data mining) lies the automation of typical investigative techniques, especially the searching of large databases for characteristics that have been associated with individuals of interest, that protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 21is, people who are worthy of further investigation. through the benets of automation, the investigative power of these traditional techniques can be greatly expedited and broadened in comparison to former practices, and therefore they can provide important assistance in the ght against terrorism.subjectbased data mining can include, for example, people who own cars with license plates that are discovered at the scene of a terrorist act or whose ngerprints match those of people known to be involved in terrorist activity. subjectbased data mining might also include people who have been in communication with other persons of interest, people who have traveled to various places recently, and people who have transferred large sums of money to others of interest. when several disparate pieces of information of this type are obtained that are associated with terrorist activity, identifying a subset of a database that matches one or more of these various pieces of information can be referred to as ﬁdrilling down.ﬂ this is a data mining technique that simply expands and automates what a police detective or intelligence analyst would carry out with sufcient time.there are two key requisites for this use of data mining. one is the development of linkages relating data and information in the relevant databases, which facilitates response to these types of queriesšfor example, being able to identify all numbers that have recently called or been called by a given telephone number. of course, attestations regarding the accuracy and provenance of such identication are also necessary for condence in the ultimate results. the second requisite is the quality of the information collected. individuals claimed by law enforcement ofcials to match prints found at a crime scene have sometimes turned out not to match upon further investigation.12 also, matching names or other forms of record linkage are errorprone operations, generally because of data quality issues.similarly, socalled rulebased techniques collect joint characteristics or data for individuals (or other units of analysis, such as networks of individuals) whom detectives or intelligence analysts view as being potentially associated with terrorist activity. this activity can include, for example, the recent purchase, possibly as a member of a group, of chemicals or biological agents that can be used to create explosives or toxins. again, this is a simple extension of what analysts would do with sufcient resources and represents a relatively unsophisticated application of data mining. the key element is the use of analysts to identify the important 12 s. kershaw, ﬁspain and u.s. at odds on mistaken terror arrest,ﬂ new york times, june 5, 2004, available at http://query.nytimes.com/gst/fullpage.html?res=9800efdb1031 f936a35755c0a9629c8b63.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.22 protecting individual privacy in the struggle against terroristsrules or patterns that are indicative of or associated with terrorist activity. given that terrorists often operate in groups, networkbased methods have particular importance and should be used in concert with rulebased methods when possible. as above, the use of rulebased techniques can be greatly compromised by poorquality data.patternbased data mining techniques either require a feedback mechanism to generate learning over time or are more assumptiondependent than subjectbased techniques. machine learning is one such technique: in situations in which the truth of a decision process can often be made known, the feedback of knowing which results were decided correctly and incorrectly can be used to improve the decision process, which ﬁlearnsﬂ over time to become a better discriminator. for example, in scanning carryon luggage to decide which contents are of concern and which are not, the process of simultaneously and individually searching a large number of the bags identied both of concern and not of concern and feeding back this information into the decision algorithm, can be used to improve the algorithm. over time the algorithm can learn which patterns are associated with bags of concern. these situations in which cases of interest and cases not of interest become known for a large number of instances, referred to as a training set, permit machine learning to operate. this represents a collection of techniques that might have important applicability to specic, limited components of the counterterrorism problem.there are also a number of situations in which the identication of anomalous patterns, in comparison to a long historical pattern of behavior or use, might make it possible to ultimately discriminate between activities of interest and activities not of interest to intelligence analysts. referred to as signaturebased analysis, current successful applications of data mining in these situations include the identication of anomalous patterns of credit card use or the fraudulent use of a telephone billing account. however, in those applications, a training set is available to help evaluate the extent to which the pattern of interest is useful in discriminating the behavior of interest from that not of interest.when a training set or some formal means for assessing predictive validity is not available (i.e., if there is no way to test predictions against some kind of ground truth), these techniques are unlikely to provide useful information for counterterrorism. nevertheless, it may be possible to use subjectmatter experts to identify discriminating patterns, and one cannot reject a priori the possibility that anomalous patterns might be identied that intelligence analysts would also view as very likely to be associated with terrorist activity. working collaboratively, signaturebased data mining techniques might be developed that could effectively discriminate in counterterrorism between patterns of interest and those not protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 23of interest. such patterns might then provide leads for further investigation through traditional law enforcement or national security means.this rough partitioning of data mining techniques into patternbased and subjectbased approaches is meant to describe two relatively broad classes of techniques representing two ﬁpure typesﬂ of methods used. however, many of the approaches used in practice can be considered combinations of these pure types, and therefore the examples included here of these two approaches do not fully explore the richness of techniques that is possible. indeed, the data mining components of a real system are likely to re˚ect aspects of both subjectbased and patternbased data mining algorithms, through joint use of several perspectives using different units of analysis, combining evidence in several ways.in many cases, the unit of analysis is the individual, and the objective is discriminating between the people who are and are not of interest. however, rather than using the individual as the basic unit of analysis, many techniques may use other constructs, such as the relevant group of close associates, the date of some possible terrorist activity, or the intended target, and then tailor the information retrieval and the analysis using that perspective. to best address a given problem, it may be benecial at times to use more than one unit of analysis (such as a group), and to combine such analyses so that mutually consistent information can be recognized and used. the unit of analysis selected has implications for the rulebased techniques that might be used, or what patterns or signatures might be seen to be anomalous and therefore of interest.13in addition, the use of data mining procedures may occur as component parts of a counterterrorism system, in which data mining tools address specic needs, such as identifying all the nancial dealings, contacts, events, travels, etc., corresponding to a person of interest. the overall system would be managed by intelligence agents, who would also have impacts on both the design of the data mining components and on the remaining components, which might involve skills that could not be automated. the precise form of such a system is only hinted at here, and both system development and deployment are likely to require a substantial investment of time and resources as well as collaboration with those with stateoftheart expertise in data mining, database management, and counterterrorism.finally, no single operational system has access to all of the relevant data at the same time. in practice, the results of an analysis from any given system will often result in queries being made of other systems exploit13 additional examples in the fraud detection context are provided, for example, in r.j. bolton and d.j. hand, ﬁstatistical fraud detection, a review,ﬂ statistical science 17(3):235255, 2002.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.24 protecting individual privacy in the struggle against terroristsing different analytical techniques with access to different databases. for example, an intensive analysis on one system may be made using a limited set of records to identify a set of initial leads. in subsequent stages using different systems, progressively more extensive sets of data may be analyzed to winnow the set of initial leads. such a practicešoften known as multistage inferencešmay help to improve efciency and to reduce privacy impacts.in general, there is little doubt about the utility of subjectbased data mining as an investigative technique. however, the utility of patternbased data mining and information fusion depends on the availability of a training set and the application to which the techniques are applied. patternbased data mining is most likely to be useful when training sets are available; there are supplementary tasks for which data mining tools might be helpful that do not require a training set. at the same time, the utility of patternbased data mining, without a training set, to identify patterns indicative of individuals and events worth additional investigation, is very unclear. although there is no a priori argument that categorically eliminates patternbased data mining as useful tools for counterterrorism applications, considerable basic research will be necessary to develop operational systems that help to provide a prioritization of cases for experts to examine in more depth. such research would examine the feasibility and utility of patternbased data mining and information fusion for counterterrorism applications and subsequent development into specic applications components. that approach to the problem in question might not succeed but the potential gains are large, and for this reason such a modest program investment, structured in accordance with the framework proposed in chapter 2, may be well worth making.1.6.2 behavioral surveillancebehavioral surveillance seeks to detect physiological behaviors, conditions, or responses and the attendant biological activity that indicate that an individual is about to commit an act of terrorism. specically, behavioral surveillance seeks to detect patterns of behavior thought to be precursors or correlates of wrongdoing (e.g., deception, expressing hostile emotions) or that are anomalous in certain situations (e.g., identifying a person who shows much greater dgeting and much more facial reddening than others in a security line).if people were incapable of lying, the easiest and most accurate way to determine past, current, and future behavior would be to ask them what they have been doing, what they are doing, and what they plan to do. but people are highly capable of lying, and it is currently very difcult to detect lying with great degrees of accuracy (especially through protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 25automated means). thus, the terrorist™s desire to avoid detection makes this verbal channel of information highly unreliable.for this reason, behavioral surveillance focuses on biological or physiological indicators that are relatively involuntary (i.e., whose presence or absence is not subject to voluntary control) or provide detectible signs when they are being manipulated. for example, physiological indicators, such as cardiac activity, facial expressions, and voice tone, can be monitored and the readings used to make inferences about internal psychological states (e.g., ﬁbased on this pattern of physiological activity, this person is likely to be engaged in deceptionﬂ). however, such indicators do not provide direct evidence of deception of any sort, let alone terrorist behavior (e.g., the deception if present at all may not relate to terrorist behavior but rather to cheating on one™s income tax or spouse), and thus the problem becomes one of inferring the specic (i.e., terrorist behavior) from more general indicators.to illustrate the government interest in behavioral surveillance, consider project hostile intent, conducted under the auspices of the u.s. department of homeland security™s human factors division in the science and technology directorate. this project seeks to develop models of hostile intent and deception, focusing on behavioral and speech cues. these cues would be determined from experiments and derived from operationally based scenarios that re˚ect the screening and interviewing objectives of the department. in addition, the project seeks to develop an automated suite of noninvasive sensors and algorithms that can automatically detect and track the input cues to the models. if successful, the resulting technologies would afford capabilities to identify deception and hostile intent in real time, on the spot, using noninvasive sensors, with the goal of being able to screen travelers in an automated fashion with equal or greater effectiveness than the methods used today without impeding their ˚ow.14although behavioral methods are useful under some circumstances (such as reallife circumstances that closely approximate laboratory conditions), they are intrinsically subject to three limitations:ł manytoone. any given pattern of physiological activity can result from or be correlated with a number of quite different psychological or physical states.ł probabilistic. any detected sign or pattern conveys at best a change 14 u.s. department of homeland security, ﬁdeception detection: identifying hostile intent,ﬂ s&t snapshots: science stories for the homeland security enterprise 1(1), may 2007, available at http://www.homelandsecurity.org/snapshots/newsletter/200705.htm#deception.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.26 protecting individual privacy in the struggle against terroristsin the likelihood of the behavior, intent, or attitude of interest and are far from an absolute certainty.ł errors. in addition to the highly desirable true positives and true negatives that are produced, there will be the very troublesome false positives (i.e., a person telling the truth is thought to be lying) and false negatives (i.e., a person lying is thought to be telling the truth). such errors are linked to the probabilistic nature of behavioral signals and a lack of knowledge today about how to interpret such signals.privacy issues associated with behavioral surveillance are regarded by the committee to be far more signicant and farranging than those associated with the collection and use of electronic databases, in part because of their potential for abuse, in part because of what they may later reveal about an individual that is potentially unconnected to terrorist activities, in part because of a sense that the intrusion is greater if mental state is being probed, in part because people expect to be allowed to keep their thoughts to themselves, and in part because there is often much more ambiguity regarding interpretation of the results.1.7 the social and organizational contexttechnology is always embedded in a social and organizational context. people operate machines and devices and make decisions based on what these machines and devices tell them. in turn, these decisions are based on certain criteria that are organizationally specied. for example, a metal detector is placed at the entrance to a building. at the request of the security guard, a visitor walks through the detector. if the detector buzzes, the guard searches the visitor more closely. if the guard nds a weapon, the guard conscates it and calls his superior to take the visitor for additional questioning. the guard carries out these procedures because they are required by the organization responsible for building securityšand if the guard does not carry out these procedures, security may be compromised despite the presence of the metal detector.nor can the presence of the relevant machines and devices be taken for granted. there are many steps that must be taken before the relevant machine or device is actually deployed and put into use at a security checkpoint, and even when the science underpinning the relevant machines and devices is known, the science must be instantiated into artifacts. for example, a functional metal detector depends on some understanding of the science of metal detection, even if the theory is not completely known. prototypes must be built and problems in the manufacturing process overcome. budgets must be available to acquire the necessary devices and to train security guards in their operation. oversight protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 27must be exercised to ensure that the processes and procedures necessary to decide on and implement a program are correctly followed.protecting privacy often depends on social and organizational factors as well. for example, the effectiveness of rules that prohibit agents or analysts from disclosing certain kinds of personal information about the targets of their investigations is based on the willingness and ability of those agents or analysts to follow the rules and the organization™s willingness and ability to enforce them. while encryption may provide the technical capability to protect data from being viewed by someone without the decryption key, policies and practices determine whether encryption capabilities are actually used in the proper circumstances.the social and organizational context in which technology is embedded is important from a policy standpoint because the best technology embedded in a dysfunctional organization or operated with poorly trained human beings is often ineffective. this point goes beyond the usual concerns about a technology that is promising in the laboratory being found too unwieldy or impractical for widespread use in the eld.1.8 key concepts1.8.1 the meaning of privacy15in both everyday discourse and the scholarly literature, a commonly agreedon abstract denition of privacy is elusive. for example, privacy may refer to protecting the condentiality of information; enabling a sense of autonomy, independence, and freedom to foster creativity; wanting to be left alone; or establishing enough trust that individuals in a given community are willing to disclose data under the assumption that they will not be misused. for purposes of this report, the term ﬁprivacyﬂ is generally used in a broad and colloquial sense that encompasses the technical denitions of privacy and condentiality commonly used in the statistical literature. that is, the statistical community™s denition of privacy is an individual™s freedom from excessive intrusion in the quest for information and an individual™s ability to choose the extent and circumstances under which his or her beliefs, behaviors, opinions, and attitudes will be shared with or withheld from others. condentiality is the care in dissemination of data in a manner that does not permit identication of the respondent or would in any way be harmful to him or her and that 15 an extended discussion of the meaning of privacy can be found in national research council, engaging privacy and information technology in a digital age, the national academies press, washington, d.c., 2007.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.28 protecting individual privacy in the struggle against terroriststhe data are immune from legal process.16 put differently, privacy relates to the ability to withhold personal data, whereas condentiality relates to the activities of an agency that has collected such data from others. yet another sense of privacy to keep in mind is that of a set of restrictions on how or for how long personal information can be used. in this report, when these distinctions are important, these different senses of meaning will be explicitly addressed, but in the less technical sections, the term ﬁprivacyﬂ will be used in a more generic fashion.in its starkest terms, privacy is about what personal information is being kept private and which parties the information is being kept from. for example, one notion of privacy involves condentiality or secrecy of some specic information, such as preventing disclosure of an individual™s library records to the government. a second notion of privacy involves anonymity, as re˚ected in, for example, an unattributable chat room discussion that threatens the use of violence against innocent parties.these two simple examples illustrate two key points regarding privacy. first, the party against which privacy is being invoked may have a legitimate reason for wanting access to the information being deniedša government conducting a terrorist investigation may want to know what a potential suspect is reading, or a law enforcement ofcial may need the identity of the person threatening violence in order to protect innocent people. second, some kind of balancing of competing interests may be necessaryšthus raising the question of the circumstances under which the government should have access to such information.in practice, three other issues are also critical to understanding the privacy interests in any given situation: what the information will be used for, where the information comes from, and what the consequences are for the individual whose information is at issue. regarding purpose, divulging personal information for one purpose may not be regarded as a violation of privacy, whereas divulging the same information for a different purpose may be regarded as a clear violation of privacy. (in other words, a ﬁjustiedﬂ violation of an individual™s privacyšthat is, for a reason that is good and valid to the individual in questionšis generally not viewed as a violation of his or her privacy interests by that individual.) regarding source, government collection of personal information is often regarded as different in kind from private collection of personal information, although government is increasingly making use of personal data gathered by private parties. this point is especially signicant because laws that restrict government collection of personal information often do 16 national research council, private lives and public policies: condentiality and accessibility of government statistics, national academy press, washington, d.c., 1993.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 29not apply to private collection, and the government breaks no law in purchasing such information from private parties. regarding consequences, for many people, a primary consideration in privacy is the adverse consequences they may experience if their privacy is compromisedšdenial of nancial benets, personal embarrassment or shame, and so on.the notion of trust is intimately related to the meaning of privacy. brie˚y put, people tend to invoke rights to privacy much more strongly when they fear the motivations or intent of the entity that is to receive their data. that is, a lack of trust in these datareceiving entities drives both the strength of people™s desires for privacy and their conceptions of privacy. this is especially true when the datareceiving entity is capable of imposing an adverse consequence on them. box 1.1 addresses this point further.privacy also has a variety of more technical meanings, some of which are elaborated in appendix l (ﬁthe science and technology of privacy protectionﬂ). the most welldened of these meanings for scientic study is based on the intuitive notion that a system containing an individual™s information protects his or her privacy if all events, such as being singled out for additional attention at airport security, being denied medical insurance coverage, or gaining entrance to the college of his or her choice, are no more likely than if the system did not contain that information. this meaning can be formalized, as described in appendix l (section l.2).1.8.2 effectivenessthe effectiveness of a technology, a system, or a program is judged by the extent to which it directly furthers the objective being sought. effectiveness is a measure of technical performance, and policy makers and government ofcials responsible for developing, purchasing, deploying, and using informationbased programs must make judgments regarding whether a given level of effectiveness is sufcient to proceed with the use or deployment of a given technology, system, or program. section 1.8.4 addresses false positives and false negatives as essential elements of judging the effectiveness of a program.the qualication of ﬁdirectlyﬂ furthering the objective being sought is an important one. from time to time, technologies, systems, or programs are admittedly ineffective from a technological point of view and yet are justied on the basis of their alleged deterrent value. that is, their mere presence and the adversary™s concern that they might work are said to help deter the adversary from taking such an action.17 the desirability of 17 in the example of the metal detector, one might imagine that the device consisted only of a buzzer activated randomly on 30 percent of the individuals passing through and with no protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.30 protecting individual privacy in the struggle against terroristsadmittedly ineffective systems that might help to deter adversaries is not considered in this report.1.8.3 law and consistency with valuesmeasures of effectiveness deal with issues of feasibility. legality and ethicality, in contrast, address issues of desirability. not all technically feasible technologies, systems, or programs are desirable. law provides one codication of national values that prescribes required actions and metal detection circuitry at all. such a device would be useless in detecting metal knives and guns, but assuming its internal operation were kept secret, its presence could still arguably provide deterrent valuešwouldbe carriers of guns and knives would be deterred by the possibility that they faced some chance that they would be physically searched. in practice, the physical search would be the mechanism for detecting 30 percent of the individuals carrying guns or knives, but the detector as such would have no value. note also that a policy of sampling 30 percent of individuals at random would have the same effect in practice, and both would arguably have a comparable deterrent effect.box 1.1 a relationship between privacy and trust the national research council report engaging privacy and information technology in a digital age (2007) explicitly addresses the relationship between privacy and trust. specically, that committee found (in finding 4) that ﬁprivacy is particularly important to people when they believe that the entity receiving their personal information is not trustworthy and that they may be harmed by sharing that information.ﬂ that report goes on to explain (pp. 311312): trust is an important issue in framing concerns regarding privacy. in the context of an individual providing personal information to another, the sensitivities involved will depend on the degree to which the individual trusts that party to refrain from acting in a manner that is contrary to his or her interests (e.g., to pass it along to someone else, to use it as the basis for a decision with inappropriately adverse consequences). as an extreme case, consider the act of providing a complete dossier of personal information on a stack of paperšto a person who will destroy it. if the destruction is veriable to the person providing the dossier (and if there is no way for the destroyer to read the dossier), it would be hard to assert the existence of any privacy concern at all. but for most situations in which one provides personal information, the basis for trust is less clear. children routinely assert privacy rights to their personal information against their parents when they do not trust that parents will not criticize them or punish them or think ill of them as a result of accessing that information. (they also assert privacy rights in many other situations.) adults who purchase health insurance often assert privacy rights in their medical information because they are concerned that insurers might not insure them or might charge high prices on the basis of some information in their medical record. many citizens assert privacy rights against government, although few would object to the gathering of personal information within the borders of the united states and about u.s. citizens if they could be assured that such information was being used only for genuine national security purposes and that any information that had been gathered about them was accurate and appropriately interpreted and treated . . . . perversely, many people hold contradictory views about their own privacy and other people™s privacyšthat is, they support curtailing the privacy of some demographic groups at the same time that they believe that their own should not be similarly curtailed. this dichotomy almost certainly re˚ects their views about the trustworthiness of certain groups versus their own. in short, the act of providing personal information is almost always accompanied to varying degrees by a perceived risk of negative consequences ˚owing from an abuse of trust. the perception may or may not be justied by the objective facts of the situation, but trust has an important subjective element. if the entity receiving the information is not seen as trustworthy, it is likely that the individuals involved will be much more hesitant to provide that information (or to provide it accurately) than they would be under other circumstances involving a greater degree of trust. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 31box 1.1 a relationship between privacy and trust the national research council report engaging privacy and information technology in a digital age (2007) explicitly addresses the relationship between privacy and trust. specically, that committee found (in finding 4) that ﬁprivacy is particularly important to people when they believe that the entity receiving their personal information is not trustworthy and that they may be harmed by sharing that information.ﬂ that report goes on to explain (pp. 311312): trust is an important issue in framing concerns regarding privacy. in the context of an individual providing personal information to another, the sensitivities involved will depend on the degree to which the individual trusts that party to refrain from acting in a manner that is contrary to his or her interests (e.g., to pass it along to someone else, to use it as the basis for a decision with inappropriately adverse consequences). as an extreme case, consider the act of providing a complete dossier of personal information on a stack of paperšto a person who will destroy it. if the destruction is veriable to the person providing the dossier (and if there is no way for the destroyer to read the dossier), it would be hard to assert the existence of any privacy concern at all. but for most situations in which one provides personal information, the basis for trust is less clear. children routinely assert privacy rights to their personal information against their parents when they do not trust that parents will not criticize them or punish them or think ill of them as a result of accessing that information. (they also assert privacy rights in many other situations.) adults who purchase health insurance often assert privacy rights in their medical information because they are concerned that insurers might not insure them or might charge high prices on the basis of some information in their medical record. many citizens assert privacy rights against government, although few would object to the gathering of personal information within the borders of the united states and about u.s. citizens if they could be assured that such information was being used only for genuine national security purposes and that any information that had been gathered about them was accurate and appropriately interpreted and treated . . . . perversely, many people hold contradictory views about their own privacy and other people™s privacyšthat is, they support curtailing the privacy of some demographic groups at the same time that they believe that their own should not be similarly curtailed. this dichotomy almost certainly re˚ects their views about the trustworthiness of certain groups versus their own. in short, the act of providing personal information is almost always accompanied to varying degrees by a perceived risk of negative consequences ˚owing from an abuse of trust. the perception may or may not be justied by the objective facts of the situation, but trust has an important subjective element. if the entity receiving the information is not seen as trustworthy, it is likely that the individuals involved will be much more hesitant to provide that information (or to provide it accurately) than they would be under other circumstances involving a greater degree of trust. prohibits other actions. although society expects its government to obey the law, it is also true that technologies and events outpace the rate at which law changes. such rapid changes often leave policy makers with a difcult gray area in which certain actions are not explicitly prohibited but that nevertheless may be inconsistent with a broad notion of american values.a good example of the impact of technological change on the law is the interpretation of the supreme court in 1976 in united states v. miller18 that there can be no reasonable expectation of privacy in information held by a third party. the case involved cancelled checks, to which, the court noted, ﬁrespondent can assert neither ownership nor possession.ﬂ19 such documents ﬁcontain only information voluntarily conveyed to the banks and exposed to their employees in the ordinary course of business,ﬂ20 and 18 united states v. miller, 425 u.s. 435 (1976).19 id. at 440.20 id. at 442.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.32 protecting individual privacy in the struggle against terroriststherefore the court found that the fourth amendment is not implicated when the government sought access to them:the depositor takes the risk, in revealing his affairs to another, that the information will be conveyed by that person to the government. this court has held repeatedly that the fourth amendment does not prohibit the obtaining of information revealed to a third party and conveyed by him to government authorities, even if the information is revealed on the assumption that it will be used only for a limited purpose and the condence placed in the third party will not be betrayed.21congress reacted to the decision by enacting modest statutory protection for customer nancial records held by nancial institutions,22 but there is no constitutional protection for nancial records or for any other personal information that has been disclosed to third parties. as a result, the government can collect even the most sensitive information from a third party without a warrant and without risk that the search may be found unreasonable under the fourth amendment.the court reinforced its holding in miller in the 1979 case of smith v. maryland, involving information about (as opposed to the content of) telephone calls.23 the court found that the fourth amendment is inapplicable to telecommunications ﬁattributesﬂ (the number dialed, the time the call was placed, the duration of the call, etc.), because that information is necessarily conveyed to, or observable by, third parties involved in connecting the call.24 ﬁ[t]elephone users, in sum, typically know that they must convey numerical information to the phone company; that the phone company has facilities for recording this information; and that the phone company does in fact record this information for a variety of legitimate business purposes.ﬂ25 as with information disclosed to nancial institutions, congress reacted to the supreme court™s decision by creating a statutory warrant requirement for pen registers,26 but the constitution does not restrict government action in this area.some legal analysts believe that this interpretation regarding the categorical exclusion of records held by third parties from fourth amendment protection makes less sense today because of the extraordinary increase in both the volume and the sensitivity of information about individuals so often held by third parties. in this view, the digital transactions of daily 21 id. at 443 (citation omitted).22 right to financial privacy act of 1978, 12 u.s.c. §§ 34013422.23 442 u.s. 735 (1979).24 442 u.s. 735 (1979).25 id. at 743.26 18 u.s.c. §§ 3121, 1841. a pen register is a device that records all numbers dialed from a particular telephone line.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 33life have become ubiquitous.27 such transactions include detailed information about individuals™ behavior, communications, and relationships.at the same time, people who live in modern society do not have a real choice to refrain from leaving behind such trails. even in the 1970s when miller and smith were decided, individuals who wrote checks and made telephone calls did not voluntarily convey information to third partiesšthey had no choice but to convey the information if they wanted to make largevalue payments or communicate over physical distances. and in those cases, the third parties did not voluntarily supply the records to the government. financial institutions are required to keep records (ironically, this requirement is found in the right to financial privacy act), and telephone companies are subject to a similar requirement about billing records. in both cases, the government demanded the records. and, at the same time, the information collected and stored by banks and telephone companies is subject to explicit or implicit promises that it will not be further disclosed. most customers would be astonished to nd their checks or telephone billing records printed in the newspaper.today, such transactional records may be held by more private parties than ever before. for example, a handful of service providers already process, or have access to, the large majority of credit and debit card transactions, automated teller machine (atm) withdrawals, airline and rental car reservations, and internet access, and the everyday use of a credit card or atm card involves the disclosure of personal nancial information to multiple entities. in addition, digital networks have facilitated the growth of vigorous outsourcing markets, so information provided to one company is increasingly likely to be processed by a separate institution, and customer service may be provided by another. and all of those entities may store their data with still another. moreover, there are information aggregation businesses in the private sector that already combine personal data from thousands of privatesector sources and public records. they maintain rich repositories of information about virtually every adult in the country, which are updated daily by a steady stream of incoming data.28finally, in this view, the fact that all of the data in question are in digital form means that increasingly powerful toolsšsuch as automated data miningšcan be used to analyze it, thereby reducing or eliminating privacy protections that were previously based on obscurity and difculty 27 k.m. sullivan, ﬁunder a watchful eye: incursions on personal privacy,ﬂ pp. 128146 in the war on our freedoms: civil liberties in an age of terrorism (r.c. leone and g. anrig jr., eds.), the century foundation, new york, n.y., 2003. 28 see, generally, u.s. government accountability ofce, personal information: agency and reseller adherence to key privacy principles, gao 06421, washington, d.c., 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.34 protecting individual privacy in the struggle against terroristsof access to the data. the impact of miller in 1976 was limited primarily to government requests for specic records about identied individuals who had already done something to warrant the government™s attention, whether or not the suspicious activity amounted to probable cause. today, the miller and smith decisions allow the government to obtain the raw material on millions of individuals without any reason for identifying anyone in particular.thus, in this view, the argument suggests that by removing the protection of the fourth amendment from all of these records solely because they are held by third parties, there is a signicant reduction in the constitutional protection for personal privacyšnot as the result of a conscious legal decision, but through the proliferation of digital technologies. in short, under current fourth amendment jurisprudence, all personal information in thirdparty custody, no matter how sensitive or how revealing of a person™s health, nances, tastes, or convictions, is available to the government without constitutional limit. the government™s demand need not be reasonable, no warrant is necessary, no judicial authorization or oversight is required, and it does not matter if the consumer has been promised by the third party that his or her data would be kept condential as a condition of providing the information.a contrary view is that miller and smith are important parts of the modern fourth amendment and that additional privacy protections in this context should come from congress rather than the courts. according to this view, miller and smith ensure that there are some kinds of surveillance that the government can conduct without a warrant. fourth amendment doctrine has always left a great deal of room for unprotected activity, such as what happens in public: the fact that the police can watch in public areas for criminal activity without being constrained by the fourth amendment is critical to the balance of the fourth amendment™s rule structure. in switching from physical activity to digital activity, everything becomes a record. if all records receive fourth amendment protection, treating every record as private, the equivalent of something inside the home, then the government will have considerable difculty monitoring criminal activity without a warrant. in effect, under this interpretation, the fourth amendment would apply much more broadly to recordsbased and digital crimes than it does to physical crimes, and all in a way that would make it very difcult for law enforcement to conduct successful investigations. in this view, the best way forward is for the supreme court to retain smith and miller and for congress to provide statutory protections when needed, much as it has done with the enactment of privacy laws, such as the electronic communications privacy act.given these contrasting perspectives and the important issues they protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 35raise, the constitutional and policy challenges for the future are to decidešexplicitly and in light of new technological developmentsšthe appropriate boundaries of fourth amendment jurisprudence regarding the disposition of data held by third parties. the courts are currently hearing cases that help get to this question; so far they have indicated that noncontent information is covered by miller but that content information receives full fourth amendment protection. but these cases are new and may be overturned, and it will be some years before clearer boundaries emerge denitively.1.8.4 false positives, false negatives, and data quality29false positives and false negatives arise in any kind of classication exercise.30 for example, consider a counterterrorism exercise in which it is desirable to classify each individual in a set of people as ﬁnot worthy of further investigation/does not warrant obtaining more information on these peopleﬂ or ﬁworthy of further investigation/does warrant obtaining more information on these people,ﬂ based on an examination of data associated with each individual. a false positive is someone placed in the latter category who has no terrorist connection. a false negative is someone placed in the former category who has a terrorist connection.consider a naïve notional system in which a computer program or a human analyst examines the data associated with each individual, searching for possible indications of terrorist attack planning. this examination results in a score for each individual that indicates the relative likelihood of him or her being ﬁworthy of further investigationﬂ relative to all of the others being examined.31 when all of the individuals are examined, they are sorted according to this score.this rank ordering does not, in itself, determine the classicationšin addition, a threshold must be established to determine what scores will correspond to each category. the critical point here is that setting this threshold is the responsibility of a human analystštechnology does not, 29 this section is adapted largely from national research council, engaging privacy and information technology in a digital age, the national academies press, washington, d.c., 2007, chapter 1.30 an extensive treatment of false positives and false negatives (and the tradeoffs thereby implied) can be found in national research council, the polygraph and lie detection, the national academies press, washington, d.c., 2003.31 the score calculated by any given system may simply be an index with only ordinal (rankordering) properties. if more information is available and a more sophisticated analytical approach is possible, the score may be an actual bayesian probability or likelihood that could be manipulated quantitatively in accordance with the mathematics of probability and statistics.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.36 protecting individual privacy in the struggle against terroristsindeed cannot, set this threshold. moreover, it is likely that the appropriate setting of a threshold depends on the consequences for the individual being miscategorized. if the realworld consequence of a false positive for a given individual is being denied boarding of an airplane compared with looking at more records relevant to that individual, one may wish greater certainty to reduce the likelihood of a false positivešthis desire would tend to drive the threshold higher in the rst instance than in the second. in addition, any real analyst will not be satised with a system that impedes the further investigation of someone whose score is below the threshold. that is, an analyst will want to reserve the right (have the ability) to designate for further examination an individual who may have been categorized as below thresholdšto say, in effect, ﬁthat guy has a lower score than most of the others, but there™s something strange about him anyway, and i want to look at him more closely even if he is below threshold.ﬂbecause the above approach is focused on individuals, any realistic setting of a threshold is likely to result in enormous numbers of false positives. one way to reduce the number of false positives signicantly is to exploit the fact that terroristsšespecially those with big plans in mindšare most likely to operate in small groups (also known as cells). thus, a more sophisticated system could consider a different unit of analysisšgroups of individuals rather than individualsšthat might be worth further investigation. this approach, known as collective inference, focuses on analyzing large collections of records simultaneously (e.g., people, places, organizations, events, and other entities).32 conceptually, the output of this system could be a rank ordering of all possible groups (combinations) of two individuals, another rank ordering of all possible groups of three individuals, and so on. once again, thresholds would be set to determine groups that were worth further investigation. the rank orderings resulting from a grouporiented analysis could also be used to rule out individuals who might otherwise be classied as worthy of further investigationšif an individual with an abovethreshold score was not found among the groups with abovethreshold scores, that individual would be either a lone wolf or clearly seen to be a false positive and thus eliminated before the investigation went any further.a ﬁbruteforceﬂ search of all possible groups of two, of three, and so on when the population in question is that of the united states is daunting, to say the least. but in practice, most of those groups will be individuals with no plausible connections among them, and thus the 32 more detail on these ideas can be found in d. jensen, m. rattigan, and h. blau, ﬁinformation awareness: a prospective technical assessment,ﬂ proceedings of the 9th acm sigkdd international conference on knowledge discovery and data mining, 2003, available at http://kdl.cs.umass.edu/papers/jensenetalkdd2003.pdf.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 37records containing information about those groups need not be examined. identifying such groups is a problem, but other techniques may be useful in eliminating some groups at a fairly early stagešfor example, if a group does not contain individuals who have communicated with each other, that group might be eliminated from further consideration. all such criteria also run the risk of incurring false negatives, and it remains to be seen how useful such pruning efforts are in practice.false positives and false negatives arise from two other sources. one is the validity of the model used to distinguish between terrorists and innocent individuals. a perfectly valid model of a terrorist is one in which a set of specic measurable characteristics, if correctly associated with a given individual, would correctly identify that individual as a terrorist with 100 percent accuracy, and other individuals lacking one or more of those characteristics would be correctly identied as an innocent individual. of course, in the real world, no model is perfect, and so false positives and false negatives are inevitable from the imperfection of models.the second and independent source of false positives and false negatives is imperfect data. that is, even if a model were perfect, in the real world, the data asserted to be associated with a given individual is not in fact associated with that individual. for example, an individual™s height may be recorded as 6.1 meters, whereas his height may in fact be 1.6 meters. her religion may be recorded as protestant, but in fact she may be a practicing catholic. such data errors arise for a wide range of reasons, including keyboarding errors, faulty intelligence, errors of translation, and so on. improving data quality can thus reduce the rate of false positives and false negatives, but only up to the limits inherent in the imperfections of the model. since models, for computability, abstract only some of the variables and behaviors of reality, they are by design imperfect. model imperfections are a builtin source of error, and better data cannot compensate for a model™s inadequacies.model inadequacies stem from several possible sources: (1) the required data for various characteristics in the assumed causal model may not be available, (2) some variables may be left out to simplify computations, (3) some variables that are causal may be available but unknown, (4) the precise form of the relationship between the predictor variables and the assessment of degree of interest is unknown, (5) the form of the relationship may be simplied to expedite computation, and (6) the phenomenon may be dynamic in nature and therefore any datedness in the inputs could cause erroneous improper predictions.data quality is the property of data that allows them to be used effectively and rapidly to inform and evaluate decisions.33 ideally, data should 33 a.f. karr, a.p. sanil, and d.l. banks, ﬁdata quality: a statistical perspective,ﬂ statistical methodology 3:137173, 2006; t.c. redman, ﬁdata: an unfolding quality disaster,ﬂ protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.38 protecting individual privacy in the struggle against terroristsbe correct, current, complete, and relevant. data quality is intimately related to false positives and false negatives, in that it is intuitively obvious that using data of poor quality is likely to result in larger numbers of false positive and false negatives than would be the case if the data were of high quality.data quality is a multidimensional concept. measurement error and survey uncertainty contribute (negatively) to data quality, as do issues related to measurement bias. many issues arise as the result of missing data elds; inconsistent data elds in a given record, such as recording a pregnancy for a 9yearold boy; data incorrectly entered into the database, such as that which might result from a typographical error; measurement error; sampling error and uncertainty; timeliness (or lack thereof); coverage or comprehensiveness (or lack thereof); improperly duplicated records; data conversion errors, as might occur when a database of vendor x is converted to a comparable database using technology from vendor y; use of inconsistent denitions over time; and denitions that become irrelevant over time.all of the forgoing discussion relates to the implications of measurement error that could easily arise in a given environment or database. however, when data come from multiple databases, they must be linked, and the methodology for performing data linkages in the absence of clear, unique identiers is probabilistic in nature. even in welldesigned record linkage studies, such as those developed by the census bureau, automated matching is capable of reliably matching only about 75 percent of the people (although some appreciable fraction of the remainder are not matchable), and handmatching of records is required to reduce the remaining number of unresolved cases.34 the difculty of reliable matching, superimposed on measurement error, will inevitably produce much more substantial problems of false positives and false negatives than most analysts recognize.data issues also arise as the result of combining databasesšsyntactic inconsistencies (one database records phone numbers in the form 2025551212 and another in the form 2025551212); semantic inconsistencies (weight measured in pounds vs. weight measured in kilograms); different dm review magazine, august 2004, available at http://www.dmreview.com/articlesub.cfm?articleid=1007211; w.w. eckerson, ﬁdata warehousing special report: data quality and the bottom line,ﬂ application development trends magazine, may 1, 2002, available at http://www.adtmag.com/article.aspx?id=6303; y. wand and r. wang, ﬁanchoring data quality dimensions in ontological foundations,ﬂ communications of the acm 39(11):8695, november 1996; and r. wang, h. kon, and s. madnick, ﬁdata quality requirements analysis and modelling,ﬂ ninth international conference of data engineering, vienna, austria, 1993.34 m.j. anderson and s.e. fienberg, who counts? the politics of censustaking in contemporary america, russell sage foundation, new york, 1999, p. 70.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 39provenance for different databases; inconsistent data elds for records contained in different databases on a given data subject; and lack of universal identiers to specify data subjects.missing data are a major cause of reduction in data quality. in the situation in which network linkages are of interest and are directly represented in a database, the problem of missing data can sometimes be easier and sometimes more challenging than in the case of a rectangular le. a rectangular le usually consists of a list of individuals with their associated characteristics. in this situation, missing data can be of three general types: item nonresponse, unit nonresponse, and undercoverage. item and unit nonresponse, while certainly problematic in the current context, are limited in impact and can sometimes be addressed using such techniques as imputation. even undercoverage, while troubling, is at least limited to the data for the individual in question. (if such an individual is represented on another database to which one has access, merging and unduplicating operations can be helpful to identication, and estimates of the number of omissions can be developed using dualsystems estimation.)on one hand, when the appropriate unit of analysis is networks of individuals (i.e., the individuals and their characteristics along with the various linkages between them are represented as being present or absent), the treatment of missing data can be easier when linkages from other individuals present in a database, such as phone calls, emails, or the joint issuance of plane tickets, etc., can help inform the analyst of another individual™s existence for whom no direct information was collected.on the other hand, treating missing data can also be a challenging problem. if the data for a person in a network is missed, not only is the information on that individual unavailable, but also the linkages between that person and others may be missing. this can have a substantial impact on the data for the missing individual, as well as the data for the other members of the group in the network and even the structure of the network, since in an extreme case it may be that the missing individual is the sole linkage between two otherwise separate groups. it is likely that existing missing data techniques can be adapted to provide some assistance in the less extreme cases, but at this point this is an area in which additional research may be warranted.false positives and false negatives are in some sense complementary for any given database and given analytical approach. more precisely, for a given database and analytical approach, one can drive the rate of false positives to zero or the rate of false negatives to zero, but not simultaneously. decreases in the false positive rate are inevitably accompanied by increases in the false negative rate and vice versa, although not necessarily in the same proportion. however, as the quality of the data is protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.40 protecting individual privacy in the struggle against terroristsimproved or if the classication technique is improved, it is possible to reduce both the false positive rate and the false negative rate, provided an accurate model for true positives and negatives is used.both false positives and false negatives pose problems for counterterrorist efforts. in the case of false positives, a counterterrorism analyst searching for evidence of terrorist attack planning may obtain personal information on a number of individuals. all of these individuals surrender some privacy, and those who have not been involved in terrorist activity (the false positives) have had their privacy violated or their rights compromised despite the lack of such involvement. moreover, the use of purloined identitiesšidentity theftšhas enabled various kinds of fraud and evasion of law enforcement already. if terrorists are able to assume other identities, not only will that capability enable them to evade some detection and obfuscate the data used in the modelsšthat is, deliberately manipulate the system, resulting in the generation of false positives against innocent individualsšbut also it also might result in extreme measures being taken against the innocent individuals whose identities have been stolen.every false positive also has an opportunity cost; that is, it is associated with a waste of resourcesšprecious investigative or analytical resources that are expended in the investigation of a innocent individual. in addition, false positives put pressure on ofcials to justify the expenditure of such resources, and such pressures may also lead to abuses against innocent individuals. from an operational standpoint, the key question is how many false alarms are acceptable. if one has innite resources, it is easy to investigate every false alarm that may emerge from any system, no matter how poor its performance. but in the real world of constrained resources, it is necessary to balance the number of false alarms against the resources available to investigate them as well as the severity of the perceived threat. furthermore, it is also important to consider other approaches that might be protably applied to the problem, as well as other security issues in need of additional effort.false negatives are also a problem and the nightmare of the intelligence analyst. a false negative is someone who should be under suspicion and is not. that is, the analyst simply misses the terrorist. from a political standpoint, the only truly acceptable number for false negatives is zerošbut this political requirement belies the technical reality that the number of false negatives can never be zero. moreover, identifying false negatives in any given instance may be problematic. in the case of the terrorist investigation, it is essentially impossible to know with certainty if a person is a false negative until he or she is known to have committed a terrorist act.false positives and false negatives (and data quality, because it affects protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 41both false positives and false negatives) are important in a discussion of privacy because they are the language in which the tradeoffs between privacy and other needs are often cast. one might argue that the consequences of a false negative (a terrorist plan is not detected and many people die) are in some sense much larger than the consequences of a false positive (an innocent person loses privacy or is detained). for this reason, many decision makers assert that it is better to be safe than sorry. but this argument is fallacious. there is no reason to expect that false negatives and false positives trade off against one another in a oneforone manner. in practice, the tradeoff will almost certainly entail one false negative against an enormous number of false positives, and a society that tolerates too much harm to innocent people based on large a number of false positives is no longer a society that respects civil liberties.1.8.5 oversight and prevention of abuseadministrators of government agencies face enormous challenges in ensuring that policies and practices established by higher authorities (e.g., congress, the executive ofce of the president, the relevant agency secretary or director) are actually followed in the eld by those who do the daytoday work of the agency. in the counterterrorism context, one especially important oversight responsibility is to ensure that the policies and practices meant to protect citizen privacy are followed in a mission environment that is focused on ensuring transportation safety, protecting borders, and pursuing counterterrorism. challenges in this domain arise not only from external pressures based on public concern over privacy but also from internal struggles about how to motivate high performance while adhering to legal requirements and staying within budget.preventing privacy abuses from occurring is particularly important in a counterterrorism context, since privacy abuses can erode support for efforts that might in fact have some effectiveness in or utility for the counterterrorist mission. in this context, abuse refers to practices that result in a dissemination of personally identiable information and thereby violate promised, implied, or legally guaranteed condentiality or civil liberties.35 this point implies that oversight must go beyond the enforcement 35 personally identiable information (pii) refers to any information that identies or can be used to identify, contact, or locate the person to whom such information pertains. this includes information that is used in a way that is personally identiable, including linking it with identiable information from other sources, or from which other personally identiable information can easily be derived, including, but not limited to, name, address, phone number, fax number, email address, nancial proles, social security number, credit card information, and in some cases internet ip address. although pii is also said to not include information collected anonymously, the discussion above suggests that the ability to make protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.42 protecting individual privacy in the struggle against terroristsof rules and procedures established to cover known and anticipated situations, to be concerned with unanticipated situations and circumstances.oversight can occur at the planning stage to approve intended operations, during execution to monitor performance, and retrospectively to assess previous performance so as to guide future improvements. effective oversight may help to improve trust in government agencies and enhance compliance with stated policy.1.9 the need for a rational assessment processin the years since the september 11, 2001, attacks, the u.s. government has initiated a variety of informationbased counterterrorist programs that involved data mining as an important component. it is fair to say that a number of these programs, including the total information awareness program and the computerassisted passenger prescreening system ii (capps ii), generated signicant controversy and did not meet the test of public acceptability, leaving aside issues of technical feasibility and effectiveness.such outcomes raise the question of whether the nature and character of the debate over these and similar programs could have been any different if policy makers had addressed in advance some of the difcult questions raised by a program. although careful consideration of the privacy impact of new technologies is necessary even before a program seriously enters the research stage, it is interesting and important to consider questions in two categories: effectiveness and consistency with u.s. laws and values.the threshold consideration of any privacysensitive technology is whether it is effective toward a clearly dened law enforcement or national security purpose. the question of effectiveness must be assessed through rigorous testing guided by scientic standards. research on the question of how largescale data analytical techniques, including data mining, could help the intelligence community identify potential terrorists is certainly a reasonable endeavor. assuming that the initial scientic research justies additional effort based on the scientic community™s standards of success, that work should continue, but it must be accompanied by a clear method for assessing the reliability of the results.an identication may depend both on the specic values of the pii in question and on the ability to aggregate data in ways that reduce signicantly or even eliminate the anonymity originally promised or implied. thus, information that previously was not pii may at a later date become pii as new techniques are developed or as other nonpii information becomes available. in short, the denition of pii can easily vary with context. for more discussion, see national research council, engaging privacy and information technology in a digital age, the national academies press, washington, d.c., 2007.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.scoping the issue: terrorism, privacy, and technology 43even if a proposed technology is effective, it must also be consistent with existing u.s. law and democratic values. addressing this issue may involve a twopart inquiry. one must assess whether the new technique and objective comply with existing law, yet the inquiry cannot end there. inasmuch as some programs seek to enable the deployment of very largescale data mining over a larger universe of data than the u.s. government has previously analyzed, the fact that a given program complies with existing law does not establish that such surveillance practice is consistent with democratic values.a framework for decision making about informationbased programs couched in terms of questions in these two categories is presented in chapter 2.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.442a framework for evaluating informationbased programs to fight terrorism or serve other important national goalsthe government increasingly uses technologies, programs, and systems that involve the acquisition, use, retention, or sharing of information about individuals to ght terrorism or serve other important national goals. these systems are very diverse and in the counterterrorism context range from requiring identication to board airplanes or enter government buildings to telephone and email surveillance and intensive mining of commercial records. for purposes of this framework, this chapter describes all of these, together with the people who operate them, as informationbased programs because they have in common their reliance on information about individuals.this chapter proposes a framework for evaluating and deploying technologies, programs, and systems that rely on personal data to prevent terrorism or to serve other important national goals. this framework establishes sets of criteria to address the likely effectiveness and the lawfulness and consistency with u.s. values of any proposed informationbased program.2.1 the need for a framework for evaluating informationbased programsalthough informationbased programs are not new, advances in digital technology and the proliferation of digital information about individuals have expanded their variety, the interest in their use, and potentially their impact. as a result, informationbased programs often raise difcult protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 45questions about privacy and other civil liberties, cost, effectiveness, legality, and consistency with societal values.these issues and the lack of consensus about how they should be evaluated have contributed to limiting the ability of public ofcials to make rational and informed choices about informationbased programs for counterterrorism, research on potentially promising systems, and the availability of information about such systems and their use.many groups and individuals have considered how informationbased programs should be evaluated and under what conditions they should be deployed. the u.s. department of defense technology and privacy advisory committee,1 the u.s. department of homeland security privacy and integrity advisory committee,2 the markle foundation task force on national security in the information age,3 and the mccormick tribune foundation™s cantigny conference on counterterrorism technology and privacy4 are among the many groupsšinside and outside governmentšto address these vital issues. there is a striking degree of consistency among their recommendations and also in the extent to which they have not been implemented.building on the work of these prior efforts and informed by the members™ experiences and research, the committee designed a framework to guide public ofcials charged with making decisions about the development, procurement, and use of informationbased programs. its purpose is not to impose bureaucratic compliance requirements, but rather to assist wellmeaning people at every level of government to do their jobs better, to enhance their effectiveness in countering terrorist threats, to facilitate the wise and timely implementation of new programs, to invest limited government resources wisely, and to ensure that basic american values are not compromised when doing so. the committee also intends the framework to assist judges and policy makers responsible for approving or evaluating those decisions, legislators in crafting the law that governs these programs, and the press and the public in their broad and critical oversight of government activities.this framework not only shares much in common with the recommendations of prior groups, but it is also consistent with many of the widely recognized standards that already guide information technology procurement, deployment, and use decisions in industry and other areas 1 see technology and privacy advisory committee, safeguarding privacy in the fight against terrorism, department of defense, washington, d.c., march 2004, available at http://www.cdt.org/security/usapatriot/20040300tapac.pdf.2 see http://www.dhs.gov/xinfoshare/committees/editorial0512.shtm.3 for more information, see http://www.markletaskforce.org/.4 see ﬁthe cantigny principles on technology, terrorism, and privacy,ﬂ national security law report 27(1):1416, february 2005.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.46 protecting individual privacy in the struggle against terroristsof government. although this framework is necessarily broader, since it reaches far beyond information technology, it mirrors many of the best practices re˚ected in the control objectives for information and related technologies (cobit), the it infrastructure library (itil), international organization for standards (iso) 17799, and the standards promulgated by the national institute of standards and technology (nist), among others.in short, the individual elements of what the committee proposes are not wholly new. they re˚ect much of the wise advice that the government has receivedšand largely failed to implementšmany times before, advice that both it and the private sector do follow in other areas. it is the committee™s hope that by adding to this prior work the breadth of experience, knowledge, and expertise re˚ected in its membership, it can offer a comprehensive framework that policy makers will, in fact, implement. it is the integration of the individual elements that the committee does think is new.at the heart of this framework are two sets of questions: first, is an informationbased program effective or likely to be effective in achieving its intended goalšin short, does it work? second, does the program comply with the law and re˚ect the values of society, especially concerning the protection of data subjects™ civil liberties?although these questions are posed as having yesno answers, any serious application of the framework will almost certainly result in information on how effective and how protective of civil liberties any given informationbased program is. this is critical knowledge when determining which of many competing systems, if any, should be developed, acquired, or deployed, and how they might be used or improved. for any potential program, policy makers will have to exercise sound judgment in deciding whether the program is sufciently effective and sufciently protective of privacy to warrant proceeding with it, although such judgment should be undertaken after the framework has been applied rather than before.the questions posed by this framework should be asked not only of all new informationbased programs, but also of existing programs today, at regular intervals in the future, and any time that a program is to be altered or put to a different use, to ensure that scarce resources are invested wisely; tools are used appropriately, lawfully, and consistently with societal values; and the best protection is pursued for national security and civil liberties. as discussed in greater detail below, achieving such goals requires routine monitoring, ongoing auditing, and clear, competent oversight. in short, the application of the framework is an ongoing process that should last throughout the operational lifetime of a program.technology can aid considerably in the application of the framework, protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 47and the effectiveness with which the framework addresses many issues can be enhanced through the use of technologyšfor example, the creation of immutable audit records and the continuous, automated analysis of those records. but technology alone is not sufcient. what is most critical is that the tools necessary to ensure compliance with the frameworkšwhether or not they are technologicalšbe built into informationbased programs to the greatest extent possible and internalized into the processes by which they are developed, acquired, deployed, and used.the framework is deliberately and necessarily broad because it is designed to apply to all informationbased programs. as a result, not all of the points addressed by the framework may be applicable to all programs. points that are inapplicable should be noted explicitly, along with a clear explanation of why they are inapplicable. the fact that a point is difcult to address should not be a justication for ignoring it. honest, wellreasoned responses are far more useful to system developers, users, and overseers than none at all, and incomplete or erroneous responses can be supplemented or corrected as additional experience with a program is gained.the framework and the processes by which it is implemented need to be evaluated regularly and revised as necessary to ensure that it is achieving these objectives. the fact that the framework is undoubtedly imperfect is no reason for avoiding it. too frequently the argument is heard that national security is too important and the terrorist threat too great to pause to ask hard questions of the systems to be deployed to protect the nation. in the committee™s view, that is the wrong approach. it is precisely because national security is important and the threats to it are great that it is so important to ensure that the systems to be deployed to protect the nation are effective and are consistent with u.s. values.2.2 evaluating effectivenessthe rst inquiry about an informationbased program is concerned with effectiveness: whether a program achieves its intended purpose (i.e., does it work?), with what precision it does so (i.e., how well does it work?), how it might be made to work better in the future, and how its effectiveness compares with that of other available alternatives. for example, grounding all airplanes would be a highly effective technique for preventing terrorist bombings of airplanes in ˚ight, but it would not be a workable solution because it would also keep millions of lawabiding passengers from ˚ying. as this example suggests, ineffective or overly broad programs often create signicant side effects that extend far beyond the immediate impact on the data subjects.it is impossible in the abstract to establish acceptable levels of effecprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.48 protecting individual privacy in the struggle against terroriststiveness because the level that society demands of any given program is likely to depend on the severity and likelihood of the consequences it is designed to guard against and the burden on individuals and overall cost of the program designed to prevent those consequences.what matters is that policy makers and government ofcials responsible for developing, purchasing, deploying, and using informationbased programs systematically evaluate the effectiveness of those programs and assess whether they are warranted in light of their likely effectiveness. this is seldom easy, and it is made more difcult by four factors: the rapid change in technologies and applications, the evolving nature of terrorist threats, the fact that so much of the information about terrorist threats and countermeasures is classied, and the reality that dealing with broadbased terrorist threats will require many programs to be scalable to a level far beyond what is typically required in industry or academic settings.the following criteria are designed to assess and enhance effectiveness in light of these challenges. they are intended to ensure that the nation invests its human, technological, and nancial resources wisely. they should be addressed before a new informationbased program is procured or deployed and, as appropriate, at regular intervals during the development and use of such a program.1. there should be a clearly stated purpose for the informationbased program. it is impossible to assess a program™s effectiveness without knowing what it was intended to accomplish. a clear, precise objective is the foundation for any system.a. is that objective worthwhile?b. is it legally appropriate?c. is there a demand or need for it?d. is it already being accomplished or could it be accomplished through less intrusive or less costly means?a system™s purpose should be the basis for judging if the system is appropriate, and thereafter a basis for assessment of the system and for audits of its use. the purpose may be updated in response to changed circumstances or new experience with the system, but changes to the purpose should be explicit.2. there should be a sound rational basis for the informationbased program and each of its components. is there a scientic foundation for the system? for most informationbased programs, the rational basis will have to take into account not only how individual components work in a laboratory, but also how they will work together and in connection with other systems in the eld. this inquiry is likely to involve not only computer science, statistics, and related elds, but also a range of other social and behavioral sciences.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 493. there should be a sound experimental basis for the informationbased program and each of its components. experimental science, and much of engineering as well, generally involves a logical progression from theory to simulations to laboratory tests, to smallscale eld tests, to larger scale tests. in the rush to nd quick responses to pressing national security concerns, there is a natural tendency to want to skip one or more of these phases, but the hundreds of millions of dollars wasted on systems that did not go through appropriate experimentation and subsequently did not work suggest that such omissions seldom pay off.a. does the system work to achieve its stated purpose?b. has the new system been shown to work in simulations or laboratory settings or has it been eldtested?c. did the test conditions take into account realworld conditions?d. has it been applied to historical data to determine if it accurately accomplished its objective?e. have experimental successes been replicated to demonstrate that they were not coincidence?f. has the system been subjected to critical analysis, challenge, and likely countermeasures (for example, through ﬁredteamingﬂ)?54. the informationbased program should be scalable. a system for enhancing security that appears promising in the laboratory may well fail in the eld if it cannot be scaled up to deal with the realworld ˚ood of data (or even the physical demands of conducting background checks or security scans at airports). testing scalability has been a special challenge in this area because of the difculty of obtaining data sets for testing of appropriate size and complexity. in some instances, congress has proven too quick to rush to judgment on potential systems that were being tested but not deployed, and administration ofcials have been insufciently frank about the need for data for testing. testing on a data set of adequate size is essential to predicting the scalability and therefore the effectiveness of any informationbased program. 5. there should be a clearly stated set of operational or business processes that comprehensively specify how the informationbased program should operate in the organization, including who interacts with the program, whether programmatically for input, analysis, or obtaining results, or operationally for maintenance and modication, and with what authority; the information sources and how they are processed; and how the operations dened by the processes contributes to achieving 5 ﬁredteamingﬂ refers to the practice of conducting realistic ﬁblindﬂ tests against a system. such tests are blind in the sense that the operators of the system do not know that they are being tested, and realistic in the sense that the testers are free to do most or all of the things that actual terrorists might or could do in challenging the system.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.50 protecting individual privacy in the struggle against terroriststhe stated purpose. this criterion addresses issues related to operational integration of the program with the organization.6. the informationbased program should be capable of being integrated in practice with relevant systems and tools inside and outside the organization. for example:a. does the system interact effectively with the sources of information on which it relies?b. if it requires combining data, can it do so in practice to yield meaningful results, at the necessary speed, while maintaining an appropriate level of information integrity?c. can the end product of the system be acted on meaningfully by people or other systems?7. informationbased programs should be robust. this requires not only that the program work reliably in the eld, but also that it not easily be compromised by user errors or circumvented by countermeasures. investments in programs that are easily undercut or avoided are rarely sound.8. there should be adequate guarantees that the data on which the informationbased program depends are appropriate and reliable. data should be stored as long as necessary, but they should be deleted when appropriate and regularly updated if they are needed by the system on an ongoing basis.a. are there adequate guarantees of the information™s validity, provenance, availability, and integrity? such guarantees are particularly important if a failure to meet the guarantees might adversely affect an individual.b. are the data easily compromised or manipulated so that the system can be defeated?an informationbased program is no better than the data on which it relies, and too many proposals for systems that initially appeared promising foundered when questions were raised about the adequacy and reliability of the source data.9. the informationbased program should provide for appropriate data stewardship, a term that refers to accountability for program resources being used and protected appropriately according to the dened and authorized purpose. the data must be protected from unlawful or unauthorized disclosure, manipulation, or destruction. in addition, there should be technologies and/or procedures built into the system to ensure that privacy, security, and other data stewardship and governance policies are followed.10. there should be adequate guarantees of objectivity in the testing and assessment of the informationbased program. in the race for success stories and government contracts in the ght against terrorism, there is protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 51a clear tendency to promote systems that lack appropriate guarantees of objectivity in the testing of their effectiveness. this is unacceptable when spending public money, especially when the stakes are so high. no agency or vendor should do all of the testing on the informationbased programs it is promoting. academics typically depend on peer review. that may be more difcult when the systems involved are classied, but it is the standard that the government should be seeking to achieve through appropriate measures. often scientists or other experts with clearances can help test and evaluate the test results on systems they have not been involved in developing. technical advisory committees, with members with appropriate clearances, are useful. thirdparty assessment even within the government, so that one agency tests another™s systems, would help bring independence to the development and evaluation process. the government should assess independently the effectiveness of any system that it is considering purchasing or deploying. to the extent possible, testing should be blindšto both researchers and research subjectsšso that the risk of biasing the outcome is diminished. the causes of failures should be documented so that they can be avoided in developing future systems, or reexplored as technologies and data sources evolve. failures, as well as successes, should be reported together with what the agency has learned about the cause of those failures.11. there should be ongoing assessment of the informationbased program. no system, no matter how well designed or tested, will be perfect. there will always be not only unforeseen issues, but also entirely foreseeable ones, such as erroneous or mismatched data, false positives, and false negatives. assessment is critical to detecting errors, correcting them, and improving systems to reduce errors in the future. assessment is also essential to ensuring that the system is used properly and only for appropriate purposes. are there mechanisms for detecting, reporting, and correcting errors? are there monitoring tools and regular audits to assess system and operator performance?12. the effectiveness of the informationbased program and its compliance with these key requirements should be documented. documentation is necessary to ensure that these critical issues are addressed during the development of new informationbased programs, and also to respond to subsequent inquiries about their effectiveness. satisfactory documentation should be required before any informationbased program is procured or deployed. when such a system uses personally identiable information or otherwise affects privacy, the documentation should be examined by an entity, such as an independent scientic review committee, that is capable of evaluating the scientic evidence of effectiveness outside the agency promoting the new system.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.52 protecting individual privacy in the struggle against terrorists2.3 evaluating consistency with u.s. law and valuesthe second inquiry is concerned with whether a proposed (or existing) informationbased program is consistent with u.s. law and values. lawfulness is more likely to be binary: a proposed action either is or is not against the law. u.s. society expects its government to obey the law, and it is required by the constitution to do so. in addition, because technologies and events usually outpace law, it is necessary to constantly consider what types of informationbased programs should be lawful. in short, are they consistent with the values of u.s. society?the values inquiry is always difcult, especially in the context of a diverse and pluralistic society like that of the united states. but it is essential in order to respect the values that undergird the system of government and bind people together. evaluating informationbased programs in light of values is also essential because the supreme court has limited the fourth amendment to protect only ﬁreasonable expectationsﬂ of privacy, and it has found that reasonableness is measured in part by what society is willing to accept as reasonable and in part by what individuals™ subjective expectations are. an awareness of society™s values and individual expectations is therefore critical for understanding what expectations of privacy the law is likely to regard as reasonable and therefore afford legal protection. in addition, paying attention to core values is necessary to avoid creating a race to the bottomšin which the public begins to accept uses of personal data only because the law permits them.there are also practical, utilitarian reasons for concern about values. promising antiterrorism systems may be derailed, even ones well within existing law, because they so offend popular and political understandings of privacy that go beyond existing legal requirements.the determination as to whether a proposed system is lawful, or should be lawful, often requires evaluating the effectiveness of the system in light of its purpose, cost, and the consequences if it fails. as a result, while clear and unambiguous (brightline) legal rules are desirable, they inevitably rely on subjective judgments that overlap with the effectiveness criteria described above. for example, the precision and accuracy of a system are key aspects of any determination of legality in which individual rights are involved. if the government obtains a warrant to tap a specied phone line but taps another line instead, it has probably broken the law. or if a surveillance order from a court requires the government to delete nonrelevant communications but it fails to do so, the entire court order and all of the evidence obtained through it can be thrown out. understanding a program™s effectiveness is also often necessary because the law requires the government and courts to assess whether there are any equally effective but less intrusive means of accomplishing the purpose. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 53in the absence of an assessment of effectiveness, such a requirement is impossible to satisfy.effectiveness also matters from the standpoint of values, not so much as a requirement of a specic law, but as a commonsense or even an ethical requirement. any intrusion on privacy would be entirely unjustied if it were not accompanied by some reasonable chance of accomplishing a worthwhile purpose. if an intrusion is perforce ineffective, it would seem by its very nature unwarranted. (of course, the converse is not necessarily truešit may be that even effective programs should not be deployed because they do offend the ethical sensibilities of the citizenry.)the following criteria are therefore designed not only to ensure that a proposed system is lawful in the face of existing laws, but also to reduce the impact on privacy that might otherwise render the system either unlawful in the future or politically impractical. they should be addressed by agency ofcials before a new informationbased program is procured or deployed and, as appropriate, at regular intervals during the development and use of such a system. the committee also believes that the criteria should be useful to judicial and congressional ofcials as they evaluate new and existing programs and determine the boundaries of the nation™s laws protecting privacy and other civil liberties. the criteria are divided into three categories to facilitate their application.2.3.1 data1. need for personal data. the need for personal data to accomplish the stated purpose and the specic uses for personal data should be clearly identied. personal data should not be used unless they are reasonably necessary to achieve the stated objective and effective in doing so. alternatives should be explicitly considered to determine whether there are equally effective means of achieving the same purpose that rely less on personal data (or on less personal data). such alternatives are usually preferable.2. sources of data. the sources of those personal data should be clearly identied. it must be lawful for the source to supply the data and for the agency to obtain them.3. appropriateness of data. the personal data should be determined to be appropriate for the intended use, taking into account the purpose(s) for which the data were collected, their age, and the conditions under which they have been stored and protected. data quality, integrity, and provenance should be assessed explicitly and determined to be appropriate for the intended use and objective. in addition, informationbased programs should not rely exclusively on data that relate to the exercise of protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.54 protecting individual privacy in the struggle against terroristsrights protected by the first amendment (i.e., freedom of expression, the press, assembly, religion, and petition).4. thirdparty data. because using personal data from other government agencies or from private industry may present special risks, such thirdparty data should be subject to additional protections:a. the agency should take into account the purpose for which the data were collected, their age, and the conditions under which they have been stored and protected when determining whether the proposed informationbased program is appropriate.b. if data are to be used for purposes that are inconsistent with those for which they were originally collected, the agency should specically evaluate whether the inconsistent use is justied and whether the data are appropriate for such use.c. because of the difculty of updating, overseeing, and maintaining the accuracy and context of data that have been copied from place to place, data should be left in place whenever possible (i.e., in the hands of the third parties that originally controlled those data). if this is impossible, they should be returned or destroyed as soon as practicable.d. private entities that provide data to the government on request or subject to judicial process should be reasonably compensated for the costs they incur in complying with the government™s request or order.2.3.2 programs5. objective. the objective of the informationbased program should be clearly stated. that objective must be lawful to pursue by the agency developing, procuring, or deploying the program.6. compliance with existing law. the informationbased program should comply with applicable existing law.7. effectiveness. using scientically valid criteria, the informationbased program should be demonstrated to be effective in achieving the intended objective.8. frequency and impact of false positives. the informationbased program should be demonstrated to yield a rate of false positives that is acceptable in view of the purpose of the search, the severity of the effect of being identied, and the likelihood of further investigation.9. reporting and redress of false positives. there must be in place a process for identifying the frequency and effects of false positives and for dealing with them (e.g., reporting false positives to developers to improve the system, correcting incorrect information if possible, remedying the effects of false positives as quickly as practicable), as well as a specic locus of responsibility for carrying out this process.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 5510. impact on individuals. the likely effects on individuals identied through the informationbased program should be dened clearly (e.g., they will be the subject of further investigation for which a warrant will be sought, they will be subject to additional scrutiny before being allowed to board an aircraft, and so on).11. data minimization. the informationbased program should operate with the least personal data consistent with its objective. only the minimally necessary data should be accessed, disseminated, or retained. this has long been a requirement of u.s. surveillance law, although it has been rendered largely irrelevant in recent years as technology and applications have evolved so that vast streams of data are recorded and stored, rather than just limited, relevant elements. moreover, the proliferation of digital data and dramatic reductions in the costs associated with sharing and storing data mean that even irrelevant data are routinely retained by the government indenitely. giving new force to minimization requirements is essential to avoiding the situation of government maintaining ubiquitous data records that threaten to invade personal privacy and overwhelm efforts to use data effectively to enhance security. whenever practicable, the informationbased program should rely on personal data from which information by which specic individuals can be commonly identied (e.g., name, address, telephone number, social security number, unique title) has been removed, encrypted, or otherwise obscured.12. audit trail. the informationbased program should create a permanent, tamperresistant record of when data have been accessed and by whom. continuous, automated analysis of audit records can help ensure compliance with applicable laws and policies. this is especially important when sensitive or potentially sensitive data are involved.13. security and access. the informationbased program should be secured against accidental or deliberate unauthorized access, use, alteration, or destruction. access to such an informationbased program should be restricted to persons with a legitimate need and protected by appropriate access controls, taking into account the sensitivity of the data.14. transparency. the informationbased program should be developed, deployed, and operated with the greatest transparency possible, consistent with its objective. persons affected by the program and the public generally should be informed as fully as practicable of the existence of the program, its purpose, cost, the laws and regulations under which it operates, the measures in place for assessing its effectiveness and protecting privacy, and the process for reporting and obtaining redress of grievances concerning its operation.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.56 protecting individual privacy in the struggle against terrorists2.3.3 administration and oversight15. training. all persons engaged in developing or using informationbased programs should be trained in their appropriate use and the laws and regulations applicable to their use.16. agency authorization. no informationbased program that involves the acquisition, use, retention, or sharing of personally identiable information should be developed, procured, or deployed until a senior agency ofcial, preferably one subject to senate conrmation, has certied in writing that it complies with the requirements of this framework.17. external authorization. the deployment or use of any informationbased program that relies on sensitive personally identiable information, personally identiable information collected surreptitiously, personally identiable information that has been obtained from a third party without individual consent, or personally identiable information that is being used for a purpose that is incompatible with that for which it was originally collected should be conditioned on an appropriately specic authorization from a source external to the informationbased program.6 typically, this would be authorization by an appropriate court (federal article iii, foreign intelligence surveillance, or state), but congress may provide for other forms of external authorization.18. auditing for compliance. informationbased programs should be audited not less than annually to ensure compliance with the provisions of this framework and other applicable laws and regulations. the party conducting such audits may or may not be in the department responsible for the program but should operate and report independently of the program in question.19. privacy ofcer. before an agency develops, procures, or deploys an informationbased program, it should have in place a policylevel privacy ofcer. the privacy ofcer would be responsible for ensuring the training of appropriate agency personnel on privacy issues; assisting in the design and implementation of systems to protect privacy; working with the general counsel, inspector general, other appropriate ofcials in 6 the specicity of the authorization required in any given instance is an issue that changing technologies have highlighted in the context of the wiretapping of voice calls. for example, for criminals who use throwaway cell phones, authorizations that grant wiretap authority to law enforcement agencies only for specic phone numbers are obviously much less useful than authorizations that grant wiretap authority for all phones that a specic individual might use. furthermore, the committee expects that the issue of specicity will become more important as the scope of information sought becomes broader. because the nature of the appropriate specicity depends on the particular information needs of a given program, it is impossible for the committee to specify in advance in its broad framework the appropriate level of specicity. however, it does note that policy makers should make explicit decisions regarding the appropriate level of specicity.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 57the agencies to ensure compliance with such systems; providing advice and information on privacy issues and tools for protecting privacy; and advising agency leaders and personnel on privacy matters and the implementation of this framework.20. reporting. an agency that develops, procures, or deploys an informationbased program should report to congress not less than annually, or more frequently as required by law, on the use of the system; its effectiveness; the nature, use, and timeliness of redress mechanisms; and the integrity of the system and the data on which it relies. the report should be made public to the greatest extent possible.2.4 a note for policy makers: applying the framework in the futurein times of crisis, policy makers are often pressured into making important decisions with inadequate information and too little time for consultation and deliberation. when those decisions involve laws concerning informationbased programs, the consequences can be especially signicant and longlasting. law inevitably tends to lag behind technology, yet dramatic technological changes can alter the scope of laws overnight. so, for example, when the supreme court excluded records maintained by third parties from the scope of the fourth amendment in 1976, it created a situation in which, 30 years later, because of the proliferation of digital records maintained by third parties, almost all information about individuals would be accessible to the government without judicial authorization.the committee intends the entire framework proposed in this chapter to be useful to policy makers in outlining issues to be addressed through legislation or regulatory policy, as well as in proposing specic steps for ensuring that the nation ghts terrorism effectively and consistently in accord with its core values. however, the breadth and variety of informationbased programs, as well as the constantly changing capacity of technology, make crafting legislation governing those programs and protecting civil liberties a difcult task. to further facilitate effective legislation to achieve these critical goals, the committee presents this additional brief discussion of how the framework might be applied in the legislative context.in the committee™s view, all such legislation should specically address the following eight areas (many specic elements of which have already been described above):1. agency competency. is the agency being authorized to operate or use the informationbased program competent to do so? is the program protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.58 protecting individual privacy in the struggle against terroristsconsistent with its mission? is it staffed appropriately? are its staff trained appropriately? does it have a policylevel chief privacy ofcer? does it have a culture of respecting the law and civil liberties?2. purpose. does the informationbased program have a clearly articulated purpose against which its effectiveness and impact on civil liberties can be assessed? are there appropriate protections to guard against mission creep or repurposing of the program without careful deliberation? will that purpose remain valid in the face of countermeasures or likely technological changes? are there procedures in place for reevaluating that purpose?3. effectiveness. are there appropriate guarantees that the informationbased program and each of its components are effective? are credible processes in place to measure effectiveness and to ensure continual assessment of effectiveness and efforts to improve effectiveness? are measures of effectiveness documented?4. authorization. are requirements in place for authorization by an identied, accountable ofcial both before an informationbased programs is created, procured, or deployed and before such programs are applied to personal data about a specic individual? does the authorization for applying the program to a specic individual come from a court or other source external to the agency operating the program, especially if the data gathering or use is covert?5. data. are there reasonable guarantees that the personal data to be used by an informationbased program are appropriate, sufciently accurate for the stated purpose, and reliably available on a timely basis? are there protections to ensure that only necessary personal data are used, retained no longer than necessary, and protected against accidental or deliberate misuse? are the data and the manner in which they are obtained consistent with u.s. values? does their use deter the exercise of constitutionally protected rights?6. redress. are there robust systems in place to identify errors, such as false positives, use them systematically to improve informationbased programs, and provide rapid, effective redress to affected individuals?7. assessment. are there reliable tools for assessing the performance of informationbased programs and their compliance with applicable laws and regulations, as well as for acting on those assessments? are the results of ongoing assessment documented?8. oversight. is the informationbased program subject to meaningful oversight from both inside and outside the agency, including from congress? are the program and its oversight mechanism transparent to the public and the press to the greatest extent possible? if transparency is impossible, are there reliable means for heightened independent agency, judicial, and/or congressional oversight?protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 592.5 summary of framework criteria2.5.1 for evaluating effectiveness1. is there a clearly stated purpose for the informationbased program? ł is that objective worthwhile? ł is it legally appropriate? ł is there a demand or need for it? ł is it already being accomplished or could it be accomplished through less intrusive or less costly means?2. is there a sound rational basis for the informationbased program and each of its components? ł is there a scientic foundation for the system?3. is there a sound experimental basis for the informationbased program and each of its components? ł does the system work to achieve its stated purpose? ł has the new system been shown to work in simulations or laboratory settings or has it been eldtested? ł did the test conditions take into account realworld conditions? ł has it been applied to historical data to determine if it accurately accomplished its objective? ł have experimental successes been replicated to demonstrate that they were not coincidence? ł has the system been subjected to critical analysis, challenge, and likely countermeasures (for example, through ﬁredteamingﬂ)?4. is the informationbased program scalable? ł has it been tested on a data set of adequate size to predict its scalability? ł has it been tested against likely countermeasures or changes in technologies, threats, and society?5. is there a clearly stated set of operational or business processes that comprehensively specify how the informationbased program should operate in the organization?6. is the informationbased program capable of being integrated in practice with related systems and tools? ł does the system interact effectively with the sources of information on which it relies?protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.60 protecting individual privacy in the struggle against terrorists ł if it requires combining data, can it do so in practice to yield meaningful results and at the speed necessary? ł can the end product of the system be acted on meaningfully by people or other systems?7. is the informationbased program robust? ł can it easily be compromised by user errors? ł can it easily be circumvented by countermeasures?8. are there appropriate guarantees that the data on which the informationbased program depends are appropriate and reliable? ł are there adequate guarantees of the information™s validity, provenance, availability, and integrity? ł are the data easily compromised or manipulated so that the system can be defeated?9. does the informationbased program provide for appropriate data stewardship? ł are the data protected from unlawful or unauthorized disclosure, manipulation, or destruction? ł are there technologies and/or procedures built into the system to ensure that privacy, security, and other data stewardship and governance policies are followed?10. are there adequate guarantees of objectivity in the testing and assessment of the informationbased program? ł has there been peer review or its equivalent? ł has the program been evaluated by entities with no stake in its success? ł have test results been evaluated by independent experts? ł was testing blindšto both researchers and research subjectsšwhenever possible?11. is there ongoing assessment of the informationbased program? ł are there mechanisms for detecting and reporting errors? ł are there monitoring tools and regular audits to assess system and operator performance?12. have the effectiveness of the informationbased program and its compliance with these key requirements been documented? ł has the documentation been examined by an entity capable of evaluating the scientic evidence of effectiveness outside the agency promoting the new system?protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 612.5.2 for evaluating consistency with laws and valuesthe agency1. does the agency have in place a policylevel privacy ofcer?2. does the agency report to congress not less than annually, or more frequently as required by law, on the use of its informationbased programs, their effectiveness, the nature and use of redress mechanisms, and the integrity of the programs and the data on which they rely? is that report made public to the greatest extent possible?3. have all persons engaged in developing or using informationbased programs been trained in their appropriate use and the laws and regulations applicable to their use?the program4. is the objective of the informationbased program clearly stated? is that objective lawful for the agency developing, deploying, or using the program to pursue?5. does the informationbased program comply fully with applicable existing law?6. has the informationbased program been demonstrated to be effective in achieving the intended objective? is that demonstration based on scientically valid criteria?7. has the informationbased program been demonstrated to yield a rate of false positives that is acceptable in view of the purpose of the search, the severity of the effect of being identied, and the likelihood of further investigation?8. is there a process in place for identifying the frequency and effects of false positives and for dealing with them (e.g., reporting false positives to developers to improve the system, correcting incorrect information if possible, remedying the effects of false positives as quickly as practicable), as well as a specic locus of responsibility for carrying out this process?9. have the likely effects on individuals identied through the informationbased program been dened clearly (e.g., they will be the subject of further investigation for which a warrant will be sought, they will be subject to additional scrutiny before being allowed to board an aircraft, and so on)?10. does the informationbased program operate with the least personal data consistent with its objective? does it access, disseminate, and retain only minimally necessary data? have data by which specic individuals can be commonly identiprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.62 protecting individual privacy in the struggle against terroristsed (e.g., name, address, telephone number, social security number, unique title) been removed, encrypted, or otherwise obscured whenever possible?11. does the informationbased program create a permanent, tamperresistant record of when data have been accessed and by whom? does it provide for continuous, automated analysis of audit records?12. is the informationbased program developed, deployed, and operated with the greatest transparency possible, consistent with its objective?13. is the informationbased program secured against accidental or deliberate unauthorized access, use, alteration, or destruction? is access to the informationbased program restricted to persons with a legitimate need and protected by appropriate access controls, taking into account the sensitivity of the data?14. has (or will) a senior agency ofcial, preferably one subject to senate conrmation, certied (or will certify) in writing that the informationbased program complies with the requirements of this framework?15. if the informationbased program relies on sensitive personally identiable information, personally identiable information collected surreptitiously, personally identiable information that has been obtained from a third party without individual consent, or personally identiable information that is being used for a purpose that is incompatible with that for which it was originally collected, have its deployment and use been conditioned on authorization from a source external to that in which the informationbased program will exist, and have they been approved by an external authority (e.g., an appropriate court or other authority)?16. is the informationbased program audited not less than annually to ensure compliance with the provisions of the proposed framework and other applicable laws and regulations?the data17. are personal data necessary to accomplish the objective of a given informationbased program? are the specic uses for personal data clearly identied? are there equally effective means of achieving the same purpose that rely less on personal data (or on less personal data)?protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 6318. are the sources of personal data clearly identied? is it lawful for the source to supply the data and for the agency to obtain the data?19. are the personal data appropriate for the intended use, taking into account the purpose(s) for which the data were collected, their age, and the conditions under which they have been stored and protected? do the data relate solely to the exercise of rights protected by the first amendment (i.e., freedom of expression, the press, assembly, religion, and petition)?20. if an informationbased program uses personal data from other government agencies or from private industry, are the following additional protections in place? ł have the purpose for which the data were collected, their age, and the conditions under which they have been stored and protected been taken into account when determining whether the proposed informationbased program is appropriate? ł if data are to be used for purposes that are inconsistent with those for which they were originally collected, has the agency specically evaluated whether the inconsistent use is justied and whether the data are appropriate for such use? ł are the data being left in place whenever possible? if this is impossible, are they being returned or destroyed as soon as practicable? ł is the agency reasonably compensating private entities that provide data to the government on request or subject to judicial process for the costs they incur in complying with the government™s request or order?2.5.3 for developing new laws and policies1. agency competency ł i s the agency being authorized to operate or use the informationbased program competent to do so? ł is the program consistent with the agency™s mission? ł is the agency staffed appropriately? ł are its staff trained appropriately? ł does it have a policylevel chief privacy ofcer? ł does it have a culture of respecting the law and civil liberties?protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.64 protecting individual privacy in the struggle against terrorists2. purpose ł does the informationbased program have a clearly articulated purpose against which its effectiveness and impact on civil liberties can be assessed? ł are there appropriate protections to guard against mission creep or repurposing of the program without careful deliberation? ł will the program™s purpose remain valid in the face of countermeasures or likely technological changes? ł are there procedures in place for reevaluating the program™s purpose?3. effectiveness ł has the informationbased program been demonstrated to be effective in achieving the intended objective? ł is that demonstration based on scientically valid criteria? ł are there credible processes in place to measure effectiveness and to ensure continual assessment of effectiveness and efforts to improve effectiveness? ł are measures of effectiveness documented?4. authorization ł are there requirements in place for authorization by an identied, accountable ofcial both before an informationbased program is created, procured, or deployed and before such programs are applied to personal data about a specic individual? ł does the authorization for applying the program to a specic individual come from a court or other source external to the agency operating the program, especially if the data gathering or use is covert?5. data ł are personal data necessary to accomplish the objective of a given informationbased program? ł are the specic uses for personal data clearly identied? ł are there equally effective means of achieving the same purpose that rely less on personal data (or on less personal data)? ł are there protections to ensure that only necessary personal data are used, retained no longer than necessary, and protected against accidental or deliberate misuse?protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.a framework for evaluating informationbased programs 65 ł does the informationbased program operate with the least personal data consistent with its objective? ł does the program access, disseminate, and retain only necessary data? ł have data by which specic individuals can be commonly identied (e.g., name, address, telephone number, social security number, unique title, and so on) been removed, encrypted, or otherwise obscured whenever possible? ł are there reasonable guarantees that the personal data to be used by an informationbased program are appropriate, sufciently accurate for the stated purpose, and reliably available? ł are the sources of those personal data clearly identied? ł is access to the informationbased program restricted to persons with a legitimate need and protected by appropriate access controls, taking into account the sensitivity of the data? ł is it lawful for the source to supply the data and for the agency to obtain the data? ł are the data and the manner in which they are obtained consistent with u.s. values? ł does their use deter the exercise of constitutionally protected rights? ł if an informationbased program uses personal data from other government agencies or from private industry, are the appropriate additional protections in place?6. redress ł is there a process in place for identifying the frequency and effects of false positives and for dealing with them (e.g., reporting false positives to developers to improve the system, correcting incorrect information if possible, remedying the effects of false positives as quickly as practicable, and so on)? ł have the likely effects on individuals identied through the informationbased program been dened clearly (e.g., they will be the subject of further investigation for which a warrant will be sought, they will be subject to additional scrutiny before being allowed to board an aircraft)? ł has the informationbased program been demonstrated to yield a rate of false positives that is acceptable in view of the purpose of the search, the severity of the effect of being identied, and the likelihood of further investigation?protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.66 protecting individual privacy in the struggle against terrorists ł are there robust systems in place to identify errors, such as false positives, use them systematically to improve informationbased programs, and provide rapid, effective redress to affected individuals?7. assessment ł are there reliable tools for assessing the performance of informationbased programs and their compliance with applicable laws and regulations, as well as for acting on those assessments? ł does the informationbased program create a permanent, tamperresistant record of when data have been accessed and by whom? ł does it provide for continuous, automated analysis of audit records? ł is the informationbased program audited not less than annually to ensure compliance with the provisions of this framework and other applicable laws and regulations? ł are the results of ongoing assessment documented?8. oversight ł is the informationbased program subject to meaningful oversight from both inside and outside the agency, including from congress? ł are the program and its oversight mechanism transparent to the public and the press to the greatest extent possible? ł if transparency is impossible, are there reliable means for heightened independent agency, judicial, and/or congressional oversight?protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.673conclusions and recommendations3.1 basic premisesthe committee™s work was informed by a number of basic premises. these premises framed the committee™s perspective in developing this report, and they can be regarded as the assumptions underlying the committee™s analysis and conclusions. the committee recognizes that others may have their own analyses with different premises, and so for analytical rigor, it is helpful to lay out explicitly the assumptions of the committee.premise 1. the united states faces two real and serious threats from terrorists. the rst is from terrorist acts themselves, which could cause mass casualties, severe economic loss, and social dislocation to u.s. society. the second is from the possibility of inappropriate or disproportionate responses to the terrorist threat that can do more damage to the fabric of society than terrorists would be likely to do.the events of september 11, 2001, provided vivid proof of the damage that a determined terrorist group can in˚ict on u.s. society. all evidence to date suggests that the united states continues to be a prime target for such terrorist groups as al qaeda, and future terrorist attacks could cause protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.68 protecting individual privacy in the struggle against terroristsmajor casualties, severe economic loss, and social disruption.1 the danger of future terrorist attacks on the united states is both real and serious.at the same time, inappropriate or disproportionate responses to the terrorist threat also pose serious dangers to society. history demonstrates that measures taken in the name of improving national security, especially in response to new threats or crises, have often proven to be both ineffective and offensive to the nation™s values and traditions of liberty and justice.2 so the danger of unsuitable responses to the terrorist threat is also real and serious.given the existence of a real and serious terrorist threat, it is a reasonable public policy goal to focus on preventing attacks before they occurša goal that requires detecting the planning for such attacks prior to their execution. given the possibility of inappropriate or disproportionate responses, it is also necessary that programs intended to prevent terrorist attacks be developed and operated without undue compromises of privacy.premise 2. the terrorist threat to the united states, serious and real though it is, does not justify government authorities conducting activities or operations that contravene existing law.the longevity of the united states as a stable political entity is rooted in large measure in the respect that government authorities have had for the rule of law. regardless of the merits or inadequacies of any legal regime, government authorities are bound by its requirements until the legal regime is changed, and, in the long term, public condence and trust in government depend heavily on a belief that the government is indeed adhering to the laws of the land. the premises above would not change even if the united states were facing exigent circumstances. if existing legal authorities (including any emergency action provisions, of which there are many) are inadequate or unclear to deal with a given situation 1 for example, the national intelligence estimate of the terrorist threat to the u.s. homeland provides a judgment that ﬁthe u.s. homeland will face a persistent and evolving terrorist threat over the next three years. the main threat comes from islamic terrorist groups and cells, especially alqa™ida, driven by their undiminished intent to attack the homeland and a continued effort by these terrorist groups to adapt and improve their capabilities.ﬂ see the terrorist threat to the u.s. homeland, national intelligence estimate, july 2007, available from ofce of the director of national intelligence, washington, d.c.2 consider, for example, the 1942 internment of u.s. citizens of japanese origin in the wake of the pearl harbor attack. the united states formally apologized to the japanese american community for this act in 1988, and beginning in 1990 paid reparations to surviving internees.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 69or contingency, government authorities should seek to change the law rather than to circumvent or disobey it.a willingness of u.s. government authorities to circumvent or disobey the law in times of emergency is not unprecedented. for example, recently declassied central intelligence agency (cia) documents indicate widespread violations of the agency™s charter and applicable law in the 1960s and 1970s, during which time the cia conducted surveillance operations on u.s. citizens under both democratic and republican presidents that were undertaken outside the agency™s charter.3the u.s. congress has also changed laws that guaranteed condentiality in order to gain access to individual information collected under guarantees. for example, section 508 of the usa patriot act, passed in 2001, allows the u.s. department of justice (doj) to gain access to individual information originally collected by the national center for education statistics under a pledge of condentiality. in earlier times, the war powers act of 1942 retrospectively overrode the condentiality provisions of the census bureau, and it is now known that bureau ofcials shared individually identiable census information with other government agencies for the purposes of detaining foreign nationals.4today, many laws provide statutory protection for privacy. conforming to such protections is not only obligatory, but it also builds necessary discipline into counterterrorism efforts that serves other laudable purposes. by making the government stop and justify its effort to a senior ofcial, a congressional committee, or a federal judge, warrant requirements and other privacy protections often help bring focus and precision to law enforcement and national security efforts. in point of fact, courts rarely refuse requests for judicial authorization to conduct surveillance. as government ofcials often note, one reason for these high success rates is the quality of internal decision making that the requirement to obtain judicial authorization requires.premise 3. challenges to public safety and national security do not warrant fundamental changes in the level of privacy protection to which nonterrorists are entitled.the united states is a strong nation for many reasons, not the least of which is its commitment to the rule of law, civil liberties, and respect 3 m. mazzetti and t. weiner, ﬁfiles on illegal spying show c.i.a. skeletons from cold war,ﬂ new york times, june 27, 2007.4 w. seltzer and m. anderson, ﬁcensus condentiality under the second war powers act (19421947),ﬂ paper prepared for the annual meeting of the population association of america, march 30, 2007, population association of america, new york, available at http://www.uwm.edu/~margo/govstat/seltzerandersonpaa2007paper3122007.doc.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.70 protecting individual privacy in the struggle against terroristsfor diversity. especially in times of challenge, it is important that this commitment remain strong and unwavering. new technological circumstances may necessitate an update of existing privacy laws and policy, but privacy and surveillance law already includes means of dealing with national security matters as well as criminal law investigations. as new technologies become more commonly used, these means will inevitably require extension and updating, but greater government access to private information does not trump the commitment to the bedrock civil liberties of the nation.note that the term ﬁprivacyﬂ has multiple meanings depending on context and interpretation. appendix l (ﬁthe science and technology of privacy protectionﬂ) explicates a technical denition of the term, and the term is often used in this report, as in everyday discourse, with a variety of informal meanings that are more or less consistent with the technical denition.premise 4. exploitation of new science and technologies is an important dimension of national counterterrorism efforts.although the committee recognizes that other sciences and technologies are relevant as well, the terms of reference call for this report to focus on information technologies and behavioral surveillance techniques. the committee believes that when large amounts of information, personal and otherwise, are determined to be needed for the counterterrorist mission, the use of information technologies will be necessary and counterterrorist authorities will need to collect, manage, and analyze such information. furthermore, it believes that behavioral surveillance techniques may have some potential for inferring intent from observed behavior if the underlying science proves soundša capability that could be very useful in counterterrorist efforts ﬁon the groundﬂ if realized in the future.premise 5. to the extent reasonable and feasible, counterterrorist programs should be formulated to provide secondary benets to the nation in other domains.counterterrorism programs are often expensive and controversial. in some cases, however, a small additional expenditure or programmatic adjustment may enable them to provide benets that go beyond their role in preventing terrorism. thus, they would be useful to the nation even if terror attacks do not occur. for example, hospital emergency reporting systems can improve medical care by prompt reporting of in˚uenza, food poisoning, or other health problems, as well as alerting ofcials of bioterrorist and chemical attacks.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 71at the same time, policy makers must be aware of the phenomenon of ﬁstatutory mission creepﬂšin which the goals and missions of a program are expanded explicitly as the result of a specic policy action, such as congressional amendment of an existing lawšand avoid its snares. in some instances, such as hospital emergency reporting systems, privacy interests may not be seriously compromised by their application to multiple missions. but in others, such as the use of systems designed for screening terrorists to identify ordinary criminals, privacy interests may be deeply implicated because of the vast and voluminous new data sets that must be brought to bear on the expanded mission. mission creep may also go beyond the original understandings of policy makers regarding the scope and nature of a program that they initially approve, and thus effectively circumvent careful scrutiny. in some cases, a sufcient amount of mission creep may even result in a program whose operation is not strictly legal.3.2 conclusions regarding privacythe rich digital record that is made of people™s lives today provides many benets to most people in the course of everyday life. such data may also have utility for counterterrorist and law enforcement efforts. however, the use of such data for these purposes also raises concerns about the protection of privacy and civil liberties. improperly used, programs that do not explicitly protect the rights of innocent individuals are likely to create secondclass citizens whose freedoms to travel, engage in commercial transactions, communicate, and practice certain trades will be curtailedšand under some circumstances, they could even be improperly jailed.3.2.1 protecting privacyconclusion 1. in the counterterrorism effort, some degree of privacy protection can be obtained through the use of a mix of technical and procedural mechanisms.the primary goal of the nation™s counterterrorism effort is to prevent terrorist acts. in such an effort, identication of terrorists before they act becomes an important task, one that requires the accurate collection and analysis of their personal information. however, an imperfect understanding of which characteristics to search for, not to mention imperfect and inaccurate data, will necessarily draw unwarranted attention to many innocent individuals.thus, records containing personal information of terrorists cannot be protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.72 protecting individual privacy in the struggle against terroristsexamined without violating the privacy of others, and so absolute privacy protectionšin the sense that the privacy of nonterrorists cannot be compromisedšis not possible if terrorists are to be identied.this technical reality does not preclude putting into place strong mechanisms that provide substantial privacy protection. in particular, restrictions on the use of personal information ensure that innocent individuals are strongly protected during the examination of their personal information, and strong and vigorous oversight and audit mechanisms can help to ensure that these restrictions are obeyed.how much privacy protection is afforded by technical and procedural mechanisms depends on critical design features of both the technology and the organization that uses it. two examples of relevant technical mechanisms are encryption of all data transports to protect against accidental loss or compromise and individually logged5 audit records that retain details of all queries, including those made by fully authorized individuals to protect against unauthorized use.6 but the mere presence of such mechanisms does not ensure that they will be used, and such mechanisms should be regarded as one enableršone set of necessary but not sufcient toolsšfor the robust independent program oversight described in recommendation 1c below.relevant procedural mechanisms include restrictions on data collection and restrictions on use. in general, such mechanisms govern important dimensions of information collection and use, including an explication of what data are collected, whether collection is done openly or covertly, how widely the data are disseminated, how long they are retained, the decisions for which they are used, whether the processing is 5 ﬁindividually loggedﬂ refers to audit records designed to monitor system usage by individual users and maintain individual accountability. for example, consider a personnel ofce in which users have access to those personnel records for which they are responsible. individually logged audit trails can reveal that an individual is printing far more records than the average user, which could indicate the selling of personal data.6 note that audit records documenting accesses to a database are conceptually distinct from the data contained within a database. an audit record typically identies the party that took some specic action now captured in the audit record and the nature of the data involved in that action, but it does not specify the content of the data involved. (for example, a database of nancial transactions is routinely updated to include all of the credit card purchases of john smith for the last year. since today is april 14, 2008, the database contains all of his purchases from april 14, 2007, to april 13, 2008. an audit record relevant to those records might include the fact that on january 17, 2004, agent mary doe viewed john smith™s credit card purchasesšthat is, she looked at his purchases from january 17, 2003, to january 16, 2004.) one result of this distinction is that the data within a database may be purged within a short period of time in accordance with a specied data retention policy, but audit records describing accesses to that data may be kept for the entire life of the database.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 73performed by computer or human, and who has the right to grant permissions for subsequent uses.historically, privacy from government intrusion has been protected by limiting what information the government can collect: voice conversations collected through wiretapping, email collected through access to stored data (authorized by the electronic communications privacy act, passed in 1986 and codied as 18 u.s.c. 2510), among others. however, in many cases today, the data in question have already been collected and access to them, under the thirdparty business records doctrine, will be readily granted with few strings attached. as a result, there is great potential for privacy intrusion arising from analysis of data that are accessible to government investigators with little or no restriction or oversight. in other words, powerful investigative techniques with signicant privacy impact proceed in full compliance with existing lawšbut with signicant unanswered privacy questions and associated concerns about data quality.analytical techniques that may be justied for the purpose of national security or counterterrorism investigations, even given their potential power for privacy intrusion, must come with assurances that the inferences drawn against an individual will not then be used for normal domestic criminal law enforcement purposes. hence, what is called for, in addition to procedural safeguards for data quality, are usage limitations that provide for full exploitation on new investigative tools when needed (and justied) for national security purposes, but that prevent those same inferences from being used in criminal law enforcement activity.an examplešfor illustration onlyšof the latter is the use of personal data for airline passenger screening. privacy advocates have often expressed concerns that the government use of largescale databases to identify passengers who pose a potential risk to the safety of an airplane could turn into farreaching enforcement mechanisms for all manner of offenses, such as overdue tax bills or child support payments. one way of dealing with this privacy concern would be to apply a usagelimiting privacy rule that allows the use of databases for the purpose of counterterrorism but prohibits the use of these same databases and analysis for domestic law enforcement. those suspicious of government intentions are likely to nd a rule limiting usage rather less comforting than a rule limiting collection, out of concern that government authorities will nd it easier to violate a rule limiting usage than a rule limiting collection. nevertheless, welldesigned and diligently enforced auditing and oversight processes may help over time to provide reassurance that the rule is being followed as well as to provide some actual protection for individuals.finally, in some situations, improving citizen privacy can have the protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.74 protecting individual privacy in the struggle against terroristsresult of improving their security and vice versa. for example, improvements in the quality of data (i.e., more complete, more accurate data) used in identifying potential terrorists are likely to increase security by enhancing the effectiveness of informationbased programs to identify terrorists and to decrease the adverse consequences that may occur due to condentiality violations for the vast majority of innocent individuals. in addition, strong audit controls that record the details of all accesses to sensitive personal information serve both to protect the privacy of individuals and to reduce barriers to information sharing between agencies or analysts. (agencies or analysts are often reluctant to share information, even among themselves, because they feel a need to protect sources and methods, and audit controls that limit information access provide a greater degree of reassurance that sensitive information will not be improperly distributed.)conclusion 2. data quality is a major issue in the protection of the privacy of nonterrorists.as noted in chapter 1, the issue of data quality arises internally as a result of measurement errors within databases and also as a consequence of efforts to link data or records across databases in the absence of clear, unique identiers. sharing personal information across agencies, even with ﬁnamesﬂ attached, offers no assurances that the linked data are sufciently accurate for counterterrorism purposes; indeed, there are no metrics for accuracy that appear to be systematically used to assess such linking efforts.data of poor quality severely limit the value of data mining in a number of ways. first, the actual characteristics of individuals are often collected in error for a wide array of reasons, including denitional problems, identify theft, and misresponse on surveys.these errors could obviously result in individuals being inaccurately represented by data mining algorithms as a threat when they are not (with the consequence that personal and private information about them might be inappropriately released for wider scrutiny). second, poor data quality can be amplied during le matching, resulting in the erroneous merging of information for different individuals into a single le. again, the results can be improper treatment of individuals as terrorist threats, but here the error is compounded, since entire clusters of information are now in error with respect to the individual who is linked to the information in the merged le.such problems are likely to be quite common and could greatly limit the utility of data mining methods used for counterterrorism. there are no obvious mechanisms for rectifying the current situation, other than colprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 75lecting similar information from multiple sources and using the duplicative nature of the information to correct inaccuracies. however, given that today the existence of alternate sources is relatively infrequent, correcting individual errors will be extraordinarily difcult.3.2.2 distinctions between capability and intentconclusion 3. inferences about intent and/or state of mind implicate privacy issues to a much greater degree than do assessments or determinations of capability.although it is true that capability and intent are both needed to pose a real threat, determining intent on the basis of external indicators is inherently a much more subjective enterprise than determining capability. determining intent or state of mind is inherently an inferential process, usually based on indicators such as whom one talks to, what organizations one belongs to or supports, or what one reads or searches for online. assessing capability is based on such indicators as purchase or other acquisition of suspect items, training, and so on. recognizing that the distinction between capability and intent is sometimes unclear, it is nevertheless true that placing people under suspicion because of their associations and intellectual explorations is a step toward abhorrent government behavior, such as guilt by association and thought crime. this does not mean that government authorities should be categorically proscribed from examining indicators of intent under all circumstancesšonly that special precautions should be taken when such examination is deemed necessary.3.3 conclusions regarding the assessment of counterterrorism programsconclusion 4. program deployment and use must be based on criteria more demanding than ﬁit™s better than doing nothing.ﬂin the aftermath of a disaster or terrorist incident, policy makers come under intense political pressure to respond with measures intended to prevent the event from occurring again. the policy impulse to do something (by which is usually meant something new) under these circumstances is understandable, but it is simply not true that doing something new is always better than doing nothing. indeed, policy makers may deploy new informationbased programs hastily, without a full consideration of (a) the actual usefulness of the program in distinguishing people or characteristic patterns of interest for followup from those not of interprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.76 protecting individual privacy in the struggle against terroristsest, (b) an assessment of the potential privacy impacts resulting from the use of the program, (c) the procedures and processes of the organization that will use the program, and (d) countermeasures that terrorists might use to foil the program.the committee developed the framework presented in chapter 2 to help decision makers determine the extent to which a program is effective in achieving its intended goals, compliant with the laws of the nation, and re˚ective of the values of society, especially with regard to the protection of data subjects™ privacy. this framework is intended to be applied by taking into account the organizational and human contexts into which any given program will be embedded as well as the countermeasures that terrorists might take to foil the program.the framework is discussed in greater detail in chapter 2.3.4 conclusions regarding data mining73.4.1 policy and law regarding data miningconclusion 5. the current policy regime does not adequately address violations of privacy that arise from informationbased programs using advanced analytical techniques, such as stateoftheart data mining and record linkage.the current privacy policy regime was established prior to today™s world of broadband communications, networked computers, and enormous databases. in particular, it relies largely on limitations imposed on the collection and use of certain kinds of information, and it is essentially silent on the use of techniques that could be used to process and analyze alreadycollected information in ways that might compromise privacy.for example, an activity for counterterrorist purposes, possibly a data mining activity, is likely to require the linking of data found in multiple databases. the literature on record linkage suggests that, even assuming the data found in any given database to be of high quality, the data derived from linkages (the ﬁmosaicﬂ consisting of the collection of linked data) are likely to be errorprone. certainly, the better the quality of the individual lists, the fewer the errors that will be made in record linkage, but even with highquality lists, the percentage of false matches and false nonmatches may still be uncomfortably high. in addition, it is also the case that certain data mining algorithms are less sensitive to record linkage errors as inputs, since they use redundant information in a way that can, at times, identify such errors and downweight or delete them. again, even in the best circumstances, such problems are currently extremely 7 additional observations about data mining are contained in appendix h.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 77difcult to overcome. errorprone data are, of course, both a threat to privacy (as innocent individuals are mistakenly associated with terrorist activity) and a threat to effectiveness (as terrorists are overlooked because they have been hidden by errors in the data that would have suggested a terrorist connection).the committee also notes that the use of analytical techniques such as data mining is not limited to government purposes; private parties, including corporations, criminals, divorce lawyers, and private investigators, also have access to such techniques. the largescale availability of data and advanced analytical techniques to private parties carries clear potential for abuses of various kinds that might lead to adverse consequences for some individuals, but a deep substantive examination of this issue is outside the primary focus of this report on government policy.3.4.2 the promise and limitations of data miningchapter 1 (in section 1.6.1) notes that data mining covers a wide variety of analytical approaches for using large databases for counterterrorist purposes, and in particular it should be regarded as being much broader than the common notion of a technology underlying automated terrorist identication.conclusion 6. because data mining has proven to be valuable in privatesector applications, such as fraud detection, there is reason to explore its potential uses in countering terrorism. however, the problem of detecting and preempting a terrorist attack is vastly more difcult than problems addressed by such commercial applications.as illustrated in appendix h (ﬁdata mining and information fusionﬂ), data mining has proven valuable in a number of privatesector applications. but the data used by analysts to track sales, banks to assess loan applications, credit card companies to detect fraud, and telephone companies to detect fraud are fundamentally different from counterterrorism data. for example, privatesector applications generally have access to a substantial amount of relatively complete and structured data. in some cases, their data are more accurate than government data, and, in others, large volumes of relevant data sometimes enable statistical techniques to compensate8 to some extent for data of lower qualityšthus, either way, reducing the datacleaning effort required. in addition, a few false positives and false negatives are acceptable in privatesector 8 a fact that underlies the ability of internet search engines to propose correct spellings of many incorrectly spelled words.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.78 protecting individual privacy in the struggle against terroristsapplications, because a few false positives can usually be cleared up by contact with clients without a signicant draw on resources, and a few false negatives are tolerable. ground truthšthat is, knowledge of what is actually true that can be used to validate or verify a new measurement or techniquešis available in many privatesector applications, a point that enables automated learning and renement to take place. all of the relevant data are availablešat oncešin privatesector applications.these attributes are very different in the counterterrorism domain. ground truth is rarely available in tracking terrorists, in large part because terrorists and terrorist activity are rare. data specically associated with terrorists (targeted collection efforts) are sparse and mostly collected in unstructured form (free text, video, audio recordings). the availability of much of the relevant data depends on the specic nature of data collected earlier (e.g., information may be needed to obtain a search warrant that then leads to additional information). data tracks of terrorists in commercial and government administrative databases (as contrasted with government intelligence databases) are comingled with enormously larger volumes of similar data associated with innocent individuals, and they are not in any way apparent or obvious from the fact of their collectionšthat is, it is generally unknown who is a terrorist in any such database. and links among records in databases of varying accuracy will tend to re˚ect accuracies characteristic of the most inaccurate of the databases involved.such differences are not described here to argue that data mining for counterterrorist applications is ipso facto unproductive or operationally useless. but the existence of these differences underscores the difculty of productively applying data mining techniques in the counterterrorist domain.conclusion 7. the utility of patternbased data mining is found primarily if not exclusively in its role in helping humans make better decisions about how to deploy scarce investigative resources, and action (such as arrest, search, denial of rights) should never be taken solely on the basis of a data mining result. automated terrorist identication through data mining (or any other known methodology) is neither feasible as an objective nor desirable as a goal of technology development efforts.as noted in appendix h, subjectbased data mining and patternbased data mining have very different characteristics. the common example of patternbased data mining is what might be called automated terrorist identication, by which is meant an automated process that examines large databases in search of any anomalous pattern that might indicate a terrorist plot in the making. automated terrorist idenprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 79tication is not technically feasible because the notion of an anomalous patternšin the absence of some welldened ideas of what might constitute a threatening patternšis likely to be associated with many more benign activities than terrorist activities. in this situation, the number of false leads is likely to exhaust any reasonable limit on investigative or analytical resources. for these reasons, the desirability of technology development efforts aimed at automated terrorist identication is highly questionable.other kinds of patternbased data mining may be useful in helping analysts to search for known patterns of interest (i.e., when they have a basis for believing that such a pattern may signal terrorist intent). for example, analysts may determine that a pattern is suggestive of terrorist activity on the basis of historical experience. by searching for patterns known to be associated with (prior) terrorist incidents, it may well be possible to uncover tangible and useful evidence of similar terrorist plots in the making. the signicance of uncovering such plots, even if they are similar to those that have occurred in the past, should not be underestimated. terrorists learn from their past failures and successes, and to the extent that counterterrorist activities can force them to develop newšand unprovenšapproaches, they will be placed at a signicant disadvantage.patterns of interest may also be identied by analysts thinking about sets of activities that are indicative of or associated with terrorist activity, even if there is no historical precedent for such associations. under some circumstances, terrorists might well be limited in the options they might pursue in attacking a specic target. if so, it might be reasonable to search for patterns associated with the planning and execution of those options.still, patterns of interest identied using these techniques should be regarded as indicative rather than authoritative, and they should be used only to suggest when further investigation may be warranted rather than as denitive indications of terrorist activity. the committee believes that data mining routines should never be the sole arbiter prior to actions that have a substantial impact on people™s lives. data mining should be used to help humans make decisions when the combination of human judgment and automated data mining results in better decisions than human judgment alone. but even when this is the case, it does not negate the fact that data mining routines, on their own, can make obvious mistakes in deciding the rankings and that the use of human judgment can dramatically reduce the rate of errors.conclusion 8. although systems that support analysts in the identication of terrorists can be designed with features and functionality that enhance privacy protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.80 protecting individual privacy in the struggle against terroristsprotection without signicant loss to their primary mission, privacypreserving examination of individually identiable records is fundamentally a contradiction in terms.systems can often be designed in ways that enhance privacy without compromising their primary mission. for example, in searching for a weapon at a checkpoint, a scanner might generate anatomically correct images of a person™s body in graphic detail. since what is of interest is not those images but rather the presence or absence of weapons, a system could be designed to detect the presence or absence of a weapon in a particular scan and that fact (presence or absence) reported rather than the image itself. procedural protections could also be put into place: for example, an individual might be given the choice of going through an imaging scanner or undergoing a patdown search. (note also that a different and broader set of privacy implications arises if images are stored for further use, as they may well be for system assessments.)nevertheless, in the absence of a nearperfect prole of a terrorist, it is not possible, even in principle, to somehow examine the records of an individual (who might or might not be a terrorist) but to expose those records only if he or she actually is a terrorist. (a prole of a terrorist is intended to enable the sorting of individuals into those who match the prole and those who do not. if the prole is perfect, and the data contained in individual records are entirely accurate, all of those who match can be regarded with certainty as terrorists and all of those who do not match can be regarded with certainty as nonterrorists. in practice, proles are never perfect and data are not entirely accurate, and so the notion of degrees of match is much more relevant than the notion of simply match or nonmatch.)as a result, any realistic system examining databases containing information about terrorists will bring a mix of terrorists and nonterrorists to the attention of analysts, who will decide whether these individuals warrant further investigation. ﬁfurther investigationﬂ in this nonroutine context necessarily results in an examination of the private personal information for these individuals, and it may result in tangible inconvenience and loss of various freedoms.conclusion 9. research and development on data mining techniques using real population data are inherently invasive of privacy to some extent.much of data mining is focused on looking for patterns of behavior, characteristics, or transactions that are a priori plausible (i.e., plausible on the basis of expert judgment and experience) as possible indicators of terrorist activity. but these expert judgments about patterns of interest protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 81must be empirically valid if they are to have signicant operational utility, whereby validity is measured by a high true positive rate in identifying terrorist activity and a low false positive rate.on one hand, a degree of empirical validity can be obtained through the use of synthetic and anonymized data or historical data. for example, large population databases can be seeded with data created to resemble data associated with real terrorist activity. although such data are, by denition, based on assumptions about the nature and character of terrorist activities, the expert judgment of experienced counterterrorism analysts can provide such data with signicant face validity.9 by testing various algorithms in this environment, the simulated terrorist signatures provide a measure of ground truth against which various data mining approaches can be tested.on the other hand and by denition, the use of synthetic data to simulate terrorist signatures does not provide realworld empirical validation. only real data can be the basis for realworld empirical validation. thus, another approach is to use historical data on terrorists. for example, a great deal is known today about the actual behavioral and activity signatures of the september 11, 2001, terrorists. seeding large population databases with such data and requiring various algorithms to identify known terrorists provide a complementary approach to validation.the use of historical data on terrorists is limited in one fundamental respect: it does not account for unprecedented events. but it is entirely reasonable to suggest that the successful application of proposed tools and techniques to known past events is a minimum and necessary (though not sufcient) metric of success.using real population databasesšlarge databases lled with actual behavioral and activity data on actual individualsšpresents a serious privacy issue. almost all of these individuals will have no connection to terrorists, and the use of such data in this context means that their private personal information will indeed be compromised.it is a policy decision as to whether the risks to privacy inherent in conducting research and development (r&d) on data mining techniques for counterterrorism using real population data are outweighed by the potential operational value of using those techniques. the committee 9 generally speaking, procedures that produce sensible outputs in response to given, often extreme inputs (often bestcase and worstcase scenarios) are said to have gained face validity. for example, input data for ctitious individuals that are designed to provoke an investigation given current procedures, and which are ranked as being of high interest using a data mining algorithm, provide some degree of face validity for that procedure and vice versa. the same is true for ctitious inputs for cases that would be of no interest to counterterrorism analysts for further investigation.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.82 protecting individual privacy in the struggle against terroristsrecommends that such r&d should be conducted on synthetic data (see section 3.7), but if the decision is made to use real population data, the committee urges that policy makers face, acknowledge, and report on this issue explicitly.3.5 conclusions regarding deception detection and behavioral surveillanceconclusion 10. behavioral and physiological monitoring techniques might be able to play an important role in counterterrorism efforts when used to detect (a) anomalous states (individuals whose behavior and physiological states deviate from norms for a particular situation) and (b) patterns of activity with wellestablished links to underlying psychological states.scientic support for linkages between behavioral and physiological markers and mental state is strongest for elementary states (simple emotions, attentional processes, states of arousal, and cognitive processes), weak for more complex states (deception), and nonexistent for highly complex states (terrorist intent and beliefs). the status of the scientic evidence, the risk of false positives, and vulnerability to countermeasures argue for behavioral observation and physiological monitoring to be used at most as a preliminary screening method for identifying individuals who merit additional followup investigation. indeed, there is no consensus in the relevant scientic community nor on the committee regarding whether any behavioral surveillance or physiological monitoring techniques are ready for use at all in the counterterrorist context given the present state of the science.conclusion 11. further research is warranted for the laboratory development and renement of methods for automated, remote, and rapid assessment of behavioral and physiological states that are anomalous for particular situations and for those that have wellestablished links to psychological states relevant to terrorist intent.a number of techniques have been proposed for the machineassisted detection of certain behavioral and physiological states. for example, advances in magnetic resonance imaging (mri), electroencephalography (eeg), and other modern techniques have enabled measures of changes in brain activity associated with thoughts, feelings, and behaviors.10 research in image analysis has yielded improvements in machine recog10 p. root wolpe, k.r. foster, and d.d. langleben, ﬁemerging neurotechnologies for liedetection: promises and perils,ﬂ the american journal of bioethics 5(2):3949, march 2005.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 83nition of faces under a variety of circumstances (e.g., when a face is smiling or when it is frowning) and environments (e.g., in some nonlaboratory settings).however, most of the work is still in the basic research stage, with much of the underlying science still to be validated or determined. if realworld utility of these techniques is to be realized, a number of issuesšpractical, technical, and fundamentalšwill have to be addressed, such as the limits to understanding, the largely unknown measurement validity of new technologies, the lack of standardization in the eld, and the vulnerability to countermeasures. public acceptability regarding the privacy implications of such techniques also remains to be demonstrated, especially if the resulting data are stored for unknown future uses or undened lengths of time.for example, the current stateoftheart of functional mri technology can identify changes in the hemodynamics in certain regions of the brain, thus signaling activity in those regions. but such results are not necessarily consistent across individuals (i.e., different areas in the brains of different individuals may be active under the same stimulus) or even in the same individual (i.e., a slightly different part of the brain may become active even in the same individual under the same stimulus). certain regions of the brain may be active under a variety of different stimuli. in short, understanding of what these regions do is still primitive. furthermore, even if simple associations can be made reliably in laboratory settings, this does not necessarily translate into usable technology in less controlled situations. behavior of interest to detect, such as terrorist intent, occurs in an environment that is very different from the highly controlled behavioral science laboratory.conclusion 12. technologies and techniques for behavioral observation have enormous potential for violating the reasonable expectations of privacy of individuals.because the inferential chain from behavioral observation to possible adverse judgment is both probabilistic and long, behavioral observation has enormous potential for violating the reasonable expectations of privacy of individuals. it would not be unreasonable to suppose that most individuals would be far less bothered and concerned by searches aimed at nding tangible objects that might be weapons or by queries aimed at authenticating their identity than by technologies and techniques whose use will inevitably force targeted individuals to explain and justify their mental and emotional states. even if behavioral observation and physiological monitoring are used only as a preliminary screening methods for identifying individuals who merit additional followup investigation, protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.84 protecting individual privacy in the struggle against terroriststhese individuals will be subject to suspicion that would not fall on others not so identied.3.6 conclusions regarding statistical agenciesconclusion 13. census and survey data collected by the federal statistical agencies are not useful for terrorism prevention: such data have little or no content that would be useful for counterterrorism. the content and sampling fractions of household surveys as well as the lack of personal identiers makes it highly unlikely that these data sets could be linked with any reasonable degree of precision to other databases of use in terrorism prevention.the content of the data collected by the federal statistical agencies under the auspices of survey and census programs is generally inconsistent with the needs of counterterrorist activities, which require individually identiable data. even ignoring issues of access, the value of the data collected on national household or business surveys for terrorism prevention is minimal.the reasons are several:ł censuses collect little information beyond name, address, and basic demographic data on age, sex, and race; such data are unlikely to be of much value for identifying terrorists or terrorist behavior.ł because a substantial proportion of individuals move frequently, the 10year cycle of censuses means that the census information is unlikely to be timely, even in supplying current addresses.ł the census long form, which has been collected on a sample basis (and its successor program, the american community survey, acs) have more information but still very little that is directly relevant to predicting terrorist activity. moreover, because these data are collected only for a sample, the probability that those of interest would be in the sample for a given year of the acs is very slight, and, furthermore, the ability to match les without identiers into other record systems would be limited. at best, these data might provide background information to provide a description of the socioeconomic makeup of a clustered group of blocks.ł other household surveys also collect little of direct relevance to terrorism prevention, and because they typically draw on much less than 1 percent of the population, the chances of identifying new information on an individual of interest are rather low.regarding establishment surveys, for terrorism detection one might be interested in businesses that have increased activity with people in protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 85various parts of the world, but such information is not contained on federal statistical system business censuses and surveys.a variety of surveys collect information relevant to crime prevention and public health. data collections on criminal activity, such as the national crime victimization survey and the uniform crime reports, contain data on victims of crime, and they are most useful in identifying geographic areas in which such criminal activity seems to be prevalent. health surveys, such as the national health information survey, the national health and nutrition examination survey, and the national ambulatory medical care survey (largely collected by the national center for health statistics) have value in broader public health programs, but they cannot provide timely information for purposes of biosurveillance or for addressing a bioterrorist attack.in addition, statistical agencies often collect information under a promise of condentiality, and the costs of altering or relaxing the rules for condentiality protection are quite substantial. the quality of the data collected could be adversely affected as a consequence of respondents™ decreased willingness to cooperate. statistical agencies typically collect information under a promise of condentiality, and reneging on such ofcially provided assurances could substantially reduce the quality of the data collected, resulting in much poorer data on the state of the nation.11aside from census and survey data, statistical agencies also hold considerable administrative data (which they have collected from other agencies); such data may be merged with data collected for statistical purposes and thus create the potential for data sets and databases that could at some point conceivably be useful for purposes of counterterrorism. while these derived data sets are currently protected by pledges of 11 at times, even the use of nonpersonally identiable information collected by the statistical agencies for counterterrorism purposes can lead to public protest and endanger the cooperation of the public in providing information to statistical agencies. for example, in august 2002 and december 2003, the u.s. department of homeland security asked the u.s. census bureau to provide information on the number of arab americans living in the united states by smallarea tabulations, and the census bureau complied with this request. although this request violated no law, it caused a public furor and led the census bureau to rethink its dissemination policy, even though no personally identiable information was involved. in addition, groups representing arab americans threatened to withhold their future cooperation in the collection of data by the census bureau. (see l. clemetson, ﬁhomeland security given data on arabamericans,ﬂ new york times, july 30, 2004; l. clemetson, ﬁthreats and responses: privacy; coalition seeks action on shared data on arabamericans,ﬂ new york times, august 13, 2004; e. lipton, ﬁpanel says census move on arabamericans recalls world war ii internments,ﬂ new york times, november 10, 2004.) if such public concern emerges from data requests that are entirely consistent with the condentiality guarantees provided under existing law, it is not difcult to imagine that actions to weaken these guarantees might lead to similar controversy.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.86 protecting individual privacy in the struggle against terroristscondentiality if any of the component data sets are so protected, some additional consideration needs to be given to such constructs and how to respond to requests for them from other government agencies.3.7 recommendationsin light of the conclusions presented above, the committee has two central recommendations. the rst recommendation has subparts ad.3.7.1 systematic evaluation of every informationbased counterterrorism programrecommendation 1. u.s. government agencies should be required to follow a systematic process (such as the one described in the framework proposed in chapter 2) to evaluate the effectiveness, lawfulness, and consistency with u.s. values of every informationbased program, whether classied or unclassied, for detecting and countering terrorists before it can be deployed, and periodically thereafter.appendix j (ﬁthe total/terrorist information awareness programﬂ) recounts the story of the total information awareness (tia) program of the defense advanced research projects agency (darpa) and the intense controversy it engenderedšwhich was a motivation for launching this study. the committee notes that in december 2003, the department of defense (dod) inspector general™s (ig) audit of tia concluded that the failure to consider privacy adequacy during the early development of tia led dod to ﬁrisk spending funds to develop systems that may not be either deployable or used to their fullest potential without costly revision.ﬂ12 the dodig report noted that this was particularly true with regard to the potential deployment of tia for law enforcement: ﬁdarpa need[ed] to consider how tia will be used in terms of law enforcement to ensure that privacy is built into the developmental process.ﬂ13 greater consideration of how the technology might be used not only would have served privacy but also would probably have contributed to making tia more useful.the committee believes that a systematic approach to the development, procurement, and use of informationbased counterterrorism programs is necessary if their full value is to be obtained. the framework 12 u.s. department of defense, ofce of the inspector general, information technology management: terrorism information awareness program (d2004033), washington, d.c., 2003, p. 4.13 id. at 7.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 87developed by the committee and provided in chapter 2 is intended as a template for government decision makers to use in evaluating the effectiveness, appropriateness, and validity of every informationbased counterterrorism program and system. the u.s. department of homeland security (dhs)šand all agencies of the u.s. government with counterterrorism responsibilitiesšshould adopt the framework described in chapter 2, or one similar to it, as a central element in their decision making about new deployments and existing programs in use. failure to adopt such a systematic approach is likely to result in reduced operational effectiveness, wasted resources, privacy violations, mission creep, and diminished political support, not only for those programs but also for similar and perhaps for notsosimilar programs across the board.to facilitate accountability, such evaluations (and the data on which they are based) should be made available to the broadest audience possible. broad availability implies that these evaluations should be unclassied to the maximum extent possiblešbut even if evaluations are classied, they should still be performed and should be made available to those with the requisite clearances.such evaluations should be independent and comprehensive, and in particular they should assess both program effectiveness and privacy together, involving independent experts with the necessary technical, legal, and policy expertise to understand each of these areas and how interactions among them might affect the evaluation. for example, the meaning of privacy is in part technical, and an assessment of privacy cannot be left exclusively to individuals lacking such technical understanding.chapter 2 noted that much of the committee™s framework is not new and also that government decision makers have failed to implement many of the guidelines embedded in the framework even when they have been cognizant of them. it is the committee™s hope that by presenting to policy makers a comprehensive framework independent of any particular program, the pressures and exigencies associated with specic crises can be removed from the consideration and adoption of such a framework for application to all programs.the committee also calls attention to four subrecommendations that derive from recommendation 1.recommendation 1a. periodically after a program has been operationally deployed, and in particular before a program enters a new phase in its life cycle, policy makers should apply a framework such as the one proposed in chapter 2 to the program before allowing it to continue operations or to proceed to the next phase.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.88 protecting individual privacy in the struggle against terroristsa systematic approach such as the framework in chapter 2 is not intended to be applied only once in the life cycle of any given program. as noted in appendix d (ﬁthe life cycle of technology, systems, and programsﬂ), a program undergoes a number of different phases in its lifetime: identication of initial needs, research and technology development, systems development, and operational deployment and continual operational monitoring. each of these phases provides a desirable opportunity for applying the framework to help decide whether and how the program should transition to the next phase. each of the framework™s questions should still be asked. but the answers to those questions as well as the interpretation of the answers will vary depending on the phase. such a review may result in a signicant modication or even a cancellation of a given program.the committee calls special attention to the importance of operational monitoring, whose purpose is to ensure that the initial deployed capability remains both effective at contributing to the mission for which it was designed and acceptable from a privacy standpoint. often after initial deployment, the operational environment changes. improved base technologies or entirely new technologies become available. existing threat actors change their tactics, or entirely new threats emerge. executive branch policies change, or new administrations take ofce. analysts gain experience, or new analysts arrive. interpretations of existing law change through court decisions, or new legislation is passed. databased models may change simply because more data have become available that change the parameters and estimates on which the models are based. error rates may change for similar reasons. because every program is necessarily embedded in this milieu, the net result is that successful programs are almost always dynamic, in that they evolve in response to such changing circumstances.an evolved program is, by denition, not the same as the original programšand it is a fair question to ask whether the judgments made about any program in its original form would be valid for an evolved program. for these reasons, a policy regime is necessary that provides for periodic reassessment and reevaluation of a program after initial deployment, at the same time promoting and fostering necessary changesšwhether technological, procedural, legal, ethical, or other.recommendation 1a is important to programs currently in existencešthat is, programs in existence today, and especially programs that are operationally deployed today should be evaluated against the framework. to the best of the committee™s knowledge, no such evaluations have been performed for any data mining or deception detection programs in operation, although this is not to say that none have been done. if such evaluations have been performed, they should be made protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 89available to policy makers (senior ofcials in the executive branch or the u.s. congress), and if possible, the public as well. if not, they should be undertaken with all due speed. and if they cannot be performed without access to classied information, an independent group of experts with the requisite clearances should be chartered to perform such assessments.recommendation 1b. to protect the privacy of innocent people, the research and development of any informationbased counterterrorism program should be conducted with synthetic population data. if and when a program meets the criteria for deployment in the committee™s illustrative framework described in chapter 2, it should be deployed only in a carefully phased manner, e.g., being eld tested and evaluated at a modest number of sites before being scaled up for general use. at all stages of a phased deployment, data about individuals should be rigorously subjected to the full safeguards of the framework.almost by denition, technology in the r&d stage is nascent and unproven. nascent and unproven technologies are not sufciently robust or reliable to warrant risking the privacy of individualsšthat is, the very uncertain (perhaps nonexistent) benet that would be derived from their use does not justify the very real cost to privacy that would inevitably accompany their widespread use in operational settings. thus, the committee advocates r&d based on synthetic population data whose use poses very little risk of violating the privacy of innocent individuals. in addition, the successful use of synthetic data in many elds, such as epidemiology, medicine, and chemistry, for testing methods provides another reason to explore its potential uses in counterterrorism.the committee believes that realistic synthetic population data could probably be created along the lines originally suggested in rubin and in little and further developed by fienberg et al. and reiter,14 for the specic purpose of providing the background against which terrorist signatures are sought. furthermore, because it is difcult to create from entirely synthetic data large databases that are useful for testing and (partially) validating data mining techniques and algorithms, a partial substitute for entirely synthetic data is data derived from real population data in such a way that the individual identities of nonterrorists are masked 14 d.b. rubin, ﬁdiscussion: statistical disclosure limitation,ﬂ journal of ofcial statistics 9(2):461468, 1993; r.j.a. little, ﬁstatistical analysis of masked data,ﬂ journal of ofcial statistics 9(2):407426, 1993; s.e. fienberg, u.e. makov, and r.j. steele (with discussion by p. kooiman and a response), ﬁdisclosure limitation using perturbation and related methods for categorical data,ﬂ journal of ofcial statistics 14:485511, 1998; j.p. reiter, ﬁinference for partially synthetic, public use microdata sets,ﬂ survey methodology 29:181188, 2003.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.90 protecting individual privacy in the struggle against terroristswhile preserving some of the important largescale statistical properties of those data.using synthetic population data as the background, a measure of the utility of various data mining approaches can be obtained in r&d. such results must be evaluated in the most rigorous and independent manner possible in order to determine if the program should move into deployment.if the results are determined to be sufciently promising (e.g., with sufciently low false positive and false negative rates) that they offer signicant operational capability, it is reasonable to apply the new capabilities to real data in an operational context.15 but the change from synthetic to real data must be accompanied by a full array of operational safeguards that protect individuals from harm to their privacy, as suggested by the committee™s proposed framework. put differently, if real data are to be used, theyšand the individuals with whom they are associatedšdeserve the full benet of the privacy protections associated with the program in question.transitioning to an operational context from r&d must also be done carefully and is best undertaken in small phases. the traditional approach to acquisition generally involves the deployment of operational capabilities in large blocks of capability (i.e., large functional components deployed on a wide scale). experience indicates that this approach is often slow and cumbersome, and it increases technical, programmatic, and budgetary risks. the operational environment often changes signicantly in the time between initial requirements specication and rst deploymentšthus, the capability may even be obsolete when it is rst deployed. and deploying systems on a large scale before they are deployed on a small scale is almost always problematic, because smallscale operational trials are needed to shake out the inevitable bugs when r&d technologies meet the real world.by contrast, phased deployment is based on a philosophy of ﬁbuildalittle, testalittle, deployalittle.ﬂ phased deployment recognizes that kinks and problems in the deployment of any new capability are inevitable, positing that by making small changes, system developers will be able to more easily identify and correct these problems than when everything changes all at once. small changes are easier to reverse, should that become necessary. it also becomes feasible to test new capabilities offered by small changes in parallel with the baseline version, so that ground 15 note, however, that to the best of the committee™s knowledge, current data mining programs for counterterrorist purposes have not been evaluated for operational effectiveness in such a manner, either with synthetic data or with real data.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 91truth provided by the baseline version can be used to validate the new capabilities when their domain of operation is the same.the committee recognizes that, under this approach, operational capabilities will not have been subject to realworld empirical validation before deployment, although they will have had as much validation as possible with synthetic population data. and the phased deployment of privacysensitive capabilities reduces the likelihood of inappropriate or improper compromises of privacy from what they would have been under a more traditional acquisition model.16the approach recommended above (synthetic data before deployment, deployment only in measured phases) places a high premium on two actions. first, every effort must be made to create good synthetic data that are useful for testing the validity of machinelearning tools and are simultaneously very realistic. for synthetic terrorist data, both historical data and expert judgment play a role in developing signatures that might plausibly be associated with terrorist activity, and plausibility should be assessed through independent panels of judges without a vested interest in any given scenario. such judges must also be trained in or experienced with evasion or obfuscation techniques. for synthetic population data, every use must be made of known techniques for condentiality protection and statistical disclosure limitation17 to reduce the likelihood that the privacy of individuals is compromised, and further research on the creation of better synthetic data to represent largescale populations is certainly warranted.second, evaluation of r&d results must truly be independent and rigorous, with high standards of performance needed for a decision to deploy. as noted in conclusion 4, the rule that ﬁx is better than doing nothingﬂ often drives deployment decisions, and, given the high potential costs to individual privacy of deployment, the benets afforded by deployment must be more than marginal to warrant the potential cost.recommendation 1c. any informationbased counterterrorism program of the u.s. government should be subjected to robust, independent oversight of the operations of that program, a part of which would 16 the qualier of ﬁprivacysensitiveﬂ increments of capability is important, because it would be all too easy for a program manager to shortchange privacy considerations in attempts to ﬁget something workingﬂ for demonstration purposes. that is, privacy functionality must be built into the system from the start, rather than being an addon to be deployed at the end ﬁwhen everything else works.ﬂ17 additional discussion of some of these techniques can be found in the national research council publications expanding access to research data: reconciling risks and opportunities (the national academies press, washington, d.c., 2005) and private lives and public policies (national academy press, washington, d.c., 1993).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.92 protecting individual privacy in the struggle against terroristsentail a practice of using the same data mining technologies to ﬁmine the miners and track the trackers.ﬂin practice, operational monitoring is generally the responsibility of the program managers and operational personnel. but as discussed in appendix g (ﬁthe jurisprudence of privacy law and the need for independent oversightﬂ), oversight is necessary to ensure that actual operations have been conducted in accordance with stated policies.the reason is that, in many cases, decision makers formulate policies in order to balance competing imperatives. for example, the public demands both a high degree of effectiveness in countering terrorism and a high degree of privacy. program administrators themselves face multiple challenges: motivating high performance, adhering to legal requirements, staying within budget, and so on. but if operational personnel adhere to some elements of a policy and not to others, the balance that decision makers intended to achieve will not be realized in practice.the committee emphasizes that independent oversight is necessary to ensure that commitments to minimizing privacy intrusions embedded in policy statements are realized in practice. the reason is that losses of privacy are easy to discount under the pressure of daily operations, and those elements of policy intended to protect privacy are more likely to be ignored or compromised. without effective oversight mechanisms in place, public trust is less likely to be forthcoming. in addition, oversight can support continuous improvement and guide administrators in making organizational change.for example, program oversight is essential to ensure that those responsible for the program do not bypass procedures or technologies intended to protect privacy. noncompliance with existing privacyprotecting laws, regulations, and best practices diminishes public support and creates an environment in which counterterrorism programs may be curtailed or eliminated. indeed, even if shortcuts and bypasses increase effectiveness in a given case, in the long run scandals and public outcry about perceived abuses will reduce the political support for the programs or systems involvedšand may deprive the nation of important tools useful in the counterterrorist mission. even if a program is effective in the laboratory and expected to be so in the eld, its deployment must be accompanied by strong technical and procedural safeguards to ensure that the privacy of individuals is not placed at undue risk.oversight is also needed to protect against abuse and mission creep. experience and history indicate that in many programs that collect or use personal information, some individuals may violate safeguards intended to protect individual privacy. hospital clerks have been known to examprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 93ine the medical records of celebrities without having a legitimate reason for doing so, simply because they are curious. police ofcers have been known to examine the records of individuals in motor vehicle information systems to learn about the personal lives of individuals with whom they interact in the course of daily business. and, of course, compromised insiders have been known to use the information systems of law enforcement and intelligence agencies to further nefarious ends.the phenomenon of mission creep is illustrated by the computerassisted passenger prescreening system ii (capps ii) program, initially described in congressional testimony as an aviation security tool and not a law enforcement tool but which morphed in a few months to a system that would analyze information on persons ﬁwith [any] outstanding state or federal arrest warrants for crimes of violence.ﬂ18to guard against such practices, the committee advocates program oversight that mines the miners and tracks the trackers. that is, all operation and command histories and all accesses to databased counterterrorism information systems should be logged on an individual basis, audited, and mined with the same technologies and the same zeal that are applied to combating terrorists. if, for example, such practices had been in place during robert hanssen™s tenure at the federal bureau of investigation (fbi), his use of its computer systems for unauthorized purposes might have been discovered sooner.finally, the committee recognizes the phenomenon of statutory mission creep, as dened above in the discussion of premise 5. it occurs, for example, because in responding to a crisis, policy makers will naturally focus on adapting existing programs and capabilities rather than creating new ones. on one hand, if successful, adaptation often promises to be less expensive and faster than creating a new program or capabilities from scratch. on the other hand, because an existing program is likely to be highly customized for specic purposes, adapting that program to serve other purposes effectively may prove difcultšperhaps even more difcult than creating a program from scratch. as importantly, adapting an existing program to new purposes may well be contrary to agreements and understandings established in order to initiate the original program in the rst place.18 an initial description of capps ii by deputy secretary of dhs admiral james loy, then administrator of the transportation security administration, assured congress that capps ii was intended to be an aviation security tool, not a law enforcement tool. testimony of admiral james loy before house government reform subcommittee on technology, information policy, intergovernmental relations and the census (may 6, 2003). morphed systemšinterim final privacy act notice, 68 fed. reg. 45265 (august 1, 2003).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.94 protecting individual privacy in the struggle against terroriststhe committee does not oppose expanding the goals and missions of a program under all circumstances. nevertheless, it cautions that such expansion should not be undertaken hastily in response to crisis. in the committee™s view, following diligently the framework presented in chapter 2 is an important step in exercising such caution.recommendation 1d. counterterrorism programs should provide meaningful redress to any individuals inappropriately harmed by their operation.programs that are designed to balance competing interests (in the case of counterterrorism, collective security and individual privacy and civil liberties) will naturally be biased in one direction or another if their incentive/penalty structure is not designed to re˚ect this balance. the availability of redress to the individual harmed thus acts to promote the goal of compliance with stated policyšas does the operational oversight mentioned in recommendation 1cšand to provide incentives for the government to improve the policies, technologies, and data underlying the operation of the program.although the committee makes no specic recommendation concerning the form of redress that is appropriate for any given privacy harm suffered by innocent individuals as the result of a counterterrorism program, it notes that many forms of redress are possible in principle, ranging from apology to monetary compensation. the most appropriate form of redress is likely to depend on the nature and purpose of the specic counterterrorism program involved. however, the committee believes that, at a minimum, an innocent individual should always be provided with at least an explicit acknowledgment of the harm suffered and an action that reduces the likelihood that such an incident will ever be repeated, such as correcting erroneous data that might have led to the harm. note that responsibilities for correction should apply to the holder of erroneous data, regardless of whether the holder is the government or a third party.the availability of redress might, in principle, enable terrorists to manipulate the system in order to increase their chances of remaining undetected. however, as noted in item 7 of the committee™s framework on effectiveness, informationbased programs should be robust and not easily circumvented by adversary countermeasures, and thus the possibility that terrorists might manipulate the system is not a sufcient argument against the idea of redress.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 953.7.2 periodic review of u.s. law, policy, and procedures for protection of privacyrecommendation 2. the u.s. government should periodically review the nation™s laws, policies, and procedures that protect individuals™ private information for relevance and effectiveness in light of changing technologies and circumstances. in particular, congress should reexamine existing law to consider how privacy should be protected in the context of informationbased programs (e.g., data mining) for counterterrorism.the technological environment in which policy is embedded is constantly changing. although technological change is not new, the pace of technological change has dramatically increased in the digital age. as noted in engaging privacy and information technology in a digital age, advances in information technology make it easier and cheaper by orders of magnitude to gather, retain, and analyze information, and other trends have enabled access to new kinds of information that previously would have been next to impossible to gather about another individual.19 furthermore, new information technologies have eroded the privacy protection once provided through obscurity or the passage of time. today, it is less expensive to store information electronically than to decide to get rid of it, and new and more powerful data mining techniques and technologies make it much easier to extract and identify personally identiable patterns that were previously protected by the vast amounts of data ﬁnoiseﬂ around them.the security environment is also constantly changing. new adversaries emerge, and counterterrorist efforts must account for the fact that new practices and procedures for organizing, training, planning, and acquiring resources may emerge as well. most importantly, new attacks appear. the number of potential terrorist targets in the united states is large,20 and 19 national research council, engaging privacy and information technology in a digital age, the national academies press, washington, d.c., 2007.20 analysts and policy makers have debated the magnitude of this number. in one version of the total information awareness program, the number of important and plausible terrorist targets was estimated at a few hundred, while other informed estimates place the number at a few thousand. still other analysts argue that the number is virtually unlimited, since terrorists could, in principle, seek to strike anywhere in their attempts to sow terror. there is evidence on both sides of this point. some point to al qaeda planning documents and other intelligence information to suggest that it continues to be very interested in largescale strikes on targets that are mediaworthy around the world, such as targets associated with air transportation. others point out that the actual history of terrorist attacks around the world has for the most part involved attacks on relatively soft and undefended targets, of which there are very many.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.96 protecting individual privacy in the struggle against terroristsalthough the different types of attack on these targets may be limited, attacks might be executed in myriad ways.as an example of a concern ripe for examination and possible action, the committee found common ground in the proposition that policy makers should seriously consider restrictions on how personal information is used in addition to restrictions on how records are collected and accessed. usage restrictions could be an important and useful supplement to access and collection limitation rules in an era in which much of the personal information that can be the basis for privacy intrusion is already either publicly available or easily accessible on request without prior judicial oversight. privacy protection in the form of information usage restrictions can provide a helpful tool that balances the need to use powerful investigative tools, such as data mining, for counterterrorism purposes and the imperative to regulate privacy intrusions of such techniques through accountable adherence to clearly stated privacy rules. (appendix g elaborates on this aspect of the recommendation.)such restrictions can serve an important function in helping to ensure that programs created to address a specic area stay focused on the problem that the programs were designed to address and in guarding against unauthorized or unconsidered expansion of government surveillance power. they also help to discourage mission creep, which often expands the set of purposes served by the program without explicit legislative authorization and into areas that are poorly matched by the original program™s structure and operation. an example of undesirable mission creep would be the use of personal data collected from the population acquired for counterterrorist purposes to uncover tax evaders or parents who have failed to make child support payments. this is not to say that nding such individuals is not a worthy social goal, but rather that the mismatch between such a goal and the intrusiveness of data collection measures for counterterrorist purposes is substantial indeed. without clear legal rules dening the boundaries for use between counterterrorism and inappropriate law enforcement uses, debates over mission creep are likely to continue without constructive resolution.a second example of a concern that may be ripe for legislative action involves the current legal uncertainty supporting privatesector liability for cooperation with government data mining programs. such uncertainty creates real risk in the private sector, as indicated by the present variety of private lawsuits against telecommunications service providers,21 and privatesector responsibilities and rights must be claried along 21 for example, the electronic frontier foundation led a classaction lawsuit against at&t on january 31, 2006, claiming that at&t violated the law and the privacy of its customers by collaborating with the national security agency in the terrorist surveillance program.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 97with government powers and privacy protections. what exists today is a mix of law, regulation, and informal in˚uence in which the legal rights and responsibilities of privatesector entities are highly uncertain and not well understood.a coherent, comprehensive legal regime regulating informationintensive surveillance such as government data mining, would do much to reduce such uncertainty. as one example, such a regime might address the issue of liability limitation for privatesector data sources (database providers, etc.) that provide privacyintrusive information to the government.without spelling out the precise scope and coverage of the comprehensive regime, the committee believes that to the extent that the government legally compels a private party to provide data or a private party otherwise complies with an apparently legal requirement to disclose information, it should not be subject to liability simply for the act of complying with the government compulsion or legal requirement. any such legal protection should not extend to the content of the information it supplies, and the committee also believes that the regime should allow incentives for data providers to invest reasonable effort in ensuring the quality of the data they provide. furthermore, they should provide effective legal remedies for those individuals who suffer harm as a result of provider negligence. furthermore, the regime would necessarily preserve the ability of individuals to challenge the constitutionality of the underlying data access statute.listed below are other examples of how the adequacy of privacyrelated law might be called into question by a changing environment (appendix f elaborates on these examples).ł conducting general searches. on one hand, the fourth amendment forbids general searchesšthat is, searches that are not limited as to the location of the search or the type of evidence the government is seekingšby requiring that all searches and seizures must be reasonable and that all warrants must state with particularity the item to be seized and the place to be searched. on the other hand, machineaided searching of enormous digital transaction records is in some ways analogous to a general search. such a search can be a dragnet that sweeps through millions or billions of records, often containing highly sensitive information. much like a general search in colonial times was not limited to a particular person or place, a machineaided search through digital databases can be very broad. how, if at all, should database searches be regulated by the fourth amendment or by statute?a related issue is that the historical difculty of physical access to ostensibly public information has provided a degree of privacy protection protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.98 protecting individual privacy in the struggle against terroristsfor that informationšwhat might be known as privacy through obscurity. but a searchenabled digital world erodes some of these previously inherent protections against invasions of privacy, changing the technological milieu that surrounds privacy jurisprudence.ł increased access to data; searches and surveillance of u.s. persons outside the united states. the supreme court has not yet addressed whether the fourth amendment applies to searches and surveillance for national security and intelligence purposes that involve u.s. persons22 who are connected to a foreign power or that are conducted wholly outside the united states.23 lower courts, however, have found that there is an exception to the fourth amendment™s warrant requirement for searches conducted for intelligence purposes within the united states that involve only nonu.s. persons or agents of foreign powers.24 the supreme court has yet to rule on this important issue, and congress has not supplied any statutory language to ll the gap.ł thirdparty records. two supreme court cases (united states v. miller, 1976, and smith v. maryland, 1979)25 have established the precedent that there is no constitutionally based reasonable expectation of privacy for information held by a third party, and thus the government today has access unrestricted by the fourth amendment to privatesector records on every detail of how people live their lives. today, these thirdparty transactional records are available to the government subject to a very low thresholdšthrough subpoenas that can be written by almost any government agency without prior judicial oversightšand are one of the primary data feeds for a variety of counterterrorist data mining activities. thus, the public policy response to privacy erosion as a result of data mining used with these records will have to address some combination of the scope of use for the data mining results, the legal standards for access to and use of transactional information, or both.26 (see also appendix g for 22 a u.s. person is dened by law and executive order 12333 to mean ﬁa united states citizen, an alien known by the intelligence agency concerned to be a permanent resident alien, an unincorporated association substantially composed of united states citizens or permanent resident aliens, or a corporation incorporated in the united states, except for a corporation directed and controlled by a foreign government or governments.ﬂ23 j.h. smith and e.l. howe, ﬁfederal legal constraints on electronic surveillance,ﬂ pp. 133148 in protecting america™s freedom in the information age, markle foundation task force on national security in the information age, markle foundation, new york, n.y., 2002.24 see united states v. bin laden, 126 f. supp. 2d 264, 27172 (s.d.n.y. 2000).25 united states v. miller, 425 u.s. 435 (1976); smith v. maryland, 442 u.s. 735 (1979).26 transactional information is the data collected on individuals from their interactions (transactions) with outside entities, such as businesses (e.g., travel and sales records), public facilities and organizations (e.g., library loans), and web sites (e.g., internet usage). aggregate information, in contrast, is information in summary form (e.g., total visitors and sales) that does not contain data that would permit the identication of a specic individual. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 99discussion of how usage limitations can ll gaps in current regulation of the condentiality of thirdparty records.)ł electronic surveillance law. today™s law regarding electronic surveillance is complex. some of the complexity is due to the fact that the situations and circumstances in which electronic surveillance may be involved are highly varied, and policy makers have decided that different situations call for different regulations. but it is an open question as to whether these differences, noted and established in one particular set of circumstances, can be effectively maintained over time. although there is broad agreement that today™s legal regime is not optimally aligned with the technological and circumstantial realities of the present, there is profound disagreement about whether the basic principles underlying today™s regime continue to be sound as well as in what directions changes to today™s regime ought to occur.in making recommendation 2, the committee intends the government™s reexamination of privacy law to cover the issues described above but not be limited to them. in short, congress and the president should work together to ensure that the law is clear, appropriate, up to date, and responsive to real needs.greater clarity and coherence in the legal regime governing informationbased programs would have many benets, both for privacy protection and for the counterterrorist mission. it is perhaps obvious that greater clarity helps to protect privacy by eliminating what might be seen as loopholes in the lawšambiguities that can be exploited by wellmeaning national security authorities, thereby overturning or circumventing the intent of previously established policy that balanced competing interests. but the benets of greater clarity from the standpoint of improving the ability of the u.s. government to prosecute its counterterrorism responsibilities are less obvious and thus deserve some elaboration.first and most importantly from this perspective, greater legal clarity would help to reduce public controversy over potentially important tools that might be used for counterterrorist purposes. although many policy makers might wish that they had a free hand in pursuing the counterterrorist mission and that public debate and controversy would just go away, the reality is that public controversy does result when the government is seen as exploiting ambiguities and loopholes.as discussed in appendix i (ﬁillustrative government data mining programs and activityﬂ), a variety of government programs have been shut down, scaled back, delayed, or otherwise restricted over privacy considerations: tia, capps ii for screening airline passengers, matrix (multistate antiterrorism information exchange) for linking law enforcement records across states with other government and privatesector protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.100 protecting individual privacy in the struggle against terroristsdatabases, and a number of datasharing experiments between the u.s. government and various airlines. public controversy about these efforts may have prematurely compromised counterterrorism tools that might have been useful. in addition, they have also made the government more wary of national security programs that involve data matching and made the private sector more reluctant to share personal information with the government in the future.in this regard, this rst rationale for greater clarity is consistent with the conclusion of the technology and privacy advisory committee: ﬁ[privacy] protections are essential so that the government can engage in appropriate data mining when necessary to ght terrorism and defend our nation. and we believe that those protections are needed to provide clear guidance to dod personnel engaged in antiterrorism activities.ﬂ27second, greater legal clarity and coherence can enhance the effectiveness of certain informationbased programs. for example, the privacy act of 1974 requires that personal data used by federal agencies be accurate, relevant, timely, and complete. on one hand, these requirements increase the likelihood that highquality data are stored, thus enhancing the effectiveness of systems that use data subject to those requirements. on the other hand, both the fbi™s national crime information center and the passenger screening database of the transportation security administration have exemptions from some of these requirements;28 to the extent that these exemptions result in lowerquality data, these systems are likely to perform less well.third, the absence of a clear legal framework is likely to have a profound effect on the innovation and research that are necessary to improve the accuracy and effectiveness of informationbased programs. such clarity is necessary to support the investment of nancial, institutional, and human resources in often risky research that may not pay dividends for 27 technology and privacy advisory committee, safeguarding privacy in the fight against terrorism, u.s. department of defense, washington, d.c., march 2004, p. 48, available at http://www.cdt.org/security/usapatriot/20040300tapac.pdf. 28 the department of justice and the transportation security administration have published notices on these programs in the federal register, exempting them from certain provisions of the privacy act that are allowed under the act. in march 2003, the doj exempted the fbi™s national crime information center from the privacy act™s requirements that data be ﬁaccurate, relevant, timely and complete,ﬂ privacy act of 1974; implementation, 68 federal register 14140 (2003) (doj, nal rule). in august 2003, the department of homeland security exempted the tsa™s passenger screening database from the privacy act™s requirements that government records include only ﬁrelevant and necessaryﬂ personal information, privacy act of 1974: implementation of exemption, 68 federal register 49410 (2003) (dhs, nal rule). outside these exceptions, the privacy act otherwise applies to these programs. (under the act, exemptions have to be published to be effective, and so the committee assumes that there are no ﬁsecretﬂ exemptions.)protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.conclusions and recommendations 101decades. but that type of research is essential to counterterrorism efforts and to nding better ways of protecting privacy.finally, a clear and coherent legal framework will almost certainly be necessary to realize the potential of new technologies to ght terrorism. because such technologies will operate in the political context of an american public concerned about privacy, the publicšand congressional decision makersšwill have to take measures that protect privacy when new technologies are deployed. all technological solutions will require a legal framework within which to operate, and there will always be gaps left by technological protections, which law will be essential to ll. consequently, a lack of clarity in that framework may not only slow their development and deployment, as described above, but also make technological solutions entirely unworkable.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendixesprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.105aacronyms911 reference to the terrorist attacks on the u.s. that occurred september 11, 2001ace automated commercial environmentacs automated commercial systemadvise analysis, dissemination, visualization, insight, and semantic enhancementallwme all weapons of mass effectanfo ammonium nitrate/fuel oilannm ammonium nitrate nitromethaneans autonomic nervous systemaps advance passenger information systemaq al qaedaarcos automation of reports of consolidated orders systemarpa advanced research projects agencyatf bureau of alcohol, tobacco, and firearmsatm automated teller machineats automated targeting systembats bomb arson tracking systembkc biodefense knowledge centerbsa bank secrecy actprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.106 protecting individual privacy in the struggle against terroristscaaiopee (kdd application)cagr compound annual growth ratecalea communications assistance for law enforcement act of 1994cappsii computerassisted passenger prescreening system iicart computer analysis and response teamcbp customs and border protectioncctv closed circuit televisioncdc centers for disease control and preventioncdr call data recordcdt center for democracy and technologycia central intelligence agencycipsea condential information protection and statistical efciency actcmir international transportation of currency or monetary instruments reportcms centers for medicare and medicaid servicescobit control objectives for information and related technologiesconus continental united statescots commercial offtheshelfcpni customer proprietary network informationcrs congressional research servicectr currency transaction reportctrc currency transaction report by casinoscvs crew vetting systemdarpa defense advanced research projects agencydartts data analysis and research for trade transparency systemdea drug enforcement administrationdep designation of exempt persondhs department of homeland securitydme durable medical equipmentdmv department of motor vehiclesdna deoxyribonucleic aciddod department of defensedodig department of defense inspector generaldoj department of justicedot department of transportationdt&e developmental test and evaluationdtl drug theft lossprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix a 107dto disruptive technology ofceecpa electronic communications privacy acted emergency departmentedw enterprise data warehouseeeg electroencephlalographeff electronic frontier foundationemg electromyelogrameta euskadi ta askatasuna (terrorist organization)faa federal aviation administrationfacts factual analysis criminal threat solutionfbar foreign bank and financial accounts reportfbi federal bureau of investigationfcc federal communications commissionfda food and drug administrationfdle florida department of law enforcementfdnsds fraud detection and national security data systemfincen financial crimes enforcement networkfisa foreign intelligence surveillance actfmri functional magnetic resonance imagingfoia freedom of information actftc federal trade commissionftttf foreign terrorist tracking task forcegao government accountability ofcehhs department of health and human serviceshippa health insurance portability and accountability acthtf high terrorist factori2f intelligence and information fusioniao information awareness ofceic3 internet crime complaint centerice immigration and customs enforcementicepic ice pattern analysis and information collection systemichast interagency center for applied homeland securityicu intensive care unitid identicationidw investigative data warehouseiir institute for intergovernmental researchip internet protocolprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.108 protecting individual privacy in the struggle against terroristsira irish republican armyirs internal revenue serviceirss institute for research in social scienceiso international organization for standardsisp internet service providerit information technologyitil it infrastructure libraryiv&v independent verication and validationkdd knowledge, discovery in databaseslea law enforcement agenciesli lawful interceptsllnl lawrence livermore national laboratoryltte liberation tigers of tamil eelam (terrorist organization)matrix multistate antiterrorism information exchangemeg magnetoencephalographymergepurge (kdd application)msb money service businessnasa national aeronautics and space administrationnctc national counterterrorism centernetleads law enforcement analytic data systemniiso national immigration information sharing ofcenimd novel intelligence from massive datanips numerical integrated processing systemnist national institute of standards and technologynora nonobvious relationships awarenessnrc national research councilnsa national security administrationnw3c national white collar crime centernyc new york citynycdoh new york city department of healthocdetf organized crime and drug enforcement task forceoecd organization for economic cooperation and developmentoip online investigative projectomb ofce of management and budgetota ofce of technology assessmentotc overthecounterprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix a 109ot&e operational test and evaluationparc palo alto research centerpda personal digital assistantpet positron emission tomographypii personally identiable informationpkk kurdistan workers party (terrorist organization)pnr passenger name recordpums public use microdata sampleqid questioned identication documentsr&d research and developmentraf red army faction (terrorist organization)rdd randomdigitdialedrfid radiofrequency identicationrr3 response rate (category 3)1rr4 response rate (category 4)2rtas remote threat alerting systems&t science and technologysar suspicious activity reportsec securities and exchange commissionskycat (kdd application)sql structured query languagessn social security numberstar systemtoassess riskswift society for worldwide interbank financial telecommunicationtapac dod technology and privacy advisory committeetasa telecommunications alarmsequence analyzer (kdd application)tb terabytetecs treasury enforcement communications systemtia total/terrorist information awareness programtiss tactical information sharing systemtsa transportation security administrationtvis threat vulnerability integration system1 see more information at http://www.pol.niu.edu/response.html.2 see more information at http://www.pol.niu.edu/response.html.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.110 protecting individual privacy in the struggle against terroristsurl uniform resource locatorusa patriot uniting and strengthening america by providing appropriate tools required to intercept and obstruct terrorismussocom united states special operations commandvoip voice over internet protocolwmd weapons of mass destructionwme weapons of mass effectprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.111bterrorism and terroristsb.1 the nature of terrorismterrorism is the deliberate targeting of noncombatants for a political purpose. it is the means used, and not the ends pursued, that determine whether or not a group is a terrorist group. terrorism is a weapon of the weak. because terrorist groups are both outmanned and outgunned by their opponents, they use violence against civilians, not in the expectation of defeating their adversary but rather to communicate a political message.1 the choice of symbolic and particularly vulnerable targets enhances the psychological impact of their actions and thereby compensates for their relative weakness. put differently, terrorism is often the strategy of choice for parties without the capability to achieve their note: this appendix provides some essentials about terrorism, but the reader is urged to consult more authoritative references, including d. benjamin and s. simon, the age of sacred terror, radical islam™s war against america, random house, new york, 2003; m. crenshaw, ed., terrorism in context, pennsylvania state university press, university park, pa., 1995; r. gunaratna, inside al qaeda™s global network of terror, columbia university press, new york, 2002; b. hoffman, inside terrorism, 2nd edition, columbia university press, new york, 2006; w. reich, ed., origins of terrorism: psychologies, ideologies, theologies, states of mind, woodrow wilson center press, washington d.c., 1998; l. richardson, what terrorists want, understanding the enemy, containing the threat, random house, new york, 2006; marc sageman, understanding terror networks, university of pennsylvania press, philadelphia, pa., 2004.1 taking this point seriously means that not all acts that create terror in the population are terrorist acts. for example, although the washington, d.c., sniper incident was widely reported as a terrorist incident, the d.c. snipers did not act with any known political motivation or purpose in mind, and so the d.c. sniper incident does not meet the denition of a terrorist act.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.112 protecting individual privacy in the struggle against terroristsobjectives otherwise. it is an ﬁasymmetricﬂ response in the face of greater power of more conventional forms. box b.1 draws the contrast between conventional war and a war against terrorists.unlike the case for perpetrators of other forms of political violence, for terrorists the victims of their violence and the audience they seek to in˚uence are not the same. victims are chosen either at random or as box b.1 the contrast between conventional war and counterterrorist efforts the struggle against terrorism differs from historical norms for providing for our security. in the past, we have raised armies to defend against stateorganized military forces and to enforce our security and interests outside our borders. these ﬁenemyﬂ forces were most often easily identiable as enemies and we created a set of rules for monitoring their activities, for defending against them, and for attacking them. these rules regularly call for the violation of the laws of other countries. we have also provided for our security against those who break our laws through the application of law enforcement techniques by federal, state, and local governments. those who are found guilty of breaking laws are regarded as ﬁcriminals.ﬂ until they are found guilty, they are afforded all the rights of the innocent and can be found guilty only by a rigorous process of evidence and judicial process. the rules for armies dealing with ﬁenemiesﬂ in battle conditions have evolved to be quite different from those that apply to lawenforcement agencies dealing with ﬁpotential criminalsﬂ within the domestic borders of the united states. armies permit their elements and members to destroy ﬁenemiesﬂ upon ﬁrecognition.ﬂ they do so quickly and without ﬁdue processﬂ by any separate jurisdictional structure. one of the most demanding new attributes of our current struggle with terrorists is that some of the ﬁenemyﬂ is imbedded in our daytoday midst. the ﬁenemyﬂ has advertised its intent to destroy our society as a necessary part of defending its own and has demonstrated the potential to be a serious threat to our way of life. the ﬁcriminalﬂ is seeking to satisfy selsh interest at the expense of others but is not attempting to destroy society. although the difference between these motives is profound, our processes for dealing with ﬁenemies withinﬂ and ﬁcriminalsﬂ is not much different. a criminal act that produces localized terror is different from the serious national threat posed by a terrorist group from a foreign organization. we cannot realistically prevent all manner of tragedies that are the result of criminal behavior, stupidity, or random actsšu.s. highway fatalities, for example, total something like 30,000 per year. however, those conditions create a quality of anxiety very different from the citizen™s sense of insecurity that results from his/her government being unable to provide safety in the face of the threat of foreign organizations that wish to do them and their country harm. one involves the routine and understood risks of daily life that can be addressed by each individual in his/her own way. the other is a frighteningly everpresent risk of unknown harm from an uncertain deliverer.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix b 113representatives or symbols of a larger group in order to in˚uence the behavior of a third party, usually a government. what sets terrorism apart from other forms of political violence, even the most proximate forms like guerrilla warfare, is the deliberate targeting of civilians, not as an unintended consequence of warfare, but as deliberate strategy.b.2 some tactics of terrorismthe operational code of the current generation of transnational terrorists is to use the strengths of western democracies against us. for example, they exploit a free press to amplify their actions and spread the fear their operations inspire. and they exploit the openness of society to operate covertly. although basic training and recruitment may occur in the open (much as al qaeda operated in afghanistan), operational planning and training are often undertaken in an undercover manner. that is, the individuals, the organizations, and their leadership attempt to keep their identities, communications, plans, and locations from being known to the targeted nation even when the terrorists are within the borders of the nation being targeted.in addition, terrorists are prepared often to give up their lives, take the lives of innocent bystanders, and disavow other conventional forms of value in pursuit of their goals. this ferocity of commitment makes deterrence more complicated than it might be for nationtonation confrontation. in stark terms, what might serve to deter a suicide bomber? whatever the answer is to this question, death is not it.lastly, for most practical purposes, terrorists do not appear to place many limits on the violence that they are willing to perpetrate,2 and so the specter of terrorists with weapons of mass destruction looms large in counterterrorist efforts. likewise, the highly interdependent nature of modern society leaves the united states (and other developed nations) 2 a memo found on an al qaeda computer in late 2001 appeared to indicate that even al qaeda recognized some limits on the extent of violence they were willing to perpetrate. the memo said that: because of saddam and the baath party, america punished a whole population. thus its bombs and its embargo killed millions of iraqi muslims. and because of osama bin laden, america surrounded afghans and bombed them, causing the death of tens of thousands of muslims . . . god said to assault whoever assaults you, in a like manner . . . in killing americans who are ordinarily off limits, muslims should not exceed four million noncombatants, or render more than ten million of them homeless. we should avoid this, to make sure the penalty [that we are in˚icting] is no more than reciprocal. god knows what is best. cited in a. cullison, ﬁinside al qaeda™s hard drive,ﬂ the atlantic monthly, pp. 5570, september 2004.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.114 protecting individual privacy in the struggle against terroristsmore vulnerable than many other societies. our access to power, communications, information, transportation and ultimately food and water are very vulnerable to attack. this asymmetric mismatch between modern dependence on attackable infrastructure and the relatively lower dependence of terrorist adversaries on such infrastructure lessens the ability to deter through conventional forms of retaliation.b.3 a historical perspective on terrorismterrorism is not a new phenomenon. documented groups like the zealots and the sicarii date as far back as the rst century in the common era. like their contemporary successors they had a mix of religious and political motives and sought to ignite a general revolt among the masses against the established authorities. the medieval assassins, who operated from the 11th to the 13th century, provide an early example of statesponsored terrorism as well as an early example of a culture of martyrdom among terrorists. generally speaking, terrorist groups prior to the french revolution tended to mix religious and political motives, whereas in the 19th and 20th centuries terrorists groups, re˚ecting the broader secularization of society, tended to focus on political objectives. this changed in the 1970s with the impact of the iranian revolution and the popularization of the ideas of fundamentalist islamic writers like maulana mawdudi and sayyid qutb that again fused religion and politics and inspired the founders of contemporary islamic terrorist groups.although the primary terrorist threat to the united states emanates from islamic extremists, terrorists have belonged to most religious traditions and to none. there have been christian terrorists, like the eta in spain and the ira in ireland. there have been jewish terrorists, like the zealots, the sicarii, and the stern gang in palestine. there have been hindu terrorists, like the thugi in india. there have been atheist terrorists, like the raf in germany, action directe in france, and the red brigades in italy, and there have been secular terrorists like the shining path in peru, the pkk in turkey, and the ltte in sri lanka.b.4 explaining terrorismterrorism is a tactic employed by many different groups in many parts of the world in pursuit of many different objectives. there are no simple or uniform explanations of its causes. the fact that terrorism has been so widespread, used by peruvian peasants, german professors, saudi imams, egyptian intellectuals, tamil teenagers, and young cricket players from britain, suggests that no single cause can explain the actions of such a diverse group. yet, the actual practitioners of terrorist tactics are very few. metaexplanations like poverty, inequality, or alienation protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix b 115thus cannot adequately explain the behavior of small groups, when these conditions are so widespread. factors like inequality and alienation are better understood as risk factors that increase the likelihood of terrorism and increase the likelihood that once a terrorist group forms it will gain adherents, rather than as causes of terrorism per se. the essential requirements for terrorism are a disaffected individual, a complicit community, and a legitimizing ideology.it is helpful to think in terms of terrorists as having both primary and secondary motives, or underlying and immediate motives. the primary motives differ with the type of group: ethnonationalist groups, for example, want autonomy or secession; social revolutionary groups want to overthrow capitalism; religious groups want to bring about the apocalypse or to replace secular law with religious law. terrorist groups have been singularly unsuccessful in achieving these underlying or primary objectives. however, terrorists have been quite successful in achieving their secondary or more immediate objectives: revenge, renown, and reaction.the single most powerful motive of the terrorist is the desire for revenge. this holds true no matter what the precise political objective is or where in the world the terrorist is operating. sometimes this is revenge for a perceived wrong in˚icted on the individual or his family; more often it is a wrong in˚icted on a group with which the terrorist identies. second, terrorists seek renown. this implies publicity, but much more than that, it implies glory in an effort to redress the perceived humiliation a person, or the group with which he identies, has suffered. finally, terrorists seek to provoke their adversaries into a reaction, preferable an overreaction. terrorists do not have territory or even armies; all that they have is their action, and it is how they communicate with the world. by reacting, their adversary demonstrates their importance. by provoking the war on terror, terrorists have succeeded in exacting revenge, in attaining renown, and in eliciting a reaction.b.5 al qaeda and the terrorist threat to the united statesever since the terrorist attacks of september 11, 2001, the threat of further attacks has become the primary national security concern of the united states and many of its allies. the scale, ferocity, and nature of the attack were unprecedented in the lengthy annals of terrorism. the fact that the attack took place on american soil, targeted american civilians, and in˚icted casualties greater than the attack on pearl harbor in 1941 has led to a serious reevaluation of u.s. national security strategy.for the rst time in u.s. history nonstate actors have both demonstrated a capacity to in˚ict serious harm on the united states and have protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.116 protecting individual privacy in the struggle against terroristsarticulated a desire to do so. previously u.s. foreign and defense policy has been based on the assumption that our adversaries were other states or alliances of other states, but now we face a threat from transnational substate actors. the evolving nature of this threat requires that the united states develop new strategies in response.operation enduring freedom was launched in fall 2001 in response to the attacks of 9/11. this campaign succeeded in toppling the taliban regime in afghanistan, which had harbored al qaeda, the group responsible for the attacks. the military campaign also succeeded in destroying the central commandandcontrol structure of the group. the group and the ideology to which it adheres, however, survive.today, the most salient and serious terrorist threat to the united states is al qaeda, even though throughout history there have been many other types of terrorist movements in many parts of the world.3 its senior leadership has explicitly argued that the continued success of the western way of life, as exemplied by the united states, will inevitably lead to the erosion of traditional islamic values and their way of life. in the face of this proposition, al qaeda has resorted to terrorism as a means to achieve its ends because that choice does not confront u.s. economic and military strength and it leverages the safeguards of u.s. domestic freedoms to their advantage. other movements or organizations may emerge in the future to challenge the united states in this way, but for the moment, al qaeda is the primary terrorist adversary of the united states.the basis of al qaeda™s strength is twofold. they have a motivating ideology that a great many people nd appealing, and they have demonstrated extraordinary organizational agility. al qaeda™s ideology is an eclectic and inconsistently articulated mix of islamic fundamentalism; animus toward the west and secular muslim regimes; objections to specic u.s. policies in the middle east, in particular u.s. support for israel; and grandiose aspirations for a return to a mythical caliphate stretching from spain to indonesia. the breadth of these criticisms of the west means that disaffected muslims all over the world can identify with some part of the ideology while the religious basis provides a legitimacy and coherence to the appeal. unlike earlier terrorist groups that tended to start with local grievances and then build from there, part of the success of al qaeda has been the ease with which the ideology has infused local conditions, thereby gaining adherents for the transnational cause. the religious nature of the ideology has facilitated the elevation of the con˚ict with the west into cosmic terms, thereby eliminating previous constraints on the 3 even the united states has been the target of nonal qaeda terrorism, as occurred on april 19, 1995, when the alfred p. murrah federal building was bombed in oklahoma city, okla.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix b 117behavior of individuals and legitimizing and rationalizing the in˚iction of mass casualties.the organizational agility has been demonstrated by the ease with which al qaeda has adapted to the destruction of its central command structure and training bases and reemerged in an entirely new organizational form: a diffuse network of likeminded individuals bent on destruction of the west. the new incarnation of al qaeda is made possible by the existence of new technologies, the very attributes of the globalization they are so quick to decry but are so adept at exploiting. the current organization of al qaeda, therefore, is unprecedented as it is entirely dependent on a set of new technologies that were unavailable to its predecessors.it is impossible to know how many terrorists there are who wish to harm the united states. ten of thousands of mujahadeen fought against the soviet union in afghanistan. after the war many returned to their country of origin, radicalized local militant groups, and fought to overthrow local secular regimes. others turned their attention to the ght against the west, which was blamed for propping up corrupt regional leaders.after the rst gulf war the deployment of u.s. troops in saudi arabia, designed to serve as a trip wire in the event of another iraqi invasion, served as a rallying cry for extremists who perceived the deployment as humiliating and were convinced that the united states was determined to take over the muslim world. al qaeda reestablished training camps in afghanistan under the taliban and recruited young muslims from the middle east and the muslim diaspora in europe to come and be trained in the militant arts of jihad.the war in iraq has served to swell the ranks of those who wish to attack the west. young men from north africa and the gulf states are ˚ocking to iraq to take part in the war against the united states while the unpopularity of the war is radicalizing young muslims resident in europe to attack their compatriots, as occurred in madrid on march 11, 2004, and in london on july 7, 2005. the numbers, therefore, appear to be growing.the numbers, however, tell only part of the story. one of the more disturbing trends is the fact that weapons of greater and greater lethality can now fall into the hands of smaller and smaller groups. the problem for the security services is that the smaller the group, the more difcult it will be to detect.up until now, terrorist groups, with the singular exception of the aum shinriku cult in japan that released sarin gas on the tokyo subway in march 1995, have evinced little interest in using weapons of mass destruction, specically nuclear, radiological, chemical, or biological weapons. but earlier terrorist groups have not attempted to in˚ict protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.118 protecting individual privacy in the struggle against terroristsmass casualties. the perpetrators of 9/11, however, clearly wished to kill as many people as possible. the actions of the al qaeda leadership and their statements both suggest that if they could acquire these weapons, they would deploy them. the difculties of acquiring, transporting, and successfully deploying these types of weapons are such that this is a verylowprobability event. but the consequences of a successful deployment of even the easiest of them, a radiological device, would be so catastrophic that there is no responsible option but to defend against them.we cannot accurately predict how terrorists will next choose to attack us. historically terrorists have been very conservative in their use of tactics, preferring simple tried technologies, given the conditions of uncertainty in which they operate. hence, bombs and bullets have been tools of choice. however, the psychological payback of a successful deployment of even a crude chemical or radiological device is such that some terrorists are likely to try to acquire these weapons.still, the probability is higher that terrorists will attempt an attack with conventional explosives that can be acquired very easily but when strategically deployed can in˚ict signicant casualties and even great psychological damage. the diffuse nature of the threat, and the fact that many militants operate largely independently of any central command, suggest the need to be prepared for all types of attack as well as the fact that different types of attack could be planned simultaneously.particular branches of fundamentalist islam have proven to be very successful in attracting a range of different individuals to the jihadi cause and in so doing making it impossible to single out those to track. these range from poor uneducated young men from the middle east and north africa, to middle class, computerliterate, and westerneducated young men from the region, as well as rst and secondgeneration muslims living in the west. they have also won converts to the cause via the web, prisons, and personal networks. there is no simple prole of the terrorist; rather, the background of those participating in violence is constantly expanding and increasingly including formerly excluded categories of individuals. the anonymity of the web, for example, permits the participation of women.b.6 terrorists and their supporting technologiesthe most important of these new technologies is information technology, and in particular the internetšal qaeda could not function without it. today, islamic fundamentalist terrorist groups rely on the internet to communicate with their members, their supporters, and one another across the globe. they use the internet to recruit members by hosting web sites detailing the iniquities of their adversaries, the successes of protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix b 119their attacks against the west, and the path to action. in this way they have successfully won adherents to the cause in counties as diverse as algeria, the united kingdom, saudi arabia, the united states, pakistan, and spain. once recruited, they use the internet to train their followers by providing online education manuals as well as directions to training camps. they produce propaganda videos both to sustain the converted and to intimidate western publics as well as to win recruits and to raise funds. they use the internet to create a virtual community of support for the militant wherever he or she may be and to sustain their commitment to the cause. they also use the internet to plan and carry out their attacks, as was effectively demonstrated on september 11th.just as important, terroristsšby their very modes of operationšintermingle with the society they target. not only do they use the indigenous information technology infrastructure and the internet to interact with each other, they must also interact with society at large. thus, they use cell phones, pay with credit cards, travel commercially, rent vehicles and apartments, and otherwise engage in conventional commercial activitiesšall of which are activities that leave a digital footprints that may subsequently be tracked.lastly, terrorists have more or less lost the territorial bases they used to house their own institutional infrastructure. given the anonymity, affordability, and ease of access to the internet, they have created a commandandcontrol structure in cyberspace. given the determination of western governments to deny terrorist groups safe physical havens within which to operate and to train with impunity, it seems certain that their reliance on new information technologies will only increase.b.7 looking to the futurewe can reasonably expect the threat from terrorists groups to continue for the foreseeable future. there are no signs of the abatement of the threat. terrorism, like other tactics, will continue to be deployed as long as it proves effective. terrorists have been unsuccessful in achieving the fundamental political change they seek, but they have been particularly successful in achieving their more immediate goals: exacting revenge for real or perceived grievances, achieving renown for themselves and their cause, and provoking a reaction from the authorities. as long as terrorists continue to be successful in achieving their objectives of revenge, renown, and reaction, they are likely to continue to use terrorist tactics.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.120cinformation and information technologyc.1 the information life cycleas chapter 1 points out, digital information in use typically goes through a sevenstep life cycle. these steps include collection, correction and cleaning, storage, use or analysis, publication or sharing, monitoring and evaluation, and retention or deletion.c.1.1 information collectionthe information collected for a program must be appropriate to its purpose. data minimization requires that only information critical to that purpose be collected, though minimization often con˚icts with the temptation to gather more information ﬁjust in caseﬂ it might be useful later in easing the relevant analytical tasks or even for other possibly relevant purposes. legislation, regulation, or other governance rules may require that internal or external authorization to collect the information be obtained, including from relevant third parties. the information source(s) and the information itself must be veried as reliable, objective, and compliant with relevant laws.the government collects information for counterterrorism from many other sources, primarily as extracts from information systems. the government mandates or requests information from many industries: customs and border protection obtains manifests for trucks entering the united states from trucking rms; the department of homeland security (dhs), including the transportation security administration, and protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix c 121the national aeronautics and space administration obtain passenger names and records from airlines; the justice department obtains web search terms, urls, and other records from the information technology (it) and telecommunications industries; the national security agency obtains phone call records from communications providers; and the treasury department obtains suspicious activity reports from the nancial community.in addition, employers, retailers, banks, and travel and telecommunications companies collect data directly from customers as well as from many other government and private sources. the largest databases in the world are clickstreams collected from web interactions, second only to retail and scientic databases. for example, it is conventional practice for companies to collect extensive information on prospective employees from nancial and educational institutions, law enforcement, former employers, and so forth. information collection is a signicant and growing sector of the information economy.finally, the government obtains a great deal of data from private data brokers, who aggregate data on individuals from all legally available sources. because the data are collected by private parties, much of the data are not subject to existing restrictions on government collection efforts.c.1.2 information correction and cleaninga signicant practical and research challenge is to ensure that the information is correct, accurate, and reliable. this is aided by ensuring reliable information provenance and the use of automated and human data validation techniques. for example, automated techniques could be used easily to recognize as anomalous an indicator of pregnancy in the medical records of a male.moreover, in certain instances, laws govern the rights of an individual to correct information errors in commercial applications, for example in one™s credit report. if the individual nds what he or she believes to be an error, documentation of that error can be provided and the error corrected. if the party providing the data does not agree that it made an error, the individual has the right to insert into the record a statement of limited length providing his side of the story.to the best of the committee™s knowledge, individuals negatively affected by counterterrorism programs as the result of data errors have no comparable ability. indeed, for national security reasons, individuals are not permitted to review the data on which adverse decisions are based, even though they may experience the negative consequences (e.g., by being denied boarding a plane).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.122 protecting individual privacy in the struggle against terroristsc.1.3 information storageto be used subsequent to collection, information must be stored in some information repository, often an electronic database. the storage mechanism must maintain the data quality, reliability, and accuracy while ensuring operational characteristics such as robustness to failure and scalability to accommodate both data and processing volumes. in addition, since information systems have vulnerabilities and are subject to threats, appropriate data stewardship must be enforced.whereas banks and telecommunications companies rate highest in information protection, many industries and the government in particular rate considerably lower. increasingly, laws or regulations govern the storage and management of information both at rest (i.e., on a storage device) and in motion (i.e., as it traverses communications networks), thus mandating improvements in data stewardship. for example, regulations requiring the encryption of information on a detachable storage medium or transmitted through a communications channel can be used to protect information in transit and at rest.c.1.4 information analysis and usethe step of information analysis and use involves the use of the program during its operational lifetime to deliver the services dened in the purpose and the rational basis and tested in the experimental basis. as with information storage, information processing must meet operational requirements such as robustness and scalability. as stated in the committee™s proposed framework (see chapter 2) and others, a program must be used solely as dened in the approved purpose and rational basis (i.e., requirements).additional uses must be reviewed and approved as an extension to the approved purpose. for example, if a law enforcement program were applied to counterterrorism, that new use should be reviewed under the relevant laws and regulations. unfortunately, unless protected by a privacy policy, commercial information systems are often used for purposes unanticipated by customers, e.g., customers receiving marketing and promotional material unrelated to the ticket that they purchased from an airline. in approving additional uses of information, one need not specify the precise method of analysis, since that is often difcult to anticipatešonly the general purpose to which the information will be directed needs to be specied.c.1.5 information sharinga major counterterrorism theme that has emerged since september 11 (9/11) is the notion of information sharingšthat u.s. counterterrorist protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix c 123efforts will be more effective when the relevant agencies can easily and effectively cooperate and share information.1 the national counterterrorism center (nctc) was established to serve as a multiagency center analyzing and integrating all intelligence pertaining to terrorism, including threats to u.s. interests at home and abroad. nctc also is responsible for developing, implementing, and assessing the effectiveness of strategic operational planning efforts to achieve counterterrorism objectives.compared to the relevant policy and practices, the technology for sharing information is relatively well developed. today, modern information systems live in an ecosystem of other information systems and services, accessible enterprisewide over an intranet or worldwide over the internet, and it is increasingly common for both raw information and analytical results to be published electronically.a modern information system obtains information and services from many other information systems, in some cases thousands of information systems, and reciprocally provides information and services. such ecosystems developed originally to increase automation by eliminating paper or electronic reports that were exchanged with humans or other systems by largely human means. currently such ecosystems permit organizations to modify and enhance their businesses with great speed and agility. customers have the convenience of reserving a trip with a travel agent and having all of the relevant hotels, car rental agencies, airlines, credit card companies, and banks handled transparently. while information systems™ interoperation and information sharing are a convenience for a customer, they are a businesscritical requirement in almost every business.clear civil liberties concerns arise when information is shared and repurposed without restriction. hence, the committee™s framework lists the criteria and best practices that are required to protect civil liberties, including appropriateness, agency and external authorization, dened purpose, and assessment, as discussed below.c.1.6 information monitoringan information program must be continuously monitored and assessed to ensure that it is effective in achieving its purpose and that 1 see for example, national security council, national strategy for combating terrorism, national security council, washington, d.c., september 2006, available at http://www.whitehouse.gov/nsc/nsct/2006/; national commission on terrorist attacks upon the united states, 9/11 commission report, u.s. government printing ofce, washington, d.c., july 2004; and three reports of the markle foundation task force on national security in the information age, markle foundation, new york, n.y., available at http://www.markletaskforce.org/: protecting america™s freedom in the information age (2002), creating a trusted network for homeland security (2003), and mobilizing information to prevent terrorism: accelerating development of a trusted information sharing environment (2006).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.124 protecting individual privacy in the struggle against terroristsit complies with all relevant laws, regulations, and governance. the committee™s framework lists several relevant criteria for which there are best practices, including audit trails, auditing for compliance with existing laws, ensuring reporting and redress of false positives and related impacts on individuals, and having in place a privacy ofcer, training, agency authorization, and external authorization.one of the most challenging aspects of informationintensive systems is evaluating their efcacy or their effectiveness relative to their purpose. the growth in data, transactions, and analytical volumes is a direct measure of the value and the efcacy of data and information processing. the continued growing investment in these programs is a direct measure of their effectiveness in promoting economic competitiveness in the marketplace.2 more specically, each industry and application domain, such as telecommunications billing, has welldened measures of efcacy or business effectiveness. for example, two of the many telecommunications billing metrics include time and cost to produce. an extreme example involves wall street arbitrageurs who search the entire history of stock market trades and simultaneous trades as they occur in all u.s. trading ˚oors and nd, on a regular basis, investment opportunities in 100ths of seconds. typically there are best practices and dened standards for assessing effectiveness, as called for in the committee™s framework. following information system best practices, counterterrorism programs should have efcacy metrics dened for them against which they can be assessed.c.1.7 information retentionthe nal step of the information life cycle involves the retention or deletion of information based on a dened retention period, data quality, data minimization, or other criteria.3 data retention refers to the period of time during which an organization can or must retain data in its automated and manual records. a data retention requirement may be that data 2 in 2005, the information technology products sector accounted for $640 billion or 2.8 percent of the u.s. gross domestic output, while the communications sector accounted for $514 billion or 2.25 percent. the it sector has experienced a 2.7 percent compound annual growth rate (cagr) since 1998, and the communications sector a 6.5 percent cagr (u.s. department of commerce, bureau of economic analysis, ﬁgross domestic product: fourth quarter 2006 (advance),ﬂ available at http://www.bea.gov/newsreleases/national/gdp/2007/gdp406a.htm; andrew bartels, u.s. it spending summary: q3 2006, forrester research, inc., cambridge, mass., november 29, 2006).3 data privacy and integrity advisory committee, framework for privacy analysis of programs, technologies, and applications, report no. 200601, u.s. department of homeland security, washington, d.c., adopted march 7, 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix c 125can be kept no longer than the dened period or that it must be kept at least until the dened period is over. when a data item is to be deleted, all copies of the item must be found and deleted from all automated and manual records. in the context of this report, data retention is a privacy and civil liberties issue when applied to personally identiable information (pii) such as name plus social security number.the increased digitization of individuals™ personal and professional lives has led to dramatic increases in the amount of pii that is stored in automated and manual records. while this information provides signicant value and convenience, it also exposes people to risks such as identity theft, one of the most frequent crimes in the united states, and to other digital crimes and loss of privacy. one report indicates that over 168 million data records have been compromised due to security breaches in the united states from january 2005 to october 2007.4 to protect the public from such crimes, state and federal governments have passed many laws and regulations5 and are continuing to draft new laws and regulations in response to the increased risks related to the growth of retained pii and the power of current technologies. these laws and regulations dene data retention periods for specic types of data.information retention poses complex and unresolved business, legal, and technical issues. in the normal course of business, data must be retained relative to the relevant business cycle, e.g., to monthly, quarterly, or annual billing cycles, and to the much longer, e.g., 10 years, statute of limitations periods during which legal disputes could arise and be prosecuted. at the same time organizations may want to delete data to reduce their exposure to compliance irregularities or potential legal discovery by data forensic techniques, data such as email trials in the enron case and voice mails in a case involving hewlett packard. businesses must meet the requirements of relevant regulations; sarbanesoxley is one of hundreds that are applicable to specic data types in specic business contexts.legal issues include evolving and con˚icting laws, regulations, and government requests. within the united states, there are more than 45 different state data security and privacy laws and several evolving federal laws. government agencies make con˚icting requests. the department of justice (doj) and dhs requested lengthy retention periods to ght child pornography, e.g., 20 years, and terrorism, e.g., forever, respectively. at 4 privacy rights clearing house, ﬁa chronology of data breaches,ﬂ posted april 20, 2005, available at http://www.privacyrights.org/ar/chrondatabreaches.htm#cp.5 see, for example, u.s. congressional research service, data security: protecting the privacy of phone records, rl33287, congressional research service, library of congress, washington, d.c., updated may 17, 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.126 protecting individual privacy in the struggle against terroriststhe same time, the federal communications commission (fcc) and the federal trade commission (ftc) requested shortened retention periods, e.g., 90 days, to protect privacy and other civil liberties.technical issues involve keeping up with evolving data retention requirements, mediating between con˚icting requirements, and simply implementing data retention policies covering unimaginable volumes of data. information sharing causes information to be copied and distributed to other systems within an organization or via the internet across the world. one form of information distribution is to publish it on paper or digital media, as reports, or for technical purposes such as backup and disaster recovery. implementing a data retention policy requires that all copies be traced or identied so that they can be deleted compliant with the relevant policy. as the requirements change, so must technical solutions for managing the data retention policy as it applies to all copies. entirely new content and record management technologies are being developed to automate data retention policies. positive impacts of data retention laws and regulations include data minimizatoinšeliminating all data that are not essential to the relevant business purposešand raising the previously low priority of data protection and security in all organizations.c.1.8 issues related to data linkageadditional issues arise when information is assembled or collected from a variety of sources for presentation to an application. assembling such a collection generally entails linking records based on data elds such as unique identiers (if present and available) or less perfect identiers (such as combinations of name, address, and date of birth). in practice, it is often the case that data may be linked with little or no control for accuracy or ability to correct errors in these elds, with the likely outcome that many records will be linked improperly and/or that many other records that should be linked are not linked. without checks on the accuracy of such linkages, there is no way of understanding how errors resulting from linkage may affect the quality of the subsequent analysis. (for more on issues related to data linkage, see appendix h.)c.1.9 connecting the information life cycle to the frameworkthe framework dened in chapter 2 of this report provides guidance on information practices to achieve efcacy of counterterrorism programs while ensuring adequate civil liberties protections. all information practices related to informationbased programs can be considered in the context of the typical information life cycle. each step of the life cycle is protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix c 127governed by prevailing laws, regulations, and governance rules intended to protect condentiality, intellectual property, and, for example, in the intelligence community, classied information.efcacy and civil liberties issues arise in each step of the information life cycle. hence, the effective and appropriate use of information programs involves the use of relevant best practices in each step.6 the term ﬁbest practiceﬂ refers to a practice or solution that was known to have worked well according to the requirements. the name ﬁbest practiceﬂ is misleading, since a best practice is seldom proven to be best nor to work in all circumstances. even if best practices were effective, they are used in less than 30 percent of applicable cases. these issues and practices also arise in and pose challenges for informationintensive programs in the private sector.for example, most commercial enterprises publish a privacy policy that denes how they treat customer information in each step of the information life cycle. privacy policies generally dene what information is collected, indicate customer rights to correct the information, state that the information is stored and used by the enterprise (typically at their discretion), describe what information will be shared under specic circumstances, pledge to monitor its appropriate use, and nally, say how long the information will be retained. hence, the committee™s framework calls for a privacy ofcer to oversee these issues for each counterterrorism program.the main criterion on which a program is evaluated is its purpose or objective. all other evaluation criteria are based on the program™s stated purpose or objective. due to the investment in resources and the impact programs can have, programs require a sound rational and experimental basis. in information systems terminology, the rational basis is expressed in terms of systems requirements that dene precisely what the information system is to do and how it is to operate. the purpose and rational basis must be evaluated relative to the relevant realworld requirements and the prevailing laws and regulations. once approved, this acts as the approved basis for the program. it is the nature of programs that their requirements evolve constantly. when they do, they must be evaluated and approved, as were the original requirements. the experimental basis is proven, objectively, during various testing and user acceptances tests in which the information system is tested in all possible environments against the outcomes dened in the systems requirements. the purpose, 6 d. aron and a. rowselljones, success with standards, gartner exp, stamford, conn., may 2006; it governance institute (itgi), it governance global status reportš2006, itgi, rolling meadows, ill., 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.128 protecting individual privacy in the struggle against terroristsalong with the rational and experimental bases, must cover all steps of the information life cycle and be fully documented.c.2 the underlying communications and information technologyc.2.1 communications technologytwentyrst century communications technology is in a continuing phase of rapid growth, evolution, and transformation. today, there are more than 5,600 telecommunications providers in the united states. whereas in the past providers were distinguished by the technology of the communications medium involved, more recently deregulation and advances in technology have led to a convergence of technologies and companies, and today any company can become a telecommunications provider, thus expanding both the number of service providers and the types of communications services. for example, the shell oil company is treated for certain purposes as a communications service provider because it provides its customers internetbased services with which to check or modify heating or other electrical appliances in their home.the scale of communications network usage is almost beyond imagination and growing rapidly. in the united states, the average annual growth rate in wireless calls, voip calls, and email has been around 50 percent. in addition to these conventional forms of communication there is a wide range of new services such as instant messaging, small messaging service, video messaging, and a plethora of new business services communicated over the internet. these communications are also enormous in data volume. a 2003 rough estimate7 of annual data volumes claimed over 9 exabytes of wireline calls and over 2 exabytes of wireless calls, with over 1.5 petabytes of internet trafc. a rough approximation of an exabyte is 100,000 times the data volume that corresponds to the more than 19 million books in the library of congress.the data associated with telecommunications fall into three categories:ł the actual communication or content of the communication. in general but depending on the nature of the service, communications providers are generally precluded from examining content except for technical reasons such as improving quality of service.7 p. lyman and h.r. varian, how much information, 2003, retrieved from http://www.sims.berkeley.edu/howmuchinfo2003 on may 13, 2008.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix c 129ł the information required to manage and process the call, e.g., the source number, the destination number, the start time, and the end time, called call data records (cdr). (such information is generally known as customer proprietary network information (cpni).) communications providers retain the management data for billing and other technical and business purposes, such as detection and prevention of telecommunications fraud, and thus maintain vast data repositories of cdrs (in the petabyte range). for example, in 2001 at&t reported generating more than 300 million cdrs per day for 100 million longdistance accounts.ł subscriber information, such as address, credit and billing information, and descriptions of services provided. as services become more sophisticated, the need for additional subscriber information grows to further dene services and increase ease of use. for example, customer proles kept by service providers on the internet often include detailed preferences so that the automated service can meet customer needs without having to request that information on each use.telecommunications companies collect data in all three categories. access to cpni is strictly governed by federal and other legislation and by telecommunications regulations with severe penalties for each violation. due to the signicant growth in the types of communications services and a continuing large growth in communications volumes, as well as signicant advances in technology, the nature, management, and governance of cpni must be constantly updated, and laws, regulations, and practices must be revised to re˚ect new and emerging opportunities and threats, including those related to counterterrorism and civil liberties. one illustration of the need for rebalancing is an ongoing tension between the fcc, the ftc, and civil liberties interests (who have argued for reducing the time that service providers retain cpni) and dhs and doj (which have argued to increase retention time in case it is required for terrorist, legal, or other security purposes).access to data in the other categories provides a more highly revealing portrait of personal behavior and is covered by law (although not telecommunications law).c.2.2 information technologyfor most citizens in daily life, the world is increasingly digital. citizens apply electronically for government services, such as passports and licenses. in an increasingly cashless society, consumers engage in numerous nancial transactions that are precisely recorded, often including the location and time. whether for entertainment, personal, or professional purposes, clicks on the internet are recorded for future use. every trip is protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.130 protecting individual privacy in the struggle against terroristsrecorded, from the airline, hotel, and car rental reservations to the actual events of the trip. increasingly people and organizations publish detailed aspects of themselves, including electronic calendars, photographs, videos, music, and aspects of their personal lives. increasingly activities in public places, stores, and enterprises are recorded and stored by surveillance systems. educational institutions, e.g., ˚ight schools, record their members™ activities. employers record and retain extensive information on employees. with the increasing use of technologies such as rfid (radio frequency identication) tags, objects that people own and use provide personal information that can be read at a distance; for example, automobile and appliance parts, articles of clothing, retail products, and electronic devices such as telephones, personal data assistants, and computers can communicate information such as location, status, and temperatures.moreover, the very types of personal information that can be collected are proliferating. for most of the 20th century, digital information referred to structured information such as name, address, telephone number, purchase order number, and the like. in the 21st century, digital information has expanded to include anything that can be represented digitally such as graphics, music, and video. there is a dramatic growth in unstructured information, captured, for example, by the 4.2 million closedcircuit television (cctv) cameras in britainšabout one for every 14 people and other surveillance cameras in the united states, much of it stored for future processing.the scale of information processing undertaken in the united states is unimaginably large. fortune 500 companies and large federal agencies are likely to have more than 5,000 information systems each with one or more databases. it would be rare to nd any business of any size in the united states that did not have a signicant investment in information systems and databases. the largest databases in the world, according to the 2005 biennual winter corporation survey,8 exceeded 23 terabytes (tb) for transactional databases and more than 100 tb with 3 trillion entries for data warehouses, which is equivalent in data volume to 10 times the contents of the library of congress. growth rates over 2 years for these databases were between a factor of 2 for transactional databases and a factor of 3 for the largest data warehouse. over the past 4 years the average database size rose 243 percent, while the maximum size rose 578 percent. the use of these databases, or workloads, is equally staggering. the largest transactional workload was 1 billion sql statements (e.g., a database query) per hour, with an average of 35 million and 30 million for the largest data warehouse (query only) workload, at an average of 2 million 8 k. auerbach, 2005 topten program summary: select findings from the topten program, winter corporation, waltham, mass., may 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix c 131per hour. (sql is a computer language for accessing and querying databases.) winter estimated in 2005 that by 2008 transactional workloads would have grown 174 percent while data warehouse workloads would have quadrupled. while individual databases and their use are growing dramatically, so is the total number of databases.c.2.3 managing information technology systems and programsthere are many formally dened privatesector9 and government10 it assessment frameworks, i.e., guidelines and best practices, for improving it governance, transparency, and performance management, as well as improving specic areas, such as security,11 privacy,12 and information fairness.13 these frameworks are intended to quantify difculttoevaluate information systems objectives such as information systems effectiveness, quality, availability, agility, reliability, accuracy, completeness, efciency, compliance with applicable regulations, and condentiality. although these criteria are difcult to dene and evaluate, they are common requirements that the it industry must evaluate for all critical systems on a regular basis. while there is never a simple or discrete answer, the it industry must make its best approximation.three of the 30 most widely followed frameworks are control objectives for information and related technologies (cobit), it infrastructure library (itil), and international organization for standardization (iso) 9 d. aron and a. rowselljones, success with standards, gartner exp, stamford, conn., may 2006; the it governance institute (itgi), it governance global status reportš2006, itgi, rolling meadows, ill., 2006.10 u.s. general accounting ofce (gao), information technology investment management: a framework for assessing and improving process maturity, gao04394g, version 1.1, gao, washington, d.c., march 2004.11 u.s. ofce of management and budget, ﬁsecurity of federal automated information resources,ﬂ omb circular a130, appendix iii, available at http://www.whitehouse.gov/omb/circulars/a130/a130appendixiii.html, revises procedures formerly contained in appendix iii to omb circular no. a130 (50 fr 52730; december 24, 1985) and incorporates requirements of the computer security act of 1987 (p.l. 100235) and responsibilities assigned in applicable national security directives; w.h. ware, ed., security controls for computer systems: report of defense science board task force on computer security, ad # a076617/0, rand corporation, santa monica, calif., february 1970, reissued october 1979; federal information security management act of 2002 (fisma, 44 u.s.c. § 3541, et seq.).12 data privacy and integrity advisory committee, framework for privacy analysis of programs, technologies, and applications, report no. 200601, u.s. department of homeland security, washington, d.c., adopted march 7, 2006.13 u.s. department of health, education, and welfare, secretary™s advisory committee on automated personal data systems, records, computers, and the rights of citizens, code of fair information practices, july 1973, available at http://aspe.hhs.gov/datacncl/1973privacy/tocprefacemembers.htm.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.132 protecting individual privacy in the struggle against terrorists17799.14 in comparison with cobit, which has 34 highlevel objectives that cover 215 control objectives, the committee™s framework has two highlevel objectives (i.e., effectiveness, and consistency with u.s. laws and values) that cover 30 control objectives. although no one framework has the same highlevel and control objectives as the committee™s framework, they nevertheless provide guidance for achieving all of the committee™s information and communications technologies criteria. analysts advise that organizations judiciously select specic frameworks or criteria based on their relevance to welldened objectives and the readiness of the organization to apply them.15 this method applies also to implementing the committee™s framework.most it organizations surveyed worldwide16 and in the united states17 have adopted a framework. while many have developed their own, there is increasing adoption of formal frameworks based on reports of their efcacy, such as a 30 percent increase in productivity over 2 years through a consistent application of formal frameworks.18 failures with framework implementation are often related to inappropriate selection of criteria, as well as to formulaic implementations that emphasize process and checklists by those who do not understand the objectives or how to evaluate whether they have been achieved.14 the it governance institute (itgi), it governance global status reportš2006, itgi, rolling meadows, ill., 2006.15 d. aron and a. rowselljones, success with standards, gartner exp, stamford, conn., may 2006.16 the it governance institute (itgi), it governance global status reportš2006, itgi, rolling meadows, ill., 2006.17 c. symons, it governance survey results: more work to be done, forrester research, cambridge, mass., april 14, 2005.18 d. aron and a. rowselljones, success with standards, gartner exp, stamford, conn., may 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.133dthe life cycle of technology, systems, and programsas noted in chapter 2, the framework articulated for evaluating and deploying informationbased technologies, programs, and systems acknowledges that the proposed inquiries are unlikely to yield denitive answers (i.e., ﬁyesﬂ or ﬁnoﬂ) at a given point in time and also that the answers may well change with time due to changes in the operational environment. this reality suggests that the policy regimešthat is, what to make of and do with the answers to the questions provided by the frameworkšmust be linked to the program life cycle. (in principle, the complete program life cycle begins with research, goes through development and deployment and then into operations, maintenance, and upgrade, and ends with program retirement.)mature models exist in other application areas that provide some guidance for how to proceed in this domain. for example, before new pharmaceuticals are approved by the food and drug administration they must pass through multiple stages of testing designed to assess drug efcacy (therapeutic benet) as well as safety (acceptable risks) in clinical trials. after approval is obtained for deployment, ongoing monitoring evaluates effectiveness and risks in the realworld environment; drugs may be recalled if they fall below acceptable standards. similarly, product development programs typically rely on increasingly constrained testing regimes that, prior to deployment of a new system, mimic the realworld operating environment as nearly as is possible. even product recall is not uncommon if, after deployment, a product is deemed to be ineffective or otherwise unacceptable (e.g., for safety reasons).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.134 protecting individual privacy in the struggle against terroristssimilar processes exist to guide software development programs. for example, the national aeronautics and space administration has for many years relied on independent verication and validation (iv&v) for safetycritical software applications. and the software engineering institute and others have dened guidelines for verication and validation of large software applications. but these processes do not effectively address the complexities inherent in this class of informationbased programs.multiple versions of what constitutes a program life cycle can be found in literature; here the committee describes a generic model with the following phases:ł identication of needs. analyze the current environment and solutions or processes currently in use; identify capability gaps or unmet needs.ł research and technology development. develop potential solutions to meet the identied needs.ł systems development and demonstration. develop and demonstrate the integrated system.ł operational deployment. complete production and full deployment of the program.ł operational monitoring. provide for ongoing monitoring to ensure that the deployed capability remains both effective and acceptable.ł systems evolution. institute upgrades to improve or enhance system functionality.an effective policy regime should address each of the above phases in turn as indicated below:ł identication of needs. during this phase, questions 1 and 2 from the summary of framework critera for evaluating effectiveness in section 2.5.1 of chapter 2 should be addressedšthat is, the research should proceed only if a clear purpose and a rational basis are established and documented. measures of effectiveness (benet) and measures of performance (risk) should be drafted during this phase.ł research and technology development. during this phase, testing should occur in a controlled laboratory settingšthe equivalent of animal testing in the drug development process or developmental test and evaluation (dt&e) in traditional technology development programs. a key issue in testing informationbased programs is access to data sets that adequately simulate realworld data such that algorithm efcacy can be evaluated. ideally, standardized (and anonymized) data sets should be generated and maintained to support this phase of testing; the data sets maintained by the national institute of standards and technology for protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix d 135use in evaluating ngerprint and other biometric detection algorithms may serve as a useful model.1 the program should proceed beyond this phase only after demonstration that a sound experimental basis exists in a laboratory setting; measures of effectiveness and measures of performance will likely require renement during this phase of program development.ł system development and demonstration. during this phase, the program should be eldtestedšsubjected to the equivalent of human subject trials in the drug development process or operational test and evaluation (ot&e) in traditional technology development programs. the test environment must mimic realworld conditions as nearly as possible, and so both the simulation environment and requisite data sets must be designed and implemented with appropriate oversight. if it is necessary, for example, to use realworld data, then the test regime must provide appropriate protections to guard against inappropriate use of either the data or the results. during this phase of testing, the various elements of question 3 of the effectiveness criteria summary in section 2.5.1 should be addressed (eldtested? tested to take into account realworld conditions? successful in predicting historical events? experimental successes replicated?), as should questions 4, 6, and 7 (scalability, capability for integration with relevant systems and tools, robustness in the eld and against countermeasures). in addition, the development team should respond to questions 8 and 9 (guarantees regarding appropriateness and reliability of data, provision of appropriate data stewardship).also, given the class of programs under consideration in this report, a requirement for iv&v is needed at this phase of the life cycle. the iv&v process should review results from prior phases of testing and address the inquiries in question 10 (objectivity). measures of effectiveness and measures of performance should be nalized for use in ongoing monitoring of the program if it is subsequently operationally deployed.ł operational deployment. the nal gate prior to operational deployment is an agencylevel review of all items delineated in the summary of criteria for evaluating consistency with laws and values in section 2.5.2, assurance that an ongoing monitoring process is in place, and denition of the conditions for operational deployment (e.g., threshold values for key measures). this review process should ensure that compliance is documented and reviewed in accordance with question 12 of the effectiveness criteria summary in section 2.5.1.1 see http://www.itl.nist.gov/iad/894.03/databases/defs/dbases.html#nglist for more information.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.136 protecting individual privacy in the struggle against terroristsł operational monitoring. once deployed, ongoing monitoring against established measures is vital to ensure that the system remains both effective and acceptable. if results in realworld operations suggest that, due either to changes in the external environment or to a lack of delity in the ot&e environment, system performance does not meet the established thresholds, an immediate agencylevel review should be conducted to determine whether operational authorization should be revoked.ł systems evolution. in general, information systems evolve or become obsolete. they evolve for many reasons. for example, new technologies may become available whose adoption can make the system more usable, or new applications may be required in a new operating environment, or new capabilities previously planned but not yet incorporated may be deployed. because system evolution results in new functionality, reapplication of the framework described in chapter 2 is usually warranted.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.137ehypothetical and illustrative applications of the framework to various scenariosthis appendix illustrates how elements of the framework described in chapter 2 might be applied to various hypothetical scenarios. each scenario posits a particular kind of terrorist threat, a possible technological approach to addressing the threat, and some of the possible impacts on privacy entailed by that scenario. the scenarios are intended to illustrate how application of the framework draws out important questions to consider and answer when deciding on the deployment of a program. they are by no means exhaustive in their application of the framework, and they do not exemplify all the technologies considered in this report.note: the committee emphasizes that the descriptions of technological approaches in this appendix are not an endorsement of or a recommendation for their use.e.1 airport securitye.1.1 the threatterrorists continue to target air travel as an important objective. for the foreseeable future, aviation authorities will have to guard against the threat of an armed hijacking or the destruction of one or more fully loaded passenger planes.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.138 protecting individual privacy in the struggle against terroristse.1.2 a possible technological approach to addressing the threatcheckpoint screening of airport passengers and their baggage to prevent the transport of weapons (e.g., rearms, explosives) will continue. however, with advancing technologies, future security checkpoints could be different from today™s checkpoints in several ingenious respects:ł use of new sensors. new imaging sensors could be introduced to reveal whether weapons are being hidden under clothing, although these sensors might also reveal anatomical features of the body. retinal scans and other biometrics could be introduced to help validate passenger identity. sensors for thermal imaging of the body or portions of the body could be introduced to detect signs of nervousness or excitement, and additional video cameras could be introduced with new software for face recognition and for analyzing body motion to search for signs of nervousness and other suspicious activity. some of these sensors could be positioned so that passengers are aware they are being sensed, while others might be positioned so that passengers have no specic, explicit warning that they are being sensed.ł use of realtime networking to share data instantaneously across multiple airport security checkpoints (both within the same airport and at different airports), and to integrate data with information in other databases. this approach would enable realtime sharing and fusion of information such as the detection that a nonstandard homemade briefcase containing unacceptable materials was found in airport a, and another similar event occurred in airport b, resulting in immediate transmission of information about the briefcase that would enable detecting other copies of it at other airports.ł use of data mining methods to draw inferences from a large shared data set, and to provide guidance to the human checkpoint operators. for example, computerbased screening proles for luggage and passengers might be improved continuously based on experience with millions of passengers across many airports. as one example, consider that today a human operator decides to hand inspect a certain fraction of luggage after it has passed through the xray scanner, perhaps because a suspiciouslooking object is seen in the xray scan. each time this occurs, the result of the hand inspection could be provided as a training example to a data mining program so that it could learn, from hundreds of thousands of such experiences, which xray images correspond to truly dangerous objects as opposed to false alarms. computerbased machine learning algorithms could use such training data, collected from many security checkpoints at many airports, to formulate a potentially more accurate prole that could automatically estimate a risk level for each object seen in an xray scan and to assist the human screener with the goal of reducing the number of false alarms leading to invasive manual searches.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix e 139this imaginary future security checkpoint allows grounding many of the generic issues faced when deciding whether and how to introduce new information collection, fusion, and analysis systems and how to manage their potential impacts on civil liberties both in their specic implementation and in terms of general policies and legal frameworks.e.1.3 possible privacy impactsthe privacy impact of detection technologies can vary signicantly depending on choices made during deployment. the committee suggests that future regulations should differentiate systems and deployments based on features that can signicantly affect perceived privacy impact, including:ł which data features are collected. for example, when capturing images of baggage contents, the images might or might not be associated with the name or image of the passenger. anonymous images of baggage, even if stored for future data mining, might be perceived as less invasive than baggage images associated with the owner.ł covertness of collection. images of passengers might be collected covertly, without the awareness of the individual, throughout the airport, or alternatively with the passenger™s awareness and implicit consent at the security checkpoint. many will consider the former to be more invasive of their privacy.ł data dissemination. data might be collected and used only for local processing, or disseminated more widely. for example, images of bags and passengers might be used only locally, or disseminated widely in a nationwide data store accessible to many agencies.ł retention. data might be required by regulations to be destroyed within a specied time interval, or kept forever.ł use. data might be restricted to a particular use (e.g., anatomically revealing images of airport passengers might be available for the sole purpose of checking for hidden objects), or unrestricted for arbitrary future use. the perceived impact on privacy can be very different in the two cases.ł use by computer versus human. the data might be used (processed) by a computer, or alternatively by a human. for example, anatomically revealing images might be accessible only to a computer program that determines whether there is evidence of a hidden object under clothing. alternatively, these images might be examined by the human security screener to manually search for hidden objects. the former case may be judged as less invasive by many passengers. note that if a computer examination identies a suspicious case, then a manual examination can be the next step. if the computer examination is sufciently accurate, such protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.140 protecting individual privacy in the struggle against terroristsa twostage computerthenhuman process might signicantly reduce the perceived privacy impact.ł control of permissions. if data are retained for future uses, regulations might be placed on who can grant permission for subsequent dissemination and use (e.g., the collector of the data, a court, or the subject of the data). if the subject of the data is given a hand in granting permission, then the perceived privacy impact may be lessened.e.1.4 applying the frameworkto illustrate the use of the framework proposed in chapter 2 for evaluating the potential deployment of new systems, consider how it might be used to evaluate the possible deployment of one of the technologies suggested above. in particular, consider that company x comes to the u.s. government with a proposal to deploy a system that would (1) create a network to share images of baggage that are currently collected at all u.s. airport checkpoints, as well as the outcome of any manual searches of those bags by security screeners, and (2) use this nationwide database for two purposes: rst, to perform data mining to identify homemade versus massproduced luggage bags (based on their relative frequency of appearance at airports), and second, to use the results of the thousands of manual searches performed nationwide to automatically train more accurate software to spot suspicious items in xray images of baggage. how would the proposed framework apply to evaluating such a proposal?effectivenessfirst, the framework asks for a clearly articulated purpose for the new system, an evaluation of why it may out perform current methods, and a thorough experimental evaluation of the system before full deployment. note one might experimentally evaluate whether the data mining software of company x is capable of distinguishing homemade versus massproduced luggage without going to the step of a full network deployment, by testing its use in one or two individual trial airports rst. however, in many data mining applications, including this one, proving the value of collecting the full data set by testing on small sets is difcult, because performance sometimes improves as the size of the data set grows.the framework would also raise issues regarding the rational basis for the program (is it of signicant value to spot custommade luggage or custommodied massproduced luggage?, does data mining the results of manual luggage inspections actually lead to more accurate automated luggage inspections and if so does this lead in turn to safer or less invaprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix e 141sive screening?). it would raise issues about scalability (can the computer system and human infrastructure handle the large volume of data from all u.s. airports in real time?), and data stewardship (who will be responsible for the data collection?, and how will it be administered?).compliance with laws and valuesthe framework asks whether an informationbased program is consistent with u.s. law and values. the criteria for such consideration have been divided into three categories: data, programs, administration, and oversight. does the proposed system operate with the least personal data consistent with goals of the system? note that this question raises the issue of whether the owner of the luggage should be identied with each luggage image, and of evaluating the impacts of this on both system utility and on personal privacy. does the system produce a tamperresistant audit trail of who accesses which data? is it secured against illegal tampering? what process is in place to assure monitoring the performance of the deployed system in terms of false positives and in terms of likely impacts on individuals? the framework asks questions about the agency collecting and deploying the system, perhaps the transportation security administration in this case. does this agency have a policylevel privacy ofcer, are its employees and others who might access the data trained appropriately, and are all of the uses of this nationwide luggage image dataset clearly articulated and in compliance with existing laws?e.2 syndromic surveillancee.2.1 the threata major issue for those concerned with ensuring public health is the early detection of an outbreak or attack capable of causing widespread disease, injury, or death. the presumption behind most early detection systems is that early warning would aid the rapid deployment of emergency resources and the initiation of public health and medical responses that would help to limit the spread of disease or any ill effects.e.2.2 a possible technological approach to addressing the threatin the past, ofcials have relied on hospitals and doctors to signal outbreaks by reporting disturbing or unusual trends and troubling cases or indicators. today, however, with the increasing sophistication of technology, including data mining, sensors, and communications capabilities, many ofcials are investigating better ways of getting earlier warning of protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.142 protecting individual privacy in the struggle against terroristsoutbreaks or attacks. for example, could it be useful to monitor pharmacy sales of overthecounter (otc) drugs to get early warning for, say, something like an in˚uenza epidemic? perhaps it could be helpful to monitor school or work absentee rates for indications of widespread illness or biological attack. these forms of socalled ﬁsyndromic surveillanceﬂ are geared toward achieving the earliest possible detection of public health emergencies.1syndromic surveillance requires access to many different kinds of data. for example, in a large city, the data streams into a syndromic surveillance system might include digital records of common, otc sales of medicines from pharmacies in the city, absentee records from city schools and some select businesses, counts of 911 calls to the city categorized into more than 50 call types (e.g., ﬁin˚uenza like illness,ﬂ ﬁbreathing problems,ﬂ and so on), and records of chief complaints from hospital emergency departments. in addition, these data streams could contain temporal and spatial information.such data streams would be monitored periodically (say, ever 24 hours) and compared automatically to archived data collected over the past. changes from expected values would be automatically analyzed for statistical signicance. the geographical data in the streams would also enable the system to identify the location of ﬁhot spotsﬂ that might indicate possible outbreak points in the city.box e.1 describes how a syndromic surveillance system might be used in practice.e.2.3 possible privacy impactsfrom a privacy perspective, personal health data are among the most sensitive pieces of information. however, to generate initial indicators, only anonymized data are needed. followup may be needed, as might be the case if interviews with patients or providers are necessary, and undertaking followup is impossible if anonymity rules. (in many pub1 for more information on syndromic surveillance generally, as well as more information about previous efforts, see http://www.cdc.gov/mmwr/pdf/wk/mm53su01.pdf. overviews of syndromic surveillance can be found at http://iier.isciii.es/mmwr/preview/mmwrhtml/su5301a3.htm; k.d. mandl, j.m. overhage, m.m. wagner, w.b. lober, p. sebastiani, f. mostashari, j.a. pavlin, p.h. gesteland, t. treadwell, e. koski, l. hutwagner, d.l. buckeridge, r.d. aller, and s. grannis, ﬁimplementing syndromic surveillance: a practical guide informed by the early experience,ﬂ journal of the american medical informatics association 11(2):141150, 2004; and j.w. buehler, r.l. berkelman, d.m. hartley, and c.j. peters, ﬁsyndromic surveillance and bioterrorismrelated epidemics,ﬂ emerging infectious diseases 9(10):11971204, 2003.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix e 143box e.1 an illustrative operational scenario for the use of syndromic surveillance on a winter afternoon, a goodcity public health ofcial conducting routine daily data analysis notes a spike in the number of hospital emergency department (ed) visits and pharmacy sales detected by goodcity™s syyndromic surveillance system, which is designed to detect early, indirect indicators of a possible bioterror attack. none of the other data streams indicate unusual patterns. the health ofcial, who has been specially trained to operate the statistical data mining software involved, analyzes the temporal and spatial distribution of ed visits using scan statistics and nds that two hospitals in the same zip code, and located within blocks of each other, accounted for most of the excess visits. a third hospital in the same area of the city experienced a normal volume of ed visits during the previous 24 hours. further examination of available data reveals that respiratory illness was the chief complaint of a majority of the patients seen in the two eds of interest. further analysis shows that in the past 24 hours, both hospitals experienced higher rates of ed visits for ﬁrespiratory illnessﬂ than expected based on comparisons with hospitalspecic rates gathered in previous years. meanwhile, the health ofcer™s examination shows that overthecounter (otc) medicine sales, in particular medicines to treat cough and fever, are much increased compared to the previous week and compared to the same week of the previous year. the system tracks sales by store and zip code, but no pattern is evident. past analyses have shown that increased purchases of otc medications do not consistently presage a higher volume of ed visits. concerned that the increased incidence of respiratory complaints in a geographically discrete neighborhood of the city, combined with citywide increases in the purchase of cough and fever medicines, might indicate the leading edge of an aerosolized anthrax attack or some other disease outbreak of public health signicance, the health ofcial assigns a public health nurse to conduct a telephonic descriptive review of the ed cases seen in the affected hospitals. the nurse will also query staff from a sample of hospitals that are not part of the surveillance system, looking for unusual presentations or higherthanusual volume. after several hours of phone calls, the public health nurse discovers that many of the excess ed visits were indeed for cough and respiratory complaints, but most patients were not deemed seriously ill and were sent home with a diagnosis of ﬁviral illness.ﬂ early in her calls, the nurse heard of two young adult patients who had been extremely ill with apparent ﬁpneumoniaﬂ and admitted to the intensive care unit. since it is unusual for healthy young adults to require hospitalization for pneumonia, the nurse tracked down and interviewed the admitting physicians for both patients. in both cases, the patients involved had an underlying illness that explained their condition. the hospital staff consulted reported that ed volume throughout the day was not abnormally high; today™s syndromic surveillance data documenting ed visits citywide would not be available for another 12 hours. public health ofcials decided on the basis of these investigations to do nothing more, but to continue to closely monitor hospital ed visits and otc sales over the coming days.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.144 protecting individual privacy in the struggle against terroristslished articles on syndromic surveillance, the emergency department (ed) data is the most important and useful data stream for both detecting and ruling out disease outbreaks.)the efcacy of a surveillance system could be signicantly enhanced through the potential inferential power of multivariate information about specic individuals arriving through different data streams. for example, two data streams might be purchases of otc medications for coughs and school attendance records. rather than simply analyzing these data streams separately and noting temporal correlations in them, considerably more inferential power would be available if it were possible to associate a specic child absent from school on tuesday with the purchase of cough syrup on tuesday by his father.however, linking attendance records to drug store purchasing records in such a manner would require personal identiers in each stream to enable such a match. privacy interests would therefore be implicated as well. for example, while the health information portability and accountability act allows the use of medical information for public health purposes, it is unclear how to interpret the privacy restrictions in the context of regular surveillance systems. further, different laws govern access to or restrictions on data associated with educational systems and organizations, and grocery chains restrict access to proprietary information on customer purchases.e.2.4 applying the frameworksince a number of syndromic surveillance systems are in operation, the committee has been able to draw on public information and research in its re˚ection on the application of the framework presented in chapter 2 and hence report some of that information to the reader. however, the illustration here does not constitute an endorsement or disapproval of such systems by this committee. the implementation of syndromic surveillance systems was prompted largely by the federal government when the u.s. department of health and human services (hhs) made bioterrorism preparedness monies available to state health agencies in 2002. many such systems, of varying type and scope, were createdšsome by city health departments, some by state health agencies in collaboration with universities, and others by private contractors who not only designed but also operated the systems and then reported analyzed results to government ofcials.effectivenessthe framework asks for a clearly stated purpose. the purpose of most syndromic surveillance systems is to detect a covert bioterrorist attack protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix e 145before large numbers of victims seek medical care, in order to improve response and save lives. hhs did not specify any operational standards or explicit goals for the systems it helped fund, although some standards have been evolving.2when considering a rational basis, the concept that lives might be saved if a bioattack were recognized earlier rather than later, thus lengthening the time available to get countermeasures (medicines and vaccines) to those infected, to conduct investigations into where the attack occurred and who is at risk, and so on gives merit to syndromic surveillance systems. however, the systems™ integration into current practices in the eld should be taken into account. there is good evidence that syndromic surveillance systems can detect large disease outbreaks, but it is less clear how and if such detection improves public health response. health ofcials confronted with a spike in syndromic signals typically seek more denitive evidence of a true rise in illnesses among city residents before taking action.3 this is in part because there is a lot of noise in the systemsšillness rates, otc medicine purchases, 911 reportsšthat varies widely even within a given season and location. also, syndromic surveillance generates many false positives (discussed below), and the ﬁsignalﬂ is not specic enough in most instances to guide action. syndromic signals spur health ofcials to look harder but do not usually trigger a public health response.4 whether syndromic surveillance would actually improve the rapidity of the response to a bioattack compared to clinical case nding is unproven and probably not testable.5 recently, buckeridge and colleagues attempted to compare clinical case nding and syndromic 2 see the u.s. department of health and human services (hhs)sponsored published reviews of specic systems™ operating characteristics and evaluation challenges (m. sosin and j. dethomasis, ﬁevaluation challenges for syndromic surveillancešmaking incremental progress,ﬂ morbidity and mortality weekly report 53(suppl):125129, 2004) as well as a ﬁdecisionmaking frameworkﬂ for implementing syndromic surveillance suggested by a centers for disease control and prevention working group (j.w. buehler, r.s. hopkins, j.m. overhage, d.m. sosin, and v. tong, ﬁframework for evaluating public health surveillance systems for early detection of outbreaks,ﬂ morbidity and mortality weekly report 53(rr5):111, may 7, 2004).3 r. heffernan, f. mostashari, d. das, m. besculides, c. rodriguez, j. greenko, l. steinersichel, s. balter, a. karpati, p. thomas, m. phillips, j. ackelsberg, e. lee, j. leng, j. hartman, k. metzger, r. rosselli, and d. weiss, ﬁnew york city syndromic surveillance systems,ﬂ morbidity and mortality weekly report 53(suppl):2527, september 24, 2004.4 as has been evidenced from responses to signals from biosensors placed at the salt lake city olympics (2002) and with biowatch (an environmental sensor system deployed by the u.s. department of homeland security).5 in a bioattack, it is likely that many people will become ill and appear in the health care system at the same time, making it apparent to clinicians that an unusual event is unfolding. the time between syndromic signal detection plus conrmation activities may in practice offer little if any advantage over clinical case nding.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.146 protecting individual privacy in the struggle against terroristssurveillance for detection of inhalational anthrax due to a bioterror attack using a simulation study.6 these investigators found that syndromic systems could be designed such that detection of an anthrax attack would be improved by one day, but when systems were sensitive enough to detect a substantial portion of outbreaks before clinical case nding, frequent false positives were also produced, which could impose a considerable burden on public health resources.there are limits to the experimental basis for syndromic surveillance systems, and any gains should be weighed against the costs of developing and operating such systems. observable behaviors that might precede patients seeking medical care for an illness are not precisely known. although in 1993 a run on otc medicines in milwaukee famously preceded public health detection of a large, waterborne cryptosporidiosis outbreak, the purchase of nonprescription, otc medicines does not reliably precede outbreaks of illness in populations.7 moreover, a retrospective analysis of 3 years of syndromic surveillance data gathered by the new york city health department concluded that ﬁsyndromic surveillance signals [for gastrointestinal disease outbreaks] occur frequently, [and] are difcult to investigate satisfactorily. . . .ﬂ8the new york city department of health operates one of the country™s most sophisticated syndromic surveillance systems, which has been in use since the late 1990s and has been continually upgraded. this system has been documented as detecting seasonal in˚uenza a week before culturepositive samples of ˚u were found in new york city and has detected large sales of otc antidiarrheal medicines which subsequent investigations associated with gastrointestinal illness and eating spoiled food after a citywide blackout. the system failed, however, to detect either the unprecedented outbreak of west nile virus in 1999 or the anthrax cases of 2001.9syndromic surveillance systems should be developed from technical specications, data ˚ows, and types of signals that have been rigorously shown to be most reliable and productive. however, such development 6 d.l. buckeridge, d.k. owens, p. switzer, j. frank, and m.a. musen, ﬁevaluating detection of an inhalational anthrax outbreak,ﬂ emerging infectious diseases 12(12), 2006.7 r. armstrong, p. coomber, s. prior, and a. dincher, looking for trouble: a policymaker™s guide to biosensing, center for technology and national security policy, national defense university, washington, d.c., june 2004.8 s. balter, d. weiss, h. hanson, v. reddy, d. das, and r. heffernan, ﬁthree years of emergency department gastrointestinal syndrome surveillance in new york city: what have we found?,ﬂ morbidity and mortality weekly report 54(suppl):175180, august 26, 2005.9 ﬁsyndromic surveillance for bioterrorism following the attacks on the world trade centeršnew york city, 2001ﬂ morbidity and mortality weekly report 51(special issue):1315, september 11, 2002.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix e 147has many challenges. because bioterrorist attacks are rare events, most of the ﬁpositiveﬂ signals syndromic surveillance produces will be false positives. setting the system to be very sensitive (i.e., increasing the types and size of data streams) will generate more false positives, which can, over time, erode condence in the system. the complex and larger data streams are also likely to increase the complexity of the investigations that follow the detection of syndromic ﬁsignals,ﬂ which could further delay any response action.10there are also great difculties in doing realtime record linkage on multiple data streams. with static record linkage, all of the databases in question are available for analysis, which means that it is possible to perform crossvalidation, error assessment, and careful blocking to reduce comparisons. with realtime linkage, only a limited data sample is applicable (i.e., those that relate to present cases), which means that the data available to revise parameter estimates and error rates are limited.finally, a key challenge in assessing the utility and efcacy of a syndromic surveillance system is to differentiate between the power of the particular algorithmic approach used in analyzing the data (which may be inadequate regardless of the quality of the data) and the quality of the data used in that particular approach (which may be too poor regardless of the power of the algorithm).assessing the scalability of such systems is also challenging. consideration must be placed on whether this approach is viable for all localities of any size as well as whether some data streams are more important than others or must be of certain minimal scope. the tradeoffs between the size of the signal (number and size of different data streams) and the sensitivity and specicity of the signal (i.e., number of false positives and negatives) must be taken into account.a syndromic surveillance system should be designed to allow the enforcement of business processes; business processes dene the ways in which the system is used, who the agents are, who are authorized to use it, and the steps taken in each individual task. business processes can be different for different syndromic surveillance systems. for example, an agency in one city will allow anyone above a certain pay grade to execute a report but with the concurrence of the chief epidemiologist, whereas the comparable agency in another city will only allow the chief epidemiologist and two other delegated individuals to do so. business processes will help determine how syndromic surveillance systems can be integrated into routine public health practice and what additional resources are 10 a. reingold, ﬁif syndromic surveillance is the answer, what is the question?,ﬂ biosecurity and bioterrorism 1(2):7781, 2003; m. stoto, ﬁsyndromic surveillance,ﬂ issues in science and technology, spring 2005.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.148 protecting individual privacy in the struggle against terroristsrequired. when private contractors or university partners operate the syndromic surveillance systems, processes will have to be dened to ensure that health ofcials receive data and analyses in a timely manner with no uncertainties about the validity of analyses.syndromic surveillance systems have the potential to contain large amounts of data. those operating such systems will have to consider how to guarantee appropriate and reliable data as well as appropriate data stewardship. some questions to consider include: is the system collecting only the data necessary to detect a threat? can syndromic data be forwarded to health departments in a manner that protects patient privacy in routine uses but allows identication to subsequently interview particular patients, in keeping with routine public health practice, in crisis? can the utility of the system be preserved if geographic aggregation or some other form of protection is done to protect individual privacy? what is known about the accuracy of data submitted from different sources? how long do data streams need to be retained? can records of illness patterns be retained without individual data streams? if such data are retained for long periods, will clinical data about specic patients and their commercial records (e.g., drug purchases) be available in these systems? who will have access to the data? what policies need to be established to protect from unlawful or unauthorized disclosure, manipulation, or destruction?lawfulnessthe framework asks to consider whether an informationbased program, such as syndromic surveillance, is consistent with u.s. law and values. the criteria for such consideration have been divided into three categories: data, programs, and administration and oversight. for effective syndromic surveillance systems, the need for personal medical data from emergency rooms is clear, and in most (not all) current syndromic systems the data are anonymized before being sent to public health agencies. in many published articles on syndromic surveillance, the emergency room data constitute the most important and useful data stream for both detecting and ruling out disease outbreaks. data from otc purchases and attendance records seem useful to this system. however, they, as personal data, should be considered only if they are reasonably shown to prove the effectiveness of system. within currently operating systems, data on otc medications are used but are more easily associated with particular stores and less easily associated with individuals.11 linking 11 for example, individuals may purchase overthecounter medications with credit cards or store afnity cards. though these individually identiable purchase records are not rouprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix e 149such information to school absences and clinical information raises major privacy issues and has not been attempted as part of any biosurveillance program, to the committee™s knowledge.public health agencies do have legal authority to release personal medical data if such information is pertinent to public health. frequency of false positives is a major concern with these systems, as the scenario in box e.1 demonstrates. in large public health agencies where resources exist to maintain and staff syndromic surveillance systems appropriately and where digitized data streams are available, such systems may be costeffective. a bioattack alarm may lead to revelations of the names and medical conditions of specic patients seen in emergency rooms associated with syndromic reporting. in such ﬁemergenciesﬂ the violation of an individual™s privacy might be deemed acceptable given the public™s right to know what is going on. however, agencies should have procedures in place for dealing with consequences of false positives. they should also assess and identify the impact on individuals in nonalarm routine operations. the system itself should produce a tamperresistant audit trail, and all personnel authorized to use the system and its outputs should receive training in appropriate use and the laws and policies applicable to its use. the agency should employ a privacy ofcer to ensure compliance with laws, policies, and procedures designed to protect individual privacy. these are but a few considerations toward assessing whether syndromic surveillance systems are consistent with u.s. laws and values.tinely made available to public health authorities, they do exist with the data that drugstores routinely collect and could be made available under some circumstances. various authors have analyzed these data bases to illustrate the potential of early detection of bioterrorist attacksše.g., a. goldenberg, g. shmueli, r.a. caruana, and s.e. fienberg, ﬁearly statistical detection of anthrax outbreaks by tracking overthecounter medication sales,ﬂ proceedings of the national academy of sciences 99(8):52375240, april 2002. linking such information to school absences and clinical information raises major privacy issues and has not been attempted as part of any biosurveillance program to the committee™s knowledge.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.150fprivacyrelated law and regulation: the state of the law and outstanding issuesthe law intended to guide intelligence operations is complex and has failed to keep up with the signicant changes in terrorist threats, surveillance technologies, and the volume, variety, and accessibility of digital data about individuals. the absence of a coherent and uptodate legal framework has contributed to undermining trust in intelligence activities. a brief description of that law along with an explanation of its inadequacies will help illustrate why.f.1 the fourth amendmentf.1.1 basic conceptsthe government has very broad power to obtain personal information. historically, the primary constitutional limit on that power is the fourth amendment, which re˚ects the framers™ hostility to general searches. a general search is a search that is not based on specic evidence that allows the search to be targeted as to the location of the search or the type of evidence the government is seeking. the purpose of the fourth amendment was to forbid general searches by requiring that all search and seizures must be reasonable and that all warrants must state with particularity the item to be seized and the place to be searched.the fourth amendment requires that warrants be issued only ﬁupon probable cause, supported by oath or afrmation, and particularly describing the place to be searched, and the persons or things to be seized.ﬂ fedprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix f 151eral law denes ﬁprobable causeﬂ to mean ﬁa belief that an individual is committing, has committed, or is about to commit a particular offenseﬂ and that the information sought is germane to that crime.1 the supreme court generally requires that the government provide the subject of a search with contemporaneous notice of the search.2collecting information from a person constitutes a search if it violates that individual™s reasonable expectation of privacy. the supreme court has held that a person has a reasonable expectation of privacy in their homes, sealed letters, and the contents of their telephone calls. on the other hand, the court has determined, for example, that warrants are not required to search or seize items in the ﬁplain viewﬂ of a law enforcement ofcer,3 for searches that are conducted incidental to valid arrests,4 or to obtain records held by a third party, even if those records are held under a promise of condentiality.5 the court has interpreted this last exception broadly to nd that the fourth amendment is inapplicable to telecommunications ﬁattributesﬂ (e.g., the number dialed, the time the call was placed, the duration of the call, etc.), because that information is necessarily conveyed to, or observable by, third parties involved in connecting the call.6moreover, the fourth amendment poses no limits on how the government may use information, provided that it has been obtained legally, and some limits on the use of data obtained illegally. consequently, personal data seized by the government in compliance with the fourth amendment may later be used in a context for which the data could not have been obtained lawfully. the rest of this section addresses two important examples of areas in which the evolution of technology and new circumstances suggest that current fourth amendment law and practice may be outdated or inadequate.f.1.2 machineaided searchesin some ways, machineaided searching of enormous volumes of digital transaction records is analogous to a general search, especially if those records contain highly sensitive information. much like a general search in colonial times was not based on specic evidence or limited to a particular person or place, a machineaided search through digital databases can be very broad.1 18 u.s.c. § 2518(3)(a).2 richards v. wisconsin, 520 u.s. 385 (1997).3 coolidge v. new hampshire, 403 u.s. 443 (1971).4 united states v. edwards, 415 u.s. 800 (1974).5 united states v. miller, 425 u.s. 435 (1976).6 smith v. maryland, 442 u.s. 735 (1979).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.152 protecting individual privacy in the struggle against terroristsexisting fourth amendment law speaks to such searches only in limited contexts, however. the fourth amendment requires the government to obtain a search warrant when looking through a person™s hard drive or private email, for example. it also requires that the warrant specify the type of evidence the government is seeking. it may also require a warrant or a subpoena to collect information that is inside a database. however, if the government collects data in compliance with the fourth amendment, and then it aggregates the data into a database, the process of searching through the database is not itself regulated by the fourth amendment. even if the government violates the fourth amendment when collecting the data, the data may be stored, aggregated, and used for any purpose other than that for which the data were wrongfully accessed. so, for example, the court has allowed records illegally seized by criminal investigators to be used by tax investigators on the basis that restricting the subsequent use would not deter the original unconstitutional conduct.7broad machineaided searches and the government™s reuse of lawfully or unlawfully obtained data raise very important questions of public policy. what standards should govern access to or use of data that has already been collected? should use of databases or specic analytical techniques such as data mining be regulated at all? if querying a database or running a data mining program on a database constitutes a search, when is such a search ﬁreasonableﬂ? must the police have a specic individual in mind before searching a database for information on him or her? in the absence of clear standards or guidelines to govern their conduct or even to help them make reasonable judgments, the police cannot do their work. moreover, what level of legal authorization should guide database queries? if a legal standard is used, is relevance the right standard? or is something more like reasonable suspicion or probable cause the proper standard to use?f.1.3 searches and surveillance for national security and intelligence purposes that involve u.s. persons connected to a foreign power or that are conducted wholly outside the united statesthe fourth amendment applies to searches and surveillance conducted for domestic law enforcement purposes within the united states, and those conducted outside of the united states if they involve u.s. citizens (although not necessarily permanent resident aliens). in a 1972 case commonly referred to as the keith decision, the supreme court held that the fourth amendment also applies to searches and surveillance conducted for national security and intelligence purposes within the united 7 united states v. janis, 428 u.s. 433, 455 (1975).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix f 153states if they involve u.s. persons who do not have a connection to a foreign power.8 the court, however, recognized that ﬁdifferent policy and practical considerationsﬂ might apply in the national security context than in traditional law enforcement investigations, and specically invited congress ﬁto consider protective standards for . . . [domestic security] which differ from those already prescribed for specied crimes in title iii.ﬂ9 the court left open the question of whether the fourth amendment applies to searches and surveillance for national security and intelligence purposes that involve u.s. persons who are connected to a foreign power or are conducted wholly outside of the united states,10 and the congress has not supplied any statutory language to ll the gap.f.1.4 the millersmith exclusion of thirdparty recordsas noted in chapter 1, some legal analysts believe that there is no better example of the impact of technological change on the law than the exemption from the fourth amendment created by the supreme court for records held by third parties. according to this perspective, such an exemption signicantly reduces constitutional protections for personal privacyšnot as the result of a conscious legal decision, but through the proliferation of digital technologies that make larger quantities of more detailed information available for inspection than ever before.other analysts suggest that as a general point, the protection of privacy is better founded as a matter of statute and regulation (that is, of policy choices) rather than as a matter of constitutional right.11 in this view, legislatures have many advantages that enable the legislative privacy rules regulating new technologies to be more balanced, comprehensive, and effective than judicially created rules. these advantages include the ability to act more quickly in the face of technological change than courts are able to do and to appreciate existing technology and the impact of different legal rules. in addition, and specically relevant to the third party exemption for the privacy of records held by third par8 united states v. u.s. district court for the eastern district of michigan, 407 u.s. 297 (1972).9 id. at 322.10 j.h. smith and e.l. howe, ﬁfederal legal constraints on electronic surveillance,ﬂ p. 133 in protecting america™s freedom in the information age (markle foundation task force on national security in the information age), markle foundation, new york, n.y., 2002. lower courts have found, however, that there is an exception to the fourth amendment™s warrant requirement for searches conducted for intelligence purposes within the united states that involve only nonu.s. persons or agents of foreign powers. see united states v. bin laden, 126 f. supp. 2d 264, 27172 (s.d.n.y. 2000).11 o.s. kerr, ﬁthe fourth amendment and new technologies: constitutional myths and the case for caution,ﬂ michigan law review 102:801888, 2004.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.154 protecting individual privacy in the struggle against terroriststies, some analysts argue that without some ability for law enforcement ofcials to obtain some transactional data without a warrant, criminals and terrorists operating in cyberspace would be largely able to prevent law enforcement from obtaining probable cause to obtain indictments or to investigate more deeply.f.2 the electronic communications privacy actthe fourth amendment is not the only restraint on the government™s power to collect and use information through surveillance. the electronic communications privacy act (ecpa) is a collection of three different statutes that also regulates government collection of evidence in the context of telecommunications networks. the wiretap act is amended in title i of ecpa, and as amended deals with the interception of telephone and internet communications in transmission.12 it applies to ﬁwire communications,ﬂ although not to video unaccompanied by sound. to intercept communications in transit requires a ﬁ‚super™ search warrant,ﬂ13 unless an exception to the warrant requirement applies such as consent. a warrant can only be sought by designated federal ofcials and requires probable cause, details about the communication to be intercepted, minimization of any nonrelevant communications inadvertently intercepted, and termination immediately upon completion. information obtained in violation of these requirements can subject the responsible agent to minimum damages of $10,000 per violation and is subject to the exclusionary rule (except for email) so that it cannot be used in a subsequent criminal prosecution.title iišthe stored communications actšwhich was adopted in 1986 deals with communications in electronic storage, such as email and voice mail.14 it contains rules that govern compelled disclosure of information from service providers as well as when providers can disclose information voluntarily. traditional warrants are required to obtain access to communications stored 180 days or less. to obtain material stored for more than 180 days, the government need only provide an administrative subpoena, a grand jury subpoena, a trial subpoena, or a court order, all of which are easier to obtain than a traditional warrant. noncontent information, such as information about a customer™s account maintained by a communications provider, can be obtained by the government either 12 wiretap act, public law 90351, 82 stat. 197 (1968) (codied as amended at 18 u.s.c. §§ 25102522).13 o.s. kerr, ﬁinternet surveillance law after the usa patriot act: the big brother that isn™t,ﬂ northwestern university law review 97(2):607673, 2003.14 stored communications act, public law 99508, title ii, § 201, 100 stat. 1848 (1986) (codied as amended at 18 u.s.c. §§ 27012711).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix f 155with a subpoena or by providing ﬁspecic and articulable facts showing that there are reasonable grounds to believe that . . . the records or other information sought are relevant and material to an ongoing criminal investigation.ﬂ15 violations carry a minimum ne of $1,000; no exclusionary rule applies.title iiišthe pen register actšwhich was also adopted in 1986, applies to ﬁpen registersﬂ (to record outgoing call information) and ﬁtrap and traceﬂ devices (to record incoming call information).16 to obtain information akin to what is contained in a phone bill or revealed by ﬁcaller id,ﬂ email header information (the ﬁto,ﬂ ﬁfrom,ﬂ ﬁre,ﬂ and ﬁdateﬂ lines in an email), or the ip address of a site visited on the web, the government need only obtain a court order. the court must provide the orderšthere is no room for judicial discretionšif the government certied that ﬁthe information likely to be obtained by such installation and use is relevant to an ongoing investigation.ﬂ17 the exclusionary rule does not apply to violations of the act.f.3 the foreign intelligence surveillance actwhile the ecpa regulates surveillance for law enforcement purposes, successive presidents insisted that it did not limit their power to engage in surveillance for national security purposes. in the aftermath of watergate, the senate created the select committee to study government operations with respect to intelligence activities, chaired by senator frank church (didaho). the church committee™s nal report, published in 1976, cataloged a wide array of domestic intelligence surveillance abuses committed under the protection of the president™s national security authority.18 while some must have been plainly understood at the time by their perpetrators to have involved wrongdoing, such as spying on political opponents, many involved what today would be called ﬁmission creep.ﬂ19that report, the unresolved nature of the president™s power to con15 18 u.s.c. § 2703(d).16 pen register act, public law 99508, title iii, § 301(a), 100 stat. 1868 (1986) (codied as amended at 18 u.s.c. §§ 31213127).17 18 u.s.c. § 3123(a).18 senate select committee to study government operations with respect to intelligence activities, 94th congress, final report on intelligence activities and the rights of americans, book ii, april 26, 1976; see also m.h. halperin, j.j. berman, r.l. borosage, and c.m. marwick, the lawless state: the crimes of the u.s. intelligence agencies, penguin publishing company ltd., london, u.k., 1976.19 senate select committee to study government operations with respect to intelligence activities, 94th congress, final report on intelligence activities and the rights of americans, book ii, april 26, 1976.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.156 protecting individual privacy in the struggle against terroristsduct domestic surveillance, and the supreme court™s 1972 invitation to congress in the keith decision to ﬁconsider protective standardsﬂ in this area all coalesced in enactment of the foreign intelligence surveillance act (fisa) of 1978.20 the act creates a statutory regime governing the collection of ﬁforeign intelligenceﬂ from a ﬁforeign powerﬂ or ﬁagent of a foreign powerﬂ within the borders of the united states.the act created a special courtšthe foreign intelligence surveillance courtšof seven (now eleven) federal district court judges. the court meets in secret and hears applications from the department of justice (doj) for ex parte orders authorizing surveillance or physical searches. all that the government must show is that there is ﬁprobable cause to believe that the target of the electronic surveillance is a foreign power or agent of a foreign powerﬂ21 and that gathering foreign intelligence is ﬁthe purposeﬂ of the requested order.22 in 2001, the usa patriot act changed this standard to ﬁa signicant purpose.ﬂ23 this change and a decision from the threejudge fisa review court created by the statute to hear appeals brought by the government have resulted in making information obtained from fisa surveillance freely available in criminal prosecutions.24 in 2003, for the rst time, the federal government sought more surveillance orders under fisa than under ecpa.25as this report is being written (november 2007), changes to the fisa act are being contemplated by the u.s. congress. the nal disposition of these changes remains to be seen.f.4 the privacy actthe privacy act of 1974 provides safeguards against an invasion of privacy through the misuse of records by federal agencies and establishes a broad regulatory framework for the federal government™s use of personal information.26 the act requires federal agencies to store only relevant and necessary personal information and only for purposes required to be accomplished by statute or executive order; to collect information 20 public law 95511, 92 stat. 1783 (1978) (codied at 50 u.s.c. § 18011811).21 50 u.s.c. § 1805(a)(3)(a).22 id. § 1804(7) (prior to being amended in 2001).23 uniting and strengthening america by providing appropriate tools required to intercept and obstruct terrorism act of 2001, public law 10756, § 204, 115 stat. 272 (codied at 50 u.s.c. § 1804(a)(7)(b)).24 in re sealed case, 310 f.3d 717 (fisa review court 2002).25 p.p. swire, ﬁthe system of foreign intelligence surveillance law,ﬂ george washington law review 72(6):13061308, 2004. this article provides analysis of the history and details of fisa generally.26 5 u.s.c. § 552a.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix f 157to the extent possible from the data subject; to maintain records that are accurate, complete, timely, and relevant; and to establish administrative, physical, and technical safeguards to protect the security of records.27 the privacy act also prohibits disclosure, even to other government agencies, of personally identiable information in any record contained in a ﬁsystem of records,ﬂ except pursuant to a written request by or with the written consent of the data subject, or pursuant to a specic exception.28 agencies must log disclosures of records and, in some cases, inform the subjects of such disclosures when they occur. under the act, data subjects must be able to access and copy their records, each agency must establish a procedure for amendment of records, and refusals by agencies to amend their records are subject to judicial review. agencies must publish a notice of the existence, character, and accessibility of their record systems.29 finally, individuals may seek legal redress if an agency denies them access to their records.the privacy act is far less protective of privacy than may rst appear, because of numerous broad exceptions.30 twelve of these are expressly provided for in the act itself. for example, information contained in an agency™s records can be disclosed for ﬁcivil or criminal law enforcement activity if the activity is authorized by law.ﬂ31 an agency can disclose its records to ofcers and employees within the agency itself, the census bureau, the national archives, congress, the comptroller general, and consumer reporting agencies.32 information subject to disclosure under the freedom of information act is exempted from the privacy act.33 and under the ﬁroutine useﬂ exemption,34 federal agencies are permitted to disclose personal information so long as the nature and scope of the routine use was previously published in the federal register and the disclosure of data was ﬁfor a purpose which is compatible with the purpose for which it was collected.ﬂ according to the ofce of management 27 id.28 id. § 552a(b).29 id. § 552a(e)(4).30 s. fogarty and d.r. ortiz, ﬁlimitations upon interagency information sharing: the privacy act of 1974,ﬂ pp. 127128 in protecting america™s freedom in the information age (markle foundation task force on national security in the information age), markle foundation, new york, n.y., 2002.31 5 u.s.c. § 552a (b)(7).32 id. § 552a(b).33 id. § 552a(b)(2).34 id. § 552a(b)(3).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.158 protecting individual privacy in the struggle against terroristsand budget, ﬁcompatibilityﬂ covers uses that are either (1) functionally equivalent or (2) necessary and proper.35moreover, the privacy act applies only to information maintained in a ﬁsystem of records.ﬂ36 the act denes ﬁsystem of recordsﬂ as a ﬁgroup of any records under the control of any agency from which information is retrieved by the name of the individual or by some identifying number, symbol, or other identifying particular assigned to the individual.ﬂ37 the u.s. court of appeals for the district of columbia circuit held that ﬁretrieval capability is not sufcient to create a system of records. . . . ‚to be in a system of records, a record must . . . in practice [be] retrieved by an individual™s name or other personal identier.™ﬂ38 this is unlikely to be the case with new antiterrorism databases, in which information may not be sufciently structured to constitute a ﬁsystem of recordsﬂ in the meaning of the privacy act.the privacy act has also been subject to judicial interpretations which have created new exceptions. for example, courts have found that the following entities do not constitute an ﬁagencyﬂ: a federally chartered production credit association, an individual government employee,39 state and local government agencies,40 the white house ofce and those components of the executive ofce of the president whose sole function is to advise and assist the president,41 grand juries,42 and national banks.43as a result, the privacy act plays little role in providing guidance for government intelligence activities or limiting the government™s power to collect personal data from third parties. moreover, the privacy act only 35 privacy act of 1974, 5 u.s.c. § 552a; ﬁguidance on the privacy act implications of ‚call detail™ programs to manage employees™ use of the government™s telecommunications systems,ﬂ 52 fed. reg. 12900, 12993 (1987) (omb) (publication of guidance in nal form); see generally s. fogarty and d.r. ortiz, ﬁlimitations upon interagency information sharing: the privacy act of 1974,ﬂ pp. 127128 in protecting america™s freedom in the information age (markle foundation task force on national security in the information age), markle foundation, new york, n.y., 2002.36 5 u.s.c. § 552a(b).37 id. § 552a(a)(5).38 henke v. united states department of commerce, 83 f.3d 1453, 1461 (d.c. cir. 1996) (quoting bartel v. faa, 725 f.2d 1403, 1408 n.10 (d.c. cir. 1984)).39 petrus v. bowen, 833 f.2d 581 (5th cir. 1987).40 perezsantos v. malave, 23 fed. app. 11 (1st cir. 2001); ortez v. washington county, 88 f.3d 804 (9th cir. 1996).41 flowers v. executive ofce of the president, 142 f. supp. 2d 38 (d.d.c. 2001).42 standley v. department of justice, 835 f.2d 216 (9th cir. 1987).43 united states v. miller, 643 f.2d 713 (10th cir. 1981). see generally s. fogarty and d.r. ortiz, ﬁlimitations upon interagency information sharing: the privacy act of 1974,ﬂ pp. 127128 in protecting america™s freedom in the information age (markle foundation task force on national security in the information age), markle foundation, new york, n.y., 2002, supra at 128.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix f 159applies to federal agenciesšit does not generally regulate the collection of personal information by privatesector entities. in short, the privacy act provides limited protection when governmentcollected data are involved, and very little when privatesector data are involved.f.5 executive order 12333 (u.s. intelligence activities)promulgated on december 4, 1981, executive order (eo) 12333 regulates the conduct of u.s. intelligence activities.44 section 2.2 of eo 12333 sets forth ﬁcertain general principles that, in addition to and consistent with applicable laws, are intended to achieve the proper balance between the acquisition of essential information and protection of individual interests.ﬂ using a denition of united states person specied in section 3.4(i) of this order (a united states person is ﬁa united states citizen, an alien known by the intelligence agency concerned to be a permanent resident alien, an unincorporated association substantially composed of united states citizens or permanent resident aliens, or a corporation incorporated in the united states, except for a corporation directed and controlled by a foreign government or governmentsﬂ), section 2.3 of eo 12333 establishes constraints on procedures for agencies within the intelligence community (ic) to collect, retain or disseminate information concerning united states persons.under eo 12333, only certain types of information may be collected, retained, or disseminated by ic agencies. these types of information include ﬁinformation that is publicly available or collected with the consent of the person concerned; information constituting foreign intelligence or counterintelligence, including such information concerning corporations or other commercial organizations; information obtained in the course of a lawful foreign intelligence, counterintelligence, international narcotics or international terrorism investigation; information needed to protect the safety of any persons or organizations, including those who are targets, victims or hostages of international terrorist organizations; information needed to protect foreign intelligence or counterintelligence sources or methods from unauthorized disclosure; information concerning persons who are reasonably believed to be potential sources or contacts for the purpose of determining their suitability or credibility; information arising out of a lawful personnel, physical or communications security investigation; information acquired by overhead reconnaissance not directed at specic united states persons; incidentally obtained information that may indicate involvement in activities that may violate 44 the full text of eo 12333 can be found at http://www.tscm.com/eo12333.html.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.160 protecting individual privacy in the struggle against terroristsfederal, state, local or foreign laws; and information necessary for administrative purposes.ﬂunder section 2.4 of eo 12333, ic agencies are required to use the least intrusive collection techniques feasible within the united states or directed against united states persons abroad. in addition, this section places certain limitations on various agencies. for example, the central intelligence agency is forbidden to engage in electronic surveillance within the united states except for the purpose of training, testing, or conducting countermeasures to hostile electronic surveillance. in addition, no ic agency is allowed to conduct ﬁphysical surveillance of a united states person abroad to collect foreign intelligence, except to obtain signicant information that cannot reasonably be acquired by other means.ﬂ (see the full text of the eo for additional restrictions.)f.6 the adequacy of today™s electronic surveillance lawthe law applicable to surveillance and intelligence gathering and the attention to limitations in the law suggests that the law suffers from what professor daniel solove has described as ﬁprofound complexity.ﬂ45 professor orin kerr has written that ﬁthe law of electronic surveillance is famously complex, if not entirely impenetrable.ﬂ46 courts agree with these assessments and have ﬁdescribed surveillance law as caught up in a ‚fog,™ ‚convoluted,™ ‚fraught with trip wires,™ and ‚confusing and uncertain.™ﬂ47why is today™s law regarding electronic surveillance complex? some of the complexity is certainly due to the fact that the situations and circumstances in which electronic surveillance may be involved are highly varied, and policy makers have decided that different situations and situations call for different regulations. that is, different treatment of electronic surveillance in different situations is a consequence of legislative and executive branch policy choices to treat these situations differently.but it is another issue as to whether such differences, noted and established in a one particular set of circumstances, can be effectively maintained over time. first, circumstances evolve. for example, today™s law includes major distinctions based on the location of the surveillance, the purposes for which the intercepted information is sought, and whether 45 d.j. solove, ﬁreconstructing electronic surveillance law,ﬂ george washington law review 72, 2004. the article provides a description and analysis of electronic surveillance law in the united states.46 o.s. kerr, ﬁlifting the ‚fog™ of internet surveillance: how a suppression remedy would change computer crime law,ﬂ hastings law journal 54:805820, 2003.47 d.j. solove, op. cit., p. 1293.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix f 161the target is a ﬁu.s. personﬂ or a ﬁnonu.s. person.ﬂ yet these distinctions are difcult to apply in a world of digital communications and networks that do not easily recognize national borders, terrorist threats of foreign origin that are planned or executed within the borders of the united states, and the growing integration of foreign intelligence, domestic intelligence, and law enforcement.another important distinction is the historical separation between criminal and national security investigations. since september 11, 2001, some of the barriers separating criminal and national security investigations have been lowered (for example, the government is now freer to share information gathered by law enforcement in criminal investigations with national security authorities, and vice versa). however, the ecpa and the fisa are based on the existence of clear distinctions between criminal and national security investigations, as re˚ected in their disparate treatment of information that is collected and stored under each regime.second, evolving technologies also complicate the application of laws and precedents created in an earlier technological era, and at times existing law seems outpaced by technological change. in 2004, the department of defense technology and privacy advisory committee (tapac) wrote in its nal report:laws regulating the collection and use of information about u.s. persons are often not merely disjointed, but outdated. many date from the 1970s, and therefore fail to address extraordinary developments in digital technologies, including the internet. . . . dramatic advances in information technology, however, have greatly increased the government™s ability to access data from diverse sources, including commercial and transactional databases. . . .. . . current laws are often inadequate to address the new and difcult challenges presented by dramatic developments in information technologies. and that inadequacy will only become more acute as the store of digital data and the ability to search it continue to expand dramatically in the future.48as an example, the ecpa draws a sharp distinction regarding whether a message is ﬁin transitﬂ or ﬁin storage.ﬂ when ecpa was adopted in 1986, users downloaded email from their service provider onto their local computer. messages therefore were not stored centrally after being read. today, many email systems are accessed through web interfaces, so email is by default stored on servers belonging to third parties. thus, according to an analysis by the center for democracy and technology, ﬁas a result of ecpa™s complex rules, the same email mes48 u.s. department of defense, technology and privacy advisory committee, safeguarding privacy in the fight against terrorism, march 2004, p. 6.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.162 protecting individual privacy in the struggle against terroristssage will be subject to many different rules during its life span. these complex rules likely do not match the expectations of email users.ﬂ49the government exploits such distinctions. the federal bureau of investigation™s key logger system, which records individuals™ keystrokes on their computers, was designed to collect data only when the users™ machines are not connected to the internet. when a user logs on, the keystroke recording stops, so that the agency argues that the device is not capturing communications ﬁin transit,ﬂ but merely ﬁin storage,ﬂ and therefore is not required to comply with title i of the ecpa.50a second example is that when the statutory authorization was adopted for the national security agency (nsa) to carry out electronic surveillance outside of the united states, it was highly unusual for ordinary persons in the u.s. to make international phone calls, and email did not yet exist.51 today, the proliferation of information technology into the population at large means that many ordinary people in the u.s. make international phone calls and use email, with the result that many more communications of ordinary people are potentially subject to nsa surveillance.52 to be sure, a variety of regulations exist to prevent just such occurrences from intruding on the privacy of ordinary americans, but it is undeniable that more communications involving americans will fall within the ambit of electronic surveillance directed outside u.s. borders as global communications increase.third, the law today embeds in some signicant inconsistencies. for example, the very high protection for communications under title i of ecpa does not extend to video surveillance if sounds are not captured at the same time. meanwhile, the much weaker protection of fisa does apply. ﬁforeign agents therefore receive protection against silent video surveillance whereas united states citizens do not.ﬂ53 similarly, protection for stored communications hinges on whether the message has been stored for more than 180 days. why? telephone calls and email receive signicantly different protection from government surveillance without any apparent reason.fourth, key intelligence questions remain without clear answers. for example, do any of these laws apply to ﬁdata miningﬂ or searches for keywords or relationships conducted by computer? is it possible to show 49 center for democracy and technology (cdt), digital search & seizure: updating privacy protections to keep pace with technology, cdt, washington, d.c., 2006, p. 11.50 see united states v. scarfo, 180 f. supp. 2d 572 (d.n.j. 2001); see generally d.j. solove, op. cit., pp. 12811282.51 center for democracy and technology (cdt), digital search and seizure: updating privacy protections to keep pace with technology, cdt, washington, d.c., 2006.52 ibid.53 d.j. solove, op. cit., p. 1293.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix f 163probable cause, under either the high standard of title i of ecpa or the weaker standard of fisa, for searches that target a pattern of behavior rather than an identied person? how should opened email and voice mail messages be treated? doj argues that they are merely remotely stored les and therefore do not fall within the protection of title ii of ecpa.54 why aren™t they simply stored communications that are directly covered by title ii (the stored communications act)?55finally, the slow pace at which law has evolved in the face of changing technologies may have done more to undermine rather than enhance trust in information sharing. the supreme court initially refused to apply the fourth amendment to wiretapping at all,56 and it took the court 39 years to reverse that decision.57 conversely, in 1934 congress prohibited wiretapping in any form and for any purpose.58 it took 34 years before congress recognized the potential of electronic surveillance, properly regulated, to aid law enforcement,59 and another twelve before it statutorily authorized its use to advance national security.60 congress also receives only limited information about surveillance conducted under ecpa and fisa, and even less about the administration™s surveillance conducted outside of this statutory framework. there is no federal reporting requirement about electronic surveillance by states, which account for the majority of wiretaps, and only half of the states in fact report statistics about their wiretap orders.6154 computer crime and intellectual property section, u.s. department of justice, manual on searching and seizing computers and obtaining electronic evidence in criminal investigations iii.b, 2001.55 for more detailed analyses of gaps and inconsistencies in statutory and fourth amendment protections, see p.l. bellia, ﬁsurveillance law through cyberlaw™s lens,ﬂ george washington law review 72:1375, 2004; d.k. mulligan, ﬁreasonable expectations in electronic communications: a critical perspective on the electronic communications privacy act,ﬂ george washington law review 72:1557, 2004; d.j. solove, ﬁreconstructing electronic surveillance law,ﬂ george washington law review 72:1264, 2004; p.p. swire, ﬁthe system of foreign intelligence surveillance law,ﬂ george washington law review 72:1306, 2004; o.s. kerr, ﬁinternet surveillance law after the usa patriot act: the big brother that isn™t,ﬂ northwestern university law review 97(2):607673, 2003; o.s. kerr, ﬁlifting the ‚fog™ of internet surveillance: how a suppression remedy would change computer crime law,ﬂ hastings law journal 54:805820, 2003.56 olmstead v. united states, 277 u.s. 438 (1928).57 united states v. katz, 389 u.s. 347 (1967).58 communications act of 1934, ch. 652, § 605, 48 stat. 1064 (codied as amended at 47 u.s.c. § 605).59 omnibus crime control and safe streets act of 1968, public law 90351, § 802, 82 stat. 212 (codied as amended at 18 u.s.c. § 25102520).60 foreign intelligence surveillance act of 1978, public law 95511, 92 stat. 1783 (codied at 50 u.s.c. § 18011811).61 d.j. solove, op. cit., p. 1296.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.164 protecting individual privacy in the struggle against terroristswhat does the analysis above imply for changing today™s law regarding electronic surveillance? there is broad agreement that today™s legal regime is not optimally aligned with the technological and circumstantial realities of the present. but there is profound disagreement both about whether the basic principles underlying today™s regime continue to be sound and about the directions in which changes to today™s regime ought to occur. some analysts believe that the privacy has suffered as the result of an increasing gap between technology/circumstances and the more slowly changing law, while others believe that technological change is upsetting the traditional balance away from the legitimate needs of law enforcement and national security.f.7 further reflections from the technology and privacy advisory committee reportmany of the issues discussed above were also ˚agged in the report issued by the tapac, a bipartisan panel of independent legal experts and former government ofcials appointed by secretary of defense donald rumsfeld in the wake of the tia [total/terrorist information awareness program; see appendix j] debacle. for example, the report noted that the risks to informational privacy of government data mining efforts were exacerbated by disjointedness in the laws applicable to data mining. thus, programs that appear to pose similar privacy risks are subject to a variety of often inconsistent legal requirements. such inconsistencies, the report argued, re˚ected ﬁthe historical divide in the united states between laws applicable to law enforcement and those applicable to foreign intelligence and national security activities, as well as the different departments, contexts, and times in which those programs were developed.ﬂit also noted that depending on which department developed the tools, the use of data mining to protect the homeland was either required or prohibited and that today™s laws regulating the collection and use of information about u.s. persons were created in the 1970s, and thus do not take into account recent developments in digital technologies, including the internet. pointing out that ﬁthe ubiquity of information networks and digital data has created new opportunities for tracking terrorists and preventing attacks,ﬂ the report argued that ﬁnew technologies [also] allow the government to engage in data mining with a far greater volume and variety of data concerning u.s. persons, about whom the government has no suspicions, in the quest for information about potential terrorists or other criminalsﬂ and that thencurrent laws were ﬁoften inadequate to address the new and difcult challenges presented by dramatic developments in information technologies.ﬂprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix f 165the tapac report concludes that ﬁ[t]hese developments highlight the need for new regulatory boundaries to help protect civil liberties and national security, and to help empower those responsible for defending our nation to use advanced information technologiesšincluding data mining appropriately and effectively. it is time to update the law to respond to new challenges.ﬂ6262 u.s. department of defense, technology and privacy advisory committee, safeguarding privacy in the fight against terrorism, march 2004, p. ix.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.166gthe jurisprudence of privacy law and the need for independent oversightprivacy protection rules regulating law enforcement and national security use of personal information can be usefully understood in two distinct categories: rst, substantive rules that limit access to and usage of private information and, second, procedural rules that provide safeguards to encourage compliance and ensure accountability for compliance failures.neither the constitution nor any statute can anticipate in advance every particular privacy issue raised by future technologies. so the evolving balance between the government™s need to intrude on the private lives of individuals in the service of its public safety mission and the requirement to maintain individual liberty has been maintained over time by providing a degree of transparency in the use of new technologies, along with accountability to rules assured by judicial and legislative oversight. as new technologies and investigative techniques come into use, courts and legislatures have the opportunity to review these advances and make assessments of their privacy impact, guided by constitutional and public policy foundations. when new privacy risks arise or when the government powers are judged to have been extended beyond the boundaries established through the democratic process, corrective action can be taken. in order for this dynamic equilibrium of privacy and public safety to be maintained, however, transparency of the investigative process and accountability to the rule of law are essential. this appendix presents both the substantive constitutional foundations of privacy rights necessary for evaluating new technology, along with a consideration of transparency, protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix g 167accountability, and oversight mechanisms necessary to keep counterterrorism activities within view of the democratic process.g.1 substantive privacy rulesin general, substantive privacy rules involve restrictions on access to and use of personal information by the government. such restrictions are a means of limiting the power of government and privatesector institutions. for example, in the spirit of the bedrock constitutional principle of limited government, the fourth amendment denes limits on government power by establishing individual rights against certain intrusions. it protects privacy not only because americans value individual liberty as an end in and of itself, but also because their collective political, cultural, and social ˚ourishing depends on it. to this end, privacy protections generally take the form of boundaries between individuals and institutions (or sometimes other individuals). these boundaries may limit the information that is collected (in the case of wiretapping or other types of surveillance), how that information is handled (the fair information practices that seek care and openness in the management of personal information described in box g.1), or rules governing the ultimate use of information (such as prohibitions on the use of certain health information for making employment decisions).today, a variety of new technologies put pressure on existing boundaries between individuals and large institutions. new surveillance and analysis technologies used in the service of counterterrorism goals are effective precisely because they give investigators new capabilities that erode the boundaries previously established between individuals and governments. for example, data mining techniques operating over large collections of information, each element of which is not particularly revealing, may yield detailed proles of individuals, and locationaware sensor networks allow collection of tracking information on large numbers of individuals when most of them are not actually suspected of any crime at the time of data collection. new identication documents (including driver™s licenses and passports) will collect biometric information in digital form on most of the population, marking the rst time the digital images of the faces of the population will be available for law enforcement use. all of these technologies are susceptible to a wide variety of different uses, with widely varying intrusiveness.g.1.1 privacy challenges posed by advanced surveillance and data miningmany of the privacy questions facing the information age society are protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.168 protecting individual privacy in the struggle against terroristsbox g.1 fair information practices fair information practices are standards of practice required to ensure that entities that collect and use personal information provide adequate privacy protection for that information. these practices include notice to and awareness of individuals with personal information that such information is being collected, providing them with choices about how their personal information may be used, enabling them to review the data collected about them in a timely and inexpensive way and to contest that data™s accuracy and completeness, taking steps to ensure that their personal information is accurate and secure, and providing them with mechanisms for redress if these principles are violated. fair information practices were rst articulated in a comprehensive manner in the u.s. department of health, education and welfare™s 1973 report records, computers and the rights of citizens.1 this report was the rst to introduce the code of fair information practices, which has proven in˚uential in subsequent years in shaping the information practices of numerous private and governmental institutions and is still well accepted as the gold standard for privacy protection.2 from their origin in 1973, fair information practices ﬁbecame the dominant u.s. approach to information privacy protection for the next three decades.ﬂ3 their ve principles not only became the common thread running through various bits of sectoral regulation developed in the united states, but also they were reproduced, with signicant extension, in the guidelines developed by the organization for economic cooperation and development (oecd). these principles are extended in the oecd guidelines, which govern ﬁthe protection of privacy and transborder ˚ows of personal dataﬂ and include eight principles that have come to be understood as ﬁminimum standards . . . for the protection of privacy and individual liberties.ﬂ4 the oecd guidelines also include a statement about the degree to which data controllers should be accountable for their actions. this generally means that there are costs associated with the failure of a data manager to enable the realization of these principles.1 u.s. department of health, education, and welfare, records, computers and the rights of citizens, report of the secretary™s advisory committee on automated personal data systems, mit press, cambridge, mass., 1973.2 fair information principles are a staple of the privacy literature. see, for example, the extended discussion of these principles in d. solove, m. rotenberg, and p. schwartz, information privacy law, aspen publishers, new york n.y., 2006; a. westin, ﬁsocial and political dimensions of privacy,ﬂ journal of social issues 59(2):431453, 2003; h. nissenbaum, ﬁprivacy as contextual integrity,ﬂ washington law review 79(1):119158, february 2004; and an extended discussion and critique in r. clarke, ﬁbeyond the oecd guidelines: privacy protection for the 21st century,ﬂ available at http://www.anu.edu.au/people/roger.clarke/dv/pp21c.html.3 a. westin, ﬁsocial and political dimensions of privacy,ﬂ journal of social issues 59(2):431453, 2003, p. 436.4 m. rotenberg, the privacy law sourcebook 2001, electronic privacy information center, washington, d.c., 2001, pp. 270272.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix g 1695 see http://www.ftc.gov/reports/privacy3/fairinfo.htm.source: national research council, engaging privacy and information technology in an information age, j. waldo, h.s. lin, and l. millett, eds., the national academies press, washington, d.c., 2007. as enunciated by the u.s. federal trade commission (other formulations of fair information practices also exist),5 the ve principles of fair information practice include: ł notice and awareness. secret record systems should not exist. individuals whose personal information is collected should be given notice of a collector™s information practices before any personal information is collected and should be told that personal information is being collected about them. without notice, an individual cannot make an informed decision as to whether and to what extent to disclose personal information. notice should be given about the identity of the party collecting the data; how the data will be used and the potential recipients of the data; the nature of the data collected and the means by which it is collected; whether the individual may decline to provide the requested data and the consequences of a refusal to provide the requested information; and the steps taken by the collector to ensure the condentiality, integrity, and quality of the data. ł choice and consent. individuals should be able to choose how personal information collected from them may be used, and in particular how it can be used in ways that go beyond those necessary to complete a transaction at hand. such secondary uses can be internal to the collector™s organization, or they can result in the transfer of the information to third parties. note that genuinely informed consent is a sine qua non for observation of this principle. individuals who provide personal information under duress or threat of penalty have not provided informed consentšand individuals who provide personal information as a requirement for receiving necessary or desirable services from monopoly providers of services have not, either. ł access and participation. individuals should be able to review in a timely and inexpensive way the data collected about them and to similarly contest those data™s accuracy and completeness. thus, means should be available to correct errors or, at the very least, to append notes of explanation or challenges that would accompany subsequent distributions of this information. ł integrity and security. the personal information of individuals must be accurate and secure. to ensure data integrity, collectors must take reasonable steps, such as using only reputable sources of data and crossreferencing data against multiple sources, providing consumer access to data, and destroying untimely data or converting it to anonymous form. to provide security, collectors must take both procedural and technical measures to protect against loss and the unauthorized access, destruction, use, or disclosure of the data. ł enforcement and redress. enforcement mechanisms must exist to ensure that the fair information principles are observed in practice, and individuals must have redress mechanisms available to them if these principles are violated.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.170 protecting individual privacy in the struggle against terroristsboth challenging as a matter of public policy and difcult because they seem to call into question the adequacy of much of existing privacy law. a strong constitutional foundation constrains government actions and policies: the fourth amendment guarantee against unreasonable search and seizure. although the u.s. supreme court has rejected the idea that the fourth amendment protects a general right to privacy, the amendment does create boundaries between the citizen and the powers of the state in certain domains. in the words of the court,1[t]he fourth amendment cannot be translated into a general constitutional ﬁright to privacy.ﬂ that amendment protects individual privacy against certain kinds of governmental intrusion, but its protections go further, and often have nothing to do with privacy at all. other provisions of the constitution protect personal privacy from other forms of governmental invasion. but the protection of a person™s general right to privacyšhis right to be let alone by other peoplešis, like the protection of his property and of his very life, left largely to the law of the individual states.yet the court™s interpretation of what types of intrusions raise constitutional questions has been ˚exible over time, re˚ecting the underlying values of the fourth amendment. in katz and subsequent cases, the court rejected the idea that rights conferred by the fourth amendment are determined by xed physical or technical boundaries. as the court explained:[t]he fourth amendment protects people, not places. what a person knowingly exposes to the public, even in his own home or ofce, is not a subject of fourth amendment protection. see lewis v. united states, 385 u.s. 206, 210; united states v. lee, 274 u.s. 559, 563. but what he seeks to preserve as private, even in an area accessible to the public, may be constitutionally protected.the actual boundaries of the fourth amendment have changed over time, shaped by changing technological capabilities, social attitudes, government activities, and supreme court justices, as indicated by a series of supreme court decisions in the past century. the nature of this evolution, driven both by judicial intervention and legislative action, demonstrates an ongoing and vital role for policy makers and jurists to ensure that the values re˚ected in the fourth amendment are kept alive in the face of new technologies.whether a government activity is permissible under the fourth amendment is determined by the answer to two basic questions: (1) is the action a ﬁsearchﬂ within the meaning of the constitution and (2) if it is a 1 katz v. united states, 389 u.s. 347 (1967).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix g 171search, is it ﬁreasonable.ﬂ a government action is considered a search if it crosses into some recognized private interest. what constitutes a private domain is sometimes easy to determine based on history and culture, the canonical one being a person™s private home. but a dependence on history implies that there is no xed denition of ﬁprivate domain,ﬂ and thus it falls to statutory law, judicial action, and executive branch action to protect privacy within whatever denition of private domain has been dened at the time.as an example of how constitutional jurisprudence and statutory law have interacted to strike a balance between the protection of privacy and the legitimate needs of law enforcement, consider the legal framework surrounding telephone wiretaps. this framework requires communications carriers to provide law enforcement agencies (lea) with lawful intercepts (li) (e.g., wiretaps) on specic telephones under specic conditions once the appropriate warrants or subpoenas have been issued and presented. li laws require that wiretaps be very specicšfor an ongoing investigation, for a specic subject (individual), and often for a specic form of communications, such as a wireline telephone and for a specic telephone number.while some may have an image of a detective sitting in a smoky hotel room listening to a call via a wire tapped to a phone in an adjacent room, modern li or electronic eavesdropping is automated as an integral part of the telecommunications infrastructure. when a law enforcement agency provides a communications carrier with a warrant for a specic lawful intercept, the communications carrier is obligated to intercept the content of specic communications and deliver them to the agency. typically, this involves routing calls to a location designated by the law enforcement agency, where the information is captured and stored for later analysis using technologies designed for communications surveillance and analysis.the rst step in establishing today™s legal framework was the katz decision of the supreme court in 1967. in that decision, the court found that a person in a telephone booth had a reasonable expectation of privacy and thus the content of phone conversations in the booth was entitled to the protections of the fourth amendment. in response to this decision, congress passed the 1968 wiretap act (now known as title iii).strictly speaking, katz v. united states addressed only the issue of whether the fourth amendment applied to telephone conversations held in a public telephone booth.2 but the wiretap act imposed requirements on law enforcement ofcials to obtain warrants for wiretaps on conversa2 under previous precedent and law, warrants were required in order to tap phone conversations held in private residences.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.172 protecting individual privacy in the struggle against terroriststions regardless of where they were being held, and it laid out a variety of conditions that had to be met for a warrant to be issuedšconditions that were not stipulated in the katz decision.since the wiretap act was passed, congress has enacted many laws governing lawful intercepts, including the communications assistance for law enforcement act of 1994 (calea), the pen register/trap and trace provisions of title 18; and the interception and pen/trap provisions of the foreign intelligence surveillance act, title 50 u.s.c. sections 18011845 (fisa). these laws have a historical context that re˚ects technology prevalent when the laws were written, and they were sometimes passed in response to a new supreme court decision or public demands for greater privacy acted on by the legislature.g.1.2 evolution of regulation of new technologiesnew technologies often pose challenges for courts and policy makers in deciding whether the surveillance power made available constitutes a permissible intrusion on a private interest.table g.1 illustrates the ways in which the law of electronic surveillance has evolved privacy protections over time. for example, early wiretapping was found not to violate the fourth amendment in 1928, but when the supreme court considered the question of telephone surveillance again in 1967, it reversed itself and found that citizens™ reasonable expectation of privacy in private telephone calls meant that surveillance of telephone calls could be done only with a judicially approved warrant and ongoing supervision of a ﬁdetached, neutral magistrate.ﬂ as reliance on new communications technologies continued, congress stepped in to establish basic privacy protections and provisions for law enforcement access to electronic mail. in an important instance of proactive legislative action determined to be necessary to provide stable privacy protection for a new electronic communications medium, congress acted on the belief that ﬁthe law must advance with the technology to ensure the continued vitality of the fourth amendment.ﬂ3with the advent of the world wide web, congressional action extended privacy protections to web and email access transaction logs, along with clear procedures for legitimate law enforcement access with judicial supervision.a more recent consideration of a new technologyšuse of infrared scanning of a person™s home for the purpose of detecting highheat plant grow lights (indicating a possible indoor marijuana farm)šwas found to 3 senate judiciary committee report on the electronic communications privacy act of 1986 (s. 2575), report 99541, 99th congress, 2d session, 1986, p. 5.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix g 173table g.1 historical evolution of regulation of electronic surveillancecommunications technologylawregulatory approach1890stelegraphstate wiretapping crimescriminal prohibition1934telephonecommunications act of 1934criminal prohibition and inadmissibility of evidence1967telephone and bugging equipmentfourth amendmentinadmissibility of evidence and civil liability1968telephone and bugging equipmentwiretap actcriminal prohibition, civil liability, and inadmissibility1978telephone and bugging equipmentforeign intelligence surveillance actcriminal prohibition, civil liability, and inadmissibility1986email and internet communicationselectronic communications privacy actcriminal prohibition and civil liability2001telephone and internetusa patriot actcriminal prohibition and civil liabilitybe a violation of the fourth amendment. justice antonin scalia found4 that this transgressed the inviolability of the home, even though the police ofcers using the infrared detector did not actually enter the person™s home.still another issue arising recently is the changing relevance of political boundaries to communications. previous communications technologies and the laws that addressed them often re˚ected political boundaries. in today™s communications technologies, political boundaries may be impossible to determine. this is signicant, since a signicant portion of the world™s communications trafc is routed through u.s. switches, raising questions on the propriety of electronic eavesdropping on communications whose origins and destinations cannot be determined. in this case, recent legislation addresses this point,5 allowing the warrant4 ﬁat the very core of the fourth amendment stands the right of a man to retreat into his own home and there be free from unreasonable governmental intrusion. with few exceptions, the question whether a warrantless search of a home is reasonable and hence constitutional must be answered no.ﬂ (kyllo, scalia for the court, internal quotation marks and citations omitted) kyllo v. united states. 533 u.s. 27 (2001) (scalia, j.).5 protect america act of 2007, public law 11055, august 5, 2007.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.174 protecting individual privacy in the struggle against terroristsless monitoring of communications that pass through the united states as long as both parties to the communications are reasonably believed to be located outside it.as the above examples illustrate, the regulation of new technologies is affected by both by the evolution of the supreme court™s fourth amendment jurisprudence on what constitutes a search and by policy choices within those boundaries made by the legislative and executive branches. supreme court jurisprudence on this point has evolved to limit government intrusion into certain ﬁprotected areasﬂ because the founding fathers could not have anticipated the current and forthcoming advances in technology and practices. furthermore, legislative and executive branch policy makers have expanded the scope of protections to ensure that constitutional values of limited government and protection of individual liberty are protected notwithstanding technological advances.legal analysts have a variety of views on whether regulation of new technologies should be driven by policy decisions or by the fourth amendment. for example, one view is that legislatures have considerable institutional advantages that enable the legislative privacy rules regulating new technologies to be more balanced, comprehensive, and effective than judicially created rules, and that the courts should adopt only modest formulations of fourth amendment protections in deference to these advantages.6 another view is that constitutionally derived protections of privacy in the face of new technologies are, by denition, more enduring and thus less subject to the often poorly justied actions of legislatures and executives, who may be acting in the heat of the moment after a terrorist incident.7 of course, in practice, regulation of new technologies has been in˚uenced by both policy decisions and the fourth amendment.it would be a mistake to infer from this brief history that every new surveillance technology is greeted automatically by courts and legislatures with a xed, linear expansion of privacy protection. in some cases, long periods of time go by before a given technology receives clear privacy consideration. and it is certainly not possible to establish a priori clear measures of how much privacy protection ought to be brought to bear on new surveillance capabilities. what this history reveals is that careful consideration of the privacy impact of new surveillance powers has generally resulted in a measure of privacy protection that gives citizens condence, while at the same time preserving apparently adequate 6 see o.s. kerr, ﬁthe fourth amendment and new technologies: constitutional myths and the case for caution,ﬂ michigan law review 102(5):801888, 2004.7 see, for example, p.m. regan, legislating privacy: technology, social values, and public policy, university of north carolina press, chapel hill, n.c., 1995, pp. 221227.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix g 175access to data for law enforcement engaged in legitimate investigative activity.g.1.3 new surveillance techniques that raise privacy questions unaddressed by constitutional or statutory privacy rulesa number of the government counterterrorism investigative techniques with real privacy implications are likely to fall outside the boundary of what the supreme court today considers to be a search. inasmuch as all levels of government are now seeking to use the most advanced, effective technologies to detect and apprehend terrorist threats, it is not surprising that many of these new technologies and techniques will have intrusive power not previously considered by either courts or legislators. the committee heard considerable testimony on the use of data mining for the purpose of identifying potential terrorist behavior. in many cases, the bulk of the information used in such data mining operations is collected from commercial data vendors and public records, such as property records, voting rolls, and other local and state databases. access to these data is available with little or no privacy protection and little or no thirdparty supervision.8 furthermore, while data mining activity may be subject to procedural regulation under the federal privacy act (see appendix f), it is not subject to any substantive statutory limitations whatsoever. it will be up to congress to consider the appropriate limits on the use of data mining and other new privacyinvasive techniques.g.1.4 new approaches to privacy protection: collection limitation versus use limitationthere is growing agreement that regulation of largescale analysis of personal information, such as data mining, will have to rely on usage limitations rather than merely collection limitations.9 historically, privacy 8 see smith v. maryland, 442 u.s. 735 (1979) (nding no reasonable expectation of privacy transactional records of phone numbers dialed because they were ﬁdisclosedﬂ voluntarily and duly recorded by the phone company in the ordinary course of business); and united states v. miller, 425 u.s. 435 (1976) (nding no fourth amendment interest in banking records, since they are not condential communications and are voluntarily presented to the bank). see also j.x. dempsey and l.m. flint, ﬁcommercial data and national security,ﬂ george washington law review 72(6):6, august 2004.9 see the reports from the markle foundation task force on national security in the information age: mobilizing information to prevent terrorism: accelerating development of a trusted information sharing environment, 3rd report, july 13, 2006; creating a trusted network for homeland security, 2nd report, december 2, 2003; and protecting america™s freedom in the information age, 1st report, october 7, 2002. available at http://www.markletaskforce.org/ [11/7/07].protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.176 protecting individual privacy in the struggle against terroristsagainst government intrusion has been protected by limiting what information the government can collect: voice conversations collected through wiretapping, email collected through legally authorized access to stored data, etc. but today, as the data mining discussion in appendix h illustrates, the greatest potential for privacy intrusion may come from analysis of data that are accessible to government investigators with little or no restriction and little or no oversight. the result is that powerful investigative techniques with signicant privacy impact proceed in full compliance with existing law, but with signicant unanswered privacy questions and associated concerns about data quality. however, attempts to limit collection of or access to the data that feed data mining activities may create signicant burdens on legitimate investigative activity without producing any real privacy benet. in many cases, the data in question have already been collected and access to them, under the thirdparty business records doctrine, will be readily granted with few strings attached.the privacy impact of new analytic techniques that merit regulation is not access to any individual element of personal information, but rather to the overall use of a large quantity of individually innocuous items of personal information. as the debate over airline passenger screening systems has shown,10 the main objections to proposed proling systems are in the potential for ﬁmission creepﬂ and the risk of inaccurate data being used against innocent citizens.the challenge before policy makers is how to craft appropriate privacy regulation that achieves the historic but dynamic balance between privacy protection and important public safety priorities. establishing clear usage limitations along with traditional procedural oversight safeguards on new data analysis techniquesšincluding but not limited to data miningšwould ensure that the most powerful new investigative techniques are available against the serious threats to national security. at the same time, given the substantial new and untested power that these techniques could confer on domestic law enforcement, their use in the nonnational security arena would be limited.g.2 procedural privacy rules and the need for oversightthe establishment of law and regulation in any given domain is an articulation of public concerns and values in that domain. but if law and 10 see department of homeland security, notice to establish system of records, secure flight test records, 69 fed. reg. 57,345 (sept. 24, 2004), available at http://edocket.access.gpo.gov/2004/0421479.htm, and comments (link to criticism publications available at http://www.epic.org/privacy/airtravel/secure˚ight.html).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix g 177regulation are to have any substantive or tangible impact on behavior, mechanisms are necessary for ensuring that the targets of such law and regulation behave accordingly.in the context of the fourth amendment, such mechanisms are provided through thirdparty review of government intrusions on private domains. when properly implemented, such mechanisms provide a signicant measure of accountability to ensure that these intrusions are not abused.g.2.1 oversight mechanisms of the u.s. governmentthe u.s. government is based on a threeway system of internal checks and balances that was designed to limit power and ensure reviews across the executive, legislative, and judicial branches. for example, the president nominates supreme court and circuit and district court judges and the congress votes to conrm them. the president also proposes budgets, which congress must approve. for national security issues, the federal bureau of investigations (fbi) conducts investigations inside the united states that are subject to oversight by the federal intelligence security court (established by the foreign intelligence surveillance act).11 in addition, congress oversees the activities of the department of justice, which is responsible for the fbi.12congressional oversight of executive branch departments and agencies are especially potent and controversial because congressional committees have the power of subpoena and they control budget allocations. in addition, congressional committee meetings generate intense press and public interest, especially when they are investigating failures, corruption, or other malfeasance. this form of oversight, called ﬁghting res,ﬂ is contrasted with scheduled regular reviews, called ﬁpatrolling streets.ﬂ13some politicians are attracted to ghting res because of the high visibility, but the patrolling streets model can be successful in preventing 11 j. berman and l. flint, ﬁguiding lights: intelligence oversight and control for the challenge of terrorism,ﬂ criminal justice ethics, winter/spring 2003. available at http://www.cdt.org/publications/030300guidinglights.pdf [11/7/07].12 c.j. bennett and c.d. raab, the governance of privacy: policy instruments in global perspective. mit press, cambridge, mass., 2006.13 m.d. mccubbins and t. schwartz, ﬁcongressional oversight overlooked: police patrols versus re alarms,ﬂ american journal of political science 28(1):165179, february 1984; a. lupia and m.d. mccubbins, ﬁdesigning bureaucratic accountability,ﬂ law and contemporary problems 57(1):91126, 1994; a. lupia and m.d. mccubbins, ﬁlearning from oversight: fire alarms and police patrols reconstructed,ﬂ journal of law, economics and organization 10(1):96125, 1994; and h. hopenhayn and s. lohmann, ﬁfirealarm signals and the political oversight of regulatory agencies,ﬂ journal of law, economics and organization 12(1):196213, 1996.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.178 protecting individual privacy in the struggle against terroristsproblems, although it takes more effort. critics of congressional oversight suggest that at times members may not be sufciently informed to ask the right questions or appreciate the complexities of the agencies they review.executive branch agencies often create independent oversight boards to review internal activities so as to improve performance and generate public trust. examples include the national aeronautic and space administration™s shuttle oversight board,14 the department of energy™s performance assurance program independent oversight,15 the food and drug administration™s (fda) drug safety board,16 and the nuclear regulatory commission™s oversight committee.17 in addition, agencies often have internal oversight committees and inspectors general who monitor compliance with policy.the judicial branch is often the arbiter of government claims that invasions of individual privacy are needed to advance other national interests. for example, warrants that allow physical searches and orders that allow wiretapping are often issued by the judicial branch upon the showing of probable cause. in this way, the courts handle many cases of potential privacy violations by federal, state, and local police or other government agencies.federal agencies also conduct oversight of parts of the commercial sector to ensure adherence to legal requirements and consumer protection. examples include the federal reserve™s regulation of banking practices and the fda™s work on pharmaceutical testing and production. government agencies can also be the source of trusted investigations, such as the work of the national transportation safety board in studying plane crashes.other mechanisms to detect problems in government and other organizations are sometimes applied. some organizations include ombudsmen whose role is to constantly review practices and respond to internal or external concerns. another strategy that has legal protection in u.s. is whistleblowing. government employees who report illegal or improper 14 see nasa, standing review board handbook, august 1, 2007; available at http://fpd.gsfc.nasa.gov/npr71205d/srbhandbook.pdf.15 see u.s. department of energy, independent oversight and performance assurance program, doe o 470.2b, october 31, 2002; available at http://hss.energy.gov/indepoversight/ guidedocs/o4702b/4702b.html.16 see information on the food and drug administration™s drug safety oversight board at u.s. food and drug administration, ﬁfda improvements in drug safety monitoring,ﬂ fda fact sheet, february 15, 2005; available at http://www.fda.gov/oc/factsheets/drugsafety.html.17 u.s. senate, committee on environment and public works, subcommittee on clean air and nuclear safety.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix g 179activity are protected by several laws, especially the whistleblower protection act (5 u.s.c. § 1221(e)).these mechanisms for oversight vary in the extent to which they are (and are perceived to be) independent. independence (along with the necessary authority) is a key dimension of oversight because of the suspicionšoften warrantedšthat oversight controlled or in˚uenced by the entity being overseen is not meaningful and that problems revealed by nonindependent oversight will be concealed or improperly minimized. independent oversight mechanisms also generally have greater ability to bring fresh and unbiased perspectives to an organization that is caught up in its daytoday work.g.2.2 a framework for independent oversightthe rich variety of independent oversight strategies makes it difcult to compare them and recognize missing features. a framework for understanding the organizational structures and operating methods would therefore help identify best practices and sources of successful outcomes. some clarity can be gained by taking a ﬁwho, when, how, whatﬂ approach, as described by these components:who: ensure independence.when: choose time for review.how: set power to investigate.what: raise impact of results.administrators will need to tune the process to t each situation, but these components can serve as a starting point. first, some denitions: the independent oversight board members are referred to as members, and their goal is to review the operation of an organization led by administrators who supervise employees.ensure independenceattaining the right level of independence means that the independent oversight board members are distant enough from the organization and employees so that their judgments are free from personal sympathy, coercion, bias, or con˚icts of interest. however, they need to be close enough to be familiar with the organization and its operation. members need to be knowledgeable about the domain of work and experienced at doing reviews of other organizations. in corporate audits, the independent accounting rms have helpful expertise in that they review multiple corporations, so they are familiar with standard and risky practices in protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.180 protecting individual privacy in the struggle against terroristseach industry. many analysts believe that the fraudulent business practices that led to the collapse of enron could have been ˚agged by its accounting rm, arthur anderson, but they failed to do so because of their lack of independence.independent oversight board members should be trusted individuals whose credibility is also respected because of their career accomplishments. in addition to distance, experience, trust, and credibility, another issue tied to independence is transparency. while some activities may need to be kept private, the process should be visible enough.match nature of review to appropriate stage in event trajectoryoversight typically occurs at three points: before, during, and after some activity. these forms of oversight can be regarded as relevant to planning (approval of a proposed activity), execution (monitoring of activity while it is happening), and retrospective review (review of a completed activity) (see figure g.1.)ł planning oversight occurs when a specic activity has been planned but before any work begins. for example, the fisa court reviews approximately 2,000 plans for surveillance by the fbi each year; rejections are extremely rare. another government example is the defense base closure and realignment commission, which reviews department of defense decisions. academic examples include the approval of plans for medical experiments by institutional review boards. planning oversight also includes review boards that are convened to help make critical decisions, such as the launch of national aeronautics and space administration missions, the opening of natural preserves to oil drilling, or acceptance of papers for publication in scientic journals.figure g.1 planning oversight is a check on plans, execution oversight is continuous review, and retrospective oversight reviews past performance.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix g 181ł execution oversight is the continuous oversight (patrolling streets) of a process, such as meat packing, pharmaceutical manufacture, or banking. such processes can be laborintensive and boring but require continuous vigilance. independence is a challenge in these circumstances, since the oversight members may work closely with employees on a daily basis, thereby becoming personally familiar with them. the federal reserve board has strict rules about personal contacts of its regulators with bank employees.ł retrospective oversight occurs when the review covers previous organizational operations (ghting res is one form) to validate performance and provide guidance for future performance. corporate audits by independent accountants typically review a scal year and produce a report within 3090 days. audit reports must be led with the securities and exchange commission (sec) and become public. university tenure committees are retrospective reviews, in that the members review career accomplishments of junior academics. university accreditation committees typically deal with retrospective as well as planning oversight; for example, they may review the past ve years and plans for the next ve years. in the u.s. government, the inspector general is an internal reviewer but sometimes functions to review other agencies or departments.provide authority to investigateindependent oversight boards typically receive written reports and live presentations, but in many cases they can ask questions of individuals or request further information. in some cases, they have subpoena power to require delivery of further information. a greater power to investigate raises the importance of an oversight committee and increases its perceived independence. the time limits on an independent oversight also in˚uence its efcacy. a short review of a day or two for a review may not be enough to uncover problems, while long reviews can be a burden on organizations.the forms of investigation vary widely, from simply reading of internal reports to extensive interviews with administrators and employees. deeper investigations could assess organizational impact on others, such as customers, travelers, visa applicants, etc., by personal interview, survey questionnaire, or data collection (e.g., monitoring water quality).disseminate results of oversightindependent oversight boards typically produce a printed report, and its distribution is critical to its impact. if the only recipients are the protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.182 protecting individual privacy in the struggle against terroristsadministrators being reviewed, then there is a chance that the report will be ignored. if the recipients include employees, other stakeholders, journalists, and wider circles of the interested public, then the impact could be greater.independent oversight boards may also present their results verbally in private or public forums to the employees and administrators being reviewed. some discussion may be allowed, and revised reports may be made. such presentations can help ensure that the report is well understood and that appropriate clarications are made, and recommendations for change contained in such reports are more likely to be implemented if they are made public.reports can also be made public and permanently available, as in sec lings. a further possibility is that reports may include timetables for implementing changes and a review process to ensure that recommendations are followed.since there may be disagreements among independent oversight board members, a minority report may be included to allow strongly felt concerns to be raised by a subset of the members. such minority reports, as in supreme court decisions, allow public exposure of alternate views that may be useful in future discussions.g.2.3 applying independent oversight for government agencies to protect privacythe u.s. department of homeland security (dhs) has a difcult job that includes ensuring transportation safety, protecting national infrastructure, investigating terror threats, and many other tasks. for these and other purposes, dhs conducts extensive surveillance, which may invade the privacy of u.s. residents. dhs makes several efforts to assess its performance and provide internal and independent oversight. by statute, dhs has a chief privacy ofcer (hugo teufell iii, appointed in july 2006), a privacy ofce, and a 20member data privacy and integrity advisory board (http://www.dhs.gov/xabout/structure/editorial0510.shtm). the mission statement of the dhs privacy ofce is ﬁto minimize the impact on the individual™s privacy, particularly the individual™s personal information and dignity.ﬂ it remains to be seen whether the advisory board acts more as an internal review committee or a truly independent oversight board.18within dhs, the citizenship and immigration services has an 18 m. rotenberg. the sui generis privacy agency: how the united states institutionalized privacy oversight after 911, september 2006. available at http://epic.org/epic/ssrnid933690.pdf.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix g 183ombudsman ofce to help individuals and employers in resolving problems. they make an annual report to congress and submit recommendations for internal improvements.other agencies, such as the fbi (in the department of justice) must request review of planned investigations by the fisa court, but they have rarely been turned down.19 there does not seem to have been a retrospective review mechanism for the fisa court, or a retrospective review by the fisa court of fbi performance.the president™s privacy and civil liberties oversight board (http://privacyboard.gov/) held its rst meeting with six members in march 2006. this board could be helpful in generating public trust, but concerns about its independence and efcacy were raised after its rst public presentation in december 2006. if this board can promote planning, execution, and retrospective oversight, it could emerge as a positive in˚uence on many government agencies.public concern about warrantless domestic surveillance has become a controversial topic. a federal judge in michigan found in july 2006 that government surveillance required review by a fisa court. after ghting this decision, the current administration agreed to fisa court oversight for at least some of their intelligence operations, but as this report is being written, the ultimate outcome of the relevant legislative proposals is unclear.the traditional reliance on judicial review for privacy protection remains an effective process for dealing with evolving technologies and normative expectations. the judiciary™s role in protecting the legal and privacy rights of citizens is effective because judicial decisions are a form of independent oversight that is widely respected. furthermore, the rights it protects are established by the constitution, which all branches of government are sworn to uphold.independent oversight is potentially very helpful for continuous improvement of government operations, especially when dealing with the complex issues of privacy protection. there are many forms of independent oversight and many strategies for carrying it out. some government agencies conduct responsible independent oversight programs, but critics question their efcacy and independence. more troubling to critics are attempts to avoid, delay, or weaken independent oversight practices that are in place. public discussion of independent oversight could help 19 electronic privacy information center, foreign intelligence surveillance act orders 19792007, updated may 8, 2008. available at http://epic.org/privacy/wiretap/stats/sastats.html. some analysts interpret this fact to suggest that the fisa application process is more or less pro forma and does not provide a meaningful check on government power in this area, while others suggest that applications are done with particular care because the applicants know the applications will be carefully scrutinized.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.184 protecting individual privacy in the struggle against terroristsresolve these differences and raise trust in government efforts to protect privacy.g.2.4 collateral benets of oversightensuring compliance with policy is not the only benet afforded by oversight. indeed, administrators of government agencies face enormous challenges, not only from external pressures based on public concern over privacy, but also from internal struggles about how to motivate high performance while adhering to legal requirements and staying within budget.management strategies for achieving excellence in government agencies, corporations, and universities include many forms of internal review, measurement, and evaluation and a variety of strategies for external review. external reviews from consultants, advisory boards, or boards of visitors are designed to bring fresh perspectives that promote continuous improvement, while generating good will and respect from external stakeholders.a welldesigned oversight process can support the goal of continuous improvement and guide administrators in making organizational change, while raising public trust for an organization. although many forms of oversight have been applied in corporate settings, the main approach is the board of directors. such boards may be a weak form of oversight as they often mix internal with external participants who are less than independent. a stronger form of independent oversight and advice may come from external consultants or review panels that are convened for specic decisions or projects, but even stronger forms are possible.for example, in the united states, corporate boards of directors are required to include an audit committee that is responsible for monitoring the external nancial reporting process and related risks. an important role of the audit committee is to commission an external audit from an independent accounting rm, which is required annually for every publicly traded u.s. corporation by the sec. these external audits are major events that provide independent oversight for nancial matters with public reports to the sec that become available to investors. in response to recent failures of independent oversight such as in the enron and worldcom bankruptcies, the sarbanesoxley act (2002) has substantially strengthened the rules.2020 j.c thibodeau and d. freier, auditing after sarbanesoxley, mcgrawhill/irwin, new york, n.y., 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.185hdata mining and information fusionthis appendix addresses the science and technology of data mining and information fusion and their utility in a counterterrorism context. the use of these techniques for counterterrorist purposes has substantial implications for personal privacy and freedom. while technical and procedural measures offer some opportunities for reducing the negative impacts, there is a real tension between the use of data mining for this purpose and the resulting impact on personal privacy, as well as other consequences from false positive identication. these privacy implications are primarily addressed in other parts of this report.h.1 the need for automated techniques for data analysisin the past 20 years, the amount of data retained by both business and government has grown to an extraordinary extent, mainly due to the recent, rapid increase in the availability of electronic storage and in computer processing speed, as well as the opportunities and competitiveness that access to information provides. moreover, the concept of data or information has also broadened. information that is retained for analytic purposes is no longer conned to quantitative measurements, but also includes (digitized) photographs, telephone call and email content, and representations of web travels. this new view of what constitutes information that one would like to retain is inherently linked to a broader set of questions to which mathematical modeling has now been protably protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.186 protecting individual privacy in the struggle against terroristsapplied. for example, handwritten text can now be considered to be data, and progress in automatic interpretation of handwritten text has already reached the point that over 80 percent of handwritten addresses are automatically read and sorted by the u.s. postal service every day. a problem of another type on which substantial progress has also been made is how to represent the information in a photograph efciently in digital form, since every photograph has considerable redundancy in terms of information content. it is now possible to automatically detect and locate faces in digital images and, in some restricted cases, to identify the face by matching it against a database.this new world of greatly increased data collection and novel approaches to data representation and mathematical modeling have been accompanied by the development of powerful database technologies that provide easier access to these massive amounts of collected data. these include technologies for dealing with various nonstandard data structures, including representing networks between units of interest and tools for handling the newer forms of information touched on above. a question not addressed herešbut of considerable importance and a difcult challenge for the agencies responsible for counterterrorism in the united statesšis how best to represent massive amounts of very disparate kinds of data in linked databases so that all relevant data elements that relate to a specic query can be easily and simultaneously accessed, contrasted, and compared.even with these new database management tools, the retention of data is still outpacing its effective use in many areas of application. the common concern expressed is that people are ﬁdrowning in data but starving for knowledgeﬂ (fayyad and uthurusamy1 refer to this phenomenon as ﬁdata tombsﬂ). this might be the result of several disconnects, such as collecting the wrong data, collecting data with insufcient quality, not framing the problem correctly, not developing the proper mathematical models, or not having or using an effective database management and query system. although these problems do arise, in general, more and more areas of application are discovering novel ways in which mathematical modeling, using large amounts and new kinds of information, can address difcult problems.various related elds, referred to as knowledge discovery in databases (kdd), data mining, pattern recognition, machine learning, and information or data fusion (and their various synonyms, such as knowledge extraction and information discovery) are under rapid development and providing new and newly modied tools, such as neural networks, 1 u. fayyad and r. uthurusamy, ﬁevolving data mining into solutions for insights,ﬂ communications of the acm 45(3):2831, 2002. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 187support vector machines, genetic algorithms, classication and regression trees, bayesian networks, and hidden markov models, to make better use of this explosion of information.while there has been some overrepresentation of the gains in certain applications, these techniques have enjoyed impressive successes in many different areas.2 data mining and related analytical tools are now used extensively to expand existing business and identify new business opportunities, to identify and prevent customer churn, to identify prospective customers, to spot trends and patterns for managing supply and demand, to identify communications and information systems faults, and to optimize business operations and performance. some specic examples include:ł in image classication, skicat outperformed humans and traditional computational techniques in classifying images from sky surveys comprising 3 terabytes (1012 bytes) of image data.ł in marketing, american express reported a 1015 percent increase in credit card use through the application of marketing using data mining techniques.ł in investment, lbs capital management uses expert systems, neural nets, and genetic algorithms to manage portfolios totaling $600 million, outperforming the broad stock market.ł in fraud detection, prism systems are used for monitoring credit card fraud; more generally, data mining techniques have been dramatically successful in preventing billions of dollars of losses from credit card and telecommunications fraud.ł in manufacturing, cassiopee diagnosed and predicted problems for the boeing 737, receiving the european rst prize for innovative application.ł in telecommunications, tasa uses a novel framework for locating frequently occurring alarm episodes from the alarm stream, improving the ability to prune, group, and develop new rules.ł in the area of data cleaning, the mergepurge system was successfully applied to the identication of welfare claims for the state of washington.ł in the area of internet search, data mining tools have been used to improve search tools that assist in locating items of interest based on a user prole.under their broadest denitions, data mining techniques include a 2 u. fayyad, g.p. shapiro, and p. smyth, ﬁfrom data mining to knowledge discovery in databases,ﬂ ai magazine 17(3):3754, 1996.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.188 protecting individual privacy in the struggle against terroristsdiverse set of tools for mathematical modeling, going by such names as knowledge discovery, machine learning, pattern recognition, and information fusion. the data on which these techniques operate may or may not be personally identiable information, and indeed they may not be associated with individuals at all, although of course privacy issues are implicated when such information is or can be linked to individuals.knowledge discovery is a term, somewhat broader than that of data mining, which denotes the entire process of using unprocessed data to generate information that is easy to use in a decisionmaking context. machine learning is the study of computer algorithms that often form the core of data mining applications. pattern recognition refers to a class of data mining approaches that are often applied to sensor data, such as digital photographs, radiological images, sonar data, etc.finally, data and information fusion are data mining methods that combine information from disparate sources (often so much so that it is difcult to dene a formal probabilistic model to assist in summarizing the information). information fusion seeks to increase the value of disparate but related information above and beyond the value of the individual pieces of information (ﬁobtaining reliable indications from unreliable indicatorsﬂ).because data mining has been useful to decision making in many diverse problem domains, it is natural and important to consider the extent to which such methodologies have utility in counterterrorism efforts, even if there is considerable uncertainty regarding the problems to which data mining can be productively applied.one issue is whether and to what extent data mining can be effectively used to identify people (or events) that are suspicious with respect to possible engagement in activities related to terrorism; that is, whether various data sources can be used with various data mining algorithms to help select people or events that intelligence agents working in counterterrorism would be interested in investigating further. data mining algorithms are proposed as being able to effectively rank people and events from those of greatest interest, with the potential to dramatically reduce the cases that intelligence agents have to examine.of course, human beings would be still required both to set the thresholds that delineate which people would receive further review and which would not (presumably dependent on available resources) and to check the cases that were selected for further inspection prior to any actions. that is, human experts would still decide, probably on an individual basis, which cases were worthy of further investigation.a second issue is the possibility that data mining has additional uses beyond identifying and ranking candidate people and events for intelligence agents. specically, data mining algorithms might also be used protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 189as components of a datasupported counterterrorist system, helping to perform specic functions that intelligence agents nd useful, such as helping to detect aliases, or combining all records concerning a given individual and his or her network of associates, or clustering events by certain patterns of interest, or logging all investigations into an individual™s activity history. data mining could even help with such tasks as screening baggage or containers. such tools may not specically rank people as being of interest or not of interest, but they could contribute to those assessments as part of a humancomputer system. this appendix considers these possible roles in an examination of what is currently known about data mining and its potential for contributing to the counterterrorism effort.an important related question is the issue of evaluating candidate techniques to judge their effectiveness prior to use. evaluation is essential, rst, because it can help to identify which among several contending methods should be implemented and whether they are sufciently accurate to warrant deployment. second, it is also useful to continually assess methods after they have been elded to re˚ect external dynamics and to enable the methods to be tuned to optimize performance. also, assuming that these new techniques can provide important benets in counterterrorist applications, it is important to ask about the extent to which their application might have negative effects on privacy and civil liberties and how such negative effects might be ameliorated. this topic is the focus of appendix l.h.2 preparing the data to be minedit is well known by those engaged in implementing data mining methods that a large fraction of the energy expended in using these methods goes into the initial treatment of the various input data les so that the data are in a form consistent with the intended use (data correction and cleaning, as described in section c.1.2). the goal here is not to provide a comprehensive list of the issues that arise in these efforts, but simply to mention some of the common hurdles that arise prior to the use of data mining techniques so that the entire process is better understood.the following discussion focuses on databases containing personal information (information about many specic individuals), but much of the discussion is true for more general databases.several common data deciencies need prior treatment:ł reliable linkages. often several databases can be used to provide information on overlapping sets of individuals, and in these cases it is extremely useful to identify which data entries are for the same individuals across the various databases. this is a surprisingly difcult and protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.190 protecting individual privacy in the struggle against terroristserrorprone process due to a variety of complications: (1) identication numbers (e.g., social security numbers, ssns) are infrequently represented in databases, and when they are, they are sometimes incorrect (ssns, in particular, have deciencies as a matching tool, since in some cases more than one person has the same ssn, and in others people have more than one ssn, not to mention the data les that attribute the wrong ssns to people). (2) there are often several ways of representing names, addresses, and other characteristics (e.g., use of nicknames and maiden names). (3) errors are made in representing names and other characteristics (e.g., misspelled names, switching rst and last names). (4) matching on a small number of characteristics, such as name and birth date, may not uniquely identify individuals. (5) people™s characteristics can change over time (e.g., people get married, move, and get new jobs). furthermore, deduplicationšthat is, identifying when people have been represented more than once on the same databasešis hampered by the same deciencies that complicate record linkage. herzog et al. point out the myriad challenges faced in conducting record linkage.3 they point out that the ability to correctly link records is surprisingly low, given the above listed difculties. (this is especially the case for people with common names.) the prevalence of errors for names, addresses, and other characteristics in public and commercial data les greatly increases the chances of records either being improperly linked or improperly left unlinked. furthermore, given the size of the les in question, record linkage generally makes use of blocking variables to reduce the population in which matches are sought. errors in such blocking variables can therefore result in two records for the same individual never being compared. given that data mining algorithms use as a fundamental input whether the joint activities of an individual or group of individuals are of interest or not, the possibility that these joint activities are actually for different people (or that activities that are joint are not viewed as joint since the individuals are considered to be separate people) is a crucial limitation to the analysis.ł appropriate database structure. the use of appropriate database management tools can greatly expedite various data mining methods. for example, the search for all telephone numbers that have either called a particular number or been called by that number can be carried out orders of magnitude faster when the database has been structured to facilitate such a search. the choice of the appropriate database framework can therefore be crucially important. included in this is the ability to link 3 t.n. herzog, f.j. scheuren, and w.e. winkler, data quality and record linkage techniques, springer science+business media, new york, n.y., 2007protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 191relevant data entries, to ﬁdrill downﬂ to subsets of the data using various characteristics, and to answer various preidentied queries of interest.ł treatment of missing data. nonresponse (not to mention undercoverage) is a ubiquitous feature of large databases. missing characteristics can also result from the application of editing routines that search for joint values for variables that are extremely unlikely, which if found are therefore deleted. (a canonical example is a male who reports being pregnant.) many data mining techniques either require or greatly benet from the use of data sets with no missing values. to create a data le with the missing values lled in, imputation techniques are used, which collectively provide the resulting database with reasonable properties, with the assumption that the missing data are missing at random. (missing at random means that the distribution of the missing information is not dependent on unobserved characteristics. in other words, missing values have the same joint distribution as the nonmissing values, given other nonmissing values available in the database.) if the missing data are not missing at random, the resulting bias in any subsequent analysis may be difcult to address. the generation of highquality imputations is extremely involved for massive data sets, especially those with a complicated relational structure.ł equating of variable denitions. very often, when merging data from various disparate sources, one nds information for characteristics that are similar, but not identical, in terms of their denition. this can result from time dynamics (such as similar characteristics that have different reference periods), differences in local administration, geographic differences, and differences in the units of data collection. (an example of differences in variable denitions is different diagnostic codes for hospitals in different states.) prior to any linkage or other combination of information, such differences have to be dealt with so that the characteristics are made to be comparable from one person or unit of data collection to the next.ł overcoming different computing environments. merging data from different computer platforms is a longstanding difculty, since it is still common to nd data les in substantially different formats (including some data not available electronically). while automatic translation from one format to another is becoming much more common, there still remain incompatible formats that can greatly complicate the merging of data bases.ł data quality. deciencies in data quality are generally very difcult to overcome. not only can there be nonresponse and data linkage problems as indicated above, but also there can be misresponse due to a number of problems, including measurement error and dated responses. (for example, misdialing a phone number might cause one to become protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.192 protecting individual privacy in the struggle against terroristsclassied as a person of interest.) sometimes use of multiple sources of data can provide opportunities for verication of information and can be used to update information that is not current. also, while not a data problem per se, sometimes data (that might be of high quality) have little predictive power for modeling the response of interest. for example, data on current news magazine subscriptions might be extremely accurate, but they might also provide little help in discriminating those engaged in terrorist activities.h.3 subjectbased data mining as an extension of standard investigative techniquesthis appendix primarily concerns the extent to which stateoftheart data mining techniques, by combining information in relatively sophisticated ways, may be capable of helping police and intelligence ofcers reduce the threat from terrorism. however, it is useful to point out that there are applications of data mining, sometimes called subjectbased data mining,4 that are simply straightforward extensions of longstanding police and intelligence work, which through the benets of automation can be greatly expedited and broadened in comparison to former practices, thereby providing important assistance in the ght against terrorism. although the extent to which these more routine uses of data have already been implemented is not fully known, there is evidence of widespread use both federally and in local police departments.for example, once an individual is under strong suspicion of participating in some kind of terrorist activity, it is standard practice to examine that individual™s nancial dealings, social networks, and comings and goings to identify coconspirators, for direct surveillance, etc. data mining can expedite much of this by providing such information as (1) the names of individuals who have been in email and telephone contact with the person of interest in some recent time period, (2) alternate residences, (3) an individual™s nancial withdrawals and deposits, (4) people that have had nancial dealings with that individual, and (5) recent places of travel.furthermore, the activity referred to as drilling downšthat is, examining that subset of a dataset that satises certain constraintsšcan also be used to help with typical police and intelligence work. for example, knowing several characteristics of an individual of interest, such as a 4 j. jonas and j. harper, ﬁeffective counterterrorism and the limited role of predictive data mining,ﬂ pp. 112 in policy analysis, no. 584, cato institute, washington, d.c., december 11, 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 193description of their automobile, a partial license plate, and/or partial ngerprints, might be used to provide a much smaller subset of possible suspects for further investigation.the productivity and utility of a subjectbased approach to data mining depends entirely on the rules used to make inferences about subjects of interest. for example, if the rules for examining the recent places to which an individual has traveled are unrelated to the rules for ˚agging the national origin of large nancial transactions, inferences about activities being worthy of further investigation may be less useful than if these rules are related. counterterrorism experts thus have the central role in determining the content of the applicable rules, and most experts can make up lists of patterns of behavior that they would nd worrisome and therefore worthy of further investigation. for example, these might include the acquisition of such materials as toxins, biological agents, guns, or components of explosives (when their occupations do not involve their use) by a community of individuals in regular contact with each other. implemented properly, rulebased systems could be very useful for reducing the workload of intelligence analysts by helping them to focus on subjects worthy of further investigation.the committee recognizes that when some of the variables in question refer to personal characteristics rather than behavior, issues of racial, religious, and other kinds of stereotyping immediately arise. the committee is silent on whether and under what circumstances personal characteristics do have predictive value, but even if they do, policy considerations may suggest that they not be used anyway. in such a situation, policy makers would have to decide whether the value for counterterrorism added by using them would be large enough to override the privacy and civil liberties interests that might be implicated through such use.h.4 patternbased data mining techniques as illustrations of more sophisticated approachesoriginating in various subdisciplines of computer science, statistics, and operations research, a class of relevant data mining techniques for counterterrorist application includes (1) those that might be used to identify combinations of variables that are associated with terrorist activities and (2) those that might identify anomalous patterns that experts would anticipate would have a higher likelihood of being linked to terrorist activities. the identication of combinations of variables that are associated with terrorist activities essentially requires a training setšwhich is a set of data representing the characteristics of people (or other units) of interest and those not of interest, so that the patterns that best discrimiprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.194 protecting individual privacy in the struggle against terroristsnate between these two groups can be discerned.5 this use of a training set is referred to as supervised learning.the creation of a training set requires the existence of ground truth. that is, for a supervised learning application to learn to distinguish x (i.e., things or people or activities of interest) from notx (i.e., things or people or activities not of interest), the training set must contain a signicant number of examples of both x and notx.for an example, consider airport baggage inspections. here, supervised learning techniques can provide an improvement over rulebased expert systems by making use of feedback loops using training sets to rene algorithms through continued use and evaluation. machines that use various types of sensing to ﬁlookﬂ inside baggage for weapons and explosives can be trained over time to discriminate between suspicious bags and nonsuspicious ones. it might be possible, given the large volume of training data that can be collected from many airports, that they might be trained over time to demonstrate greater prociency than human inspectors.the inputs to such a procedure could include the types of bags, the arrangement of items inside the bags, the images recorded when the bags are sensed, and information about the traveler. useful training sets should be very easy to produce in this application for two reasons. first, many people (sometimes inadvertently) pack forbidden items in carryon luggage, thereby providing many varied instances of data from which the system could learn. second, ground truth is available, in the sense that bags selected for further inspection can be objectively determined to contain forbidden items or not. (it would be useful, in such an application, to randomly select bags that were viewed as uninteresting for inspection to measure the false negative rate.) furthermore, if necessary, a larger number of examples of forbidden articles can be introduced articiallyšthis process would increase the number of examples from which an algorithm might learn to recognize such items.6the requirement in supervised learning methods that a training set must contain a signicant number of labeled examples of both x and notx places certain limitations on their use. in the context of distinguishing between terrorist and nonterrorist activity, because of the relative infrequency of terrorist activity, only a few instances can be included in a training set, and thus learning to discriminate between 5 there is a slightly different denition of a training set when the goal is estimation instead of classication.6 however, performance would improve only with respect to information contained in images of the bagšbecause such seeding would necessarily be carried out by a nonrandom set of the population, it would not be possible to improve performance with respect to information about bag owners.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 195normal activity and preterrorist activity through use of a labeled training set will be extremely challenging. moreover, even a labeled training set can miss unprecedented types of attacks, since the ground truth they contain (whether or not an attack occurred) is historical rather than forwardlooking.by contrast, a search for anomalous patterns is an example of unsupervised learning, which is often based on examples for which no labels are available. the denition of anomalous behavior that is relevant to terrorist activity is rather fuzzy and unclear, although it can be separated into two distinct types. first, behavior of an individual or household can be distinctly different from its own historical behavior, although such differences may not (indeed, most often will not) relate specically to terrorist behavior. for example, credit card use or patterns of telephone calls can be distinctly different from those observed for the same individual or individuals in the past. this is referred to as signaturebased anomaly detection. second, behavior can be distinctly different crosssectionally; that is, an individual or household™s behavior can be distinctly different from that of other comparable individuals or households. unsupervised learning seeks to identify anomalous patterns, some of which might indicate novel forms of terrorist activity. candidate patterns must be checked against and validated by expert judgment.as an example, consider the simultaneous booking of seats on an aircraft of a group of unrelated individuals from the same foreign country without a return ticket. a statistical model could be developed to estimate how often this pattern would occur assuming no terrorism and therefore how anomalous this circumstance was. if it turned out that such a pattern was extremely common, possibly no further action would be taken. however, if this were an extremely rare occurrence, and assuming that intelligence analysts viewed this pattern as suspicious, further investigation could be warranted.a more recent class of data mining techniques, which are still under development, use relational databases as input.7 relational databases represent linkages between units of analysis, and in a counterterrorism context the key example is social networks. social networks are people who regularly communicate with each other, for example, by telephone or email, and who might be acting in concert. certainly, if one could produce a large relational database of individuals known to be in communication, it would be useful. one could then identify situations similar to those in which each member acquired an uninteresting amount of some chemical, but in which the total amount over all communicating individu7 e. segal, d. pe™er, a. regev, d. koller, and n. friedman, ﬁlearning module networks,ﬂ journal of machine learning research 6(apr):557588, 2005.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.196 protecting individual privacy in the struggle against terroristsals was capable of doing considerable harm. of course, the vast majority of the networks would be entirely innocent, and only a few would be worthy of further investigation. however, having the potential for such assessments could be useful.a key question then is, how useful is patternbased data mining likely to be in counterterrorism? without more empirical experience, it is difcult to make strong assertions, but some things are relatively clear. when training sets are available, as in the case of baggage inspection, patternbased data mining techniques are very likely to provide substantial benets. at this point, it is not known how prevalent such applications are likely to be, but an effort should be made to identify such situations, given the strong tools available in such cases. also, when there is a specic initiating person(s) or event(s) that is known to be of interest, as argued in the previous section, subjectbased techniques are certain to be very useful in helping those working in counterintelligence to expeditiously nd other people and events of interest.in the absence of training sets, and for the situation in which there are no initiating persons or events to provide initial foci of investigation, the benets obtained from the use of patternbased data mining techniques for counterterrorism are likely to be minimal. the reason is that ordinary people often engage in anomalous activities. many people have the experience of having been temporarily restricted from making credit card purchases because their recent transactions have been viewed as being atypical. people travel to places they haven™t been before, make larger withdrawals of funds than they have before, buy things they haven™t bought before, and they call and email people whom they have not called or emailed before.a basic result from multivariate statistical analysis is that, when more characteristics are considered simultaneously, it is more likely for such joint events to be unusual relative to the remainder of the data. so, if the simultaneous actions of travel, communications, purchases, movement of funds, and so on are considered jointly, it is more likely that a joint set of characteristics will be viewed as anomalous. therefore, searches for anomalous activities, without being trained and without using some linkage to a ground truth assessment of whether the activity is or is not terroristrelated, are much more likely to focus on innocent activity rather than activity related to terrorism.data mining tools can also be useful to intelligence analysts if they can reduce the time it currently takes them to carry out their current duties, as long as their accuracies are not less than those of the analysts. (of course, if the analysts are unable to do a good job, because of data inadequacies for example, automated data mining tools will also result protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 197in a bad job, only faster. in such a case, the tools can™t hurt, but spending money to acquire them may not be the best use of limited resources.)as an illustration, consider a suite of data mining tools that facilitates the detection of aliases, record linkages concerning a given individual and his or her network of associates, identication of cluster of related events by certain patterns of interest, and indexed audio/images/video from surveillance monitors. add to this suite data mining tools that performed as well as a very good analyst in identifying patterns of interest but did so more quickly. such a suite could improve the productivity of an analyst signicantly by allowing him or her to spend less time on ﬁgrunt workﬂ and to spend more time on cases that did warrant further investigation. note also that these activities are likely not to require training sets for their development.it is not the goal of this appendix to include a description of the objectives or operations of the leading data mining techniques. (excellent tutorials exist for most of the important methods, and software is typically readily available. also, a number of recent texts provide excellent descriptions of the majority of the current data mining techniques.8) some of the prominent techniques are listed in box h.1.different techniques have different attributes, which make any given technique more or less suitable in a given application. these attributes include whether or the extent to which a given technique:1. is scalable. scalability indicates whether the technique will run efciently on very large data sets. scalability is important because some data sets are far too large for an inefcient technique to process in any reasonable length of time.2. easily incorporates privacy protections. if so, it will be possible to incorporate into the methodology algorithms that provide reasonable protections against disclosures.3. is easily interpretable. an easily interpretable technique is one for which the general predictive model underlying the technique can be communicated to analysts without specic training.4. is able to handle missing data. some techniques are better than others at handling data sets with missing values.5. has effective performance with lowquality data (i.e., with a small fraction of data having widely discrepant values).6. has effective performance in the face of erroneous record linkages. the 8 t. hastie, r. tibshirani, and j. friedman, the elements of statistical learning; data mining, inference and prediction, springerverlag, new york, n.y., 2001; c. bishop, pattern recognition and machine learning, springerverlag, new york, n.y., 2006; t. mitchell, machine learning, mcgraw hill, columbus, ohio, 1997.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.198 protecting individual privacy in the struggle against terroristsbox h.1 common data mining techniqueslogistic regressionregression treesbagginghidden markov modelsboostinggenetic algorithmsbayesian networkscluster analysisneural networksgenetic algorithmsclassication treesnearest neighbor estimationsupport vector machinessupervised learningrandom forestsrecursive partitioningissue arises because record linkages often result in data with such values (10 percent or more of the data may have such values), and some techniques do not perform reliably when applied to such data.7. is resistant to gaming. resistance to gaming indicates whether an adversary can take countermeasures to reduce the effectiveness of the method.h.5 the evaluation of data mining techniquesit is crucially important that analysts planning to use a data mining algorithm for counterterrorism have some objective understanding of its performance, both prior to use and continually updated while in use. evaluation provides the basis for (1) an understanding of the quality of the assessments provided, which is particularly important when those assessments are to be used in conjunction with other sources of information; (2) a quantitative way of judging the tradeoffs between the benets derived from the use of an algorithm and its associated costs, especially including a decrease in privacy, and particularly when those tradeoffs justify its use; and (3) determining when a competing algorithm should be adopted in replacement or determining when a modication should be made. evaluation of data mining techniques can be particularly difcult protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 199in certain counterterrorism applications, for several reasons discussed below.h.5.1 the essential difculties of evaluationevaluation of data mining methods can be carried out in two very general ways. first, internal validation can be used: an algorithm is examined stepbystep, assessing the likelihood of any assumptions obtaining, the quality of input data, the validity of any statistical models, etc. sensitivity analyses are used in internal validation to examine the impact of divergences from the ideal. second, external validation compares the predictions to ground truth for situations in which ground truth is available. external validation is very strongly preferred, since it is a direct assessment of the value of a data mining tool.as mentioned above, data mining algorithms could play a number of very disparate supplementary roles in counterterrorism. in some cases, evaluation might be obvious, such as when the data mining tool performs the same function currently performed by intelligence agents, but much faster. an example might that of logging all investigations into an individual™s activity history.however, in situations in which a patternbased data mining algorithm is being used to discriminate between people or events of interest and those not of interest, a training set is not only extremely important for developing the data mining algorithm, but it is also nearly essential for carrying out an evaluation of such an algorithm when it has completed development. the difculties in developing such algorithms therefore translate to difculties in their evaluation.as far as the committee knows, there are no data sets available that represent the activities of a diverse group of people including both terrorists (i.e., people of interest and worthy of further investigation) and nonterrorists (i.e., those not of interest) and also where they are correctly identied as such in the database. also, since the development of procedures used to discriminate between two populations is greatly facilitated when there are substantial numbers of both types represented in the training set, the rarity of terrorist events, and more broadly the rarity of people of interest, complicates both the development and the evaluation of data mining techniques for counterterrorism.even if a procedure could be evaluated on a current training set, there is always the possibility that terrorists could adjust (game) their procedures to avoid detection once a methodology is implemented.9 9 for example, a wide variety of countermeasures to polygraph use are wellknown. see, for example, national research council, the polygraph and lie detection, the national academies press, washington, d.c., 2003.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.200 protecting individual privacy in the struggle against terroristseven without gaming, other dynamics might impact the effectiveness of a methodology over time. so not only is there a need for evaluation, but also there is a need for constant reevaluation.to address this situation, evaluation must be carried out as an iterative process, in which techniques are initially implemented on a research basis, followed by a period of continuous evaluation and testing. then, only those procedures that have demonstrated their utility would be formally deployed, and, after deployment, procedures would be continuously evaluated both to monitor their performance given the dynamic nature of the threat and to tune procedures to increase their effectiveness.the importance of evaluation here is difcult to overstate, since the use of ineffective data mining procedures represents a threefold cost. first, there is the potentially enormous cost of using a less effective algorithm for identifying terrorists and possibly not preventing an attack. second, there is the serious impact each additional data mining procedure has on the freedoms and privacy of u.s. citizens. third, investigating false leads from ineffective data mining procedures may waste substantial resources, reducing the energies that can be addressed to real threats. for these reasons, evaluation plays an important role in the committee™s framework. it is therefore vitally important that procedures be comprehensively evaluated both in development and if implemented, throughout the history of their use, and further that implementation be contingent on a careful assessment of a technique™s effectiveness, as well as its costs in terms of impact on privacy and its required resources for continued use. furthermore, it is crucial, given the nite resources and the costs to privacy, that poorly performing procedures be removed from development or from use as soon as possible.h.5.2 evaluation considerationssome progress in the evaluation of data mining techniques for counterterrorism can be made without the use of training sets. in the dichotomous supervised learning case, in which one is using data mining to discriminate between terrorist activities and nonterrorist activities, two types of errors that can be made are false positives and false negatives.while some data mining techniques do separate the cases into those of interest and those not of interest, most data mining techniques only rankorder the cases from those of least interest to those of greatest interest, without specifying where a line should be drawn between the two groups. however, in practice, the intelligence and police agencies are likely to draw a line at some point, based on the results of the data mining algorithm, and some people will be further investigated (which may protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 201mean having an analyst look over the data and okay or not okay further investigation) and some people will not be investigated. therefore, for evaluation purposes, it makes sense to proceed as if there are false positives and false negatives that are the direct result of the application of data mining methods.even without a training set, the assessment of the false positive rate for a procedure is in some sense straightforward, because if a procedure identies a number of people as being of interest, one can further investigate (a sample of) such people and determine whether they were, in fact, of interest. however, this procedure is clearly resourceintensive.the assessment of the false negative rate is considerably more difcult than for the false positive rate. a number of ideas might be suggested to produce a type of training set for use in evaluation:ł have intelligence and police ofcers look at data on (likely) tens of thousands of individuals, identifying some as worthy of further investigation, with the remainder not of interest. however, the likely result is that the training set constructed in this way will not contain very many people of interest given the rarity of terrorist activity.ł to deal with the lack of identied people of interest, one could relax the denition of ﬁperson of interestﬂ to include people with less direct links to terrorist activity. this will boost the number of people of interest in the training set. however, the obvious problem is that the resulting data mining procedure will then be oriented to identify many more false positive cases.ł another way of increasing the number of identied people of interest is to introduce synthetic data that represent ctitious people worth further investigation.any of these ideas will require assessments of which cases are and are not of interest, which will require more resourceintensive use of analysts to make the assessments. once such a training set is created, algorithms can then be run on the data to determine the ability of a procedure to correctly discriminate between those of interest and those not of interest.the goal is that, over time, the data mining procedures trained on such data would mimic what the intelligence ofcers would do if they could process millions of data records. the downside is that the data mining algorithm is then limited to mimicry and does not have the capacity to anticipate new terrorism patterns that might elude intelligence experts.a variety of approaches can be used for evaluating data mining methodologies. many possibilities for evaluation exist in addition to the ones described below, including various forms of sensitivity analysis and protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.202 protecting individual privacy in the struggle against terroristsmeasuring the performance of an algorithm using mixtures of real and synthetic data sets.crossvalidationone should not evaluate a data mining routine on the same training set that was used to develop the procedure, since the routine will then be overt to that particular data set and therefore assessment of its performance on that training set will be optimistically biased. crossvalidation is one approach that can be used to counter this bias.crossvalidation denotes an approach in which the available data are rst separated into a training subset and a test subset. the system is trained using only the training subset, and the resulting trained procedure is then evaluated on the heldout test set of data. one typical procedure, called kfold crossvalidation, involves randomly splitting the training sample into k equalsized subsets, and then training a procedure using all but the ith subset, evaluating that procedure by using it to predict the response of interest for the cases on the setaside ith subset. this process is repeated so that each of the k subsets is used as the test set on one of the folds, and the evaluated accuracy over these k repetitions is averaged.while crossvalidation is strongly recommended as an evaluation tool, it has two limitations. first, as mentioned above, for any supervised learning technique, since a training set is typically not representative of time dynamics, crossvalidation does not evaluate a procedure™s value for future data sets. second, using this technique, one is evaluating each procedure as a single entity. however, the data mining procedures will be used as elements of a portfolio approach to counterterrorism. therefore, what is desired is not how a procedure performs in isolation, but what a procedure adds to an existing group of techniques. in that sense, novelty may be much more valuable than correspondence with an extremely useful methodology that is already implemented.finally, crossvalidation is most readily applied to data sets in which the specied subsets have no relationships with each other. it is likely that crossvalidation can also be applied to more complicated data structures, such as networks, but additional research may be needed to determine the best way to do this.face validityanother evaluation tool is face validity. generally speaking, procedures that produce sensible outputs in response to given, often extreme inputs (often bestcase and worstcase scenarios) are said to have gained face validity. in addition, input data for ctitious individuals that are protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 203designed to provoke an investigation given current procedures, and which are subsequently ranked as being of high interest using a particular data mining algorithm, provide some degree of face validity for that algorithm and procedure. the same is true for ctitious inputs for cases that would be of no interest to counterterrorism analysts for further investigation. another way that a data mining procedure used for counterterrorism would gain face validity would be if counterterrorism analysts found the results of the procedure useful in their work.so if a data mining routine provides rankings of interest for people (or other units of analysis) that an analyst nds saves time in deciding where to focus investigative attention, that outcome is a good starting point for indicating the potential value of the algorithm.however, achieving face validity is a very limited form of evaluation. it does not help to tune or optimize a procedure, it is by its nature a small sample assessment, and experts in the eld might have difculty agreeing on whether a particular approach has face validity or objectively comparing several competing techniques. however, face validity is, at the least, a necessary hurdle for a methodology to overcome prior to elding.the committee suggests that the results of expert judgment should be retained in some fashion and incorporated into the data mining procedures in use over time so that their subsequent use re˚ects this input. this can be done in several ways, but the basic idea is that cases that experts view differently from the data mining procedurešfor example, a person clearly of interest who receives a low ranking by the data mining procedurešshould result in modications to the procedure to avoid repeating that error in the future. to support this, not only should experts examine cases identied as of interest to discover false positives, but also a sample of those identied as not of interest should be reviewed in order to have some possibility, admittedly remote, of discovering false negatives. the evaluation and improvement of data mining procedures for counterterrorism needs to be an iterative process.finally, one could use face validity as a method for evaluating competing algorithms. one could conduct an experiment in which investigators are given leads from two competing data mining algorithms, denoted a and b to blind the comparison. at the end of the experiment, the experts involved in the experiment could be asked whether they preferred the leads from a or b.gaming and countermeasuresanother topic that needs to be considered in evaluating data mining procedures for use in counterterrorism is the extent to which these procedures can be gamed. that is, if someone has some general knowledge protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.204 protecting individual privacy in the struggle against terroristsof the procedures being used, could their behavior be adjusted to reduce the effectiveness of the data mining technique (or to completely defeat the algorithm)?of course, specic knowledge of the precise procedures (and the specic parameter values) being used would be enormously valuable, although nearly impossible to obtain. what is more likely is that there would be a general understanding of what is being carried out. certainly, there would be advantages to the typical actions those engaged in illegal activities already take to mask their identities, such as the use of false identications and aliases, frequent changes of residences, etc.however, our broad expectation is that some of the patterns that would be focused on through use of data mining would be difcult to mask. therefore, while some gaming of the routines used would be effective, having a sufciently diverse portfolio of algorithms might, over time, provide alternate avenues toward the discovery of terrorists engaged in many different kinds of terrorist activities. a general statement is that it is not whether a procedure can or cannot be gamed, but how relatively easily a procedure can be gamed relative to other competing ones, what is the impact on the procedure™s effectiveness, and how the opportunities for gaming can be reduced. keeping the procedures and the input data sources secret reduces the opportunity for gaming, though at the same time it runs counter to the public™s right to know what the government is doing that may compromise personal privacy and other rights. finding the appropriate middle ground is difcult.the issue of how an adversary might take countermeasures against any data mining system or data collection effort raises an important policy issue regarding the costs and benets of greater transparency into these systems and efforts (i.e., more public knowledge about the nature of the data being collected and how the systems work). as noted above, costs could include an increased risk of adversary circumvention of these systems and efforts and perhaps also strong negative reactions of citizens attempting to stop the loss of privacy and condentiality. however, greater transparency is likely to result in increasing trust in government and some relief that the threat of terrorism was possibly being reduced.reducing bias in evaluationa central issue in research and development is evaluation. it is easy to propose techniques, and vendors and other interested parties propose purportedly new techniques all the time. government agencies like the u.s. department of homeland security (dhs) and the national security agency (nsa) will acquire data mining algorithms for use in counterterrorism in two ways: from outside developers (contractors) and from protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 205algorithm developers within the agency. but both internal and external developers are likely to have biases and vested interests in the outcome of any evaluation they may have conducted to judge the performance of an algorithm that they have developed. thus, before deployment and operational use, such techniques must be as carefully and comprehensively evaluated as possible using the best available evaluation techniques and methods. many such techniques and methods are used in sophisticated commercial applications.for these reasons, independent checks on the evaluation work of developers are necessary to minimize the possibility of bias, regardless of whether proprietary claims are asserted. thus, those conducting the checks should have as much information as necessary to conduct the reviews involved (e.g., full access to descriptions of the algorithms, results of previous evaluations, and descriptions of adjustments that have been made in response to earlier evaluations) and work as independently as possible from the developers.evaluators can also build on the foundations provided by preliminary or internal evaluations, since a great deal can be learned about the performance of a system through its performance throughout development. developers often view these as proprietary, so if dhs or nsa is at the early stage of requesting proposals for development of such techniques, the sharing of such information must be specied in the contract prior to the beginning of work.finally, it is also important to subject work in this area to peer evaluation to the extent possible consistent with the needs to protect classied information. engagement of the best talent and expertise available and solicitation of their contributions as input to the decision making process are important. such expertise is generally needed to make critical judgments about vendor claims concerning new technological solutions, and it is essential toward deploying effective measures to security problems. possible mechanisms to support such contributions include interagency professional agreements, sabbatical arrangements for academics, consulting agreements, and external advisory groups.h.6 expert judgment and its role in data miningthe importance of responsible expert judgment in various aspects of data mining, from research and development to eld deployment, cannot be overstated. expert judgment (of individuals with different background and experiences) is critical both in operations and in development.from an operational standpoint, human beings are required to interpret the results of a data mining application. as noted above, data mining generally does not identify cases of interest. instead, data mining protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.206 protecting individual privacy in the struggle against terroristsrankorders cases from those of no interest to those of great interest. but it is a matter of human judgment to set thresholds (e.g., those above a certain specied line are of interest, and those below a certain, different, specied line are not of interest) and to determine exceptions (e.g., closer examination of person x who ranked above the threshold indicates that in fact he is not of interest). that is, human experts must decide, probably on an individual basis, which cases are worthy of further investigation or other action. therefore, there is a need to consider the operator and the data mining algorithms as a sociotechnical system, as well as a need to determine how operators and the data mining technology can best work together.as an example of a sociotechnical issue, consider a frequently held belief in the infallibility of a computer. although in principle a human expert may be required to validate and check a computer™s conclusions or rank orderings, in practice it is all too easy for the humanšespecially a young and inexperienced onešto play it safe by accepting at face value a machinegenerated conclusion. procedures and incentives must be developed to shape the human™s behavior so that she or he is neither too trusting nor too skeptical of the computer™s output.from a development standpoint, human judgment and expertise play critical roles in shaping how a given system works. in addition to the abovementioned role for experts in deciding which cases should be further investigated, expert assessments also have other important roles:ł deciding which variables are discriminating and the values of these variables that indicate whether a given case is of interest or not. for example, a variable (ﬁitem purchasedﬂ) and an amount may be associated with a credit card transaction, some purchases and amounts should be indicated as being of interest and some not, and this is probably best determined by experts. additional work is needed to determine which input data sets contain potentially relevant information.ł deciding on criteria to separate anomalous patterns (i.e., patterns that are unusual in some sense) into those that are and are not potentially threatening and indicative of terrorist activity.ł deciding on the specic form of the algorithm that is evaluated for use. (for example, should one use a transformed or untransformed version of a predictor in a logistic regression model?)ł improving the robustness of data mining routines against gaming and steps taken to ﬁ˚y under the radar.ﬂ for example, a routine may be adjusted to account for an individual making many small purchases over an extended period of time by making that effectively equal to a large onetime purchase.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 207these multiple and signicant roles for expert judgment remain even with the best of data mining technologies. over time, it may be that more of this expertise can be represented in the portfolio of techniques used in an automated way, but there will always be substantial deciencies that will require expert oversight to address.h.7 issues concerning the data available for use with data mining and the implications for counterterrorism and privacyit is generally the case that the effectiveness of a data mining algorithm is much more dependent on the predictive power of the data collected for use than on the precise form of the algorithm. for example, it typically does not matter that much, in discriminating between two populations, whether one uses logistic regression, a classication tree, a neural net, a support vector machine, or discriminant analysis. priority should therefore be given to obtaining data of sufcient quality and in sufcient quantity to have predictive value in the ght against terrorism.the rst step is to ensure that the data are of high quality, especially when they are to be linked. when derived from record linkages, data tend to assume the worst accuracies in the original data sets rather than the best. inaccurate data, regardless of quantity, will not produce good or useful results in this counterterrorism context.a second step is to ensure that the amount of data is adequatešalthough as a general rule, the collection of more data on people™s activities, movements, communications, nancial dealings, etc., results in greater opportunities for a loss of privacy and the misuse of the information. portions of the committee™s framework provide for best practices to minimize the damage done to privacy when information is collected on individuals, but ultimately, a policy still needs to be identied that species how much additional data should be used for obtaining better results.insight into the specics of the tradeoff can be obtained through the use of synthetic data for the population at large (i.e., the haystack within which terrorist needles are hiding) without compromising privacy. at the outset, researchers would use as much synthetic data as they were able to generate in order to assess the effectiveness of a given data mining technique. then, by removing databases one by one from the scope of the analysis, they would be able to determine the magnitude of the negative impact of such removal. with this analysis in hand, policy makers would have a basis on which to make decisions about the tradeoff between accuracy and privacy.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.208 protecting individual privacy in the struggle against terroristsh.8 data mining components in an  informationbased counterterrorist systemit is too limiting a perspective to view data mining algorithms only as standalone procedures and not to view them as potentially components of a datasupported counterterrorist system. consider, for example, that data mining techniques have played an essential role as various components of the algorithm that comprises an internet search engine.a search engine, at the user level, is not a data mining system, but instead a database with a natural query language. however, the component processes of populating this database, ranking the results, and making the query language more robust are all carried out through the essential use of data mining algorithms. these component processes include (1) spell correction, (2) demoting web sites that are trying various techniques to in˚ate their ﬁpage rank,ﬂ (3) identifying web sites with duplicate content, (4) clustering web pages by concept or similarity of central topic, (5) modifying ranking functions based on the history of users™ click sequences, and (6) indexing images and video.without these and other features, implemented partially in response to efforts to game search engines, search results would be nearly useless compared with their current value. but as these features have been added over the years, they have increased the value of search engines enormously over their initial implementations, and today search engines are an indispensable part of an individual™s online experience.in a somewhat similar way, one can imagine a search engine, in a general sense of the term, that was designed and optimized for counterterrorist applications. such a system could, among other things: (a) generalize/specialize the detection of aliases and/or address the ambiguity in foreign names, (b) combine all records concerning a given individual and his or her network of associates, (c) cluster related events by certain patterns of interest and other topics (such as the acquisition of materials and expertise useful for the development of explosives, toxins, and biological agents), (d) log all investigations into an individual™s activity history and develop ratings of people as to their degree of interest, and (e) index audio/images/video from surveillance monitors.all of these are typical data mining applications that do not depend on the existence of training data, and they would seem to be critical components in any counterterrorism system that is designed to collect, organize, and make available for query information on individuals and other units of interest for possibly further data collection, investigation, and analysis. therefore, data mining might provide many component processes of what would ideally be a large counterterrorism system, with human analysts and investigators playing an essential role alongside specic data mining tools.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 209over time, as more data are acquired and different sources of data are found to be more or less useful, as attempts at gaming are continuously monitored and addressed, as various additional unforeseen complexities arise and are addressed, a system could conceivably be developed that could provide substantial assistance in reducing the risk from terrorism. few of the necessary components of this idealized system currently exist, and therefore this is not something that could be implemented quickly. however, in the committee™s view, the threat from terrorism is very likely to persist, and therefore the committee is in support of a fully supported research and development program with the goal of examining the potential effectiveness of such a system.it is important to point out that each of the above component applications is quite nontrivial. for example, part (b) ﬁcombine all records concerning a given individual and his or her network of associatesﬂ would be an extremely complicated tool to develop in a way that would be easy to access and use.and it is useful to point out that when viewing data mining applications as part of a system, their role and therefore their evaluation changes. for example, consider a data mining algorithm that was extremely good at identifying patterns of behavior that are not indicative of terrorist activity but was not nearly as effective at identifying patterns that are. such a component process could be useful as a lter, reducing the workload of investigators, and thereby freeing up resources to devote to a smaller group of individuals of potential interest. this algorithm would fail as a standalone tool, but as part of a system, it might perform a useful function.development of such a system would certainly be extremely challenging, and success in reducing the threat from terrorism would be a signicant achievement. therefore, research and development of such an approach requires the direct involvement of data mining experts of the rst rank. what is needed is not simply the modication of commercial offtheshelf techniques developed for various business applications, but a dedicated collaborative research effort involving both data miners and intelligence analysts with the goal of developing what are currently nonexistent techniques and tools.h.9 information fusionanother class of data mining techniques, referred to as ﬁinformation fusion,ﬂ might be useful in counterterrorism. information fusion refers to a class of methods for combining information from disparate sources in order to make inferences that may not be possible from a single source. one possible, more limited application to counterterrorism is matching protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.210 protecting individual privacy in the struggle against terroristspeople using a variety of sources of information, including address, name, and date of birth, as well as ngerprints, retinal scans, and other biometric information. a broader application of information fusion is identifying patterns that are jointly indicative of terrorist activity.with respect to the narrower application of person matching, there are different ways of aggregating information to measure the degree to which the personal information matches. one can develop (a) distance metrics using sums of distances using the measured quantities themselves, (b) sums of measures of the assessment of the degree of match for each characteristic, and (c) voting rules that aggregate over whether or not there is a match for each characteristic. there may be advantages in different applications to combining information at different levels of the decision process. (a common approach to joining information at level (a) is through use of the fellegisunter algorithm.) the committee thinks that information fusion might prove helpful in this limited application. however, the problems mentioned above concerning the difculties of record linkage will greatly reduce the effectiveness of many information fusion algorithms that are used to assist in person matching.regarding the broader application, consider the problem of identifying whether there is a terrorist threat from the following disparate sources of information: recent meetings of known terrorists, greater than usual movement of funds from countries known to harbor terrorists, and greater than usual purchases of explosives in the united states. information fusion uses such techniques as the kalman lter and bayesian networks to learn how to optimally join disparate pieces of information at different levels of the decision process, by either combining individual data elements or combining higher level assessments for the decision at hand, in order to make improved decisions in comparison to more informal use of the disparate information.clearly, information fusion directly addresses an obvious need that arises repeatedly in the attempt to use various data sources and types of data for counterterrorism. intelligence agencies will have surveillance photographs, information on monetary transactions, information on the purchase of dangerous materials, communications of people with suspected terrorists, movements of suspected people into and out of the country, and so on, all of which will need to be combined in some way to make decisions as to whether to initiate further and more intrusive investigations.to proceed, information fusion for these broader applications typically requires estimates of a number of parameters, such as conditional probabilities, that model how to link the evidence received at various levels of the decision process to the phenomenon of interest. an example might be the probability that a terrorist act is planned in country b in the next three months, given a monetary movement of more than x dollars protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 211from a bank in country a to one in country b in the last six months and the purchase in the last two months of more than the usual amounts of explosives of a certain type and greater than usual air travel in the last two months of individuals from country a to country b. clearly, a conditional probability like this would be enormously useful to have, but how could one estimate it? it is possible that this conditional probability could be expressed as an arithmetic function of simpler conditional probabilities under some conditional independence assumptions, but then there is the problem of validating those assumptions to link those more primitive conditional probabilities to the desired conditional probability.more fundamentally, information fusion for the broader problem of counterterrorism requires a structure that expresses the forms in which information is received and how it should be combined. at this time, especially given the great infrequency of terrorist events, it will be extremely difcult to validate either the above assumptions or the overall structure proposed for use. therefore, while information fusion is likely to be useful for some limited problems, it does not currently seem likely to be productive for the broad problem of identifying people and events of interest.h.10 an operational notethe success of any data mining enterprise depends on the availability of relevant data in the universe of data being mined and the ability of the data mining algorithms being used to identify patterns of interest.in the rst instance (availability of data), the operational security skills of the wouldbe terrorists are the determining factor as to whether data is informative. for terrorists planning highend attacks (e.g., nuclear explosions involving tens or hundreds of thousands of deaths), the means and planning needed for carrying out a successful attack are complex indeed. on one hand, almost by denition, a terrorist group that could carry out such an attack would have a considerable level of sophistication, and it would take great care to minimize its database tracks. thus, for attacks at the high end, those intending to carry out such attacks may be better able to reduce the evidence of their activities. on the other hand, the complicated planning necessary for these attacks might provide greater opportunity for data mining to succeed. the tradeoff in this case is difcult to evaluate.in the second instance, regarding the identication of patterns of interest against a noisy background, the primary issue is the fact that the means to carry out smallscale terrorist attacks (e.g., attacks that might result in a few to a few dozen deaths) are easily available. though not a terrorist, in 2007 the virginia tech shooter, for example, killed a few dozen individuals with guns purchased over the counter at a gun store. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.212 protecting individual privacy in the struggle against terroristsmoreover, the planning needed to carry out such an attack is fairly minimal, especially if the terrorist is willing to die. thus, those intending to carry out relatively smallscale attacks might in principle leave a relevant database track, but the difcult (and for practical purposes, probably insoluble) problem would be the ability to identify that track and infer terrorist actions against a much larger background of innocuous activity.for practical purposes, then, data mining tools may be most useful against the intermediate scale of terrorist attack (say, car or truck bombs using conventional explosives that might cause many tens or hundreds of deaths). moreover, as a practical matter, terrorists must face the possibility of unknown leakagesštelltale signs that a terrorist group may not know they are leaving, or human intelligence tips that cue counterterrorism authorities about what to look for (box h.2)šand likelihood of such leakages can be increased by a comprehensive effort that aggressively seeks relevant intelligence information from all sources. this point further underscores the importance of seeing data mining as one element of a comprehensive counterterrorist effort.box h.2 an illustrative compromise in operational security from a terrorist perspective a conversation between a u.s. person and an unknown individual in pakistan is intercepted. the call was initiated in the detroit area from a pay phone using a prepaid phone card. the conversation was conducted in the arabic language. the initiator is informing the recipient of the upcoming ﬁmarriageﬂ of the initiator™s brother in a few weeks. the initiator makes reference to the ﬁmarriageﬂ of the ﬁdead indelﬂ some years ago and says this ﬁmarriageﬂ will be ﬁsimilar but bigger.ﬂ the recipient cautions the initiator about talking on the telephone and terminates the call abruptly. the intelligence analyst™s interpretation of this conversation is that ﬁmarriageﬂ is open code for martyrdom. interrogation of another source indicates that the association of ﬁmarriageﬂ and ﬁdead indelﬂ is a reference to the oklahoma city bombing. it is the analyst™s assessment that a major anfo or annm attack on the continental united states is imminent. red team analysis concludes that large quantities of ammonium nitrate can be untraceably acquired by making cash purchases that are geographically and temporally distributed. a ﬁtipﬂ such as this phone conversation might well trigger a major ad hoc data mining exercise through previously unsearched databases, such as those of home improvement and gardening suppliers.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 213h.11 assessment of data mining for counterterrorismpast successes in applying data mining techniques in many diverse domains have interested various government agencies in exploring the extent to which data mining could play a useful role in counterterrorism. on one hand, this track record alone is not an unreasonable basis for interest in exploring, through research and development, the potential applicability of data mining for this purpose. on the other hand, the operational differences between the counterterrorism application and other domains in which data mining has proven its value are signicant, and the intellectual burden that researchers must surmount in order to demonstrate the utility of data mining for counterterrorism is high.as an illustration of these differences, consider rst the use of data mining for credit scoring. credit scoring, as described in hand and in lambert,10 makes use of the history of nancial transactions, current debts, income, and accumulated wealth for a given individual, as well as for similar individuals, to develop models of how people behave who are likely to default on a loan, and those who are not likely. such histories are extensive and have been collected for many years.training sets are developed that contain the above information on people who have been approved for loans who later paid in full and also those who were approved for loans and who later defaulted. training sets are sometimes augmented by data on a sample of those who would not have been approved for a loan but who were granted one nonetheless, and whether or not they later defaulted on the loan. training sets in this application can be used to develop very predictive models that discriminate well between those for whom additional loans would be both a good and a bad decision on the part of the credit granting institution.the utility of training sets in this application benets from the prevalence of the failure to repay loans. while there is a great interest in reducing the number of bad loans to the extent possible, missing a small percentage of bad loans is not a catastrophe. therefore, false negatives are to be avoided, but a few bad loans are acceptable. while there is a substantial effort to game the process of awarding credit, it has been possible to discover ways to adjust the models that are used to discriminate between good and bad loan applications to retain their utility. finally, while applications for credit from those new to the database are problem10 d.j. hand and w.e. henley, ﬁstatistical classication methods in consumer credit scoring: a review,ﬂ journal of the royal statistical society, series a 160(3):523541, 1997; also d. lambert, ﬁwhat use is statistics for massive data?,ﬂ bell labs/lucent technologies, murray hill, n.j., unpublished paper, 2000.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.214 protecting individual privacy in the struggle against terroristsatic, it has also been possible to develop models that can be used for initial loan applicants to handle those without a credit history.11by contrast, consider the contrasting problem of implementing a ﬁno˚yﬂ list. although the details of actual programs remain secret, enough is known in the public domain to identify key differences between this problem and that of credit scoring. some data on behavior relevant to potential terrorist activity (or more likely past activity) are available, but they are very incomplete, and the predictive power of the data collected and the patterns viewed as being related to terrorist activity is quite low. (for example, it is known that an individual with a name that is similar to that of a person on a terrorist watch list is cause for suspicion and additional screening.) labeled training sets for supervised learning methods cannot be developed because the number of people that have attempted to initiate attacks on aircraft and other terrorist activity is extremely small. furthermore, gamingšfor example, the use of aliases and false documentation, including passportsšis difcult to adjust to. finally, as in credit scoring, there is a need for a process to deal with individuals for whom no data are available, but in this application there seems to be much less value in ﬁborrowing informationﬂ from other people.given these differences, it is not surprising that the base technologies in each example have compiled vastly different track records: data mining for credit scoring is widely acknowledged as an extremely successful application of data mining, while the various no˚y programs (e.g., capps ii) have been severely criticized for their high rate of false positives.12 box h.3 describes the largely unsuccessful german experience with counterterrorist proling based on personal characteristics and backgrounds.at a minimum, subjectbased data mining (section h.3) is clearly relevant and useful. this type of data miningšfor example, structured searches for identifying those in regular contact with known terrorists 11 this description ignores some complexities. all loans are not of equal dollar amount, so making a number of mistakes on a group of loan decisions is not well summarized by the number of mistakes made, that is, the amount loaned in error is also useful to know. furthermore, it may be protable to let in some poor loans if more prot is made collectively through the group of loans. also, there is a selection problem, in that typically it is not known for those rejected for a loan whether that decision was appropriate or not. finally, external circumstances can change, for example, an economic recession can occur, which may impact the effectiveness of the models used.12 implementing the no˚y list also illustrates the importance of human intervention. in most cases, individuals ˚agged for further screening are indeed allowed to board aircraft, although they may miss their ˚ight or suffer further inconvenience or harm. the reason they are allowed to do so is because the data mining technology has ˚agged them as likely risks, but the additional (humanbased) screening efforts, though timeconsuming, have determined that the individual in question is not likely to be a risk.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 215box h.3 the german experience with profiling in the aftermath of the september 11, 2001, terrorist attacks on the united states, german law enforcement authorities sought to explore the possibilities of using largescale statistical proling of entire sectors of the population with the purpose of identifying potential terrorists. an initial prole was developed, largely based on the social characteristics of the known perpetrators of 9/11 (male, 1840 years old, current or former student, islamic, legal resident in germany, and originating from one of a list of 26 muslim countries). this prole was scanned against the registers of residents™ registration ofces, universities, and the central foreigners™ register to identify individuals matching the dened prolešan exercise that resulted in approximately 32,000 entries. individuals in this database were then checked against another database of about 4 million individuals identied as possibly having the relevant knowledge to carrying out a terrorist attack, or who had familiarity with places that could constitute possible terrorist targets. this included, for example, individuals with a pilot™s license (or attending a course to obtain it), members of sporting aviation associations, as well as employees of airports, nuclear power plants, chemical plants, the rail service, laboratories and other research institutes, as well as students of the german language at the goethe institutes. the comparison of these two databases yielded 1,689 individuals as potential ﬁsleepers.ﬂ these individuals were investigated at greater length by the german police, but after one year not one sleeper had been identied. seven individuals suspected of being members of a terrorist cell in hamburg were arrested, but they did not t the statistical prole. in the entire proling exercise, data were collected and analyzed on about 8.3 million individualsšwith a null result to show for it. the exercise was terminated after about 18 months (in summer 2003) and the databases deleted. (in april 2006, the german federal constitutional court declared the thenterminated exercise unconstitutional.)source: adapted from giovanni capoccia, ﬁinstitutional change and constitutional tradition: responses to 9/11 in germany,ﬂ in martha crenshaw (ed.), the consequences of counterterrorist policies in democracies, new york, russell sage, forthcoming.or identifying those, possibly as part of a group, who are collecting large quantities of toxins, biological agents, explosive material, or military equipmentšmight well identify individuals of interest that warrant further investigation, especially if their professional and personal lives indicate that they have no need for such material. (such searches could also result in a large number of false positives that would require human judgment to dispose of.) such searches are within the purview of law enforcement and intelligence analysts today, and it would be surprising if protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.216 protecting individual privacy in the struggle against terroristssuch searches were not being conducted today as extensions of standard investigative techniques.these approaches have been criticized because they are relevant primarily to future events that have a nontrivial similarity to past events, thus providing little leverage in anticipating terrorist activities that are qualitatively different from those carried out in the past. but even if this criticism is valid (and only research and experience will provide such indications), there is denite and important benet in being able to reduce the risk from known forms of terrorist activity. forcing terrorists to use new approaches implies new training regimes, new operational difculties, and new resource requirementsšall of which complicate their own planning and reduce the likelihood of successful execution.the jury is still out on whether patternbased data mining algorithms produced without the benets of machine learning will be similarly useful, and in particular whether such techniques could be useful in discovering more subtle, novel patterns of behavior as being indicative of the planning of a terrorist event that would have been unrecognized a priori as such by intelligence analysts. jonas and harper (2006) refer to this kind of data mining as ﬁpatternbasedﬂ data mining.13 the distinction between subjectbased and patternbased data mining is important. subjectbased data mining is focused on terrorist activities that are either precedented (because analysts have some retrospective understanding of them) or anticipated (because analysts have some basis for understanding the precursors to such activities), while patternbased data mining is focused on future terrorist activities that are unanticipated and unprecedented (that is, activities that analysts are not able to predict or anticipate).subjectbased techniques have the advantage of being based on strongly predictive models. for example, being a close associate of someone suspected of terrorist activity and having similar connections to persons or groups of interest are strong predictors that a given person will also be of interest for further investigation. by contrast, patternbased techniques, in the absence of a training set, are likely to have substantially less predictive power than the subjectbased patterns chosen by counterintelligence experts based on their experiencešand consequently a very large false positive rate. (indeed, one might expect such an outcome, since patternbased techniques, by denition, seek to discover anomalous patterns that are not a priori associated with terrorist activity and therefore have no historical precedents to support them. patternbased techniques 13 j. jonas and j. harper, ﬁeffective counterterrorism and the limited role of predictive data mining,ﬂ pp. 112 in policy analysis, no. 584, cato institute, washington, d.c., december 11, 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix h 217are also, at their roots, tools for identifying correlations, and as such they do not provide insight into why a particular pattern may arise.)jonas and harper (2006) identify three factors that are likely to have a bearing on the utility of data mining for counterterrorist purposes:ł the ability to identify subtle and complex data patterns indicating likely terrorist activity,ł the construction of training sets that facilitate the discovery of indicative patterns not previously recognized by intelligence analysts, andł the high false positive rates that are likely to result from the problems in the rst two bullets.a number of approaches can be taken to possibly address this argument. for example, as mentioned above, it may be possible to develop training sets by broadening the denition of what patterns of behavior are of interest for further investigation, although that raises the false positive rate. also, it may be possible to reduce the rate of false positives to a manageable percentage by using a judicious mix of human analysis and different automated tools. however, this is likely to be very resource intensive. the committee does not know whether there are a large number of useful behavioral proles or patterns that are indicative of terrorist activity.in addition to these issues, a variety of practical considerations are relevant, including the paucity of data, the oftenpoor quality of primary data, and errors arising from linkage between records. (section h.2 discusses additional issues in more detail.)protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.218iillustrative government data mining programs and activityseveral federal agencies have sought to use data mining to reduce the risk of terrorism, including the department of defense (dod), the department of homeland security (dhs), the department of justice (doj), and the national security agency (nsa). some of the data mining programs have been withdrawn; some are in operation; some have changed substantially in scope, purpose, and practice since they were launched; and others are still in development. this appendix brie˚y describes a number of the programs, their stated goals, and their current status (as far as is known publicly).1 the programs described vary widely in scope, purpose, and sophistication. some are research efforts focused on the fundamental science of data mining; others are intended as efforts to create general toolsets and developer toolkits that could be tailored to meet various requirements. most of the programs constitute specic deployments of one or more forms of data mining technology intended to achieve particular 1a 2004 u.s. government accountability ofce (gao) report provided a comprehensive survey of data mining systems and activities in federal agencies up to that time. see gao, data mining: federal efforts cover a wide range of uses, gao04548, gao, washington, d.c., may 2004. other primary resources: j.w. seifert, data mining and homeland security: an overview, rl31798, congressional research service, washington, d.c., updated june 5, 2007; u.s. department of homeland security (dhs), ﬁdata mining report: dhs privacy ofce response to house report 108774,ﬂ dhs, washington, d.c., july 6, 2006; dhs ofce of inspector general, ﬁsurvey of dhs data mining activities,ﬂ oig0656, dhs, washington, d.c., august 2006. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 219operational goals. the programs vary widely in sophistication of the technologies used to achieve operational goals; they also vary widely in the sources of data used (such as government data, proprietary information from industry groups, and data from private data aggregators) and in the forms of the data (such as structured and unstructured). the array of subject matter of the projects is broad: they cover law enforcement, terrorism prevention and preemption, immigration, customs and border control, nancial transactions, and international trade. indeed, the combination of the variety of applications and the variety of denitions of what constitutes data mining make any overall assessment of data mining programs difcult. the scientic basis of many of these programs is uncertain or at least not publicly known. for example, it is not clear whether any of the programs have been subject to independent expert review of performance. this appendix is intended to be primarily descriptive, and the mention of a given program should not be taken as an endorsement of its underlying scientic basis.i.1 total/terrorism information awareness (tia) status: withdrawn as such, but see appendix j for a description.i.2 computerassisted passenger prescreening system ii (capps ii) and secure flight status: capps ii abandoned; secure flight planned for deployment in 2008.in creating the transportation security administration (tsa), congress directed that it implement a program to match airline passengers against a terrorist watch list. capps ii was intended to fulll that directive. it was dened as a prescreening system whose purpose was to enable tsa to assess and authenticate travelers™ identities and perform a risk assessment to detect persons who may pose a terroristrelated threat. however, it went beyond the narrow directive of checking passenger information against a terrorist watch list and included, for instance, assessment of criminal threats. according to the dhs fact sheet on the program, capps ii was to be an integral part of its layered approach to security, ensuring that travelers who are known or potential threats to aviation are stopped before they or their baggage board an aircraft.2 it 2 u.s. department of homeland security, ﬁfact sheet: capps ii at a glance,ﬂ february 13, 2004, available at http://www.dhs.gov/xnews/releases/pressrelease0347.shtm. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.220 protecting individual privacy in the struggle against terroristswas meant to be a rulebased system that used information provided by the passenger (name, address, telephone number, and date of birth) when purchasing an airline ticket to determine whether the passenger required additional screening or should be prohibited from boarding. capps ii would have examined both commercial and government databases to assess the risk posed by passengers. in an effort to address privacy and security concerns surrounding the program, dhs issued a press release about what it called myths and facts about capps ii.3 for instance, it stated that retention of data collected would be limitedšthat all data collected and created would be destroyed shortly after the completion of a traveler™s itinerary. it also said that no data mining techniques would be used to prole and track citizens, although assessment would have extended beyond checking against lists and would have included examining a wide array of databases. a study by gao in 2004 found that tsa was sufciently addressing only one of eight key issues related to implementing capps ii.4 the study found that accuracy of data, stress testing, abuse prevention, prevention of unauthorized access, policies for operation and use, privacy concerns, and a redress process were not fully addressed by capps ii. despite efforts to allay concerns, capps ii was abandoned in 2004. it was replaced in august 2004 with a new program called secure flight.secure flight is designed to fulll the congressional directive while attempting to address a number of concerns raised by capps ii. for instance, unlike capps ii, secure flight makes tsa responsible for crosschecking passenger ˚ight information with classied terrorist lists rather than allowing such checking to be done by contracted vendors. although the possibility of using commercial databases to check for threats is still included, the use of commercial data is now precluded.5 other differences between capps ii and secure flight include limiting screening to checking for terrorism threats, not criminal offenses (although this was initially included), and using only historical data during testing phases. tsa states that the mission of secure flight is ﬁto enhance the security of domestic commercial air travel within the united states through the 3 u.s. department of homeland security, ﬁcapps ii: myths and facts,ﬂ february 13, 2004, available at http://www.dhs.gov/xnews/releases/pressrelease0348.shtm. 4 u.s. government accountability ofce (gao), aviation security: computerassisted passenger prescreening system faces signicant implementation challenges, gao04385, gao, washington, d.c., february 2004.5 u.s. transportation security administration, ﬁsecure flight: privacy protection,ﬂ available at http://www.tsa.gov/whatwedo/layers/secure˚ight/secure˚ightprivacy.shtm. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 221use of improved watch list matching.ﬂ6 according to tsa, when implemented, secure flight would:decrease the chance of compromising watchlist data by centralizing use of comprehensive watch lists.provide earlier identication of potential threats, allowing for expedited notication of lawenforcement and threatmanagement personnel.provide a fair, equitable, and consistent matching process among all aircraft operators.offer consistent application of an expedited and integrated redress process for passengers misidentied as posing a threat. however, secure flight has continued to raise concerns about privacy, abuse, and security. a 2006 gao study of the program found that although tsa had made some progress in managing risks associated with developing and deploying secure flight, substantial challenges remained.7 after publication of the study report, tsa announced that it would reassess the program and make changes to address concerns raised in the report. the 2006 dhs privacy ofce report on data mining did not include an assessment of secure flight; it stated that searches or matches are done with a known name or subject and thus did not meet the denition of data mining used in the report.8 in a prepared statement before the senate committee on commerce, science, and transportation in january 2007, the tsa administrator noted progress in addressing those concerns and the intention to make the program operational by some time in 2008.9 most recently, dhs secretary michael chertoff announced that secure flight would no longer include data mining and would restrict information collected about passengers to full name and, optionally, date of birth and sex. chertoff stated that secure flight will not collect commercial data, assign risk scores, or attempt to predict behavior, as was 6 u.s. transportation security administration, ﬁsecure flight: layers of security,ﬂ available at http://www.tsa.gov/whatwedo/layers/secure˚ight/index.shtm. 7 u.s. government accountability ofce (gao), aviation security: signicant management challenges may adversely affect implementation of the transportation security administration™s secure flight program, gao06374t, gao, washington, d.c., february 9, 2006.8 u.s. department of homeland security (dhs), ﬁdata mining report: dhs privacy ofce response to house report 108774,ﬂ july 6, 2006; dhs ofce of inspector general, survey of dhs data mining activities, oig0656, dhs, washington, d.c., august 2006, p. 20, footnote 25.9 prepared statement of kip hawley, assistant secretary of the transportation security administration before the u.s. senate committee on commerce, science and transportation, january 17, 2007, available at http://www.tsa.gov/press/speeches/aircargotestimony.shtm. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.222 protecting individual privacy in the struggle against terroristsenvisioned in earlier versions of the program.10 the information provided will be compared with a terrorist watch list. i.3 multistate antiterrorism information exchange (matrix) status: pilot program ended; no followon program started.this program was an effort to support informationsharing and collaboration among lawenforcement agencies.11 it was run as a pilot project administered by the institute for intergovernmental research for dhs and doj.12 matrix involved collaborative informationsharing between public, private, and nonprot institutions. a congressional research service (crs) report described matrix as a project that ﬁleverages advanced computer/information management capabilities to more quickly access, share, and analyze public records to help law enforcement generate leads, expedite investigations, and possibly prevent terrorist attacks.ﬂ13 the matrix system was developed and operated by a private floridabased company, and the florida department of law enforcement controlled access to the program and was responsible for the security of the data.14 although ﬁterrorismﬂ is part of the program name, the primary focus appears to have been on law enforcement and criminal investigation. until the system was redesigned, participating states were required to transfer stateowned data to a private company.15 the core function of the system was the factual analysis criminal threat solution (facts) application used to query disparate data sources by using available investigative information, such as a portion of a vehicle license number, to combine records dynamically to identify people of potential interest. according 10 michael j. sniffen, ﬁfeds off simpler ˚ight screening plan,ﬂ associated press, august 9, 2007.11u.s. department of homeland security (dhs), ﬁmatrix report: dhs privacy ofce report to the public concerning the multistate antiterrorism information exchange,ﬂ dhs, washington, d.c., december 2006, p. 1. 12the institute for intergovernmental research (iir) is a floridabased nonprot research and training organization specializing in law enforcement, juvenile justice, criminal justice, and homeland security. see http://www.iir.com/default.htm.13w.j. krouse, the multistate antiterrorism information exchange (matrix) pilot project, rl32536, u.s. congressional research service (crs), washington, d.c., august 18, 2004, p. 1, italics original. note that the ofcial web site for matrix program cited in this crs report is no longer available.14ibid., p. 2. the company, seisint, was acquired by reed elsevier subsidiary lexisnexis in july 2004.15j. rood, ﬁcontroversial datamining project nds ways around privacy laws,ﬂ cq homeland securityšintelligence, july 23, 2004, p. 1.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 223to the crs report, facts included crimemapping, associationcharting, lineup and photograph montage applications, and extensive query capabilities.16 data sources available in the system included both those traditionally available to law enforcementšsuch as criminal history, correctionsdepartment information, driver™s license, and motorvehicle datašand nontraditional ones, such as:17 pilot licenses issued by the federal aviation administration,aircraft ownership,property ownership,u.s. coast guard vessel registrations,state sexualoffender lists,corporate lings,uniform commercial code lings or business liens,bankruptcy lings, andstateissued professional licenses. concerns were raised that the data would be combined with private data, such as credit history, airline reservations, and telephone logs; but the matrix web site stated those would not be included. the system initially included a scoring system called high terrorist factor (htf) that identied people who might be considered highrisk, although it was later claimed that the htf element of the system had been eliminated.18the pilot program ended in april 2005. legal, privacy, security, and technical concerns about requirements to transfer stateowned data to matrix administrators and continuing costs associated with using the system prompted several states that initially participated or planned to participate in matrix to withdraw.19 by march 2004, 11 of the 16 states that originally expressed interest in participating had withdrawn from the program. in an attempt to address some of the concerns, the architecture was changed to allow distributed access to data in such a way that no 16 krouse, op. cit., p. 4.17 data sources are identied in the congressional research service report (krouse, op. cit., p. 6) as referenced from the ofcial matrix program web site, http://www.matrixat.org, which is no longer available.18 b. bergstein, ﬁdatabase rm gave feds terror suspects: ‚matrix™ developer turned over 120,000 names,ﬂ associated press, may 20, 2004, available at http://www.msnbc.msn.com/id/5020795/.19 see, for instance, georgia department of motor vehicle safety, ﬁdepartment of motor vehicle safety™s participation in matix,ﬂ september 29, 2003; new york state police, letter to chairman of matrix, march 9, 2004; texas department of public safety, letter to chair, project matrix, may 21, 2003. those documents and additional information on state involvement are available from the american civil liberties union (aclu) web site at http://www.aclu.org/privacy/spying/15701res20050308.html. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.224 protecting individual privacy in the struggle against terroristsdata transfers from statecontrolled systems would be required to share data.20 the crs report concluded that ﬁit remains uncertain whether the matrix pilot project is currently designed to assess and address privacy and civil liberty concerns.ﬂ21 for instance, there appears to have been no comprehensive plan to put safeguards and policies in place to avoid potential abuses of the system, such as monitoring of activities of social activists or undermining of political activities.22i.4 able danger status: terminated in january 2001.this classied program established in october 1999 by the u.s. special operations command and ended by 2001 called for the use of data mining tools to gather information on terrorists from government databases and from open sources, such as the world wide web.23 the program used link analysis to identify underlying connections between people.24 analysis would then be used to create operational plans designed to disrupt, capture, and destroy terrorist cells. link analysis is a form of network analysis that uses graph theory to identify patterns and measure the nature of a network. the related socialnetwork analysis is now considered a critical tool in sociology, organizational studies, and information sciences. cohesion, betweenness, centrality, clustering coefcient, density, and path length are some of the measures used in network analysis to model and quantify connections. the combination of complex mathematics and the enormous volumes of data required to gain an accurate and complete picture of a network make the use of information technology critical if useful analysis is to be performed on a large scale. several networkmapping software packages are available commercially. applications include fraud detection, relevance ratings in internet search engines, and epidemiology.20 rood, op. cit., p. 1.21 krouse, op. cit., p. 10.22 ibid., p. 8.23 u.s. department of defense (dod) ofce of the inspector general, ﬁreport of investigation: alleged misconduct by senior dod ofcials concerning the able danger program and lieutenant colonel anthony a. shaffer, u.s. army reserve,ﬂ case number h05l97905217, dod, washington, d.c., september 18, 2006. 24 ﬁlink analysisﬂ was an informal term used to describe the analysis of connections between individuals rather than any kind of formal ﬁrecord linkageﬂ between database records.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 225able danger was focused specically on mapping and analyzing relationships within and with al qaeda. the program became public in 2005 after claims made by rep. curt weldon that able danger had identied 9/11 hijacker mohammad atta before the attack surfaced in the mass media. a member of able danger, anthony shaffer, later identied himself as the source of weldon™s information.25 he further claimed that intelligence discovered as part of able danger was not passed on to federal bureau of investigation (fbi) and other civilian ofcials. shaffer said a key element of able danger was the purchase of data from information brokers that identied visits by individuals to specic mosques.26 that information was combined with other data to identify patterns and potential relationships among alleged terrorists. claims made by shaffer were refuted in a report written by the dod inspector general.27 the report showed examples of the types of charts produced by link analysis.28 it characterized able danger operations as initially an effort to gain familiarity with stateoftheart analytical tools and capabilities and eventually to apply link analysis to a collection of data from other agencies and from public web sites to understand al qaeda infrastructure and develop a strategy for attacking it.29 the program was then terminated, having achieved its goal of developing a (stillclassied) ﬁcampaign planﬂ that ﬁformed the basis for followon intelligence gathering efforts.ﬂ30 an investigation by the senate select committee on intelligence concluded that able danger had not identied any of the 9/11 hijackers before september 11, 2001.31no followon intelligence effort using linkanalysis techniques developed by able danger has been publicly acknowledged. however, the existence of a program known as able providence supported through the ofce of naval intelligence, which would reconstitute and improve 25 cable news network, ﬁofcer: 9/11 panel didn™t receive key information,ﬂ august 17, 2005, available at http://www.cnn.com/2005/politics/08/17/sept.11.hijackers. 26 j. goodwin, ﬁinside able dangeršthe secret birth, extraordinary life and untimely death of a u.s. military intelligence program,ﬂ government security news, september 5, 2005, available at http://www.gsnmagazine.com/cms/lib/410.pdf. 27u.s. department of defense ofce of the inspector general, ﬁreport of investigation: alleged misconduct by senior dod ofcials concerning the able danger program and lieutenant colonel anthony a. shaffer, u.s. army reserve,ﬂ case number h05l97905217, september 18, 2006.28 ibid., pp. 89.29 ibid., p. 14.30 ibid.31 g. miller, ﬁalarming 9/11 claim is baseless, panel says,ﬂ los angeles times, december 24, 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.226 protecting individual privacy in the struggle against terroristson able danger, was reported by weldon in testimony to the u.s. senate committee on the judiciary as part of its investigation.32i.5 analysis, dissemination, visualization, insight, and semantic enhancement (advise) status: under development (some deployments decommissioned).this program, being developed by dhs, was intended to help to detect potentially threatening activities by using link analysis of large amounts of data and producing graphic visualizations of identied linkage patterns. it was one of the most ambitious data mining efforts being pursued by dhs. advise was conceived as a data mining toolset and development kit on which applications could be built for deployment to address specic needs. an assessment of advise was not included in the 2006 dhs privacy ofce report on data mining, because it was considered a tool or technology and not a specic implementation of data mining.33 that position was noted in a gao report on the program that questioned the decision not to include a privacy assessment of the program, given that ﬁthe tool™s intended uses include applications involving personal information, and the egovernment act, as well as related ofce of management and budget and dhs guidance, emphasize the need to assess privacy risks early in systems development.ﬂ34the gao report identied the program™s intended benet as helping to ﬁdetect activities that threaten the united states by facilitating the analysis of large amounts of data that otherwise would be very difcult to review,ﬂ noting that the tools developed as part of advise are intended to accommodate both structured and unstructured data.35 the report concluded that advise raised a number of privacy concerns and that although dhs had added security controls related to advise, it had failed to assess privacy risks, including erroneous associations of people, misidentication of people, and repurposing of data collected for other 32 representative curt weldon in testimony to the united states senate committee on the judiciary, september 21, 2005, available at http://judiciary.senate.gov/testimony.cfm?id=1606&witid=4667. see also p. wait, ﬁdatamining offensive in the works,ﬂ government computer news, october 10, 2005. 33 u.s. department of homeland security (dhs), ﬁdata mining report: dhs privacy ofce response to house report 108774,ﬂ dhs, washington, d.c., july 6, 2006; dhs ofce of inspector general, ﬁsurvey of dhs data mining activities,ﬂ oig0656, dhs, washington, d.c., august 2006, p. 20, footnote 25.34 u.s. government accountability ofce (gao), data mining: early attention to privacy in developing a key dhs program could reduce risks, gao07293, gao, washington, d.c., february 2007, p. 3.35 ibid., p. 3.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 227purposes.36 it called on dhs ﬁto conduct a privacy impact assessment of the advise tool and implement privacy controls as needed to mitigate any identied risks.ﬂ37dhs responded to the gao report, saying that it was in the process of developing a privacy impact assessment tailored to the unique character of the advise program (as a tool kit). a later dhs privacy ofce report did review the advise program and drew a careful distinction between advise as a technology framework and advise deployments.38 the report rst reviewed the technology framework in light of privacy compliance requirements of the dhs privacy ofce described in the report.39 in light of those requirements, it then assessed six planned deployments of advise:40interagency center for applied homeland security technology (icahst). icahst evaluates promising homelandsecurity technologies for dhs and other government stakeholders in the homelandsecurity technology community.allweapons of mass effect (allwme). originally begun by the department of energy, allwme used classied message trafc collected by the national laboratories™ eld intelligence elements to analyze information related to foreign groups and organizations involved in wme material ˚ows and illicit trafcking. deployment has been discontinued. biodefense knowledge management system. this was a series of three deployment initiatives planned by the biodefense knowledge center with the overall goal of identifying better methods for assisting dhs analysts in identifying and characterizing biological threats posed by terrorists. all the deployments have ended, and there are no plans for future deployments.remote threat alerting system (rtas). rtas sought to determine whether the advise technology framework could assist dhs customs and border protection (cbp) in identifying anomalous shipments on the basis of cargo type and originating country. all rtas activities ended in september 2006.immigration and customs enforcement demonstration (ice demo). this deployment was operated by the dhs science and technology director36 ibid., p. 18.37 ibid., from ﬁhighlights: what gao recommends.ﬂ see also p. 23.38 u.s. department of homeland security, ﬁdhs privacy ofce review of the analysis, dissemination, visualization, insight and semantic enhancement (advise) program,ﬂ dhs, washington, d.c., july 11, 2007. page 2 discusses and denes these terms.39 ibid., pp. 35.40 ibid. denitions and descriptions of these programs are drawn from the report beginning on p. 7.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.228 protecting individual privacy in the struggle against terroristsate and lawrence livermore national laboratory to determine whether the advise technology framework could assist dhs immigration and customs enforcement (ice) in using existing ice data better. all activity related to this deployment of advise has ended.threat vulnerability integration system (tvis). tvis used a series of data sets to identify opportunities to test the capability of the advise technology framework to help analysts in the dhs ofce of intelligence and analysis. early pilot deployment phases have been followed by subsequent pilot deployment phases.the report found that some of the deployments did use personally identiable information without conducting privacy impact assessments.41 it also recommended short and longterm actions to address the problems. in particular, it recommended actions that would integrate privacy compliance requirements into project development processes, echoing recommendations made in the gao report on the program.42 dhs ended the program in september 2007, citing the availability of commercial products to provide similar functions at much lower cost.43 i.6 automated targeting system (ats) status: in use.this program is used by cbp, part of dhs, to screen cargo and travelers entering and leaving the united states by foot, car, airplane, ship, and rail. ats aassess risks by using data mining and dataanalysis techniques. the risk assessment and links to information on which the assessment is based are stored in the ats for up to 40 years.44 the assessment is based on combining and analyzing data from several existing sources of informationšincluding the automated commercial system, the automated commercial environment system, the advance passenger information system, and the treasury enforcement communications systemšand from people crossing the u.s. land border known (the passenger name record).ats compares a traveler™s name with a list of known and suspected 41 ibid., p. 1.42 u.s. government accountability ofce (gao), data mining: early attention to privacy in developing a key dhs program could reduce risks, gao07293, gao, washington, d.c., february 2007. see especially p. 24.43 m.j. sniffen, ﬁdhs ends criticized datamining program,ﬂ washington post, september 5, 2007. 44 u.s. department of homeland security, ﬁnotice of privacy act system of records,ﬂ federal register 71(212): 6454364546, november 2, 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 229terrorists. it also performs link analysis, checking, for example, the telephone number associated with an airline reservation against telephone numbers used by known terrorists.45 such checking has been credited by dhs with preventing entry of suspected terrorists and with identifying criminal activity,46 but concerns about high numbers of false alarms, efcacy of the risk assessment, lack of a remediation process, and ability of the agency to protect and secure collected data properly have been raised by some in the technical community and by civilliberties groups.47i.7 the electronic surveillance program status: continuing subject to oversight by the foreign intelligence surveillance court.this program, also called the terrorist surveillance program, involves the collection and analysis of domestic telephonecall information with the goal of targeting the communications of al qaeda and related terrorist groups and afliated individuals. details about the program remain secret, but as part of the program the president authorized nsa to eavesdrop on communications of people in the united states without obtaining a warrant when there is ﬁreasonable basis to conclude that one party to the communication is a member of al qaeda.ﬂ48 existence of the program rst surfaced in a new york times article published in december 2005.49 questions as to the legality of the program led a federal judge to declare the program unconstitutional and illegal and to order that it be suspended. that ruling was overturned on appeal on narrow grounds regarding the standing of the litigants rather than the legality of the program.50 in a letter to the senate committee on the 45 remarks of stewart baker, assistant secretary for policy, department of homeland security at the center for strategic and international studies, washington, d.c., december 19, 2006.46 ibid. baker noted the use of ats to identify a childsmuggling ring. cbp ofcers who examined ats data noticed that a woman with children had not taken them with her on the outbound ˚ight; this led to further investigation.47 see, for instance, b. schneier, ﬁon my mind: they™re watching,ﬂ forbes, january 8, 2007; electronic privacy information center, automated targeting system, http://www.epic.org/privacy/travel/ats/default.html. 48 press brieng by attorney general alberto gonzales and general michael hayden, principal deputy director for national intelligence, december 19, 2005, available at http://www.whitehouse.gov/news/releases/2005/12/200512191.html. 49 j. risen and e. lichtblau, ﬁbush lets u.s. spy on callers without courts,ﬂ new york times, december 16, 2005.50 a. goldstein, ﬁlawsuit against wiretaps rejected,ﬂ the washington post, july 7, 2007, p. a1. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.230 protecting individual privacy in the struggle against terroristsjudiciary on january 17, 2007, attorney general alberto gonzales stated that the program would not be reauthorized by the president although the surveillance program would continue subject to oversight by the foreign intelligence surveillance court (fisc). although the legality of the program has been the primary focus of the press, it is unclear to what extent data mining technology is used as part of the program. some press reports suggest that such technology is used extensively to collect and analyze data from sources that include telephone and internet communication, going well beyond keyword searches to use link analysis to uncover hidden relationships among data points.51 the adequacy of the fisc to address technology advances, such as data mining and trafcanalysis techniques, has also been called into question.52as this report is being written (june 2008), changes in the foreign intelligence surveillance act are being contemplated by congress. the nal disposition of the changes is not yet known.i.8 novel intelligence from massive data (nimd) program status: in progress.nimd is a research and development program funded by the disruptive technology ofce,53 which is part of the ofce of the director of national intelligence. the program, which has many similarities to the total/terrorism information awareness program, is focused on the development of data mining and analysis tools to be used in working with massive data. according to a ﬁcall for 2005 challenge workshop proposals,ﬂ ﬁnimd aims to preempt strategic surprise by addressing root causes of analytic errors related to bias, assumptions, and premature attachment to a single hypothesis.ﬂ54 two key challenges are identied: data triage to support decisionmaking and realtime analysis of petabytes of data and practical knowledge representation to improve machine processing and 51 e. lichtblau and j. risen, ﬁspy agency mined vast data trove, ofcial report,ﬂ new york times, december 23, 2005; s. harris, ﬁnsa spy program hinges on stateoftheart technology,ﬂ national journal, january 20, 2006.52 see, for instance, k.a. taipale, ﬁwhispering wires and warrantless wiretaps: data mining and foreign intelligence surveillance,ﬂ nyu review of law and security, issue 7, supplemental bulletin on law and security, spring 2006.53 the disruptive technology ofce was previously known as the advanced research and development activity (arda).54 advanced research development activity, ﬁcall for 2005 challenge workshop proposals,ﬂ available at http://nrrc.mitre.org/ardaexplorprog2005cfp.pdf. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 231datasharing among disparate agencies and technologies. the challenge identies ve focus areas for nimd research with the overarching goal of building ﬁsmart software assistants and devil™s advocates that help analysts deal with information overload, detect early indicators of strategic surprise, and avoid analytic errorsﬂ: ﬁmodeling analysts and analytic processes, capturing and reusing prior and tacit knowledge, generating and managing hypotheses, organizing/structuring massive data (mostly unstructured text), and human interaction with information.ﬂ advocacy groups and some members of congress have expressed concerns that at least some of the research done as part of the tia program has continued under nimd.55 in contrast with tia, congress stipulated that technologies developed under the program are to be used only for military or foreign intelligence purposes against nonu.s. citizens. i.9 enterprise data warehouse (edw)status: operational since 2000 and in use.this system collects data from cbp transactional systems and subdivides them into data sets for analysis.56 the data sets are referred to as data marts. their creation is predicated on the need for a specic grouping and conguration of selected data.57 edw acquires and combines data from several customs and other federal databases to perform statistical and trend analysis to look for patterns, for instance, to determine the impact of an enforcement action or rule change.58 edw uses commercial offtheshelf technology for its analysis.59 edw data are treated as read55 ﬁu.s. still minding terror data,ﬂ associated press, washington, d.c., february 23, 2004; m. williams, ﬁthe total information awareness project lives on,ﬂ technology review, april 26, 2006. 56 u.s. department of homeland security (dhs), ﬁdata mining report: dhs privacy ofce response to house report 108774,ﬂ july 6, 2006, pp. 2021. 57 an explanation of the distinction between a data warehouse and a data mart is provided as a footnote in dhs ofce of inspector general, ﬁsurvey of dhs data mining activities,ﬂ oig0656, august 2006, p. 11.58 see u.s. customs and border protection, ﬁu.s. customs data warehousing,ﬂ available at http://www.cbp.gov/xp/cgov/trade/automated/automatedsystems/datawarehousing.xml; databases used as sources include automated commercial system (acs), automated commercial environment (ace), treasury enforcement communications system (tecs), administrative and financial systems, the automated export system. see u.s. customs, ﬁenterprise data warehouse: where it stands, where it™s heading,ﬂ u.s. customs today, august 2000, available at http://www.cbp.gov/custoday/aug2000/dwartic4.htm.59 u.s. department of homeland security (dhs), ﬁdata mining report: dhs privacy ofce response to house report 108774,ﬂ dhs, washington, d.c., july 6, 2006, p. 21. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.232 protecting individual privacy in the struggle against terroristsonly; all changes occur in source systems propagated to it periodically (every 24 hours).60i.10 law enforcement analytic data system (netleads) status: in use.this program facilitates ice lawenforcement activities and intelligence analysis capabilities through the use of searches and pattern recognition based on multiple data sources.61 as with edw, netleads uses data marts. link analysis is used to show relationships, such as associations with known criminals. information analyzed includes criminalalien information and terrorism, smuggling, and criminalcase information derived from federal and state government lawenforcement and intelligence agencies™ data sources and commercial sources.62 the technology includes timeline analysis, which allows comparisons of relationships at different times. trend analysis across multiple cases can also be performed in the context of particular investigations and intelligence operations.i.11 ice pattern analysis and information collection system (icepic)  status: operating as pilot program as of july 2006; planned to enter fullscale operation in scal year 2008.63whereas the netleads focus is on law enforcement, icepic focuses on the goal of disrupting and preventing terrorism.64 link analysis is performed to uncover nonobvious associations between individuals and organizations to generate counterterrorism leads. data for analysis is drawn from dhs sources and from databases maintained by the department of state, doj, and the social security administration. icepic uses technology from ibm called nonobvious relationships awareness (nora) to perform the analysis.65 icepic, netleads, and two other systemsšthe data analysis and research for trade transparency system 60 ibid.61 ibid., pp. 2124. 62 ibid., pp. 2223.63 immigration and customs enforcement fact sheet, http://www.ice.gov/pi/news/factsheets/icepic.htm.64 u.s. department of homeland security ofce of inspector general, ﬁsurvey of dhs data mining activities,ﬂ oig0656, dhs, washington, d.c., august 2006, p. 11.65 u.s. department of homeland security (dhs), ﬁdata mining report: dhs privacy ofce response to house report 108774,ﬂ dhs, washington, d.c., july 6, 2006, pp. 2426.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 233(dartts) and the crew vetting system (cvs)šall use association, the process of discovering two or more variable that are related, as part of the analysis.66 i.12 intelligence and information fusion (i2f) status: in development.using commercial offtheshelf systems, this program uses tools for searching, link analysis, entity resolution, geospatial analysis, and temporal analysis to provide intelligence analysts with an ability to view, query, and analyze information from multiple data sources.67 the program is focused on aiding in discovery and tracking of terrorism threats to people and infrastructure. with three other dhs programsšnumerical integrated processing system (nips), questioned identication documents (qid), and tactical information sharing system (tiss)ši2f uses collaboration processes that support application of crossorganizational expertise and visualization processes that aid in presentation of analysis results.68 data may be drawn from both government and commercial sources.i.13 fraud detection and national security data system (fdnsds) status: in use but without analytical tools to support data mining; support for data mining capabilities not expected for at least 2 years.this program (formerly the fraud tracking system) is used to track immigrationrelated fraud, publicsafety referrals to ice, and nationalsecurity concerns discovered during background checks.69 in its present form, fdnsds is a casemanagement system with no analytical or data mining tools. it is planned to add those capabilities to allow identication of fraudulent schemes.66 u.s. department of homeland security ofce of inspector general, ﬁsurvey of dhs data mining activities,ﬂ oig0656, dhs, washington, d.c., august 2006, pp. 911.67 u.s. department of homeland security (dhs), ﬁdata mining report: dhs privacy ofce response to house report 108774,ﬂ dhs, washington, d.c., july 6, 2006, p. 26.68 u.s. department of homeland security ofce of inspector general, ﬁsurvey of dhs data mining activities,ﬂ oig0656, dhs, washington, d.c., august 2006, p. 13.69 u.s. department of homeland security (dhs), ﬁdata mining report: dhs privacy ofce response to house report 108774,ﬂ dhs, washington, d.c., july 6, 2006, p. 27.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.234 protecting individual privacy in the struggle against terroristsi.14 national immigration information sharing office (niiso)  status: in use without data mining tools; pilot project that includes data mining capabilities being planned.this program is responsible for fullling requests for immigrationrelated information from other dhs components and lawenforcement and intelligence agencies.70 the program does not include any data mining tools and techniques, relying instead on manual searches based on specic requests to supply information to authorized requesting agencies. plans to add such analytical capabilities are being developed. data for analysis would include data collected by immigration services, publicly available information, and data from commercial aggregators.71i.15 financial crimes enforcement network (fincen) and bsa directstatus: fincen in use; bsa direct withdrawn.fincen applies data mining and analysis technology to data from a number of sources related to nancial transactions to identify cases of moneylaundering and other nancial elements of criminal and terrorist activity. the goal of fincen is to promote informationsharing among lawenforcement, regulatory, and nancial institutions.72 fincen is responsible for administering the bank secrecy act (bsa). as part of that responsibility, it uses data mining technology to analyze data collected on the basis of requirements of bsa and to identify suspicious activity tied to terrorists and organized crime.in 2004, fincen began a program called bsa direct intended to provide lawenforcement agencies with access to bsa data and to data mining capabilities similar to those available to fincen.73 bsa direct was permanently halted in july 2006 after cost overruns and technical implementation and deployment difculties.74 70 u.s. department of homeland security (dhs), ﬁdata mining report: dhs privacy ofce response to house report 108774,ﬂ dhs, washington, d.c., july 6, 2006, p. 28.71 ibid.72 see the fincen web site at http://www.ncen.gov/affaqs.html for further details on its mission.73 statement of robert w. werner before the house committee on government reform subcommittee on criminal justice, drug policy, and human resources, may 11, 2004, p. 3, available at http://www.ncen.gov/wernertestimonynal051104.pdf. 74 fincen, ﬁfincen halts bsa direct retrieval and sharing project,ﬂ july 13, 2006, available at http://www.ncen.gov/bsadirectnr.html. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 235i.16 department of justice programs involving patternbased data miningstatus: all programs under development or in use.responding to requirements of the usa patriot improvement and reauthorization act of 2005,75 doj submitted a report to the senate committee on the judiciary that identied seven programs that constitute patternbased data mining as dened in the act.76 the report carefully scoped what was considered patternbased data mining on the basis of the denition of the act to determine which programs it was required to report on.77 for each program identied, the report provides a description, plans for use, efcacy, potential privacy and civilliberties impact, legal and regulatory foundation, and privacy and accuracyprotection policies.78 the report notes that the scope of the programs and the detail provided vary widely. the following is a summary of the programs drawn from the doj report.79 systemtoassessrisk (star) initiative. focused on extending the capabilities of the foreign terrorist tracking task force (ftttf), this program is a riskassessment software system that is meant to help analysts to set priorities among persons of possible investigative interest. data used by star are drawn from the ftttf data mart, an existing data repository ﬁcontaining data from u.s. government and proprietary sources (e.g., travel data from the airlines reporting corporation) as well as access to publicly available data from commercial data sources (such as choicepoint).ﬂ80 star is under development.identity theft intelligence initiative. this program extracts data from the federal trade commission™s identity theft clearinghouse and compares them with fbi data from case complaints of identity theft and with suspicious nancial transactions led with fincen. further comparisons are made with data from private data aggregators, such as lexisnexis, accurint, and autotrack. on the basis of the results of the analysis, fbi creates a knowledge base to evaluate identitytheft types, identify 75 u.s. pub. l. no. 109177, sec. 126.76 u.s. department of justice, ﬁreport on ‚datamining™ activities pursuant to section 126 of the usa patriot improvement and reauthorization act of 2005,ﬂ july 9, 2007, available at http://www.epic.org/privacy/fusion/dojdataming.pdf. 77 ibid., pp. 16. 78 the report includes a review of only six of the seven initiatives identied, saying that a supplemental report on the seventh initiative will be provided at a later date.79 ibid., pp. 730. 80 ibid., p. 8. choicepoint is a private data aggregator; see http://www.choicepoint.com/index.html. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.236 protecting individual privacy in the struggle against terroristsidentitytheft rings through subject relationships, and send leads to eld ofces. the program has been operational since 2003.health care fraud initiative. this program is used by fbi analysts to research and investigate healthcare providers. the program draws data from medicare ﬁsummary billing records extracted from the centers for medicare and medicaid services (cms), supported by the cms fraud investigative database, searchpoint [the drug enforcement administration™s pharmaceuticalclaims database], and the national health care antifraud association special investigative resource and intelligence system (private insurance data).ﬂ81 the program has been in use since 2003.internet pharmacy fraud initiative. this program™s aim is to search consumer complaints (made to the food and drug administration and internet fraud complaint center) involving alleged fraud by internet pharmacies to develop common threads indicative of fraud by such pharmacies. data on internet pharmacies available from opensource aggregators are also incorporated into the analysis. the program began in december 2005 and is operational.housing fraud initiative. this program run by the fbi uses publicsource data containing buyer, seller, lender, and broker identities and property addresses purchased from choicepoint to uncover fraudulent housing purchases. all analysis is done by fbi analysts manually (that is, not aided by computer programs) to identify connections between individuals and potentially fraudulent realestate transactions. the program rst became operational in 1999 and continues to be extended by choicepoint as new real estate transaction information becomes available.automobile accident insurance fraud initiative. this program run by fbi was designed to identify and analyze information regarding automobileinsurance fraud schemes. data sources include formatted reports of potential fraudulent claims for insurance reimbursement as identied and prepared by the insurance industry™s national insurance crime bureau, fbi casereporting data, commercial data aggregators, and healthcare insurance claims information from the department of health and human services (dhhs) and the chiropractic industry. the program is being run as a pilot program in use by only one fbi eld ofce. no target date has been set for national deployment.in addition to the programs identied as meeting the denition of patternbased data mining used by the doj report, several programs were identied as potentially meeting other denitions of data mining. that report does not provide details about the programs, but it includes brief 81 ibid., p. 20. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix i 237sketches of them. the programs identied as ﬁadvanced analytical tools that do not meet the denition in section 126ﬂ and included in the doj report are as follows: 82drug enforcement administration (dea) initiatives: searchpoint. dea project that uses prescription data from insurance and cash transactions obtained commercially from choicepoint, included the prescribing ofcial (practitioner), the dispensing agent (pharmacy, clinic, hospital, and so on), and the name and quantity of the controlled substance (drug information) to conduct queries about practitioners, pharmacies, and controlled substances to identify the volume and type of controlled substances being subscribed and dispensed. automation of reports of consolidated orders system (arcos). dea uses data collected from manufacturers and distributors of controlled substances and stored in the arcos database to monitor the ˚ow of the controlled substances from their point of manufacture through commercial distribution channels to point of sale or distribution at the dispensing or retail level (hospitals, retail pharmacies, practitioners, and teaching institutions).drug theft loss (dtl) database. this is similar to arcos, but the data source is all dea controlledsubstance registrants (including practitioners and pharmacies).online investigative project (oip). oip enables dea to scan the internet in search of illegal internet pharmacies. the tool searches for terms that might indicate illegal pharmacy activity.bureau of alcohol, tobacco, firearms, and explosives initiatives:bomb arson tracking system (bats). bats enables lawenforcement agencies to share information related to bomb and arson investigations and incidents. the source of information is the various lawenforcement agencies. possible queries via bats include similarities of components, targets, or methods. bats can be used, for example, to make connections between multiple incidents with the same suspect.gangnet. this system is used to track gang members, gangs, and gang incidents in a granular fashion. it enables sharing of information among lawenforcement agencies. it can also be used to identify trends, relationships, patterns, and demographics of gangs. federal bureau of investigation initiative: durable medical equipment (dme) initiative. dme is designed to help in setting investigative priorities on the basis of analysis of suspicious claims submitted by dme providers by contractors for cms. data 82 ibid., pp. 3135. descriptions are drawn from the report.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.238 protecting individual privacy in the struggle against terroristssources include complaint reports from the cms and dhhs inspector general™s ofce and fbi databases.other doj activities:organized crime and drug enforcement task force (ocdetf) fusion center. ocdetf maintains a data warehouse named compass that contains relevant drug and related nancial intelligence information from numerous lawenforcement organizations. as stated in the report, ﬁthe goal of the data warehouse is to use crosscase analysis tools to transform multiagency information into actionable intelligence in order to support major investigations across the globe.ﬂ83investigative data warehouse (idw). managed by fbi, this warehouse enables investigators to perform efcient distributed searches of data sources across fbi. idw provides analysts with the capability to examine relationships between people, places, communication devices, organizations, nancial transactions, and caserelated information.internet crime complaint center (ic3). apartnershipbetweenfbia partnership between fbi and the national white collar crime center (nw3c), ic3 is focused on cybercrime. it provides a reporting mechanism for suspected violations. reports are entered into the ic3 database, which can then be queried to discover common characteristics of complaints.computer analysis and response team (cart) family of systems. this is a set of tools used to support computer forensics work. cart maintains a database of information collected from criminal investigations. data can be searched for similarities among conscated computer hard drives. before publication of the report, many of the programs were either unknown publicly or had unclear scopes and purposes. commenting on the doj report shortly after its delivery to the senate committee on the judiciary, senator patrick leahy commented that ﬁthis report raises more questions than it answers and demonstrates just how dramatically the bush administration has expanded the use of this technology, often in secret, to collect and sift through americans™ most sensitive personal information,ﬂ and said that the report provided ﬁan important and all too rare ray of sunshine on the department™s data mining activities and provides congress with an opportunity to conduct meaningful oversight of this powerful technological tool.ﬂ8483 ibid., p. 34.84 comment of senator patrick leahy, chairman, senate judiciary committee on department of justice™s data mining report, july 10, 2007; see http://leahy.senate.gov/press/200707/071007c.html. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.239jthe total/terrorist information awareness programj.1  a brief history1 in 2002, in the wake of the september 11, 2001, attacks, the defense advanced research projects agency (darpa) of the u.s. department of defense (dod) launched a research and development effort known as the total information awareness (tia) program. later renamed the terrorism information awareness program, tia was a research and development program intended to counter terrorism through prevention by developing and integrating information analysis, collaboration, and decisionsupport tools with languagetranslation, datasearching, patternrecognition, and privacyprotection technologies.2 the program included the development of a prototype system/network to provide an environment for integrating technologies developed in the program and as a testbed for conducting experiments. five threads for research investigation were to be pursued: secure collaborative problemsolving among disparate agencies and institutions, structured informationsearching and pattern recognition based 1 this description of the tia program is based on unclassied, public sources that are presumed to be authoritative because of their origin (for example, department of defense documents and speeches by senior program ofcials). recognizing that some aspects of the program were protected by classication, the committee believes that this description is accurate but possibly incomplete.2 defense advanced research programs agency (darpa), ﬁreport to congress regarding the terrorism information awareness program: in response to consolidated appropriations resolution, 2003, pub. l. no. 1087, division m, § 111(b),ﬂ darpa, arlington, va., may 20, 2003. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.240 protecting individual privacy in the struggle against terroristson information from a wide array of data sources, socialnetwork analysis tools to understand linkages and organizational structures, datasharing in support of decisionmaking, and languagetranslation and informationvisualization tools. a technical description of the system stressed the importance of using real data and real operational settings that were complex and huge.3the tia program sought to pursue important research questions, such as how data mining techniques might be used in nationalsecurity investigations and how technological approaches might be able to ameliorate the privacy impact of such analysis. for example, in a speech given in august 2002, john poindexter said that4iao [information awareness ofce] programs are focused on making total information awarenessštiašreal. this is a high level, visionary, functional view of the worldwide systemšsomewhat over simplied. one of the signicant new data sources that needs to be mined to discover and track terrorists is the transaction space. if terrorist organizations are going to plan and execute attacks against the united states, their people must engage in transactions and they will leave signatures in this information space. this is a list of transaction categories, and it is meant to be inclusive. currently, terrorists are able to move freely throughout the world, to hide when necessary, to nd sponsorship and support, and to operate in small, independent cells, and to strike infrequently, exploiting weapons of mass effects and media response to in˚uence governments. we are painfully aware of some of the tactics that they employ. this lowintensity/lowdensity form of warfare has an information signature. we must be able to pick this signal out of the noise. certain agencies and apologists talk about connecting the dots, but one of the problems is to know which dots to connect. the relevant information extracted from this data must be made available in largescale repositories with enhanced semantic content for easy analysis to accomplish this task. the transactional data will supplement our more conventional intelligence collection.nevertheless, authoritative information about the threats of interest to the tia program is scarce. in some accounts, tia was focused on a generalized terrorist threat. in other informed accounts, tia was premised on the notion of protecting a small number of highvalue targets in the united states, and a program of selective hardening of those targets 3 defense advanced research programs agency (darpa), total information awareness program system description document, version 1.1, darpa, arlington, va., july 19, 2002. 4 j. poindexter, overview of the information awareness ofce, remarks prepared for darpatech 2002 conference, anaheim, calif., august 2, 2002, available at http://www.fas.org/irp/agency/dod/poindexter.html. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix j 241would force terrorists to carry out attacks along particular lines, thus limiting the threats of interest and concern to tia technology.the tia program was cast broadly as one that would ﬁintegrate advanced collaborative and decision support tools; language translation; and data search, pattern recognition, and privacy protection technologies into an experimental prototype network focused on combating terrorism through better analysis and decision making.ﬂ5 regarding datasearching and pattern recognition, research was premised on the idea that . . . terrorist planning activities or a likely terrorist attack could be uncovered by searching for indications of terrorist activities in vast quantities of transaction data. terrorists must engage in certain transactions to coordinate and conduct attacks against americans, and these transactions form patterns that may be detectable. initial thoughts are to connect these transactions (e.g., applications for passports, visas, work permits, and drivers™ licenses; automotive rentals; and purchases of airline ticket and chemicals) with events, such as arrests or suspicious activities.6 as described in the dod tia report, ﬁthese transactions would form a pattern that may be discernable in certain databases to which the u.s government would have lawful access. specic patterns would be identied that are related to potential terrorist planning.ﬂ7furthermore, the program would focus on analyzing nontargeted transaction and event data en masse rather than on collecting information on specic individuals and trying to understand what they were doing. the intent of the program was to develop technology that could discern event and transaction patterns of interest and then identify individuals of interest on the basis of the events and transactions in which they participated. once such individuals were identied, they could be investigated or surveilled in accordance with normal and ordinary lawenforcement and counterterrorism procedures.the driving example that motivated tia was the set of activities of the 9/11 terrorists who attacked the world trade center. in retrospect, it was discovered that they had taken actions that together could be seen 5 defense advanced research programs agency (darpa), ﬁreport to congress regarding the terrorism information awareness program: in response to consolidated appropriations resolution, 2003, pub. l. no. 1087, division m, § 111(b),ﬂ darpa, arlington, va., may 20, 2003.6 darpa. defense advanced research projects agency™s information awareness ofce and terrorism information awareness project. available at http://www.taipale.org/references/iaotia.pdf.7 defense advanced research programs agency (darpa), ﬁreport to congress regarding the terrorism information awareness program: in response to consolidated appropriations resolution, 2003, pub. l. no. 1087, division m, § 111(b),ﬂ may 20, 2003, p. 14.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.242 protecting individual privacy in the struggle against terroristsas predictors of the attack even if no single action was unlawful. among those actions were ˚ight training (with an interest in level ˚ight but not in takeoff and landing), the late purchase of oneway air tickets with cash, foreign deposits into banking accounts, and telephone records that could be seen to have connected the terrorists. if the actions could have been correlated before the fact, presumably in some automated fashion, suspicions might have been aroused in time to foil the incident before it happened.because the tia program was focused on transaction and event data that were already being collected and resident in various databases, privacy implications generally associated with the collection of data per se did not arise. but the databases were generally privately held, and many privacy questions arose because the government would need access to the data that they contained. the databases also might have contained the digital signatures of most americans as they conducted their everyday lives, and this gave rise to many concerns about their vast scope. after a short period of intense public controversy, congress took action on the tia program in 2003. section 8131 of h.r. 2658, the department of defense appropriations act of 2004, specied that(a) notwithstanding any other provision of law, none of the funds appropriated or otherwise made available in this or any other act may be obligated for the terrorism information awareness program: provided, that this limitation shall not apply to the program hereby authorized for processing, analysis, and collaboration tools for counterterrorism foreign intelligence, as described in the classied annex accompanying the department of defense appropriations act, 2004, for which funds are expressly provided in the national foreign intelligence program for counterterrorism foreign intelligence purposes.(b) none of the funds provided for processing, analysis, and collaboration tools for counterterrorism foreign intelligence shall be available for deployment or implementation except for: (1) lawful military operations of the united states conducted outside the united states; or (2) lawful foreign intelligence activities conducted wholly overseas, or wholly against nonunited states citizens.(c) in this section, the term ﬁterrorism information awareness programﬂ means the program known either as terrorism information awareness or total information awareness, or any successor program, funded by the defense advanced research projects agency, or any other department or element of the federal government, including the individual components of such program developed by the defense advanced research projects agency.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix j 243it is safe to say that the issues raised by the tia program have not been resolved in any fundamental sense. though the program itself was terminated, much of the research under it was moved from darpa to another group, which builds technologies primarily for the national security agency, according to documents obtained by the national journal and to intelligence sources familiar with the move. the names of key projects were changed, apparently to conceal their identities, but their funding remained intact, often under the same contracts.8 the immediate result, therefore, of congressional intervention was to drive the development and deployment of data mining at dod from public view, relieve it of the statutory restrictions that had previously applied to it, block funding for research into privacyenhancing technologies, and attenuate the policy debate over the appropriate roles and limits of data mining. law and technology scholar k.a. taipale wrote:9at rst hailed as a ﬁvictoryﬂ for civil liberties, it has become increasingly apparent that the defunding [of tia] is likely to be a pyrrhic victory. . . . not proceeding with a focused government research and development project (in which congressional oversight and a public debate could determine appropriate rules and procedures for use of these technologies and, importantly, ensure the development of privacy protecting technical features to support such policies) is likely to result in little security and, ultimately, brittle privacy protection. . . . indeed, following the demise of iao and tia, it has become clear that similar data aggregation and automated analysis projects exist throughout various agencies and departments not subject to easy review.thus, many other data mining activities supported today by the u.s. government continue to raise the same issues as did the tia program: the potential utility of largescale databases containing personal information for counterterrorism and lawenforcement purposes and the potential privacy impact of the use of such databases by lawenforcement and nationalsecurity authorities. j.2  a technical perspective on tia™s approach to protecting privacyas noted above, managers of the tia program understood that their approach to identifying terrorists before they acted had major privacy implications. to address privacy issues in tia and similar programs, such 8 s. harris, ﬁtia lives on,ﬂ national journal, february 23, 2006, available at http://nationaljournal.com/about/njweekly/stories/2006/0223nj1.htm#.9 k.a. taipale, ﬁdata mining and domestic security: connecting the dots to make sense of data,ﬂ columbia science and technology law review 5(2):183, 2003.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.244 protecting individual privacy in the struggle against terroristsas matrix, tygar10 and others have advocated the use of what has come to be called selected revelation, involving something like the riskutility tradeoff in statistical disclosure limitation. sweeney11 used the term to describe an approach to disclosure limitation that allows data to be shared for surveillance purposes ﬁwith a sliding scale of identiability, where the level of anonymity matches scientic and evidentiary need.ﬂ that corresponds to a monotonically increasing threshold for maximum tolerable risk in the riskutility condentialitymap framework previously described in duncan et al.12 some related ideas emanate from the computerscience literature, but most authors attempt to demand a stringent level of privacy, carefully dened, and to restrict access by adding noise and limitations on the numbers of queries allowed (e.g., see chawla et al.13).the tia privacy report suggests that14selective revelation [involves] putting a security barrier between the private data and the analyst, and controlling what information can ˚ow across that barrier to the analyst. the analyst injects a query that uses the private data to determine a result, which is a highlevel sanitized description of the query result. that result must not leak any private information to the analyst. selective revelation must accommodate multiple data sources, all of which lie behind the (conceptual) security bar10 j.d. tygar, ﬁprivacy architectures,ﬂ presentation at microsoft research, june 18, 2003, available at http://research.microsoft.com/projects/swsecinstitute/slides/tygar.pdf; j.d. tygar, ﬁprivacy in sensor webs and distributed information systems,ﬂ pp. 8495 in software security theories and systems, m. okada, b. pierce, a. scedrov, h. tokuda, and a. yonezawa, eds., springer, new york, 2003.11 l. sweeney, ﬁprivacypreserving surveillance using selective revelation,ﬂ lidap working paper 15, carnegie mellon university, 2005; updated journal version is j. yen, r. popp, g. cybenko, k.a. taipale, l. sweeney, and p. rosenzweig, ﬁhomeland security,ﬂ ieee intelligent systems 20(5):7686, 2005.12 g.t. duncan, s.e. fienberg, r. krishnan, r. padman, and s.f. roehrig, ﬁdisclosure limitation methods and information loss for tabular data,ﬂ pp. 135166 in condentiality, disclosure and data access: theory and practical applications for statistical agencies, p. doyle, j. lane, j. theeuwes, and l. zayatz, eds., northholland, amsterdam, 2001. see also g.t. duncan, s.a. kellermcnulty, and s.l. stokes, database security and condentiality: examining disclosure risk vs. data utility through the rœu condentiality map, technical report 142, national institute of statistical sciences, research triangle park, n.c., 2004; g.t. duncan and s.l. stokes, ﬁdisclosure risk vs. data utility: the rœu condentiality map as applied to topcoding,ﬂ chance 17(3):1620, 2004.13 s.c. chawla, c. dwork, f. mcsherry, a. smith, and h. wee, ﬁtowards privacy in public datatbases,ﬂ in theory of cryptography conference proceedings, j. kilian, ed., lecture notes in computer science, volume 3378, springerverlag, berlin, germany.14 information systems advanced technology (isat) panel, security with privacy, darpa, arlington, va., 2002, p. 10, available at http://www.cs.berkeley.edu/~tygar/papers/isatnalbrieng.pdf.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix j 245rier. private information is not made available directly to the analyst, but only through the security barrier. one effort to implement this scheme was dubbed privacy appliances by golle et al. and was intended to be a standalone device that would sit between the analyst and the private data source so that private data stayed in authorized hands.15 the privacy controls would also be independently operated to keep them isolated from the government. according to golle et al., the device would provide:inference control to prevent unauthorized individuals from completing queries that would allow identication of ordinary citizens. access control to return sensitive identifying data only to authorized users.immutable audit trails for accountability.implicit in the tia report and in the golle et al. approach was the notion that linkages between databases behind the security barrier would use identiable records and thus some form of multiparty computation method involving encryption techniques. the real questions of interest in ﬁinference controlﬂ are, what disclosurelimitation methods should be used? to which databases should they be applied? how can the ﬁinference controlﬂ approaches be combined with the multiparty computation methods? here is what is known in the way of answers:both sweeney and golle et al. refer to microaggregation, known as kanonymity, but with few details on how it could be used in this context. the method combines observations in groups of size k and reports either the sum or the average of the group for each unit. the groups may be identied by clustering or some other statistical approach. left unsaid is what kinds of users might perform with such aggregated data. furthermore, neither kanonymity nor any other condentiality tool does anything to cope with the implications of the release of exactly linked les requested by ﬁauthorized users.ﬂ much of the statistical and operationsresearch literature on condentiality fails to address the riskutility tradeoff, largely because it 15 philippe golle et al. ﬁprotecting privacy in terrorist tracking applications,ﬂ presentation to computers, freedom, and privacy 2004, available at http://www.cfp2004.org/program/materials/wgolle.ppt.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.246 protecting individual privacy in the struggle against terroristsfocuses primarily on privacy or on technical implementations without understanding how users wish to analyze a database.16a clear lesson from the statistical disclosurelimitation literature is that privacy protection in the form of ﬁsafe releasesﬂ from separate databases does not guarantee privacy protection for a merged database. a gure in lunt et al.17 demonstrates recognition of that by showing privacy appliances applied for the individual databases and then independently for the combined data. there have been a small number of crosswalks between the statistical disclosurelimitation literature on multiparty computation and riskutility tradeoff choices for disclosure limitation. yang et al. provide a starting point for discussions on kanonymity.18 there are clearly a number of alternatives to kanonymity and alternatives that yield ﬁanonymizedﬂ databases of far greater statistical utility.the ﬁhypeﬂ associated with the tia approach to protection has abated, largely because tia no longer exists as an ofcial program. but similar programs continue to appear in different places in the federal government and no one associated with any of them has publicly addressed the privacy concerns raised here regarding the tia approach.when congress stopped the funding for darpa's tia program in 2003, work on the privacy appliance's research and development effort at parc research center was an attendant casualty. thus, prototypes of the privacy appliance have not been made publicly available since then, nor are they likely to appear in the near future. the claims of privacy protection and selective revelation continued with matrix and other data warehouse systems but without an attendant research program, and the federal government continues to plan for the use of data mining techniques in other initiatives, such as the computer assisted passenger pro16 r. gopal, r. garnkel, and p. goes, ﬁcondentiality via camou˚age: the cvc approach to disclosure limitation when answering queries to databases,ﬂ operations research 50:501516, 2002.17 t. lunt, j. staddon, d. balfanz, g. durfee, t. uribe, d. smetters, j. thornton, p. aoki, b. waters, and d. woodruff, ﬁprotecting privacy in terrorist tracking applications,ﬂ presentation at the university of washington/microsoft research/carnegie mellon university software security summer institute, software security: how should we make software secure? on june 1519, 2003, available at http://research.microsoft.com/projects/swsecinstitute/veminute/balfanz5.ppt.18 z. yang, s. zhong, and r.n. wright, ﬁanonymitypreserving data collection,ﬂ pp. 334343 in proceedings of the 11th acm sigkdd international conference on knowledge discovery and data miningkdd™05, association for computing machinery, new york, n.y., 2005.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix j 247ling system ii (capps ii). similar issues arise in the use of government, medical, and private transaction data in bioterrorism surveillance.19j.3 assessmentsection j.1 provided a brief history of the tia program. whatever one™s views regarding the desirability or technical feasibility of the tia program, it is clear that from a political standpoint, the program was a debacle. indeed, after heated debate, the senate and house appropriations committees decided to terminate funding of the program.20 on passage of the initial funding limitation, a leading critic of the tia program, senator ron wyden, declared:the senate has now said that this program will not be allowed to grow without tough congressional oversight and accountability, and that there will be checks on the government™s ability to snoop on lawabiding americans.21the irony of the tia debate is that although the funding for the tia program was indeed terminated, both research on and deployment of data mining systems continue at various agencies (appendix i, ﬁillustrative government data mining programs and activityﬂ), but research on privacymanagement technology did not continue, and congressional oversight of data mining technology development has waned to some degree. the various outcomes of the tia debate raise the question of whether the nature of the debate over the program (if not the outcome) could have been any different if policy makers had addressed in advance some of the difcult questions that the program raised. in particular, it is interesting to consider questions in the three categories articulated in the framework of chapter 2: effectiveness, consistency with u.s. laws and values, and possible development of new laws and practices. the tia example further illustrates how careful consideration of the privacy impact of new technologies is needed before a program seriously begins the research stage.the threshold consideration of any privacysensitive technology is whether it is effective in meeting a clearly dened lawenforcement or 19 see s.e. fienberg and g. shmueli, ﬁstatistical issues and challenges associated with rapid detection of bioterrorist attacks,ﬂ statistics in medicine 24:513529, 2005; l. sweeney, ﬁprivacypreserving bioterrorism surveillance,ﬂ presentation at aaai spring symposium, ai technologies for homeland security, stanford university, stanford, calif., 2005.20 u.s. house, conference report on h.r. 2658, department of defense appropriations act, (house report 108283), u.s. government printing ofce, washington, d.c., 2004.21 declan mccullagh, ﬁsenate limits pentagon ‚snooping™ plan,ﬂ cnet news.com, january 24, 2003. available at http://sonyvaiocnet.com.com/210010233981945.html.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.248 protecting individual privacy in the struggle against terroristsnationalsecurity purpose. the question of effectiveness must be assessed through rigorous testing guided by scientic standards. the tia research program proposed an evaluation framework, but none of the results of evaluation have been made public. some testing and evaluation may have occurred in a classied setting, but neither this committee nor the public has any knowledge of results. research on how largescale dataanalysis techniques, including data mining, could help the intelligence community to identify potential terrorists is certainly a reasonable endeavor. assuming that initial research justies additional effort on the basis of scientic standards of success, the work should continue, but it must be accompanied by a clear method for assessing the reliability of the results. even if a proposed technology is effective, it must also be consistent with existing u.s. law and democratic values. first, one must assess whether the new technique and objective comply with law. in the case of tia, darpa presented to congress a long list of laws that it would comply with and afrmed that ﬁany deployment of tia™s search tools may occur only to the extent that such a deployment is consistent with current law.ﬂ second, inasmuch as tia research sought to enable the deployment of very largescale data mining over a larger universe of data than the u.s. government had previously analyzed, even compliance with thencurrent law would not establish consistency with democratic values. the surveillance power that tia proposed to put in the hands of u.s. investigators raised considerable concern among policy makers and the general public. that the program, if implemented, could be said to comply with law did not address those concerns. in fact, the program raised the concerns to a higher level and ultimately led to an effort by congress to stop the research altogether. tiastyle data mining was, and still is, possible because there are few restrictions on government access to thirdparty business records. any individual business record (such as a travel reservation or creditcard transactions) may have relatively low privacy sensitivity when looked at in isolation; but when a large number of such transaction records are analyzed over time, a complete and intrusive picture of a person™s life can emerge. developing the technology to derive such individual proles was precisely the objective of the tia program. it proposed to use such proles in only the limited circumstances in which they indicated terrorist activity. that may be a legitimate goal and could ultimately be recognized explicitly as such by law. however, that the program was at once legal and at the same time appeared to cross boundaries not previously crossed by lawenforcement or nationalsecurity investigations gives rise to questions that must be answered. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix j 249john poindexter, director of the darpa ofce responsible for tia, was aware of the policy questions and took notable steps to include in the technical research agenda various initiatives to build technical mechanisms that might minimize the privacy impact of the data mining capabilities being developed. in hindsight, however, a more comprehensive analysis of both the technical and larger publicpolicy considerations associated with the program was necessary to address congress™s concerns about privacy impact. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.250kbehavioralsurveillance techniques and technologiesthe primary question in behavioral science as applied to the use of behavioral technologies in the antiterrorism effort is, how can detection of particular behaviors and the attendant biological activity be used to indicate current and future acts of terrorism? k.1 the rationale for behavioral surveillancesome behavioral methods attempt to detect terrorist activity directly (for example, through surveillance at bridges, docks, and weapon sites). however, the focus in this appendix is on behavioral methods that are more indirect. such methods are used to try to detect patterns of behavior that are thought to be precursors or correlates of wrongdoing (such as deception and expression of hostile emotions) or that are anomalous in particular situations (for example, identifying a person who dgets much more and has much more facial reddening than others in a security line).many behavioraldetection methods monitor biological systems (such as cardiac activity, facial expressions, and voice tone) and use physiological information to draw inferences about internal psychological states (for example, ﬁon the basis of this pattern of physiological activity, this person is likely to be engaged in deceptionﬂ). in most situations, the easiest and most accurate way to determine past, current, and future behavior might be to ask the person what he or she has been doing, is doing, and plans protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix k 251to do. however, the terrorist™s desire to avoid detection and the ﬁcat and mouseﬂ game that is played by terrorists and their pursuers make such a verbal mode of informationgathering highly unreliable. because verbal reports can be manipulated and controlled so easily, we might turn to biological systems that are less susceptible to voluntary control or that provide detectable signs when they are being manipulated. once we move to the biological level, however, we have abandoned direct observation of terrorist behavior and moved into the realm of inference of likely behavior from more primitive and less specic sources. biobehavioral methods can be powerful and useful, but they are intrinsically subject to three limitations: manytoone. any given pattern of physiological activity can result from or correlate with a number of quite different psychological or physical states. probabilistic. any detected sign or pattern conveys some likelihood of the behavior, intent, or attitude of interest but not an absolute certainty.errors. in addition to the highly desirable true positives and true negatives that are produced, there will be the troublesome false positives (an innocent person is thought to be guilty) and false negatives (a guilty person is thought to be innocent). depending on the robustness of the biobehavioral techniques involved, it may be possible in the face of countermeasures for a subject to induce false negatives by manipulating his or her behavior.in addition, even if deception or the presence of an emotion can be accurately and reliably detected, information about the reason for deception, a given emotion, or a given behavior is not available from the measurements taken. a person exhibiting nervousness may be excited about meeting someone at the airport or about being late. a person lying about his or her travel plans may be concealing an extramarital affair. a person dgeting may be experiencing back pain. none of those persons would be the targets of counterterrorist efforts, nor should they bešand the possibility that their true motivations and intents may be revealed has denite privacy implications.k.2 major behavioraldetection methodsmost behavioral methods are based on monitoring the activity of neural systems that are thought to be difcult to control voluntarily or that reveal measurable signs when they are being controlled. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.252 protecting individual privacy in the struggle against terroristsk.2.1 facial expressionfacial muscles are involved in the expression and communication of emotional states. they can be activated both voluntarily and involuntarily,1 so there is ample opportunity for a person to interfere with the expression of emotion in ways that serve personal goals. there is strong scientic evidence that different congurations of facialmuscle contractions are associated with what are often called basic emotions.2 those emotions include anger, contempt, disgust, fear, happiness, surprise, and sadness. there is also evidence that other emotions can be identied on the basis of patterns of movement in facial and bodily muscles (for example, embarrassment3) and that distinctions can be made between genuine felt happiness and feigned unfelt happiness according to whether a smile (produced by the zygomatic major muscles) is accompanied by the contraction of the muscles (orbicularis oculi) that circle the eyes.4 facialmuscle activity can be measured accurately by careful examination of the changes in appearance that are produced as the muscles cause facial skin to be moved.5 trained coders working with video recordings can analyze facial expressions reliably, but it is extremely timeconsuming (it can take hours to analyze a few minutes of video fully). greatly simplied methods that focus only on the key muscle actions involved in a few emotions of interest and that are appropriate for realtime screening are being developed and tested. some basic efforts to develop automated computer systems for analyzing facial expressions have also been undertaken,6 but the problems inherent in adapting them for realworld, naturalistic applications are enormous.7 1 w.e. rinn, ﬁthe neuropsychology of facial expression: a review of the neurological and psychological mechanisms for producing facial expressions,ﬂ psychological bulletin 95(1):5277, 1984.2 p. ekman, ﬁan argument for basic emotions,ﬂ cognition and emotion 6(34):169200, 1992.3 d. keltner, ﬁsigns of appeasement: evidence for the distinct displays of embarrassment, amusement, and shame,ﬂ journal of personality and social psychology 68(3):441454, 1995.4 p. ekman and w.v. friesen, ﬁfelt, false and miserable smiles,ﬂ journal of nonverbal behavior 6(4):238252, 1982.5 p. ekman and w.v. friesen, facial action coding system, consulting psychologists press, palo alto, calif., 1978.6 j.f. zlochower, a.j. j. lien, and t. kanade, ﬁautomated face analysis by feature point tracking has high concurrent validity with manual facs coding,ﬂ psychophysiology 36(1):3543, 1999.7 for example, according to a german eld test of facial recognition conducted in 2007, an accuracy of 60 percent was possible under optimal conditions, 30 percent on average (depending on light and other factors). see bundeskriminalamt (bka), face recognition as a tool for finding criminals: picturemanhunt, final report, bka, wiesbaden, germany, february 2007. available in german at http://www.cytrap.eu/les/euist/2007/pdf/200707facerecognitionfieldtestbkagermany.pdf.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix k 253there are several other ways to measure facialmuscle activity. the electrical activity of the facial muscles themselves can be measured (with electromyelography [emg]). that requires the application of many electrodes to the face, each placed to maximize sensitivity to the action of particular muscles and minimize sensitivity to the action of other muscles. because of the overlapping anatomy of facial muscles, their varied sizes, and their high density in some areas (such as around the mouth), the emg method may be better suited to simple detection of emotional valence (positive or negative) and intensity than to the detection of specic emotions. another indirect method of assessing facialmuscle activity is to measure the ﬁheat signatureﬂ of the face associated with changes in blood ˚ow to different facial regions.8 that information can be read remotely by using infrared cameras; however, the spatial and temporal resolutions are problematic.even if a method emerged that allowed facialmuscle activity to be measured reliably, comprehensively, economically, and unobtrusively, there would be the issue of its utility in a counterterrorism effort. necessary (but not sufcient) conditions for utility would include: the availability of tools that can determine the specic emotion that is being signaled if and when emotional facial expression is displayed. the superiority of a facialexpressionœbased emotionprediction system to a system based on any other biological or physiological markers. the detectability of indicators that a person is attempting to conceal his or her true emotional state or to shut down facial expression entirely, such assmall, ˚eeting microexpressions of the emotion being felt. telltale facial signs of attempted control (such as tightening of some mouth muscles). signs that particular emotions are being simulated.characteristic increases in cardiovascular activity mediated by the sympathetic branch of the autonomic nervous system.9 because no specic facial sign is associated with committing or plan8 see, for example d.a. pollina and a. ryan, the relationship between facial skin surface temperature reactivity and traditional polygraph measures used in the psychophysiological detection of deception: a preliminary investigation, u.s. department of defense polygraph institute, ft. jackson, s.c., 2002.9 j.j. gross and r.w. levenson, ﬁemotional suppression: physiology, selfreport, and expressive behavior,ﬂ journal of personality and social psychology 64(6):970986, 1993; j.j. gross and r.w. levenson, ﬁhiding feelings: the acute effects of inhibiting negative and positive emotion,ﬂ journal of abnormal psychology 106(1):95103, 1997.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.254 protecting individual privacy in the struggle against terroristsning a terrorist act, using facial measurement in a counterterrorism effort will have to be based on some combination of the detection of facial expressions thought to indicate malevolent intent (such as signs of anger, contempt, or feigned happiness in some situations), the detection of facial expressions thought to indicate deception,10 and the detection of facial expressions that are anomalous compared with those of other people in the same situation. results of research on the connection between facial expression and emotional state suggest correlations between the two. however, the suggestive ndings have generally not been subject to rigorous, controlled tests of accuracy in a variety of settings that might characterize realworld application contexts.k.2.2 vocalizationin addition to the linguistic information carried by the human voice, a wealth of paralinguistic information is carried in pitch, timbre, tempo, and the like and is thought to be related to a person™s emotional state.11 those paralinguistic qualities of speech can be difcult to control voluntarily, so they are potentially useful for detecting underlying emotional states and deception. in the emotion realm, much of the promise of mapping paralinguistic qualities of vocalization onto specic emotions has yet to be realized, and the history of using paralinguistic markers in the deception realm is not very encouraging. at one time, a great deal of attention was given to the detection of deception by quantifying microtremors in the voice (ﬁvoice stress analyzersﬂ), but this approach has failed to withstand scientic scrutiny.12 why has more progress not been made in using paralinguistic qualities of speech to detect emotions and deception? there are several possible reasons. the relationships between paralinguistic qualities of speech and psychological states are much weaker than originally thought. the eld has not yet identied the right characteristics to measure. and siz10 p. ekman and m. o™sullivan, ﬁfrom ˚awed selfassessment to blatant whoppers: the utility of voluntary and involuntary behavior in detecting deception,ﬂ behavioral sciences and the law. special issue: malingering 24(5):673686, 2006.11 k.r. scherer, vocal measurement of emotion, academic press, inc., san diego, calif., 1989.12 see, for example, national research council, the polygraph and lie detection, the national academies press, washington, d.c., 2003; mitchell s. sommers, ﬁevaluating voicebased measures for detecting deception,ﬂ the journal of credibility assessment and witness psychology 7(2):99107, 2006, available at http://truth.boisestate.edu/jcaawp/2006no2/200699107.pdf; j. masip, e. garrido, and c. herrero, ﬁthe detection of deception using voice stress analyzers: a critical review,ﬂ estudios de psicologãa 25(1):1330, 2004.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix k 255able individual differences in speech need to be accounted for before interindividual consistencies will emerge. in the interim, new approaches that do not rely on paralinguistic vocalizations in isolation but rather combine them with other indicators of deception and emotion (such as facial expressions and physiological indicators) may prove useful. is is ironic that it is fairly simple to obtain highquality, noninvasive samples of vocalizations in realworld contexts. moreover, costeffective, accurate instrumentation for analyzing the acoustic properties of speech is readily available. thus, the tools are already in place; it is just the science that is lagging.k.2.3 other muscle activitytechnology is readily available for quantifying the extent of overall motor activity (sometimes called gross motor activity or general somatic activity). it can be done with accelerometers attached to a person (some are built into watchlike casings) or with pressuresensitive devices (such as piezoelectric transducers) placed under standing and sitting areas. the latter can be used to track motion in multiple dimensions and thus enable characterization of patterns of pacing, dgeting, and moving. although clearly not specically related to any particular emotional or psychological state, high degrees of motor activity may be noteworthy when they are anomalous in comparison with usual levels of agitation and tension.k.2.4 autonomic nervous system the autonomic nervous system (ans) controls the activity of the major organs, including the heart, blood vessels, kidneys, pancreas, lungs, stomach, and sweat glands. decades of methodological development in medicine and psychophysiology have produced ways to measure a wide array of autonomic functions reliably and noninvasively. some of the measures are direct (such as using the electrical activity of the heart muscle to determine heart rate), and some are indirect (such as estimating vascular constriction by using the re˚ection of infrared light to determine the amount of blood pooling in peripheral sites or using impedance methods to measure the contractile force of the left ventricle as it pumps blood from the heart to the rest of the body). additional work has been directed toward developing methods of ambulatory monitoring that enable tracking of ans activity in freely moving people. remote sensing of autonomic function is still in its infancy, but some progress has been made in using variation in surface temperature to indicate patterns of blood ˚ow. measures of ans activity are essentially measures of arousal and re˚ect the relative activation and deactivation of various organ systems to protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.256 protecting individual privacy in the struggle against terroristsprovide the optimal milieu to support current body activity (such as sleep, digestion, aggression, and thinking). debate has raged over the decades as to whether specic patterns of autonomic activity are associated with particular psychological states, including emotions. for emotion, the issue is whether the optimal bodily milieu for anger (ans support for ghting) is different from that for disgust (ans support for withdrawal and expulsion of harmful substances). evidence in support of that kind of autonomic specicity for at least some of the basic emotions is drawn from experimentation, metaphors found in language (such as association of heat and pressure with anger or of coolness with fear), and observable signs of autonomic activity (such as crying during sadness but not during fear or gagging during disgust but not during angers). there are a number of reviews of these issues and the associated scientic evidence.13over the years, patterns of ans activity have been mapped onto several nonemotionl states. among the more durable of them have been the distinction between stimulus intake (elevated skin conductance plus heart rate deceleration) and stimulus rejection (elevated skin conductance plus heart rate acceleration),14 and the more recent distinction between the cardiovascular responses to threat (moderate increases in cardiac contractility, no change or decrease in cardiac output, and no change or increase in total peripheral resistance) and to challenge (increase in cardiac contractility, increase in cardiac output, and decrease in total peripheral resistance).15 regardless of the putative pattern, using the existence of any particular pattern of ans activity by itself to infer psychological or emotional states is fraught with danger. the ans is the slave to many masters, and any ans pattern may re˚ect any of a host of nonpsychological and psychological states. the other way in which ans monitoring has been used extensively is to detect deception. the use of autonomic measurement in liedetection technology has a long history in law enforcement, security screening, and personnel selection. despite its history (which continues), most of the major scientic investigations of the validity of the polygraph have raised serious reservations. for example, an independent review of the 13 r.w. levenson, ﬁautonomic specicity and emotion,ﬂ pp. 212224 in handbook of affective sciences, r.j. davidson, k.r. scherer, and h.h. goldsmith, eds., oxford university press, new york, n.y., 2003.14 j.i. lacey, j. kagan, b.c. lacey, and h.a. moss, ﬁthe visceral level: situational determinants and behavioral correlates of autonomic response patterns,ﬂ pp. 161196 in expression of the emotions in man, p.h. knapp, ed., international university press, new york, n.y., 1963.15 j. tomaka, j. blascovich, r.m. kelsey, and c.l. leitten, ﬁsubjective, physiological, and behavioral effects of threat and challenge appraisal,ﬂ journal of personality and social psychology 65(2):248260, 1993.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix k 257use of the polygraph commissioned by the ofce of technology assessment concluded that16 there is at present only limited scientic evidence for establishing the validity of polygraph testing. even where the evidence seems to indicate that polygraph testing detects deceptive subjects better than chance (when using the control question technique in specicincident criminal investigations), signicant error rates are possible, and examiner and examinee differences and the use of countermeasures may further affect validity. (p. 96)in 2003, a review by the national research council was similarly critical,17 concluding that the polygraph has a better than chance but far less than perfect performance in detecting specic incidents of deception but that it is not acceptable for use in general screening and is highly vulnerable to countermeasures. in considering the use of the polygraph in antiterrorism efforts, it is important to weigh its possible utility in ﬁguilty knowledgeﬂ situations (for example, the person being interrogated is denying knowing something that he or she knows) against the likelihood that the person will be trained in using countermeasures. empirically, ﬁguilty knowledgeﬂ studies indicate that the polygraph confers at best a minimal advantage in identifying such situations and suggest that guilty parties may not need to take countermeasures at all to evade detection by a polygraph.k.2.5 central nervous systemthe brain is clearly the source of motivated behavioršboth good and evil. thus, measuring brain activity is appealing if the goal is to detect intentions, motives, planned behaviors, allegiances, and a host of other mental states related to terrorism and terrorist acts. the electrical activity of the brain can be measured directly with electroencephalography (eeg) and indirectly with such methods as magnetoencephalography (meg, which detects changes in magnetic elds produced by the brain™s electrical activity), positronemission tomography (pet, which uses radioactive markers to track blood ˚ow into the brain areas that are most active), and functional magnetic resonance imaging (fmri, which uses strong magnetic elds to detect changes in the magnetic properties of blood ˚owing 16 ofce of technology assessment, scientic validity of polygraph testing: a research review and evaluation, u.s. congress, ofce of technology assessment, washington, d.c., 1983.17 national research council, the polygraph and lie detection, the national academies press, washington, d.c., 2003.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.258 protecting individual privacy in the struggle against terroriststhrough the brain that occur when active brain areas use the oxygen carried by red blood cells).the electrical activity of the brain can be monitored using these technologies while an individual is undertaking fairly complex behavioral activities and can sometimes be linked to particular discrete stimulus events. an overarching goal of the research using these methods has been to understand how and where in the brain such basic mental activities as error detection, con˚ict monitoring, emotion activation, and behavioral regulation occur. in most brain research, the focus has been more on specic cognitive processes than on specic emotions. some patterns of brain activity can be used to predict when a person is experiencing emotion but not the particular emotion. in addition to emotional activation, some patterns indicate attempts at emotion regulation and control.18 each of the existing measures of brain activity has advantages and disadvantages in temporal resolution, spatial resolution, invasiveness, susceptibility to movement artifact, methodological requirements, and expense. much of the current excitement in the eld is focused on fmri. viewed from the perspective of counterterrorism, fmri presents numerous challenges: subjects must be supine in a tube for a long period (typically 15 minutes to 2 hours), temporal resolution is low, and the method is highly vulnerable to movement artifacts (movements greater than 3 mm can result in unusable images). although the committee heard testimony about detection of deception with fmri, the paucity of research supporting it and the considerable constraints associated with it make it difcult to imagine its having any immediate antiterrorism utility. k.3 assessing behavioralsurveillance techniquesproponents and advocates (especially vendors) often seek to demonstrate the validity of a particular approach to behavioral surveillance or deception detection by presenting evidence that it discriminates accurately between truthfulness and deception in a particular sample of examinees. although such evidence would be necessary to accept claims of validity, it is far from sufcient.the 2003 national research council report on the polygraph and lie detection19 provided a set of questions that guide the collection of credible evidence to support claims of validity of any proposed technique for deception detection and a set of characteristics of highquality studies 18 k.n. ochsner and j.j. gross, ﬁthe cognitive control of emotion,ﬂ trends in cognitive sciences 9(5):242249, 2005.19 national research council, 2003, op. cit.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix k 259that address issues of accuracy. those questions and characteristics are presented in box k.1.k.4 behavioral and data mining methods: similarities and differences behavioral and data mining methods have many similarities and some key differences. perhaps most important, they face many of the same challenges and can both be evaluated in the overall framework presented in this report. these are some characteristics that are common to the two methods:probabilistic. data mining and behavioral surveillance seek patterns that are likely to be associated with terrorist acts. successful methods will need to have high rates of true positives and true negatives and low rates of false positives and false negatives. because of the low base rate of terrorism in most contexts (for example, in airport security lines), both methods will detect many acts of malfeasance that are not directly related to terrorism (for example, acts by people who have committed or are planning other crimes). the value and cost of these ﬁtrue positives of another sortﬂ must be considered in evaluating any applications of the methods. remote and secret monitoring. data mining and some kinds of behavioral surveillance allow information to be collected and analyzed without direct interaction with those being monitored. countermeasures. data mining and behavioral surveillance are vulnerable to countermeasures and disinformation.gateways to human judgment. data mining and behavioral surveillance may best be viewed as ways to identify situations that require followup investigation by skilled interviewers, analysts, and scientists.privacy. data mining and behavioral surveillance raise serious concerns for the protection of individual liberties and privacy. need for prior empirical demonstration. data mining and behavioral surveillance should deployed operationally on a wide scale only after their utility has been empirically demonstrated in the laboratory and on a limited scale in operational contexts.need for continuing evaluation. the use of data mining and of behavioral surveillance should be accompanied by a continuing process of evaluation to establish utility, accuracy and error rates, and violation of individual privacy. the following are some of the important differences:collection versus analysis. techniques for detecting deception require protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.260 protecting individual privacy in the struggle against terroristsbox k.1 questions for assessing validity and characteristics of accurate studiesquestions for assessing validity does the technique have a plausible theoretical rationale, that is, a proposed psychological, physiological, or brain mechanism that is consistent with current physiological, neurobiological, and psychological knowledge?does the psychological state being tested for (deception or recognition) reliably cause identiable behavioral, physiological, or brain changes in individuals, and are these changes measured by the proposed technique?by what mechanisms are the states associated with deception linked to the phenomena the technique measures?are optimal procedures being used to measure the particular states claimed to be associated with deception?by what mechanisms might a truthful response produce a false positive result with this technique? what do practitioners of the technique do to counteract or correct for such mechanisms? is this response to the possibility of false positives reasonable considering the mechanisms involved?by what means could a deceptive response produce a false negative result? that is, what is the potential for effective countermeasures? what do practitioners of the technique do to counteract or correct for such phenomena? is this response to the possibility of false negatives and effective countermeasures reasonable considering the mechanisms involved?are the mechanisms purported to link deception to behavioral, physiological, or brain states and those states to the test results universal for all people who might be examined, or do they operate differently in different kinds of people or in different situations? is it possible that measured responses do not always have the same meaning or that a test that works for some kinds of examinees or situations will fail with others?how do the social context and the social interactions that constitute the examination procedure affect the reliability and validity of the recordings that are obtained?are there plausible alternative theoretical rationales regarding the underlying mechanisms that make competing empirical predictions about how the technique performs? what is the weight of evidence for competing theoretical rationales?research methods for demonstrating accuracy randomized experimentation. in analog studies, this means that examinees are randomly assigned to be truthful or deceptive. it is also useful to have studies in which examinees are allowed to decide whether to engage in the target behavior. such studies gain a degree of realism for what they lose in experimental control.manipulation checks. if a technique is claimed to measure arousal, for example, there should be independent evidence that experimental manipulations actually create different levels of arousal in the different groups.blind administration and blind evaluation of the technique, whoever administers and scores tests based on the technique must do so in the absence of any information on whether the examinee is truthful or deceptive.adequate sample sizes. most of the studies examined [in the national research council 2003 polygraph report] were based on relatively small sample sizes that were sometimes adequate to allow for the detection of statistically signicant differences but were insufcient for accurate assessment of accuracy. changing the results of only a few cases might dramatically affect the implications of these studies.appropriate comparison conditions and experimental controls. these conditions and controls will vary with the technique. a suggestion of what may be involved is the idea in polygraph research of comparing a polygraph examination with a bogus polygraph examination, with neither the examiner nor the examinee knowing that the test output might be bogus.crossvalidation of any exploratory data analytic solution on independent data. any standardized or computerized scoring system for measurements from a technique cannot be seriously considered as providing accurate detection unless it has been shown to perform well on samples of examinees different from those on whom it was developed.examinees masked to experimental hypotheses if not to experimental condition. it is important to sort out precisely what effect is being measured. for example, the results of a countermeasures study would be more convincing if examinees were instructed to expect that the examiner is looking for the use of countermeasures, among other things, rather than being instructed explicitly that this is a study of whether countermeasures work and can be detected.standardization. an experiment should have sufcient standardization to allow reliable replication by others and should analyze the results from all examinees. it is important to use a technique in the same way on all the examinees, which means: clear reporting of how the technique was administered; sharply limiting the examiner™s discretion in administering the technique and interpreting its results; and using the technique on all examinees, not only the ones whose responses are easy to classify. if some examinees are dropped from the analysis, the reasons should be stated explicitly. this is a difcult test for a procedure to pass, but it is appropriate for policy purposes.analysis of sensitivity and specicity or their equivalents. data should be reported in a way that makes it possible to calculate both the sensitivity and specicity of the technique, preferably at multiple thresholds for diagnostic decision making or in a way that allows comparisons of the test results with the criterion on other than binary scales. source: national research council, the polygraph and lie detection, the national academies press, washington, d.c., 2003, pp. 222224.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix k 261box k.1 questions for assessing validity and characteristics of accurate studiesquestions for assessing validity does the technique have a plausible theoretical rationale, that is, a proposed psychological, physiological, or brain mechanism that is consistent with current physiological, neurobiological, and psychological knowledge?does the psychological state being tested for (deception or recognition) reliably cause identiable behavioral, physiological, or brain changes in individuals, and are these changes measured by the proposed technique?by what mechanisms are the states associated with deception linked to the phenomena the technique measures?are optimal procedures being used to measure the particular states claimed to be associated with deception?by what mechanisms might a truthful response produce a false positive result with this technique? what do practitioners of the technique do to counteract or correct for such mechanisms? is this response to the possibility of false positives reasonable considering the mechanisms involved?by what means could a deceptive response produce a false negative result? that is, what is the potential for effective countermeasures? what do practitioners of the technique do to counteract or correct for such phenomena? is this response to the possibility of false negatives and effective countermeasures reasonable considering the mechanisms involved?are the mechanisms purported to link deception to behavioral, physiological, or brain states and those states to the test results universal for all people who might be examined, or do they operate differently in different kinds of people or in different situations? is it possible that measured responses do not always have the same meaning or that a test that works for some kinds of examinees or situations will fail with others?how do the social context and the social interactions that constitute the examination procedure affect the reliability and validity of the recordings that are obtained?are there plausible alternative theoretical rationales regarding the underlying mechanisms that make competing empirical predictions about how the technique performs? what is the weight of evidence for competing theoretical rationales?research methods for demonstrating accuracy randomized experimentation. in analog studies, this means that examinees are randomly assigned to be truthful or deceptive. it is also useful to have studies in which examinees are allowed to decide whether to engage in the target behavior. such studies gain a degree of realism for what they lose in experimental control.manipulation checks. if a technique is claimed to measure arousal, for example, there should be independent evidence that experimental manipulations actually create different levels of arousal in the different groups.blind administration and blind evaluation of the technique, whoever administers and scores tests based on the technique must do so in the absence of any information on whether the examinee is truthful or deceptive.adequate sample sizes. most of the studies examined [in the national research council 2003 polygraph report] were based on relatively small sample sizes that were sometimes adequate to allow for the detection of statistically signicant differences but were insufcient for accurate assessment of accuracy. changing the results of only a few cases might dramatically affect the implications of these studies.appropriate comparison conditions and experimental controls. these conditions and controls will vary with the technique. a suggestion of what may be involved is the idea in polygraph research of comparing a polygraph examination with a bogus polygraph examination, with neither the examiner nor the examinee knowing that the test output might be bogus.crossvalidation of any exploratory data analytic solution on independent data. any standardized or computerized scoring system for measurements from a technique cannot be seriously considered as providing accurate detection unless it has been shown to perform well on samples of examinees different from those on whom it was developed.examinees masked to experimental hypotheses if not to experimental condition. it is important to sort out precisely what effect is being measured. for example, the results of a countermeasures study would be more convincing if examinees were instructed to expect that the examiner is looking for the use of countermeasures, among other things, rather than being instructed explicitly that this is a study of whether countermeasures work and can be detected.standardization. an experiment should have sufcient standardization to allow reliable replication by others and should analyze the results from all examinees. it is important to use a technique in the same way on all the examinees, which means: clear reporting of how the technique was administered; sharply limiting the examiner™s discretion in administering the technique and interpreting its results; and using the technique on all examinees, not only the ones whose responses are easy to classify. if some examinees are dropped from the analysis, the reasons should be stated explicitly. this is a difcult test for a procedure to pass, but it is appropriate for policy purposes.analysis of sensitivity and specicity or their equivalents. data should be reported in a way that makes it possible to calculate both the sensitivity and specicity of the technique, preferably at multiple thresholds for diagnostic decision making or in a way that allows comparisons of the test results with the criterion on other than binary scales. source: national research council, the polygraph and lie detection, the national academies press, washington, d.c., 2003, pp. 222224.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.262 protecting individual privacy in the struggle against terroriststhe collection of physiological and biological data, whereas datamining is a technique for analyzing alreadycollected data.degree of intrusiveness. traditional jurisprudence and ethics generally regard a person™s body as worthy of a higher degree of protection than his or her information, residences, or possessions. thus, techniques that require the collection of physiological and biological data (especially data relevant to one™s thoughts) are arguably more intrusive than collection schemes directed at different kinds of personal data.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.263lthe science and technology of privacy protectionto the extent that there is a tension between counterterrorism efforts and protection of citizens™ privacy, it is useful to understand how it may be possible to design counterterrorism information systems to minimize their impact on privacy. this appendix considers privacy protection from two complementary perspectivesšprivacy protection that is built into the analytical techniques themselves and privacy protection that can be engineered into an operational system. the appendix concludes with a brief illustration of how government statistical agencies have approached condential data collection and analysis over the years. a number of techniques described here have been proposed for use in protecting privacy; none would be a panacea, and several have important weaknesses that are not well understood and that are discussed and illustrated.l.1 the cybersecurity dimension of privacyrespecting privacy interests necessarily means that parties that should not have access to personal information do not have such access. security breaches are incompatible with protecting the privacy of personal information, and good cybersecurity for electronically stored personal information is a necessary (but not sufcient) condition for protecting privacy.from a privacy standpoint, the most relevant cybersecurity technologies are encryption and access controls. encryption obscures digitally stored information so that it cannot be read without having the key necesprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.264 protecting individual privacy in the struggle against terroristssary to decrypt it. access controls provide privileges of different sorts to specied users (for example, the system may grant john doe the right to know that a le exists but not the right to view its contents, and it may give jane doe both rights). access controls may also be associated with audit logs that record what les were accessed by a given user.because of the convergence of and similarities between communication and information technologies, the technologies face increasingly similar threats and vulnerabilities. furthermore, addressing these threats and vulnerabilities entails similar countermeasures or protection solutions. a fundamental principle of security is that no digital resource that is in use can be absolutely secure; as long as information is accessible, it is vulnerable. security can be increased, but the value of increased security must be weighed against the increase in cost and the decrease in accessibility.human error, accident, and acts of god are the dominant sources of loss and damage in information and communication systems, but the actions of hackers and criminals are also of substantial concern. terrorists account for a small percentage of losses, nancial and otherwise, but could easily exploit vulnerabilities in government and business to cause much more serious damage to the nation. security analysts and specialists report a large growth in the number and diversity of cyberthreats1 and vulnerabilities.2 despite a concurrent growth in countermeasures (that is, security technologies3) penetrations and losses are increasing. a databreach chronology reports losses of 104 million records (for example, in lost laptop computers) containing personally identiable information from january 2005 to february 2007.4 the department of homeland security national cyber security division reports that over 25 new vulnerabilities were discovered each day in 2006.5the state of government information security is unnecessarily weak. 1a.t. williams, a. hallawell, r. mogull, j. pescatore, n. macdonald, j. girard, a. litan, l. orans, v. wheatman, a. allan, p. firstbrook, g. young, j. heiser, and j. feiman, hype cycle for cyberthreats, gartner, inc., stamford, conn., september 13, 2006.2 national vulnerability database, national institute of standards and technology computer security division, sponsored by the u.s. department of homeland security national cyber security division/u.s. computer emergency readiness team (uscert), available at http://nvd.nist.gov/.3 a.t. williams, a. hallawell, r. mogull, j. pescatore, n. macdonald, j. girard, a. litan, l. orans, v. wheatman, a. allan, p. firstbrook, g. young, j. heiser, and j. feiman, hype cycle for cyberthreats, gartner, inc., stamford, conn., september 13, 2006.4 a chronology of data breaches, privacy rights clearing house.5 national vulnerability database, national institute of standards and technology computer security division, sponsored by the u.s. department of homeland security national cyber security division/u.s. computer emergency readiness team (uscert), available at http://nvd.nist.gov/.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix l 265for example, the u.s. government accountability ofce (gao) noted in march 2008 that [m]ajor federal agencies continue to experience signicant information security control deciencies that limit the effectiveness of their efforts to protect the condentiality, integrity, and availability of their information and information systems. most agencies did not implement controls to sufciently prevent, limit, or detect access to computer networks, systems, or information. in addition, agencies did not always effectively manage the conguration of network devices to prevent unauthorized access and ensure system integrity, patch key servers and workstations in a timely manner, assign duties to different individuals or groups so that one individual did not control all aspects of a process or transaction, and maintain complete continuity of operations plans for key information systems. an underlying cause for these weaknesses is that agencies have not fully or effectively implemented agencywide information security programs. as a result, federal systems and information are at increased risk of unauthorized access to and disclosure, modication, or destruction of sensitive information, as well as inadvertent or deliberate disruption of system operations and services. such risks are illustrated, in part, by an increasing number of security incidents experienced by federal agencies.6such performance is re˚ected in the public™s lack of trust in government agencies™ ability to protect personal information.7 security of government information systems is poor despite many relevant regulations and guidelines.8 most communication and information systems are unnecessarily vulnerable to attack because of poor security practices, and 6 statement of gregory c. wilshusen, gao director for information security issues, ﬁinformation security: progress reported, but weaknesses at federal agencies persist,ﬂ testimony before the subcommittee on federal financial management, government information, federal services, and international security, committee on homeland security and governmental affairs, u.s. senate, gao08571t, march 12, 2008. available at http://www.gao.gov/new.items/d08571t.pdf.7 l. ponemon, privacy trust study of united states government, the ponemon institute, traverse city, mich., february 15, 2007.8 appendix iii, omb circular a130, ﬁsecurity of federal automated information resources,ﬂ (ofce of management and budget, washington, d.c.) revises procedures formerly contained in appendix iii, omb circular no. a130 (50 fr 52730; december 24, 1985), and incorporates requirements of the computer security act of 1987 (p.l. 100235) and responsibilities assigned in applicable national security directives. see also federal information security management act of 2002 (fisma), 44 u.s.c. § 3541, et seq., title iii of the egovernment act of 2002, public law 107347, 116 stat. 2899, available at http://csrc.nist.gov/drivers/documents/fismanal.pdf.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.266 protecting individual privacy in the struggle against terroriststhe framework outlined in chapter 2 identies data stewardship as a critical evaluation criterion.9although cybersecurity and privacy are conceptually different, they are often con˚atedšwith good reasonšin the public™s mind. cybersecurity breachesšwhich occur, for example, when a hacker breaks into a government information system that contains personally identiable information (addresses, social security numbers, and so on)šare naturally worrisome to the citizens who may be affected. they do not particularly care about the subtle differences between a cybersecurity breach and a loss of privacy through other means; they know only that their privacy has been (potentially) invaded and that their loss of privacy may have deleterious consequences for them. that reaction has policy signicance: the government agency responsible (perhaps even the entire government) is viewed as being incapable of protecting privacy, and public condence is undermined when it asserts that it will be a responsible steward of the personal information it collects in its counterterrorism mission. l.2 privacypreserving data analysisl.2.1 basic conceptsit is intuitive that the goal of privacypreserving data analysis is to allow the learning of particular facts or kinds of facts about individuals (units) in a data set while keeping other facts secret. the term data set is used loosely; it may refer to a single database or to a collection of data sources. under various names, privacypreserving data analysis has been addressed in various disciplines.a statistic is a quantity computed on the basis of a sample. a major goal of ofcial statistics is to learn broad trends about a population by studying a relatively small sample of members of the population. in many cases, such as in the case of u.s. census data and data collected by the internal revenue service (irs), privacy is legally mandated. thus, the goal is to identify and report trends while protecting the privacy of individuals. that sort of challenge is central to medical studies: the analyst wishes to learn and report facts of life, such as ﬁsmoking causes cancer,ﬂ while preserving the privacy of individual cancer patients. the analyst must be certain that the privacy of individuals is not even inadvertently compromised. 9 data stewardship is accountability for program resources being used and protected appropriately according to the dened and authorized purpose.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix l 267providing such protection is a difcult task, and a number of seemingly obvious approaches do not work even in the best of circumstances, for example, when a trusted party holds all the condential data in one place and can prepare a ﬁsanitizedﬂ version of the data for release to the analyst or can monitor questions and refuse to answer when privacy might be at risk. (this point is discussed further in section l.2.2 below.) in the context of counterterrorism, privacypreserving data analysis is excellent for teaching the data analyst about ﬁnormalﬂ behavior while preserving the privacy of individuals. the task of the counterterrorism analyst is to identify ﬁatypicalﬂ behavior, which can be dened only in contrast with what is typical. it is immediately obvious that the data on any single specic individual should have little effect on the determination of what is normal, and in fact this point precisely captures the source of the intuition that broad statistical trends do not violate individual privacy. assuming a good knowledge of what is ﬁnormal,ﬂ technology is necessary for counterterrorism that will scrutinize data in an automated or semiautomated fashion and ˚ag any person whose data are abnormal, i.e., that satisfy a putatively ﬁproblematicﬂ prole. in other words, the outcome of data analysis in this context must necessarily vary widely (ﬁyes, it satises the proleﬂ or ﬁno, it does not satisfy the proleﬂ), depending on the specic person whose data is being scrutinized. whether the prole is genuinely ﬁproblematicﬂ is a separate matter.in summary, privacypreserving data analysis may permit the analyst to learn the denition of normal in a privacypreserving way, but it does not directly address the counterterrorism goal: privacypreserving data analysis ﬁmasksﬂ all individuals, whereas counterterrorism requires the exposure of selected individuals. there is no such thing as privacypreserving examination of an individual™s records or privacypreserving examination of a database to pinpoint problematic individuals.the question, therefore, is whether the counterterrorism goal can be satised while protecting the privacy of ﬁtypicalﬂ people. more precisely, suppose the existence of a perfect prole of a terrorist: the falsepositive and falsenegative rates are very low. (the existence of such a perfect prole is magical thinking and contrary to fact, but suppose it anyway.) would it be possible to analyze data, probably from diverse sources and in diverse formats, in such a way that the analyst learns only information about people who satisfy the prole? as far as we know, the answer to that question is no. however, it might be possible to limit the amount of information revealed about those who do not satisfy the prole, perhaps by controlling the information and sources used or by editing them after they are acquired. that would require major efforts and attention to the quality and utility of information in integrated databases.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.268 protecting individual privacy in the struggle against terroristsl.2.2 some simple ideas that do not work in practicethere are many ideas for protecting privacy, and what may seem like sensible ideas often fail. understanding how to approach privacy protection requires rigor in two senses: spelling out what ﬁprivacy protectionﬂ means and explaining the extent to which a particular technique succeeds in providing protection.for example, assume that all the data are held by a trustworthy curator, who answers queries about them while attempting to ensure privacy. clearly, queries about the data on any specic person cannot be answered, for example, what is the sicklecell status of averill harriman? it is therefore instructive to consider the common suggestion of insisting that queries be made only on large subsets of the complete database. a wellknown differencing argument (the ﬁset differencingﬂ attack) demonstrates the inadequacy of the suggestion: if the database permits the user to learn exact answers, say, to the two questions, how many people in the database have the sicklecell trait? and, how many peoplešnot named xšin the database have the sicklecell trait? then the user learns x™s sicklecell trait status. the example also shows that encrypting the data (another frequent suggestion) would be of no help. encryption protects against an intruder, but in this instance the privacy compromise emerges even when the database is operated correctly, that is, in conformance with all stated security policies.another suggestion is to monitor query sequences to rule out attacks of the nature just described. such a suggestion is problematic for two reasons: it may be computationally infeasible to determine whether a query sequence compromises privacy,10 and, more surprising, the refusal to answer a query may itself reveal information.11a different approach to preventing the set differencing attack is to add random noise to the true answer to a query; for example, the response to a query about the average income of a set of individuals is the sum of the true answer and some random noise. that approach has merit, but it must be used with care. otherwise, the same query may be issued over and over and each time produce a different perturbation of the truth. with enough queries, the noise may cancel out and reveal the true answer. insisting that a given query always results the same answer is problematic in that it may be impossible to decide whether two syntactically different queries 10 j. kleinberg, c. papadimitriou, and p. raghavan, ﬁauditing boolean attributes,ﬂ pp. 8691 in proceedings of 19th acm symposium on principles of database systems, association for computing machinery, new york, n.y., 2000.11 k. kenthapadi, n. mishra, and k. nissim, ﬁsimulatable auditing,ﬂ pp. 118127 in proceedings of the 24th acm symposium on principles of database systems, association for computing machinery, new york, n.y., 2005.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix l 269are semantically equivalent. related lower bounds on noise (the degree of distortion) can be given as a function of the number of queries.12l.2.3 private computationthe cryptographic literature on private computation addresses a distinctly different goal known as secure function evaluation.13 in this work, the term private has a specic technical meaning that is not intuitive and is described below. to motivate the description, recall the original description of privacypreserving data analysis as permitting the learning of some facts in a data set while keeping other facts secret. if privacy is to be completely protected, some things simply cannot be learned. for example, suppose that the database has scholastic records of students in middletown high school and that the middletown school district releases the fact that no student at the school has a perfect 5.0 average. that statement compromises the privacy of every student known to be enrolled at the schoolšit is now known, for example, that neither sergey nor laticia has a 5.0 average. arguably, that is no one else™s business. (some might try to argue that no harm comes from the release of such information, but this is defeating the example without refuting the principle that it illustrates.) similarly, publishing the average net worth of a small set of people may reveal that at least one person has a very high net worth; a little extra information may allow that person™s identity to be disclosed despite her modest lifestyle.private computation does not address those difculties, and the question of which information is safe to release is not the subject of study at all.14 rather, it is assumed that some facts are, by at, going to be released, for example, a histogram of students™ grade point averages or average income by block. the ﬁprivacyﬂ requirement is that no information that cannot be inferred from those quantities will be leaked. the typical setting is that each person (say, each student in middletown high school) partici12 i. dinur and k. nissim, ﬁrevealing information while preserving privacy,ﬂ pp. 202210 in proceedings of the 22nd acm sigmodsigactsigart symposium on principles of database systems, association for computing machinery, new york, n.y., 2003; c. dwork, f. mcsherry, and k. talwar, ﬁthe price of privacy and the limits of lp decoding,ﬂ pp. 8594 in proceedings of the 39th annual acm sigact symposium on theory of computing, association for computing machinery, new york, n.y., 2007. see also the related work on compressed sensing cited in the latter.13 o. goldreich, s. micali, and a. wigderson, ﬁhow to solve any protocol problem,ﬂ pp. 218229 in proceedings of the 19th acm sigact symposium on computing, association for computing machinery, new york, n.y., 1987.14 o. goldreich, s. micali, and a. wigderson, ﬁhow to solve any protocol problem,ﬂ pp. 218229 in proceedings of the 19th acm sigact symposium on computing, association for computing machinery, new york, n.y., 1987.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.270 protecting individual privacy in the struggle against terroristspates in a cryptographic protocol whose goal is the cooperative computing of the quantity of interest (the histogram of grade point averages) and that the cryptographic protocol will not cause any information to be leaked that a student cannot infer from the histogram and his or her own data (that is, from the grade point histogram and his or her own grade point average).l.2.4 the need for rigorprivacypreservation techniques typically involve altering raw data or the answers to queries. those general actions are referred to as input perturbation and output perturbation,15 depending on whether the alterations are made before the queries or in response to them. various methods are used for input and output perturbation. some involve redaction of information (for example, removing ﬁrealﬂ identiers, the use of indirect identiers, selective reporting, or forms of aggregation) or alteration of data elements by adding noise, swapping, recoding (for example, collapsing categories), and data simulation.16 but no matter 15 a relevant survey article is n. adam and j. wortmann, ﬁsecuritycontrol methods for statistical databases: a comparative study,ﬂ acm computing surveys 21(4):515556, 1989. some approaches postdating the survey are given in l. sweeney, ﬁachieving kanonymity privacy protection using generalization and suppression,ﬂ international journal on uncertainty, fuzziness and knowledgebased systems 10(5):557570, 2002; a. evmievski, j. gehrke, and r. srikant, ﬁlimiting privacy breaches in privacy preserving data mining,ﬂ pp. 211222 in proceedings of the twentysecond acm sigactsigmodsigart symposium on principles of database systems, association for computing machinery, new york, n.y., 2003; and c. dwork, f. mcsherry, k. nissim, and a. smith, ﬁcalibrating noise to sensitivity of functions in private data analysis,ﬂ pp. 265284 in proceedings of the thirtyninth annual acm symposium on theory of computing, association for computing machinery, new york, n.y., 2006, and references therein.16 many of these methods are described in the following papers: s.e. fienberg, ﬁcon˚icts between the needs for access to statistical information and demands for condentiality,ﬂ journal of ofcial statistics 10(2):115132, 1994; federal committee on statistical methodology, ofce of management and budget (omb), ﬁstatistical policy working paper 2. report on statistical disclosure and disclosureavoidance techniques,ﬂ omb, washington, d.c., 1978, available at http://www.fcsm.gov/workingpapers/sw2.html; federal committee on statistical methodology, omb, ﬁstatistical policy working paper 22 (second version, 2005), report on statistical disclosure limitation methodology,ﬂ originally prepared by subcommittee on disclosure limitation methodology, omb, washington, d.c., 1994, and revised by the condentiality and data access committee, 2005, available at http://www.fcsm.gov/workingpapers/spwp22.html. many of these techniques are characterized as belonging to the family of matrix masking methods in g.t. duncan and r.w. pearson, ﬁenhancing access to microdata while protecting condentiality: prospects for the future (with discussion),ﬂ statistical science 6:219239, 1991. the use of these techniques in a publicpolicy context is set by the following publications: national research council (nrc), private lives and public policies: condentiality and accessibility of government statistics, g.t. duncan, t.b. jabine, protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix l 271what the technique or approach, there are two basic questions: what does it mean to protect the data? how much alteration is required to achieve that goal?the need for a rigorous treatment of both questions cannot be overstated, inasmuch as ﬁpartially protecting privacyﬂ is an oxymoron. an extremely important and often overlooked factor in ensuring privacy is the need to protect against the availability of arbitrary context information, including other databases, books, newspapers, blogs, and so on.consider the anonymization of a socialnetwork graph. in a social network, nodes correspond to people or other social entities, such as organizations or web sites, and edges correspond to social links between them, such as email contact or instantmessaging. in an effort to preserve privacy, the practice of anonymization replaces names with meaningless unique identiers. the motivation is roughly as follows: the social network labeled with actual names is sensitive and cannot be released, but there may be considerable value in enabling the study of its structure. anonymization is intended to preserve the pure unannotated structure of the graph while suppressing the information about precisely who has contact with whom. the difculty is that anonymous socialnetwork data almost never exist in the absence of outside context, and an adversary can potentially combine this knowledge with the observed structure to begin compromising privacy, deanonymizing nodes and even learning the edge relations between explicitly named (deanonymized) individuals in the system.17a more traditional example of the difculties posed by context begins with the publication of redacted condential data. the census bureau receives condential information from enterprises as part of the economic census and publishes a redacted version in which identifying information on companies is suppressed. at the same time, a company may release information in its annual reports about the number of shares held by particular holders of very large numbers of shares. although the redaction may be privacyprotective, by using very simple linkage tools on the redacted data and the public information, an adversary will be able to add back some of the identifying tags to the redacted condential data. roughly speaking, those tools allow the merging of data sets that contain, for example, different types of information about the same set of entities. and v.a. de wolf, eds., national academy press, washington, d.c., 1993; nrc, expanding access to research data: reconciling risks and opportunities, the national academies press, washington, d.c., 2005.17 l. backstrom, c. dwork, and j. kleinberg, ﬁwherefore art thou r3579x? anonymized social networks, hidden patterns, and structural steganography,ﬂ pp. 181190 in proceedings of the 16th international conference on world wide web, 2007, available at http://www2007.org/proceedings.html.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.272 protecting individual privacy in the struggle against terroriststhe key point is that entities need not be directly identiable by name to be identied. companies can be identied by industrial code, size, region of the country, and so on. any public company can be identied by using a small number of such variables, which may well be deduced from the company™s public information and thus provide a means of matching against the condential data.similarly, individuals need not be identied only by their names, addresses, or social security numbers. the linkage software may use any collection of data elds, or variables, to determine that records in two distinct data sets correspond to the same person. and if the ﬁprivacyprotectedﬂ or deidentied records include values for additional variables that are not yet public, simple recordlinkage tools might let an intruder identify a person (that is, match les) with high probability and thus leak this additional information in the deidentied les. for example, an adversary may use publicly available data, including newspaper accounts from new orleans on the effects of hurricane katrina and who was rescued in what efforts, to identify people with unusual names in a condential epidemiologic data set on rare genetic diseases gathered by the centers for disease control and prevention and thus learn all the medical and genetic information about the individuals that redaction was supposed to protect.for a nal, smallscale, example, consider records of hospital emergencyroom admissions, which contain such elds as name, year of birth, zip code, ethinicity, and medical complaint. the combinations of elds are known to identify many people uniquely. such a collection of attributes is called a quasiidentier. in microaggregation, or what is known as kanonymization, released data are ﬁcoarsenedﬂ; for example, zip codes with the same rst four digits are lumped together, so for every possible value of quasiidentier, the data set contains at least k records. however, if someone sees an ambulance at his or her neighbor™s house during the night and consults the published hospital emergencyroom records the following day, he or she can learn a small set of complaints that contains the medical complaint of the neighbor. additional information known to that person may allow the neighbor™s precise complaint to be pinpointed.context also comes into play in how different privacypreserving techniques interact when they are applied to different databases. for example, the work of dwork et al. rigorously controlled the amount of information leaked about a single record.18 if several databases, all containing the same record, use the same technique, and if the analyst has 18 c. dwork, f. mcsherry, k. nissim, and a. smith, ﬁcalibrating noise to sensitivity of functions in private data analysis,ﬂ pp. 265284 in proceedings of the 3rd theory of cryptography conference, association for computing machinery, new york, n.y., 2006. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix l 273access to all these databases, the cumulative erosion of privacy of the given record may be as great as the sum of the leakages suffered in the separate databases that contain it.and that is a good case! the many methods in elds spanning computer science, operations research, economics, and statistics deal with data of different types recorded in many forms. for a targeted set of methods and specic kinds of data, although there may be results that can ﬁguaranteeﬂ privacy in a released data le or a system responding to a series of queries, many wellknown approaches fail to offer such guarantees or even weaker assurances. for example, some literature on data imputation for privacy protection never denes privacy at all;19 thus, it is difcult to assess the extent to which the methods, although heuristically reasonable, actually guarantee privacy.l.2.5 the effect of data errors on privacyin the real world, data records are imperfect. for example, honest people make errors when providing information. clerical errors yield ˚awed recording of correct data. many data values may be measurements of quantities that regularly ˚uctuate or that for various other reasons are subject to measurement error. because of imperfections in the data, a person may be mischaracterized as problematic. that is, the prole may be perfect, but the system may be operating with bad data. that appears to be an accuracy problem, but for several reasons it also constitutes a privacy problem.although we have not discussed a denition of privacy, the recent literature studies the appropriate technical denition at length. the approach favored in the cryptography community, modied for the present context, says that for anyone whose true data do not t the prole, there is (in a quantiable sense) almost no difference between the behavior of a sys19 d.b. rubin, ﬁdiscussion: statistical disclosure limitation,ﬂ journal of ofcial statistics 9(2):461468, 1993; t.e. raghunathan, j.p. reiter, and d.b. rubin, ﬁmultiple imputation for statistical disclosure limitation,ﬂ journal of ofcial statistics 19(2003):119, 2003. however, there is also a substantial literature that does provide an operational assessment of privacy and privacy protection. for example, see g.t. duncan and d. lambert, ﬁthe risk of disclosure for microdata,ﬂ journal of business and economic statistics 7:207217, 1989; e. fienberg, u.e. makov, and a.p. sanil, ﬁa bayesian approach to data disclosure: optimal intruder behavior for continuous data,ﬂ journal of ofcial statistics 13:7589, 1997; and j.p. reiter, ﬁestimating risks of identication disclosure for microdata,ﬂ journal of the american statistical association 100(2005):11031113, 2005. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.274 protecting individual privacy in the struggle against terroriststem that contains the person™s data and the behavior of a system that does not. that is, the behavior of the system in the two cases should be indistinguishable; it follows that the increase in the risk of adverse effects of participating in a data set is small. that approach allows us to avoid subjective decisions about which type of information leakage constitutes a privacy violation. clearly, indistinguishability can fail to hold in the case of a nonterrorist whose data are incorrectly recorded. the harm to a person of appearing to satisfy the perfect prole may be severe: the person may be denied credit and the freedom to travel, be prevented from being hired for some jobs, or even be prosecuted. finally, at the very least, such a misidentication will result in further scrutiny and consequent loss of privacy. (see gavison on protection from being brought to the attention of others.20)the problem of errors is magnied by linkage practices because errors tend to propagate. consider a database, such as the one assembled by choicepoint by linking multiple databases. consider, say, three separate databases created by organizations a, b, and c. if a and b are extremely scrupulous about preventing data errors but c is not, the integrated database will contain inaccuracies. the accuracy of the integrated database is only as good as the accuracy of the worst input database. furthermore, if each database contains errors, they may well compound to create a far greater percentage of les with errors in the integrated database. finally, there are the errors of matching themselves, which are inherent in record linkage; if these are as substantial as the literature on record linkage suggests,21 the level of error in the merged database is magnied, and this poses greater risks of misidentication.all the above difculties are manifested even when a perfect prole is developed for problematic people. but imperfect proles combined with erroneous data will lead to higher levels of false positives than either alone. moreover, if we believe that data are of higher quality and that proles are more accurate than they actually are, the rate of false negativesšpeople who are potential terrorists but go undetectedšwill also grow, and this endangers all of us.record linkage also lies at the heart of datafusion methods and has major implications for privacy protection and harm to people. the 20 r. gavison, ﬁprivacy and the limits of the law,ﬂ pp. 332351 in computers, ethics, and social values, d.g. johnson and h. nissenbaum, eds., prentice hall, upper saddle river, n.j., 1995.21 w.e. winkler, overview of record linkage and current research directions, statistical research report series, no. rrs2006/02, u.s. bureau of the census, statistical research division, washington, d.c., 2006, and w.e. winkler, ﬁthe quality of very large databases,ﬂ proceedings of quality in ofcial statistics, 2001, cdrom (also available at http://www.census.gov/srd/www/byyear.html as rr01/04).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix l 275literature on record linkage22 makes it clear that to achieve low rates of error (high accuracy) one needs both ﬁgoodﬂ variables for linkage (such as names) and ways to organize the data by ﬁblocks,ﬂ such as city blocks in a census context or welldened subsets of individuals characterized by variables that contain little or no measurement error. as measurement error grows, the quality of matches deteriorates rapidly in techniques based on the fellegisunter method. similarly, as the size of blocks used for sorting data for matching purposes grows, so too do both the computational demands for comparing records in pairs and the probabilities of correct matches. lowquality recordlinkage results will almost certainly increase the rates of both false positives and false negatives when merged databases are used to attempt to identify terrorists or potential terrorists. false negatives correspond to the failure of systems to detect terrorists when they are present and represent a systemic failure. false positives impinge on individual privacy. government uses of such methods, either directly or indirectly, through the acquisition of commercial databases constructed with fusion technologies need to be based on adequate information on data quality especially as related to recordlinkage methods.l.3 enhancing privacy through informationsystem designsome aspects of informationsystem design are related to the ability to protect privacy while maintaining effectiveness, and there are many designs (and tradeoffs among those designs) for potential public policies regarding data privacy for information systems. moreover, times and technology have changed, and a new set of policies regarding privacy and information use may be needed. to be rational in debating and choosing the policies and regulations that will provide the most appropriate combination of utility (such as security) and privacy, it is helpful to consider the generic factors that in˚uence both. this section lists the primary components of informationsystem design that are related to privacy and indicates the issues that are raised in considering various options.l.3.1 data and privacya number of factors substantially in˚uence the effects of a deployed information system on privacy. debates and regulations can benet from differentiating systems and applications on the basis of the following:22 see, for example, t.n. herzog, f.j. scheuren, and w.e. winkler, data quality and record linkage techniques, springer science and business media, new york, n.y., 2007.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.276 protecting individual privacy in the struggle against terroristswhich data features are collected. in wiretapping, recording the fact that person a telephoned person b might be less invasive than recording the conversation itself.covertness of collection. data may be collected covertly or with the awareness of those being monitored. for example, images of airport passengers might be collected covertly throughout the airport or with passenger awareness at the security checkin.dissemination. data might be collected and used only for a local application (for example, at a security checkpoint) or might be disseminated widely in a nationwide data storage facility accessible to many agencies. retention periods. data might be destroyed within a specied period or kept forever.use. data might be restricted to a particular use by policy (for example, anatomically revealing images of airport passengers might be available for the sole purpose of checking for hidden objects) or unrestricted for arbitrary future use. one policy choice of particular importance is whether the data are subject to court subpoena for arbitrary purposes or the ability to subpoena is restricted to specied purposes.audit trail. an audit trail (showing who accessed the data and when) should be kept. control of permissions. if data are retained, policy might specify who can grant permission for dissemination and use (for example, the collector of the data, a court, or the subject of the data).trust. the perception of privacy violations depends heavily on the trust of the subject that the government and everyone who has access to the data will abide by the stated policy on data collection and use.analytical methods involved. analysis of data collected or the presentation of analytical results might be restricted by policy. for example, in searching for a weapon at a checkpoint, a scanner might generate anatomically correct images of a person™s body in graphic detail. what is of interest is not those images but rather the image of a weapon, so analytical techniques that detected the presence or absence of a weapon in a particular scan could be used, and that fact (presence or absence) could be reported rather than the image itself.l.3.2 information systems and privacychapter 2 describes a framework for assessing informationbased programs. but the specics of program™s implementation make a huge difference in the extent to which it protects (or can protect) privacy. the following are some of the implementation issues that arise.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix l 277does the application require access to data that explicitly identify individuals? applications such as searching a database for all information about a particular person clearly require access to data that are associated with individual names. other applications, such as discovering the pattern of patient symptoms that are predictive of a particular disease, need not necessarily require that individual names be present.does the application require that individually identied data be reported to its human user, and, if so, under what conditions? some computer applications may require personally identied data but may not need to report personal identications to their users. for example, a program to learn which overthecounter drug purchases predict emergencyroom visits for in˚uenza might need personally identied data of drug purchases so that it can merge them with personally identied emergencyroom records, but the patterns that it learns and reports to the user need not necessarily identify individuals or associate specic data with identiable individuals. other systems might examine many individually identied data records but report only records that match a criterion specied by a search warrant. is the search of the data driven by a particular starting point or person, or is it an indiscriminate search of the entire data set for a more general pattern? searches starting with a particular lead (for example, find all people who have communicated with person a in the preceding week) differ from searches that consider all data equally (for example, find all groups of people who have had email exchanges regarding bombs). the justication for the former hinges on the justication for suspecting person a; the latter involves a different type of justication.can the data be analyzed with privacyenhancing methods? technologies in existence and under development may in some cases enable discovery of general patterns and statistics from data while providing assurances that features of individual records are not divulged.does the data analysis involve integrating multiple data sources from which additional features can be inferred, and, if so, are these features inferred and reported to the user? in some cases, it is possible to infer data features that are not explicit in the data set, especially when multiple data sets are merged. for example, it is possible in most cases to infer the names of people associated with individual medical records that contain only birthdates and zip codes if that data set is merged with a census database that contains names, zip codes, and birthdates. l.4 statistical agency data and approaches government statistical agencies have been concerned with condentiality protection since early in the 20th century and work very hard to protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.278 protecting individual privacy in the struggle against terroristsﬁdeidentifyﬂ information gathered from establishments and individuals. they have developed methods for protecting privacy. their goals are to remove information that could be harmful to a respondent from released data and to protect the respondents from identication. as a consequence, released statistical data, even if they may be related to individuals, are highly unlikely to be linkable with any reasonable degree of precision to other databases that are of use in prevention of terrorism. that is, the nature of redaction of individually identiable information seems to yield redacted data that are of little value for this purpose. l.4.1 condentiality protection and public data releasestatistical agencies often promise condentiality to their respondents regarding all data provided in connection with surveys and censuses, and, as noted above, these promises are often linked to legal statutes and provisions. but the same agencies have a mandate to report the results of their datacollection efforts to others either in summary form or in tables, reports, and publicuse microdata sample (pums) les. pums les are computeraccessible les that contain records of a sample of housing units with information on the characteristics of each unit and the people in it. the data come in the form of a sample of a much larger population; as long as direct identiers are removed and some subset of other variables ﬁaltered,ﬂ there is broad agreement that sampling itself provides substantial protection. roughly speaking, the probability of identifying an individual™s record in the sample le is proportional to the probability of selection into the sample (given that it is not known whether a given individual is in the sample).23 (in particular, if a person is not selected for the sample, the person™s data are not collected and his or her privacy is protected.) it is also possible to provide privacy guarantees even in the worst case (that is, worst case over sampling).24nonetheless, many of the methods used by the agencies are ad hoc and may or may not ﬁguaranteeﬂ privacy on their own, let alone when used with combining data from multiple databases. nor would they satisfy the technical denitions of privacy described above. rather, they represent an effort to balance data access with condentiality protectionšan 23 see e.a.h. elamir and c. skinner, ﬁrecord level measures of disclosure risk for survey microdata,ﬂ journal of ofcial statistics 22(3):525539, 2006, and references therein.24 a. evmievski, j. gehrke and r. srikant, ﬁlimiting privacy breaches in privacy preserving data mining,ﬂ pp. 211222 in proceedings of the twentysecond acm sigactsigmodsigart symposium on principles of database systems, acm, new york, n.y., 2003; c. dwork, f. mcsherry, k. nissim, and a. smith, ﬁcalibrating noise to sensitivity of functions in private data analysis,ﬂ pp. 265284 in 3rd theory of cryptography conference, acm, new york, n.y., 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix l 279approach that ts with technical statistical frameworks.25 such tradeoffs may be considered informally, but there are various formal sets of tools for their quantication.26duncan and stokes apply such an approach to the choice of ﬁtopcodingﬂ for income, that is, truncating the income scale at some maximum value.27 they illustrate tradeoff choices for different values of topcoding in terms of risk (of reidentication through a specic form of record linkage) and utility (in terms of the inverse mean square error of estimation for the mean or a regression coefcient).for some other approaches to agency condentiality and data release in the european context, see willenborg and de waal.28l.4.2 record linkage and public use filesone activity that is highly developed in the context of statisticalagency data is record linkage. the original method that is still used in most approaches goes back to pioneering work by fellegi and sunter, who used formal probabilistic and statistical tools to decide on matches and nonmatches.29 inherent in the method is the need to assess accuracy of matching and error rates associated with decision rules.30 the same ideas are used, with renements, by the census bureau 25 for a discussion of the approaches to tradeoffs, see the various chapters in condentiality, disclosure and data access: theory and practical applications for statistical agencies, p. doyle, j. lane, j. theeuwes, and l. zayatz, eds., northholland publishing company, amsterdam, 2001. 26 a framework is suggested in g.t. duncan and d. lambert, ﬁdisclosurelimited data dissemination (with discussion),ﬂ journal of the american statistical association 81:1028, 1986. see additional discussion of the riskutility tradeoff by g.t. duncan, s.e. fienberg, r. krishnan, r. padman, and s.f. roehrig, ﬁdisclosure limitation methods and information loss for tabular data,ﬂ pp. 135166 in condentiality, disclosure and data access: theory and practical applications for statistical agencies, p. doyle, j. lane, j. theeuwes, and l. zayatz, eds., northholland publishing company, amsterdam, 2001. a full decisiontheoretic framework is developed in m. trottini and s.e. fienberg, ﬁmodelling user uncertainty for disclosure risk and data utility,ﬂ international journal of uncertainty, fuzziness, and knowledgebased systems 10(5):511528, 2002; and m. trottini, ﬁa decisiontheoretic approach to data disclosure problems,ﬂ research in ofcial statistics 4(1):722, 2001.27 g.t. duncan and s.l. stokes, ﬁdisclosure risk vs. data utility: the ru condentiality map as applied to topcoding,ﬂ chance 3(3):1620, 2004.28 l. willenborg and t. de waal, elements of statistical disclosure control, springerverlag inc., new york, n.y., 2001. 29 i. fellegi and a. sunter, ﬁa theory for record linkage,ﬂ journal of the american statistical association 64:11831210, 1969.30 see, for example, w. winkler, the state of record linkage and current research problems, statistical research report series, no. rr99/04, u.s. census bureau, washington, d.c., 1999; w.e. winkler, ﬁreidentication methods for masked microdata,ﬂ pp. 216230 in privacy in statistical databases, j. domingoferrer, ed., springer, new york, n.y., 2004; m. bilenko, protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.280 protecting individual privacy in the struggle against terroriststo match persons in the current population survey (sample size, about 60,000 households) with irs returns. the census bureau and the irs provide the data to a group that links the records to produce a set of les that contain information from both sources. the merged les are redacted, and noise is added until neither the census bureau nor the irs can rematch the linked les with their original les.31 the data are released as a form of pums le. those who prepared the pums le have done sufcient testing to offer specic guarantees regarding the protection of individuals whose data went into the preparation of the le. this example illustrates not only the complexity of data protection associated with record linkage but the likely lack of utility of statisticalagency data for terrorism prevention, because linked les cannot be matched to individuals.r. mooney, w.w. cohen, p. ravikumar, and s.e. fienberg, ﬁadaptive namematching in information integration,ﬂ ieee intelligent systems 18(5):1623, 2003.31 for more details, see j.j. kim and w.e. winkler, ﬁmasking microdata les,ﬂ pp. 114119 in proceedings of the survey research methods section, american statistical association, alexandria, va., 1995; j.j. kim and w.e. winkler, masking microdata files, statistical research report series, no. rr973, u.s. bureau of the census, washington, d.c., 1997.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.281mpublic opinion data on u.s. attitudes toward government counterterrorism effortsm.1 introductionsince september 11, 2001 (9/11), americans have been forced to confront con˚ict between the values of privacy and security more directly than at any other time in their history. on one hand, in view of the unprecedented threat of terrorism, citizens must depend on the government to provide for their own and the nation™s security. on the other hand, technological advances mean that government surveillance in the interests of national security is potentially more sweeping in scope and more exhaustive in detail than at any time in the past, and thus it may represent a greater degree of intrusion on privacy and other civil liberties than the american public has ever experienced. in this appendix, we review the results of public opinion surveys that gauge the public™s reaction to government surveillance measures and informationgathering activities designed to foster national security. we attempt to examine the public™s view of the con˚ict between such surveillance measures and preservation of civil liberties.prior to 9/11, the american public™s privacy attitudes were located in the broad context of a tradition of limited government and assertion of note: the material presented in this appendix was prepared by amy corning and eleanor singer of the survey research center of the university of michigan, under contract to the national research council, for the committee responsible for this report. apart from some minor editorial corrections, this appendix consists entirely of the original paper provided by corning and singer.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.282 protecting individual privacy in the struggle against terroriststhe individual rights of citizens. in the past, expanded government powers have been instituted to promote security during national emergencies, but after the emergency receded, such powers have normally been rescinded.1 although this historical context is one crucial in˚uence, attitudes have been further shaped by developments of the postwar period. the importance of civil rights was highlighted by the social revolutions of the 1960s and 1970s, a period also characterized by growing distrust of government; the latter decade also brought legislation designed to secure individuals™ rights to privacy. during the 1980s, developments in computing and telecommunications laid the groundwork for new challenges to privacy rights. the public consistently opposed the consolidation of information on citizens in centralized les or databanks, and federal legislation attempted to preserve existing privacy protections in the context of new technological developments.2 by the 1990s, however, technological advancesšincluding the rise of the internet, the widespread adoption of wireless communication, the decoding of human dna, the development of data mining software, increasing automation of government records, the increasing speed and decreasing cost of computing and online storage poweršoccurred so quickly that they outpaced efforts to modify legislation to protect privacy, as well as the public™s ability to fully comprehend their privacy implications, contributing to high salience of privacy considerations and concerns.3the terrorist attacks of september 11, 2001, thus occurred in a charged environment, in which the public already regarded both business and government as potential threats to privacy. almost immediately, the passage of the patriot act in 2001 raised questions about the appropriate nature and scope of the government™s expanded powers and framed the public debate in terms of a sacrice of civil liberties, including privacy, in the interests of national security. citizens appeared willing to make such sacrices at a time of national emergency, however, and in the months following 9/11, tolerance for government antiterrorism surveillance was extremely high. nevertheless, the public did not uncritically accept government intrusions: to use westin™s term, they exhibited ﬁrational ambivalenceﬂ by simultaneously expressing support for surveillance and 1 a.f. westin, ﬁhow the public sees the securityversusliberty debate,ﬂ pp. 1936 in protecting what matters: technology, security, and liberty since 9/11 (c. northouse, ed.), brookings institution press, washington, d.c., 2005.2 a.f. westin, ﬁsocial and political dimensions of privacy,ﬂ journal of social issues 59(2):411429, 2003.3 a. corning and e. singer, survey of u.s. privacy attitudes, report prepared for the center for democracy and technology, washington, d.c., 2003.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 283concern about protection of civil liberties as the government employed its expanded powers in investigating potential terrorist threats.4like other analysts,5 we nd that acceptance of government surveillance measures has diminished over the years since 9/11, and that people are now both less convinced of the need to cede privacy and other civil liberties in the course of terrorism investigation and personally less willing to give up their freedoms. we show that critical views are visible in the closely related domains of attitudes toward individual surveillance measures and toward recently revealed secret surveillance programs. more generally, public pessimism about protection of the right to privacy has increased.westin identied ve in˚uences on people™s attitudes toward the balance between security and civil liberties: perceptions of terrorist threat; assessment of government effectiveness in dealing with terrorism; perceptions of how government terrorism prevention programs are affecting civil liberties; prior attitudes toward security and civil liberties; and broader political orientations, which may in turn be shaped by demographic and other social background factors.6 this review conrms the role of these in˚uences on public attitudes toward privacy and security in the post9/11 era.this examination of research on attitudes toward government surveillance since 9/11 leads us to draw the following general conclusions:1. as time from a direct terrorist attack on u.s. soil increases, the public is growing less certain of the need to sacrice civil liberties for terrorism prevention, less willing to make such sacrices, and more concerned that government counterterrorism efforts will erode privacy.2. tolerance for most individual surveillance measures declined in the ve years after 9/11. the public™s attitudes toward recently revealed monitoring programs are mixed, with no clear consensus.3. there is no strong support for health information databases that could be used to identify bioterrorist attacks or other threats to public health.4 the term is westin™s. see a.f. westin, ﬁhow the public sees the securityversusliberty debate,ﬂ pp. 1936 in protecting what matters: technology, security, and liberty since 9/11 (c. northouse, ed.), brookings institution press, washington, d.c., 2005.5 see, for example, a.f. westin, ﬁhow the public sees the securityversusliberty debate,ﬂ pp. 1936 in protecting what matters: technology, security, and liberty since 9/11 (c. northouse, ed.), brookings institution press, washington, d.c., 2005; s.j. best, b.s. krueger, and j. ladewig, ﬁprivacy in the information age,ﬂ public opinion quarterly, 70(3):375401, 2006.6 a.f. westin, ﬁhow the public sees the securityversusliberty debate,ﬂ pp. 1936 in protecting what matters: technology, security, and liberty since 9/11 (c. northouse, ed.), brookings institution press, washington, d.c., 2005.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.284 protecting individual privacy in the struggle against terrorists4. however, few citizens feel that their privacy has been affected by the government™s antiterrorism efforts.5. the public tends to defend civil liberties more vigorously in the abstract than in connection with threats for specic purposes. despite increasingly critical attitudes toward surveillance, the public is quite willing to endorse specic measures, especially when the measures are justied as necessary to prevent terrorism.6. however, most people are more tolerant of surveillance when it is aimed at specic racial or ethnic groups, when it concerns activities they do not engage in, or when they are not focusing on its potential personal impact. we note that people are not concerned about privacy in general, but rather with protecting the privacy of information about themselves.7. people are concerned with control over decisions related to privacy.8. attitudes toward surveillance and the appropriate balance between rights and security are extremely sensitive to situational in˚uences, particularly perceptions of threat.9. the framing of survey questions, in terms of both wording and context, strongly in˚uences the opinions elicited.m.2 data and methodologyin this appendix, we examine data from relevant questions asked by major research organizations in surveys since september 11, 2001, incorporating data from before that point when they are directly comparable to the later data or when they are pertinent. this review concentrates on trends, based on the same or closely similar questions that have been asked at multiple time points; we occasionally discuss the results from questions asked at only one point in time, when the information is illuminating or when trend data on a particular subject are not available. we restrict this review to surveys using adult national samples (or occasionally, national samples of registered voters); for the most part, these surveys are conducted by telephone using randomdigitdialed (rdd) samples,7 although occasionally we report on surveys conducted by personal inter7 these survey results may be biased by the fact that most or all of the surveys used did not attempt to reach cellphoneonly respondents; that is, the phone numbers called were land lines. in an era in which many individuals are using cell phones only, these surveys will not have reached many of such individuals. an article by the pew research center for the people and the press suggests that this problem is not currently biasing polls taken for the entire population, although it may very well be damaging estimates for certain subgroups (e.g., young adults) in which the use of a cell phone only is more common. (see s. keeter, ﬁhow serious is polling™s cellonly problem? the landlineless are different and their numbers are growing fast,ﬂ pew research center for the people and the press, june 20, 2007, available at http://pewresearch.org/pubs/515/pollingcellonlyproblem.)protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 285view. we have not reviewed web surveys. in the few instances in which samples represent groups other than the u.s. national adult population, we indicate that in the text or relevant charts or tables.survey list and intext citations. the annex at the end of this appendix lists the surveys to which we refer, identifying research organizations and sponsors as well as details on administration dates, mode, and sample design. (response rate information is not available.) the abbreviations used in the text to identify the survey research organizations are also listed. the source citations in the text and in charts and tables are keyed to this list via the abbreviation identifying the research organization and survey date. source citations appear as close as possible to the reported data; in other words, for data reported in gures or tables, the sources are generally indicated on the gures or tables.response rates. we alert readers that response rates to national rdd sample surveys have declined. in a study reported in 2006, mean response rates for 20 national media surveys were estimated at 22 percent, using american association for public opinion research response rates rr3 or rr4, with a minimum of 5 percent and a maximum of 40 percent. mean response rates for surveys done by government contractors (n = 7 for such surveys) during the same period were estimated at 46 percent, with minimums of 28 percent and maximums of 70 percent.8we also note that we have no way of detecting or estimating nonresponse bias. recent research on the relationship between nonresponse rates and nonresponse bias indicates that there is no necessary relationship between the two.9 a 2003 pew research center national study of nonresponse rates and nonresponse bias shows signicant differences on only 7 of 84 items in a comparison of a survey achieving a 25 percent response rate and one achieving a 50 percent response rate through the use of more rigorous methods.10 two other studies also report evidence that, despite very low response rates, nonresponse bias in the surveys examined has 8 a.l. holbrook, j.a kronsnick, and a. pfent, ﬁresponse rates in surveys by the news media and government survey research firms,ﬂ paper presented at the second conference on telephone survey methodology, miami, fla., january 14, 2006.9 r.m. groves, ﬁnonresponse rates and nonresponse bias in household surveys,ﬂ public opinion quarterly 70(5):646675, 2006.10 s. keeter, c. kennedy, m. dimock, j. best, and p. craighill, ﬁgauging the impact of growing nonresponse on estimates from a national rdd telephone survey,ﬂ public opinion quarterly 70(5):759779, 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.286 protecting individual privacy in the struggle against terroristsbeen negligible.11 these ndings cannot, however, be generalized to the surveys used for this current examination. thus, the possibility of nonresponse bias in the ndings reported cannot be ruled out, nor is there a way to estimate the direction of the bias, if it exists.we can speculate that nonresponse bias in the surveys reviewed here might result, on one hand, in an overrepresentation of individuals especially concerned about privacy or civil liberties, if they are drawn to such survey topics; on the other hand, nonresponse might be greatest among those most worried about threats to privacy, if they refuse to participate in surveys. of the over 100 surveys used in this review, however, most are generalpurpose polls that include some questions about privacy or civil liberties among a larger number of questions on broad topics, such as current social and political affairs, health care attitudes or satisfaction with medical care, technology attitudes, terrorism, etc. fewer than 1 in 10 of the surveys examined could be construed as focusing primarily or even substantially on privacy or civil liberties. thus, it is unlikely that the survey topics would produce higher response among those concerned with privacy. we expect that whatever bias exists will be in the direction of excluding those most concerned about privacy and that the ndings reported will tend to underestimate levels of privacy concern.sources of data and search strategies. this examination draws on several different sources of survey data. first, we rely on univariate tabulations of opinion polling data that are in the public domain, available through the ipoll databank at the roper center for public opinion research at the university of connecticut (http://www.ropercenter.uconn.edu/dataaccess/ipoll/ipoll.html) and through the institute for resource and security studies (irss) repository at the university of north carolina (http://www.irss.unc.edu/odum/jsp/contentnode.jsp?nodeid=140).we searched these repositories using combinations of the following keywords (or variants thereof): airport security, biometrics, bioterrorism, civil liberties, civil rights, data, database, data mining, health, medical, monitor, personal information, privacy, rights, safety, search, scan, screen, security, surveillance, technology, terrorism, trust, video.second, we searched the reports archived at the pew research center for the people and the press (http://peoplepress.org/reports/) and data compiled by the polling report (http://www.pollingreport.com/).searching was an iterative process, in the course of which we added 11 s. keeter, c. miller, a. kohut, r. groves, and s. presser, ﬁconsequences of reducing nonresponse in a national telephone survey,ﬂ public opinion quarterly 64(2):125148, 2000; r. curtain, s. presser, and e. singer, ﬁthe effects of response rate changes on the index of consumer sentiment,ﬂ public opinion quarterly 64(4):413428, 2000.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 287new keywords. thus, it frequently turned out that the surveys we identied through searches of the irss archives, the pew reports, and the polling report were also archived at the roper center when we searched on the new keywords. since the roper center archive is more complete with respect to details on methodology, and since it allows those interested to easily obtain further data from the cited surveys, we identify it as the source of data, even when we initially identied a survey by searching other sources.third, when tabulations of the original survey data are not available, we draw on reports that research organizations or sponsors have prepared and posted on the internet. these reports were identied via internet searches using the same keywords as for the data archive searches. when referring to data drawn from such reports, the source information included in the text identies both the survey (listed by abbreviation in subsection m.8.3 in the annex) and the report (listed in subsection m.8.4).finally, we refer to several articles by researchers who have conducted their own reviews of poll results or who have conducted independent research on related topics.m.3 organization of this appendixthe remainder of this appendix is divided into four sections. in section m.4, ﬁgeneral privacy attitudes,ﬂ we brie˚y review public opinion on privacy in general, not directly related to antiterrorism efforts, in order to establish a context for understanding attitudes toward government monitoring programs. section m.5, ﬁgovernment surveillanceﬂ begins with an overview of responses to a variety of surveillance measures, as examined in repeated surveys conducted by harris interactive. we then review data on attitudes toward seven specic areas of surveillance or monitoring:ł communications monitoringł monitoring of nancial transactionsł video surveillanceł travel securitył biometric identication technologiesł government use of databases and data miningł public health uses of medical informationsection m.6 is devoted to a consideration of attitudes toward the balance between defense of privacy and other civil rights that may interfere with effective terrorism investigation, on one hand, and terrorism preprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.288 protecting individual privacy in the struggle against terroristsvention measures that may curtail liberties, on the other. here we review survey results on public assessments of the proper balance between liberty and security, as well as trends in perceptions of the need to exchange liberty for security and personal willingness to make such sacrices. in the concluding section, we discuss several factors that affect beliefs about the proper balance between liberty and security.m.4 general privacy attitudesfigure m.1 displays results from a question asked by survey researchers throughout the 1990s: ﬁhow concerned are you about threats to your personal privacy in america today?ﬂ as the chart shows, respondents™ concern about this issue increased steadily throughout the decade; by the last years of the 1990s, roughly 9 in 10 respondents were either ﬁveryﬂ or ﬁsomewhatﬂ concerned about threats to personal privacy. once privacy issues became even more salient after september 11, 2001, the question was presumably no longer able to discriminate effectively between levels of concern about privacy, and it was not asked again by survey organizations.fig m1.eps1990100959085807570199119921994survey yearpercent ﬁveryﬂ or ﬁsomewhatﬂ concerned199519981999figure m.1 ﬁhow concerned are you about threats to your personal privacy in america today?švery concerned, somewhat concerned, not very concerned, or not concerned at all?ﬂ (harris surveys, 19901999). source: a. corning and e. singer, 2003, ﬁsurveys of u.s. privacy attitudes,ﬂ report prepared for the center for democracy and technology.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 289related data for the post9/11 period, however, suggest that general concerns about privacy have not abated. for example, public perceptions of the right to privacy are characterized by increasing pessimism. in july 2002, respondents to a survey conducted by the public agenda foundation were asked ﬁdo you believe that the right to privacy is currently under serious threat, is it basically safe, or has it already been lost?ﬂ (table m.1). onethird of respondents thought it was basically safe, while 41 percent thought it was under serious threat and onequarter regarded it as already lost. by september 2005, when the question was repeated in a cbs/new york times poll, over half thought it was under serious threat, and 30 percent thought it had already been lost. just 16 percent regarded it as ﬁbasically safe.ﬂ such pessimism may re˚ect generalized fears of privacy invasion, fueled by media reports of compromised security and ads that play to anxiety about fraud and identity theft; in addition, it may betray concerns about government intrusions on privacy in the post9/11 era.the perception that privacy is under threat is also due in part to concerns that the privacy of electronic information is difcult, if not impossible, to maintain. over the past decade, survey researchers have repeated a question about online threats to privacy: ﬁhow much do you worry that computers and technology are being used to invade your privacyšis that something you worry about a lot, some, not much, or not at all?ﬂ as figure m.2 shows, at most of the time points, half or more of respondents worried ﬁsomeﬂ or ﬁa lot.ﬂ the ˚uctuations from one observation to the next are probably due to house differences and to question context effects,12 rather than to any substantive change in attitudes, and overall there appears to be a slight trend toward increasing worry about online privacy since 1994. (considered separately, both the princeton survey research associates, psra, and the abc surveys show parallel upward trends.) as best et al. note,13 growing concern about online privacy may be attributed to frequent reports of unauthorized access to or loss of 12 the two observations of lowest levels of concernšjune 1994 and january 2000šboth occurred in surveys carried out by abc. in both cases and in contrast to all the other surveys (including the march 2005 abc/washington post survey), the question about privacy threat from computers immediately followed other questions asking about computers and privacy threat. when survey respondents are asked several questions belonging to the same domain, they tend to avoid redundancy, excluding information used in answering prior questions when answering subsequent ones (see n. schwarz, f. strack, and h.p. mai, ﬁassimilation and contrast effects in partwhole question sequences: a conversational logic analysis,ﬂ public opinion quarterly 55(1):323, 1991). thus, the apparent lower levels of concern in the two abc surveys may result from the fact that respondents had already expressed their concerns when answering previous questions.13 s.j. best, b.s. krueger, and j. ladewig, ﬁprivacy in the information age,ﬂ public opinion quarterly 70(3):375401, 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.290 protecting individual privacy in the struggle against terroristsfig m2.epsjan. 1994 (psra)june 1994 (abc)may 1995 (psra)feb. 1996 (mar)oct. 1998 (psra)jan. 2000 (abc)june 2003 (psra)mar. 2005 (abc/wp)1008060402009070503010survey date (survey organization)percent worrying ﬁa lotﬂ or ﬁsomeﬂtable m.1 right to privacy (public agenda foundation and cbs/new york times surveys)july 2002september 2005percentpercentﬁdo you believe that the right to privacy is currently under serious threat, is it basically safe, or has it already been lost?ﬂabasically safe3416currently under serious threat4152has already been lost2430don™t know 2 2 acbs/nyt 9/05: ﬁdo you believe that currently the right to privacy is basically safe, under serious threat, or has already been lost?ﬂsources: paf/rma 7/02; cbs/nyt 9/05.figure m.2 ﬁhow much do you worry that computers and technology are being used to invade your privacy?ﬂ (surveys by psra, abc news, and marist college, 19942005). note: marist wording: ﬁ. . . that computers and advances in technology used to . . .ﬂ sources: psra/tm 1/94, 5/95; abc 6/94, 1/00; mar 2/96; psra/pew 10/98, 6/03; abc/wp 3/05.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 291electronic data held by a wide variety of institutions, as well as to users™ experience with spam and viruses.these data on electronic privacy suggest that the public identies multiple threats to privacy; surveillance by the federal government may be the most visible and controversial, but it is far from the only, or even the most important threat, in the public™s view. in july 2002, respondents to a national constitution center survey regarded banks and credit card companies as the greatest threat to personal privacy (57 percent), while 29 percent identied the federal government as the greatest threat (paf/rma 7/02). when a similar question was asked in 2005 by cbs/nyt, 61 percent thought banks and credit card companies, alone or in combination with other groups, posed the greatest threat, while 28 percent named the federal government alone or in combination with other groups (cbs/nyt 9/05). (responses cannot be compared directly, because of differences in the response options offered.)m.5 government surveillancem.5.1 trends in attitudes toward surveillance measuresover the years since september 11, 2001, harris interactive has asked a series of questions about support for specic surveillance measures that have been implemented or considered by the u.s. government as part of its terrorism prevention programs. for most of the questions, six or eight observations are available, for the period beginning just one week after the terrorist attacks in september 2001 and extending to july 2006. table m.2 displays percentages of respondents favoring each of the measures at each time point.support for nearly all the measures peaked in the immediate aftermath of the 9/11 attacks, with support for stronger document and security checks and expanded undercover activities exceeding 90 percent. as the emotional response to the attacks subsided over the four years that followed, support for each of the measures declined, in many cases by more than 10 percentage points. as of the june 2005 observation, total decreases in support were fairly small for three of the more intrusive measures, which had not been as enthusiastically received in the rst place: adoption of a national id system, expanded camera surveillance in public places, and law enforcement monitoring of internet discussions. in contrast, support for expanded monitoring of cell phone and email communicationsšwhich had only barely received majority support in september 2001šhad declined by 17 percentage points, to 37 percent, as of june 2005. at each time point it has been the least popular measure, by a margin of 9 or more percentage points.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.292 table m.2 support for government surveillance measures (harris surveys, 20012006)september 2001amarch 2002february 2003february 2004september 2004june 2005february 2006july 2006percentpercentpercentpercentpercentpercentpercentpercenthere are some increased powers of investigation that law enforcement agencies might use when dealing with people suspected of terrorist activity, which would also affect our civil liberties. for each, please say if you would favor or oppose it? (ﬁfavorﬂ)stronger document and physical security checks for travelers93898484838184šstronger document and physical security checks for access to government and private office buildings92898285ššššexpanded undercover activities to penetrate groups under suspicion93888180827682šuse of facial recognition technology to scan for suspected terrorists at various locations and public events86817780ššššcontinuedprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved. 293september 2001amarch 2002february 2003february 2004september 2004june 2005february 2006july 2006percentpercentpercentpercentpercentpercentpercentpercentissuance of a secure id technique for persons to access government and business computer systems, to avoid disruptions84787576ššššcloser monitoring of banking and credit card transactions, to trace funding sources8172676467626661adoption of a national id system for all u.s. citizens68596456606164šexpanded camera surveillance on streets and in public places6358616160596770law enforcement monitoring of internet discussions in chat rooms and other forums6355545059576062expanded government monitoring of cell phones and email, to intercept communications5444443639374452 afieldwork conducted september 1924, 2001.source: hi 9/01, 3/02, 2/03, 2/04, 9/04, 6/05, 2/06, 7/06.table m.2 continuedprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.294 protecting individual privacy in the struggle against terroristsbeginning with the february 2006 observation, however, most of the measures show an upturn in support, probably due to the london underground bombings of july 2005. in particular, the growth in public approval for camera surveillance may have resulted from the role of video camera footage in establishing the identities of the london underground bombers. a year after the london bombings, in july 2006, support for three of the measuresšexpanded camera surveillance, monitoring of chat rooms and other internet forums, and expanded monitoring of cell phones and emailšcontinued to show increases.these data suggest several generalizations. first, people appear more willing to endorse measures that they believe are unlikely to affect them. tolerance for undercover activities targeted at suspected groups has remained at high levels. other data support this conclusion as well: table m.3 shows results from questions about surveillance measures asked in pew surveys, which reveal that acceptance of racial/ethnic proling is also comparatively high. and in surveys carried out by cbs/nyt, respondents were asked whether they ﬁwould be willing to allow government agencies to monitor the telephone calls and email of ordinary americans.ﬂ beginning in 2003, they were also asked the same question with regard to the communications ﬁof americans the government is suspicious of.ﬂ the data, plotted in figure m.3, indicate that support for monitoring the communications of people the government is suspicious of is much higher than support for monitoring those of ordinary americans.second, people are more likely to accept measures that they do not regard as especially burdensome. support has been highest for more rigorous security, both for travelers and for access to buildings; the added inconvenience represented by the extra checks may not seem signicant to respondents. acceptance of surveillance in public places also tends to be high. by contrast, measures intended to monitor the traditionally private domain of communicationsšwhether internet chat rooms or, especially, telephone and email communicationšhave been the least accepted, at each time point.m.5.2 communications monitoringgeneral trends over time. two pieces of research focusing on communications monitoring conrm the harris data trends, mirroring both the longterm decreases in support for monitoring and sensitivity to perceptions of increased threat. first, the cbs/nyt data displayed in figure m.3 show that the trend for ﬁordinary americansﬂ displays the same pattern visible in table m.2, with a slow decline after 9/11 but an upturn discernible in mid2006; here the upturn probably represents a response protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved. 295table m.3 support for government surveillance measures (pew center/psra surveys, 20012006)september 2001august 2002january 2006december 2006personal wordingpersonal wordingimpersonal wordingapersonal wordingpersonal wordingimpersonal wordingapercentpercentpercentpercentpercentpercent ﬁwould you favor or oppose the following measures to curb terrorism?ﬂ (ﬁfavorﬂ)requiring that all citizens carry a national identity card at all times to show to a police officer on request7059š5757šallowing airport personnel to do extra checks on passengers who appear to be of middleeastern descentš59š5757šallowing the u.s. government to monitor your personal telephone calls and emails2622b332422b34allowing the u.s. government to monitor your credit card purchases4032b432926b42 athe word ﬁyourﬂ was omitted from the question text. asked of form 1 half sample. basked of form 2 half sample.source: psra/pew 9/01, 8/02, 1/06, 12/06.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.296 protecting individual privacy in the struggle against terroristsfigure m.3 ﬁin order to reduce the threat of terrorism, would you be willing or not willing to allow government agencies to monitor the . . .ﬂ (surveys by cbs news, 20012006). sources: cbs/nyt 9/01a, 9/01b, 12/01, 11/02, 1/06, 8/06; cbs 1/02a, 1/02b, 2/02, 5/03, 4/05, 5/06.fig m3.epssep. 13œ14, 2001sep. 20œ23, 2001dec. 2001jan. 5œ6, 2002jan. 15œ17, 2002feb. 2002nov. 2002may 2003apr. 2005jan. 2006may 2006aug. 20068060705040302010ﬁtelephone calls and emails of ordinaryamericans on a regular basisﬂﬁtelephone calls and emails of americansthe government is suspicious ofﬂ0survey datepercent willingto media reports of an averted terrorist plot to bomb airplanes bound for the united states. the upturn for ﬁamericans the government is suspicious ofﬂ shows an earlier increase as well, possibly in response to the london underground bombings. second, pew center survey questions on monitoring of communications reveal similar declines in support after the immediate post9/11 period (table m.3).importance of question wording. taken together, the three sets of research by harris, pew, and cbs/nyt (shown in tables m.2 and m.3 and figure m.3) reveal the degree to which attitudes are dependent on specic question wording. the wording of the rst pew question, about a national id program (table m.3), is fairly similar in emphasis to the wording used in the harris surveys (table m.2). levels of support correspond closely across the two questions, starting at 6870 percent in september 2001 and remaining steady at about 60 percent thereafter. in the questions on monitoring of communications and credit card purchases shown protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 297in table m.3, however, pew highlighted the potential personal impact of the measures, asking respondents how they would react to programs that would allow their own phone calls, emails, and credit card purchases to be monitored. the differences are striking: even in september 2001, 54 percent supported the harris measure allowing the government to monitor phone calls and email (harrisštable m.2), but less than half as many reacted favorably to the possibility that their own telephone and email communications might be monitored (pewštable m.3).14 similarly, 81 percent approved of ﬁcloser monitoring of bank and credit card transactionsﬂ in 2001 (harrisštable m.2), but again, just half as many were comfortable with the idea that their own purchases could be monitored (pewštable m.3).at two time points, august 2002 and december 2006, pew used a splitsample experiment that further conrms the impact of wording changes. in these experiments, half the sample was asked the questions about communications and credit card purchase monitoring in the usual form, while the other half of the sample heard the questions in a more impersonal form produced simply by omitting the word ﬁyourﬂ: ﬁallowing the u.s. government to monitor personal telephone calls and emailsﬂ; ﬁallowing the u.s. government to monitor credit card purchases.ﬂ results for the personal and impersonal wording are compared in table m.3. on both measures, the impersonal wording boosted support by 11 or more percentage points at each observation.telephone records database program. in may 2006, it was disclosed that the national security agency (nsa) was compiling a database containing the telephone call records of millions of ordinary american citizens, using information obtained from verizon, at&t, and bellsouth. survey organizations responded to the ensuing controversy by asking respondents about their reactions. the public was divided: approval for the program ranged between 43 and 63 percent, with levels of support predictably varying by question wording (table m.4). gallup™s question, which emphasized the scope of the database and the participation of the telephone companies and mentioned terrorism only at the very beginning of a long question, showed the lowest support, at 43 percent. when questions mentioned a more menacing ﬁthreat of terrorismﬂ or ﬁterrorist activity,ﬂ as the cbs and fox news questions did, about half of respondents favored the measure. the abc news/wp question, which includes two mentions of terrorism and is the only question to note that 14 one further difference in these questions is that the harris wording includes the phrases ﬁto intercept communicationsﬂ and ﬁto trace funding sources,ﬂ which, by reminding respondents of the purpose of the measures, may have helped to justify them. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.298 protecting individual privacy in the struggle against terroriststable m.4 four questions on attitudes toward nsa™s telephone records database program, may 2006approve/support/consider acceptabledisapprove/oppose/consider unacceptableunsurepercentpercentpercentﬁas you may know, as part of its efforts to investigate terrorism, a federal government agency obtained records from three of the largest u.s. telephone companies in order to create a database of billions of telephone numbers dialed by americans. based on what you have read or heard about this program to collect phone records, would you say you approve or disapprove of this government program?ﬂ (gallup/usa today)43516ﬁdo you approve or disapprove of the government collecting the phone call records of people in the u.s. in order to reduce the threat of terrorism?ﬂ (cbs news)51445ﬁas part of a larger program to detect possible terrorist activity, do you support or oppose the national security agency collecting data on domestic phone calls and looking at calling patterns of americans without listening in or recording the calls?ﬂa (opinion dynamics/fox news)52416ﬁit™s been reported that the national security agency has been collecting the phone call records of tens of millions of americans. it then analyzes calling patterns in an effort to identify possible terrorism suspects, without listening to or recording the conversations. would you consider this an acceptable or unacceptable way for the federal government to investigate terrorism?ﬂ (abc/washington post)63352 anational sample of registered voters.sources: gal/usa 5/06, cbs 5/06, od/fox 5/06, abc/wp 5/06.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 299the phone calls are not listened to, found that 63 percent considered the program acceptable.the public™s ambivalence is re˚ected in mixed ndings on concern about the program™s potential personal consequences. more than half (57 percent) said they would feel their privacy had been violated if they learned that their own phone company had provided their records to the government under the program (gal/usa 5/06). but apart from such objections to phone companies releasing information without customers™ approval, respondents do not appear to be overly concerned about personal implications of the program. in answer to questions by gallup and abc, onethird of respondents said they would be ﬁveryﬂ or ﬁsomewhat concerned/botheredﬂ if they found out that the government had records of their phone calls (gal/usa 5/06, abc/wp 5/06). yet despite the size of the database, most people seemed to regard this as an unlikely possibility: only onequarter were ﬁveryﬂ or ﬁsomewhat concernedﬂ that the government might have their personal phone call records (cbs 5/06). thus a minority, albeit a substantial one, expressed concern about the personal implications of the program.when confronted with the con˚icting values of investigating terrorism via the telephone records program on one hand, and the right to privacy on the other, respondents again displayed ambivalence, and different surveys showed majorities giving priority to each value. in the gallup survey, the 43 percent who approved of the program (n = 349) were asked whether they approved because they felt the program did not ﬁseriously violateﬂ civil liberties or because they thought it was more important to investigate terrorism: 69 percent believed that terrorism investigation was the more important goal (gal/usa 5/06). a survey conducted by the winston group (win 5/06; national sample of registered voters) found that 60 percent favored continuing the program because ﬁwe must do whatever we can within the law to prevent another terrorist attack,ﬂ while 36 percent thought it should be discontinued because ﬁit infringes on the right to privacyﬂ (4 percent were unsure). a psra study showed that 41 percent thought the program was ﬁa necessary tool to combat terrorism,ﬂ while 53 percent found that it went ﬁtoo far in invading people™s privacy,ﬂ and 6 percent were undecided (psra/nw 5/06). and when respondents to the cbs survey were asked whether phone companies should share their phone records with the government or whether that was an invasion of privacy, just 32 percent thought the phone companies should share that information, while 60 percent felt it was an invasion of privacy (cbs 5/06).the variation in question wording, and consequently in results, makes it difcult to draw rm conclusions about public attitudes toward the program. what seems clear, however, is that, despite generally low protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.300 protecting individual privacy in the struggle against terroristssupport for surveillance of communications in the abstract, as shown by the harris and particularly the psra/pew results discussed earlier, the public exhibits greater tolerance for specic instances of surveillance, such as the telephone records database programšespecially when the surveillance is justied as an antiterrorist measure.still, between onethird and twothirds in each survey opposed the program. that opposition may betray public skepticism about the effectiveness and accuracy of the program. according to the cbs survey, 46 percent thought the phone call records database program would be ﬁeffective in reducing the threat of terrorism,ﬂ 43 percent thought it would not be effective, and 11 percent were uncertain. and in the gallup survey, twothirds were concerned that the program would misidentify innocent americans (36 percent ﬁvery concernedﬂ and 29 percent ﬁsomewhat concernedﬂ).finally, the public exhibited no clear consensus even on the subject of whether the news media should disclose such secret counterterrorism efforts. in the gallup poll, 47 percent thought the media should report on ﬁthe secret methods the government is using to ght terrorism,ﬂ while 49 percent thought they should not; an abc news/wp poll found that 56 percent thought the news media were right, and 42 percent thought they were wrong to report on the program (abc/wp 5/06).m.5.3 monitoring of financial transactionstables m.2 and m.3 show change in support for government monitoring of individuals™ credit card purchases in surveys conducted by harris and psra/pew between 2001 and 2006. although the two organizations found different overall levels of support owing to specic question wording, both trends show a total decline of 14 to 20 percentage points in the approximately veyear period since september 2001. at each time point, however, support for the monitoring of nancial transactions was greater than for the monitoring of communications.following the revelations about the nsa™s telephone call database program but prior to reports of systematic searches of international banking data carried out by the central intelligence agency/treasury department, several other surveys asked respondents for their opinion on nancial monitoring. among the u.s. sample in a june 2006 survey sponsored by the german marshall fund, 39 percent supported ﬁthe government having greater authority to monitor citizens™ banking transactionsﬂ as part of the effort to prevent terrorism, but 58 percent opposed such powers, and 3 percent were not sure (tns/gmf 6/06). and in a cbs may protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 3012006 survey, only onequarter of respondents thought that credit card companies should ﬁshare information about the buying patterns of their customers with the governmentﬂ (cbs 5/06).after the revelations about the cia/treasury department program, a los angeles times survey found that 65 percent of respondents considered government monitoring of international bank transfers an ﬁacceptableﬂ way to investigate terrorism (lat 7/06)šroughly the same percentage favoring monitoring of nancial transactions in general between 2003 and 2006, as shown by the harris surveys (table m.2). also in july 2006, harris found that 61 percent of respondents favored the monitoring of nancial transactions, a decline of 5 percentage points compared with the previous observation (table m.2), while pew also found a slight decline (table m.3). these data are limited, but they suggest that public support for the government monitoring of nancial transactions either remained stable or declined slightly in response to information about the program.m.5.4 video surveillancetable m.2 shows that, despite initial declines in the years following september 2001, public support for video surveillance has been increasing. the percentages favoring increased video surveillance surpassed the september 2001 level (63 percent) in both february 2006 (67 percent) and july 2006 (70 percent). as noted earlier, the growing favorability may be due to the role of video cameras in identifying suspects in the london underground bombings of 2005.other trend data on video surveillance attitudes also suggest that support is widespread, particularly when linked to terrorism prevention. in 1998, a cbs news poll asked respondents whether installing video cameras on city streets was ﬁa good idea because they may help to reduce crime,ﬂ or ﬁa bad idea because [they] may infringe on people™s privacy rights.ﬂ although more than half thought such cameras were a good idea, 34 percent regarded the cameras as an infringement on privacy (cbs 3/98). the same question, repeated in 2002, generated similar results (cbs 4/02). in july 2005, after the london underground bombings, the question was rephrased to mention reducing ﬁthe threat of terrorismﬂ instead of reducing crime. this time, 71 percent of respondents considered video surveillance a good idea, and just 23 percent thought it a bad idea (cbs 7/05). other data on attitudes to video surveillance at national monumentsšnot explicitly linked to crime or to terrorismšshowed that 81 percent support such surveillance, with only 17 percent nding it an invasion of privacy (cbs 4/02).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.302 protecting individual privacy in the struggle against terroristsm.5.5 travel securitytighter airport security has been a source of frustration for travelers, and media reports perennially question the effectiveness of the measures. nevertheless, the harris data show higher levels of support for passenger screening and searches than for any other measure, both immediately after 9/11 and continuing through 2006 (see table m.2).while respondents are by no means fully convinced of airport security™s effectiveness, public condence does not appear to be waning, perhaps because of the absence, since 9/11, of terrorism involving airliners. in 2002, fox news asked a sample of registered voters whether they thought the ﬁrandom frisks and bag searches at airport security checkpoints are mostly for showﬂ or whether they were ﬁeffective ways to prevent future terrorist attacks.ﬂ the poll found that 41 percent thought the searches were for show and 45 percent thought they were effective, with 14 percent unsure (od/fox 4/02). in january and august 2006, cbs respondents were asked to evaluate the effectiveness of the government™s ﬁscreening and searches of passengers who travel on airplanes in the u.s.ﬂ while only 24 and 21 percent thought they were ﬁvery effectiveﬂ in january and august, respectively, 53 percent in january and 61 percent in august found them ﬁsomewhat effectiveﬂ (cbs 1/06 and 8/06). the fox and cbs questions are of course not directly comparable, but there is no evidence of a decline in public condence.however, travel security now extends well beyond such airport searches to encompass such issues as what information airlines may collect and share with the government. when asked in 2006 whether airport security ofcials should have access to ﬁpassengers™ personal data like their previous travel, credit card information, email addresses, telephone numbers and hotel or car reservations linked to their ˚ight,ﬂ just over half of respondents agreed that ofcials should have such access, while 43 percent said they should not (srbi/time 8/06). when the public is asked whether ﬁthe government should have the right to collect personal information about travelers,ﬂ support is somewhat lower (ir/qns 6/06). onequarter thought the government should have the right under any circumstances, and another 17 percent only with the traveler™s consent. still, a further 39 percent favored collecting such information if the traveler was suspected of some wrongdoing. a 2003 survey for the council for excellence in government proposed a ﬁsmart cardﬂ that would store personal information digitally and could facilitate checkin, but it might also lead to the abuse of information; only 27 percent felt that the benets of such a card outweighed the concerns, while 54 percent thought the concerns outweighed the benets (h&t 2/03).in addition, there is the question of what the airlines or the govprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 303ernment may do with information they have collected. a council for excellence in government survey in february 2004 (h&t 2/04) showed that 59 percent of respondents supported airline companies™ sharing of information with the government ﬁif there is any chance that it will help prevent terrorism,ﬂ but 36 percent thought the government should not have access to the information ﬁbecause that information is private and there are other things the government can do to prevent terrorism.ﬂ in the ipsosreid survey (ir/qns 6/06), 73 percent would allow the government to share traveler information with foreign governmentsšbut only 21 percent thought the government should be allowed to share information about any traveler, while 52 percent would restrict such sharing to information about travelers suspected of wrongdoing.m.5.6 biometric identication technologiesa small handful of studies have attempted to gauge public attitudes toward biometric technologies that may be used for the identication of terrorists. as indicated in table m.2, public support for the use of facial recognition technology declined somewhat after 9/11 but remained at high levels. in february 2004, the most recent observation available, 80 percent favored the use of such technology.other surveys have examined attitudes toward biometrics in the context of enhancing airport security. in a survey conducted in late september 2001 (hi/id 9/01a), respondents were read the following description of an electronic ngerprint scanning process that could facilitate checkin and security procedures:i would like to read you a description of a new airport security solution and get your opinion. this new solution uses an electronic image of a ngerprint for a ﬁrealtimeﬂ background check to ensure that passengers, airline personnel, and airport employees are not linked with criminal or terrorist activities. the ngerprint images of people with no criminal or terrorist associations are immediately destroyed to protect the individual™s privacy. the ngerprint image is used to link passengers to their boarding pass, baggage and passport control for better security.based on this description, and in the tense atmosphere immediately following 9/11, public support was substantial: 76 percent said such a new system would be ﬁextremelyﬂ or ﬁvery valuable,ﬂ and a further 16 percent thought it would be ﬁsomewhat valuable.ﬂ respondents were also overwhelmingly willing to have their own ngerprints scanned for airport security: 82 percent would be ﬁvery willing,ﬂ and an additional 13 percent ﬁwould do it reluctantly.ﬂ only 4 percent ﬁwould not do it under any circumstances.ﬂprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.304 protecting individual privacy in the struggle against terroristsseveral days later, in a subsequent survey by the same sponsor and organization, respondents were asked to choose between the ngerprint scan and an electronic facial scan:i want to explain two technologies that are being offered up as important solutions for airport security. the rst is an electronic nger scan. fingerprints are recognized as a highly accurate means of identicationševen among identical twins. this new solution uses an electronic image of a ngerprint for a ﬁrealtimeﬂ background check to ensure that passengers, airline personnel, and airport employees are not linked with criminal or terrorist activities. the ngerprint images of people with no criminal or terrorist associations are immediately destroyed to protect the individual™s privacy.the second is an electronic facial scan. with this solution, a camera captures images of all people in the airport within range of the camera to provide a ﬁrealtimeﬂ background check against known criminals or terrorists. the solution is automatic and does not require a person™s permission or knowledge that it is occurring. this solution is convenient. however, there are more likely to be errors in distinguishing between people with very similar appearance, especially identical twins. additionally, changes in facial hair or cosmetic surgery may make it difcult to provide an accurate match.after hearing these descriptions, respondents rated the value of each method. attitudes toward the ngerprint scan were again very favorable, closely matching the previous results. clearly, the question portrays the facial scan as the less palatable optionšnot only is it more susceptible to errors, but it also can be used without consent or even knowledge. not surprisingly, the facial scan ratings were substantially lower, with just 28 percent considering it ﬁextremelyﬂ or ﬁvery valuable,ﬂ and 44 percent nding it ﬁsomewhat valuableﬂ (hi/id 9/01b).more recent data on attitudes toward the use of biometric technology for security purposes are not available, but data from 2006 do indicate that this is an area about which the public is still not well informed. the ipsosreid study found that, in the united states, just 5 percent of respondents considered themselves ﬁvery knowledgeableﬂ about ﬁbiometrics for facial and other bodily recognition,ﬂ and only 24 percent said they were ﬁsomewhat knowledgeableﬂ about the technology (ir/qns 6/06).m.5.7 government use of databases and data miningreports about the telephone records database program, discussed separately above, offer a view of public reaction to a specic instance of government compilation and searching of data. but in general, does the protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 305public feel it is appropriate for the government to use such methods? the few surveys that have examined this issue suggest that there is support for database searches by the government, particularly when presented as instrumental to counterterrorism efforts. in december 2002, respondents to a poll by the los angeles times were told thatthe department of defense is developing a program which could compile information from sources such as phone calls, emails, web searches, nancial records, purchases, school records, medical records and travel histories to provide a database of information about individuals in the united states. supporters of the system say that it will provide a powerful tool for hunting terrorists. opponents say it is an invasion of individual privacy by the government. (lat 12/02)roughly equal proportions expressed support for the program (31 percent) and opposition to it (36 percent). however, respondents™ lack of knowledge about data mining was re˚ected in the large percentage saying they hadn™t heard enough to judge (28 percent). (indeed, the ipsosreid survey [ir/qns 6/06] indicates that respondents were somewhat more knowledgeable about ﬁdata mining of personal informationﬂ than about biometrics, but still not well informed. in all, 11 percent said they were ﬁvery knowledgeableﬂ about it, and 30 percent ﬁsomewhat knowledgeable,ﬂ leaving more than half ﬁnot veryﬂ or ﬁnot at all knowledgeable.ﬂ)in early 2003, another study asked respondents to make a similar choice between the competing priorities of terrorism investigation and privacy with respect to government searches of ﬁexisting databases, such as those for social securityﬂ (h&t 2/03). again, respondents were divided, with 49 percent nding it ﬁappropriateﬂ for government to carry out such searches, and 42 percent nding it ﬁnot appropriate.ﬂ (both percentages are higher than in the los angeles times survey because no ﬁdon™t know enoughﬂ option was explicitly offered.)when respondents are not forced to choose between terrorism prevention and privacy, they express substantial concern about such efforts. in may 2006, in the context of questions about the telephone call records database program, gallup asked respondents, ﬁhow concerned are you that the government is gathering other information on the general public, such as their bank records or internet usage?ﬂ (gal/usa 5/06). this question mentions only two of the possible personal information sources listed in the los angeles times description of the defense department program. nonetheless, 45 percent were ﬁvery concernedﬂ and 22 percent ﬁsomewhat concernedﬂ about such informationgathering.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.306 protecting individual privacy in the struggle against terroristsm.5.8 public health uses of medical informationprivacy of medical information. previous studies indicate high levels of concern about the privacy of health care information.15 in 1999, harris found that 54 percent of respondents were ﬁvery concernedﬂ and 29 percent ﬁsomewhat concernedﬂ about protecting the privacy of their health and medical information (harris 4/99). a gallup survey in 2000 found that over threequarters of respondents thought it was ﬁvery importantﬂ that their medical records be kept condential (corning and singer 2003). (the questions are worded differently, so no conclusions about trends can be drawn from these data).the health insurance portability and accountability act (hipaa), with provisions designed to protect the privacy of individuals™ health information, took effect in 2003. the 2005 national consumer health privacy survey was partly devoted to an evaluation of the impact of hipaa on public attitudes, but the results were not encouraging. the study found that, although 67 percent of respondents claimed to be aware of federal laws protecting the privacy and condentiality of medical records and 59 percent could recall receiving a privacy notice, only 27 percent thought they now had more rights than before. the study recorded high levels of concern about medical privacy: 67 percent of respondents overall and 73 percent of those belonging to an ethnic minority were ﬁveryﬂ or ﬁsomewhat concernedﬂ about the privacy of their ﬁpersonal medical records.ﬂ16 and 52 percent of respondents were worried that insurance claims information might be used against them by their employersšan increase of 16 percentage points over the 1999 gure (for/chcf summer/05; california health care foundation 2005).concern about medical privacy may in part re˚ect a lack of trust in the condentiality of shared information. the health condence survey, conducted in 1999 and 20012003, found that just under half of respondents had high condence that their medical records were kept condential (grn/ebri 5/99, 4/01, 4/02, 4/03; there is no evidence of systematic change over the four observations available). in the national consumer health privacy survey, onequarter of respondents were aware of incidents in which the privacy of personal information had been compromised, and those who were aware of such privacy breaches said that such 15 e. singer, r.y. shapiro, and l.r. jacobs, ﬁprivacy of health care data: what does the public know? how much do they care?,ﬂ pp. 393418 in health care and information ethics: protecting fundamental human rights (a.r. chapman, ed.), sheed and ward, kansas city, mo., 1997; a. corning and e. singer, survey of u.s. privacy attitudes, report prepared for the center for democracy and technology, washington, d.c., 2003.16 the same question was not asked in the 1999 survey, so no overtime comparison is possible for these data on medical privacy concern.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 307incidents had contributed to their concern about the privacy of their own health records (for/chcf summer/05; chcf 2005).several surveys have compared concern about privacy in different domains, nding that levels of concern with regard to medical information are high. even in 1978, harris reported that 65 percent of respondents thought that it was important for congress to pass additional privacy legislation in the area of medicine and health, as well as in the area of insuranceša larger proportion than favored such legislation for employment, mailing lists, credit cards, telephone call records, or public opinion polling (harris 11/78). more recently, nancial privacy concerns have exceeded concerns about medical records. as mentioned above, 54 percent of respondents in the 1999 harris survey were concerned about protection of health and medical privacy, compared with 64 percent who were concerned about protecting privacy of information about their nancial assets (harris 4/99). and in 1995, psra found that more than half of respondents were ﬁveryﬂ or ﬁsomewhat concernedﬂ about ﬁthreats to privacy from growing computer useﬂ in the areas of bank accounts (65 percent), credit cards (69 percent), and job and health records (59 percent; psra/nw 2/95).attitudes toward electronic medical records. indeed, corning and singer (2003) note that the public™s concerns about the privacy of health and medical information are due in part to the computerization of health and medical records and to perceptions of the vulnerability of computerized records to hacking or other unauthorized use. a 1999 survey found that 59 percent of respondents were worried ﬁthat some unauthorized person might gain access to your nancial records or personal information such as health records on the internetﬂ (icr/npr 11/99). of those, 36 percent were ﬁvery worriedﬂ about such unauthorized access. the pew research center in 2000 found that 60 percent thought it would be ﬁa bad thingﬂ if ﬁyour health care provider put your medical records on a secure internet web site that only you could access with a personal password,ﬂ because ﬁyou would worry about other people seeing your health recordsﬂ (psra/pew 7/00). the 2005 national consumer health privacy survey found that 58 percent of respondents thought medical records were ﬁveryﬂ or ﬁsomewhat secureﬂ in electronic format, compared with 66 percent in paper format (for/chcf summer/05; chcf 2005). and in the 2005 health condence survey, just 10 percent said they were ﬁextremelyﬂ or ﬁvery condentﬂ that their medical records would remain condential if they were ﬁstored electronically and shared through the internet,ﬂ 20 percent were ﬁsomewhat condent,ﬂ and 69 percent were ﬁnot tooﬂ or ﬁnot at all condentﬂ (grn/ebri 6/05).incidents in which the privacy of personal information stored elecprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.308 protecting individual privacy in the struggle against terroriststronically has been compromised have tended to increase concern about online medical recordkeeping (for/chcf summer/05; chcf 2005). a markle foundation study in 200617 found that 65 percent of respondents were interested in storing and accessing their medical records in electronic format, but 80 percent were worried about identity theft or fraud, and 77 percent were worried about the information being used for marketing purposes (lrp/av 11/06; markle foundation 2006).opposition to national medical databases. such concerns are likely to have contributed to public opposition to the establishment of national databases that would store medical information. opposition to such databases and to proposed systems of medical identication numbers ranges from moderate to nearly unanimous, depending on the question asked. for example, in 1992, 56 percent of respondents had ﬁa great dealﬂ of concern about ﬁa health insurance company putting medical information about you into a computer information bank that others have access toﬂ (ra/acluf 11/92, survey conducted via personal interview). similarly, a 1998 psra survey examined attitudes toward a system of medical identication numbers. after answering a series of questions about potential risks and benets of the proposed system, respondents answered a summary question, which showed that 52 percent would oppose such a system (psra/chcf 11/98). in 2000, gallup asked respondents, ﬁwould you support a plan that requires every american, including you, to be assigned a medical identication number, similar to a social security number, to track your medical records and place them in a national computer database without your permission?ﬂ in response to that question, 91 percent of respondents opposed the plan (gal/ihf 8/00).support for public health uses of medical records. there have been few attempts to gauge attitudes toward the sharing of medical information for public health purposes, such as the conduct of research on health care, detection of disease outbreaks, or identication of bioterrorist attacks. the limited data available suggest that public support for such uses of medical information varies substantially depending on the safeguards specied, but it is far from universal. in the national consumer health privacy survey, only 30 percent of respondents were willing to share their medical information with doctors not involved in their care, and only 20 percent with government agencies (for/chcf summer/05; chcf 2005). more17 markle foundation, survey finds americans want electronic personal health information to improve own health care, 2006. available at http://www.markle.org/downloadableassets/researchdoc120706.pdf. [accessed 3/10/07]protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 309over, just half of respondents in that survey believed they had a ﬁdutyﬂ to share medical information in order to improve health care.guarantees of anonymity may boost support: in 2003, parade magazine asked respondents whether, ﬁassuming that there is no way that anyone will have access to your identity,ﬂ they would be willing to release health information for various purposes. a total of 69 percent said they would share health information ﬁso that doctors and hospitals can try to improve their servicesﬂ; 67 percent, in order for ﬁresearchers to learn about the quality of health care, disease treatment, and prevention, and other related issuesﬂ; and 56 percent, so that ﬁpublic health ofcials can scan for bioterrorist attacksﬂ (crc/par 12/03). the markle foundation™s most recent survey questions also provided for the protection of patient identity and found somewhat greater enthusiasm for the sharing of medical data: 73 percent would be willing to release their information to detect outbreaks of disease, 72 percent for research on improving the quality of care, and 58 percent to detect bioterrorist attacks (lrp/av 11/06; markle foundation 2006).18control and consent. the desire for control over personal medical information is a recurrent theme in the research on attitudes toward online medical recordkeeping. in general, those who are willing to accept the online storage of medical records appear to be motivated by perceived personal benets (for/chcf summer/05; chcf 2005). some of these benets take the form of increased control over the content of medical records: in the markle foundation survey, 91 percent of respondents wanted to have access to electronic health records in order to ﬁsee what their doctors write down,ﬂ and 84 percent in order to check for errors (lrp/av 11/06; markle foundation 2006). other types of perceived personal benets, such as better coordination of medical treatment (for/chcf summer/05; chcf 2005) or reductions in unnecessary procedures (lrp/av 11/06; markle foundation 2006) also tend to incline respondents more positively toward electronic medical recordkeeping.in addition to seeking greater control over what is in the medical record, survey respondents also express a desire for control over decisions about the release of medical information. in data from the 1990s, singer, shapiro, and jacobs (1997)19 found broad support for individual consent 18 the actual question wording is not available, but it is possible that the greater support found in the markle foundation survey may be due in part to provisions for consent prior to release of the information.19 e. singer, r.y. shapiro, and l.r. jacobs, ﬁprivacy of health care data: what does the public know? how much do they care?,ﬂ pp. 393418 in health care and information ethics: protecting fundamental human rights (a.r. chapman, ed.), sheed and ward, kansas city, mo., 1997.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.310 protecting individual privacy in the struggle against terroristsprior to the release of medical data to those not involved in treatment. respondents also preferred to require that the patient™s permission be obtained for the use of medical records in research, even when the patient was not personally identied; 56 percent thought that general advance consent was not satisfactory and that permission should be required each time the record was accessed. corning and singer (2003) note that a strong majority of respondents to the 1998 chcf survey thought that requiring individual consent before using data would be an effective way to protect privacy (psra/chcf 11/98; chcf 1999). finally, the markle foundation™s (2006) report noted that respondents ﬁwant to have some control over the use of their informationﬂ for research or public health purposes.the implications of these ndings for public support of databases designed to monitor public health threats are threefold. first, concerns about privacy make respondents hesitant about any online health database system. second, respondents expect to exert no small degree of control over how their medical information is used and to whom it is released. third, when respondents perceive personal benets, they are more willing to consider online storage and sharing of information, but they do not appear to be motivated to share information by broader concerns about social wellbeing or by any sense of civic duty. thus, to the extent that members of the public regard disease outbreaks or bioterrorist attacks as remote possibilities that will probably not affect them directly, they are unlikely to wish to share medical information to help track such occurrences.m.6 the balance between civil liberties and terrorism investigationin recent years, survey organizations have used several broad questions asking respondents to weigh the competing priorities of terrorism investigation, on one hand, and protection of privacy or civil liberties, on the other. although such questions are articial in that they present the con˚ict between protection of individual rights and security in extreme, allornothing terms, they do re˚ect the reality that support for civil rights is not an absolute value, but is dependent on judgments about the importance of other strongly held values.20 in this section we review data from such forcedchoice questions to examine public willingness to exchange privacy for security. we also examine public perceptions of the 20 d.w. davis and b.d. silver, ﬁcivil liberties vs. security: public opinion in the context of the terrorist attacks on america,ﬂ american journal of political science 48(1):2846, 2004.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 311need to sacrice civil liberties, as well as personal willingness to make such sacrices.m.6.1 civil liberties versus terrorism preventionbetween 2002 and 2006, the following question was included in nine different surveys, mostly conducted by gallup in conjunction with cnn and usa today, but on two occasions conducted by quinnipiac university:which comes closer to your view? the government should take all steps necessary to prevent additional acts of terrorism in the u.s., even if it means your basic civil liberties would be violated. or: the government should take steps to prevent additional acts of terrorism, but not if those steps would violate your basic civil liberties.and, focusing more specically on privacy, abc news/wp asked:what do you think is more important right nowšfor the fbi [federal government] to investigate possible terrorist threats, even if that intrudes on personal privacy, or for the fbi [federal government] not to intrude on personal privacy, even if that limits its ability to investigate possible terrorist threats?ﬂ21for each question, the trends for percentages choosing the civil libertiesœoriented options are plotted in figure m.4, which shows graphically the increasing afrmation of civil liberties since 9/11. shortly after 9/11, in january 2002, 47 percent thought that ﬁthe government should take all steps necessaryﬂ for terrorism prevention (data not shown), but roughly half of respondents defended the preservation of civil liberties. by december 2005, just after the government had conrmed the existence of its warrantless monitoring program, 65 percent favored protection of civil liberties in the course of terrorism prevention. when ﬁpersonal privacyﬂ is singled out, as in the abc/wp question, the overall percentages defending privacy against investigative measures are lower, but the trend is similar.22the trend for another forcedchoice question is plotted in figure m.5. respondents were asked, ﬁwhat concerns you more right now? that 21 before january 2006, the question asked about the ﬁfbi.ﬂ as of january 2006, the wording was changed, replacing ﬁfbiﬂ with ﬁfederal government.ﬂ thus, the magnitude of the change between september 2003 and january 2006 may result in part from the change in wording. nevertheless, the overall trend corresponds to that identied in other data.22 it is possible that the phrase ﬁpersonal privacyﬂ tends to minimize the scope and nature of the violation. when the phrase ﬁprivacy rightsﬂ is used in another forcedchoice question, results correspond closely to those from a similar question about ﬁcivil libertiesﬂ (see below).protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.312 protecting individual privacy in the struggle against terroristsfig m4.epsjan. 2002june 2002sep. 2002apr. 2003aug. 2003sep. 2003nov. 2003july 2005dec. 2005jan. 2006may 2006aug. 2006sep. 200680706050301040200survey dategallup qu: ﬁthe government should take steps to prevent additional acts ofterrorism, but not if those steps would violate our basic civil liberties.ﬂabc/wp: more important ﬁfor the fbi/federal government not to intrude on personalprivacy, even if that limits its ability to investigate possible terrorist threats.ﬂpercentfigure m.4 support for preserving privacy/civil liberties in the course of terrorism prevention (surveys by gallup, quinnipiac university, abc, 20022006). sources: gallup/qu: gal/cnn/usa 1/02, 6/02, 9/02, 4/03, 8/03, 12/05; gal 11/03; qu 7/05, 8/06. abc/washington post: abc/wp 6/02, 1/06, 5/06; abc 9/02, 9/03, 9/06.the government will fail to enact strong antiterrorism laws, or that the government will enact new antiterrorism laws which excessively restrict the average person™s civil liberties?ﬂ (responses to the second option are plotted.) figure m.5 shows that since september 2001, concern for preserving civil liberties has increased, and has remained at high levels or even grown slightly since 2002. a similar question, examining concerns specically about privacy, was included in nbc/wsj polls: ﬁwhich worries you morešthat the united states will not go far enough in monitoring the activities and communications of potential terrorists living in the united states, or that the united states will go too far and violate the privacy rights of average citizens?ﬂ in december 2002, 31 percent were more worried that the united states would go too far; by july 2006, that gure had increased to 45 percent (h&t/nbc/wsj 12/02, h&i/nbc/wsj 7/06). other observations are not available, but the trend conforms to that for the question asking more broadly about civil rights.the public™s concern does not appear to be based on any personal experience of privacy intrusions resulting from government efforts at protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 313fig m5.epsapr. 1995 (lat)sep. 2001 (psra)dec. 2001 (cbs/nyt)jan. 2002 (psra)june 2002 (psra)nov. 2002 (cbs/nyt)jan. 2006 (cbs/nyt)may 2006 (cbs)aug. 2006 (cbs)80705030100604020survey datepercent concernedfigure m.5 concern that government will enact antiterrorism laws that restrict civil liberties (surveys by los angeles times, psra, and cbs news, 19952006). sources: lat 4/95, psra/pew 9/01, 1/02, 6/02; cbs/nyt 12/01, 11/02, 1/06; cbs 5/06, 8/06.terrorism prevention. when harris asked a question phrased in more personal termsšﬂhow much do you feel government antiterrorist programs have taken your own personal privacy away since september 11, 2001?ﬂšperceptions showed stability over the same period (table m.5). at each time point, a majority felt that their privacy had not been affected at all or had been affected ﬁonly a little.ﬂsensitivity to perceptions of threat. attitudes toward the proper balance between terrorism investigation and protection of civil liberties are clearly responsive to changes in threat perception. such volatility is especially visible in responses to the gallup/qu question (figure m.4), which show declines in support for civil liberties at the july 2005 and august 2006 observations, which occurred just after the london underground bombings and the reports of planned terrorist attacks on transatlantic protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.314 protecting individual privacy in the struggle against terrorists˚ights, respectively.23 responses to the abc/wp question, which asked specically about privacy, appear less sensitive, perhaps partly as a result of the timing of the observations. it may also be that the public regards such rights as due process and personal freedom as greater obstacles to terrorism investigation than privacy as such, but of course those rights have important privacy dimensions as well. concern for preserving civil liberties (figure m.5) has also been more stable, though we note that the peak in may 2006 coincided with reports on the nsa telephone records database.24 thus, it is not only attitudes toward specic surveillance measures that are responsive to perceptions of increased threat (see table m.2 23 it should also be noted that these two observations showing lower support are both from studies carried out by quinnipiac university, in contrast to all other observations, which are from gallup surveys. however, the decreases make substantive sense and correspond to trends identied elsewhere.24 change in the percentages of respondents who are worried that strong laws will not be enacted usually correspond to changes in concern about civil liberties, but this is not always the case. in the mid1990s, 44 percent expressed greater concern that the government would restrict civil liberties, while 40 percent (data not shown) were more concerned that strong laws would not be enacted. in september 2001, concern about civil liberties dropped to 34 percent, but there was no corresponding increase in concern that strong laws would not be enacted; rather, the percentage who were concerned about both possibilities increased, as did the percentage who couldn™t say. concern that strong laws would fail to be enacted has remained at 3540 percent (data not shown) since june 2002. percentages saying ﬁdon™t knowﬂ have also been stable, so that, since then, increases in concern about civil liberties have been matched by decreases in concern about enactment of laws (and vice versa).table m.5 impact on personal privacy of government antiterrorist programs (harris surveys, 20042006)february 2004september 2004june 2005february 2006percentpercentpercentpercentﬁhow much do you feel government antiterrorist programs have taken your own personal privacy away since september 11, 2001 (the date of the terrorist attacks on the world trade center and the pentagon)?ﬂa great deal88107quite a lot6977a moderate amount22212423only a little29262528none at all35353235not sure/na111šsource: hi 2/04, 9/04, 6/05, 2/06.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 315and figure m.3), but also broader prioritizations of individual rights and terrorism investigation.m.6.2 privacy costs of terrorism investigationin 1996, well before the events of 9/11 and even prior to several terrorist attacks on u.s. interests, 69 percent of respondents to an nbc news/wall street journal survey said they would support ﬁnew laws to strengthen security measures against terrorism, even if that meant reducing privacy protections such as limits on government searches and wiretappingﬂ (h&t/nbc/wsj 8/96). thus it should come as no surprise that, in recent years, majorities of respondents recognize that terrorism investigation comes at a cost to privacy. in surveys conducted in september 2003, january 2006, and september 2006, between 58 and 64 percent agreed that, ﬁin investigating terrorism . . . federal agencies like the fbi are intruding on some americans™ privacy rightsﬂ (abc 9/03, 9/06; abc/wp 1/06). yet between 49 and 63 percent of those who regarded the investigations as infringing on privacy rights thought the loss of privacy was justied (abc 9/03, 9/06; abc/wp 1/06).further evidence of the public™s belief that sacrices of civil liberties or personal freedoms will be needed in order to combat terrorism comes from two questions asked between march 1996 and august 2006. during that period, the pew research center/psra asked, ﬁin order to curb terrorism in this country, do you think it will be necessary for the average person to give up some civil liberties, or not?ﬂ25 and beginning in september 2001, cbs news asked, ﬁdo you think americans will have to give up some of their personal freedoms in order to make the country safe from terrorist attacks, or not?ﬂ the two trends are shown in figure m.6. the overall difference between proportions agreeing with the two different propositions can probably be attributed to the difference between cbs news™ higher bar of making ﬁthe country safeﬂ from threateningsounding ﬁterrorist attacksﬂ (versus the more measured ﬁcurb terrorismﬂ in the pew/psra studies).both trends show the same pattern, however: percentages believing that sacrices would be necessary were highest immediately after september 11, 2001. with increasing distance from those events, the public became less convinced of the need for sacrices. yet even when the percentages agreeing that sacrices of civil liberties would be called for were at their lowest post9/11 level, in july 2004, they had still not returned to the levels of the mid1990s.25 in july 2004 and july 2005, the question read, ﬁ. . . do you think it is necessary . . . .ﬂprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.316 protecting individual privacy in the struggle against terroristsfig m6.epsmar. 1996apr. 1997sep. 2001oct. 2001jan. 2002apr. 2002june 2002aug. 2002july 2003july 2004july 2005jan. 2006aug. 2006sep. 20068090706050301040200survey datepercent saying ﬁyesﬂcbs news: ﬁdo you think americans will have to give up some of their personalfreedoms in order to make the country safe from terrorist attacks, or not?ﬂpsra: ﬁin order to curb terrorism in this country do you think it will be necessaryfor the average person to give up some civil liberties, or not?ﬂfigure m.6 beliefs about need to give up civil liberties in order to curb terrorism (surveys by psra and cbs news, 19962006). sources: psra: psra/pew 3/96, 4/97, 1/02, 6/02, 7/03, 7/04, 7/05, 9/06; psra/nw 9/01, 8/02. cbs: cbs/nyt 9/01a, 8/06; cbs 10/01, 4/02, 1/06.m.6.3 personal willingness to sacrice freedomspublic beliefs about the need for sacrice at the national level appear to translate into personal willingness to make sacrices as well. when respondents are asked whether they themselves would ﬁgive up some of [their] personal freedom in order to reduce the threat of terrorism,ﬂ substantial proportions say they are willing to do so. figure m.7 shows that the trend on this question, too, conforms to the pattern discerned earlier. again, there is an early observation, in may 2001, that serves as a pre9/11 baseline: at that point, 33 percent said they would be willing to sacrice some freedom, a gure that leaped to 71 percent after 9/11. the curve shows a decline over the next 12 months to 61 percent, where it remains until dropping again in january and may 2006. at the time of those surveys, respondents may have felt less inclined to consider further sacrices, perhaps having become awarešafter hearing reports about the government™s warrantless monitoring and telephone call records database programsšthat they were already giving up more freedoms than they had realized. still, the low point in may 2006 of 54 percent does not approach the pre9/11 gure of 33 percent, suggesting that 9/11 may have protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 317fig m7.eps807060503010may2001oct.2001june2002sep.2002july2005jan.2006may200640200survey datepercent saying ﬁyesﬂfigure m.7 ﬁwould you be willing to give up some of your personal freedom in order to reduce the threat of terrorism?ﬂ (national samples of registered voters; opinion dynamics surveys, 20012006). sources: od/fox 5/01, 10/01, 6/02, 9/02, 7/05, 1/06, 5/06.brought about real change in the extent to which americans are willing to assert their right to customary freedoms.m.6.4 concerns about uses of expanded powershave the public™s concerns about how expanded powers would be used changed over the period since 2001? table m.6 shows the percentages expressing ﬁhighﬂ or ﬁmoderate concernﬂ about possible problems in the implementation of surveillance measures, both at the level of oversight and at the level of application of those measures. in february 2006, roughly threequarters of respondents were concerned about the potential for abuses of civil liberties by the courts and congress, with slightly fewer concerned about inappropriate use of powers by law enforcement. concerns about abuses by law enforcement changed little over the veyear period, while concerns about lapses by the courts and congress declined slightly. in fact, ﬁhighﬂ concern about abuses by the courts decreased substantially over the period, from 44 to 34 percent (data not shown).in contrast to these trends, a new question added in 2004 about the adequacy of white house oversight shows an increase in concern, protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.318 protecting individual privacy in the struggle against terroriststable m.6 concern about uses of expanded powers (harris surveys, 20012006)september 2001february 2004september 2004june 2005february 2006percentpercentpercentpercentpercentﬁnow, here are some concerns that people might have about the way these increased powers might be used by law enforcement. would you say you have high concern, moderate concern, not much concern, or no concerns at all about each of the following possibilities?ﬂ (percent ﬁhighﬂ or ﬁmoderateﬂ concern).judges who authorize investigations would not look closely enough at the justifications for that surveillance7978777576congress would not include adequate safeguards for civil liberties when authorizing these increased powers7875747575law enforcement would investigate legitimate political and social groups6867686868the white house would not issue the proper rules for legal due process for government surveillance programsšš697275the mail, telephone, emails, or cellphone calls of innocent people would be checked7276šššnonviolent critics of government policies would have their mail, telephone, emails, or cellphone calls checked7176šššnew surveillance powers would be used to investigate crimes other than terrorism6771there would be broad profiling of people and searching them based on their nationality, race, or religion7773šššsource: hi 9/01, 2/04, 9/04, 6/05, 2/06.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 319from 69 to 75 percent over the three observations available. most of this increase was the result of expanding ﬁhighﬂ concern, from 35 to 41 percent (data not shown). with respect to the groups responsible for regulating increased powers, then, public condence in congress, the courts, and law enforcement has remained stable or increased slightly since 2001, but citizens are growing less sanguine about how those powers are used by the executive branch of government.respondents were also asked how concerned they were about some specic inappropriate uses of the increased powers (table m.6). between september 2001 and february 2004, concerns that the communications of innocent people would be monitored, that nonviolent groups would be investigated, and that new surveillance powers would be used for purposes other than terrorism investigation each showed small increases, while concerns about racial and religious proling decreased slightly; more recent data for these questions are not available.the trends discussed above point to growing support for defending privacy and other civil liberties, even at some cost to terrorism investigation; to sustained high levels of concern, after the immediate post9/11 period, that antiterrorism laws will restrict civil liberties; to declining public conviction that sacrice of civil liberties is truly necessary for terrorism prevention; to decreasing personal willingness to sacrice freedom for the sake of terrorism investigation; and to stability or slight increases in concern about abuses of expanded powers. the in˚uence of specic events, such as terrorist incidents, news about terrorist activity, and reports of surveillance programs, can be discerned as high and low points in the overall trends. but the longterm trends themselves can probably best be attributed to distance in time from the most recent instance of terrorism within the united states and to dissatisfaction with the balance the government has achieved between protecting civil liberties and combating terrorism.m.7 conclusionsin the introduction to this appendix, we noted the main conclusions to emerge from this review of trends in attitudes toward government surveillance and the associated loss of privacy. here, we discuss some of the relevant ndings from more indepth research on support for civil liberties in the post9/11 period.this literature offers insights into demographic and other attitudinal correlates of opinions about civil liberties versus security, which we have not been able to explore in this review because bivariate tabulations of data by demographic group are not readily available and a reanalysis of data sets is beyond the scope of this research. a recent study shows protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.320 protecting individual privacy in the struggle against terroriststhat demographic in˚uences on attitudes toward the civil liberties versus security balance are important, however. davis and silver (2004) carried out a national survey shortly after the attacks of 9/11, in which they studied people™s willingness to exchange civil liberties for security.26 in a multivariate analysis that controls for the effects of other variables, the authors found that african americans showed a stronger preference for preserving civil liberties, even at the expense of security, compared with whites (osr/msu 11/01). similarly, afrmation of civil liberties is stronger among young people (ages 1824) and urban residents. political ideology is also signicant, with liberals more likely than conservatives to favor protection of civil rights over terrorism investigation; dogmatic people, who are characterized by intolerance, in˚exibility, and insecurity, are more likely to favor security over the defense of civil liberties. these ndings support and expand on the demographic relationships noted by westin.27the literature also provides corroboration of the trends described abovešin particular, the nding that abstract support for civil rights tends to dissolve in specic situations.28 this phenomenon manifests itself in two ways in the data discussed in this review. first, however strongly respondents avow their support for civil liberties, they are willing to make concessions when called on to choose between preserving rights and supporting specic security measures that may violate those rights. such willingness is most clearly visible in the contrast between the high levels of support for restricting terrorism prevention steps to those that preserve civil liberties, shown in figure m.4, and the even higher levels of support for individual surveillance measures, shown in table m.2. the widespread belief that sacrices of civil liberties will be required in order to combat terrorism, as well as respondents™ willingness to countenance such sacrices (see figures m.6 and m.7) also reveal public willingness to compromise on privacy and other rights.second, the phenomenon can be observed in the vulnerability of support for privacy and other personal freedoms to the external in˚uence of 26 the survey was conducted between november 14, 2001, and january 15, 2002, by means of telephone interviews with an adult national rdd sample. the response rate (calculated as rr4 in the ﬁstandard denitionsﬂ of the american association for public opinion research [aapor]) was 52.3 percent, and the refusal rate was 19.0 percent. the survey was carried out by the ofce for survey research of the institute for public policy and social research at michigan state university. see d.w. davis and b.d. silver, op. cit.27 a.f. westin, ﬁhow the public sees the securityversusliberty debate,ﬂ pp. 1936 in protecting what matters: technology, security, and liberty since 9/11 (c. northhouse, ed.), brookings institution press, washington, d.c., 2005.28 see, for example, l. huddy, n. khatib, and t. capelos, ﬁtrends: reactions to the terrorist attacks of september 11, 2001,ﬂ public opinion quarterly 66(3):418450, 2002; and davis and silver, 2004, op. cit.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 321terrorist threat. nearly all of the trends that contain sufcient data points display a response, in the form of reduced support for civil liberties and/or greater support for surveillance measures, to two periods of increased threat perception: july 2005, when the london underground bombings took place, and august 2006, when it was reported that a major terrorist attack on transatlantic airliners had been averted.29 this inverse relationship between perceptions of threat and support for civil rights was examined more systematically in the research by davis and silver (2004). the authors conclude that ﬁwhen they feel threatened, people who previously protected civil liberties and personal freedom may compromise on these values for greater security.ﬂ30the in˚uence of a sense of threat extends beyond a straightforward negative association with support for civil liberties, however, to important interaction effects. davis and silver31 found that the perception of threat conditions the relationship between other variables, such as trust in government and liberalconservative ideology and civil liberties support. trust in government is negatively associated with afrmation of civil rights: those with greater trust in government are more willing to sacrice freedoms, compared with those with less trust. and, other things being equal, liberals are more likely to defend civil liberties than conservatives. however, the effect of both variables on attitudes toward civil liberties is moderated by the sense of threat. for example, there is a substantial reduction in support for civil liberties among those who have strong trust in government and who perceive high threat. and liberals with a strong sense of threat may be less supportive of civil liberties than conservatives who perceive no threat.this examination of trend data, of course, does not allow us to denitively identify associations between variables, much less interactions. however, we have noted above that reductions in support for civil liberties appear to correspond to periods when threat perception is high. following davis and silver,32 we would expect declines in trust in government to be re˚ected in increased concern for preservation of civil liberties, 29 whether numerous other instances of terrorismšthe madrid train bombings of 2004, the attacks on a residential compound for foreigners in saudi arabia in 2003, and the bali bombing of 2002, among othersšmay likewise have increased threat perception among the american public, we cannot say, because pollsters did not conduct surveys (or did not ask questions about surveillance and/or civil liberties versus security) in the immediate aftermath of those incidents. this is a reminder that knowledge of public attitudes and the ability to discern trends based on public opinion data are strongly dependent on judgments by the media and pollsters about what events offer worthwhile material for the study of public reaction.30 davis and silver, 2004, op. cit, p. 38.31 davis and silver, 2004, op. cit.32 ibid.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.322 protecting individual privacy in the struggle against terroristsparticularly if part of the reason for the reduction in trust is a perception of indifference to individual rights on the part of the government. yet concern for civil liberties can be easily, and dramatically, suppressed by heightened threat.m.8 annexm.8.1 details of cited surveyseach survey cited in this appendix is identied in the text by an abbreviation referring to the research organization and, in most cases, the sponsor and the date; these abbreviations and dates are included at the beginning of each entry.surveys are grouped alphabetically by abbreviation identifying the research organization/sponsor; within the groups for each research organization/sponsor, surveys are listed in chronological order.methodological details include sample design, sample size, survey method, and eldwork dates. not all information is available for all surveys, however, and response rates are not available. all surveys were conducted in the united states, and all were conducted either by telephone (random digit dialed) or via personal interview. internet surveys are not included in this review.unless otherwise indicated in the entries, the data cited can be found at the ipoll databank at the roper center for public opinion research, university of connecticut: http://www.ropercenter.uconn.edu/ipoll.html. the survey title given here is the title listed in the ipoll archive. when data were obtained from sources other than the ipoll databank, the survey entry identies the report or web site from which the data were obtained.m.8.2 research organization/sponsor name abbreviationsabc abc newsabc/wp abc news/washington postcbs cbs newscbs/nyt cbs news/new york timescrc/par charleton research company for parade magazinefor/chcf forrester research for the california healthcare foundationgal gallup organizationgal/cnn/usa gallup organization for cnn/usa todayprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 323gal/usa gallup organization for usa todaygrn/ebri matthew greenwald and associates for employee benet research institute, consumer heath education councilharris louis harris and associateshi harris interactivehi/id harris interactive for identixh&m/nbc/wsj hart and mcinturff research companies for nbc news/wall street journalh&t hart and teeter research companiesh&t/nbc/wsj hart and teeter research companies for nbc news/wall street journalicr/npr international communications research for national public radio, the henry j. kaiser family foundation, and harvard university™s kennedy school of governmentlat los angeles timeslrp/av lake research partners and american viewpoint for the markle foundationmar marist college institute for public opinionod/fox opinion dynamics for fox newsosr/msu ofce for survey research of the institute for public policy and social research at michigan state universitypaf/rma public agenda foundation and robinson and muenster associates for the national constitution centerpsra princeton survey research associatespsra/chcf princeton survey research associates for the california health care foundationpsra/nw princeton survey research associates for newsweekpsra/pew princeton survey research associates for the pew research centerqns/ir ipsosreid for queens university, canadaqu quinnipiac university polling institutera/acluf response analysis for the american civil liberties union foundationsrbi/time schulman, ronca and bucuvalas for timetns/gmf tns opinion and social institutes for the german marshall fund of the u.s. and the compagnia di san paolo, italywin winston group for new modelsprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.324 protecting individual privacy in the struggle against terroristsm.8.3 list of surveysabc 6/94. abc news poll. telephone survey conducted by abc news, with a national adult sample of 813. fieldwork carried out june 78, 1994.abc 1/00. abc news poll. telephone survey conducted by abc news, with a national adult sample of 1,006. fieldwork carried out january 2126, 2000.abc 9/02. abc news poll. telephone survey conducted by tns intersearch for abc news, with a national adult sample of 1,011. fieldwork carried out september 58, 2002.abc 9/03. abc news poll. telephone survey conducted by tns intersearch for abc news, with a national adult sample of 1,004. fieldwork carried out september 47, 2003.abc 9/06. abc news poll. telephone survey conducted by tns intersearch for abc news, with a national adult sample of 1,003. fieldwork carried out september 57, 2006.abc/wp 6/02. abc news/washington post poll. telephone survey conducted by tns intersearch for abc news/washington post, with a national adult sample of 1,004. fieldwork carried out june 79, 2002.abc/wp 3/05. abc news/washington post poll. telephone survey conducted by tns intersearch for abc news/washington post, with a national adult sample of 1,001. fieldwork carried out march 1013, 2005.abc/wp 1/06. abc news/washington post poll. telephone survey conducted by tns intersearch for abc news/washington post with a national adult sample of 1,001. fieldwork carried out january 58, 2006.abc/wp 5/06. abc news/washington post poll. telephone survey conducted by tns intersearch for abc news/washington post with a national adult sample of 502. fieldwork carried out may 11, 2006.cbs 3/98. cbs news poll. telephone survey conducted by cbs news with a national adult sample of 994. fieldwork carried out march 30april 1, 1998.cbs 10/01. cbs news poll. telephone survey conducted by cbs news with a national adult sample of 436. fieldwork carried out on october 8, 2001.cbs 1/02a. cbs news poll. telephone survey conducted by cbs news, with a national adult sample of 1,000. fieldwork carried out january 56, 2002.cbs 1/02b. cbs news poll. telephone survey conducted by cbs news, with a national adult sample of 1,030. fieldwork carried out january 1517, 2002.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 325cbs 2/02. cbs news poll. telephone survey conducted by tns research for cbs news, with a national adult sample of 861. fieldwork carried out february 2426, 2002.cbs 4/02. cbs news poll. telephone survey conducted by cbs news, with a national adult sample of 1,119. fieldwork carried out april 1518, 2002.cbs 5/03. cbs news poll. telephone survey conducted by cbs news, with a national adult sample of 758. fieldwork carried out may 2728, 2003.cbs 4/05. cbs news poll. telephone survey conducted by cbs news, with a national adult sample of 1,149. fieldwork carried out april 1316, 2005.cbs 7/05. cbs news poll. telephone survey conducted by cbs news, with a national adult sample of 632. fieldwork carried out july 1314, 2005.cbs 1/06. cbs news poll. telephone survey conducted by cbs news, with a national adult sample of 1,151. fieldwork carried out january 58, 2006.cbs 5/06. cbs news poll. telephone survey conducted by cbs news, with a national adult sample of 636. fieldwork carried out may 1617, 2006.cbs 8/06. cbs news poll. telephone survey conducted by cbs news, with a national adult sample of 974. fieldwork carried out august 1113, 2006.cbs/nyt 9/01a. cbs news/new york times poll. telephone survey conducted by cbs news/new york times, with a national adult sample of 959. fieldwork carried out september 1314, 2001.cbs/nyt 9/01b. cbs news/new york times poll. telephone survey conducted by cbs news/new york times, with a national adult sample of 1,216. fieldwork carried out september 2023, 2001.cbs/nyt 12/01. cbs news/new york times poll. telephone survey conducted by cbs news/new york times, with a national adult sample of 1,052. fieldwork carried out december 710, 2001.cbs/nyt 11/02. cbs news/new york times poll. telephone survey conducted by cbs news/new york times, with a national adult sample of 996. fieldwork carried out november 2024, 2002.cbs/nyt 9/05. cbs news/new york times poll. telephone survey conducted by cbs news/new york times, with a national adult sample of 1,167. (an oversample of african americans was employed, but results are weighted to be representative of the national adult population.) fieldwork carried out september 913, 2005.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.326 protecting individual privacy in the struggle against terroristscbs/nyt 1/06. cbs news/new york times poll. telephone survey conducted by cbs news/new york times, with a national adult sample of 1,229. fieldwork carried out january 2025, 2006.cbs/nyt 8/06. cbs news/new york times poll. telephone survey conducted by cbs news/new york times, with a national adult sample of 1,206. fieldwork carried out august 1721, 2006.crc/par 12/03. parade/researchamerica health poll. telephone survey conducted by charleton research company for parade magazine, with a national adult sample of 800. fieldwork carried out during december 2003.for/chcf summer/05. national consumer health privacy survey 2005. telephone survey conducted by forrester research for the california healthcare foundation, with a sample of 1.000 adults. the total sample size of 2,100 includes an oversample (n = 1,000) of california residents and an oversample of respondents with hiv or substance abuse (n = 100). results cited here are for the national sample only. specic eldwork dates are not provided; materials indicate that the survey was conducted in ﬁsummer 2005.ﬂ data reported in ﬁexecutive summary,ﬂ retrieved march 29, 2006, from http://www.chcf.org/topics/view.cfm?itemid=115694.gal 11/03. gallup poll. telephone survey conducted by gallup organization, with a national adult sample of 1,004. fieldwork carried out november 1012, 2003.gal/cnn/usa 1/02. gallup/cnn/usa today poll. telephone survey conducted by gallup organization for cnn and usa today, with a national adult sample of 1,011. fieldwork carried out january 2527, 2002.gal/cnn/usa 6/02. gallup/cnn/usa today poll. telephone survey conducted by gallup organization for cnn and usa today, with a national adult sample of 1,020. split sample employed so that only half of the sample responded to some questions reported here. fieldwork carried out june 2123, 2002.gal/cnn/usa 9/02. gallup/cnn/usa today poll. telephone survey conducted by gallup organization for cnn and usa today, with a national adult sample of 1,003. split sample employed so that some questions reported here were asked of only half the sample. fieldwork carried out september 24, 2002.gal/cnn/usa 4/03. gallup/cnn/usa today poll. telephone survey conducted by gallup organization for cnn and usa today, with a national adult sample of 1,001. fieldwork carried out april 2223, 2003.gal/cnn/usa 8/03. gallup/cnn/usa today poll. telephone survey conducted by gallup organization for cnn and usa today, with a protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 327national adult sample of 1,009. split sample employed so that some questions reported here were asked of only half the sample. fieldwork carried out august 2526, 2003.gal/cnn/usa 12/05. gallup/cnn/usa today poll. telephone survey conducted by gallup organization for cnn and usa today, with a national adult sample of 1,003. fieldwork carried out december 1618, 2005.gal/ihf 8/00. public attitudes toward medical privacy. telephone survey conducted by gallup organization for the institute for health freedom, with a national adult sample of 1,000. fieldwork carried out august 1126, 2000. data reported in corning and singer, 2003.gal/usa 5/06. gallup/usa today poll. telephone survey conducted by gallup organization for usa today, with a national adult sample of 809. fieldwork carried out may 1213, 2006.grn/ebri 5/99. health condence survey 1999. telephone survey conducted by matthew greenwald and associates for employee benet research institute, consumer education council, with a national adult sample of 1,001. fieldwork carried out may 13june 14, 1999.grn/ebri 4/01. health condence survey 2001. telephone survey conducted by matthew greenwald and associates for employee benet research institute, consumer education council, with a national adult sample of 1,001. fieldwork carried out april 17may 27, 2001.grn/ebri 4/02. health condence survey 2002. telephone survey conducted by matthew greenwald and associates for employee benet research institute, consumer education council, with a national adult sample of 1,000. fieldwork carried out april 18may 19, 2002.grn/ebri 4/03. health condence survey 2003. telephone survey conducted by matthew greenwald and associates for employee benet research institute, consumer education council, with a national adult sample of 1,002. fieldwork carried out april 24may 24, 2003.grn/ebri 6/05. health condence survey 2005. telephone survey conducted by matthew greenwald and associates for employee benet research institute, consumer education council, with a national adult sample of 1,003. fieldwork carried out june 30august 6, 2005.harris 11/78. dimensions of privacy. survey conducted by louis harris and associates for sentry insurance, with a national adult sample of 1,513. the survey was conducted by personal interview november 30december 10, 1978.harris 4/99. consumers and the 21st century survey. telephone survey conducted by louis harris and associates for the national consumers league, with a national adult sample of 1,006. fieldwork carried out april 22may 3, 1999.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.328 protecting individual privacy in the struggle against terroristshi 9/01. harris poll. telephone survey conducted by harris interactive with a national adult sample of 1,012. fieldwork carried out september 1924, 2001.hi 3/02. harris poll. telephone survey conducted by harris interactive with a national adult sample of 1,017. fieldwork carried out march 1319, 2002.hi 2/03. harris poll. telephone survey conducted by harris interactive with a national adult sample of 1,010. fieldwork carried out february 1216, 2003.hi 2/04. harris poll. telephone survey conducted by harris interactive with a national adult sample of 1,020. fieldwork carried out february 916, 2004.hi 9/04. harris poll. telephone survey conducted by harris interactive with a national adult sample of 1,018. fieldwork carried out september 913, 2004.hi 6/05. harris poll. telephone survey conducted by harris interactive with a national adult sample of 1,015. fieldwork carried out june 712, 2005.hi 2/06. harris poll. telephone survey conducted by harris interactive with a national adult sample of 1,016. fieldwork carried out february 714, 2006.hi 7/06. harris poll. telephone survey conducted by harris interactive with a national adult sample of 1,000. fieldwork carried out july 2124, 2006.hi/id 9/01a. airport security survey. telephone survey conducted by harris interactive for identix, with a national adult sample of 1,015. fieldwork carried out september 2124, 2001.hi/id 9/01b. airport security survey. telephone survey conducted by harris interactive for identix, with a national adult sample of 1,009. fieldwork carried out september 2629, 2001.h&m/nbc/wsj 7/06. nbc news/wall street journal poll. telephone survey conducted by hart and mcinturff research companies with a national adult sample of 1,010. fieldwork carried out july 2124, 2006.h&t 2/03. egovernment survey. telephone survey conducted by hart and teeter research companies for the council for excellence in government, with a national adult sample of 1,023. fieldwork carried out february 1925, 2003.h&t 2/04. america speaks out about homeland security survey. telephone survey conducted by hart and teeter research companies for the council for excellence in government, with a national adult sample of 1,633. fieldwork carried out february 58, 2004.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 329h&t/nbc/wsj 8/96. nbc news/wall street journal poll. telephone survey conducted by hart and teeter research companies with a national adult sample of 1,203. fieldwork carried out august 26, 1996.h&t/nbc/wsj 12/02. nbc news/wall street journal poll. telephone survey conducted by hart and teeter research companies with a national adult sample of 1,005. fieldwork carried out december 79, 2002.icr/npr 11/99. npr/kaiser/harvard technology survey. telephone survey conducted by international communications research for national public radio, the henry j. kaiser family foundation, and harvard university™s kennedy school of government, with a national adult sample of 1,506. the sample included an oversample of black respondents, but results are weighted to represent the national adult population. fieldwork carried out november 15december 19, 1999.ir/qns 6/06. global privacy of data international survey. telephone survey conducted by ipsosreid for queens university, canada/the surveillance project, with a u.s. national adult sample of 1,000. fieldwork carried out june 27july 28, 2006. report retrieved march 29, 2006, from http://www.queensu.ca/sociology/surveillance/les/ipsosreportnov2006.pdf.lat 4/95. los angeles times poll. telephone survey conducted by the los angeles times with a national adult sample of 1,032. fieldwork carried out april 2627, 1995.lat 12/02. los angeles times poll. telephone survey conducted by the los angeles times with a national adult sample of 1,305. fieldwork carried out december 1215, 2002.lat 7/06. los angeles times/bloomberg poll. telephone survey conducted by the los angeles times/bloomberg with a national adult sample of 1,478. fieldwork carried out july 28august 1, 2006.lrp/av 11/06. connecting americans to their health care. telephone survey conducted by lake research partners and american viewpoint for the markle foundation, with a national adult sample of 1,003. fieldwork carried out november 1115, 2006. data reported in markle 2006, retrieved march 10, 2007, from http://www.markle.org/downloadableassets/researchdoc120706.pdf.mar 2/96. marist college institute for public opinion poll. telephone survey conducted by marist college institute for public opinion, with a national adult sample of approximately 900. fieldwork carried out during february 1996.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.330 protecting individual privacy in the struggle against terroristsod/fox 5/01. fox news/opinion dynamics poll. telephone survey conducted by opinion dynamics for fox news, with a national registered voters sample of 900. fieldwork carried out may 910, 2001.od/fox 10/01. fox news/opinion dynamics poll. telephone survey conducted by opinion dynamics for fox news, with a national registered voters sample of 900. fieldwork carried out october 1718, 2001.od/fox 4/02. fox news/opinion dynamics poll. telephone survey conducted by opinion dynamics for fox news, with a national registered voters sample of 900. fieldwork carried out april 1617, 2002.od/fox 6/02. fox news/opinion dynamics poll. telephone survey conducted by opinion dynamics for fox news, with a national registered voters sample of 900. fieldwork carried out june 45, 2002.od/fox 9/02. fox news/opinion dynamics poll. telephone survey conducted by opinion dynamics for fox news, with a national registered voters sample of 900. fieldwork carried out september 89, 2002.od/fox 7/05. fox news/opinion dynamics poll. telephone survey conducted by opinion dynamics for fox news, with a national registered voters sample of 900. fieldwork carried out july 2627, 2005.od/fox 1/06. fox news/opinion dynamics poll. telephone survey conducted by opinion dynamics for fox news, with a national registered voters sample of 900. fieldwork carried out january 1011, 2006.od/fox 5/06. fox news/opinion dynamics poll. telephone survey conducted by opinion dynamics for fox news, with a national registered voters sample of 900. fieldwork carried out may 1618, 2006.osr/msu 11/01. civil liberties survey. telephone survey conducted by the ofce for survey research of the institute for public policy and social research at michigan state university, with a national adult sample of 1,448. an oversample of african american and hispanic respondents was included, but results reported here are weighted to be representative of the national adult population. the response rate (calculated as rr4 in the ﬁstandard denitionsﬂ of the american association for public opinion research) was 52.3 percent, and the refusal rate was 19.0 percent. fieldwork was carried out between november 14, 2001 and january 15, 2002. study results reported in darren w. davis and brian d. silver, ﬁcivil liberties vs. security: public opinion in the context of the terrorist attacks on america,ﬂ american journal of political science, 48(1):2846, 2004.paf/rma 7/02. knowing it by heart: the constitution and its meaning survey. telephone survey conducted by public agenda foundation/robinson and muenster associates, inc. for the national conprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 331stitution center, with a national adult sample of 1,520. fieldwork carried out july 1024, 2002.psra/chcf 11/98. medical privacy and condentiality survey. telephone survey conducted by princeton survey research associates for the california health care foundation, using a national adult sample of 1,000. a separate sample of california residents was also included, but results reported here are for the national sample only. fieldwork carried out november 12december 22, 1998. data reported in ﬁtopline report,ﬂ retrieved april 7, 2007, from http://www.chcf.org/topics/view.cfm?itemid=12500psra/nw 2/95. princeton survey research associates/newsweek poll. telephone survey conducted by psra for newsweek, with a national adult sample of 752. fieldwork carried out february 1617, 1995.psra/nw 9/01. princeton survey research associates/newsweek poll. telephone survey conducted by princeton survey research associates for newsweek, with a national adult sample of 1,005. fieldwork carried out september 2021, 2001.psra/nw 8/02. princeton survey research associates/newsweek poll. telephone survey conducted by princeton survey research associates for newsweek, with a national adult sample of 1,005. fieldwork was carried out august 2829, 2002.psra/nw 5/06. princeton survey research associates international/newsweek poll. telephone survey conducted by princeton survey research associates for newsweek with a national adult sample of 1,007. fieldwork carried out may 1112, 2006.psra/pew 3/96. pew news interest index poll. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 1,500. a split sample was used for some of the questions reported here, so that they were asked only of half the sample. fieldwork carried out march 2831, 1996.psra/pew 4/97. pew news interest index poll. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 1,206. fieldwork carried out april 36, 1997.psra/pew 10/98. people and the press 1998 technology survey. telephone survey conducted by princeton survey research associates for the pew research center, using a national adult sample of 3,184. (an oversample of 1,184 internet users was included, but results are weighted to be representative of the national adult population.) fieldwork carried out october 26december 1, 1998.psra/pew 7/00. tracking online life survey. telephone survey conducted by princeton survey research associates for the pew research protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.332 protecting individual privacy in the struggle against terroristscenter, with a national adult sample of 2,109. fieldwork carried out july 24august 20, 2000.psra/pew 9/01. people and the press postterrorist attack poll. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 1,200. fieldwork was carried out september 1317, 2001, but data cited here are from questions asked september 1417 only.psra/pew 1/02. pew news interest index poll. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 1,201. fieldwork carried out january 913, 2002.psra/pew 6/02. pew news interest index poll. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 1,212. fieldwork carried out june 1923, 2002.psra/pew 8/02. people and the press 2002 yearafter9/11 poll. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 1,001. fieldwork was carried out august 1425, 2002.psra/pew 6/03. 2003 methodology study poll 1. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 1,000. the study included in this review was a standard survey; another study (the 2003 methodology study poll 2) incorporated procedures designed to maximize response rates, but those results are not reported here. fieldwork was carried out june 48, 2003.psra/pew 7/03. 2003 values update survey. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 2,528. the sample included an oversample of blacks, but results are weighted to be representative of the national adult population. fieldwork was carried out july 14august 5, 2003.psra/pew 7/04. foreign policy and party images poll. telephone survey conducted by princeton survey research associates for the pew research center and the chicago council on foreign relations, with a national adult sample of 2,009. fieldwork was carried out july 818, 2004.psra/pew 7/05. pew news interest index poll. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 1,502. fieldwork was carried out july 1317, 2005.psra/pew 1/06. pew news interest index poll. telephone survey conducted by princeton survey research associates for the pew research protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix m 333center, with a national adult sample of 1,503. fieldwork carried out january 48, 2006.psra/pew 9/06. pew news interest index poll. telephone survey conducted by princeton survey research associates for the pew research center, with a national adult sample of 1,507. fieldwork carried out september 610, 2006.psra/pew 12/06. pew news interest index poll. telephone survey conducted by princeton survey research associates for the pew research center, with a national adults sample of 1,502. fieldwork carried out december 610, 2006.psra/tm 1/94. technology in the american household. telephone survey conducted by princeton survey research associates for times mirror, with a national adult sample of 3,667, including an oversample of 207 modem users. fieldwork carried out january 4february 17, 1994.psra/tm 5/95. technology and online use survey. telephone survey conducted by princeton survey research associates for times mirror, using a national adult sample of 3,603. (an oversample of 402 online users was employed, but results are weighted to be representative of the national adult population). fieldwork carried out may 25june 22, 1995.qu 7/05. quinnipiac university poll. telephone survey conducted by quinnipiac university polling institute, with a national registered voters sample of 920. fieldwork conducted july 2125, 2005.qu 8/06. quinnipiac university poll. telephone survey conducted by quinnipiac university polling institute, with a national registered voters sample of 1,080. fieldwork conducted august 1723, 2006.ra/acluf 11/92. american public opinion about privacy at home and at work. personal interview survey conducted by response analysis for the american civil liberties union foundation, using a national adult sample of 993. fieldwork carried out november 13december 13, 1992.srbi/time 8/06. time/srbi poll. telephone survey conducted by schulman, ronca and bucuvalas for time, with a national adult sample of 1,002. fieldwork carried out august 2224, 2006.tns/gmf 6/06. transatlantic trends 2006 survey. telephone survey conducted by tns opinion and social institutes for the german marshall fund of the u.s. and the compagnia di san paolo, italy, with a u.s. national adult sample of 1,000. surveys were conducted in thirteen nations; data are reported for the u.s. sample only. fieldwork carried out june 624, 2006.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.334 protecting individual privacy in the struggle against terroristswin 5/06. new models national brand poll. telephone survey conducted by winston group for new models with a national sample of 1,000 registered voters. fieldwork carried out may 1617, 2006.m.8.4 referencescalifornia health care foundation (chcf). 2005. ﬁnational consumer health privacy survey 2005: executive summary.ﬂ retrieved march 10, 2007, from http://www.chcf.org/documents/ihealth/consumer privacy2005execsum.pdfcalifornia health care foundation (chcf). 1999. ﬁmedical privacy and condentiality survey: topline report.ﬂ retrieved april 7, 2007, from http://www.chcf.org/topics/view.cfm?itemid=12500ipsosreid, 2006. ﬁglobal privacy of data international survey summary report.ﬂ november 2006. queens university. retrieved march 8, 2007, from http://www.queensu.ca/sociology/surveillance/les/ipsos reportnov2006.pdf.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.335ncommittee and staff biographical informationcommittee memberswilliam j. perry, cochair, is the michael and barbara berberian professor at stanford university, with a joint appointment at the stanford institute for international studies (siis) and the school of engineering. he is also a senior fellow at siis and the hoover institution and serves as codirector of the preventive defense project, a research collaboration of stanford and harvard universities. he was the codirector of the center for international security and arms control from 1988 to 1993, during which time he was also a halftime professor at stanford. dr. perry was the 19th secretary of defense for the united states, serving from february 1994 to january 1997. he previously served as deputy secretary of defense (19931994) and as under secretary of defense for research and engineering (19771981). dr. perry is on the board of directors of several emerging hightech companies and is chair of global technology partners. his previous business experience includes serving as a laboratory director for general telephone and electronics (19541964); founder and president of esl inc. (19641977); executive vicepresident of hambrecht & quist, inc. (19811985); and founder and chairman of technology strategies and alliances (19851993). he is an expert in u.s. foreign policy, national security, and arms control. he is a member of the national academy of engineering (nae) and a fellow of the american academy of arts and sciences (aaas). he received a b.s. and m.s. from stanford university and a ph.d. from pennsylvania state university, all in mathematics.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.336 protecting individual privacy in the struggle against terroristscharles m. vest, cochair, is president of the national academy of engineering and president emeritus of the massachusetts institute of technology (mit). he became president of mit in 1990 and served in that position until december 2004. dr. vest was a director of dupont for 14 years and of ibm for 13 years, was vice chair of the u.s. council on competitiveness for eight years, and served on various federal committees and commissions, including the president™s committee of advisors on science and technology during the clinton and bush administrations, the commission on the intelligence capabilities of the united states regarding weapons of mass destruction, the secretary of education™s commission on the future of higher education, the secretary of state™s advisory committee on transformational diplomacy, and the ricechertoff secure borders and open doors advisory committee. he serves on the boards of several nonprot organizations and foundations devoted to education, science, and technology. in july 2007 he was elected to serve as president of nae for six years. he has authored a book on holographic interferometry and two books on higher education. he has received honorary doctoral degrees from ten universities and was awarded the 2006 national medal of technology by president george w. bush.w. earl boebert is an expert on information security, with experience in national security and intelligence as well as commercial applications. currently retired, he was a senior scientist at sandia national laboratories. he has 30 years experience in communications and computer security, is the holder or coholder of 12 patents, and has participated in national research council (nrc) studies on security matters. prior to joining sandia, he was the technical founder and chief scientist of secure computing corporation, where he developed the sidewinder security server, a system that currently protects several thousand sites. prior to that, he worked for 22 years at honeywell, rising to the position of senior research fellow. at honeywell he worked on secure systems, cryptographic devices, ˚ight software, and a variety of realtime simulation and control systems, and he won honeywell™s highest award for technical achievement for his part in developing a verylargescale radar landmass simulator. he developed and presented a course on systems engineering and project management that was eventually given to over 3,000 students in 13 countries. he served on the nrc committees that produced computers at risk: computing in the information age; for the record: protecting electronic health information; and information technology for counterterrorism: immediate actions and future possibilities. he participated in the nrc workshops on ﬁcyberattackﬂ and ﬁinsider threat.ﬂprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix n 337michael l. brodie is the chief scientist of verizon services operations at verizon communications and is an adjunct professor at the national university of ireland, galway. dr. brodie works on largescale strategic information technology (it) challenges for verizon communications corporation™s senior executives. his primary interest is delivering business value from advanced and emerging technologies and practices to enable business objectives while optimizing and transforming it. he also investigates the relationships between economics, business, and technology and computingcommunications convergence. his longterm industrial research focus is on advanced computational models and architectures and the largescale information systems that they support. he is concerned with the ﬁbig picture,ﬂ business and technical contexts, core technologies, and ﬁintegrationﬂ within a largescale, operational telecommunications environment. dr. brodie has authored over 150 books, chapters, journal articles, and conference papers. he has presented keynote talks, invited lectures, and short courses on many topics in over 30 countries. he is a member of the boards of several research foundations including the semantic technology institutes international (2007present); the european research consortium for informatics and mathematics (2007present); the advisory board of the school of computer and communication sciences, école polytechnique fédérale de lausanne, switzerland (2001present); the advisory board of the digital enterprise research institute, national university of ireland (2003present); forrester research, inc. (2006present); expert advisor to the information society technologies priority of the european commission™s sixth and seventh framework programmes (2003present); the vldb (very large databases) endowment (19922004); and he is on the editorial board of several research journals. he received his ph.d. in computer science from the university of toronto in 1978.duncan a. brown is a member of the principal staff and director of the strategic assessments ofce (sao) at the johns hopkins university (jhu) applied physics laboratory (apl). the sao conducts broadranging analyses and assessments of national security strategy, policy, and technology trends that may affect apl. recent efforts have included conducting an alternative futures exercise to examine potential geopolitical strategic futures and their impact on the military and related research and development, conducting an effort for the ofce of the secretary of defense and the ofce of the secretary of the navy to examine the principles of war, providing technical analysis and advice to the defense advanced research projects agency, and serving on a study panel sponsored by the national reconnaissance ofce and the navy to assess the protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.338 protecting individual privacy in the struggle against terroristsfuture use of space. prior efforts have included submarine force wartime readiness assessments, creation of the u.s. navy™s unmanned combat aerial vehicle program, serving on a naval research and advisory committee panel to examine issues associated with transitioning technology, and serving on the nrc naval studies board to examine the role of experimentation in building future naval forces. mr. brown has also served on the navy staff in the pentagon as the science advisor to the deputy chief of naval operations, in the pacic as the science advisor to the commander in chief pacic fleet, and in the pentagon as the director for submarine technology. mr. brown also headed the hydrodynamics branch at the naval undersea warfare center in newport, r.i. mr. brown has received three navy superior civilian service awards. mr. brown™s formal education includes graduate work in national security studies at georgetown and mit. he was a fellow in mit™s seminar xxi foreign politics and international relations in the national interest program. mr. brown also holds an m.s. degree from johns hopkins university in engineering management, an m.s. degree in ocean engineering from the university of rhode island, and a b.s. degree in engineering science from hofstra university.fred h. cate is a distinguished professor, the c. ben dutton professor of law, adjunct professor of informatics, and director of the center for applied cybersecurity research at indiana university. he is a senior policy advisor to the center for information policy leadership at hunton & williams llp, a member of microsoft™s trustworthy computing academic advisory board, and a member of the board of editors of privacy & information law report. he also serves as reporter for the american law institute™s project on principles of the law on government access to and use of personal digital information. previously, he served as counsel to the department of defense technology and privacy advisory committee, was a reporter for the third report of the markle task force on national security in the information age, and a member of the federal trade commission™s advisory committee on online access and security. he directed the electronic information privacy and commerce study for the brookings institution, chaired the international telecommunication union™s highlevel experts on electronic signatures and certication authorities, and served as a member of the united nations working group on emergency telecommunications. professor cate is the author of many articles and books, including privacy in the information age, the internet and the first amendment, and privacy in perspective. he researches and teaches in the areas of privacy, security, and other information policy and law issues. an elected member of the american law institute, he protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix n 339attended oxford university and received his j.d. and his a.b. with honors and distinction from stanford university.ruth a. david is the president and chief executive ofcer of anser, a notforprot, publicservice research institution that provides research and analytic support on issues relating to international and domestic terrorist threats. dr. david is a member of the department of homeland security advisory council (hsac), nae, and the corporation for the charles stark draper laboratory, inc. she is vice chair of the hsac senior advisory committee of academia and policy research and serves on the national security agency advisory board, the nrc naval studies board, the nae committee on engineering education, the aaas committee on scientic freedom and responsibility, the jet propulsion laboratory™s technical division advisory board, and the external advisory committee for purdue university™s homeland security institute. from september 1995 to september 1998, dr. david was deputy director for science and technology at the central intelligence agency (cia). as technical advisor to the director of central intelligence, she was responsible for research, development, and deployment of technologies in support of all phases of the intelligence process. she represented the cia on numerous national committees and advisory bodies, including the national science and technology council and the committee on national security. prior to moving to the cia, she was director of advance information technologies at sandia national laboratories where she began her professional career. she is the recipient of many awards including the cia™s distinguished intelligence medal, the cia director™s award, and the director of nsa distinguished service medal. she is a former adjunct professor at the university of new mexico. her research interests include digital and microprocessorbased system design, digital signal analysis, adaptive signal analysis, and system integration. dr. david received her ph.d. in electrical engineering from stanford university.ruth m. davis is president and chief executive ofcer of the pymatuning group, inc., which specializes in industrial modernization strategies and technology development. she has served on the boards of 12 corporations and private organizations and was a member of the board of regents of the national library of medicine from 1989 to 1992. she has chaired the board of trustees of the aerospace corporation. dr. davis served as assistant secretary of energy for resource applications and deputy undersecretary of defense for research and advanced technology. she has taught at harvard university and at the university of pennsylvania, and she has served on the university of pennsylvania™s board of overseers of the protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.340 protecting individual privacy in the struggle against terroristsschool of engineering and applied science. she has served on a number of advisory committees to the federal government and was on the nae council. she was elected to nae in 1976. she has served on more than two dozen nrc panels and committees. she has a ph.d. in mathematics from the university of maryland. her research interests include expediting the development process for law enforcement technologies, and she has worked extensively on means of identifying meaningful requirements for law enforcement technologies and ensuring adequacy of life cycle functions. she has studied and written on the technical and managerial features of the technologybased threat to information assets.william h. dumouchel is chief statistical scientist at the lincoln safety group of phase forward, inc. his current research focuses on statistical computing and bayesian hierarchical models, including applications to metaanalysis and data mining. dr. dumouchel is the inventor of the empirical bayesian data mining algorithm known as gps and its successor mgps, which have been applied to the detection of safety signals in databases of spontaneous adverse drug event reports. these methods are now used within the food and drug administration and industry. from 1996 through 2004, he was a senior member of the data mining research group at at&t laboratories. before that, he was chief statistical scientist at bbn software products, where he was lead statistical designer of a software advisory system for data analysis and experimental design called rs/discover and rs/explore. dr. dumouchel has been on the faculties of the university of california at berkeley, the university of michigan, mit, and most recently was professor of biostatistics and medical informatics at columbia university from 19941996. he has also been an associate editor of the journal of the american statistical association, statistics in medicine, statistics and computing, and the journal of computational and graphical statistics. dr. dumouchel is an elected fellow of the american statistical association and of the institute of mathematical statistics, and he has served previously on the nrc committee on applied and theoretical statistics. recently he served on the institute of medicine™s committee on postmarket surveillance of pediatric medical devices and is currently a member of the nrc committee on national statistics. he received his ph.d. in statistics from yale university.cynthia dwork is a principal researcher at microsoft research‚s silicon valley laboratory, which she joined at its inception in 2001. prior to that, she was a staff fellow at compaq in 2000 to 2001, and from 1985 to 2000, she was a research staff member at the ibm almaden research center. she has made seminal contributions in three areas of theoretical computer science: distributed computing, cryptography, and, most protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix n 341recently, privacypreserving analysis of data. a founding member of the journal of privacy and condentiality, she is on the editorial boards of information and computation, the journal of cryptology, internet mathematics, and the journal of theoretical computer science. dr. dwork has been a member of the advisory board for the center for discrete mathematics and theoretical computer science at rutgers university for more than a decade and is still serving on the advisory board of the bertinoro international center for informatics in italy and on the fellows selection committee of the international association of cryptologic researchers. she received the edsger w. dijkstra award in 2007 and was elected to both nae and aaas in 2008.stephen e. fienberg is the maurice falk university professor of statistics and social science at carnegie mellon university in the department of statistics, the machine learning department, and cylab. he has served as dean of the college of humanities and social sciences at carnegie mellon university and as academic vice president of york university in toronto, canada. his current research interests include approaches to data condentiality, record linkage, and disclosure limitation; modeling of network data; causation; machine learning and bayesian mixedmembership models; foundations of statistical inference; sample surveys and randomized experiments; statistics and the law. he has participated in a wide array of nrc committees and workshops, including as chair of the committee to review the scientic evidence on the polygraph, chair of the committee on national statistics, and as a member of the national academies™ division of behavioral and social sciences and education. dr. fienberg has also served as president of the institute of mathematical statistics and of the international society for bayesian analysis. he is the author, coauthor, or editor of numerous books including discrete multivariate analysis: theory and practice; the analysis of crossclassied categorical data, and who counts? the politics of censustaking in contemporary america. he is an editor of the annals of applied statistics and a founder of the journal of privacy and condentiality. he is a former editor of the journal of the american statistical association, founding coeditor of chance, and served as coeditor of the ﬁsection for statisticsﬂ of the international encyclopedia of the social and behavioral sciences. he holds a ph.d. in statistics from harvard university and is a member of the national academy of sciences and a fellow of aaas and the royal society of canada.robert j. hermann is senior partner of global technology partners, llc, which specializes in providing strategic advice on national security and technology issues. in 1998, dr. hermann retired from united technologies corporation where he held the position of senior vice president, protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.342 protecting individual privacy in the struggle against terroristsscience and technology. in this role, he was responsible for assuring the development of the company™s technical resources and the full exploitation of science and technology by the corporation. he was also responsible for the united technologies research center (utrc). dr. hermann joined the company in 1982 as vice president, systems technology, in the electronics sector and later served in a series of assignments in the defense and space systems groups prior to being named vice president, science and technology. prior to joining utrc, he served for 20 years with nsa with assignments in research and development, operations, and the north atlantic treaty organization. in 1977, he was appointed principal deputy assistant secretary of defense for communications, command, control, and intelligence. in 1979, he was named assistant secretary of the u.s. air force for research, development, and logistics and, in parallel, was director of the national reconnaissance ofce. he received b.s., m.s., and ph.d. degrees in electrical engineering from iowa state university.r. gil kerlikowske is a 32year law enforcement veteran and was appointed as the chief of police for the seattle police department in august 2000. he is a former deputy director for the u.s. department of justice™s ofce of community oriented policing services, which provides federal grants to local police agencies in support of community policing services. he served as the police commissioner for buffalo, new york, where his selection by the mayor became the rst outside appointment in 30 years. mr. kerlikowske also served as the chief of police for two florida citiesšfort pierce and port st. luciešboth of which received the attorney general™s crime prevention award. in 1985 he was a visiting fellow at the national institute of justice where he designed an evaluation of police procedures throughout the country. he began his law enforcement career in 1972 as a police ofcer for the st. petersburg police in florida. mr. kerlikowske also served in the u.s. army military police. he holds b.a. and m.a. degrees in criminal justice from the university of south florida and is a graduate of the national executive institute at the federal bureau of investigations academy.orin s. kerr is a professor of law at the george washington university of school of law. he is a prolic scholar in the area of criminal procedure and computer crime law. professor kerr™s articles have appeared in harvard law review, columbia law review, stanford law review, michigan law review, new york university law review, georgetown law journal, northwestern university law review, and many other journals. from 1998 to 2001, he was an honors program trial attorney in the computer crime and intellectual property section of the criminal division at the u.s. department of justice. he is a former law clerk for judge leonard i. garth of protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix n 343the u.s. court of appeals for the third circuit and for justice anthony m. kennedy of the u.s. supreme court. professor kerr received a b.s.e. in mechanical and aerospace engineering from princeton university, an m.s. in mechanical engineering from stanford university, and a j.d. from harvard law school.robert w. levenson is a professor in the department of psychology at the university of california, berkeley, and is the director of the institute of personality and social research and the berkeley psychophysiology laboratory. his research interests include the physiological, facial expressive, and subjective aspects of emotion, and the emotional changes that occur in neurodegenerative disorders and normal aging. he has published numerous papers on the autonomic nervous system. he has served as president of the society for psychophysiological research, as president of the association for psychological science, and as cochair of the behavioral sciences workgroup at the national institute of mental health. dr. levenson received his b.a. in psychology from georgetown university and his ph.d. from vanderbilt university in clinical psychology.tom m. mitchell is the e. fredkin professor and founding head of the machine learning department at carnegie mellon university. his research interests are generally in machine learning, articial intelligence, and cognitive neuroscience. his recent research has focused both on machine learning approaches to extracting structured information from unstructured text and on studying the neural representation of language in the human brain using functional magnetic resonance imaging. dr. mitchell is a past president of the american association of articial intelligence, past chair of the aaas section on information, computing, and communication, and author of the textbook machine learning. from 1999 to 2000, he served as chief scientist and vice president for whizbang labs, a company that employed machine learning to extract information from the web. dr. mitchell has served on the nrc™s computer science and telecommunication board and on the committee that produced the report information technology for counterterrorism: immediate actions and future possibilities. he testied at the u.s. house committee on veterans™ affairs hearing on the potential uses of articial intelligence to improve benets claims processing at the veterans™ administration. dr. mitchell received his ph.d. in electrical engineering with a computer science minor from stanford university.tara o™toole is chief executive ofcer and director of the center for biosecurity at the university of pittsburgh medical center (upmc), and professor of medicine and of public health at the university of pittsburgh. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.344 protecting individual privacy in the struggle against terroristsdr. o™toole was one of the original members of the johns hopkins center for civilian biodefense strategies and served as its director from 2001 to 2003. she was one of the principal authors and producers of ﬁdark winter,ﬂ an in˚uential exercise conducted in june 2001 to alert national leaders to the dangers of bioterrorist attacks. from 1993 to 1997, she served as the assistant secretary of energy for environment safety and health. as assistant secretary, dr. o™toole was the principal advisor to the secretary of energy on matters pertaining to protecting the environment and worker and public health from the u.s. nuclear weapons complex and department of energy laboratories. from 1989 to 1993, dr. o™toole was a senior analyst at the ofce of technology assessment (ota), where she directed and participated in studies of health impacts on workers and the public due to environmental pollution resulting from nuclear weapons production. dr. o™toole is a boardcertied internist and occupational medicine physician. she received her bachelor™s degree from vassar college, her m.d. from george washington university, and an m.p.h. from johns hopkins university. she completed a residency in internal medicine at the yale school of medicine and a fellowship in occupational and environmental medicine at johns hopkins university.daryl pregibon is a research scientist at google, inc. he is a recognized leader in data mining, the interdisciplinary eld that combines statistics, articial intelligence, and database research. from 1981 to 2004, he worked at bell labs and at&t labs and served as head of statistics research for fteen years. he is a past member of the nrc committee on national statistics, the committee on the feasibility of a national ballistics database, and the committee on applied and theoretical statistics (past chair). he is a member of the national advisory committee for the statistical and applied mathematical sciences institute and a former director of the association for computer machinery™s (acm™s) special interest group on knowledge development and data mining. in 1985 he cofounded (with bill gale) the society for articial intelligence and statistics. he has authored more than 60 publications and holds four patents. dr. pregibon received his ph.d. in statistics from the university of toronto and his m.math. degree in statistics from the university of waterloo.louise richardson is executive dean of the radcliffe institute for advanced study at harvard university. she received her bachelor™s and master™s degrees in history from trinity college, dublin, and an m.a. and a ph.d. in government from harvard university. from 1989 to 2001, dr. richardson was assistant and associate professor of government at harvard. she teaches courses on terrorism at harvard college, graduate school, and law school. a political scientist by training, dr. richardson protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix n 345has specialized in international security with an emphasis on terrorist movements. her recent publications include what terrorists want: understanding the enemy, containing the threat (2006); the roots of terrorism (2006); democracy and counterterrorism: lessons from the past (2007); and when allies differ (1996), along with numerous articles on international terrorism, british foreign and defense policy, security institutions, and international relations. she is coeditor of the suny press series on terrorism. dr. richardson™s current research projects involve a study of patterns of terrorist violence and a study on counterterrorism lessons to be derived from earlier experiences with terrorism.ben a. shneiderman is a professor in the department of computer science and the institute for advanced computer studies at the university of maryland, college park. he is a founding director of the humancomputer interaction laboratory (19832000). he has taught previously at the state university of new york (suny) and at indiana university. he is a fellow of the acm and the aaas and received the acm chi (computer human interaction) lifetime achievement award in 2001. he has coauthored two textbooks, edited three technical books, and published more than 300 technical papers and book chapters. he coauthored readings in information visualization: using vision to think with stu card and jock mackinlay and the craft of information visualization: readings and re˚ections with ben bederson. dr. shneiderman™s vision of the future is presented in his book leonardo™s laptop: human needs and the new computing technologies, which won the ieee 2003 award for distinguished literary contribution. he has consulted and lectured for many organizations including apple, at&t, citicorp, general electric, honeywell, ibm corporation, intel corporation, microsoft, ncr, the library of congress, the national aeronautics and space administration, and university research groups. he received his ph.d. from suny at stony brook.daniel j. weitzner is codirector of mit™s csail decentralized information group (dig) and teaches internet public policy in the mit electrical engineering and computer science department. he is also policy director of the world wide web consortium™s (w3c™s) technology and society activities. at dig he leads research on the development of new technology and public policy models for addressing legal challenges raised by the web, including privacy, intellectual property, identity management, and new regulatory models for the web. at w3c he is responsible for web standards needed to address public policy requirements, including the platform for privacy preference (p3p) and xml security technologies. he was the rst to advocate user control technologies such as content ltering to protect children and to avoid government censorprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.346 protecting individual privacy in the struggle against terroristsship, and he played a critical role in the landmark internet freedom of expression case in the u.s. supreme court, reno v. aclu (1997). in 1994, his advocacy work won legal protections for email and web logs in the u.s. electronic communications privacy act. mr. weitzner was cofounder and deputy director of the center for democracy and technology and deputy policy director of the electronic frontier foundation. he serves on the board of directors of the center for democracy and technology, the software freedom law center, and the internet education foundation. he has a law degree from buffalo law school and a b.a. in philosophy from swarthmore college. his writings have appeared in science, yale law review, communications of the acm, computerworld, ieee internet computing, wired magazine, social research, and the whole earth review.staff membersbetty m. chemers is a senior project ofcer at the national research council, which she joined in may 2005 after spending 30 years in the public and notforprot sectors working on criminal justice and juvenile justice issues. she currently directs two studies: one on terrorism prevention funded by the department of homeland security and the national science foundation and a second study on an assessment of the research program of the national institute of justice (nij) funded by nij. prior to this, she held numerous positions at the u.s. department of justice including director of the evaluation division of the nij (20022005) and deputy administrator for discretionary programs at the ofce of juvenile justice and delinquency prevention (19952001), where she oversaw its $100 million budget of research, demonstration, and training and technical assistance activities. her nonfederal service includes directing the planning and policy analysis division for the maryland department of public safety and correctional services and consulting on strategic planning, nance, and management issues with nonprots. she holds an m.a. in history from boston university and a b.a. in education/sociology from the university of maryland.michael l. cohen is a senior program ofcer for the nrc committee on national statistics. previously, he was a mathematical statistician at the energy information administration, an assistant professor in the school of public affairs at the university of maryland, a research associate at the committee on national statistics, and a visiting lecturer at the department of statistics, princeton university. his general area of research is the use of statistics in public policy, with particular interest in census undercount and model validation. he is also interested in robust estimation. protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix n 347he has a b.s. degree in mathematics from the university of michigan and m.s. and ph.d. degrees in statistics from stanford university.herbert s. lin is chief scientist of the computer science and telecommunications board, national research council of the national academies, where he has been the study director of major projects on public policy and information technology. these studies include a 1996 study on national cryptography policy (cryptography™s role in securing the information society); a 1992 study on the future of computer science (computing the future: a broader agenda for computer science and engineering); a 1999 study of the u.s. department of defense systems for command, control, communications, computing, and intelligence (realizing the potential of c4i: fundamental challenges); a 2001 study on workforce issues in high technology (building a workforce for the information economy); and a 2002 study on protecting children from internet pornography and sexual exploitation (youth, pornography, and the internet). prior to his nrc service, he was a professional staff member and staff scientist for the house armed services committee (19861990), where his portfolio included defense policy and arms control issues. he also has signicant expertise in mathematics and science education. he received his doctorate in physics from the massachusetts institute of technology. carol petrie is director of the nrc committee on law and justice, a standing committee within the division of behavioral and social sciences and education. in this capacity since 1997, she has developed and supervised a wide range of projects resulting in nrc reports in such areas as juvenile crime, pathological gambling, transnational organized crime, prosecution, crime victimization, improving drug research, school violence, rearms, policing, and forensic science. prior to 1997, she served as the director of planning and management at the national institute of justice, where she was responsible for policy development, budget, and administration. in 1994, she served as the acting director of the nij. throughout her career she has worked in the area of criminal justice research, statistics, and public policy at the nij and at the bureau of justice statistics. she has conducted research on violence and public policy and managed numerous research projects on the development of criminal behavior, domestic violence, child abuse and neglect, and improving the operations of the criminal justice system.julie anne schuck has been a research associate at the nrc for over six years in the division of behavioral and social sciences and education. she has worked on a number of different projects and workshops, includprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.348 protecting individual privacy in the struggle against terroristsing those on improving undergraduate instruction in science, technology, engineering, and mathematics; understanding the technical and privacy dimensions of information for terrorism prevention; and assessing the research program of the nij. prior to coming to the nrc, she was a research support specialist at cornell university, where she conducted a study examining the underrepresentation of women in physicsbased engineering majors. she holds an m.s. in education from cornell university and a b.s. in engineering physics from the university of california, san diego.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.349omeeting participants and other contributorsmeeting participantsthe committee on technical and privacy dimensions of information for terrorism prevention and other national goals held ve meetings starting in 2006. these meetings included informationgathering sessions open to the public, as well as closed segments for committee deliberation. the committee heard from numerous presenters at these meetings. they include the following by meeting date and session.april 2728, 2006session 1: deception detection and reducing errorspaul ekman, university of california, san franciscohenry greely, stanford university school of lawbarry steinhardt, technology and liberty program, american civil liberties unionjohn woodward, intelligence policy center, rand corporationtom zefro, center for functional and molecular imaging, georgetown universitysession 2: communicationsclint c. brooks, national security agency (retired)whiteld dife, sun microsystemsjohn pike, director, globalsecurity.orgjody westby, global cyber risk, university of californiaprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.350 protecting individual privacy in the struggle against terroristssession 3: data miningrandy ferryman, u.s. national counter terrorism centerjohn hollywood, rand corporationdavid jensen, knowledge discovery laboratory, university of massachusetts, amherstjeff jonas, entity analytic systems, ibm corporationdavid scott, rice universitykim taipale, center for advanced studies in science and technology policyjuly 2728, 2006session 1: privacy laws and concepts; law and policy revision effortslee tien, electronic frontier foundationsession 2: law enforcement, counterterrorism, and privacyphilip r. reitinger, trustworthy computing, microsoft corporationsession 3: data mining in the commercial worldscott loftesness, glenbrook partnersdan schutzer, financial services technology consortiumoctober 2627, 2006session 1: providing a national perspectiveadm. scott redd, national counter terrorism centersession 2: law enforcement intelligencemichael fedarcyk, bearingpoint and federal bureau of investigation (retired)roy i. apseloff, national media exploitation centerjoe connell, counterterrorist command, new scotland yardsession 3: status of research on deception detection technologiesmark frank, university at buffalora ron, ben gurion airport, israel (retired) and boston logan airportprotecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.appendix o 351session 4: biosurveillance technology and privacy issuesjames v. lawler, homeland security council, white houselynn steele, emergency preparedness and response, centers for disease control and prevention (cdc)barry rhodes, emergency preparedness and response, cdcfarzad mostashari, new york city public health departmentpatricia quinlisk, state of iowasession 5: data linkageswilliam e. winkler, u.s. census bureausession 6: presentation on dhs data system activitieslisa j. walby, transportation security administration, department of homeland security (dhs)sandy landsberg, science and technology directorate, dhsjanuary 1819, 2007closed meetingmarch 2930, 2007closed meetingother contributionsfrom january 1 to march 1, 2007, the committee solicited wellreasoned white papers that identied and discussed issues relevant to the use of data mining, information fusion, and deception detection technologies as they relate to the twin goals of protecting privacy and pursuing terrorism prevention, law enforcement, and public health. the following papers were submitted for the committee™s review:michael d. larsen. 2007. ﬁrecord linkage, nondisclosure, counterterrorism, and statistics.ﬂ department of statistics and center for survey statistics and methodology, iowa state university.peter swire. 2006. ﬁprivacy and information sharing in the war on terrorism.ﬂ villanova law review 51, available at http://ssrn.com/abstract=899626.protecting individual privacy in the struggle against terrorists: a framework for program assessmentcopyright national academy of sciences. all rights reserved.352 protecting individual privacy in the struggle against terroristsin response to the call for papers, the dhs data privacy and integrity advisory committee1 transmitted the following ve reports:data privacy and integrity advisory committee. 2006. the use of rfid for human identity verication. report no. 200602. adopted december 6, 2006. dhs, washington, d.c.data privacy and integrity advisory committee. 2006. the use of commercial data. report no. 200603. adopted december 6, 2006. dhs, washington, d.c.data privacy and integrity advisory committee. 2006. framework for privacy analysis of programs, technologies, and applications. report no. 200601. adopted march 7, 2006. dhs, washington, d.c.data privacy and integrity advisory committee. 2006. recommendations on the secure flight program. report no. 200502. adopted december 6, 2005. dhs, washington, d.c.data privacy and integrity advisory committee. 2005. the use of commercial data to reduce false positives in screening programs. report no. 200501. adopted september 28, 2005. dhs, washington, d.c.1 see http://www.dhs.gov/xinfoshare/committees/editorial0512.shtm for more information on the dhs data privacy and integrity advisory committee.