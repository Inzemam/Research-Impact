detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/10261youth, pornography, and the internet480 pages | 6 x 9 | paperbackisbn 9780309082747 | doi 10.17226/10261dick thornburgh and herbert s. lin, editors, committee to study tools andstrategies for protecting kids from pornography and their applicability toother inappropriate internet content, national research councilyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.dick thornburgh and herbert s. lin, editorscommittee to study tools and strategies for protectingkids from pornography and their applicabilityto other inappropriate internet contentcomputer science and telecommunications boardnational research councilnational academy presswashington, d.c.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.national academy press ¥ 2101 constitution avenue, n.w. ¥ washington, d.c. 20418notice: the project that is the subject of this report was approved by the governing boardof the national research council, whose members are drawn from the councils of thenational academy of sciences, the national academy of engineering, and the institute ofmedicine. the members of the committee responsible for the report were chosen for theirspecial competences and with regard for appropriate balance.this study was supported by grant no. 1999jnfx0071 between the national academy ofsciences and the u.s. departments of justice and education; grant no. p0073380 betweenthe national academy of sciences and the w.k. kellogg foundation; awards (unnumbered)from the microsoft corporation and ibm; and internal funds of the national research council. any opinions, findings, conclusions, or recommendations expressed in this publicationare those of the authoring committee and do not necessarily reflect the views of the organizations or agencies that provided support for this project.international standard book number 0309082749library of congress control number 2002110219additional copies of this report are available from the national academy press, 2101 constitution avenue, n.w., lock box 285, washington, dc 20055, (800) 6246242 or (202) 3343313(in the washington metropolitan area).this report is also available online at <http://www.nap.edu>.copyright 2002 by the national academy of sciences. all rights reserved.printed in the united states of americayouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific and engineering research, dedicated to the furtherance of science and technology and to their use for the generalwelfare. upon the authority of the charter granted to it by the congress in 1863,the academy has a mandate that requires it to advise the federal government onscientific and technical matters. dr. bruce m. alberts is president of the nationalacademy of sciences.the national academy of engineering was established in 1964, under the charterof the national academy of sciences, as a parallel organization of outstandingengineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsorsengineering programs aimed at meeting national needs, encourages educationand research, and recognizes the superior achievements of engineers. dr. wm. a.wulf is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy ofsciences to secure the services of eminent members of appropriate professions inthe examination of policy matters pertaining to the health of the public. theinstitute acts under the responsibility given to the national academy of sciencesby its congressional charter to be an adviser to the federal government and, uponits own initiative, to identify issues of medical care, research, and education.dr. harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology withthe academyõs purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by theacademy, the council has become the principal operating agency of both thenational academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientific and engineeringcommunities. the council is administered jointly by both academies and theinstitute of medicine. dr. bruce m. alberts and dr. wm. a. wulf are chairmanand vice chairman, respectively, of the national research council.national academy of sciencesnational academy of engineeringinstitute of medicinenational research councilyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.ivcommittee to study tools and strategiesfor protecting kids from pornographyand their applicability to otherinappropriate internet contentdick thornburgh, kirkpatrick & lockhart llp, washington,d.c., chairnicholas j. belkin, rutgers universitywilliam j. byron, holy trinity parishsandra l. calvert, georgetown universitydavid forsyth, university of california, berkeleydaniel geer, @stake inc.linda hodge, parent teacher associationmarilyn gell mason, tallahassee, floridamilo medin, excite@homejohn b. rabun, national center for missing and exploitedchildrenrobin raskin, ziff davis mediarobert j. schloss, ibm t.j. watson research centerjanet ward schofield, university of pittsburghgeoffrey r. stone, university of chicagowinifred b. wechsler, santa monica, californiaherbert s. lin, senior scientist and study directorgail pritchard, program officer (through june 2001)joah g. ianotta, research assistantjanice m. sabuda, senior project assistantdaniel d. llata, senior project assistant (through may 2001)mickelle rodriguez, senior project assistant (throughfebruary 2001)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.vcomputer science and telecommunications boarddavid d. clark, massachusetts institute of technology, chairdavid borth, motorola labsjames chiddix, aol time warnerjohn m. cioffi, stanford universityelaine cohen, university of utahw. bruce croft, university of massachusetts at amherstthomas e. darcie, at&t labs researchjoseph farrell, university of california, berkeleyjeffrey m. jaffe, bell laboratories, lucent technologiesanna karlin, university of washingtonbutler w. lampson, microsoft corporationedward d. lazowska, university of washingtondavid liddle, u.s. venture partnerstom m. mitchell, carnegie mellon universitydonald norman, nielsen norman groupdavid a. patterson, university of california, berkeleyhenry (hank) perritt, chicagokent college of lawburton smith, cray inc.terry smith, university of california, santa barbaralee sproull, new york universityjeannette m. wing, carnegie mellon universitymarjory s. blumenthal, directorherbert s. lin, senior scientistalan s. inouye, senior program officerjon eisenberg, senior program officerlynette i. millett, program officercynthia patterson, program officersteven woo, program officerjanet briscoe, administrative officerdavid padgham, research associatemargaret huynh, senior project assistantdavid drake, senior project assistantjanice m. sabuda, senior project assistantjennifer bishop, senior project assistantbrandye williams, staff assistantyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.viboard on children, youth, and familiesevan charney, university of massachusetts medical school,chairjames a. banks, university of washingtondonald cohen, yale universitythomas dewitt, childrenõs hospital medical center ofcincinnatimary jane england, washington business group on healthmindy fullilove, columbia universitypatricia greenfield, university of california, los angelesruth t. gross, stanford universitykevin grumbach, ucsf/san francisco general hospitalneal halfon, ucla school of public healthmaxine hayes, washington state department of healthmargaret heagarty, columbia universityren…e r. jenkins, howard universityharriet kitzman, university of rochestersanders korenman, baruch college, cunyhon. cindy lederman, juvenile justice center, dade county,floridavonnie mcloyd, university of michigangary sandefur, university of wisconsinmadisonelizabeth spelke, massachusetts institute of technologyruth stein, montefiore medical centereleanor e. maccoby (liaison, division of behavioral and socialsciences and education), stanford university (emeritus)william roper (liaison, iom council), university of northcarolina, chapel hillmichele d. kipke, director (through september 2001)mary graham, associate director, dissemination andcommunicationssonja wolfe, administrative associateelena nightingale, scholarinresidencejoah g. iannotta, research assistantyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.viiyouth, pornography, and the internet. the combination of these elements is a subject on which individuals from all walks of lifeñparents,teachers, librarians, school administrators, library board members, legislators, judges, and other concerned citizensñhave thoughts and strongopinions. those with products and services to sell are also interested inand concerned about the subject. some from the online adult entertainment industry fear that efforts to restrict the access of children to certainkinds of sexually explicit material on the internet will impinge on whatthey see as legitimate business opportunities to market their products andservices to adults. those with technologybased protection systems tosell hope to capitalize on what they see as a growing market for solutionsto the problem, however that may be defined.views in this subject area are highly polarized. because strongly heldvalues are at stake, the political debate is heated, and often characterizedby extreme views, inflammatory rhetoric, and halftruths. against thebackdrop of intense lobbying in the halls of congress and many localschool and library board meetings in communities across the country, adocument assembling in one place the different dimensions and pros andcons of approaches that might be taken to address the problem can help toconduct the debate over òwhat to doó in a more informed manner.thus, one purpose of this report is to provide a reasonably completeand thorough treatment of the problem and potential solutions that airsall sides. in addition, different communities or groups of readers arelikely to be interested in different aspects of this report.prefaceyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.viiipreface¥parents will be interested in its description and assessment of areasonably comprehensive set of tools and strategies for protecting theirchildren on the internet from exposure to inappropriate sexually explicitmaterial (and other inappropriate material for that matter), many of whichcan be deployed in their homes. furthermore, to the extent that parentsunderstand the advantages and disadvantages of these various tools andstrategies, they can engage their legislators and local administrative bodies more effectively.¥adults responsible for children and youth in other settingsñschool,libraries, afterschool programs, camps, and so onñwill be interested inthis description and assessment as well for classroom and other purposes,but also in the political and organizational issues that surround the use ofthese various tools and strategies. those responsible for education broadlyconstrued will also be attentive to the issues related to material that isimproperly or incorrectly identified as inappropriate for children and youth.¥the information technology (it) sector is likely to be interested infinding business opportunities for helping parents and others deal withthe issues as they see fit, while many commercial interests in the it sectorand in other corners are concerned about the possibility of regulation.¥law enforcement agencies may be interested in this report to helpclarify their roles and responsibilities in both preventive and tactical operations, and may benefit from the reportõs overview about existing lawin this area. the judiciary, especially at the local level, may find perspective and understanding that can be useful in trying and hearing casestouching on the subject matter of this report.¥policy makers will be interested in all of these dimensions of theissue, and must decide how to weigh them in their attempts to formulateappropriate policy. further, much of this report points to legal, economic, technical, and social realities that affect how legislation and regulation might actually play out.origin of this studyin november 1998, the u.s. congress mandated a study by the national research council (nrc) to address pornography on the internet(box p.1). in response to this mandate, the computer science and telecommunications board (cstb), responsible within the national academies for issues at the nexus of information technology and public policy,engaged the nrcõs board on children, youth, and families (bocyf) toform a committee with expertise diverse enough to address this topic.the resulting committee was composed of a diverse group of people,including individuals with expertise in constitutional law, law enforcement, libraries and library science, information retrieval and representayouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.prefaceixbox p.1legislative language that led to this studyin public law 105314, the protection of children from sexual predators act of1998, title ix, section 901, the u.s. congress passed the following legislation:sec. 901. study on limiting the availability of pornographyon the internet.(a) in generalñnot later than 90 days after the date of enactment ofthis act, the attorney general shall request that the national academy ofsciences, acting through its national research council, enter into a contractto conduct a study of computerbased technologies and other approaches tothe problem of the availability of pornographic material to children on theinternet, in order to develop possible amendments to federal criminal law andother law enforcement techniques to respond to the problem.(b) contents of studyñthe study under this section shall addresseach of the following:(1)the capabilities of presentday computerbased control technologiesfor controlling electronic transmission of pornographic images.(2)research needed to develop computerbased control technologies tothe point of practical utility for controlling the electronic transmission of pornographic images.(3)any inherent limitations of computerbased control technologies forcontrolling electronic transmission of pornographic images.(4)operational policies or management techniques needed to ensurethe effectiveness of these control technologies for controlling electronic transmission of pornographic images.(c) final reportñnot later than 2 years after the date of enactment ofthis act, the attorney general shall submit to the committees on the judiciaryof the house of representatives and the senate a final report of the studyunder this section, which report shallñ(1)set forth the findings, conclusions, and recommendations of the council;and(2)be submitted by the committees on the judiciary of the house ofrepresentatives and the senate to relevant government agencies andcommittees of congress.based on this language and as noted in the text, the statement of task was negotiated with the department of justice in ways that would lead to a report that placedthe issue of concern in context and would provide a range of useful alternatives forconstituencies affected by this issue. the charge below guided the work of thecommittee to study tools and strategies for protecting kids from pornography:the project, requested by the u.s. congress, seeks to frame the problem in anappropriate social, legal, educational, technological, and ethical context; presentwhat is and is not scientifically known about the impact on children of exposure tosexually explicit material; and provide information useful to various decisionmaking communities (e.g., parents, the information technology industry, school boards,librarians, and government at all levels) about possible courses of action across educational, legislative, law enforcement, and technological fronts. while it does notpresent explicit recommendations about actions that should be taken, it does provide findings and conclusions that result from committee deliberations.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xprefacetion, developmental and social psychology, internet and other information technologies, ethics, and education.cstb, with input from bocyf, developed a proposal that was responsive to the legislative mandate. as a result of discussions with thedepartment of justiceõs office of juvenile justice and delinquency prevention, the department of education, and various private companies inthe information technology industry, the studyõs statement of work wasadjusted to include nontechnological strategies as well as technologyoptions for protection and to address òpornographyó as the primary systematic focus of the studyõs exploration of inappropriate content, withother areas addressed as appropriate for contextsetting purposes, explored incidentally rather than systematically.further, the negotiated statement of work noted that the final reportwould place the issue of concern in context, provide a range of usefulalternatives for constituencies affected by this issue, and explicate thefoundation for a more coherent and objective local and national debate onthe subject of internet òpornography,ó but would avoid making specificpolicy recommendations that embed particular social values in this area.methodology and caveatsas with most controversial issues, the reality of both problem andsolution is much more complex than the rhetoric would indicate. tocomplement the expertise of its members and to understand the issuemore effectively, the committee took a great deal of testimony over thecourse of its study. in its plenary sessions, it heard testimony from some20 parties with differing points of view and expertise; these parties areidentified in appendix a (which provides the agendas of the variousplenary sessions). it held two workshops to explore both technical andnontechnical dimensions of the issue; summaries of these workshopswere published prior to the publication of this report.1members of the committee also visited a range of communities acrossthe united states to hear firsthand from the various constituenciesñnotthe least of which were the children involved. thus, the committee conducted seven site visits from april through june 2001 in a variety of1see national research council and institute of medicine, 2001, nontechnical strategies to reduce childrenõs exposure to inappropriate material on the internet: summary of a workshop,board on children, youth, and families and computer science and telecommunications board,joah g. iannotta, ed., national academy press, washington, d.c.; and computer science and telecommunications board, 2002, technical, business, and legal dimensions of protecting childrenfrom pornography on the internet: proceedings of a workshop, national academy press, washington, d.c.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.prefacexigeographical locales: austin, texas, on april 34; greenville, south carolina, on april 1718; salt lake city, utah, on april 2627; san diego,california, on may 23; blacksburg, virginia, on may 89; coral gables,florida, on may 30june 1; and redding, shelton, bristol, kent, andhamden, connecticut, on june 12.finally, the committee issued a call for white papers and receivedabout 10 (all of which are posted on the project web site at <http://www.itasnrc.org>). the committee noted the existence of other work andreports on the subject, such as the final report of the copa commission,2the report of the house committee on commerce on the childrenõs onlineprotection act,3 safeguarding the wired schoolhouse from the consortiumon school networking,4 and various efforts supported by the bertelsmannfoundation (e.g., protecting our children on the internet5). and, becausethe committee was, by design, composed of individuals with varyingexpertise and perspectives on the issues, the committee learned from itselfñthrough argument and discussion. as a result of this process, it isfair to say that every committee member came to understand the issuedifferently than when he or she first joined the studyñand left behindany notion that an instant solution could be found.this study is not a comprehensive study of safety on the internet, noreven one on safety for children on the internet. the primary emphasis ofthis study is on approaches to protect youth from pornographyñor moreproperly, sexually explicit material deemed inappropriate for minorsñthough the relevance of these approaches to some other kinds of materialdeemed inappropriate receives some attention as well. this emphasisdoes not reflect a consensus of the committee that inappropriate sexuallyexplicit material isñor is notñthe most important safety issue on theinternet for children, but rather the fact that such material was a centralelement in the legislative mandate to the committee.this study is not a study on the impact of exposure to such material,nor does it come to a consensus on this question. committee membershad, and continue to have, a variety of different views. committee members do share common views about the undesirability of exposing children to some kinds of sexually explicit material, but they do not share2the copa commission was established as part of the child online protection act, discussed inchapter 4. information on the copa commission can be found online at <http://www.copacommission.org>.3h.r. no. 105775.4consortium for school networking. 2001. safeguarding the wired schoolhouse. availableonline at <http://www.safewiredschools.org/pubsandtools/whitepaper.pdf>.5jens waltermann and marcel machill, eds. 2000. protecting our children on the internet.bertelsmann foundation publishers, gutersloh, germany.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xiiprefaceviews about other kinds of sexually explicit material. but coming toconsensus on a world view regarding all sexually explicit material wasnot the task given to the committee, and the consensus on the materialcontained in this reportñwhich focuses on things that communities cando to help themselvesñindicates that such agreement is not necessary formaking informed decisions.note also that this report mentions a variety of companies, products,services, and web sites. these references are for illustrative purposesonly, and their mention should not be taken by readers as an endorsement in any way.scope and purpose of this reportthis report surveys the technical, legal, law enforcement, educational,and economic dimensions of the problem of coping with materials andexperiences on the internet that are inappropriate for children. in addition, it describes a range of social and educational strategies, technologybased tools, and legal and regulatory approaches that can help children touse the internet more safely. thus, this report provides a frameworkwithin which responsible adults can develop their own approachesñembodying their own valuesñfor the children in their care.this study does not make recommendations about what communitiesshould do about the problem. although this study explicates the factorsthat can enter into choices about appropriate approaches to protectingkids from inappropriate sexually explicit material on the internet, thechoice of any particular approach implies a particular weighting of thesevarious factors, and hence embeds a particular value choice, which thecommittee was not charged to make. rather, the study emphasizes theinformation needed to conduct a reasoned discussion among those seeking to decide what to do. any given communityõs decision will be shapedby the values it brings to that decisionmaking process.acknowledgmentsmany people contributed to this complex study and comprehensivereport. the committee took testimony from many individuals at its plenary sessions and at site visits. the site visits in particular were valuableprecisely because they gave committee members a sense of life òin thetrenches,ó allowing them to put into appropriate perspective the inputreceived during plenary sessions and contributed in white papers. (appendix a provides the agendas of all meetings and site visits.)talking to children about their perceptions and reactions to sexuallyexplicit material on the internet is obviously a sensitive and delicate unyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.prefacexiiidertaking, and the committee is deeply grateful to those individuals andschools that allowed their students, teachers, and administrators to speakfreely with committee members and staff.these site visits would not have been possible without the assistanceof people at each locale. the committee and staff would like to acknowledge the following individuals:¥in austin, jeanette larson, youth services manager, austin public library, provided numerous leads regarding whom to contact toarrange focus group sessions. many thanks also to randy strickland forbrokering sessions with students and teachers at john connally highschool in pflugerville, texas; sulema vielman, for sessions with librarians at cepeda branch library, austin, texas; julia cuba of the girlscouts lone star council for her advice; and angela knottfryer ofsettlement home.¥arrangements in greenville were facilitated by norman belk, immediate past president of the south carolina library association, andbeverly white, executive director, education technology services, theschool district of greenville county. the committee is also grateful torosia gardner of mauldin middle school, simpsonville, south carolina;michael evans, branch manager of the w. jack greer library of mauldin;sheila bradley and rodney c. thompson of the phillis wheatley association, greenville; and ginger stuart, interim principal, greenville seniorhigh academy of academic excellence.¥the committee thanks chip ward, assistant director, and nancytessman, director, of the salt lake city library, for their willingness tohost sessions, make contacts, and suggest leads to staff. it also thankslaura hunter, director of content, utah education network; paula houston, obscenity and pornography complaints ombudsman, office of theattorney general; clint spindler, principal, tooele junior high school,tooele, utah; and sandra shepard, principal, tooele high school, tooele,utah, for their contributions to the site visit.¥in san diego, suzanne hess of el cajon library in el cajon andcharlie garten, director of technology in the poway unified school district, were pivotal in organizing library and school sessions. the committee also thanks paul robinson, rancho bernardo high school; walterdesmond, lincoln high school, san diego; and andrea skorepa, director, florencia gomez, youth service director, and teresa murillo, computer lab coordinator at casa familia in san ysidro, for hosting focusgroup sessions.¥sincere thanks are extended to peggy meszaros, director of thecenter for information technology impacts on children, youth, and families at the virginia polytechnic institute and state university, for heryouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xivprefaceextensive help in identifying and arranging focus groups in blacksburg,virginia. the committee also thanks gary mccoy, principal of blacksburgmiddle school; mary fain, principal of blacksburg high school; and andrew michael cohill, director of blacksburg electronic village, for theircontributions to the site visit.¥in coral gables, florida, the committee appreciates the assistanceof anne thompson, program commissioner of the national pta; karinbrown, president of miamidade county pta; joyce corces, coral gableshigh school; alexander rodriguezroia, boys and girls club of miami;and jenine gendron, fischler graduate school of education and humanresources, nova southeastern university, ft. lauderdale.¥in connecticut, the committee appreciates the assistance of arleneliscinsky, treasurer of the connecticut state pta, for the shelton visit;therese duncan, vice president for legislation of the connecticut statepta, for the kent visit; deborah walsh, president of the connecticut statepta, for the hamden visit; and beverly bobroske, president of the connecticut association of boards of education, for the bristol visit.most of all, the committee appreciates the parents and students fortheir frank participation in the focus group sessions that took place during the site visits.in the initial stages of project development, david eisner from americaonline was instrumental in convening representatives from the online industry to discuss the project. as a result of these meetings, the nrc cameto understand the concerns of this community in greater detail.the committee members also extend their appreciation to the numerous presenters who briefed them during the project. of particular interestwas a special session at the committeeõs december 2000 workshop withcommunity teams. team members were charged with listening to theexpert presentations and then applying what they had learned, as well astheir own experience, to a hypothetical scenario. committee membersengaged community teams as they reported their thoughts about application. the purpose of this activity was to provide information to the committee regarding how the expert but largely theoretical testimony mightbe interpreted and applied in practical terms by education and libraryprofessionals working in the field. for their participation in this activity,the committee thanks paulette armstrong, carol bird, stephen boyles,trina brown, andy carvin, deb elder, marjorie geldon, william giddings, wayne hartschuh, marge medd, david milhon, irene e. millett,sandra patton, jeana pulis, mike westmoreland, arthur wolinsky, and inparticular, for their enormous contribution to orchestrating the community teams, sara fitzgerald and keith krueger of the consortium forschool networking.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.prefacexvthe committee also appreciates the hundreds of suggestions and constructive criticism provided by the reviewers of an early draft of thisreport. that input helped the committee to sharpen its message andstrengthen its presentation.within the nrc, the lead unit on the project was the computer science and telecommunications board. however, the committee receiveda high level of support from members and staff of the board on children,youth, and familiesñand specifically calls attention to the critical rolesplayed by joah ianotta, research assistant for bocyf, in developing thesummary of the first workshop on nontechnical strategies, and by gailpritchard, previously staff officer for cstb, and mickelle rodriguez,former senior project assistant, in organizing the site visits under verytrying conditions.finally, grateful thanks are offered to microsoft, ibm, and the kelloggfoundation, whose financial support for this project was essential inrounding out the sponsorship of the departments of justice and education. cstbõs sponsors enable but do not influence its projects.a personal note from the chairthe national academies are well known for producing authoritativereports on controversial subjects. it is the hope of the committee that thisreport will be seen as comprehensive and authoritative, but i believe it isbound to disappoint a number of readers. it will disappoint those whoexpect a technological òquick fixó to the challenge of pornography on theinternet. it will disappoint those who suggest that an aggressive lawenforcement effort is all that is necessary to shut down pornography purveyors of all types. it will disappoint parents, school officials, and librarians who seek surrogates to fulfill the responsibilities of training andsupervision needed to truly protect children from inappropriate sexualmaterials on the internet. and it will disappoint free speech absolutistswho maintain that children have an unrestricted right to access whatevermaterials they choose to read or view in todayõs society.many of the members of this committee, including its chair, broughtto our task somewhat simplistic views of the challenges implicit in ourcharge. my own views were shaped by a career in law enforcementduring which time i learned that the issue of children and pornography ishighly political and emotionally volatile. as a parent and a grandparent,i also feel that i have a personal stake in this issue.i think it is fair to say that all committee members recognize that wefinish our task enriched by the welter of material developed for our useand by the exchanges that took place among us. most of us are somewhatchastened, i suspect, by adherence to our earlier views. for, in truth, asyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xviprefaceour report spells out in great detail, there are no easy answers to thequestions posed to our society by the proliferation of sexually explicitmaterials and their ready availability to children, particularly through themodern miracle we know as the internet.today our society is awash in graphic, sexually explicit materials thatare widely available in nearly every medium of communicationñprint,audio, and videoñand in nearly every imaginable setting from home andschool to overnight lodging. much of the material with which this reportis concerned was clearly violative of the obscenity laws a decade or soago, but seldom are prosecutions brought in this 21st century.the ubiquitous nature of the internet poses special challenges forthose concerned with this phenomenon. according to the u.s. census,twothirds of u.s. schoolage children had home access to a personalcomputer in 2000.6 and, most of these computers provide access to theinternet. these figures are even higher when schoolprovided access isadded, and 90 percent of our children have internet access in either homesor school.the rapid growth in the availability of internet images during the lastdecade has posed two specific problems in the conduct of this study. firstis the private nature of internet usage. parental and teacher or librariansupervision is not nearly as easy when children seek or are inadvertentlyexposed to sexually explicit materials on the internet as when such images are available in books or on the family television set. òpolicingó byresponsible adults is much more difficult when the internet is involved.moreover, the fact that the internet is a worldwide method of communication creates two special problems for law enforcementñevenwhen the subject matter is what has been traditionally outlawed as obscene. u.s. supreme court decisions defining what is òobsceneó depend,among other things, on the development of òcommunity standardsóagainst which the offending materials may be measured. what is theòcommunityó for a medium that is worldwide in its reach? in addition, asthe report notes, much of the pornography available on the internet in theunited states has its origins outside our borders and beyond the reach oflaw enforcement officials here. these are truly vexing challenges to eventhe most capable of modern criminal investigators and prosecutors.the breadth of background and experience of the members of thiscommittee was a significant advantage in pursuing our charge. likewise,the process undertaken by the committee was designed to seek out andwrestle with the many issues implicit in that charge. we sought to order6see u.s. census press release. 2001. ò9in10 schoolage children have computer access;internet use pervasive, census bureau reports.ó september 6. available online at <http://www.census.gov/pressrelease/www/2001/cb01147.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.prefacexviiour inquiry in a way that ensured that we heard from all sides and representatives of every interested point of view. our field trips took us tocommunities across the country so that we might learn firsthand the viewsof parents, teachers, children, community leaders, and law enforcementofficials. we also sought out experts in child development and childpsychology, those intimately familiar with the technology of the internet,and representatives of the adult entertainment industry themselves. i amsatisfied that no potential sources of information or opinion were neglected, even if certainty on many points remained elusive.in the final analysis, i believe that this report advances our understanding of the problems of childrenõs access to inappropriate sexual materials on the internet. but much work remains to be done. as noted, it isessential that unresolved legal issues be put to rest. an observation to theeffect that òwe know obscenity when we see itó will no longer suffice. welive under the rule of law, and prosecutors and courts must attempt toresolve these problems, however difficult that may be.in addition, it is by no means clear that enough research has beencarried out in this important area. social science research into the effectsof children viewing sexually explicit materials has not been carried outbecause of ethical considerations (although one must wonder if such reluctance doesnõt speak to the reality of the harm itself). the computerindustry has produced some of the largest personal fortunes in americanhistory. yet it has been curiously reluctant to commit its massive resources to leadingedge research and development efforts in this area.although, as the report emphasizes, responsibility for meeting thischallenge truly begins at home, we must exert ourselves as a society toprovide every possible support mechanism to parents concerned aboutthis threat to their childrenõs wellbeing. no concerned parent, howeverresponsible and determined, should be left to his or her own devices indealing with such a truly global challenge.it may be that some members of the committee itself complete theirassignment somewhat disappointed in our accomplishments. but, in life,the important tasks are never easy ones. if this task is deemed to beimportant for the future of our society and our children, our comprehensive study of the multitude of issues involved in protecting children frompornography on the internet may prove to be a building block for futureefforts that can provide workable answers to the difficult questions inherent in such a study.if this study has succeeded even in part in its undertaking, credit isdue to the remarkable and talented men and women who contributed somuch of their valuable time, thought, and effort to this unique and daunting task. they set themselves to this difficult task in the best traditions ofsearching inquiry which have always characterized this great nation.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xviiiprefacespecial thanks are due to dr. herbert lin, whose tireless efforts kept us ontrack and whose skills at managing a sometimes fractious group wereadmirable indeed.dick thornburgh, chaircommittee to study tools and strategies for protecting kids from pornography and their applicability to other inappropriate internet contentapril 2002youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xixthis report has been reviewed in draft form by individuals chosen fortheir diverse perspectives and technical expertise, in accordance with procedures approved by the national research councilõs report reviewcommittee. the purpose of this independent review is to provide candidand critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meetsinstitutional standards for objectivity, evidence, and responsiveness tothe study charge. the review comments and draft manuscript remainconfidential to protect the integrity of the deliberative process. we wishto thank the following individuals for their review of this report:danni ashe, danniõs hard drive,libby black, boulder valley school district,frederick p. brooks, university of north carolina,robert cornrevere, hogan and hartson llp,david finkelhor, university of new hampshire,elizabeth d. liddy, syracuse university,eleanor maccoby, stanford university,michael miller, pc magazine,anita m. pampusch, bush foundation,michael puma, the urban institute,william j. raduchel, aol time warner,sally g. reed, norfolk public library,carol lynn roddy, ohio public library information network,paul rothstein, fried, frank, harris, shriver, and jacobson,acknowledgment of reviewersyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xxacknowledgmentslynne shrum, university of georgia,jane m. spinak, columbia law school,bruce taylor, national law center for children and families,jody townsend, colorado pta,joseph turow, university of pennsylvania,willis h. ware, rand corporation,ellen wartella, university of texas at austin,gio wiederhold, stanford university, andnancy willard, university of oregon.although the reviewers listed above provided many constructive comments and suggestions, they were not asked to endorse the conclusions orrecommendations, nor did they see the final draft of the report before itsrelease. the review of this report was overseen by lyle jones, university ofnorth carolina, and eugene volokh, ucla law school. appointed by thenational research council, they were responsible for making certain thatan independent examination of this report was carried out in accordancewith institutional procedures and that all review comments were carefullyconsidered. responsibility for the final content of this report rests entirelywith the authoring committee and the institution.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xxicontentsexecutive summary1part i1introduction171.1the internet: source of promise, source of concern, 171.2a critical definitional issueñwhat is òpornographyó?, 201.3other types of inappropriate material and experiences, 221.4a broad spectrum of opinion and views, 251.5focus and structure of this report, 282technology312.1an orientation to cyberspace and the internet, 312.1.1characteristics of digital information, 312.1.2the nature of the internet medium and acomparison to other media types, 322.1.3internet access devices, 352.1.4connecting to the internet, 362.1.5identifying devices on the internet: the role ofaddressing, 382.1.6functionality of the internet, 392.1.7cost and economics of the internet, 472.1.8a global internet, 472.1.9the relative newness of the internet, 482.2technologies of information retrieval, 49youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xxiicontents2.3technologies related to access control and policyenforcement, 512.3.1filtering technologies, 512.3.2technologies for authentication and ageverification, 592.3.3encryption (and endtoend opacity), 652.3.4anonymizers, 662.3.5location verification, 662.4what the future may bring, 683the adult online entertainment industry713.1the structure and scale of the online adult entertainmentindustry, 723.2the generation of revenue , 743.3practices related to minors, 783.4what the future may hold, 793.4.1the structural evolution of the industry, 793.4.2increased regulation, 793.4.3future products and services, 813.5industry structure, product differentiation, and aggressivepromotion, 824legal and regulatory issues844.1the first amendment, 844.1.1first principles, 844.1.2the first amendment, pornography, and obscenity, 864.1.3the first amendment and protecting children fromexposure to sexually explicit material, 894.1.4the first amendment rights of minors, 924.1.5the first amendment and child pornography, 934.1.6the first amendment in public libraries, 944.1.7the first amendment in public schools, 954.1.8the first amendment and the commercialadvertising of sexually explicit material, 964.2relevant statutes and common law, 964.2.1federal obscenity statutes, 964.2.2child pornography statutes, 974.2.3the communications decency act, 994.2.4the child online protection act, 1014.2.5the childrenõs internet protection act, 1034.2.6the childrenõs online privacy protection act, 1044.2.7state statutes, 1074.2.8regulatory efforts, 107youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.contentsxxiii4.2.9international dimensions, 1124.3law enforcement, training, and education, 1125children, media, and exposure to sexuallyexplicit material1155.1children and how they use media, 1155.2sexuality in culture, 1205.3the role of media in providing information on sexualityto youth, 1235.4dimensions of exposure and access to the internet, 1275.4.1venues of access, 1275.4.2sources and channels of exposure, 1285.4.3extent of exposure, 1325.5internet exposure to sexually explicit material, solicitations,and harassment, 1365.5.1deliberate search for sexually explicit material, 1385.5.2inadvertent exposure to or intrusion of sexuallyexplicit material, 1385.5.3sexual solicitations and approaches, 1415.5.4harassment, 1426the research base on the impact of exposureto sexually explicit material: what theoryand empirical studies offer1436.1theoretical considerations, 1436.2empirical work, 1496.2.1violence, 1496.2.2sexually violent material, 1526.2.3exposure to nonviolent sexual material, 1536.2.4caveats and cautions, 1556.3factors affecting the impact on minors of exposure tosexually explicit material, 1576.3.1impact, 1576.3.2minors, 1576.3.3gender, 1586.3.4special needs, 1596.3.5exposure, 1596.3.6the type of sexually explicit material, 1607beyond the science: perspectives on impactand the public debate1617.1challenges to parents, 1617.2speculations and other perspectives on possible impact, 166youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xxivcontents7.3rhetorical concerns and issues of public debate, 1727.4judgments in the absence of a reliable research base, 1757.5concluding observations, 178part ii8approaches to protection from inappropriatematerial1838.1the identification of inappropriate material, 1838.1.1in principle, 1838.1.2in practice, 1868.2dimensions of òprotection,ó 1888.3the time line of protective actions, 1908.4differing institutional missions of schools and libraries, 1918.5the politics of protection and inappropriate materialñwho and when?, 1928.6techniques of protection, 1948.7approaches to protection, 1969legal and regulatory tools2019.1vigorous prosecutions of obscene material, 2019.2civil liability for presenting obscene material on theinternet, 2059.3options for dealing with material that is obscenefor minors, 2059.3.1age verification, 2069.3.2plain brown wrappers and age verification, 2089.3.3labeling of material that is obscene for minors, 2099.3.4prohibiting spam that is obscene for minors, 2099.3.5prohibiting the practice of mousetrapping to web sitescontaining material that is obscene for minors, 2129.4enforcement of recordkeeping requirements, 2139.5streamlining the process of handling violations, 2149.6selfregulatory approaches, 2159.7general observations, 21610social and educational strategies todevelop personal and communityresponsibility21810.1foundations of responsible choice, 21810.2definition of a social or educational strategy, 22110.3contextual issues for social and educational strategies, 22210.4parental involvement and supervision, 225youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.contentsxxv10.5peer assistance, 23310.6acceptable use policies, 23510.7afterthefact strategies, 24010.8education, 24210.8.1internet safety education, 24210.8.2information and media literacy, 24510.8.3collateral issues, 24910.9compelling and safe content, 25010.10public service announcements and media campaigns, 25410.11findings and observations about social and educationalstrategies, 25611a perspective on technologybased tools25811.1technologybased tools, 25811.2contextual issues for technologybased tools, 26111.3the questions to be asked of each tool, 26512technologybased tools for users26712.1filtering and contentlimited access, 26712.1.1what is filtering and contentlimited access?, 26712.1.2how well does filtering work?, 27512.1.3who decides what is inappropriate?, 28612.1.4how flexible and usable is the product?, 28912.1.5what are the costs of and the infrastructurerequired for filtering?, 29212.1.6what does the future hold for filtering?, 29812.1.7what are the implications of filtering use?, 30112.1.8findings on filters, 30312.2monitoring, 30412.2.1what is monitoring?, 30512.2.2how well does monitoring work?, 30712.2.3who decides what is inappropriate?, 30912.2.4how flexible and usable are products formonitoring?, 31012.2.5what are the costs and infrastructure required formonitoring?, 31112.2.6what does the future hold for monitoring?, 31412.2.7what are the implications of using monitoring?, 31512.2.8findings on monitoring, 31612.3tools for controlling or limiting òspam,ó 31712.3.1what are technologies for controlling spam?, 31812.3.2how well do spamcontrolling technologieswork?, 319youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xxvicontents12.3.3who decides what is spam?, 32012.3.4how flexible and usable are products for controllingspam?, 32012.3.5what are the costs and infrastructure required forusing spamcontrol products?, 32012.3.6what does the future hold for spamcontrollingsystems?, 32112.3.7what are the implications of using spamcontrollingsystems?, 32112.3.8findings on spamcontrolling technologies, 32112.4instant help, 32212.4.1what is instant help?, 32212.4.2how well might instant help work?, 32412.4.3who decides what is inappropriate?, 32412.4.4how flexible and usable is instant help?, 32412.4.5what are the costs and infrastructure required forinstant help?, 32512.4.6what does the future hold for instant help?, 32512.4.7what are the implications of using instanthelp?, 32612.4.8findings on instant help, 32613technologybased tools available tononend users32713.1a .xxx toplevel domain, 32713.1.1what is a .xxx toplevel domain?, 32713.1.2how well would a .xxx toplevel domainwork?, 33013.1.3who decides what material should be confined to.xxx web sites?, 33213.1.4how flexible and usable are schemes based on a .xxx toplevel domain?, 33213.1.5what are the costs and infrastructure requiredfor a .xxx toplevel domain?, 33213.1.6what does the future hold for a .xxx topleveldomain?, 33313.1.7what are the implications of using a .xxxtoplevel domain?, 33413.1.8findings on a .xxx toplevel domain, 33413.2a .kids toplevel domain, 33513.2.1what is a .kids toplevel domain?, 33513.2.2how well would a .kids toplevel domainwork?, 335youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.contentsxxvii13.2.3who decides what material should be allowed in .kids web sites?, 33713.2.4how flexible and usable are schemes based on a.kids toplevel domain?, 33713.2.5what are the costs and infrastructure requiredfor a .kids toplevel domain?, 33813.2.6what does the future hold for a .kids topleveldomain?, 33813.2.7what are the implications of using a .kids topleveldomain?, 33813.2.8findings on a .kids toplevel domain, 33913.3age verification technologies, 33913.3.1what are age verification technologies?, 34013.3.2how well do age verification technologieswork?, 34113.3.3who decides what is inappropriate?, 34313.3.4how flexible and usable are products forverifying age?, 34413.3.5what are the costs and infrastructure requiredfor age verification?, 34413.3.6what does the future hold for age verificationsystems?, 34513.3.7what are the implications of using age verificationsystems?, 34713.3.8findings on age verification technologies, 34813.4tools for protecting intellectual property, 34913.4.1what are tools for protecting intellectualproperty?, 34913.4.2how well do tools for protecting intellectualproperty work?, 34913.4.3who decides what is inappropriate?, 35113.4.4how flexible and usable are products forprotecting intellectual property?, 35213.4.5what are the costs and infrastructure required forprotecting intellectual property?, 35213.4.6what does the future hold for tools forprotecting intellectual property?, 35213.4.7what are the implications of tools forprotecting intellectual property?, 35313.4.8findings on tools for protecting intellectualproperty, 353youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.xxviiicontentspart iii14findings, conclusions, and future needs35714.1framing the issue, 35714.1.1social dimensions, 35714.1.2developmental dimensions, 35814.1.3legal dimensions, 35914.1.4technical dimensions, 36014.1.5economic dimensions, 36114.2on the impact on children of exposure to sexually explicitmaterial and experiences, 36214.3on approaches to protection, 36414.4tradeoffs and complexity, 36814.4.1social and educational tradeoffs, 37014.4.2technology tradeoffs, 37114.4.3public policy tradeoffs, 37314.5takeaway messages for different parties, 37414.5.1parents, 37414.5.2teachers and librarians, 37814.5.3industry, 38014.5.4makers of public policy, 38314.6research needs, 38614.7conclusion, 387appendixesainformationgathering sessions of thecommittee391bglossary and acronyms407cselected technology issues418dsite visit synthesis430ebiographies434index445youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.1the internet is both a source of promise for our children and a sourceof concern. the internet provides convenient access to a highly diverselibrary of educational resources, enables collaborative study, and offersopportunities for remote dialog with subjectmatter experts. it providesinformation about hobbies and sports, and it allows children to engagewith other people on a nearinfinite variety of topics. through onlinecorrespondence, their circles of friendship and diversity of experience canachieve a rich and international scope. [section 1.1]yet press reports have suggested to many that their children are vulnerable to harm on the internet. while only a small fraction of material onthe internet could reasonably be classified as inappropriate for children,that small fraction is highly visible and controversial.1 if the full educational potential of the internet for children is to be realized, such concernsmust be reasonably addressed. [section 1.1]at the request of the u.s. congress in 1998, the computer scienceand telecommunications board of the national research council assembled a committee with expertise in many fields. based on a widerange of information sources as well as the committeeõs own expertise,executive summary1for purposes of this report, òmaterialó refers to that which may be seen or read (e.g.,images, movies, or text on a web page), while òexperiencesó are interactive (e.g., talking toa stranger through instant messages or chat rooms). email sent or received that is essentially advertising is òmaterial,ó while a sequence of interactive emails corresponds toòexperiences.óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.2youth, pornography, and the internetthis report seeks to frame the problem in a legal, educational, technological, social, and societal context and to provide information useful tovarious decisionmaking communitiesñe.g., parents, the informationtechnology industry, school boards, librarians, and government at alllevelsñabout possible courses of action to help children be safer in theiruse of the internet.definitional considerations in protectingchildren from internet pornographythe term òpornographyó lacks a welldefined meaning. to be sure,broad agreement may be found that some materials are or are not òpornographic,ó but for other materials, individual judgments about what is or isnot òpornographyó will vary. in recognition of this essential point, thereport uses the term òinappropriate sexually explicit materialó to underscore the subjective nature of the term. [sections 1.2, 4.1]the term òchildó is also problematic. from birth to the age of legalemancipation covers a very wide developmental range. what is inappropriate for a 6yearold to see may not be inappropriate for a 16yearold tosee, and in particular, older high school students have information needsfor education that are very different from those of elementary schoolstudents. [section 5.1 and table 5.1]finally, òprotectionó is an ambiguous term. for example, does òprotectionó include preventing a child from obtaining inappropriate material(sexual or otherwise) even when he or she is deliberately seeking suchmaterial? or, does it mean shielding a child from inadvertent exposure?or, does it entail giving the child tools to cope effectively with exposureto inappropriate material if he or she should come across it? these scenarios pose conceptually different problems to solve. [section 8.2]all of these ambiguities complicate enormously the debate in communities about the nature of the problem and what might or should bedone about it.sexuality in mediathe fact that children can sometimes seeñand even sometimes seekoutñimages of naked people is not new. however, compared to othermedia, the internet has characteristics that make it harder for adults toexercise responsible supervision over childrenõs use of it. a particularlyworrisome aspect of the internet is that inappropriate sexually explicitmaterial can find its way onto childrenõs computer screens without beingactively sought. further, it is easy to find on todayõs internet not onlyimages of naked people, but also graphically depicted acts of heteroyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.3executive summarysexual and homosexual intercourse (including penetration), fellatio, cunnilingus, masturbation, bestiality, child pornography, sadomasochism,bondage, rape, incest, and so on. while some such material can be foundin sexually explicit videos and print media that are readily available inhotels, video rental stores, and newsstands, other sexually explicit material on the internet is arguably more extreme than material that is easilyavailable through noninternet media. [section 1.2]the internet also enables many strangers to establish contact withchildren. while many interactions between children and strangers can bebenign or even beneficial (e.g., a student corresponding with a universityscientist), strangers can also be child predators and sexual molesters. facetoface contact with such individuals may be traumatic and even lifethreatening for a child; for this reason, internetbased interaction (whichincludes chat rooms, instant messages, and email dialogs, and whichcould involve the transmission of sexually explicit material as one component) that can lead to facetoface contact poses a greater potential dangerto children than does the passive receipt of materialñeven highly inappropriate materialñper se. the anonymity and interactionatadistanceof using the internet prevent a child from using cues that arise from facetoface interaction to help judge anotherõs intent (e.g., gestures, tone ofvoice, age). [sections 1.3 and 5.5]the legal contextthe legal context for sexually explicit material is driven by the firstamendment to the constitution, and three categories of sexually explicitmaterial are subject to government regulation. obscenity is sexually explicit material that violates contemporary community standards in certain specified ways. (how the appropriate òcommunityó is defined is amatter of great uncertainty, especially in an internet context.) child pornography is material that depicts a child engaged in a sexual act or òlewdóexhibition of his or her genitals. obscenity and child pornography enjoyno first amendment protection. a third category of sexually explicitmaterial that is not obscene and not child pornography can be obscene forminors; such material may be regulated for minors but must be freelyavailable to adults. [section 4.1]new technology, different economicssearching the internet for information is generally enabled by òsearchenginesó that accept a few usertyped terms and return to the user links toweb pages that refer to those terms. a search engine can be used to findinformation on science, sports, history, and politics, as well as sexuallyyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.4youth, pornography, and the internetexplicit material. furthermore, because of ambiguities in language (e.g.,òbeaveró has both sexual and nonsexual connotations), a search willsometimes return links to material that is not related to what the user istrying to find. in some cases, that unrelated material will contain sexuallyexplicit content when it was not sought. [section 2.3 and box 2.3]a second common use of the internet is to communicate with others.however, the internet is designed in such a way that it transports bits ofinformation without regard for the meaning or content of those bits. thus,internet traffic can contain a letter to oneõs aunt, a chat about sports, adraft manuscript for a report, or sexually explicit images. furthermore,controlling traffic demands special effort at the sending and/or receivingpoints. [section 2.1 and box 2.2]the internet is also a highly anonymous medium. such anonymitycan be advantageous for a teenager who finds answers on the internet toquestions that he or she is too embarrassed to ask an adult. it can also bedisadvantageous, in that someone can conduct antisocial or criminal activities (e.g., child sexual solicitation) with less fear of identification and/or sanction than might be true in the physical world. [sections 2.1, 2.3]information technology drives the economics of information on theinternet. because information can be represented in digital form, it isvery inexpensive to send, receive, and store. thus, for a few hundreddollars to cover the cost of a digital camera and a web site, anyone canproduce sexually explicit content and publish it on the web for all to see.furthermore, because the internet is global, regulatory efforts in theunited states aimed at limiting the production and distribution of suchmaterial are difficult to apply to foreign web site operators. [section 2.1]sources of inappropriate sexually explicit material on the internet arecommercial and noncommercial. the commercial source is the onlineadult entertainment industry, which generates about a billion dollars ayear in revenue from paying adults. (for comparison, the adult entertainment industry as a whole generates several billion dollars a yearñperhaps as much as $10 billion.) according to the best information availableto the committee, u.s. business entities in the industry support around100,000 sites (globally, there are about 400,000 forpay adult sites). globally, sexually explicit web pages constitute a few percent of the 2+ billion publicly accessible web pages as of this writing. [section 3.1]for many online adult entertainment firms, profitability depends ondrawing a large volume of traffic in a search for paying customers, andmany seek revenue through the sale of advertising that typically makesno effort to differentiate between adults and children. further, the aggressive marketing campaigns that firms need to stand out in a highlysaturated marketñwhere margins are inherently low and traffic is therefore critical to economic survivalñinevitably reach both minors andyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.5executive summaryadults. the exposure of minors to such material is thus a side effect of theeffort to reach large numbers of paying customers. [section 3.2]to date, public debate has focused largely on commercial dimensionsof inappropriate sexually explicit material on the internet. but there aremany noncommercial sources of inappropriate sexually explicit materialon the internet, including material available through peertopeer file exchanges, unsolicited email, web cameras, and sexually explicit conversation in chat rooms. solutions that focus only on commercial sources willtherefore not address the entire problem. [section 5.4]the impact of sexually explicit materialon childrenperhaps the most vexing dimension of dealing with childrenõs exposure to sexually explicit material on the internet is the lack of a clearscientific consensus regarding the impact of such exposure. nonetheless,people have very strong beliefs on the topic. some people believe thatexposure to certain sexually explicit material is so dangerous to childrenthat even one exposure to it will have lasting harmful effects. othersbelieve that there is no evidence to support such a claim and that theimpact of exposure to such material must be viewed in the context of ahighly sexualized media environment. [chapter 6]it is likely that individuals on both sides of the issue could reachagreement on the undesirability of exposing children to depictions of themost extreme and most graphic examples of sexual behavior, in the sensethat most individual parents on each side would prefer to keep theirchildren away from such material. the committee concurs, in the sensethat it believes that there is some set of depictions of extreme sexualbehavior whose viewing by children would violate and offend the committeeõs collective moral and ethical sensibilities, though this sentimentwould not be based on scientific grounds. however, protagonists in thedebate would be likely to part company on whether material that is lessextreme in nature is inappropriate or harmful: such material mightinclude information on sexual health, the depiction of nontraditionalòscriptsó about how people can interact sexually, and descriptions of whatit means to be lesbian or homosexual in orientation. [sections 7.3, 7.4]extreme sexually explicit imagery to create sexual desire on the onehand, and responsible information on sexual health on the other, are arguably unrelated and, many would contend, easily distinguished. butmuch content is not so easily categorized. while some extreme sexuallyexplicit material meets legal tests for obscenity (and therefore does notenjoy first amendment protection), less extreme material may notñandmaterial described in the previous paragraph, lingerie advertisements,youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.6youth, pornography, and the internetand models in swimsuits generally do enjoy first amendment protection,at least for adults and often for children. [section 7.3]in short, sexually oriented content that falls outside the realm of extreme sexually explicit imagery is likely to be the source of greatest contention, and there are arguments about whether such content would besubject to regulatory efforts aimed at reducing the exposure of minors tomaterial that is or may be sexual in nature. [section 7.3]paths of exposurechildren may be exposed to inappropriate internet material or experiences through a variety of channels, including web pages, email, chatrooms, instant messages, usenet newsgroups, and peertopeer filesharing connections. furthermore, the exposure may be sought by the child(i.e., deliberate) or unsought by the child (i.e., inadvertent), and there aremany forms of each kind of exposure. an example of deliberate exposureoccurring is when a child searches for sexually explicit terms in a searchengine and clicks on the links returned. an example of inadvertent exposure occurring is when a child receives unsolicited email containing sexually explicit material or links to such material. [section 5.4]identifying inappropriate materialthree methods can be used to identify inappropriate material. whethermachine or human, the agent that makes the immediate decision about theappropriateness of content can do so based on its specific content, rely on atag or label associated with the material, or examine the source of thematerial (or a combination of these factors). [section 8.1]in practice, the volume of material on the internet is so large that it isimpractical for human beings to evaluate every discrete piece of information for inappropriateness. [box 2.6] moreover, the content of someexisting web pages changes very quickly, and new web pages appear ata rapid rate. thus, identifying inappropriate material must rely either onan automated, machineexecutable process for determining inappropriatecontent or on a presumption that everything that is not explicitly identified by a human being as appropriate is inappropriate. an approachbased on machineexecutable rules abstracted from human judgmentsinevitably misses nuances in those human judgments, which reduces theaccuracy of this approach compared to that of humans, while the presumptionbased approach necessarily identifies a large volume of appropriate material as inappropriate. [section 2.3]all mechanisms for determining if material is appropriate or inappropriate will make erroneous classifications from time to time. but note thatyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.7executive summarysuch misclassifications are fundamentally different from disagreementover what is inappropriate. misclassifications are mistakes due to factorssuch as inattention on the part of humans or poorly specified rules forautomated classification. they will inevitably occur, even when there isno disagreement over the criteria for inclusion in various categories. incontrast, disagreements over what is appropriate result from differencesin judgmentñperson a says, óthat material is inappropriateó and personb says of the same material, òthat material is not inappropriate.ó both ofthese issues exacerbate the problem of putting into place a systematic wayto protect children. [box 12.1]concepts of protectionwhether protection is based on law, technology, or education, it generally involves some combination of the following concepts: [section 8.6]¥restricting a minor to appropriate material through techniques thatgive a minor access only to material that is explicitly judged to be appropriate;¥blocking inappropriate material through techniques that prevent aminor from being exposed to inappropriate material;¥warning a minor of impending exposure to inappropriate material orsuggesting appropriate material, leaving him or her with an explicit choice toaccept or decline a viewing;¥deterring the access of minors to inappropriate material by detectingaccess to such material and imposing a subsequent penalty for such access;¥educating a minor about reasons not to access inappropriate material inorder to inculcate an internal sense of personal responsibility and to buildskills that make his or her internet searches less likely to turn up inappropriate material inadvertently;¥reducing the accessibility of inappropriate material so that inappropriate material is harder for minors to find;¥reducing the appeal of deliberate contact with inappropriate material bymaking access to the material (and only such material) more difficult,cumbersome, and inconvenient; and/or¥helping a minor to cope with the exposure to inappropriate material thatwill most likely occur at least occasionally with extended internet use.all of these concepts have costs and benefits. any party seeking todecide on an appropriate mix of approaches based on these conceptsmust consider the extent and nature of physical, emotional, developmental, social, ethical, or moral harm that it believes arises from exposure toinappropriate material or experiences. greater costs may be justifiable ifyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.8youth, pornography, and the internetthe presumed harm is large and highly likely, or if young children ratherthan youth in late adolescence are involved. [section 14.4]differing institutional missions must also be considered. a publicschool serves the primary purpose of providing academic instruction forindividuals that have not attained the age of majority. by contrast, apublic library serves the primary purpose of providing a broad range ofinformation to the entire community in which it is based, including children and adults, and the information needs of the communityñtaken as awholeñare generally much more diverse than those of children and youthin school. thus, it is not surprising that schools and libraries have different needs and might take different approaches in seeking to protect children and youth from inappropriate internet material and experiences.[section 8.4]approaches to protectionpublic policypublic policy to affect the supply of inappropriate sexually explicitmaterial can operate to make such material less available to children.for practical and technical reasons, it is most feasible to seek regulationof commercial sources of such materialñbecause these seek to drawattention to themselves (and noncommercial sources generally operatethrough private channels). public policy can provide incentives for theadult online industry to take actions that better deny childrenõs access totheir material and to some extent to reduce the number of providers ofsuch material. [chapter 9]public policy can go far beyond the creation of statutory punishment for violating some approved canon of behavior to include shapingthe internet environment in many ways. for example, public policy canbe used to reduce uncertainty in the regulatory environment; promotemedia literacy and internet safety education (including development ofmodel curricula, support of professional development for teachers oninternet safety and media literacy, and encouraging outreach to educateparents, teachers, librarians, and other adults about internet safetyeducation issues); support development of and access to highqualityinternet material that is educational and attractive to children in an ageappropriate manner; and support selfregulatory efforts by privateparties.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.9executive summarysocial and educational strategiessocial and educational strategies are intended to teach children howto make wise choices about how they behave on the internet and to takecontrol of their online experiences: where they go; what they see; whatthey do; who they talk to. such strategies must be ageappropriate if theyare to be effective. further, such an approach entails teaching childrento be critical, skeptical, and selfreflective of the material that they areseeing.an analogy is the relationship between swimming pools and children. swimming pools can be dangerous for children. to protect them,one can install locks, put up fences, and deploy pool alarms. all of thesemeasures are helpful, but by far the most important thing that one can dofor oneõs children is to teach them to swim. [section 10.3]perhaps the most important social and educational strategy is responsible adult involvement and supervision. [section 10.4] peer assistance can behelpful as well, as many youth learn as much in certain areas from peersor nearpeers (e.g., siblings) as they do from parents, teachers, and otheradult figures. [section 10.5] acceptable use policies in families, schools,libraries, and other organizations provide guidelines and expectationsabout how individuals will conduct themselves online, thus providing aframework within which children can become more responsible for making good choices about the paths they choose in cyberspace, thereby learning skills that are relevant and helpful in any venue of internet usage.[section 10.6]internet safety education is analogous to safety education in the physical world, and may include teaching children how sexual predators andhate group recruiters typically approach young people, how to recognizeimpending access to inappropriate sexually explicit material, and when itis risky to provide personal information online. information and medialiteracy provide children with skills in recognizing when information isneeded and how to locate, evaluate, and use it effectively, irrespective ofthe media in which it appears, and in critically evaluating the contentinherent in media messages. a child with these skills is less likely tostumble across inappropriate material and more likely to be better able toput it into context if and when he or she does. [section 10.8]the greater availability of compelling, safe, and educational internet content that is developmentally appropriate, educational, and enjoyable material on a broad range of appealing or helpful topics (including but notlimited to sex education) would help to make some children less inclinedto spend their time searching for inappropriate material or engaging ininappropriate or unsafe activities. greater availability entails both thedevelopment of new appropriate content, as well as portals and web sitesyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.10youth, pornography, and the internetdesigned to facilitate easy access to existing appropriate content. [section10.9]public service announcements and media campaigns could help to educateadults about the need for internet safety and about the nature and extentof dangers on the internet. such campaigns are best suited for relativelysimple messages (e.g., òbe aware of where your child is on the internetóand òask for parental controls when you subscribe to an internet serviceprovideró). [section 10.10]social and educational strategies focus on the nurturing of personalcharacter, the development of responsible choice, and the strengtheningof coping skills. because these strategies locate control in the hands of theyouth targeted, children have opportunities to exercise some measure ofchoiceñand as a result some children are likely to make mistakes as theylearn to internalize the object of these lessons. [section 10.11]these strategies are not inexpensive, and they require tending andimplementation. adults must be taught to teach children how to makegood choices on the internet. they must be willing to engage in sometimesdifficult conversations. they must face the tradeoffs inevitablewith pressing schedules of work and family. and these strategies do notprovide a quick fix. but in addition to teaching responsible behavior andcoping skills for when a child encounters inappropriate material and experiences on the internet, they are relevant to teaching children to thinkcritically about all kinds of media messages, including those associatedwith hate, racism, senseless violence, and so on; to conduct effectiveinternet searches for information and to navigate with confidence; and tomake ethical and responsible choices about internet behaviorñand aboutnoninternet behavior as well. [section 10.11]technologybased toolsa wide array of technologybased tools are available for dealing withinappropriate internet material and experiences. filtersñsystems or services that limit in some way the content to which users may be exposedñare the mostused technologybased tool. [section 12.1] all filters sufferfrom both false positives (overblocking) and false negatives (underblocking). however, filters can be highly effective in reducing the exposure ofminors to inappropriate content if the inability to access large amounts ofappropriate material is acceptable. teachers and librarians most commonly reported that filters served primarily to relieve political pressureon them and to insulate them from liability (suggesting that filter vendorsare more likely to err on the side of overblocking than on underblocking).in addition, filters reduced the nonproductive demands on teachers andlibrarians who would otherwise have to spend time watching what stuyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.11executive summarydents and library patrons were doing. note also that filters can be circumvented in many ways, the easiest way being to obtain unfilteredinternet access in another venue (e.g., at home).monitoring of a childõs internet use is another technologybasedoption. [section 12.2] many monitoring options are available (e.g.,remote viewing of what is on a childõs screen, logging of keystrokes,recording of web pages that he or she has visited)ñand each of theseoptions can be used surreptitiously or openly. surreptitious monitoring cannot deter deliberate access to inappropriate material or experiences, and raises many concerns about privacy (for example, in a family context, it raises the same questions as reading a childõs diary orsearching his or her room covertly). furthermore, while it probablydoes provide a more accurate window into what a child is doing onlinecompared to the lack of monitoring, it presents a conflict betweentaking action should inappropriate behavior be discovered and potentially revealing the fact of monitoring.the major advantage of monitoring over filtering is that it leaves thechild in control of his or her internet experiences, and thus provides opportunities for the child to learn how to make good decisions aboutinternet use. however, this outcome is likely only if the child is subsequently educated to understand the nature of the inappropriate use and isreinforced in the desirability of appropriate use. if, instead, the result ofdetecting inappropriate use is simply punishment, the result is likely tobe behavior motivated by fear of punishmentñwith the consequence thatwhen the monitoring is not present, inappropriate use may well resume.clandestine monitoring may also have an impact on the basic trust that isa foundation of a healthy parentchild relationship.age verification technologies (avts) seek to differentiate between adultsand children in an online environment. [section 13.3] a common avt isa request for a valid credit card number. credit cards have some meaningful effectiveness in separating children from adults, but their effectiveness will decline as creditcardlike payment mechanisms for childrenbecome more popular. other avts can provide higher assurance ofadult status, but often at the cost of greater inconvenience to at least somelegitimate users.a number of other technologybased tools are discussed in the mainreport.overall conclusionscontrary to statements often made in the political debate, the issue ofprotecting children from inappropriate sexually explicit material and experiences on the internet is very complex. individuals have strong andyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.12youth, pornography, and the internetpassionate views on the subject, and these views are often mutually incompatible. different societal institutions see the issue in very differentways and have different and conflicting priorities about the values to bepreserved. different communitiesñat the local, state, national, and international levelsñhave different perspectives. furthermore, the technicalnature of the internet has not evolved in such a way as to make controlover content easy to achieve. [section 14.1]there is no single or simple answer to controlling the access of minorsto inappropriate material on the web. to date, most of the efforts toprotect children from inappropriate sexually explicit material on theinternet have focused on technologybased tools such as filters and legalprohibitions or regulation. but the committee believes that neither technology nor policy can provide a completeñor even a nearly completeñsolution. while both technology and public policy have important rolesto play, social and educational strategies to develop in minors an ethic ofresponsible choice and the skills to effectuate these choices and to copewith exposure are foundational to protecting children from negative effects that may result from exposure to inappropriate material or experiences on the internet. [section 14.3]technology can pose barriers that are sufficient to keep those who arenot strongly motivated from finding their way to inappropriate materialor experiences. further, it can help to prevent inadvertent exposure tosuch materials. but, as most parents and teachers noted in their comments to the committee, those who really want to have access to inappropriate sexually explicit materials will find a way to get them. from thispoint, it follows that the real challenge is to reduce the number of childrenwho are strongly motivated to obtain inappropriate sexually explicit materials. this, of course, is the role of social and educational strategies.[section 14.4]as for public policy, the international dimension of the internet posessubstantial difficulties and makes a primary reliance on regulatory approaches unwise. absent a strong international consensus on appropriate measures, it is hard to imagine what could be done to persuade foreign sources to behave in a similar manner or to deny irresponsible foreignsources access to u.s. internet users. [section 14.4]this is not to say that technology and policy cannot be helpful. technologybased tools, such as filters, provide parents and other responsibleadults with additional choices as to how best to fulfill their responsibilities. law and regulation can help to shape the environment in whichthese strategies and tools are used by reducing at least to some extent theavailability of inappropriate sexually explicit material on the internet, forexample, by creating incentives and disincentives for responsible business behavior. moreover, developments in technology can help to informyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.13executive summaryand support policy choices, and public policy decisions necessarily affectboth technology and the nature and shape of parental guidance. in concert with appropriate social and educational strategies, both technologyand public policy can contribute to a solution if they are appropriatelyadapted to the many circumstances that will exist in different communities. in the end, however, values are closely tied to the definitions ofresponsible choice that parents or other responsible adults wish to impartto their children, and to judgments about the proper mix of education,technology, and policy to adopt. [section 14.3]though some might wish otherwise, no single approachñtechnical,legal, economic, or educationalñwill be sufficient. rather, an effectiveframework for protecting our children from inappropriate materials andexperiences on the internet will require a balanced composite of all ofthese elements, and real progress will require forward movement on allof these fronts. [section 14.3]youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.part iyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.16youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.17the internet is both a source of promise for our children and a sourceof concern. the promise is of internetbased access to the informationageñand the concern is over the possibility that harm might befall ourchildren as they use the internet. realizing the promise in all its richnessrequires that adults put these concerns into perspective and also takeresponsible steps to address them. the purpose of this report is to helpput the risks of internet use by children into perspective and to provide abalanced assessment of different approaches that can help parents andother responsible adults to deal constructively with the risks that childrenface on the internet, using as its primary illustrative example protectingkids from inappropriate sexually explicit material on the internet.1.1the internet: source of promise,source of concernmany policy makers, teachers, parents, and others concerned witheducation reform believe that the internet has the potential to enhanceand transform k12 education. for example, the report of the webbasededucation commission, released in march 2001, asserted that òthe internetis making it possible for more individuals than ever to access knowledgeand to learn in new and different waysó (box 1.1).1introductionnote: appendix b contains a list of acronyms and a glossary that the reader may wish toconsult.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.18youth, pornography, and the internetincreasingly, schoolage children have the ability to reach the internet,driven by the steadily increasing fraction of u.s. classrooms and schoolsconnected to the internet over the past 5 years and the growing presenceof networked information technologies in the home and elsewhere.1 bythe fall of 2000, 98 percent of public schools in the united states hadaccess to the internet, compared with 35 percent in 1994.2 in addition,1anne cattagni and elizabeth farris. 2001. internet access in u.s. public schools andclassrooms: 19942000. nces 2001071. u.s. department of education, office of educational research and improvement. u.s. government printing office, washington, d.c.2school connections to the internet have been supported by a variety of federal programs,of which the federal erate program and the technology programs operated by the department of education have been most important. for more information on the erate program,see <http://www.sl.universalservice.org/> and on the department of education programs,see <http://www.ed.gov/technology/edgrants.html>.box 1.1views of the webbased education commissionon the internet and k12 educationthe following excerpts are reproduced, respectively, from the foreword andfrom section 1 of the power of the internet for learning:for education, the internet is making it possible for more individuals than ever toaccess knowledge and to learn in new and different ways. at the dawn of the 21stcentury, the education landscape is changing. elementary and secondary schoolsare experiencing growing enrollments, coping with critical shortages of teachers,facing overcrowded and decaying buildings, and responding to demands for higher standards. . . . the internet is enabling us to address these educational challenges, bringing learning to students instead of bringing students to learning. it is allowing for the creation of learning communities that defy the constraints of time anddistance as it provides access to knowledge that was once difficult to obtain. . . .the internet is perhaps the most transformative technology in history, reshapingbusiness, media, entertainment, and society in astonishing ways. but for all its power, it is just now being tapped to transform education. . . . the internet is bringing uscloser than we ever thought possible to make learningñof all kinds, at all levels, anytime, any place, any paceña practical reality for every man, woman, and child. theworld wide web is a tool that empowers society to school the illiterate, bring jobtraining to the unskilled, open a universe of wondrous images and knowledge to allstudents, and enrich the understanding of the lifelong learner. . . . webbasededucation is just beginning, with something of far greater promise emerging in themiddle distance. yet technology, even in its current stage of development, can already allow us to realistically dream of achieving ageold goals in education: tocenter learning around the student instead of the classroom, to focus on the strengthsand needs of individual learners, [and] to make lifelong learning a reality. . . . theinternet is a tool that can help us empower every student and elevate each individualto new levels of intellectual capacity and skill.source: the power of the internet for learning: moving from promise to practice. 2001.report of the webbased education commission to the president and congress of the unitedstates. march. available online at <http://interact.hpcnet.org/webcommission/index.htm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.19introductiondialup connections were used by 74 percent of public schools with internet access in 1996, but in 2000, only 11 percent of public schools reliedon such connections, with the remainder using faster dedicatedlineinternet connections. in the classroom, only 3 percent of instructionalrooms were wired for internet access in 1994; by 2000, 77 percent of instructional rooms were connected to the internet. in public libraries,internet access is nearly ubiquitous, with over 95 percent of all libraryoutlets with an internet connection in 2000 and an average of 8.3 workstations per connection. over half of these outlets have highspeed connectivity.3 and around 17.7 million children had access to the internet fromtheir homes by late 1999.4such changes are hardly a surprise. though these adoption curvessubstantially trail the overall price reduction curves for computing capability (unit capacity halves in price every 18 months), data storage (unitcapacity halves in price every 12 months), and bandwidth (unit capacityhalves in price every 9 months), it is likely that internet access for homesand schools will be the norm in the future.for children, the internet generally eliminates many constraints oftime and space encountered in the physical world and, as such, fundamentally broadens childrenõs access to information and experiences. forexample, the internet provides convenient access to an almost unlimitedand highly diverse (if usually unverified) library of information resourcesthat can be used for educational purposes. it enables collaborative education and study, and it provides opportunities for remote engagementwith subject matter experts. it provides information about hobbies andsports. finally, it allows children to engage with other people on a nearinfinite variety of topics and interests. through online friendships andpen pals, their circles of acquaintance and diversity of experience can bevastly enlarged across state and national boundaries.at the same time, fueled by press reports and some personal experience, childrenõs easy access to the internet raises concerns in parents andcommunities about less productive or safe aspects that may result fromtheir internet use. one frequently stated concern relates to the easyinternet availability of òpornography,ó but public concerns are not confined to this area (as section 1.3 discusses further).success in dealing with such concerns is arguably a necessary (but notsufficient) condition for fully exploiting the social and educational poten3see <http://www.nclis.gov/statsurv/2000plo.pdf>.4see <http://cyberatlas.internet.com/bigpicture/demographics/article/0,,5901 390941,00.html> for a summary of the grunwald study. the full study (grunwald associates,2000, children, families, and the internet 2000, burlingame, calif.) is available online at <http://www.grunwald.com/survey/index.htm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.20youth, pornography, and the internettial of the internet for children. for example, a study from the annenbergpublic policy center found that parents in the united states are deeplyfearful about the internetõs influence on their children while at the sametime believing that the internet has important and positive educationalpotential.5 ridiculing such fears as if they were a sign either of technocultural unsophistication or of insufficient dedication to the first amendmentñas is often doneñis not helpful.given the nature of the internet and how children and other peopleuse it, it is likely that most children will be exposed to some inappropriatematerial or experiences by virtue of their mere access to the internet. thisis certainly true if no actions are taken to prevent such exposure, but thenational research councilõs committee to study tools and strategies forprotecting kids from pornography and their applicability to other inappropriate internet content concluded during its investigation that there isno set of actions that will eliminate this risk entirely.many policy makers at federal, state, and local levels (including members of the u.s. congress, state legislators, school boards, and local libraries) have sought solutions that focus primarily on the availability to children of pornography on the internet. with some exceptions, the centralelement of these solutions is a filter, based on technology that is intendedto allow objectionable content to be blocked. however, the overall problem has many facetsñtechnological, social, psychological, legal, emotional, moralñand so, too, does any particular proposed approach tosolution.1.2a critical definitional issue:what is òpornographyó?the term òpornographyó has no welldefined meaning. despite thefact that individuals use the term as though it does and behave as thoughthere is a universal understanding of what is and is not covered by theterm, judgments about the precise dividing line between the òpornographicó and the ònonpornographicó vary widely. (and, as with anypublic issue, a large fraction of the public will not particularly care aboutthe nuances of any given definition.) indeed, it was supreme court jus5joseph turow. 1999. òthe internet and the family: the view from parents, the viewfrom the press.ó annenberg public policy center, university of pennsylvania, philadelphia. this is not to say that concerns about the internet are limited to the potential negativeinfluence on children. for example, many adults, including parents, worry about a loss ofprivacy associated with internet use. moreover, attempts to differentiate children fromadultsñone aspect of protecting children from inappropriate material on the internetñmay have privacy implications as well.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.21introductiontice potter stewart who observed, òi canõt define it [obscenity], but i knowit when i see it.ó furthermore, the same image or text can have differentmeanings and interpretations depending on context. for example, ladychatterlyõs lover has been considered pornographic in some contexts andgood literature in others.recognizing these ambiguities, the committee chose to use the termòsexually explicit material,ó which is materialñtextual, visual, or auralñthat depicts sexual behavior or acts, or that exposes the reproductiveorgans of the human body. sexually explicit material may be used formany purposesñeducation, art, entertainment, science, personal sexualgratification or fantasy, and so on. from common usage, òpornographyómight be seen as material that is intended to create sexual arousal ordesire, and usually involving sexually explicit material.6for expository and analytical purposes (and to prevent passages frombeing misinterpreted or taken out of context), this report uses the termòinappropriate sexually explicit materialó in many places where it mighthave used òpornography.ó the use of the term òinappropriate sexuallyexplicit materialó manifestly raises the issue of òinappropriate by whosedefinition,ó a basic point that must be kept in mind in all discussionsrelating to this topic.public concern and controversy in this area arise from the fact that ontodayõs internet, it is easy to find graphically depicted acts of heterosexualand homosexual intercourse (including penetration), fellatio, cunnilingus, masturbation, bestiality, child pornography, sadomasochism, bondage, rape, incest, and so on. although some such material is comparableto sexually explicit videos and print media that are easily available inhotels, video rental stores, and newsstands, other sexually explicit material on the internet is more extreme than that which is easily availablethrough noninternet media. furthermore even the most graphic of theseimages can find their way onto childrenõs computer screens without being actively sought, which makes this medium different from most othermedia.because the committee found that many people are unaware of thekinds of sexually explicit material that can be found on the internet, it6of course, òintentó is itself ambiguous, because it may refer to intent on the part of thecreator of the material, or intent on the part of the viewer of the material. under this usageof the term, an individual may believe that clinical discussions of sexual behavior andadvertisements for contraceptives or lingerie are òpornographicó because some people respond to such material in a sexual manner, even if those materials were not produced withsuch a result in mind. a second issue (with this definition) arises in the likely event that ayoung child does not become sexually aroused after being exposed to such material.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.22youth, pornography, and the internetpondered how best to illustrate the range of material described above.7after deliberation, the committee decided that the best way to illustratesuch material would be to invite the reader of this report to use a generalpurpose internet search engine to search on terms such as òsex,ó òorgy,óòbondage,ó òcum,ó or òrapeó coupled with terms such as òpics,ó òavi,óand òjpg.ó if the search engineõs filter for adultsonly content is turnedoff, the search engine will return in the first several links a variety of websites containing the content listed above.8 this process will illustrate thecontent available, as well as the ease with which it is available when it isdeliberately sought out.1.3other types of inappropriate materialand experiencesyouth have been exposed to materials of concern through many different kinds of mediañprint (books, comic books, or magazines), television, movies, billboards, and telephones, as well as the internet. correspondingly, u.s. society has long been concerned about the types ofinformation to which youth are exposed. frequently, such concern focuses on information related to sexual matters, from the facts and biologyof human reproduction to graphic portrayals of unusual sexual activity.but in addition to inappropriate sexually explicit material, there are othertypes of material that various parties regard as inappropriate, some ofwhich several students and parents told the committee were more upsetting or objectionable than sexually explicit material. these include:¥hate speech and overt racism: material extolling the inherent ormoral superiority or inferiority of a particular race, ethnic group, or sexualorientation; racial epithets; or religious bigotry. (note that europeans7one alternative was to include actual screen shots of such material in the report. however, the inclusion of such material would inevitably become the primary focus of thisreport, rather than any of the committeeõs analytical work. a second alternative was toprovide specific web sites that are good examples of the material described. however,inclusion of such sites in a national academiesõ report would give them undue prominence, and the committee did not want to be in the position of increasing the exposure thatsuch sites receive.8the reader may also find it instructive to turn the filter òonó to see how one type offiltering works. in this case, the search results will be different, but some sexually explicitmaterial is likely to appear. as discussed in chapter 12, filters seek to block certain kinds ofmaterial from appearing (or, equivalently, do not return links to those kinds of material)but cannot perform this task perfectly. note that the results from filters embedded intosearch engines are not necessarily those that would be obtained from other types of filters.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.23introductionmay regard such material as being of more concern than sexually explicitmaterial, a point that underscores the cultural dimensions of concern.9)¥violent speech and imagery, including but not limited toñgraphic images of blood and gore (without medical purpose),resulting from the application of weapons to the human body. theseimages may be photorealistic or cartoonlike, and may also involve animals and/or avatars.ñdepictions of violence to the human, such as people being shot,stabbed, or beaten up.ñinformation on the use and construction of weapons, explosives,and other tools of violence.media violence has been a prominent social concern for many years,especially given that the presence of violent media content is largely unregulated. in the case of media violence, the debate centers on concernsthat exposure to such content is one factor leading to childhood aggression. however, the broadcast of obscene, indecent, and profane languageis regulated by law,10 and so sexual content has been more heavily regulated than violence on the public air waves.¥expressions of extreme nationalism or extreme political views: forexample, materials from violent conspiracy theorists, and materials extolling the inherent superiority or inferiority of certain nations or nationalgroups.¥materials recruiting new members into nontraditional religiousgroups or cults.¥information on drugs, alcohol, tobacco, gambling, and the meansto gain access to them.¥scientific concepts such as evolution and the òbig bangó theory forthe creation of the universe.of course, this short list does not begin to exhaust the type of materials that some individuals may regard as inappropriate for children. disentangling this relativism from the necessity of action cannot be madeeasy by the mere introduction of technical means, because technologycannot divine human intent or judgment (a point addressed further inchapter 2). further, different individuals even within a given community may have very different sets of concerns.9see <http://www.pewinternet.org/reports/toc.asp?report=36>. this point is furtherexplored in computer science and telecommunications board, national research council,2001, global networks and local values, national academy press, washington, d.c.10 18 u.s.c. 1464.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.24youth, pornography, and the internetas for inappropriate internet experiences, the committee concludedthat the potential harm from interacting oneonone with strangers on theinternet is a far greater threat to children than the potential harm of simply viewing inappropriate images on the internet.11 the likelihood thatsuch interactions will lead to actual meetings between children and strangers, with the obvious attendant dangers, although relatively small, shouldnot be overlooked because of the potentially very serious consequences ofsuch meetings.this theme recurred repeatedly in committee discussions with manyof the parents and children at site visits, and it served to place into perspective the concerns expressed about sexually explicit material. indeed,for these parents, the risk of predators who seek to entice children intosuch encounters is an especially serious danger for children comparedwith merely viewing inappropriate material, and the internet creates opportunities for molesters to meet potential victims in a setting where noneof the ordinary visual and location clues of the physical world apply.table 1.1 describes differences in the nature of the childõs interaction onthe internet between passive and interactive exposures to inappropriatematerial.some polling data reflect these concerns to a certain extent. for example, a survey by the pew internet and american life project12 indicated that while parents generally agree that for the most part the internetis a good thing or at least has a neutral impact on their own children, theyhave many concerns about the internet and they struggle to protect theirchildren from the worst elements of the online experience without keeping children from its benefits. they are concerned that their children willbe stalked or harassed online (parents of girls are more concerned thanparents of boys about these matters). while only a very small proportionof strangers who contact children via the internet are likely to be sexualpredators, they are understandably concerned about such interactionsgiven the possibly severe consequences. they are also concerned aboutwhat their children might see or read online (parents of younger childrenare more concerned about this than parents of older children). and manyworry that the internet may lead some young people to do dangerous orharmful things.11the committee does not intend to say that interactions with all strangers are dangerous.for example, the òstrangersó may be students at the same age level in another school, orparticipants in a moderated chat room, or the sender of a largegroup mailing list that doesnot support twoway interaction. in such cases, the interaction may be reasonably safe. butit is the potential danger raised by interacting oneonone with unknown adults that is thecommitteeõs primary concern.12see <http://www.pewinternet.org/reports/toc.asp?report=36>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.25introduction1.4a broad spectrum of opinion and viewsparents have a longrecognized responsibility to care for their children and to raise them in a manner consistent with their own values, andthey can feel that exposure to certain materials found on the internetreduces their ability to carry out their parental responsibilities. as arguedby one parent,13how i train my children and what moral values i impart to them doesnõtdo much good if theyõre simply walking by a computer in the referencearea while an adult male is accessing hardcore pornography, which hasbeen a very common occurrence at our library. what gives the libraryor anyone else that right, especially in a public institution, to take awaythe innocence of my child? we get frequent phone calls from distraughtparents . . . who are being responsible parents with their children in thelibrary and suddenly being exposed to the most vile material.while the definition of òhardcore pornographyó and the frequencyof adult males using library facilities to access such material are open todebate, sentiments such as those reflected above can be powerful motivators for political action. on the other side, another parent wrote thefollowing:14be it books, or the internet, or movies, or music, itõs our job as parents toteach children what we believe is acceptable and not acceptable, ourvalues, morals. . . . by the time theyõre old enough to read or cruise theinternet, theyõre old enough to know your basics of right or wrong. my13michelle yezerski, director, citizens for the protection of children. see <http://netwinds.com/library/yezerskimeeks.htm>.14deb mcneil, parent, benton, new york. see <http://www.csmonitor.com/durable/1999/06/01/p11s1.htm>.table 1.1 differences in the nature of the childõs interaction: passiveversus interactive exposurespassive interactioninteractive interactionsource of òthreatóthe material itselfthe predatorthe nature of possiblepsychological or emotionalphysical as well asdanger involvedharmpsychological or emotionalharmtime scale of exposureshort (minutes for a onelong (weeks or months)time exposure) to long(years for longterm mediaconsumption)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.26youth, pornography, and the internetadvice is to set perimeters in cyberspace [and] then trust their judgmentñwhich you instilled.in addition, the united states has seen in recent decades increasingcultural and social heterogeneity, and opinions on how to protect children from inappropriate sexually explicit material on the internet varywidely. such diversity was reflected in the testimony to the committeeas well.because the varying definitions of pornography, the nuances of public concern about pornography, and their implications for action defyconsensus, effective approaches that deal with pornography in ways thathonor democracy and a pluralistic society must allow for, indeed empower, varying community judgments (and in the case of the internet, apossible community with no geographic bounds on the one hand andindividual family judgments on the other), a point that is common todealing with any of the wide range of material that some people mightregard as inappropriate.15there is also considerable variability in views of the internet as compared to views of other media. in one group are those who believe thateven though the internet is a medium unlike any others, the ethical andmoral codes, cultural norms, and laws that govern behavior on the internet should be generally the same as those that govern behavior andinteractions in the physical world.16 for example, in the nonnetworkedworld, such techniques include movie ratings, special (restricted) sectionsof video and book stores, opaque wrappings over the covers of adultmagazines, reports to law enforcement officials of suspected child pornographers by photo processing lab personnel, special hours or channelsfor transmission of certain types of cable tv shows, and so on. parties inthis group suggest that the problems of minors and internet pornographyare no different than those in other media, and they see no reason fordifferent goals or types of regulation in the internet domain.in another group are those who believe that because the internet is amedium unlike any other, the ethical and moral codes, cultural norms,and laws that govern behavior on the internet should be different fromthose that govern behavior in other media.17 this second group is itself15differences in such judgments are also illustrated in computer science and telecommunications board, national research council, 2001, global networks and local values.16see, for example, jack l. goldsmith, 1998, òagainst cyberanarchy,ó university of chicago law review, fall.17see, for example, david r. johnson and david g. post, 1996, òlaw and bordersñtherise of law in cyberspace,ó stanford law review 48: 1367.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.27introductiondivided. some believe that the social and societal problems posed by theinternet differ qualitatively fromñand are worse thanñtheir physicalworld analogs, so that special regulation is warranted, including mandatory filters on school or library computers and prohibitions on certaincontent on the internet that may be freely available elsewhere. othersbelieve that although the problems with respect to the internet may notnecessarily be worse than in the physical world, special attention andregulation in the internet domain are warranted anyway, especially whereinternet access becomes an economic or educational necessity. in thiscase, the desire for regulation to cope with problems with respect to theinternet arises because the internet is a new medium that offers opportunities for solutions that did not emerge from societyõs solutions to theanalogous problems in the physical world.18still others argue that the internet is so different that regulations fromthe physical world should not apply at all. indeed, in the formulation ofthe project that is the subject of this report, a variety of cyberlibertariansand industry representatives argued that the project should be scoped asnarrowly as possible, and preferably should not be undertaken at all,because any attention to these issues would simply pointñinappropriately, from their perspectiveñto targets for government regulation.there are also differing and mutually incompatible approaches todefining what is objectionable. one approach is based on the notion thatindividual communitiesñincluding individual familiesñhave the right(and obligation) to define what is objectionable. a second approach, rarelystated but often implicit as the motivating force behind certain policypositions, is the idea that a particular definition of objectionableñnamelyone supported by specific advocates with a specific social agendañisappropriate for all communities.then, there is a question about the agendas of some people whoobject to òpornographyó and sexually explicit material. while it is likelythat agreement could be reached among people of varying perspectiveson the undesirability of minors being exposed to certain types of òhardcoreó material, there is profound disagreement about a great deal of othermaterial related to sexuality, including nudity, homosexuality, art, material about sexually transmitted diseases, bestiality as it relates to animalrights, abortion and contraception, sex education, and so on. becausemany of those who raise the most vocal objections to hardcore materialalso object to many other types of material related to sexuality, those with18for more discussion of this point, see computer science and telecommunicationsboard, national research council, 1994, rights and responsibilities of participants in networked communities, national academy press, washington, d.c. this report also addressessome of the perspectives raised in the preceding few paragraphs.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.28youth, pornography, and the internetdifferent views fear that the objections to hardcore material expressed bythe most vocal may be at least in part a cover for an agenda that willeventually restrict these other types of material as well.some parents are silent about the issue of òinternet pornographyó anddo not appear to be very active in attempting to keep their children awayfrom these materials or in protecting their children on the internet. silenceand inactivity may reflect a sense that the internet presence of adultoriented sexually explicit material is simply not much of an issue for them, ormay indicate a lack of knowledge about the quantity and type of materialavailable or about how to keep their children from it. or, it may signalresignation and an attitude that the availability of such material is yet another side effect of modernity, much as the smokestacks that were onceregarded as symbols of progress. it might also indicate a principled positionñthat it is insulting to suggest that they should have to solve the problem, that such material should not be available so profusely in the firstplace, or that regulation of such material is itself inappropriate. or, it mightindicate that parents trust that their children will not search for sexuallyexplicit materials online, or that they know what to do and are able tohandle themselves should they encounter such materials.a point on which most parties agreeñimplicitly if not explicitlyñisthat the internet is a medium in which to preserve policy ground that theyhave gained in other domains and to advance their policy goals further ifpossible. that is, the internet presents both new risks (for losing ground)and new opportunities (for gaining ground). thus, familiar policy battlesare refought, clothed in new rhetoric and updated with new facts, butreflecting the same differences in values and goals that characterized similar disagreements associated with more traditional media.1.5focus and structure of this reportthe committeeõs deliberations revealed a degree of complexity notapparent from the usual political debate. nevertheless, a number ofthemes recurred frequently. these themes are sketched in the sectionsabove, are addressed in greater detail in chapters to follow, and are summarized in box 1.2 to provide a road map for the reader.part i of this report examines the issue along several dimensions andin context. this chapter (chapter 1) provides an initial framing of theissue. chapter 2 describes the rapidly changing technological environment primarily as it relates to sexually explicit material. chapter 3 addresses the economic dimensions of the issue. chapter 4 focuses on therelevant legal and regulatory regimes. chapter 5 discusses children andtheir knowledge of, exposure to, and use of the internet. chapter 6 addresses the scientific research base regarding the impact on children ofyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.29introduction(continues)box 1.2themes pervasive throughout the reporteach of the following themes becomes apparent in the discussion and analysispresented in chapters 2 through 13. they are presented here to provide the readerwith signposts for material to come.on inappropriate material¥the term òpornographyó often serves as a proxy in the political debate for awide range of illdefined sexually explicit material and does not have a formal legaldefinition.on minors and culture¥minors span a wide developmental range that varies with age, and the age ofa minor has considerable influence on the impact that exposure to sexually explicitmaterial will have on that minor as well as on the approaches that are appropriate forprotection.¥community standards regarding sexual depictions both explicit and implied appearto have changed in the direction of greater tolerance at least over the last decade.¥many children know far more about information technology than their parents, teachers, and other adults responsible for their care and wellbeing, a situationthat reverses the traditional gap in knowledge between adults and children.on law¥the first amendment protects from government action speech on the internetas well as in other media.¥material that is obscene or that constitutes child pornography enjoys no firstamendment protection.¥definitions of material that is obscene (or that is òobscene with respect tominorsó) vary from community to community, and so whether material is legallyobscene or legally obscene with respect to minors cannot be ascertained from itscontent alone.¥sexually explicit materials that are òobscene with respect to minorsó may beregulated for minors, but not in a way that denies access to adults.¥because of the relative dearth of obscenity prosecutions in recent years, thereis considerable uncertainty about the nature of sexually explicit material that couldbe successfully prosecuted as legally obscene.¥the global reach of the internet greatly complicates the challenge of restricting content providers or internet service providers.on technology and economics¥the online adult entertainment industry exists because of demand from adultsbut is only one source of sexually explicit material.¥the anonymous interactions possible through the internet make it very difficult to differentiate between adults and minors.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.30youth, pornography, and the internetexposure to sexually explicit material. chapter 7 examines some of thenonscientific considerations involved in this issue.part ii assesses a variety of generic approaches to protecting childrenfrom exposure to inappropriate material on the internet. chapter 8 posesgeneral considerations regarding what òprotectionó means. chapter 9focuses on legal and regulatory approaches. chapter 10 addresses socialand educational strategies that seek to educate individuals to use theinternet safely, to make good decisions about content to be viewed, toreduce their exposure to inappropriate material, and to mitigate the consequences, if any, of viewing inappropriate material. chapter 11 providesa perspective on technologybased tools for protection, and chapters 12and 13 focus on a variety of specific tools for use by end users and otherparties.part iii consists of a single chapter (chapter 14) that addresses communities of action that must coordinate their use of different tools, strategies, and legal and regulatory approaches. further, it recaps key findingsand conclusions and shows relationships among several threads whosediscussion has started in chapter 1, and it outlines where a richer anddeeper knowledge base would help to address the issue of protectingchildren from inappropriate material on the internet.because this report is quite long, several chapters also include a number of tables with some summary observations that provide an orientation to the material of the report.box 1.2 (continued)¥the low cost of entry and decentralized management of the internet meanthat a large number of internet òpublishersó or content providers is inevitable. theresult, in general, is often a wide variety of sources of generically similar content (sothat there are many sources of similar sexually explicit material).on protection¥technology alone cannot protect internetusing youth at a level that eliminates the need for responsible adult supervision and education.¥multiple approaches for protection are generally appropriate, but social andeducational strategies are foundational in helping a child learn to make good decisions about internet usage and to cope effectively with inappropriate material shouldhe or she come across it.¥the specific combination of approaches that should be used to protect children depends on the values of the childõs parent or guardian and the community ofwhich these parties are members.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.31suppose that a student is assigned to do a report for school on animals that build things, and he selects beavers as his primary topic. connecting to the internet through a computer at home, he goes to an onlinesearch engine, where he tries to search the internet for information aboutòadult beavers.ó the search engine returns links to a large number ofweb pages. when he clicks on a certain link, he is surprised when hefinds a sexually oriented web site intended for adult use.this scenarioñor one similar to itñis one of the most common thatunderlies parental concerns about children using the internet. this chapter addresses the technological dimensions of this òreference scenarioóand some of the things that can be done to protect against it.2.1an orientation to cyberspace and the internet2.1.1characteristics of digital informationin the reference scenario, the student is seeking information (content)on beaversña kind of animal. all information on the internet is represented in bitsñelectronic strings of 1õs and 0õs that are later interpretedaccording to some algorithm to produce a representation that is meaningful to human beings. digital information has properties very differentfrom those of the information that a student might retrieve in a book. forpurposes of this report, the salient aspects of this digital representation ofinformation are the following:12technology1more discussion can be found in computer science and telecommunications board,national research council, 2000, the digital dilemma: intellectual property in the informationage, national academy press, washington, d.c.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.32youth, pornography, and the internet¥reproducible. unlike a physical book or photograph or analog audio recording, a digital information object can be copied infinitely manytimes, often without losing any fidelity or quality.¥easily shared. because information is easily copied, it is also easy todistribute at low cost. digital information can be shared more easily thanany type of analog information in the past. in the physical world, broadcasting information to groups has serious costs and hence requires a certain wherewithal and commitment. technologies such as email and websites allow broadcasting to many people at the touch of a single button.¥flexible. a variety of different types of information can be represented digitally: images, movies, text, sound. digital information caneven be used to control movement in the physical world through digitallycontrolled actuators.¥easily modified. digital representations of information can be easilymanipulated. it is trivial to modify an imageñsay, changing hair colorfrom blond to red, adding a few notes to a musical score, or deleting andadding text to a document. so, for example, a naked body can be affixedto a head of a child, words modified from their original intent and musicòborrowedó freely, and even virtual òpeopleó created, all without leavinga visible trace of these manipulations.¥difficult to intercept. because no physical object is necessarily associated with a digital information object, interdiction of digital informationis much more difficult than interdiction of a physical object carrying information. in other words, there is no book, no magazine, no photo thatcan be intercepted by physical means.2.1.2the nature of the internet medium anda comparison to other media typesin the reference scenario, the student relies on the internet. the preceding discussion about digital information is important, but the natureof the internet itself also makes it quite unlike other more traditionalmedia such as television, film, print, and the telephone. thus, it is usefulto describe certain key features of the internet medium and to compare itto some other, more traditional media.¥the internet supports manytomany connectivity. a single user canreceive information and content from a large number of different sources,and can also transmit his or her content to a large number of recipients(onetomany). or a single user can engage with others in a onetoonemode (onetoone). or multiple users can engage with many others (manytomany). broadcast media such as television and radio as well as print areonetomany mediañone broadcast station or publisher sends to manyrecipients. telephony is inherently onetoone, although party lines andyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.33technologyconference calling change this characterization of telephones to some extent.¥the internet supports a high degree of interactivity (box 2.1). thus,when the user is searching for content (and the search strategy is a goodone), the content that he or she receives can be more explicitly customizedto his or her own needs.2 in this regard, the internet is similar to a libraryin which the user can make an information request that results in theproduction of books and other media relevant to that request. by contrast, user choices with respect to television and film are largely limited tothe binary choice of òaccept or do not accept a channel,ó and all a user hasto do to receive content is to turn on the television. the telephone is aninherently interactive medium, but one without the manytomany connectivity of the internet.¥the internet is highly decentralized. indeed, the basic design philosophy underlying the internet has been to push management decisions to asdecentralized a level as possible. thus, if one imagines the internet as anumber of communicating users with infrastructure in the middle facilitating that communication, management authority rests mostly (but notexclusively) with the users rather than the infrastructureñwhich is simply a bunch of pipes that carry whatever traffic the users wish to send andreceive. (how long this decentralization will last is an open question.3)by contrast, television and the telephone operate under a highly centralized authority and facilities. furthermore, the international nature of theinternet makes it difficult for one governing board to gain the consensusnecessary to impose policy, although a variety of transnational organizations are seeking to address issues of internet governance globally.¥the internet is intrinsically a highly anonymous medium. that is, nothing about the way in which messages and information are passed throughthe internet requires identification of the party doing the sending.4 one2customization happens explicitly when a user undertakes a search for particular kindsof information, but it can happen in a less overt manner because customized content can bedelivered to a user based, for example, on his or her previous requests for information.3marjory s. blumenthal and david d. clark. 2001. òrethinking the design of the internet:the end to end arguments vs. the brave new world,ó in communications policy in transition: the internet and beyond, b. compaine and s. greenstein, eds. mit press, cambridge,mass.4it is true that access to the internet may require an individual to log into a computer oreven to an internet service provider. but for the most part, the identity of the userñoncecaptured for purposes of accessing the internetñis not a part of information that is automatically passed on to an applications provider (e.g., a web site owner). more importantly,many applications providersñfor entirely understandable business reasonsñchoose not torequire authentication. (strong authentication in general requires an infrastructure that iscapable of providing a trusted verification of identityñand in the absence of such an infrastructure, strong authentication is an expensive and inconvenient proposition for the user.this point is discussed at greater length in section 2.3.2.)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.34youth, pornography, and the internetbox 2.1interactivity of the internetthe internet provides bidirectional capability between communicating partiesthat can be equally rich in both directions. the internetõs interactivity can be used:¥to search for information. in this application, the user sends a little information (to specify what he or she is seeking), and can receive in return a lot of information from many sources (manytoone communication). typical applications includeusing search engines and broadcasting requests for particular kinds of information.¥to interact with other people on a peertopeer basis (onetoone communication). in this application, information exchanges tend to be more symmetric. typical applications include using email and instant messaging. for example, a youthmay encounter a friendly, or a dangerous, adult. a friendly adult might be an expertwho provides good answers to sexual questions or realtime coaching on how tohandle a bad online experience; a dangerous one might be one who seeks to lure thechild into an improper sexual encounter. or a child may gather with other childrento share sexually explicit material among themselves, or to discuss matters related tosexuality.¥to broadcast information to wide audiences (onetomany communication).in this case, the amount of information that the user sends out is relatively large, andthe volume of what is returned is typically small. typical applications include broadcasting unsolicited email (spam) to large, undifferentiated audiences with an invitation to view an adultoriented site or setting up a web site on which the user postssexually explicit pictures taken on last weekõs vacation.the interactivity of the internet and its capability of supporting realtime interaction is a major differentiator from other media such as film, books, video, and radiothat offer passively consumed content. users of these latter media view or listen tothe content offered, and how the media experience unfolds is determined by onlyone user choiceñwhether or not to continue viewing or listening. the internet, aswell as much of modern computerbased information technology such as cdrombased video games and nintendo, expands the range of user choices. thus, while itis possible to use the internet to consume media content passively (and many do useit in such a manner), it also allows the user to interact with other parties, and thenumber of modes of interaction today is large and still expanding.such interaction implies a dynamically constructed media experience, and thusone can òtalkó with people in a chat room, send instant messages on a onetoonebasis with anyone, post and read messages on computer bulletin boards on anyimaginable topic, exchange email on a onetoone or a onetomany basis withanyone, assume fictional òrolesó in games and other experiences, and join communities with others that revolve around a shared interest or passion. the informationcontent exchanged in these interactions can be text, images, video clips, sound recordings, or realtime video or sound.the interactivity of the internet is very attractive and useful for many purposes.for example, in an educational context, the internet allows students to collaborateover large geographical distances and to engage with subjectmatter experts in awide variety of fields. but interactivity on the internet also enables òchildren talkingto strangers,ó an action that raises concerns for many parents. without the normalcues available in the physical world (e.g., gestures, voice tone, facial expression,age), children are especially vulnerable to being preyed on by people who are notwhat they claim to be.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.35technologyimportant consequence of the internetõs anonymity is that it is quite difficult to differentiate between adult and minor users of the internet, a pointwhose significance is addressed in greater detail in chapter 4. a secondconsequence is that technological approaches that seek to differentiatebetween adults and minors (discussed in chapter 13) generally entailsome loss of privacy for adults who are legitimate customers of certainsexually explicit materials to which minors do not have legitimate access.¥the capital costs of becoming an internet publisher are relatively low,and thus anyone can establish a global web presence at the cost of a fewhundred dollars (as long as it conforms to the terms of service of the webhost). further, for the cost of a subscription to an internet service provider (isp), one can interact with others through instant messages andemail without having to establish a web presence at all. the costs ofreaching a large, geographically dispersed audience may be about thesame as those required to reach a small, geographically limited audience,and in any event do not rise proportionately with the size of the audience.¥because nearly anyone can put information onto the internet, the appropriateness, utility, and even veracity of information on the internet are generallyuncertified and hence unverified. with important exceptions (generally associated with institutions that have reputations to maintain), the internetis a òbuyer bewareó information marketplace, and the unwary user can bemisinformed, tricked, and seduced or led astray when he or she encounters information publishers that are not reputable.¥the internet is a highly convenient medium, and is becoming more so.given the vast information resources that it offers coupled with searchcapabilities for finding many things quickly, it is no wonder that for manypeople the internet is the information resource of first resort.2.1.3internet access devicesin the reference scenario, the student uses a computer to access theinternet. while today a personal computer is the most common way toconnect to the internet, devices for accessing the internet are proliferating.entire businesses have begun to spring up in order to ready content anddelivery of information for a host of other devices. these devices include:¥handheld organizers like palm and handspringñtypically thesedevices contain builtin wireless modems and use services like omnisky;¥cell phones with built in web access;¥webtvtm and internet access devices that are used on tv sets andcustomized to msn and aol and whose deployment began in 2001;¥blackberry rim and wireless paging devices;youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.36youth, pornography, and the internet¥standalone internet machines like the compaq ipaq and mailstations;¥kiosks designed for surfing the internet and typically used in public spaces;¥game machines like sega, nintendo, microsoftõs xbox. todayõsgaming technology (e.g., sonyõs playstation) increasingly uses the internet to provide users with multiplayer communities in which a user cancompete against and/or cooperate with other likeminded individuals.software is generally available on cdroms, and the widespread availability of cdrom writers makes the possibility of nonvendorproducedgames and activities a realistic one. gameplaying applications are alsoincreasingly available for use on various web sites, sometimes for free.note that such games often contain violent material.in addition, many commercial establishments frequented by children,including coffee shops, department stores, and fast food restaurants, willhave customerusable internet access points. broadband internet accessñneeded for efficient transmission of images and moviesñwill also growin the future, though with some uncertainty about how fast it will bedeployed. specialized web access devices will cost much less than todayõscomputers (a few hundred dollars each rather than several hundred orthousand dollars). wireless internet access is also expected to grow inpopularity, though the feasibility of transmitting highquality imagesthrough wireless links remains an open question.these devices and business trends suggest increasingly ubiquitousaccess to the internet. note also an important social pointñwireless access and access òanywhereó enable users, including children, to escapemany forms of local supervision (e.g., someone looking over his or hershoulder), and individuals will not be as dependent on school, libraries,and work to provide internet access. consequently, approaches to internet protection and safety for children that depend on actions whose effectis limited to a single venue will be increasingly ineffective.2.1.4connecting to the internetin the reference scenario, the student connects to the internet. ingeneral, access to cyberspace is provided by one or more internet serviceproviders (isps). for children, internet connections are available via:¥personal internet service. in this case, a party subscribes to a consumeroriented isp, and gains access to the internet through as manyplaces as the provider can provide access ports. such services are generally responsible for home access. there are many variations in the offerings from isps and many different fee structures as well. note that anyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.37technologyindividual child may be using a family account, a personal account associated with a family account, or a friendõs personal internet service.¥school and/or library internet service. a student (or faculty memberor staff person) or a library patron uses school or library facilities to obtaininternet access. in general, schools and libraries obtain internet servicefor their students and patrons through businessoriented isps, and awhole host of classroom isps have been brought to the market.¥public terminals. an individual pays òby the minuteó for internetaccess at a public terminal, which may be located in a coffee shop or anairport, or through a wireless service.in addition to internet connections, some isps offer other servicesdesigned to enhance the userõs experience. proprietary services (including parental controls to help manage the online experience of children)and content are offered by a number of online service providers. theseservices and content are available only to those who subscribe to thoseonline service providers. in other cases, services are available to somenonsubscribers (for example, the instant message (im) services of someisps can provide im service to those who do not subscribe to those isps).moreover, various online service providers developñand seek to developñreputations about the kinds of content that they may offer. forexample, a service provider may bill itself as being òfamilyfriendlyó andthus provide access only to web sites that it regards as appropriate. thedenial of access to all web sites not on the providerõs òfamilyfriendlyólist is a proprietary service that the online provider offers that is unavailable to others who do not subscribe to it.isps offer dialup or broadband access to the internet. the majority ofathome access is today achieved through dialup connectionsña userõscomputer dials an isp phone number and connects to the isp through anordinary modem. however, broadband access, generally through dsl(digital subscriber lines) from phone companies or cable modems fromcable tv companies, is growing because of the higherbandwidth connections offered. higher bandwidth is relevant because some kinds of material contain many more bits than others. text, for example, typicallycontains many fewer bits than do images, and images contain many fewerbits than movies have. thus, viewing of graphicsintensive materialonline through a lowbandwidth connection is often very tedious andtries the patience of all but the most dedicated users.isps also require their subscribers to abide by certain terms of service,violation of which is grounds for termination of the service contract witha subscriber. an individual subscriber to an isp is bound directly by theterms of service of that isp. an individual who obtains internet servicethrough an intermediary is bound by the terms of service imposed by theyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.38youth, pornography, and the internetintermediary, which may (or may not) be stricter than those that bind theisp and the intermediary. note also that isps vary across a wide range inthe extent to which they enforce their terms of service. a typical provision in the terms of service of many isps might forbid a user from postingsexually explicit material under most conditions.isps make decisions about content that they will carry. in particular,many isps do not allow access to every usenet newsgroup (e.g., they maynot carry newsgroups that carry a large volume of child pornography).5for subscribers to these isps, the newsgroups that are not carried can bedifficult to find and are for many practical purposes nonexistent.6finally, isps are funded by subscription and/or by advertising. subscription entails periodic payment by the user to the isp for access privileges. advertising entails payments by advertisers to the isp for theprivilege of displaying ads, and thus the user must be willing to acceptthe presence of ads in return for access privileges.2.1.5identifying devices on the internet: the role of addressingevery computer or other device connected to the internet is identifiedby a series of numbers called an ip address.7 the domain name system isa naming system that translates these computerreadable ip addressesinto humanreadable forms, namely domain names. thus, a domain nameis a name that identifies one or more ip addresses. a canonical domainname has the form òexample.com.óevery domain name has a suffix corresponding to a toplevel domain(tld), in this example .com. until october 1, 2001, the most common toplevel domains allowed for internet use have been .net, .org, .com, .edu,5usenet is a worldwide distributed discussion system consisting of a set of newsgroupswith names that are classified hierarchically by subject. òarticlesó or òmessagesó areòpostedó to these newsgroups by people on computers with the appropriate softwareñthese articles are then broadcast to other interconnected computer systems via a wide variety of networks. some newsgroups are òmoderatedó; in these newsgroups, the articles arefirst sent to a moderator for approval before appearing in the newsgroup. for more information, see chip salzenberg, òwhat is usenet?,ó available online at <http://www.faqs.org/faqs/usenet/whatis/part1/>.6there are web sites through which one can read usenet newsgroups even if the isp hasdecided not to carry certain newsgroups, thus circumventing the ispõs selection policy.7the ip address of a device provides a unique address to which and from which messages can be routed. a typical ip address has the form a.b.c.d, where a, b, c, and d arenumbers from zero to 255. the mapping between domain name and ip address is managedby devices known as domain name servers. more information is given in a computerscience and telecommunications board report on domain name systems that is currently inpreparation. note also that ip addresses may be mapped dynamically to devices, so today,a userõs computer would have one ip address and tomorrow it might have a different one.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.39technology.gov, and .mil. in addition, a number of twoletter country suffixes havebeen recognized. as this report goes to press, a number of other topleveldomains have been approved: .biz, .info, .pro, .coop, .aero, .museum, and.name. (how many other tlds will eventually be available is an openquestion, and the issue of the number and type of tlds is highly chargedpolitically and economically.) as a rule of thumb, the noncountry suffixes indicate something about the nature of the party with which the siteis affiliated. for example, example.museum is likely operated by a museum; example.gov is operated by a government agency.the domain name is a key element of routing traffic across the internet.for example, a typical email address is of the form òjohn.doe@ example.com.óthe address of a typical web site has the form òwww.example.com.ó the website address is generally part (or all) of a uniform resource locator (url) thatidentifies a particular web page that can be found on a web site. thus,www.example.com/page1 might refer to a page on the example.com web site.2.1.6functionality of the internetin the reference scenario, the student used a search engine tosearch the world wide web for information about beavers. searchengines are only one aspect of the functionality that the internet offers, and as the internet matures, new functions based on new applications and technologies are constantly being introduced. some ofthe more important applications of the internet are described belowand are summarized in table 2.1.¥the world wide web (www) refers to the set of all the informationresources that can be accessed via the hypertext transfer protocol (http).loosely speaking, it is the set of all web pages that can be addressed by arequest of the form òhttp: url.ó8 today, the publicly accessible worldwide web consists of over 2 billion web pages,9 though there is a greatdeal of uncertainty in any estimate of web size. web pages are associatedwith particular hosts (though not every host has a web page), and manyweb pages themselves include links to other web pages. the web isbased on a clientserver modelña user (client) specifically requests a webpage from a host (server).¥search engines help to organize, classify and return informationbased on a query, and those who surf the web typically rely on various8most browsers handle addresses without a preceding òhttp:ó as though it was present.also, some web pages are accessible only through the òhttps:ó protocol.9for example, as of november 2001 the google search engine had indexed 1.6 billion webpages. as of april 2002, it had indexed 2.1 billion web pages.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.40youth, pornography, and the internettable 2.1 selected internet applications and their implications forexposing children to inappropriate sexually explicit material andpotentially dangerous experienceschannelkey pointsweb pagesidentified by and accessed through knowledge of the uniform resourcelocator (for example, http://www.randomsexsite.com,http://www.justfinekidssite.com)can display still images, text, and moviesgenerally the channel used today by the adult online industrycan be found by typing the url into a browser or clicking on a link (linkscan be embedded in instant messages, email, and so on; included in otherweb pages; or found through a search engine)emailrequires knowledge of a userõs email addresscan contain (or carry) text, images, links to web pages; can be used toinitiate twoway dialog as well as to deliver information and filessenderõs email address can be faked (or be misleading)is the route for unsolicited commercial email (spam)chatgenerally textbased, and conducted in a òchat roomó; text can contain linksto web pagescan be public (accessible to anyone) or private (by invitation only)content of chat and online identities of participants are visible to everyoneparticipating in the chat roomchat rooms are an online equivalent of cb radioused to initiate, establish, and maintain online relationshipsinstantoneonone dialog, and privatemessagestextbased, but can contain links; images and voice can sometimes betransmitted as wellinitiation of instant message requires knowledge of user nameòbuddy listsó allow user to know who is online at the same time as the userusenetpopulated by some 30,000 newsgroups of specialized topics; newsgroupsfunction essentially as online bulletin boards on which users can postanything they wish, often anonymouslymany newsgroups contain sexually explicit material, and some are orientedprimarily toward such material; sexually explicit content on usenetnewsgroups is often more extreme than those on adultoriented web sitescost of content distribution is borne by internet service provider that carriesnewsgroups with content rather than by publisher or receiversexually explicit usenet newsgroups serve as conduits for advertising ofadultoriented web sites and as a medium in which sexually explicitcontent can be exchanged among usersinternet service providers make choices about what usenet newsgroups tocarry; some carry the full line, and others carry only a subset (e.g., allexcept those devoted to child pornography)peertopeerconnection between two users that is made directly withoutconnections mediation through a central serverpurpose of peertopeer connection is typically for filesharing (of any kindof content, including sexually explicit content)not generally anonymous (because connections are peertopeer, each usermust have an internet address with which to interact)cost of distribution is borne by the internet service provider rather than theend usersyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.41technologytypes of search engines to find the information they are seeking. box 2.2describes how search engines work. search engines rely on technologiesof information retrieval, as discussed in section 2.2. given the enormousvolume of information on the web, users in general do not know where tofind the information they seek. to cope with this situation, search engines have been developed to help users find the addresses of information residing on the web. while no data have been collected on this point,it is probably fair to say that search engines enable the finding of mostinformation that people access on the internet.box 2.2how search engines worksearch engines help users find information on the internet stored in web pages.typically, a user will type some words (the òsearch queryó) into a search engine, andthe search engine will return a number of òlinksó on its results page. to reach any ofthese results, the user clicks on the link, which transfers the user away from thesearch engine and into the uniform resource locator (url) corresponding to thatlink.a search engine works by matching the userõs query against an index of webpages (documents) on the internet that it has stored in a database. an index isnecessary because with over 2 billion pages on the internet, a realtime search of allof them when someone makes an information request would be prohibitively expensive and timeconsuming. an index allows a search to be completed in a muchsmaller amount of time (seconds rather than days or weeks), though at the cost ofsome incompleteness and inaccuracy (because pages may have changed or beenadded since the index was created).no search engine indexes (or even could index) all of the pages on the web, andeach search engine indexes a different set of pages. for this reason, and because ofthe dynamic nature of the web, all search engines are inherently òincomplete,ó andthe contents of their indexes (and thus search results) differ from one another.a search engine builds its index of web pages by sending out a òspideró toretrieve the pages from web sites. spiders retrieve only static pages, not pages thatare hiding as databases or are dynamically generated. most spiders also obey therobot.txt file on a web site; if the file says, òdo not index this site,ó they do not indexthat site. they can store millions of words and hundreds of thousands of sites.a paper published in nature in 1999 estimated the types of material indexed,excluding commercial sites. òscientific and educationaló sites were the largest population. health sites, personal sites, and the sites for societies (scholarly or other) areall larger than the percentage estimated for pornography; i.e., a few percent of webpages contained material that could reasonably be characterized as adultoriented,sexually explicit material.1for a more detailed description of how search engines index web pages, interpret queries, and search their databases, see appendix c.1steve lawrence and lee giles. 1999. òaccessibility of information on the web,ó nature400: 107109.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.42youth, pornography, and the internet¥email refers to messages that are sent electronically from one userto another (or to many others) and read at a time of the recipientõs choosing. email can carry attachments that can be other information objects,such as images, movies, audio recordings, and so on. email can also beused as a direct marketing tool (òspamó) analogous to thirdclass postalmail (also known as junk mail). the use of email requires knowledge ofa recipientõs email address.¥file sharing refers to a process in which devices controlled by endusers (i.e., òpeersó) interact directly with each other to transfer files between them, rather than interacting through a central server. in some filesharing networks, a central server holds a publicly accessible index to thefiles available from end users (but not the files themselves). end usersthen transfer the files between themselves.10 other peertopeer filesharing networks eliminate even the centralized server index function. usersof these systems are connected to a network of other parties (rather thanto a centralized index), and a query from one user goes to an immediatecircle of possible respondents. if not satisfied, the query then goes fromthose respondents to other respondents. furthermore, such queries arehighly anonymous, though file transfers between end users are not. although peertopeer interaction is most often performed in a usertousermode, there is no reason that in principle a single user could not establishpeertopeer connections to a large number of other users and thus function in a òserverlikeó mode for those users.¥usenet newsgroups are a broadcast medium in which anyone anywhere with a computer can be a transmitter. typically groups formaround shared social interests. thus, the usenet becomes the place fordiscussion among selfselecting groups interested in specific topics. thevolume carried by usenet newsgroups is substantial (over 50 gigabytesper day on more than 10,000 newsgroups).11 anyone can òpostó a message on any usenet newsgroup (perhaps anonymouslyñsee section 2.3),governed only by his or her own judgment in ascertaining the relevanceof the message to the nominal topic of that newsgroup. newsgroups arenamed as described in box 2.3.10this mode of file sharing first gained widespread publicity with the napster network,an online service that facilitated the sharing of digital music files among users. the filesthemselvesñthe information content of interest to end usersñalways remained on clientsystems and never passed through a centralized server (such as one that would host a webpage). instead, the server gave end users the ability to search for particular files of interestand to initiate a peertopeer transfer between the users willing to share (and receive) fileswithout the payment of a fee, even when the files constituted legally protected intellectualproperty. napster is important for this discussion because there is no particular reason thatthe files in question must be digital music filesñand indeed, extensions of the napsterprotocol can handle other types of files.11personal communication, dan geer, president of usenet.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.43technologybox 2.3characteristics of usenet newsgroupsnamingnaming of newsgroups is hierarchical and of arbitrary depth. naming of usenetnewsgroups mirrors the spirit of how computer and other network end points arenamed within the internet as a whole, which usenet predates. hence¥[comp.org.usenix] is the computer professional organization usenix,¥[comp.os.linux.announce] is announcements concerning a computer operating system named linux,¥[rec.travel.africa] is about recreational travel to africa,¥[alt.sex] is about sex in general, whereas¥[alt.sex.wanted.escorts] is an obvious specialization,¥[net.config] is about configuring networks,¥[alt.drugs.mushrooms] is about mushrooms as sources of drugs,¥[misc.health.diabetes] is advice on diabetes and health, and¥[ne.politics] is wars of words around new england politics.by technocratic convention, some parts of the hierarchy are static and new groupscan only arise by consensus voting (groups improperly created do not get carried).conversely, other parts of the hierarchy (notably òaltó) are wide open to the creation ofnew groups and subgroups, all under the banner of anticensorship. not surprisingly,the altnewsgroups contain large amounts of sexually explicit content of all varieties.moderationsome groups are òmoderated,ó which means that postings are routed to moderators, people who either approve and forward or deny and delete prospective postings.this is enormously thankless work, and firstrate moderation often requires load sharing among several people working as one. because unmoderated groups are availableto all, the òspamó problem that bedevils email is vastly worse in usenet. ironically,the parts of usenet devoted to communications about sexual matters are so overwhelmed with advertisement that they have been effectively censored inasmuch as nouseful discussion can take place within them due to the volume of junk.sexually explicit contentusenet newsgroups in the òaltó hierarchy come and go. on one day in 2001, anexamination of usenet on one server of one isp showed:¥287 usenet discussion groups in the alt.sex.* hierarchy, most of which were(in principle) text groups and which contained an aggregate of 30,541 postings in arecent 3day interval (which overcounts the number of original posts because manyare repeatedly crossposted to multiple groups);¥469 postings in one sample group, alt.sex.anal, appearing in the 3day interval,of which 102 appeared by their own headline description to be involving children;¥27 usenet groups in the pictureoriented alt.binaries.erotica.* hierarchy, containing an aggregate of 6,469 postings in the 3day interval (again without regard toduplicate crosspostings); and¥198 usenet groups in the pictureoriented alt.binaries.pictures.* hierarchy, ofwhich 57 (of the 198) appeared to be sex related and which contained an aggregate of46,417 postings in the 3day interval (again without regard to duplicate crosspostings).similar results for availability, volume, quality, repetition, and ease of accessapply to other channels in like manner.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.44youth, pornography, and the internet¥internet relay chat (irc) and chat rooms. these are popular realtimeinteractive services on the internet that function as the equivalent of cbradio, where one person talks on a channel and anyone listening on thatchannel can hear and respond. irc and chat rooms allow users to exchange textonly messages in real time with other people all over theworld. irc òchannelsó and chat rooms can be public (so that they can befound by others wishing to join the conversation) or private (so that theyare invisible to the general public and special knowledge of the channelõsor chat roomõs name is needed to join). irc and chat rooms require auser to take active (initiating) steps to join an ongoing conversation. inaddition, some chat rooms or channels on the internet are monitored byemployees or volunteers for language and content and behaviors, butmost are not. (these monitors sometimes have the ability to force particular users out of a conversation.)there are many variants of chat rooms. chat rooms can be based oninterestsñmovies, sports, hobbiesñor can be just a place to meet people.some of the latest technologies are found in the online gaming community where people assume digital visual representations called avatars.avatars can then interact with each other in cyberspace. the chat thenhas a visual animated component. muds and moos are complex onlinegames relying mainly on text interactions while relatively new games likemicrosoftõs age of empires and electronic artsõ the sims online utilizevisual representations to create fantastic communities for role playing.¥instant messaging services allow a twoway, realtime, private dialogbetween two users these services include such wellknown entities asaolõs instant messenger and yahooõs messenger. a user initiating amessage sends an invitation to talk to another (specific) user who is onlineat the same time. unlike irc, no channelseeking initiating step is required on the part of the recipient to become part of such a conversation.12instant messaging also allows someone to carry on multiple private conversations simultaneously. instant messaging is very popular today forboth professional and personal use, because unlike in chat rooms, onetends to talk to people whom one already knows. note also that ims are12buddy lists are an important element of im services. a buddy list contains the onlinenames of òbuddiesó of a given user and indicates when one or more come online. when theuser knows that òsue123ó is online, she can send òsue123ó an instant message and start aconversation. thus, buddy lists facilitate online realtime communication among peoplewho know each otherõs online names. most im services also offer a blocking option thatenables a user who receives an im from someone to block it. this option is used when auser receives an im from someone with whom the user does not want to communicate (e.g.,a stranger, or a friend with whom one is on the òoutsó).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.45technologyoften used in conjunction with chat rooms or other online activitiesñauser in a chat room can send an im to someone else in the chat room(because he or she sees the other partyõs screen name or òhandleó), thusestablishing a private communication. once limited to textonly interactions, im services are increasingly sophisticated. for example, some imscan support direct voice interactions and exchanges of music or imagefiles. other im services allow a user to block selected other parties fromcontacting him or her, thus increasing the difficulty of harassment.¥videoconferencing applications are growing. web cameras andstreaming media depend on the increasing availability of broadbandinternet connections to allow the highquality realtime transmission ofaudio and video content. todayõs internet videoconferencing suffersfrom many of the same problems as internet telephony, most notablypoor quality (low resolution as well as òjitteró in the moving images). apopular consumer videoconferencing application is cuseeme, a veryinexpensive videoconferencing tool originally developed at cornell university for educational applications and now used to support a widevariety of video applications. chat rooms are often forums in whichweb cameras are used to send pictures in real time.¥streaming media, video, and audio are allowing people to watch movies like broadcasts over the web as well. a movie that is now availablethrough payperview cable tv may readily become available throughthe internet (a phenomenon known as digital convergence), perhaps augmented by the availability of an online chat room for discussion of thatcontent with oneõs friends and/or an electronic commerce site where onecan purchase products or services illustrated in the movie.¥internet telephony allows twoway realtime voice communicationto be established without records of such communications appearing onfamily telephone bills. a variety of standards now in place facilitate theinteroperability of internet telephony products, which would otherwisebe hampered by proprietary specifications and protocols. however,because the internet was not designed to support realtime operations,the quality of such connections remains an issue, though progress isbeing made in this area. internet telephony products enable internetusers to establish realtime voice contact without the need for a telephone, and even today, voice connections (of somewhat low fidelity)can be established through certain types of instant message and in somechat rooms.in addition to these functions, there are a variety of internet applications for facilitating web activity (box 2.4). the use of these applicationsis often free, and they are important because they reduce the costs anddifficulty of establishing a (noncommercial) web presence and of generyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.46youth, pornography, and the internetating communities of shared interestñin sports, in science, and in tradingof sexually explicit materials.finally, a variety of peripheral devices are also relevant to a discussion of internet functionality. the availability of devices to convert soundinto digital form, to digitize existing images, and to record still and videoimagery enables individuals to generate digital content inexpensively andin private. digital cameras, web cameras, and camcorders are droppingin price and the pictures they take increasing in quality, and virtuallyanyone can publish videos to the web or can participate in or set upvideoconferences at very low cost.13 thus, while one might have hadbox 2.4internet applications for facilitating web activitya number of companies provide free email accounts that are accessible fromanywhere on the world wide web. because they are free, many savvy consumershave set these accounts up to do their more general email (for instance to get information from companies), while they reserve their private email address for a muchcloser circle of friends and colleagues.a second service available from service providers is free storage. a company willprovide some limited amount of storage online (25 megabytes is a common number), and the user can make that storage space accessible to anyone that he or shechooses. online storage can be used to host a web site or as a private online òdropófor any kind of digitized electronic content. a variant on free storage services is freeweb page hostingña user receives a limited amount of disk space to construct apublicly accessible web page, with content restricted only by the terms of service towhich the user agrees in return for the free service.1a third service is that of the òonline community.ó services that promote onlinecommunities help to bring likeminded individuals into electronic contact and interaction with each other. the internet service providers promoting these communitiesprovide directories, search engines, chat rooms, and an organization to help facilitate these electronic affinity groups.1note that free services often have characteristics that may make them less desirable thanforpay services. for example, a business owner who is concerned about high reliability andavailability of resources is likely to want a service that provides frequent file backup, a featurethat is unlikely to be available from a free storage provider.13a 2001 video advertisement from sony europe for its vaio line of notebook computers(which can have a webcam built into them) depicts a man working at home on his vaionotebook computer (with the webcam). an adult female whom he obviously knows entersthe room, greets him, strips to her underwear in another room, and starts behaving withhim in a very sexually aggressive manner. the advertisement closes with several businessmen on the other end of a video conference looking at their screen in surprise seeing thewoman on top of the man. the advertisement is sexually suggestive but depicts no overtsexual activity or nudity.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.47technologydifficulty in the past in taking a picture of a couple having sex (because ofthe difficulty in having the film developed), today a digital camera enables one to do the same in complete privacy.2.1.7cost and economics of the interneton the internet, the cost of handling information is rapidly decreasing. from a message senderõs point of view, electronic messages cost nextto nothing to create, exactly nothing to duplicate, and virtually nothing tosend, andñgiven the anonymity of the internetñinexpensive bandwidthimposes none of the costs normally associated with responsibility, prudence, or probity, leading to problems such as unsolicited commercial email (also known as spam). bandwidth is inexpensive enough that mostisps and services recognize that it is cheaper to òsend everythingó throughits pipes than to determine if a message or information is inappropriate,unwanted, or unrequested by the receiver.furthermore, because digital information can be so freely reproduced,it is essentially impossible to rely on mechanical difficulty or expense ofreproduction to curtail the availability of anything to anyone. once released onto the internet, content is next to impossible to banñwhether thatcontent involves a political manifesto, sensitive classified information, company trade secrets, oneõs medical records, or child pornography.14finally, the internet contains an enormous volume of material thatchanges rapidly. the sheer mass of this material means that it is economically prohibitive to review every publicly accessible item for its inappropriateness or lack thereof.the economics described above suggest that if it costs virtually nothing to provide content to everyone, then an entirely free market will seekto make all possible content available to everyone. the implications ofsuch economics are further discussed in chapter 3.2.1.8a global internetthe internet transcends the physical boundaries of local communitiesand national borders alike, thus expanding the universe from which con14this is not to say that all content on the internet remains accessible, but in practiceattempts to ban certain information content result in efforts by those interested in suchinformation to copy and distribute it. thus, while the personal medical records of john doemay not be of particular interest, and if posted today may disappear without a trace tomorrow, the reason is that no one except john doe is likely to be interested in such records.however, if the personal medical records of the president of the united states were postedon the internet, it would be virtually impossible for the most determined efforts of thewhite house to erase them and to eliminate all access to them.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.48youth, pornography, and the internettent of various kinds can be drawn. of particular relevance is that manyother nations have different views about visual depictions of sexualityand the human body. for example, images of frontal nudity are found inmainstream print media in many parts of europe, and publication orbroadcast of such images raises little concern or outcry there. thus, material not seen as òpornographicó by those providing it (e.g., content providers in europe) may be perceived as such by those viewing it in adifferent cultural context (e.g., by some viewers in the united states).a further consequence of the internetõs international nature is thatonly with great difficulty (and many would argue that it is impossible)can laws passed in one jurisdiction affect the behavior of parties in otherjurisdictions that are not generally subject to such laws.15 thus, to theextent that sexually explicit material of any kindñor any other type ofmaterial, for that matterñis available from overseas sources, laws thatseek to restrict u.s. content providers from making such material available to u.s. citizens will fail to restrict it in practice.162.1.9the relative newness of the internetamidst all of the attention given to the internet and dotcom phenomena, it is helpful to recall that the internet has been a part of thenational consciousness for less than a decade (since the mid1990s). tenyears is an enormously long time compared to the time scale of technology change, but it is quite short on the time scale of social, economic, andlegal change. given that the array of preinternet social, economic, andlegal and regulatory practices to balance competing societal interests developed over a time scale of many decades (and in some cases, centuries),it is not surprising that the internet has offered something of a vacuuminto which many parties seeking quick advantage have moved.for example, the practice of adultoriented web sites using addressesthat are based on common words or that are similar to those of nonadultbusinesses draws many people to sites that they had not intended to visit.branding histories have not been established that allow users to differentiate between reliable and unreliable information. certain practices thatare acceptable in the real worldñsuch as direct marketingñmay cross15of course, such a claim is valid only to the extent that content providers and isps arenumerous and dispersed internationally. if the number of isps is small enough (as couldhappen through attrition or mergers and acquisitions in one jurisdiction), they becomelikely targets for regulation, as regulatory efforts can be concentrated rather than dispersed.16on the other hand, sources that appear to be foreign may in fact be under the jurisdiction of u.s. law. for example, the mere fact that a domain name has a country suffix suchas .ru or .jp does not necessarily mean that its owner is located in russia or japan. indeed,in this hypothetical example, such parties may well reside in california or iowa.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.49technologyover into the unacceptable in cyberspace because they are increasinglyvoluminous and often seen as more intrusive as well.perhaps the most important consequence of the relative newness ofthe internet is the generation gap in knowledge between parent and child.it may be that as todayõs children become parents themselves, their familiarity with rapid rates of technological change will reduce the knowledgegap between them and their children, and mitigate to some extent theconsequences of the gap that remains.2.2technologies of information retrievalas suggested in the reference scenario in which a student seeks information on adult beavers, information retrieval is an important part ofwhat people do on the internet. by virtue of its vast scope, the internet isa route for obtaining a range and variety of material to which one wouldmost likely not otherwise have easy accessñsuch materials include history, science, entertainment, games, medical information, and religiousinformation, as well as materials that adults deem inappropriate for children. if children are treated as adults on the internet, children may comeacross such materials.searching for information on the internet is different from searching forinformation in, for example, a library in the physical world. typically, anindividual might search for information using an internet search engine. acommon initial search strategyñused by many inexperienced individualsñis to type one or two keywords and then to examine the sites that arereturned. for a word such as òsex,ó a search engine might return information on sex education sites, a set of biology notes on sex, and adultorientedweb sites. by contrast, a user of a physical library might rely on the contentlabeling in various classification systems, such as those of the library ofcongress and the dewey decimal systems. on the internet, this absence ofreliable content labeling confounds specificity in searching. further, thescale of a òweb catalogó (i.e., the volume of information accessible throughpopular search engines) is much larger than that of most library catalogs ofholdings, and web search engines often do not provide adequate categorization of web pages contained in their databases. finally, the most important distinction between the physical library and the internet is the fact thatall physical libraries exercise some editorial discretion in acquiring materials, whereas the internet is a venue in which the publications of any partyare available and retrievable without editorial restriction.information retrieval systems support people in finding informationin large databases of information objects (whether in the form of text,images, video, or other media) that is relevant to their problems or situations. internet search engines, where the database is the web, are a typiyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.50youth, pornography, and the internetcal example of such systems, as are libraries, where the database is thecollection. to accomplish their goals, information retrieval systems must:¥represent the content of the information objects (what the objectsare about), through a process called content representation or content analysis;¥represent the personõs information òneed,ó through a processcalled problem or user representation;¥match the representations of information objects and informationproblem, to retrieve those objects that are most likely to be useful to thesearcher (search techniques); and¥provide an interface between the user and the other components ofthe system to support the userõs interaction with those components andwith the information objects.filtering systems, discussed at greater length in sections 2.3.1 and12.1, work like information retrieval systems in reverse; that is, they areconcerned not with retrieving desirable information, but rather with making sure that undesirable information is not retrieved. however, theiressential operations remain the same: they must represent the content ofthe information objects; they must represent relevant characteristics of theuser; they must match object representations with user representations toeliminate undesirable objects; and they must provide a means for users tospecify or otherwise indicate what is not desired.the essential problem with information retrieval (and filtering) is thatall of these processes are inherently uncertain. with respect to contentanalysis, what an information object is about can be many things formany people. the problem is intrinsically difficult, even for humans: oneperson may think a picture shows a starry sky; another may interpret it asa symptom of mental illhealth; and a third is interested only in the brushtechnique. similarly, one user may find a particular page of text obscene;to a second it is merely embarrassing; and to the third, it contains important healthcare information. also, even representing what text is about isfraught with uncertainty. most words mean many things (polysemy);most concepts can be expressed in many ways (synonymy).images are a particularly difficult recognition challenge for computers. computers seek to recognize an image by analyzing the relationshipof the pixels in it (color tone, contrast, and so on). while it is oftenpossible to tell whether a picture has nearly naked people in it, images ofthe california desert and apple pies are also sometimes identified as pictures with naked people by todayõs image recognition software.17 and17d.a. forsyth and m.m. fleck. 1999. òautomatic detection of human nudes,ó international journal of computer vision 32(1): 6377.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.51technologyimage recognition technology is for the most part incapable of distinguishing minors from adults (and hence cannot identify child pornography with any reliability). at the same time, using words that may befound alongside images provides additional information that can helpidentify sexually explicit images properly.with respect to representing the user (or what the user desires ordesires not to see) the problems are similarly difficult. users are in generalunable to specify precisely that which they do not know but may besearching for, nor are they (or a computer algorithm, or another person)able to specify precisely the characteristics of that which they should notsee. the matching process is thus itself inevitably uncertain, since therepresentations on which it depends cannot be complete and certain.because information retrieval and information filtering are probabilistic, any search engine will find material that is irrelevant to the userõsneeds and fail to find material that is relevant. similarly, any filter willinevitably allow the passing of some undesirable material, and will filterout some desirable material. any attempt to avoid errors of the first typewill lead to an increase in errors of the second type, and vice versa.these points are discussed in greater detail in section 2.3.1 and inappendix c.2.3technologies related to access control andpolicy enforcementas more peopleñand childrenñconnect to the internet, problemssuch as exposure to inappropriate material and experiences assume ahigher profile. one logical conclusion might be that if technology helpedto create these problems, technology can help to solve them. while thecommittee does not believe that technology is yet the foundation of goodsolutions to these problems (and may never be), technologies nevertheless do have useful roles to play. below is a brief discussion of technologies that may be relevant.2.3.1filtering technologiesfiltering technologies allow internet material or activities that aredeemed inappropriate to be blocked, so that the individual using thatfiltered computer cannot gain access to that material or participate inthose activities. typically, material is determined to be inappropriate onthe basis of its source, its content, or the labels that have been associatedwith it. determination of inappropriate content can be accomplished bycomputerbased methods, by a combination of computerbased methodsand human judgment, or by human judgment alone. this section adyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.52youth, pornography, and the internetdresses automatic and human plus automatic methods, since the size ofthe internet effectively prevents use of human judgment alone (box 2.5).(in the case of methods based on a combination of human plus automatictechniques, a human rater examines web sites that a preliminary machineperformed analysis has identified for human examination, andmakes a judgment call about whether the site is inappropriate, and if so,determines the objectionable category into which the page falls.)filtering technologies can be applied in several ways. one is by theestablishment of socalled òblack lists,ó which are lists of sources thathave been deemed to be inappropriate, and that the user is preventedfrom accessing. another is by the establishment of òwhite lists,ó whichare lists of sources that have been deemed appropriate, and thus are theonly sources that the user is allowed to access. these two methods require a priori identification of the bad (good) sites, which are then incorporated into the filtering software, which stands between the userõs internet access tool and the internet itself. bad sites for black lists can beidentified through any of the technologies described below. also, in apriori determinations of inappropriate content, the categorization judgment is usually made days, weeks, or even months in advance of theuserõs request for the web siteña point that is significant in light of thefact that the content of web sites typically changes over time.a third means of applying filtering technologies occurs in real time,that is, at the time that the user is actually interacting on the internet andwhen the information in question is flowing directly to the user. in thiscase, there may be no a priori blocking of specific sites or sources; rather,the content or other characteristics of retrieved items are analyzed prior todisplay, and on this basis it is determined whether they should be displayed to the user. this realtime method can also be used in reverse; thatis, it can be used to analyze the userõs request, and on this basis decidewhether the request should be allowed, or disallowed. although conducted in real time, this method nevertheless requires a priori specification of indicators of content which determine that that source has inappropriate content. finally, only realtime content monitoring is useful formonitoring and selective blocking of outgoing information, such as blocking certain text from appearing in email (e.g., a phone number).note that if a requested web site is determined to be inappropriate,there are several options for how much material from that site should beblocked. for example, all material on that site might be blocked (everything on www.example.com). or only a certain directory might be blocked(www.example.com/directory1 might be blocked, while www.example.com/directory2 might not be blocked). or a particular page within a directory might be blocked (e.g., www.example.com/directory1/picture1.jpg).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.53technologybox 2.5human scrutiny of every site to be blocked?the web is so large that it is impossible for a human being to have scrutinizedevery possible web page that a viewer might access. however, filter vendors oftenclaim that some human being has examined every one of the sites blocked by theirfilter and identified it as inappropriate.on the face of it, such a claim is not necessarily inconsistent with the first statement about the size of the web. but the sheer size of the web means that thescreening process involved must involve a mix of automated and human process. inparticular, the only method that makes sense for largescale screening is for someautomated process to nominate sites for blocking, and for an individual to evaluatethe nominated sites.can the claim of human examination for every site be substantiated? one assumption on which the claim rests is that blocked sites are revisited on the time scaleon which the content of a site is likely to change. if the revisit rate is inadequate tokeep up with such changes, a site that may have been properly blocked when it wasfirst added to the list may remain blocked even if the siteõs new content would not bedeemed inappropriate (overblocking).a more serious issue is that human evaluation of a site is a laborintensive process. the critical variable is how long it takes for a human being to evaluate a webpage. finkelstein and tien1 estimate 1 minute per page as a reasonable overallestimate for sustained work. this estimate is quite plausible if the page contains asignificant amount of textual material that must be read (as would be the case forhate speech, for example), but is likely high by a factor of 5 or 10 for pages thatcontain images of the kind typically found on adult web sites. assuming about 200workdays per year, an individual doing page evaluation alone might be able toevaluate somewhere between 0.1 million and 1 million pages per year.these figures suggest that an effort of 10 personyears is needed to create a comprehensive list of a million sites to be blocked (including both text and images)ñwhile an effort on the order of a personyear is required if the primary target is sexualimages of the sort found on adult web sites.reliable software to identify possibly inappropriate sites could reduce the effortrequired considerably. that is, the softwareñset to minimize underblockingñwould propose candidate sites for human evaluation, and the resulting higher levelof overblocking would propose sites for which human decision making is essential.moreover, technology could be used to filter out duplicates, reducing further theoverall number of sites that would require human decision making.see also the discussion in finkelstein and tien, òblacklisting bytesó21seth finkelstein and lee tien, 2000, òblacklisting bytes,ó white paper submitted to thecommittee on tools and strategies for protecting kids from pornography and their applicabilityto other inappropriate internet content. available online at <http://www.itasnrc.org> and at<http://www.eff.org/censorship/censorware/20010306effnrcpaper1.html>.2finkelstein and tien, 2000, òblacklisting bytes.óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.54youth, pornography, and the internetfiltering by internet domain names and addressesfiltering by internet domain names and addresses is typically accomplished by examination of the name of the web site that is requested by theuser or returned to the user, in the case of realtime filtering. the name ofa web site (or page on a web site) is specified by a uniform resource locator(url). a given url, for example, http://www.example.com/directory1/picture1.jpg, is usually checked against this list in a number of ways.in the case of a priori filtering, the url is checked against a preexisting list of inappropriate names generated by the filter vendor. all parts ofthe url are compared to a list of words or terms that have been previously found to be associated with sites containing inappropriate material,or that are believed are likely to be associated with inappropriate material. for example, www.hotmama.com is likely to refer to an adult website.18 the .xxx domain (discussed in section 13.1) is based on this notion.this method can be used to permit access, as well as to prevent access.for instance, a site in the .gov domain would in general be consideredhighly unlikely to contain inappropriate material, as would a site with thename of a museum. in the case of realtime filtering, access would bedenied (allowed) based on the comparison; in the case of a priori filtering,the url would probably be forwarded to a human evaluator, who woulddetermine whether it should be placed on the black list.a related method is to examine the links that are made from a site andto a site. because many adult web sites are linked to each other, a referralto a known adult site a that is present on web site b provides reason toassume that b is also an adult site.a second method is to check the ip address of the web siteñin this(madeup) case, 203.12.34.12. if this address is on a list of inappropriate ipaddresses, access is blocked. this approach is helpful when a web sitehas only an ip address and no domain name associated with it.a complication in this analysis of page names is that different hostscan share the same ip address through a process known as ipbased virtual hosting, which is a way of assigning multiple domain names to thesame ip address. ipbased virtual hosting is made possible by the fact thatthe http protocol passes the url containing the requested domain nameto the site at the given ip address, and the software at that ip addressmaps the domain name to the appropriate portion of the server. thus, anentry in the domain name server need not point to a unique address, anda given ip address does not specify a web site unambiguously. thus,www.porncompany.com and www.safeforkids.com might share the18as of october 26, 2001, this web site presented a blank page. but it may not be blank inthe future.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.55technologysame ip address (e.g., 204.1.23.3), even though each of these names, whenentered into a browser, would reach the correct sites. a list that designated 204.1.23.3 as containing inappropriate material would block bothdomain names.filtering by textual analysisfiltering by textual analysis makes use of information retrieval representation technologies discussed in section 2.2 and appendix c. thebasic concept is to examine all of the text that is on the site or page that isbeing considered (or in the search request), and to determine whetherthat text is indicative of inappropriate content.the most nałve method of doing this is to compare the individualwords of the text or request to a list of words that are strongly associatedwith inappropriate content. for example, the site might be deemed inappropriate if any of a number of keywords is found (e.g., òorgy,ó òcum,óòbomb,ó ògun,ó òmarijuana,ó and so on). when such words are found,access is blocked, or the site is flagged for possible inclusion on a blacklist.however, many words have more than one meaning (for instance,òbeaveró can have both sexual and nonsexual meanings); furthermore,the context in which words appear has a great effect on their appropriateness (for instance, the word òbreastó can appear in a cancer informationsite, as opposed to an adultoriented, sexually explicit site). more sophisticated text analysis techniques that are available to address these problems can, for instance, identify phrases (e.g., òbeaver damsó or òbreastcanceró) in order to determine appropriateness more precisely.another method of textual analysis that is used for filtering is textclassification or categorization (see appendix c). this technique analyzes the text as a whole, taking account of such characteristics as frequency of occurrence of various words, cooccurrence of pairs or othercombinations of words, and other statistical parameters of the text. textclassification is first applied to a socalled training collection of texts thatare already known to be either appropriate or inappropriate, in order todiscover regularities in the statistical properties of appropriate texts andinappropriate texts. the same technique is then applied to texts retrievedfrom the web, and their statistical characteristics are used to classify themas either appropriate or inappropriate.filtering by image analysisalmost all sexually explicit material on the internet is associated withimages. as indicated in section 2.2 and appendix c, analysis of images toyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.56youth, pornography, and the internetdetermine if they are inappropriate is a very hard problem, if it is to bedone accurately. nevertheless, there are some techniques that can provide clues to the potential inappropriateness of an image.19 for instance,it is possible to identify large expanses of what is likely to be flesh in animage, and it is also possible to determine whether an image is likely to beof one or more people. also, it is possible to have a set of canonical orusual inappropriate images, against which images on a web site can becompared. however, all of these techniques are highly errorprone andtherefore are most often used in combination with other indicators ofpotential inappropriateness as described below.filtering by labelsall web pages have associated with them information that describesvarious characteristics of the page and that is typically hidden from theuser. for example, html or xml tags within the body of a page canencode various rules that determine how information is structured on thepage. this lowlevel information can be used to compare the pageõsstructure against a set of structures commonly associated with inappropriate pages. at a somewhat higher level, web sites have associated withthem information about the site or page as a whole. such metadata can beused to determine the appropriateness (or not) of a site. metadata is notdirectly viewable by the user, a feature that has been exploited by manyinappropriate (and even some appropriate) sites in order to bias searchresults toward themselves.for instance, due to the nature of search engines, the more times aword that is used in a query appears in a site, the higher up in retrievalrankings that site will be placed. thus, extended repetition of commonlyused search terms in the metadata, which have no relationship to theactual content of the site itself, will result in that siteõs being retrieved andplaced highly in the results when those terms are used.this methodology can, however, also be used for filtering purposes,in the following ways. the terms in the metadata can be compared to thewords in the text of the page, and if those in the metadata are markedlydissimilar from those in the page, that page is suspect. also, the fact ofunusual repetition of words in the metadata can be used as a clue forfiltering.19a brief summary concerning the technology of screening for sexually explicit imagescan be found in james ze wang, jia li, gio wiederhold, and oscar firschein, 1998, òsystemfor screening objectionable images,ó computer communications journal 21(15): 13551360,and papers referenced therein.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.57technologythe most straightforward method of labeling for filtering is labelingto indicate the nature of the content of the web page or site. this can beaccomplished either by third parties who label sites according to someestablished set of categories that indicate their content, or by the producerof the site. this is, in effect, the human version of the statistically basedautomatic text classification described above. the filter then works byestablishing which categories of sites are allowed to be presented, readingthe appropriate label in the metadata, and refusing all sites that are eitheron a black list of categories, or not on a white list.a common framework for labeling is the platform for internet content selection (picsñbox 2.6). in the domain of television, the vchip is afilter that is based on labeling. (movies and video games also have labelsbox 2.6the platform for internet content selectionthe platform for internet content selection (pics) is a framework for the supportof contentrating systems. pics provides standards that facilitate selfrating and thirdparty rating of content. selfrating is performed by the content providers, who labelthe content they create and distribute. thirdparty rating enables multiple, independent labeling services to associate additional labels with content created and distributed by others. services may devise their own labeling systems, and the same content may receive different labels from different services.a content provider wishing to include a picscompliant label with its contentfirst chooses a rating vocabulary to use, such as icra or rsaci. a provider willdescribe the content to be rated in terms of this vocabulary (usually generated byfilling out an online questionnaire about that content). the output of that questionnaire is metadata with the appropriate, standardized, machinereadable descriptors,which is then placed into the metadata portion of a web site. a thirdparty rater usesmuch the same process, except that the metadata is associated with the url atwhich the content is found and placed into a database residing in a òlabel server.ópics is part of a larger effort being managed by the world wide web consortiumon metadata, that is, data associated with web content that represents informationabout that content in a way that is easy for machines to deal with. metadata isintended to facilitate searching, helping authors to describe their documents in waysthat search engines, browsers, and web crawlers can understand.source: see <http://www.w3.org/pics>; paul resnick, 1997, òfiltering information on theinternet,ó scientific american, march; and jim miller and paul resnick, 1996, òpics: internetaccess controls without censorship,ó communications of the acm 39(10): 8793. for opposing views on the desirability of pics, see simson garfinkel, ògood clean pics: the most effective censorship technology the net has ever seen may already be installed on your desktop,ó<http://hotwired.lycos.com/packet/garfinkel/97/05/index2a.html>; lawrence lessig, 1997, òtyranny in the infrastructure,ó wired 5.07(july), <http://www.wired.com/wired/5.07/cyberrights.html>; and jonathan weinberg, 1997, òrating the net,ó hastings communication and entertainment law journal 19(2): 453.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.58youth, pornography, and the internet(i.e., ratings) that often appear before a program is televised or a game isplayed, but these are not machinereadable. further, these labels areintended to provide advice to consumers rather than to enable technological denial.)filtering using combinations of methodsall of the technologies of filtering that are discussed above have inherent uncertainties associated with them, which lead them to make errors both of commission (misinterpreting a site as inappropriate) or omission (not identifying an inappropriate site). however, the sources of errorin each of the techniques are different. thus, by combining the varioustechniques, the level of error can be reduced. for example, if imageanalysis indicates the high probability of a naked person but textual analysis does not indicate any of the words usually associated with adultoriented material, analysis of the associated url finds the domain .gov,and the metadata indicates that the owner of the site is the nationalgallery of art, the filter would be justified in predicting that the siteshould not be regarded as containing adultoriented, sexually explicitmaterial, despite the evidence from image analysis. such methods showpromise in improving filter performance.tradeoffs in filteringas mentioned above, filtering is subject to two kinds of error: errorsof commission, also known and referred to in this volume as type i errors, or as overblocking, and errors of omission, also referred to as type iierrors, or underblocking. in the information retrieval literature (see appendix c), these kinds of errors are associated, respectively, with theperformance measures of precision and recall. the first type of errorñoverblockingñoccurs when a site that is appropriate is filtered, i.e., isdeemed inappropriate and therefore denied to the user. the second typeof errorñunderblockingñoccurs when a site that is in fact inappropriateis deemed appropriate, and therefore permitted to the user.due to the nature of filtering, these two types of errors are inevitable.it is possible to adjust the method of filtering such that the occurrence ofone type of error is reduced; however, reducing one type of error willalways result in increasing the other type of error. for instance, one canreduce underblocking by setting the standard for what is inappropriate ata very low level (e.g., denying access to all sites or refusing all queries thatcontain the word òadultó or the word òsexó). this might result in manysexually explicit sites being successfully filtered, but it will clearly alsoresult in a concomitant increase in overblocking, since many obviouslyyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.59technologyappropriate sites will also be filtered.20 in some settings (e.g., in doingresearch), it is desirable to minimize overblocking. in other settings (e.g.,in households that are highly riskaverse), it is desirable to minimizeunderblocking. but it is not possible to minimize both simultaneously.note also that even a low rate of overblocking will still cause a largenumber of pages to be blocked, simply because most of the content on theweb consists of innocuous content.quantitatively estimating the rates of these two types of errors, or therate of success in blocking and not blocking, depends on knowledge (orestimation) of four numerical parameters, as indicated in box 2.7.placement of filtersfilters can be installed in a variety of places. some isps use filters toscreen the content they pass onto their subscribers. the major internetbrowsers (internet explorer and netscape) support labelbased filtering.some search engines provide users with the option to perform filteredsearches. thirdparty commercial software vendors sell standalone filters that can be installed on a personal computer or into a local areanetwork serving an organization (e.g., a school or a library system). seesection 12.1.1 for a more detailed discussion of this issue.2.3.2technologies for authentication and age verificationthe process of authentication involves assessing the validity of anassertion about the identity of a user.21 (note that a separate issue relatesto the identification of a specific piece of software or hardware being used(box 2.8). when only a specific individual is using that software or hardware, the authentication problem is reduced to that of identifying thespecific software or hardware in use. but in general, multiple users of agiven software or hardware system must be assumed.22)20this is a real example from a filtering system that was encountered at one of the sitevisits.21in this report, the term òidentityó is used in its colloquial sense, namely for the biological life formñthe human beingñin question. security specialists often refer to identitymore generally as a collection of information about an individual. for more discussion, seecstbõs forthcoming study on authentication technologies, with project information available at <http://www.cstb.org/web/projects/authentication>.22for more discussion of authentication technologies, see computer science and telecommunications board, national research council, computers at risk, 1991; cryptographyõsrole in securing the information society, kenneth w. dam and herbert s. lin, eds., 1996; trustin cyberspace, 1999; and realizing the potential of c4i: fundamental challenges, 1999, all published by national academy press, washington, d.c. cstbõs forthcoming study on authentication will address these technologies comprehensively (see footnote 21).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.60youth, pornography, and the internetbox 2.7appropriate and inappropriate blockinga given filter claims to work over a class of content. examples of a class includeòall web content,ó òall content in a particular set of chat rooms,ó and òall emailheaded for a particular set of inboxes.ó classes for a filter can also be combinationsof these things.at a certain moment in time, let t be the total number of òcontent itemsó towhich the particular filter could be applied. break the number t into 4 parts, suchthat a + b + c + d = t, where a, b, c, and d are defined in the table below.inappropriateappropriateblockedabnot blockedcdthe success of a filter in blocking inappropriate sites is measured by the ratio ofa to a + c, and the success of a filter in not blocking appropriate sites is the ratio ofd to b + d. thus, a completely successful filter would have values of 1 for each ofthese ratios; that is, only inappropriate sites would be blocked, and all appropriatesites would not be blocked. a value of zero for each of these ratios indicates complete failure of the filter to block inappropriate sites and to not block appropriatesites, respectively. put another way, the rate of underblocking is c/(a + c), and therate of overblocking is b/(b + d), and a value of 1 for each indicates the completefailure of the filter with respect to each measure, and a value of zero indicates complete success.most filters are assessed against static content. in these cases, it is possible inprinciple to know the values of a, b, and c for any given filter, since inappropriateand appropriate sites that are blocked (a and b) can be identified, as can inappropriate sites that are not blocked (c). however, the value of d must always be only anestimate, since we cannot know exactly all of the appropriate sites that exist on theinternet. thus, although the rate of underblocking can be empirically determined,the rate of overblocking can only be estimated.(note that filters whose parameters or rules are updated in real time (e.g., parameters or rules that are based on data gathered continuously by software watching thebehavior of network users) can result in the numbers t, a, b, c, and d varying withtime. in principle, filters can also use additional computing power to more preciselydiscriminate when traffic is modest, but fall back to less precise algorithms duringperiods of heavy traffic: t, a, b, c, and d would vary with time in this case as well.)how should d, the number of not blocked appropriate pages, be estimated? acontroversy over methodology was the subject of testimony to the committee. oneapproach is that the number of appropriate pages should be estimated on the basis ofa random sampling of web pages. a second approach is that the number should beestimated on the basis of actual usage, which weights certain popular web pagesmore heavily than those not accessed as frequently. note that computing the overblock rate in the first way increases it relative to the overblock rate computed in thesecond way.for the purpose of determining the accessibility of information in general, thefirst approach is arguably better. for the purpose of determining the accessibility ofyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.61technologybox 2.8specific identification of hardware and softwarein the earliest days of information technology, any given version of a chip or asoftware program was released to users in absolutely identical formñevery circuit inuser aõs chip was identical to that in user bõs chip, and every bit in user aõs software program was identical to user bõs software program.for a variety of technical and business reasons, there is an increasing trend toward individual identification of chips and software. thus, user a may purchase acomputer using a processor with a serial number embedded in it, and readableelectronically, and user b purchases an identical computer with an identical processor, but with a different serial number embedded in it.1 another example, whichwill become relevant below, is that every individual network interface card has associated with it a unique media access control (mac) address (a unique 48bit number assigned by its manufacturer) that identifies the card in tcp/ip networks. todayõs software often requires entering a serial number or authorization key (in thename of preventing piracy) in order for installation to proceed, and there is no particular reason that such a key cannot be embedded in documents or objects processed with that software.21for example, according to the intel corporation, a processor chip newer than the pentiumii processor (i.e., pentium iii and above) electronically embeds a processor serial number, whichserves as an identifier for the processor, and, by association, the system of which it is a part.though the default setting for the processor serial number is òoff,ó it can be turned on throughthe use of software. intel believes that system identification can enable certain benefits, such asauthenticating participants in a secure chat room or ensuring security in ecommerce situations.for business users, processor serial number identification will allow information technologydepartments to provide better information management or improved management of corporatepc assets. see <http://support.intel.com/support/processors/pentiumiii/psu.htm> and <http://support.intel.com/support/processors/pentiumiii/psqa.htm#2>.2see, for example, greg lefevre, 1999, òmicrosoftõs guid sparks fears of privacy invasion,ócnn, march 8. available online at <http://www.cnn.com/tech/computing/9903/08/microsoft.privacy.02/>.information in practice, the second approach is arguably better. the reason thatthese two approaches are different is that the information needs of peopleñaggregated as a groupñare not uniformly spread over the spectrum of information that theinternet provides. for this reason, someone looking at information needs of largegroups in practice might well choose the second approach. however, the information needs of any given individual may not fall within òtypicaló search parametersñfor those with nontypical information needs, the first approach may be morerelevant.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.62youth, pornography, and the internetin the physical world, the authentication process is conceptuallystraightforward because of facetoface interactions. when an individualbuying beer presents a driverõs license to a liquor store clerk, the clerkcan compare the picture on the license to the individual in front of him.of course, the license could be phony, but the facetoface nature of theinteraction helps to ensure that the subject being compared to the credential is real.23such assurance is not available when a facetoface interaction is notpossible, as in the automated authentication of a user to a computer system.24 automated authentication depends on the prospective system usersharing with the authentication device something the person knows, has,or includes as a feature, such as a òsmart cardó belonging to the appropriate individual, a secret password, the individualõs voice, or a biometricsignature such as a fingerprint or retinal pattern.authentication is only one dimension of keeping children away fromageinappropriate materials. the second key element is that of ensuringthat a user is older than some specified age (e.g., older than 17). whileauthentication involves assessing the validity of an assertion about theidentity of a user, it does not speak directly to the issue of age verification.assurance about age must, in general, be provided by reference to a document that provides information about it, and todayõs infrastructuresneeded to support online authentication of identity generally do not include such documents.in the physical world, age verification can be provided as a part of thecredential being presentedña driverõs license generally has a date of birth23indeed, in the physical world, someone who presents a fake id that is recognized assuch by the clerk is subject to arrest.24in principle, age verification could occur through the use of streaming video and audio.in this scenario, a web camera and microphone located on the userõs access point would beused to transmit a highfidelity voice and video image to a human being working on behalfof the adult content provider. the human being (who might be called a cyberspaceòbounceró) would ascertain the adult status from viewing the image and listening to thevoice, and if there were any doubt, the bouncer would demand to see a driverõs license thatthe alleged adult could hold up to the camera. even through voice alone, a trained humanverifier can often determine whether the person on the other end is in fact an adult, thoughthis may not always work for very young adults. the human verifier asks questions, andthen listens for tone of voice, composure, presence, stuttering, and other things that are notreflected in a typed textual interaction. because adults tend to have more confidence andselfassurance than children, such voice interactions provide valuable distinguishing information. these scenarios are technically feasible even today, but are likely not to be economically attractive. the reason is that one of the major advantages of internet commerceis the ability to drastically reduce the extent to which human beings are involved. giventhat many adultoriented web sites operate on very thin margins, the cost of using such amechanism would likely be prohibitive.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.63technologyrecorded on it. however, a driverõs license would be just as good anauthenticator of identity if it did not have the date of birth on it.in an online environment, age verification is much more difficult because a pervasive nationally available infrastructure for this purpose isnot available. one method is based on the fact that many adults (but notvery many children) have credit cardsñpresentation of a valid creditcard number is presumed to be an indicator that the presenter is an adult.taken in the large, this is not a bad assumptionñthe vast majority ofcredit cards are in fact owned by adults, and the vast majority of minorsdo not own or have legitimate access to credit cards. thus, an adultoriented web site that uses credit cards as its medium of exchange presumes that the presentation of a valid credit card also verifies that thecard user is of legal age. entering a valid credit card number grants accessto the inside of the site.25many online adult verification services (avss), which provide a verification of adult status to other adult web sites, also use credit cards.26because the credit card is generally the userõs method of payment for theservice, the avs relies on the credit card to verify the adult status of theuser.27another approach to age verification is to rely upon databases ofpublic records (i.e., governmentissued documents such as voter registrations and/or driversõ licenses). for example, an individual wishing togain access to an adultsonly service sends an online request to an ageverification service (along with a creditcard number to effect payment)for a certification of age for a given individual. he or she also providesappropriate personal information, and the adult verification servicechecks that information against public records such as state driversõ licenses and voting registration that contain or imply age information.even higher confidence in age verification can be obtained by coupling the use of public record databases to an authentication process that25determining with certainty whether a submitted credit card number corresponds to anaccount in good standing requires an online transaction between the site operator and thecredit card company. that is, the site operator transmits the number to the credit cardcompany and the company checks to see if the number refers to an account in good standing. there are other methods that allow the offline identification of some invalid creditcard numbers, but they can be defeated with a little effort and sophistication.26such services also accept applications via 1900 phone numbers (which children are notsupposed to use without parental permission) that charge phone bills automatically and viau.s. mail. mail applications are supposed to include proof of age.27the òtypicaló adult verification service provides the user with a special code number.adult web sites contract with the service (of which many exist). a user wishing access toone of these adult web sites enters the code number. the adult web site then contacts theavs to confirm that the number is valid, and if it is, grants the user access. (the adult website usually pays the avs a commission for users who are verified in this manner.)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.64youth, pornography, and the internetprovides assurance of identity. in this case, when adult status is confirmed, a credential certifying oneõs adult status is mailed (via postalservice) to the address of record on those public records. in this context,the postal service serves as an authenticating process that ensures theadult credential is sent to the right person. the individual can then usethis special key to obtain access to adultsonly services that recognize thisspecial key.a third approach is to use age verification scripts. an online scriptcan guide a user through a questionnaire that asks, among other things,the userõs age, and it can reject users who are underage. to help deal withthe problem of lying about oneõs age, some scripts are written to acceptonly one attempt at entering age, and so a user who enters ò15ó at first, isrejected for being underage, and then tries to enter ò20ó is unsuccessful.in such cases, he or she may have to try again from another computer.note that each of these methods imposes a cost in convenience of use,and the magnitude of this cost rises as the confidence in age verificationincreases. age verification scripts are very convenient for the legitimateadult user, who must simply tell the truth about his or her age. but theyare also susceptible to being fooled by a savvy adolescent who knows thatthe correct age must be entered. a credit card is less convenient for thelegitimate adult user, because he or she must be willing to incur theexpense of a subscription (or the hassle of canceling one). however, sincemost credit cards are owned by adults, the use of a credit card providesadditional confidence that it is truly an adult who is seeking to use it. atthe same time, some minors do own credit cards or prepaid cards thatfunction as credit cards, while other minors are willing to use credit cardsborrowed with or without permission from their parents. (even whenparents review credit card statements, either their own or those of theirchildren, they may not be able to identify transactions made with adultoriented sexually explicit web sites, as the adult nature of such transactions is often not readily identifiable from information provided on thestatement.) using public record databases to verify adult status providesadditional confidence in age, but increases the amount of personal information that the user must provide to gain access. mailing the certifying credential to the user provides the greatest confidence of all that thealleged adult is truly an adult, but because the user must wait forthe processing and mailing of the adult credential, it is also the leastconvenient.claims have been made that certain òbiometricó signatures can differentiate between adults and children. while human physiology does indeed dictate that certain changes in oneõs body occur as one grows fromchild to adult, the precise trajectory of these changes varies from indiyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.65technologyvidual to individual. however, oneõs legal statusñas being entitled toprivileges as an adult that are not enjoyed as a childñis fixed by laws thatspecify, for example, that individuals even one day over 18 are considered adults and one day under 18 are considered unemancipated minors.no technology today or on the horizon can hope to make such fine distinctions in the case of individuals.28 for this reason, biometric technologies as a method for age verification are not considered here.age verification technologies as integrated into functional systemsare discussed in greater detail in chapter 13.2.3.3encryption (and endtoend opacity)encryption is used to hide information from all but specific authorized parties. in the most general encryption process, an originator (thefirst party) creates a message intended for a recipient (the second party),protects (encrypts) it by a cryptographic process, and transmits it asciphertext. the receiving party decrypts the received ciphertext messageto reveal its true content, the plaintext. anyone else (a third party) whowishes undetected and unauthorized access to the message must penetrate (by cryptanalysis) the protection afforded by the cryptographic process or obtain the relevant decryption key (or use another approach toobtain the key, such as bribing someone to reveal it).encryption also has relevance to the protection of digitized intellectual property, such as proprietary images. because encryption restrictsthe access of unauthorized parties, encryption can be used to help preventthe dissemination of unauthorized reproductions of digital objects. encryption is thus the fundamental technology underlying digital rightsmanagement systems (discussed in greater detail in chapter 13). the useof encryption may increase dramatically in the coming years.in the context of this study, the significance of encryption is that ifcontent, whether acceptable or inappropriate, is encrypted properly, itcannot be identified by third parties. thus, while it is possible to interdictall information flows that are encrypted, it is impossible to interdict specific transmissions on the basis of contentña point with obvious relevanceto filtering systems intended to block specific content. thus, encryptionallows transmission and reception of information to occur with essentially no outside scrutiny possible.28see, for example, testimony of john woodward, senior policy analyst, rand, to thecopa commission on june 9, 2000. available online at <http://www.copacommission.org/meetings/hearing1/woodward.test.pdf>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.66youth, pornography, and the internet2.3.4anonymizersas noted in section 2.1.2, the technology of the internet itself does notgenerally require any party to authenticate its identity. thus, users andonline identities (e.g., a screen name or an email address) are boundtogether through administrative procedures, usually those of an isp, thatare associated with gaining access to the internet. through such bindings, any interaction of an individual with an internetrelated serviceñwhether visiting a web page, sending an email, posting a message, setting up a web page, or participating in a chat roomñis tied to a specificidentity that can, in principle, be traced administratively back to thatspecific individual.anonymizers break this binding and decouple an individual from aspecific online identity. the anonymizer provides what amounts to anidentity that is randomly generated. this identity is then used for postingmessages, sending email, participating in chats, and accessing web pages.(some anonymizers enable return paths when necessary; for example, therecipient of an anonymous email may wish to reply to the (anonymous)sender.) however, anyone seeking to trace the anonymized identity backto the original user will find a number of barriers that make it very difficult to recover the identity of the original user. one example of ananonymizer useful to publishing information on the web is described inbox 2.9.anonymizers are significant because they enable individuals to undertake activities for which they need not suffer retribution. for an individual living in a totalitarian state, an anonymizer enables him or her topost an antigovernment message in safety or to browse forbidden websites. in the united states, it enables someone to freely post a messageexpressing unpopular political views or to browse web sites in privacy.commercial enterprisesñwhich need to have a way to accept moneyñdonot have much use for anonymizers, even if they are posting materialsthat may be controversial. but those with noncommercial interests canuse the same technology to anonymously post child pornography or harass or stalk an individual online. when anonymizers are used, tracingthe identity of online criminal perpetrators becomes difficult.2.3.5location verificationthe legal regimes of today are ones in which jurisdiction is basedlargely on geographical borders. for example, as noted in chapter 4,òcommunity standardsó are an important factor in determining whethera given image is obscene. however, the internet is designed and structured in such a way that geographical borders and the physical location ofyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.67technologya user have no significance for the functionality he or she expects fromthe internet or any resources to which he or she is connected. this factraises the question of the extent to which a userõs location can in fact beestablished.one way to establish location is simply to ask the user where he orshe is located upon logging in. thus, the first screen seen by the usermight ask for his or her present zip code (or state, or country). but in theevent that the user chooses to be deceptive (e.g., to avoid restrictions oninternet service based on his or her location), the problem shifts to one ofdetermining location through technological means.under some circumstances, it can be virtually impossible to determine the precise physical location of an internet user. consider, for example, the case of an individual connecting to the internet through a dialup modem. it is not an unreasonable assumption that the user is mostlikely in the region in which calls to the dialup number are local, simplybecause it would be unnecessary for most people to incur longdistancecalling costs for such connections. however, nothing prevents a userfrom using a longdistance telephone call (e.g., from tennessee) to accessa modem in california.box 2.9publius: a system for publishing anonymouslyon the world wide webpublius is a web publishing system that provides publishers with a high degree ofanonymity. publius encrypts digital content (say, a document) and then fragmentsthis encrypted content for distribution among a number of web servers (e.g., 100servers) in such a way that the content can be reconstructed with a certain numberof fragments (e.g., 35 fragments). furthermore, any 35 fragments will do. however,someone possessing 34 or fewer fragments cannot reconstruct the original to anydegree of fidelity. (in other words, having 34 fragments tells the owner nothingabout the contents of the original document.) and, because of this encryption, thecooperating web servers have no way of knowing what is being stored. becausethe cooperation of multiple servers is needed to recreate the document, publius thusbreaks the onetoone correspondence between a web document that one mightwish to protect and a server. because any electronic payment today to a specificcreator identifies the creator, publius is difficult to use for payperview sites. but forthose who wish to distribute their work broadly and do not care about financialcompensation, publius has major advantages.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.68youth, pornography, and the internetin practice, recovering location information is a complex and timeconsuming process.29 as a rule, the information needed to ascertain thegeographic location of an ip address associated with a fixed (wired) internet access point at a given time is known collectively by a number ofadministrative entities, and could be aggregated automatically. but thereis no protocol in place to pass this information to relevant parties, andthus such aggregation is not done today.the bottom line is that determining the physical location of mostinternet users is a challenging task today, though this task is likely to beeasier in the future. appendix c provides additional discussion.2.4what the future may bringthe hardest part of this report to calibrate is how the future willchange the technologies that today scope both the problem and any putative solutions. as of this writing (may 2002), the world wide web is noteven a decade old, while the creation and adoption rates for new technologies show generally accelerating deployments of these technologies.the rapid changes of capability in the hardware underlying information technologies will lead to computing that is 100 times more costeffective, storage 1,000 times more costeffective, and bandwidth 10,000times more costeffective 10 years hence, and it is highly likely that manyapplications will emerge to take advantage of such increased capability,as has occurred in the past. what follows below is admittedly speculative, but even if any given speculation is far from the mark, taken togetherthese notions paint a portrait of a very different technological milieu inwhich the ageold problem of òprotecting children on the internetó willplay out in the future.¥mechanisms for financial transactions will change significantlyover the course of a decade. financial transactions are likely to becomeincreasingly less private, as the various forms of payment embody different features to enable traceability. even cash may become more traceablein the future. this development will favor parents who wish to monitorthe expenditures of their children, but will have no impact on those chil29while location information is not provided automatically from the ip addresses that anadministrative entity allocates, some location information can be inferred. for example, ifthe administrative entity is an isp, and the isp is, for example, a french isp, it is likelyñthough not certainñthat most of the subscribers to a french isp are located in france. ofcourse, a large french company using this isp might well have branch offices in london, sothe geographical correspondence between french isp and internet user will not always bevalid for this case, though as a rule of thumb, it is not a bad working assumption.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.69technologydren who borrow electronic wallets at home or who access those sourcesof sexually explicit material that do not charge.¥voice interaction with computers will become increasingly common, and the capability of computergenerated voices to sound like realpeople, or even parties known to an individual, will increase. today, a55yearold man can pretend to be a 13yearold girl using email andinstant messages; tomorrow, a 55yearold man may be able to sound justlike a 13yearold girl over the telephone. it may even be possible for thesame 55yearold man to sound like the girlõs mother. in short, technology will offer greater deceptive capabilities, and those that are most atrisk from the existence of such capabilities are likely to be children wholack the experience to identify deception.¥voice interaction will allow younger children, who would findtyping difficult, to speak a web site address to their computer.¥peertopeer interactions will be increasingly common, as the technology will largely eliminate the need for largescale servers, thus eliminating them as principal points of leverage for any control strategy. italready grows ever more expensive to selectively delete content than tokeep it all, and this economic fact will dominate the future with implications for privacy, digital rights management, and the steady accumulation of data that is best described as digital detritus.¥virtual reality advances will soon defeat the ability of even expertsto distinguish pictures that are real from those that are synthetic. hapticdevices (i.e., touch, motion, and pressuresensitive devices) may becomemore common as a way to interface with computers. whether then aperson, an action, or an event is real or not may soon be irrelevant tomany consumers. action, especially òactionó in the sexual and violentsubmeanings of those words, will be as realistic as the audience is willingto pay for, and the prices of such offerings will inevitably drop.¥locations from which access to the internet is possible will proliferate wildly. and, with an expansion in the types of information resources that are accessible (e.g., new virtual reality resources), policiesthat give permission to view, access, modify, or delete any informationresource will present an enormously complex problem simply as a resultof scale. even today, finegrained access control driven by policy is, orsoon will be, beyond the scope of human management and may be beyond the scope of mechanistic alternatives. if access control policies areimpossible to formulate, the only alternative is an approach that dependson users to exercise selfcontrol. monitoring of user actions in order toensure appropriately selfcontrolled users then becomes the only technical alternative to access control. this is not a statement about the desirability of this outcome, only that it is a possible one if access controlpolicies become impractical.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.70youth, pornography, and the internet30for example, the video cassette recorder, inexpensive video cameras, and cdromtechnologies found some of their first applications in the production and viewing of sexually explicit òadultó movies and interactive sexual games and entertainment. for one perspective on this point, see jonathan coopersmith, 2000, òpornography, videotape, and theinternet,ó ieee technology and society 19(1): 2734.although the notions described above are not necessarily desirablefrom a societal or personal standpoint, they are extrapolations of certainphenomena today, and there are at least some paths from today thatcould result in their coming true. on the other hand, they may not cometrue, a point that emphasizes a vast range of uncertainty about the technological future.what has been true over the years is that those who produce andconsume sexual contentñboth for commercial and noncommercial purposesñhave stayed on the leading edge of new technologies.30 thus,whatever the technological future is like in detail, it seems safe to predictwith reasonably high confidence that sexual content will be disproportionately present in the initial stages of adoption of any new technology.because technology changes rapidly, no final technological solutions arepossible. it is for this reason, among others, that the committee in laterchapters emphasizes social and educational strategies for protecting children from inappropriate sexually explicit material.finally, many of the issues associated with protecting children frominappropriate material and experiences on the internet relate to the architecture of the internet as it exists today, a state of existence that reflectspolicy and engineering decisions made decades ago. these are not immutable, though major changes that might facilitate control of contentdelivery could be made only at very considerable cost and at the potentialexpense of other societal interests.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.71while far from the only source of sexually explicit materials on theinternet, an important driver of public concerns about the access of children to pornography on the internet is the online component of the adultentertainment industry (hereafter the adult online industry). indeed,many of the canonical examples of exposure to pornography point tocommercial sites as prominent purveyors of such material that minorscan reach and see, and to a considerable extent, the fact that children cancome across such material (with or without a deliberate choice on theirpart) results from the existence of an industry that caters to adult demandfor such material. material available online from these sources (and othernoncommercial sources as well) includes images of heterosexual andhomosexual intercourse (including penetration), fellatio, cunnilingus,masturbation, bestiality, sadomasochism, bondage, rape, incest, and soon.1 for this reason, it is helpful to describe certain important characteristics of this industry.3the adult onlineentertainment industry1legitimate online adult entertainment businesses are not generally providers of childpornography. however, one firm in the adult online industry that provided access to arange of sexually explicit materials was indicted and convicted on child pornographycharges. see lenny savino, 2001, òkid porn web sites lead to 100 arrests: investigationtargets biggest such business found in u.s.,ó detroit free press, august 9, available onlineat <http://www.freep.com/news/nw/kids920010809.htm>. in addition, some adult entertainment web sites do cater to viewers wishing to see young women in sexual poses(e.g., through advertising and site copy that promises òhot teensó and òyoung girlsó), andbecause such content by assumption depicts young women in sexual poses, it is unclearfrom the images alone whether the young women depicted are in fact over 18 as requiredby law and merely look like they are younger, or if they are in fact underage.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.72youth, pornography, and the internet3.1the structure and scale of the online adultentertainment industrythe adult online industry in the united states generates approximately$1 billion in revenues annually,2 and some in the industry expect this figureto grow to $5 billion to $7 billion over the next 5 years, barring unforeseenchange. as the rest of this chapter discusses, revenues can come from anumber of sources: paid subscriptions to the site, advertisements carriedon the site, sending traffic to other sites, sale of sexrelated products, andproviding auxiliary services such as adult content search engines, contentfor other adult web site operators, or age verification services. for purposes of this report, the term òcommercial sourcesó should be understoodto mean sites that charge a fee for access and sites that provide access tocontent for free but are supported by advertising revenues.according to the best information available to the committee, subscription sites with adult content exceed 100,000 in the united states (witheach site having multiple web pages underneath it), and about 400,000forpay adult sites globally. the business entities responsible for theseu.s. sites include about 1,000 u.s. firms operating as genuine businessenterprises, with perhaps another 9,000 or so operating as (usually smallscale) affiliates of other established online adult entertainment firms.3compared to the totality of content on the public world wide web,adultoriented sites account for a relatively small fraction (about 1.5 percent).4 however, these sites account for a significant amount of webtraffic. according to industry statistics, approximately 70 million different individuals per week view at least one adult web site on a globalbasisñ20 million view adult pages that are apparently hosted on sites in2the total size of the adult entertainment industry is not well known, and estimates rangefrom $4 billion to $10 billion. see frank rich, 2001, ònaked capitalists: thereõs no businesslike porn business,ó the new york times magazine, may 20; emmanuelle richard, 2001, òtheperils of covering porn,ó online journalism review, july 10, available online at <http://ojr.usc.edu/content/story.cfm?request=608>; and dan ackman, òhow big is porn?,óforbes.com, available online at <http://forbes.com/2001/05/25/0524porn.html#story>.3numbers provided by bill johnson, director of marketing, flying crocodile inc., interview, january 2001. an òaffiliateó can be a separate business entity or can have an employee or consultant relationship to the primary firm.4the first work in this area known to the committee is that of steve lawrence and c. leegiles, 1999, òaccessibility and distribution of information on the web,ó nature 400(6740):107109, july 8. (in fact, the lawrence and giles result of 1.5 percent holds for the number ofservers found to be òpornographicó in nature. the statement in the text that adultorientedsites are 1.5 percent of all sites is based on an assumption that on average, a server supportsthe same number of sites regardless of its content. this assumption is likely to be wrong indetail, but probably holds on average.) the results for sexually explicit information weresubstantially reproduced in daniel orr and josephine ferrignostack, 2001, òchildproofingon the world wide web: a survey of adult webservers,ó jurimetrics 41(4, summer): 465475.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.73the adult online entertainment industrythe united states or canada. the number of paying subscribers is on theorder of several million in the united states, and may be as high as 10million. the majority of these viewers and subscribers are male,5 thoughthe fraction of female viewers may be growing. on average, a paid subscription generates $20 to $40 per month in revenue. the majority ofsubscribers cancel within a month, but of those who remain after a month,the typical retention time is approximately 3 to 4 months.a profitable adult online business is often difficult to sustain over thelong run, despite the high demand. the cost of entry into the business isrelatively low, and the availability of a range of services from content provision to free web site hosting and credit card transaction processing makesit easy to set up an adult web site. however, because the market is highlysaturated (i.e., for a web site with any given sexual theme, there are likelyto be a large number of competitors), and subscription prices more or lesscapped in price, the business is one with low margins.6 thus, profitableenterprises depend in large measure on drawing large volumes of traffic (inindustry jargon, òeyeballsó) in the hope of converting some of this trafficinto revenue (i.e., customers paying for subscriptions). (box 3.1 summarizes the primary methods used to increase traffic to oneõs web site.)for large firms in the adult online industry, the cost of bandwidth is amajor element in their cost structure. because its products are graphicsintensive, the adult online industry consumes enormous amounts of bandwidthñand the two largest individual buyers of bandwidth in the unitedstates are firms in the adult online industry. however, it is also true thatmost bandwidth is used by viewers of these sites who do not pay for theiruse of these sites, because nonpaying individuals can see large amountsof sexually explicit material simply by looking at the home pages of thesesites, their free òteaseró pages, and their free demos.the structure of the industry involves a relatively small number oflarge firms and a much larger number of smaller ones. the major firms(numbering 100 to 200) generate revenue from subscriptions and fromproviding content to other, smaller businesses. to increase traffic flow,these large firms also pay for traffic that is forwarded to them by other,smaller businesses. these other smaller businesses also receive contentfrom these large firms to display on their own sites. the majority of adultweb pages have adult content that draws customers who can then bereferred to another site (where they will encounter subscription offers).5alvin cooper et al.  1999. òsexuality on the internet: from sexual exploration to pathological expression,ó professional psychology: research and practice 30(2, april): 154164.6some in the adult industry have also argued that credit card fraud has forced manyadult merchants to pay much higher credit card processing fees, thereby significantly reducing profit margins.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.74youth, pornography, and the internet3.2the generation of revenuerevenue in the online adult entertainment business, as in other businesses both online and offline, results from the sale of products or services (including subscriptions) or advertising. the largest amounts ofrevenue are obtained from the enduser customer, who typically uses acredit card to subscribe to a site. as a subscriber, he obtains unlimitedaccess, though the average subscriber only uses the subscription 1.5 timesper month (one viewing session typically involves seeing around 75 to100 pages).the above models for revenue generation distinguish between adultsand children on the basis of the ability to produce a credit cardñadults,but not children, are presumed to be the legitimate owners of the creditcard used. this assumption is not valid under all circumstances, but doesnot appear to be an unreasonable approach. however, home pages thatserve as billboards for the sitesõ contents and the generation of revenuebox 3.1methods for increasing traffic to oneõs adult web siteonline methods¥sending unsolicited email (òspamó) that advertises the site¥placing advertisements for the site on other web sites¥paying search engine companies for more prominent placement in theirsearch engineõs results¥acquiring domain names with sexually oriented words in them¥acquiring domain names based on common misspellings of nonsexual website addresses¥acquiring expired domain names that have acquired some reputation forgenerating traffic¥paying other web sites to obtain their exit traffic (otherwise known as mousetrapping)¥mailing list subscriptions (for which a user must make an explicit òoptinóchoice)offline methods¥advertising in print media (e.g., an adultoriented magazine)¥advertising on tv and radio¥advertising through cooperating partners (e.g., a store associated with adultentertainment)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.75the adult online entertainment industrythrough the sale of advertising generally make no such attempt to differentiate between adults and children.a web site owner can also obtain revenue from advertisers. advertisers can choose to simply pay for their ad to be displayed or pay eachtime a person clicks on their ad. when the ad is displayed the typicaladvertiser might pay the web site owner (e.g., $3 per 1,000 displays of theadña cpm (cost per mille [thousand]) model). when the advertiser paysfor the volume of referrals that the web site sends to the advertiser (e.g.,$0.05 for every user who clicks on the ad displayed and is then transferredto the advertiserõs site), it is a cpc (cost per click) model. when theadvertiser pays only if and when it gains a new subscriber as a result ofthe web siteõs referrals to the advertiser (e.g., half of the first monthõsrevenue for every subscription that results), it is a cpa (cost per acquisition) model. by contrast, the revenue model for traditional media advertising is most similar to the cpm model, because traditional media cannottrack results from advertising to the same degree of precision that is possible on the web.a related service is providing consumer internet traffic to another adultweb site in return for a small perconsumer fee. such òtraffic forwardingóis similar to the fees paid through cpc traffic referrals, except that theconsumer is forwarded involuntarily (i.e., without an affirmative choice tobe forwarded). this practice is known as òmousetrappingó (or òselling exittrafficó in the industry), and a mousetrapped user who tries to leave asexually explicit site is automatically forwarded to another such site. thisother site may be operated by a different operator, but that fact is irrelevantto the user who just wants to get out.7 (technically, mousetrapping refersto a process enabled by javascript (a scripting language for internet browsers) in which the closing of one window automatically directs the user toanother web page. the second web page can do the same, so that attempting to exit the second page spawns a third page, and so on.8)7mousetrapping is a practice that often results in user panic, especially when the user is achild. because the computer is for practical purposes to a nonexpert disabled, the onlysolution available to the nonexpert is often rebooting or pulling the plug, which can resultin a loss of work and always costs time.8note that the technology underlying mousetrapping can have entirely legitimate purposes. for example, when a user leaves an eshopping site, a questionnaire may appearthat asks the user for feedback about his or her shopping experience. but in this instance,the user can leave the questionnaire with a single click. the problem with mousetrappingarises when many sites are mousetrapped in succession, so that the user is caught in avirtually endless sequence of new but undesired and unrequested pages and is forced toview each of them. moreover, if all of these sites are operated by different parties, anyregulatory action taken must be taken against each of the parties directing them to ceasesuch practices simultaneously.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.76youth, pornography, and the internetall of these payment schedules can be (and usually are) adjusted onthe basis of the value of the user to the advertiser. for example, if thetraffic sent to the advertiser is highly qualified (i.e., has a higher tendencyto subscribe), the payment rate per adclick might be $0.20 instead of$0.05. if the customer who subscribes to the advertiserõs web site staysmore than 2 months, the web site owner might receive a bonus of anadditional 25 percent of the first monthõs revenue.as a general rule, traffic with a higher proportion of children has lessvalue to the advertiser, because the vast majority of children are unable topay for subscriptions. so, advertisers have little incentive to attract children to their sites from the standpoint of obtaining paying customers.however, the incentives are different for the web site owners who display ads. a web site owner operating on a cpa model indeed has noparticular incentive to send children to its advertisers. but a web siteowner operating on a cpm or cpc model is in a different situation. adisplay of an ad to a child counts in just the same way as its display to anadult, and the click of a child on an ad that transfers him to the advertiserõssite counts in just the same way as an adultõs click. thus, a web siteowner operating on cpm or cpc models (which constitute the large majority of adult web site owners) has few incentives to refrain from differentiating between adults and children.9this is not to say that this is the only incentive operating. because theweb site owner must negotiate a contract with the advertiser, who is veryaware of the value of the traffic incoming from that site, the web siteowner must realize that the advertiser will offer lower commissions if thetraffic being referred has low value. thus, the web site owner has incentives at the margin to refrain from distinguishing between children andadults, but also significant incentives to refrain from too high an overallpercentage of children in the referred traffic.revenues from selling traffic to advertisers can be significant, especially if one uses some of the questionable means described in box 3.1.for example, one firm employing some of these means allegedly earnedbetween $800,000 and $1 million annually from selling traffic to advertisers whose ads were included on its web sites.10subscriber retention is extremely difficult for these pay sites without aconstant supply of fresh content that they must produce themselves or9in principle, sponsors of òaffiliateó programs bear the responsibility for policing affiliates that behave in an overaggressive manner and promote their affiliate web sites throughthe use of spam or other improper methods. in practice, some sponsors take this responsibility more seriously than others, and sanctions for improper promotion can range fromnonexistent to revocation of the affiliate relationship and withholding of payments thatwould otherwise be received for traffic.10see <http://www.ftc.gov/opa/2001/10/cupcake.htm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.77the adult online entertainment industrylicense from providers. even then, because sites have designs, styles,themes, and tastes that eventually become tiresome to the member, a highpercentage of members leave after the first month, and even more leaveafter the first few months. but these customers donõt give up on adultcontent. effectively, they simply transfer their membership by cancelingwith one site and signing up at another until they become bored and moveon again. additionally, given increasing saturation of the market, marginshave been shrinking dramatically for adult internet businesses. for thesereasons, the top sites are dependent on new subscribers far more than theyare on recurring revenues from shortterm existing members.five other business models based on providing services to the primaryproviders of adultoriented sexually explicit material are worth noting:¥counters are free services that offer businesses performance statistics, click paths and behaviors, browser technology data, and demographics on the visitors to individual sites. in exchange for the service, the siteplaces on its pages an advertisement for the vendorõs company, allowingvisitors to click and visit the vendorõs portal.11 from there, the visitormay visit any site using the service, by selecting a link from the directory.the vendor makes money by selling advertising on the portal, and also byselling a portion of the incoming traffic to other adult companies.¥indexing services provide end users with a map or index to the adultweb and receive revenue for forwarding traffic to these sites. for example, flying crocodile inc. (fci) provides both counters and indexingservices. fci generates more than 150 million impressions tracked perday by fci. approximately 20 percent of the large firms have advertisingcontracts with fci at any one time. fciõs gross annual revenues arebetween $12 million and $15 million, and 60 million unique people perweek visit the 70,000 sites (global) that contract with fci.¥thirdparty billing processors offer their services to adult internetcompanies that may or may not have merchant accounts. thirdpartybilling also avoids potential embarrassment for users who wish to subscribe with some degree of privacy (since the name of the billing partyrather than the adult web site operator appears on the creditcard bill).these services manage the secure transaction processes, transfers of funds,debits, charges, telephone billing, and all associated record keeping for apertransaction fee that is deducted from the revenues credited to the paysite owner.11a portal is a òhome baseó from which a user may access a variety of content andservices that the portal provides. content may include sports scores, financial news, andheadlines; services may include search engines, email, and message boards.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.78youth, pornography, and the internet¥adult verification services (avss) provide certification to adult website operators that an individual is an adult. as chapter 4 discusses ingreater detail, a user can provide a credit card number to an avs (possession of a credit card is regarded as proof of adulthood). in return, he orshe receives a special access code that can prove adulthood to all websites that use that particular avs. often avss are used by òfreeó adultweb sites, which receive a portion of the revenue generated by the avsrequired for entry to those sites.¥content provision services provide sexually explicit content to website operators that cannot produce their own content. such content includes still images, videos, live sex chats, interactive videocamera sexshows, and so on.3.3practices related to minorsaccording to nielsen/netratings, nearly 16 percent of the visitors toadultoriented web sites in february 2002 were under the age of 18.12one source in the adult industry asserted that traffic sent to some adultsites is 20 to 30 percent children.13 these sites are usually sites that areintended to be broadly appealing to a wide variety of tastes (rather thanthose serving more specialized tastes). even using current avss, adultsites receive traffic that is 5 percent children. that said, advances in avssand better screening may enable the industry to achieve traffic that is nomore than 2 percent children.14 in addition, sites offering highly specialized, niche products tend to have higher rates of traffic that ultimatelypurchases subscriptions (and hence lower fractions of children).in a survey of adultoriented commercial sites, the majority of adultoriented sites (about 74 percent) were found to display adult content onthe first page (accessible to anyone who visits the page), often through thedisplay of sexually explicit banner ads to other sites. nearly two thirds(66 percent) did not include a notice indicating the adult nature of the site,and only 11 percent included such a notice and also did not have adultcontent on the first page. about 25 percent employed practices that hin12nielsen/netratings, february 2002. nielsen/netratings provides internet audiencemeasurement data and analysis by monitoring actual clickbyclick internet user behaviorthrough a realtime meter installed on the computers of more than 225,000 individuals in 29countries worldwide. the meter is installed with the permission of the homeowner torecord the relevant activities of users and includes an automated login to identify who theuser is at specific times. because the family specifies the ages of household users, the websites visited need not determine if the visitor is an adult or a child, a task whose difficulty isaddressed in chapter 2.13bill johnson, fci, 2001.14bill johnson, fci, 2001.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.79the adult online entertainment industrydered the user from leaving the site (e.g., mousetrapping), and only 3percent required a credit card or other òadult checkó to proceed past thefirst page of the site (that is, most sites allow the user to take a òfreepreviewó in which some additional content is provided).153.4what the future may hold3.4.1the structural evolution of the industrya commonly occurring development path in many industries is oneof innovation, followed by imitation, and then by shakeout.16 in theinnovation phase, one or a few parties find new ways to profit frominnovationñthey provide a previously unavailable product or service forwhich there is demand at prices that are sufficient to earn a profit. in theimitation phase, a host of other parties copy (perhaps with small variants)the ideas that enabled the first innovators to succeed. imitation and thecreation of òcopycató enterprises continue until the market is saturatedand cannot support additional entries into the market. shakeout is theresult, in which a large number of firms (which may be the first innovators or the copycats) give up the business and others consolidate, resulting in a much smaller number of firms each with larger shares of themarket. these larger firms are seriously in the business and are likely toadapt to new business circumstances (e.g., markets, regulatory environment) rather than to leave the business.since perhaps the mid1990s (when the world wide web began togrow at a rapid rate), the proliferation of adult web sites suggests that theadult online industry has been in an imitation phase. if the industrycontinues on the trajectory described above, a shakeout in the industry islikely to occur in the future. if so, the remaining firms are likely to demonstrate a higher degree of corporate responsibilityñand that responsibility may well include more serious attempts at differentiating childrenfrom adults in giving access to their products and services.3.4.2increased regulationwhat might a more òresponsibleó adult online industry involve? thefollowing sketch is derived from conversations with representatives frombusinesses that are likely to become the more established responsible15daniel orr and josephine ferrignostack. 2001. òchildproofing on the world wideweb: a survey of adult webservers,ó jurimetrics 41(4, summer): 465475.16see, for example, f.m. scherer and david ross, 1990, industrial market structure andeconomic performance, houghton mifflin, boston, mass.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.80youth, pornography, and the internetcitizens described above. enterprises in this more responsible regime willnot use stolen or illegal content, will refrain from the use of fraudulentand deceptive trade practices, will have effective means for preventingfraudulent use of credit cards, and will promote widespread use of avssystems that prevent minors from being able to view sexually explicitòteaseró images. noting that all schemes for protection of minors involvea tradeoff between the need to inform a potential consumer of the content that is being offered against the risk of exposing minors to overlyexplicit material, home pages (i.e., the page accessible to users withoutgoing through an adult verification check) could contain textual descriptions only or some pictorial content that is obscured in the way that thecover of an adult magazine is obscured when displayed on the newsstand. such magazine covers may contain suggestive images, but opaqueplastic masks essentially everything except the head/face of the covermodels. such obscuration is much more complete than the token blurringthat occurs on many adult web sites covering just the genitals, but nevertheless providing a sense of what is inside. furthermore, while greaterregulation may not be desirable from the standpoint of the industry, responsible firms in the adult online industry appear to be willing to shoulder some regulatory burden as part of the cost of doing business to keepminors away from their services.one potentially important development in the industry occurred inoctober 2000, when the federal trade commission took action againstseven major firms in the industry for unfair and deceptive trade practices(discussed in chapter 4). a second occurred in october 2001 in which ittook action against a party that used misspellings of common web sitesnot oriented to adult entertainment to draw traffic and that engaged inòmousetrappingó of users.17 a third occurred in november 2001, in whicha number of adult entertainment firms on the internet paid $30 million infines in response to ftc charges that they illegally billed thousands ofconsumers for services that were advertised as òfreeó and billed otherconsumers who never visited the web sites at all. in addition, the settlement bars the illegal practices in the future and requires that the defendants post a bond before they are allowed to continue to market adultentertainment on the internet.18 the longterm meaning of such actionsfor the industry is as yet unclear, but coupled with a new administration,it may suggest that the adult industry will be feeling increased pressure inthe future. such pressures may also include increased prosecutory effortsunder obscenity statutes.17see <http://www.ftc.gov/opa/2001/10/cupcake.htm>.18see <http://www.ftc.gov/opa/2001/11/crescentstlmt.htm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.81the adult online entertainment industrythere are many paths toward a more responsible industry. one involves, of course, law and regulation that prohibit or mandate certainkinds of behavior. however, since explicit regulation is often quite onerous, businesses in an industry that is subject to regulation may have strongincentives to selfregulateñthat is, to adopt codes of behavior to ward offthe threat of explicit regulation.19 whether selfregulation will characterize the path of the adult online industry remains to be seen, but it is likelyto depend on the occurrence of a shakeout that leads to substantial consolidation in the industry and trade groups with influence over a sufficiently large number of individual firms in the business.3.4.3future products and servicestoday, the vast majority of online adult content consists of still images. the future will bring a greater emphasis on movie content and onstreaming, live video content as highspeed internet connections becomegenerally available to consumers outside the workplace. in 2000, interactive content with live òtour guidesó (i.e., a live narrator) was a businessmodel that was being investigated in partnership by live entertainmentgroup and flynt digital media. in addition, a greater degree of nichemarketing is to be expected (as discussed below in section 3.5). and,given the increasing popularity of computergenerated imagery of nearphotographic quality, a mix of real and synthetic images may becomemore common in the future.content for transmittal to devices other than computers will becomemore common as well. for example, playboy will soon begin to offerimages for display on personal digital assistants (e.g., palm pilots).20haptic (touchsensitive) content is not yet, and may not be, a productpursued by the industry. however, a variety of companies manufactureproducts that are intended to provide a tactile counterpart to the visualsexual experience. these products are connected to a computer interfacethat controls the location, relative force, and degree of stimulation. actions are initiated by a human being at some other location, by the userclicking on certain sections of a web page, or even a digitally presentedmovie. the products include devices that are intended to stimulate auserõs genitalia, realistic lifesize dolls with computerdriven actuators in19for a discussion of selfregulation within a broader statutory framework, see computerscience and telecommunications board, national research council, 2001, global networksand local values, national academy press, washington, d.c.20see <http://computerworld.com/nlt/1 percent2c3590 percent2cnav47sto66802nltpm percent2c00.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.82youth, pornography, and the internetcertain locations, and body suits capable of electronically stimulating auserõs erogenous zones.21whether or not haptic content will become widely available in thenear future is unclear, and a number of technological and economic barriers stand in the way; these barriers include technological complexity, lagtimes in haptic interactions, the difficulty of plausible haptic rendering ofeven simple sensations, and the daunting economics today of producinglarge numbers of small actuators.3.5industry structure, product differentiation,and aggressive promotionaccording to testimony from representatives of the adult online industry, minors are not a focus of their marketing efforts. indeed, theyreported that because minors for the most part cannot purchase subscriptions, targeting minors would make no economic sense for them (andindeed would be a waste of resources).nevertheless, in a saturated market with many firms, there are strongincentives for firms to be increasingly aggressive in their marketing efforts (absent any counterpressures). thus, while the adult industry maynot go out of its way to target minors, an aggressive marketing campaignon the internet that seeks to exclude minors will be more expensive thanone that is fully inclusive, and hence much of the adult industry does notmake any particular effort to exclude minors from receiving or accessingits promotional materials, and exposing some children to its materials isan inevitable byproduct of its business practices. a firm that did makespecial efforts to exclude minors would place itself at a financial disadvantage because of the extra expense involved. it would also limit itsadult audience to a greater degree than a firm that did not make suchefforts, because any attempt to exclude minors would inevitably excludesome adults as well.such considerations are also likely to play a role in the evolution of thecontent offered by the industry. for example, the committee heard fromwellestablished firms in the industry that noted that adult web sites werebecoming increasingly specialized to accommodate any imaginable sexualpreference or taste (including those that might be regarded as more òextremeó), and that predicted that marketing to these various sexual ònichesówould be the route to growth in the future. indeed, it is possible to seeintimations of this prediction today. one can find with reasonable easesites whose sexual content depicts primarily older women, gay and lesbian21a short survey of such devices can be found online at <http://www.stanford.edu/~ereyna/pornsite2/main.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.83the adult online entertainment industrysex, women with large breasts, sex with animals, bondage, and anythingelse one might desire.22 this phenomenon is explained by the incentives ina crowded market to differentiate oneõs particular web site from all of therest.these comments should not be taken to imply that no adult web siteoperator takes precautions against exposing minors to its products. on thecontrary, there are a variety that doñand some of them testified to the committee. but the committee took testimony from and interviewed only individualswho represented wellestablished firms in the industry, and was unsuccessfulin its attempts to hear from smaller òmom and popó entrepreneurs. evenamong these latter firms, there are some that do take such precautions. nevertheless, the committee believes that a smalltime entrepreneur is more likelythan a wellestablished firm to fail to take such precautions.note also that the highly fragmented structure of the industry increases significantly the difficulty of successful selfregulation. successful selfregulation is commonly associated with the existence of a smallnumber of firms that control a very large fraction of the market and whosebehavior can be coordinated in a reasonable manner. this condition doesnot apply to the adult online industry.finally, as in defining òinappropriate sexually explicit material,ó different people will have different definitions of actions that should countas òtaking precautions.ó there are two aspects to the home page that auser sees when visiting a web site. the first is content: some possibilitiesfor site content include uncensored sexually explicit images; sexually explicit images with strategically placed blurrings or black spots; imagesthat are merely suggestive but not sexually explicit; text that describes thecontent of the rest of the web site; and/or text that tells the user to leaveif he or she is a minor. the second is navigation: some possibilitiesinclude links that allow the user to see other pages on the site only withpayment, links that allow the user to see some other pages on the sitewithout payment, and/or links to other web sites.a site whose home page included uncensored sexually explicit images and links allowing the user to see other pages on the site withoutpayment is clearly not taking precautions against minors viewing sexually explicit materialñand there are many such sites available on theinternet. but there is a range of precautions that can be taken, and noobjective standard for òwhat is enough.ó some of these precautions include offering a textonly page describing the contents of the site in general terms and a warning that one must not be a minor to proceed further.however, nothing prevents a site taking such precautions from also providing free entry to sexually explicit imagery.22note that such specialization is not limited to sexual content.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.84a variety of legal issues come into play in efforts to protect childrenfrom inappropriate sexually explicit material on the internet. the u.s.constitution, state and federal statutes, and regulations issued by executive branch agencies all play important roles. in addition, the threat oflaw and regulation can also push the regulated parties into taking unmandated actions that they would not otherwise take.4.1the first amendment4.1.1first principlesthe first amendment states that òcongress shall make no law abridging the freedom of speech or of the press.ó through a complex process ofconstitutional amendment and judicial interpretation, over the past 150years the constitution has come to mean that ògovernment shall make nolaw abridging the freedom of speechóñthat is, the first amendment restricts the actions not only of the congress, but also of the president, thestate of montana, the city of pittsburgh, the university of nebraska, andpolice officers in decatur.on the other hand, like other provisions of the constitution, the firstamendment restricts only the government. it does not restrict privateindividuals. thus, a private individual cannot be said to unconstitutionallyòabridgeó another private individualõs òfreedom of speech and press.óonly the government, or its agents, can be charged with violating the firstamendment.4legal and regulatory issuesyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.85legal and regulatory issuesto give meaning to the first amendment, scholars have identified threeprimary reasons for giving constitutional protection to free expression.first, freedom of speech and press is a necessary corollary of selfgovernance. in a selfgoverning society, it is the citizens and not thegovernment who ultimately must decide on issues of public policy. toexercise this responsibility effectively, citizens must have access to theentire spectrum of information, opinions, and ideas, without interferencefrom the government.second, in the words of justice oliver wendell holmes, òthe best testof truth is the power of the thought to get itself accepted in the competition of the market.ó the idea here is that in all areas of decision making,reaching far beyond the political, and including such questions as whetherto marry, or whether to have children, or whether to go to collegeñthebest way of reaching the best decisions for both the individual and thecommunity is to allow all ideas and opinions to contest in a free and openencounter, without interference from the government.third, freedom of expression is guaranteed as a means of ensuringindividual selffulfillment. the notion here is that, as, human beings, wehave a fundamental need to speak our minds, to express our emotionsand desires, and to create and to learn from one another. the constitutional protection of free expression is an essential adjunct of ensuring ourcommon humanity and the opportunity for individual development.these three bases for providing constitutional protection to the freedom of speech and press are not always consistent with one another andsometimes point in different directions. but, in very general terms, theystate the primary values that the first amendment is thought to serve.building on these values, the supreme court has identified severalvery basic principles that have shaped its interpretation and applicationof the first amendment. three such principles are most directly relevantto the issues of interest to this committee:¥first, the supreme court has held that the government cannot constitutionally restrict speech because the speech advocates ideas, opinions,or values that the government (or perhaps more accurately the majority ofcitizens) believe to be òwrongó or òimproper.ó thus, for example, thegovernment cannot constitutionally prohibit speech calling for the legalrepeal of the draft on the ground that such expression might persuade thepublic to vote unwisely to end the draft, even if the government profoundly believes that the draft is a good thing and that it is essential to ournational welfare. the explanation here is simple: under the first amendment, it is for the citizens themselves to make such decisions, after hearing all the arguments; it is not for the governmentñor for the majorityñto prevent such decisions by shutting off debate.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.86youth, pornography, and the internet¥second, the court has generally held that, except in the most extraordinary circumstances, the government cannot constitutionally restrictspeech because the ideas expressed might cause readers or listeners toengage in unlawful or otherwise socially undesirable conduct. for example, the government cannot prohibit opposition to the draft on theground that such expression might cause others to refuse induction oreven to blow up induction centers. indeed, although the court has oftensaid that such speech can be restricted if it creates a òclear and presentdangeró of grave harm, in fact the court has not upheld a governmentaleffort to restrict speech on this basis for some 50 years.¥third, the court has generally held that the second principle isinapplicable to specific categories of speech that the court has definedas having only òlowó first amendment value. that is, as the court explained some 60 years ago:1there are certain well defined and narrowly limited classes of speech,[such as the obscene and the libelous, that] are no essential part of anyexposition of ideas and are of such slight social value as a step to truththat any benefit that may be derived from them is clearly outweighed bythe social interest in order and morality.for these categories of expression, which include not only the obscene and the libelous, but also fighting words, commercial advertising,express incitement, and threats, the court has held that some forms ofgovernment regulation are permissible.these are the three basic principles that most directly informed thecommitteeõs work. they are not exhaustiveñthey do not deal with a hostof other first amendment issues that are largely beyond the bounds ofthe committeeõs concern. but they helped frame most of the questions thecommittee considered concerning the regulation of sexually explicit materials on the internet.4.1.2the first amendment, pornography, and obscenityhow does the concept of òpornographyó square with the firstamendment? it is important to note that there is a potentially confusingissue of terminology. historically, the term òpornographyó has been usedin at least four different ways. first, the terms òobscenityó and òpornographyó traditionally were used interchangeably. second, beginning about20 years ago, the term òpornographyó began to be used by feminist scholars to refer to a concept quite distinct from the legal concept of òobscenityó; this feminist concept focused specifically on sexually explicit mate1chaplinsky v. new hampshire, 315 u.s. 568 (1942).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.87legal and regulatory issuesrial harmful to women. third, there is the concept of child pornography,which deals with a very specific problem involving the abuse of childrenin order to make certain kinds of sexually explicit material. fourth, theterm òpornographyó is often used as a catchall synonym for the genericidea of òsexually explicit material,ó especially that intended to createsexual arousal. for the sake of clarity, it is important to note that the termòpornographyó does not have a legal meaning under the first amendment. to avoid confusion, the committee therefore focuses on the threedistinct concepts of òobscenity,ó òchild pornography,ó and òsexually explicit material.óhow does the concept of òobscenityó square with the first amendment? throughout the first half of the 20th century, it was generallyassumed that the first amendment posed no barrier to the suppression ofobscene expression. the assumption was that obscene expression is ofonly òlowó first amendment value and can therefore be regulated morereadily than other forms of expression.the supreme court did not have occasion to rule on the constitutionality of antiobscenity legislation until its 1957 decision in roth v. unitedstates.2 the court reasoned as follows:all ideas having even the slightest redeeming social importanceñunorthodox ideas, controversial ideas, even ideas hateful to the prevailingclimate of opinionñhave the full protection of the [first amendment].but implicit in the history of the first amendment is the rejection ofobscenity as utterly without redeeming social importance. indeed, it isapparent that obscenity, like libel, is outside the protection intended forspeech and press. accordingly, obscene material may be suppressedwithout proof that it will create a clear and present danger of antisocialconduct.òhowever, sex and obscenity,ó the court continued,are not synonymous. obscene material is material which deals with sexin a manner appealing to prurient interest. the portrayal of sex, forexample in art, literature, and scientific works, is not itself sufficientreason to deny material constitutional protection. sex, a great and mysterious motivating force in human life, has indisputably been a subjectof absorbing interest to humankind though the ages; it is one of the vitalproblems of human interest and public concern. it is therefore essentialthat the standards for judging obscenity safeguard the protection of freedom of speech and press for material which does not treat sex in a manner appealing to prurient interest. the proper test is whether to theaverage person, applying contemporary community standards, the dom2354 u.s. 476 (1957).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.88youth, pornography, and the internetinant theme of the material taken as a whole appeals to the prurientinterest.thus, the specific holding of roth was that if material meets the definition of obscenity, it is not protected by the first amendment and maythus be restricted without any showing that its sale, exhibition, or distribution will cause any particular harm to any particular person.for the next 17 years, the court wrestled with the problem of refiningthe roth definition of obscenity, which proved difficult because of itsinherent subjectivity. it was in this era that justice potter stewart offeredhis famous quip that òi canõt define it [obscenity], but i know it when i seeit.ó as justice stewart understood, this observation did not bode well forhaving a clear and consistently applied constitutional standard.in 1973, the court revisited the question. in miller v. california,3 thecourt reaffirmed the idea that obscene expression is of such òlowó constitutional value that it is outside the protection of the first amendment.however, the court redefined the concept as having three components.miller concluded that, to be obscene, a work, taken as a whole, and judgedby contemporary community standards, must appeal to the prurient interest in sex, must depict sexual conduct in a patently offensive manner,and must lack serious literary, artistic, political, and scientific value.this definition has now been in place for the past quartercentury.under this regime, and as community standards have tended to evolvetoward a greater degree of acceptance of sexually oriented expression, itis generally thought today that only the most hardcore forms of sexuallyexplicit material are sufficient to satisfy the constitutional definition ofobscenity. as of this writing (may 2002), prosecutions for obscenity arerare though not unheard of at both the federal and local level.nonetheless, it remains the case that the government, consistent withthe first amendment as it has been interpreted, may prohibit the sale,exhibition, or distribution of obscene material, and there is no constitutional obstacle to a more aggressive policy of prosecuting obscenity on theinternet, subject to the caveats below.one caveat is the narrowness of the definition of obscenity, as described above. moreover, enforcing an antiobscenity prohibition on theinternet presents three additional problems. first, because the definitionof obscenity turns on contemporary community standards, there is considerable uncertainty about how one defines the relevant òcommunityófor purposes of the internet. for example, if x creates a sexually explicitweb site in amsterdam that y views in st. louis, what is the relevant3413 u.s. 15 (1973).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.89legal and regulatory issuescommunityñamsterdam? st. louis? is the òinternetó itself a òcommunityó for these purposes?4second, there is often a tricky problem of assigning legal responsibility. for example, suppose x makes a threat over the telephone. canat&t be held responsible for this criminal use of its phone line? becauseat&t is legally a òcommon carrier,ó the answer is no. however, thesame type of question can be asked about obscenity on the internet. if xputs obscene material on a web site that y views through, say, americaonline, can aol be held legally responsible for xõs conduct? for internet service providers, the law is evolving in this area.5third, content transmitted through the internet presents the issue ofwhat counts as òwork as a whole.ó in the physical world, the work as awhole would include a book, film, or magazine. in an online environment, is the òwork as a wholeó the web page on which an image resides,or the entire web site of which it is a part? no court cases have addressedthis point to the best of the committeeõs knowledge.4.1.3the first amendment and protecting childrenfrom exposure to sexually explicit materialas already noted, even if obscenity can constitutionally be prohibitedon the internet, this does not solve the broader problem of the exposure ofchildren to sexually explicit material because of the very narrow definition of obscenity required by the constitution. this raises the question ofwhether there are other steps the government can take, consistent withthe first amendment, to protect children from nonobscene, sexually explicit material.in recognition of the special problems posed by the exposure of children to such material, the supreme court has recognized the concept ofòvariable obscenity.ó thus, in its 1968 decision in ginsberg v. new york,6 thecourt recognized that the òpower of the state to control the conduct of4indeed, one of the primary challenges posed by the internet is to the traditional association of geographical colocation with the definition of community. to date, most constructions of òcommunityó have, in practice, reduced to some kind of geographical delineationto identify the community in question.5some analysts argue, for example, that cyberspace calls for the creation of new law andlegal institutions that apply specifically to it. see, for example, david r. johnson and davidg. post, 1996, òlaw and bordersñthe rise of law in cyberspace,ó stanford law review 48:1367. others challenge this view, arguing that it underestimates the potential of traditionallegal tools and technology to resolve the multijurisdictional regulatory problems impliedby cyberspace. see, for example, jack l. goldsmith, 1998, òagainst cyberanarchy,ó university of chicago law review 65(fall): 1199.6390 u.s. 629 (1968).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.90youth, pornography, and the internetchildren reaches beyond the scope of its authority over adults,ó that theclaim of parents òto direct the rearing of their children is basic in the structure of our society,ó and that the state òhas an independent interest in thewellbeing of its youth.ó with these factors in mind, the court held inginsberg that the government can constitutionally prohibit òthe sale to minors . . . of material defined to be obscene on the basis of its appeal to themwhether or not it would be obscene to adults.ó in other words, the government can prohibit children from having access to certain types of sexuallyexplicit material that it cannot constitutionally ban for adults. (recent legislation (e.g., the copa, discussed below) defined such speech as òharmfulto minors.ó in this report, the phrase òobscene with respect to minorsó oròobscene for minorsó is used interchangeably with òharmful to minors.ó)although this distinction compounds still further the problems of vagueness and subjectivity inherent in the very concept of obscenityñby nowcreating multiple definitions of obscenityñit is also a useful tool, for it is thedoctrine of variable obscenity that enables the government constitutionally toprohibit minors from buying, renting, or viewing certain sexually explicitmovies, magazines, or books that would not be obscene for adults.the key limitation of this doctrine, however, is that it works best(perhaps only) in those situations in which it is possible to individuate theaudienceñthat is, to separate the children from the adults. thus, thedoctrine of variable obscenity works reasonably well for movie theaters,video rental shops, and book stores, but not for television and radio. forin those latter means of communication, it is not as easy to separate thechildren from the adults. and as the supreme court recognized in its1957 decision in butler v. michigan,7 the government òmay not reduce theadult population . . . to reading only what is fit for children.óto understand this precept, it is useful to consider several recentdecisions of the supreme court. in sable communications v. fcc,8 decidedin 1989, the court unanimously held unconstitutional a federal statuteprohibiting òindecentó commercial telephone messagesñsocalled òdialapornó services. the court said that if the government wants to protectchildren in this context, it must do so by technical means rather than by atotal ban on the transmission of such messages, for although some limitednumbers of children might be able to defeat these devices, a prohibitionwould have the impermissible effect of òlimiting the content of adulttelephone conversations to that which is suitable for children to hear.óin reno v. aclu,9 decided in 1997, the court unanimously held unconstitutional the communications decency act of 1996, which prohib7352 u.s. 380 (1957).8492 u.s. 115 (1989).9521 u.s. 844 (1997).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.91legal and regulatory issuesited any person from making any òindecentó communication over theinternet with knowledge that a recipient might be under the age of 18.òindecentó was defined in the statute as expression that òdepicts or describes, in terms patently offensive as measured by contemporary community standards, sexual or excretory activities or organs.óalthough acknowledging the importance of the governmentõs interest òin protecting children from harmful materials,ó the court reaffirmedthat that òinterest does not justify an unnecessarily broad suppression ofspeech addressed to adults,ó and that the government òmay not reducethe adult population to only what is fit for children.óthe court suggested that the government should explore less speechrestrictive means of serving this interest, such as requiring indecent material to be òtaggedó in a way that facilitates parental control of materialentering the home, exempting from regulation indecent messages withartistic or educational value, and perhaps regulating only some portionsof the internetñsuch as commercial web sitesñwhile leaving unregulated noncommercial uses of the internet, such as chat rooms.the lesson of these decisions10 is this: outside the realm of speech thatis constitutionally obscene, the government may not prohibit òindecentóor òoffensiveó or òsexually explicitó or òprofaneó speech on the internetin order to protect children, unless the speech is obscene with respect tominors and government regulation does not unduly interfere with therights of adults to have access to such material. the challenge is thus to10see also the following supreme court cases. in cohen v. california, 403 u.s. 15 (1971),the court rejected the idea that profanity could be analogized to obscenity as a form ofòlowvalueó speech and dismissed the notion that such language, which can serve a usefulrole in public debate, can be prohibited merely because it is offensive to others. in fcc v.pacifica foundation, 438 u.s. 726 (1978), the court upheld the constitutionality of a federalcommunications commission order that a radio station had impermissibly broadcast indecent material when it broadcast in the middle of the day a satirical monologue that involved[the] òseven words you cannot say on the public airwaves.ó in doing so, the court suggested some latitude for the regulation of offensive but nonobscene speech in order toshield children, even at some intrusion on what otherwise would be the rights of adults. inerznoznik v. city of jacksonville, 422 u.s. 205 (1975), the court held that a city could notconstitutionally prohibit drivein movie theaters whose screens were visible to the publicfrom exhibiting movies that contain nudity, even if the goal was to protect children fromexposure to such scenes. in denver area v. fcc, 422 u.s. 205 (1996), the court held that thefcc could not constitutionally require cable operators to segregate òindecentó programming on a single, blocked channel and to unblock that channel only on a subscriberõs written request. in united states v. playboy entertainment, 529 u.s. 803 (2000), 120 s. ct. 1878(2000), the court held unconstitutional a provision of the 1996 federal telecommunicationsact that required cable operators who provide channels devoted òprimarily to sexuallyoriented programmingó either to limit their transmission of such channels to between 10:00p.m. and 6:00 a.m. or to òfully scrambleó those channels so that they cannot even inadvertently òbleed throughó to those households that do not want them.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.92youth, pornography, and the internetdevise mechanisms that reconcile these two powerfully competing interests, where the court has made clear the strong first amendment presumption that the governmentõs legitimate interests in protecting children will have to yield to the constitutional interests of adults, to theextent that those interests cannot otherwise be reconciled.4.1.4the first amendment rights of minorsbecause the first amendment relates only to government action, children have no first amendment rights against their parents. thus, if aparent prevents a child from reading a book or watching a movie, thechild cannot sue the parent for violating the first amendment. but minors òare ôpersonsõ under our constitution. . . . possessed of fundamentalrights which the state must respectó11 and òare entitled to a significantmeasure of first amendment protection.ó12moreover, a constitutional issue can arise if the government intrudesin the parentchild relationship. for example, if the government passed alaw prohibiting any person from permitting a minor to view a movie thatincludes nudity without the written permission of the minorõs parent, acourt would likely hold such a law unconstitutional, at least as applied toolder minors, and especially if the nudity were not further qualified.(note, however, that materials deemed to be illegalñthat is, to be childpornography or obscenityñdo not enjoy first amendment protection,either for adults or for minors. thus, even if a minor has permission fromhis/her parents to obtain child pornography or obscenity, he or she doesnot have a first amendment right to do so.)it is important to note that the constitutionality of any particular regulation of the speech rights of minors may turn on the age of the particularminor in question. indeed, as this report discusses in chapter 5, minorsrange from 0 to 18 years old, and there are large developmental differences between an 8yearold and a 17yearold. the supreme court hasheld that òthe strength of the governmentõs interest in protecting minorsis not equally strong throughout the [age] coverage.ó13 the constitutionalrights of minors, including their first amendment rights, get stronger asthey grow older. as the court has said, òconstitutional rights do not11tinker v. des moines independent community school district, 393 u.s. 503, 511 (1969); seeplanned parenthood v. casey, 505 u.s. 833, 899 (1992), parental consent statute must containmethod by which minor can obtain abortion without parental consent; see in re gault, 387u.s. 1, 13 (1967), minorsõ right to criminal due process.12erznoznik v. city of jacksonville, 422 u.s. 205, 212213 (1975) (citation omitted).13reno, 521 u.s. at 878 (using examples of 17yearolds); american booksellers association v.webb, 919 f.2d 1493, 150405 (11th cir. 1990); american booksellers association v. virginia, 882f.2d 125, 127 (4th cir. 1989).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.93legal and regulatory issuesmature and come into being magically only when one attains the statedefined age of majority,ó14 and these rights ripen at different times and indifferent contexts.the precise contours of the first amendment rights of minors, evenacknowledging that they may well vary with age and maturity, are uncertain. the supreme court has held that certain minors have constitutionalrights in certain circumstances that trump a general deference to parentalauthority, for example, in the case of a mature minor seeking an abortion15 or privacy rights about the use of contraception.16 further, it isarguable that mature minors have a first amendment right to receiveinformation relevant to the exercise of these substantive rights. whetherand in what circumstances a minor has a first amendment right of accessto adultoriented entertainment web sites remains an open question. buteven if minors do not themselves have a constitutional right to accesssuch material, the government cannot unduly burden the rights of adultsto such material in order to keep it away from children.4.1.5the first amendment and child pornographyanother facet of protecting children concerns the issue of child pornography. here, the primary concern is not the exposure of children tosexually explicit material, but the use (or, possibly, the apparent use) ofchildren to make such material. in new york v. ferber,17 the supremecourt upheld the constitutionality of a state statute that prohibited anyperson from knowingly producing, promoting, directing, exhibiting, orselling any material depicting a òsexual performanceó by a child underthe age of 16. the statute defined òsexual performanceó as any performance that includes òactual or simulated sexual intercourse, deviatesexual intercourse, sexual bestiality, masturbation, sadomasochisticabuse, or lewd exhibition of the genitals.ó the court explained that, likeobscenity, child pornography is of only òlowó first amendment valueand that the òuse of childrenó in such materials òis harmful to the physi14planned parenthood of central missouri v. danforth, 428 u.s. 52, 74 (1976), minorsõ right toabortion.15id. at 6403; planned parenthood v. casey, 505 u.s. 833, 899 (1992); lambert v. wicklund, 520u.s. 292 (1997).16see carey v. population services international, 431 u.s. 678 (1977) (plurality opinion).although carey was a plurality opinion, the holding that teenagers have privacy rightsregarding procreation commanded five votes. see 431 u.s. at 681 (plurality opinion) (justice brennan, joined by justices stewart, marshall, and blackmun); id. at 693, 702 (justicewhite, concurring) (agreeing with plurality in result and including òwith respect to partivó in which plurality recognized privacy interests of minors in contraception).17458 u.s. 747 (1982).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.94youth, pornography, and the internetological, emotional, and mental health of the child.ó the court addedthat, unlike obscenity, child pornography does not have to meet all of therequirements of miller.4.1.6the first amendment in public librariesthe general principles of the first amendment are designed primarily for those circumstances in which the government attempts to regulatethe free speech rights of individuals in the larger society. those principles may apply differently in special contexts, such as public librariesand schools. in public libraries, for example, the government has limitedresources. it cannot buy all books. it must therefore make choices. inmaking those choices, it inevitably must decide which books are mostnecessary and most appropriate for the particular collection. this givesthe government, in the form of the library board or the librarian, theauthority and the responsibility to make decisions based on content that itcould not make in more general regulations of public discourse. forexample, although the government cannot constitutionally prohibit allbooks on any subject but art history, it can constitutionally create a librarydedicated only to art history. and although the government cannot constitutionally prohibit all books that are not appropriate for children, it canconstitutionally create a library dedicated only to childrenõs books.on the other hand, even a public library is not free to engage inòviewpoint discrimination.ó for example, in board of education of islandtrees union free school district v. pico,18 the members of a public schoolboard of education decided to remove from the school library certainbooks, including soul on ice by eldridge cleaver and slaughterhouse fiveby kurt vonnegut, because they were òimproper fare for children.ó theboard members described the books as òantiamerican, antichristian,antisemitic, and just plain filthy.ó the supreme court held that thisaction would violate the first amendment if the intent of the board members was to deny òaccess to ideasó with which they òdisagreed.ó19it should be noted that an important reason for granting a publiclibrary broad (but not absolute) discretion to decide which books to include in its collection is the fact of limited resources. this fact is notpresent in the same way in the internet context. to the contrary, in theinternet context, where filters may be at issue, it will generally cost more18457 u.s. 853 (1982).19as a matter of legal precedent, pico has specific relevance to public school libraries;however, the applicability of its logic to other settings such as public libraries has yet to bedetermined.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.95legal and regulatory issuesto reduce rather than to expand the òcollection.ó it is unclear how thiswill affect the constitutional calculus.20another facet of the public library situation concerns the appropriaterole of parents. for example, although a public library cannot constitutionally select which books it will make available to students on the basisof whether the library officials agree or disagree with the ideas presentedin particular books, it presumably could decline to lend books to minors(at least younger minors) without parental permission, as long as thelibrary acts in a contentneutral manner itself. that is, a library couldinsist on parental permission for younger minors to borrow any bookfrom the library, but probably could not limit this requirement only to, forexample, òracistó books or books about scientology.4.1.7the first amendment in public schoolsin the context of public schools, the supreme court has expresslyrecognized, in tinker v. des moines school district,21 that neither òstudentsnor teachers shed their constitutional rights to freedom of speech or expression at the schoolhouse gate.ó on the other hand, the court has alsorecognized that, in light of òthe special characteristics of the school environment,ó public school officials may restrict expression that would òmaterially and substantially interfereó with the core activities of the school.thus, in bethel school district v. fraser,22 the court upheld a public highschoolõs decision to discipline a student for using òvulgar and lewdspeechó in a public assembly because such expression òwould underminethe schoolõs basic educational mission.ó similarly, although a publicschool may not generally deny a studentõs right to speak or to accessinformation on school grounds or through school facilities, it may restrict20for example, in mainstream loudon v. board of trustees of loudon county, 2 f. supp. 783(ed va. 1998), the court held invalid a public libraryõs use of filters (for all patrons) as anunconstitutional prior restraint. more generally, opponents of filtering in public librarieshave argued that the use of filters constitutes an unconstitutional prior restraint because thegovernment is technologically preventing the censored material from even reaching potential users. they argue that this is prior restraint because the filter relies not on the threat ofcriminal punishment after the speech takes place, but on an actual blocking of the speechitself. for relevant supreme court decisions, see freedman v. maryland, 380 u.s. 51 (1965),holding that a movie censorship board that makes decisions about what may or may not beshown publicly is constitutionally permissible if the board is screening for obscenity, butonly if the board is required immediately to go to court to obtain a prompt judicial determination that the movie is in fact obscene; and southeastern promotions v. conrad, 420 u.s. 546(1975), holding that a city manager would be required to abide by the freedman v. marylandrequirements.21393 u.s. 503 (1969).22478 u.s. 675 (1986).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.96youth, pornography, and the internetexpression or access to information that òwould undermine the schoolõsbasic educational mission,ó so long as school officials do not attempt todeny access to ideas because they disagree with them.4.1.8the first amendment and the commercialadvertising of sexually explicit materialthe supreme court has held that commercial advertising may insome circumstances be regulated more readily than other forms of expression. for example, the court has permitted government to regulatesuch advertising when it is false or deceptive in circumstances in whichsimilar regulation of political expression would not be permitted. theinterestingñand openñquestion in this context is whether the government can constitutionally regulate or even prohibit the commercial advertising of constitutionally protected sexually explicit material. in general,the court has suggested that such regulations would not be constitutionally permissible. in bolger v. youngs drug products corp.,23 for example,the court held unconstitutional a federal statute prohibiting the mailingof unsolicited advertisements for contraceptives because the interest inshielding òrecipients from materials that they are likely to find offensiveóis not sufficiently substantial to justify the suppression of òprotectedspeech.óthis does not mean that all restrictions on the emailing of unsolicitedcommercial advertisements for sexually explicit web sites would necessarily be unconstitutional. for example, such a restriction might arguablybe distinguishable from bolger if it focused specifically on material thatis obscene for minors under ginsberg. moreover, a restriction on theemailing of all unsolicited commercial advertisements might be constitutional on the theory that it is justified not by the offensiveness of anyparticular material but because this practice has the potential to overwhelm electronic mailboxes and thus to discourage the use of this valuable means of communication.4.2relevant statutes and common law4.2.1federal obscenity statutesfederal obscenity statutes restrict the use of computers and the internet to distribute obscene materials.24 section 1465 of title 18 of the u.s.code prohibits the use of any means of interstate or foreign commerce or23463 u.s. 60 (1983).24chapter 71 of title 18 (criminal code) contains the federal obscenity statutes.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.97legal and regulatory issuesan interactive computer service to sell or distribute obscenity, and thisprohibition applies to adults as well as to children. section 1470 of title18 of the u.s. code prohibits the use of any facility or means of interstateor foreign commerce to transfer obscene materials to someone under theage of 16 if the person knows that the recipient is under the age of 16.whether material is within the restrictions of either of these statutes depends on whether a reasonable person in the community would interpretthe work, taken as a whole, to appeal to the prurient interest; whether thework, as a whole, is patently offensive; and whether the work, as a wholeand in context, lacks serious literary, artistic, political, or scientific value.254.2.2child pornography statutesin general, chapter 110 of title 18 provides for civil and criminalpenalties for the production, possession, distribution, and sale of childpornography. historically, child pornography has been defined as a visual depiction involving the use of an individual under 18 engaging insexually explicit conduct (18 u.s.c. 2256, chapter 110).26 the child pornography prevention act of 1996 (cppa) amended this definition to include three additional elements: a visual depiction òthat is or appears tobe of a minor engaging in sexually explicit conduct,ó a visual depictionthat òhas been created, adapted, or modified to appear that an identifiableminor is engaging in sexually explicit conduct,ó or a visual depiction thatis òadvertised, promoted, presented, described, or distributed in such amanner that conveys the impression that the material is or contains avisual depiction of a minor engaging in sexually explicit conduct.ó thecppa also expanded the definition of òdistributionó or òreceiptó of suchdepictions through interstate or foreign commerce to include computerchannels.27on april 16, 2002, the supreme court ruled that the provisions of thecppa regarding the portion of the definition that refers to òappearing tobe a minor engaging in sexually explicit conductó were unconstitutional.box 4.1 describes the courtõs reasoning on this decision.25eckstein v. cullen, 803 f. supp. 1107 (ed va. 1992).26òsexually explicit conductõõ is defined as òactual or simulated sexual intercourse, including genitalgenital, oralgenital, analgenital, or oralanal, whether between persons ofthe same or opposite sex; bestiality; masturbation; sadistic or masochistic abuse; or lascivious exhibition of the genitals or pubic area of any person.ó27p.l. 104208, title 1, ¤ 121(a), 110 stat. 3009. the cppa amends 18 u.s.c. ¤ 2241, 18u.s.c. ¤ 2243, 18 u.s.c. ¤ 2251, 18 u.s.c. ¤ 2252, 18 u.s.c. ¤ 2256, and 42 u.s.c ¤ 2000(a) andadds 12 u.s.c. ¤ 2252(a). in addition, the sex crimes against children prevention act of1995 increases the baselevel penalty for creating, distributing, or receiving visual depictions that show, or purport to show, minors engaging in sexually explicit conduct (p.l. 10471, 28 u.s.c. ¤ 994 nt). the act amends 18 u.s.c. ¤ 2251(c)(1)(a) and 18 u.s.c. ¤ 2252(a).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.98youth, pornography, and the internetbox 4.1computergenerated child pornographyand the child pornography prevention actthe child pornography prevention act of 1996 (cppa) was enacted in part toaddress the challenges resulting from the technological advances in the computeraided creation and production of visual images. in particular, the cppa incorporated into the definition of child pornography òany visual depictionó that òappears tobe of a minor engaging in sexually explicit conduct.ó increasingly, graphics softwarepackages and computer animation have the capability to create òvirtualó imagesindistinguishable from photographic depictions of actual human beingsñincludingfictitious children engaged in apparently sexual activity.on april 16, 2002, in ashcroft v. free speech coalition, the supreme court heldthis part of the cppa unconstitutional. the court explained that òby prohibitingchild pornography that does not depict an actual child, the statute goes beyondferber, which distinguished child pornography from other sexually explicit speechbecause of the stateõs interest in protecting the children exploited by the productionprocess.ó the court added that òthe sexual abuse of a child is a most serious crimeand an act repugnant to the moral instincts of a decent people.ó thus, congressòmay pass valid laws to protect children from abuse, and it has.ó but òthe prospectof crime . . . by itself does not justify laws suppressing protected speech.óthe court emphasized that òwhere the images are themselves the product ofchild sexual abuse, ferber recognized that the state had an interest in stamping itoutó because the òproduction of the work, not its content, was the target of thestatute.ó òin contrast to the speech in ferber, [the] cppa prohibits speech thatrecords no crime and creates no victims by its production. virtual child pornographyis not ôintrinsically relatedõ to the sexual abuse of children, as were the materials inferber. while the government asserts that the images can lead to actual instances ofchild abuse, the causal link is contingent and indirect. the harm does not necessarilyfollow from the speech, but depends upon some unquantified potential for subsequent criminal acts.ó the court reaffirmed that òthe mere tendency of speech toencourage unlawful acts is not a sufficient reason for banning it.óthe government also defended the cppa on the ground that the existence ofvirtual child pornography will make it more difficult òto prosecute those who produce pornography by using real childrenó and that the ònecessary solutionó is toprohibit virtual as well as real child pornography. the court rejected this argument,noting that òthis analysis turns the first amendment upside down. the governmentmay not suppress lawful speech as the means to suppress unlawful speech. protected speech does not become unprotected merely because it resembles the latter.ófinally, the court made clear that the cppa does not deal with obscenity. as thecourt explained, under miller v. california, to establish that a work is obscene, òthegovernment must prove that the work, taken as a whole, appeals to the prurientinterest, is patently offensive in light of community standards, and lacks serious literary, artistic, political, or scientific value.ó the court noted that the cppa containednone of the miller requirements. in the courtõs view, this was fatal, for although òthefreedom of speech has its limits,ó the cppa reached beyond the limits of permissibleregulation.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.99legal and regulatory issuesfinally, the child protection and obscenity enforcement act of 1988and amendments of the child protection restoration and penalties enhancement act of 1990 added requirements associated with 18 u.s.c.2257. these requirements call for certain parties in the adult entertainment industry to create and maintain records that allow law enforcementauthorities to verify the names and birth dates of models and performersdepicted in sexually explicit activity if such depictions were made afternovember 1, 1990. these requirements were developed in 1988 in response to the avoidance of prosecution by producers and distributors ofchild pornography through claims of ignorance regarding a modelõs trueage.28 the recordkeeping requirements of 18 u.s.c. 2257 call for:¥records to be maintained that indicate the legal name, stage names,and all other names used by a performer, and date of birth of each performer, obtained by the producerõs examination of an appropriate identification document. for depictions made after may 26, 1992, a legible copyof the identification document examined (and a photo) are also required,and names must be indexed by the title or the identifying number of thedepiction involved.¥records to be categorized and retrievable by the name(s) of eachperformer and according to the title, number, or other similar identifier ofthe depiction in question.¥records to be available at the producerõs place of business, andmade available for inspection to the attorney general or his delegate forinspection at all reasonable times.4.2.3the communications decency actthe congressõs first attempt to regulate childrenõs access to sexuallyexplicit materials on the internet was the communications decency actof 1996 (cda).29 the cda, enacted as part of the telecommunicationsact of 1996, amended 47 u.s.c. ¤ 223 to prohibit the use of an interactivecomputer service to send or display, in a manner available to those underthe age of 18, any communication that describes or depicts sexual orexcretory activities or organs in terms that are patently offensive as measured by contemporary community standards.28the text of 18 u.s.c. 2257 and associated implementing regulations can be found onlineat <http://www.execpc.com/~xxxlaw/sec2257.html>.29p.l. 104104, title v, 47 u.s.c.s. ¤ 994 nt. the cda was enacted on october 21, 1998.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.100youth, pornography, and the internetthe supreme court, reviewing the cda, determined that the provisions of the cda relating to the dissemination of indecent or patentlyoffensive material to individuals under 18 violated the first amendment.30 the court struck down these sections of the act as overbroad andunconstitutionally vague, reasoning that the restrictions chilled protectedspeech and unduly restricted adultsõ access to constitutionally protectedmaterials.31 the court severed the provisions concerning obscene material because obscenity receives no protection under the first amendment;thus, the obscenity provisions were found not to suffer from the sameconstitutional infirmities as the provisions regulating indecent speech.another aspect of the cda that remains in force is protection forògood samaritanó blocking and screening of offensive material. prior tothe cda, a service provider that filtered certain kinds of material (e.g.,adultoriented, sexually explicit material) might have incurred liability asa publisher if its filtering of such material was not perfect. (so, for example, an isp that filtered could not be said to be acting in a òcommoncarrieró mode, and thus might have incurred some liability for the contentit made available to the end user.) the cda provided that service providers could not be held liable on account of any action voluntarily takenin good faith to restrict access to or availability of material that the provider considers to be òobscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable, whether or not such materialis constitutionally protected.ó32one consequence of this provision in the cda is that isps cannot beheld liable for deciding to refrain from carrying usenet newsgroups thatare, in its judgment, obscene, lewd, lascivious, filthy, excessively violent,harassing, or otherwise objectionable.one analyst further believes that another section of the cda absolvesschools and libraries of civil liability if students or patrons access inappropriate material. this analystõs reasoning is based on the fact that underthe cda, an òinteractive computer serviceó cannot be treated as the publisher of any information provided by another information content provider, and further that libraries and schools are providers of interactivecomputer services.3330reno v. aclu, 521 u.s. 844, 117 s. ct. 2329, 138 l. ed. 2d 874 (1997).31reno v. aclu, 521 u.s. 844, 117 s. ct. 2329, 138 l. ed. 2d 874 (1997).3247 u.s.c. 230.33nancy willard (university of oregon), the analyst, cites two cases in support of thisview. first, in zeran v. america online, inc. (129 f.3d 327 (4th cir. 1997)), the fourth circuitcourt of appeals expressly held that ò[b]y its plain language, ¤230 (a provision of the cda)creates a federal immunity to any cause of action that would make service providers liablefor information originating with a thirdparty user of the service.ó second, in kathleen r. v.city of livermore (cal. ct. app., 1st app. dist., a086349, 3/6/01), a mother of a teenage boyyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.101legal and regulatory issues4.2.4the child online protection actcongressõs next attempt to regulate minorsõ access to sexually explicitmaterial on the internet was the child online protection act (copa).34copa amended 47 u.s.c. ¤ 231 to prohibit the communication of material that is òharmful to minorsó in interstate or foreign commerce bymeans of the world wide web if it is available to minors. congressincluded provisions in copa that were designed to remedy the problemsidentified by the supreme court in the cda. specifically:¥copa defined a minor as one under the age of 17, whereas thecda defined minors as individuals under the age of 18.¥copa applied only to the world wide web, whereas the cdaapplied to all communications over the entire internet.¥copa applied only to web sites that exist for a commercial purpose, whereas the cda applied to commercial and noncommercial sitesalike. under copa, a commercial purpose is found if the siteõs operatoror owner is òengaged in the business of making such communications.óthe phrase òengaged in the businessó is defined as applying to òthe person who makes a communication, or offers to make a communication, bymeans of the world wide web, that includes any material that is harmfulto minors, devotes time, attention, or labor to such activities, as a regularcourse of such personõs trade or business, with the objective of earning aprofit as a result of such activities (although it is not necessary that theperson make a profit or that the making or offering to make such communication be the personõs sole or principal business or source of income).ó35¥whereas the cda provided a vague definition of òindecent material,ó copa restricts only material that is òharmful to minorsóñthat is,material that satisfies all three prongs of the miller36 test, as applied tominors. thus, copa restricts sexually explicit material only if (1) òtheaverage person, applying contemporary community standards, wouldfind, taking the material as a whole and with respect to minors, [that it]is designed to appeal to . . . the prurient interestó; (2) it òdepicts, describesor represents, in a manner patently offensive with respect to minors, ansued the library because her son had accessed sexually explicit pictures through the libraryõsinternet service. the case was dismissed, and the dismissal was upheld in appellate court.the appellate court found that under the cda, the library was an interactive service provider and was entitled to immunity, and noted that although the purpose of the cda wasto prevent minors from obtaining access to pornography, congress made a deliberate policychoice not to subject those providing internet access to tort liability.34p.l. 105227, div. c, title xiv, ¤ 231. copa was enacted on october 21, 1998.3547 u.s.c. ¤ 231(e)(2)(b).36miller v. california, 413 u.s. 15 (1973).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.102youth, pornography, and the internetactual or simulated sexual act or sexual contact, an actual or simulatednormal or perverted sexual act, or a lewd exhibition of the genitals orpostpubescent female breastsó; and (3) òtaken as a whole, lacks seriousliterary, artistic, political or scientific value for minors.ó37both the cda and copa provide an affirmative defense to prosecution if the defendant, in good faith, took reasonable measures to restrictaccess to regulated material, such as requiring a credit card, debit account, adult access code, or adult personal identification number, or accepting a digital certificate that verifies age. (the use of age verificationtechnologies is discussed in chapter 13.)as of this writing (may 2002), a preliminary injunction issued by theu.s. district court of the eastern district of pennsylvania (and upheld inthe u.s. court of appeals for the third circuit) currently prohibits theenforcement of copa because the court found that the standard used todetermine whether material is harmful to minors places an impermissibleburden on protected speech.38 the court explained that using communitystandards to assess the nature of material is inappropriate in the contextof material on the internet because web publishers do not have the technological ability to restrict access to their sites on the basis of visitorsõgeographical location. without this ability to restrict access on a geographical basis, web publishers must publish only materials that wouldnot be considered obscene for minors under the standards of the mostrestrictive community that might gain access to the material or subjectthemselves to potential liability if a viewer in a more restrictive community finds the material obscene. to avoid the liability that would beimposed by copa, a web publisher would have to publish only thosematerials that would not be considered obscene for minors by internetusers in the community with the most restrictive definition of obscenity.the supreme court heard oral arguments on copa in late november 2001 and is expected to render a decision by the summer of 2002.note added in proof: on may 13, 2002, the supreme court held thatcopaõs reliance on òcommunity standardsó to identify what material òisharmful to minorsó did not by itself render the statute substantially overbroad for first amendment purposes. however, it expressed no view as towhether copa suffers from substantial overbreadth for reasons other thanits use of community standards, whether the statute is unconstitutionallyvague, or whether the statute survives strict scrutiny. it directed the u.s.3747 u.s.c. ¤ 231(e)(6).38aclu v. reno, 31 f. supp. 2d 473 (ed pa. 1999). the third circuit court of appealsupheld this decision. aclu v. reno, 217 f. 3d 162 (3d cir. 2000), cert. granted, ashcroft v.aclu, 121 s. ct. 1997 (2001).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.103legal and regulatory issuescourt of appeals for the third circuit to examine these issues, and leftstanding the preliminary injunction against copaôs enforcement absentfurther action by the lower courts.394.2.5the childrenõs internet protection actin december 2000, congress enacted the childrenõs internet protection act (cipa).40 cipa took effect on april 21, 2001. cipa requiresschools and libraries that receive federal funds for internet access fromthe fccõs erate program,41 the department of education, or the instituteof museum and library services to enforce a policy of internet safety forminors that includes limiting the online activities of those under the ageof 17 through the operation of a òtechnology protection measureó thatòblocks or filters internet access to visual depictions that are obscene,child pornography, or ôharmful to minors.õó accordingly, public schoolsand public libraries that wish to receive these federal funds must installon computers that have internet access a specific technology protectionmeasure that blocks or filters access to child pornography, obscene materials, or material that is harmful to minors.42 the technology protectionmeasure must be operative with respect to obscenity and child pornography when adults are using those computers, and with respect to obscenity, child pornography, and material that is harmful to minors when minors are using those computers. (the cipa also allows, but does notrequire, giving an authorized person the ability to disable the technologyprotection measure during any use by an adult to enable access for bonafide research or other lawful purpose.)39ashcroft v. american civil liberties union, ñ u.s. ñ (2002).40p.l. 106554, ¤ 1(a)(4), 114 stat. 2763 (2001). a good summary of the provisions of cipacan be found online at <http://www.cybertelecom.org/cda/cipatext.htm#1712>.41the òerateó program was mandated by the telecommunications act of 1996. in thatprogram, phone companies contribute to a fund that the fcc administers to help finance thewiring of k12 public schools. the program has been important in enabling internet accessfor many schools. for more information, see <http://www.sl.universalservice.org/>.42one additional requirement placed on schools (but not on libraries) receiving federalfunding for internet access is that their policy of internet safety must include monitoringthe online activities of minors, though the tracking of internet use by any identifiable minoror adult user is not required. further, it is not clear whether technologies other than filtersas defined in chapter 12 will qualify as appropriate òtechnology protection measuresó;some parties have advanced the argument that according to the principles of statutoryconstruction, the use of the phrase òblock or filteró rather than simply òblockó means that adevice that òfiltersó but does not òblockó is consistent with the definition of òtechnologyprotection measure.ó since cipa does not provide a definition of the term òfilter,ó at leastone of these parties has argued that products that rely on the identification of inappropriatesites (filtering) but which also record access to those sites will be compliant (personal communication, nancy willard, university of oregon).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.104youth, pornography, and the internetunder cipa, material is òharmful to minorsó iftaken as a whole and with respect to minors, [it] appeals to a prurientinterest in nudity, sex, or excretion; depicts, describes or represents, in apatently offensive way with respect to what is suitable for minors, anactual or simulated normal or perverted sexual act, or a lewd exhibitionof the genitals, and taken as a whole, lacks serious literary, artistic, political or scientific value to minors.43the american civil liberties union and the american library association have both filed suit to challenge cipa on first amendmentgrounds as the act is applied to libraries.44note added in proof: on may 31, 2002, a threejudge panel of the u.s.district court for the eastern district of pennsylvania entered a finaljudgment declaring sections 1712(a)(2) and 1721(b) of the childrenõsinternet protection act (i.e., the provisions that required libraries receiving federal funds for internet access to employ technology protectionmeasures) to be facially invalid under the first amendment and permanently enjoining the defendants from enforcing those provisions.45 as ofjune 13, it is unknown if the u.s. government will appeal the decision tothe supreme court.4.2.6the childrenõs online privacy protection actthe childrenõs online privacy protection act of 1998 (coppa) prohibits the collection, maintenance, and use or disclosure46 of personalinformation47 from children under the age of 13 on commercial web sitesthat are directed at children48 or if the operator has actual knowledge that4347 u.s.c. ¤ 254(h)(7)(g) (2001).44multnomah county library v. united states. no. 01cv1322 (ed pa. 2001). availableonline at <http://www.aclu.org/court/multnomah.pdf>.45see <http://www.paed.uscourts.gov/documents/opinions/02d0414p.htm>.46disclosure of information means the release of personal information collected from achild in identifiable form for any purpose, except where such information is used for internal purposes only and the operator does not disclose or use that information for any otherpurpose, or making personal information collected from a child publicly available in identifiable form.47for purposes of coppa, personal information is òindividually identifiable informationabout an individual collected online, including: first and last name, a home or other physical address, an email address, a telephone number, a social security number, anything thatthe ftc determines permits the physical or online contacting of a specific individual, andinformation concerning the child or the parents of the child that the web site collects onlinefrom the child and combines with any of the previously mentioned information.ó48a web site directed at children is a commercial web site that is targeted to children orthe portion of a commercial site that is targeted to children.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.105legal and regulatory issuesthe child is under 13, if the information is collected without notice andwithout verifiable parental consent.49 coppa provides that the site operator50 must allow the parent to refuse to permit the operatorõs further orcontinued use, maintenance, or collection of information at any time. itfurther provides that the site operator may not condition participation ina game, a prize offer, or other activity on a disclosure of informationwhere the information requested is more than necessary to participate inthe activity. to ensure the effectiveness of these prohibitions, coppaauthorizes the federal trade commission (ftc) to enact regulations concerning the method and content of the notification provisions and itsparental consent provisions.coppa provides that a site that is directed at children and collectspersonal information, or any operator that knowingly collects information from a child, must provide notice on the web site that discloses thetype of information collected, how the operator uses the information collected, and the operatorõs disclosure practices. the ftc regulationsadopted pursuant to coppa require the operator to place the notice onthe home page of the site, as well as at each area where personal information is collected.51the ftc regulations further require that the notice be clearly andprominently displayed. a site that uses a link to the notice must ensurethat the link is clearly distinguishable from other links. the ftc regulations also prescribe the necessary content of the notice, which must beclearly written and understandable (box 4.2).coppa also requires the operator to obtain verifiable parental consent to the collection, maintenance, and use of personal information.under coppa, the operator must use òany reasonable effortó to ensurethat a parent of a child receives notice of the operatorõs collection, maintenance, use, or disclosure of personal information and that a parent authorizes any collection, maintenance, use, or disclosure of his or her childõsinformation before the information is collected from the child.52the ftc has stated that, until april 2002, it will use a sliding scale to49p.l. no. 105277, division c, title xiii, 112 stat. 2681, 15 u.s.c. ¤ 650 nt. the actamends 15 u.s.c. ¤ 41, et seq.50for purposes of coppa, a site operator is any person who operates a web site andcollects or maintains personal information from or about site visitors, or the person forwhom the information is collected, if the site is operated for commercial purposes.51how to comply with the childrenõs online privacy protection rule, november 1999, available online at <http://www.ftc.gov/bcp/conline/pubs/buspubs/coppa.htm>.52coppa provides exceptions to the requirement that the operator obtain verifiable parental consent in certain circumstances.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.106youth, pornography, and the internetbox 4.2ftc regulations implementing thechildrenõs online privacy protection actthe privacy policy notice that must be displayed at a web site that collectspersonal information from a child must include:¥the name and contact information for all operators collecting or maintaininginformation collected through the site;¥the type of personal information collected from the child, the method ofcollection, and how the operator uses the information collected;¥whether the operator discloses the information to third parties; if so, the operator must also disclose the kinds of business that the third parties are engaged in,the general purposes the information is used for, and whether the third parties haveagreed to maintain the confidentiality and security of the information;¥the parentõs option to agree to the collection and use of the informationwithout consenting to disclosure to third parties;¥a notice that the operator may not require the child to disclose more information than is reasonably necessary to participate in an activity as a condition ofparticipation; and¥a notice that the parent can review the information provided by the child,can ask to have it deleted, and can refuse to allow any further collection or use of thechildõs information, as well as the procedures for the parent to do so.the regulations make clear that the notice may not include unrelated or confusing materials.source: adapted from information available online at <http://www.ftc.gov/bcp/conline/pubs/buspubs/coppa.htm>.assess the measures used to obtain verifiable parental consent.53 underthe slidingscale approach the required effectiveness of the method useddepends upon the use that the operator makes of the information collected. if the information is only used internally for purposes such asmarketing back to the child, the operator may use email to obtain parental consent, as long as the operator also takes additional steps to increasethe likelihood that the parent has, in fact, provided consent. however, ifthe information is disclosed to third parties or made publicly available, amore reliable method must be used to obtain parental consent. a morereliable method includes such measures as getting a signed form from theparent via facsimile or mail, accepting and verifying a credit card num53how to comply with the childrenõs online privacy protection rule, november 1999, available online at <http://www.ftc.gov/bcp/conline/pubs/buspubs/coppa.htm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.107legal and regulatory issuesber, taking calls from parents through a tollfree number, or accepting emails accompanied by a digital signature. coppa also provides a safeharbor for web site operators: an operator will be found to have satisfiedthe notice and the consent requirements if it is shown that the site implemented a set of selfregulatory guidelines issued by representatives of themarketing or online industries.4.2.7state statutesall states prohibit the production, sale, or exhibition of obscenity. atypical state law on this subject would incorporate the miller definition, asapplied to the community standards of the state. to regulate the distribution specifically to minors of sexually explicit material that does not meetthe miller test for obscenity, states have often used the phrase òharmful tominors,ó which derives from ginsberg. for example, the california penalcode section 313 defines òharmful matteró as matter that, òtaken as awhole, which to the average person, applying contemporary statewidestandards, appeals to the prurient interest, and is matter which, taken as awhole, depicts or describes in a patently offensive way sexual conductand which, taken as a whole, lacks serious literary, artistic, political, orscientific value for minors.ó for the remainder of this report, the termòharmful to minorsó should be understood as meaning òobscene withrespect to minorsó (or equivalently, òobscene for minorsó), as defined bythe supreme court in ginsberg.4.2.8regulatory effortsthe federal trade commissionthe federal trade commission enforces the federal trade commission act (15 u.s.c. ¤¤ 4158) (the ftc act), which prohibits deceptive orunfair acts or practices in commerce. a representation or practice is deceptive under the ftc act if it is likely to mislead consumers actingreasonably under the circumstances and it is material, meaning that therepresentation or practice is likely to affect consumersõ conduct or decisions with respect to the product or service at issue. an act or practice isunfair under the ftc act if it causes or is likely to cause injury to consumers that is substantial, not outweighed by countervailing benefits to consumers or to competition, and not reasonably avoidable by consumersthemselves. practices within the adult entertainment industry may violate the ftc act if they utilize deceptive or unfair methods that facilitateminorsõ access to adult content. in recent years, the ftc has broughteight law enforcement actions focusing on the deceptive or unfair use ofyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.108youth, pornography, and the internetnew technology that has the effect of luring minors to sexually explicitmaterial on the internet.54in one action, the ftc filed suit in september 1999 in the u.s. districtcourt for the eastern district of virginia against a number of companiesfor òpagejackingó and òmousetrappingó in a way that exposed users notseeking it to sexually explicit material.55pagejacking refers to a practice in which almostexact copies aremade of innocuous web pages, including all the metadata that informssearch engines about the subject matter of the site. these new pages differfrom the original pages only in that they redirect a user coming to the newpage to another web site containing sexually explicit, adultoriented material. using the metadata, the sham copy of a legitimate web site wouldbe registered in the databases of search engines along with the legitimateweb site itself, but any user clicking on a searchenginegenerated link tothe sham copy would be directed to the adult web site. in this case, thedefendants located overseas produced lookalike versions of u.s.basedweb sites that were indexed by search engines. this process divertedunsuspecting consumers, including minors, to a sequence of pornography sites from which they could not easily exit, essentially òtrappingóthem at the site. the defendants cloned as many as 25 million web pages,including kidsõ game sites and movie review sites.the united states district court for the eastern district of virginiagranted a temporary injunction against these practices. subsequently,one of the defendants settled out of court and agreed to refrain fromundertaking such practices, and another was never located (though itsactions have ceased).in a second case, the ftc also took action against the use of executable dialer programs that hijack consumersõ modems and connect them toadult sites. companies advertising òfreeó adult images disconnected consumers from their local internet service without their knowledge andreconnected them to longdistance lines, resulting in enormous telephonebills. consumers victimized by this scheme included a substantial number of minors. the ftc obtained orders halting these schemes and providing redress for financial injury.56in a third case, the ftc has targeted the deceptive use of unsolicited54the ftc has a broad program of enforcement in the area of ecommerce and theinternet; the first ftc actions involving the internet date to the mid1990s. see <http://www.ftc.gov/bcp/menuinternet.htm>.55ftc v. carlos pereira d/b/a atariz.com, no. 991367a (ed va. filed sept. 14, 1999); pressrelease available online at <http://www.ftc.gov/opa/1999/9909/atariz.htm>.56ftc v. rjb telecom, inc. et al., no. 002017 phx (d. az., filed sept. 26, 2001); ftc v. tyanderson et al., no. c 001843p (wd wa., filed oct. 27, 2000); ftc v. verity international, ltd.,youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.109legal and regulatory issuescommercial email to attract consumers, including minors, to adult entertainment. defendantsõ email messages advised each consumer contactedthat his òorderó had been received, that his credit card had been charged$250, and that he should call a specified number to cancel the order. thisploy deceived numerous consumers, including minors, into making expensive international calls that connected to an audiotext entertainmentservice with sexual content. the ftc obtained a court order stopping thescheme and also obtained monetary redress for consumers.57in addition to law enforcement action, the ftc is sometimes able toobtain modification of potentially deceptive practices through informalaction. for example, one company set up an adult web site with thedomain name nasa.com, leading consumers to sexually explicit, adultoriented sites, not the national aeronautics and space administration(www.nasa.gov). at the request of ftc staff, the domain name registrynetwork solutions inc. immediately deactivated nasa.com. in october2001, the ftc charged an online firm with the use of thousands of òcopycató web addresses to divert web users from their intended internetdestinations to one of its sites; in response, the united states districtcourt for the eastern district of pennsylvania in philadelphia enjoined itsactivities pending further order of the court.58 these copycat addresseswere based on the use of domain names that are confusingly similarmisspellings of domain names or famous marks of interest to children.(for example, the firm registered 15 variations of the popular childrenõscartoon site, <www.cartoonnetwork.com>, and 41 variations on the nameof teen pop star, britney spears.) users who misspelled a web addresswere taken to the firmõs web sites, where they received a rapid series ofadvertisements for goods and services ranging from internet gambling topornography. users seeking to leave one of these sites were also mousetrapped.ftc staff currently are investigating additional, potentially deceptive, adult content industry practices that may target minors. these include the use of domain names that are confusingly similar misspellingsof domain names or famous marks of interest to children.finally, the ftc has launched what it describes as a crackdown ondeceptive unsolicited commercial email (also known as òspamó).59 infebruary 2002, seven defendants caught in an ftc sting operation agreedno. 00 civ. 7422 (lak) (sdny, filed oct. 2, 2000); ftc v. sheinkin, no. 00cv03636 (dsc,filed nov. 11, 2000); ftc v. audiotex connection, inc., cv970726 (edny, filed feb. 13,1997); beylen telecom, ltd., no. c3782 (court, final consent jan. 23, 1998).57ftc v. benoit, no. 3:99 cv 181 (wdnc, filed may 11, 1999).58see <http://www.ftc.gov/opa/2001/10/cupcake.htm>.59see <http://www.ftc.gov/opa/2002/02/eileenspam1.htm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.110youth, pornography, and the internetto settle charges that they were spamming consumers with deceptivechain letters. in addition, the ftc announced that it would mail warningletters to an additional 2,000+ individuals who were involved in this chainletter scheme. further, the agency will launch a public/private education effort in conjunction with various internet service provider associations. though the spam in these cases did not involve adultoriented,sexually explicit material, spam that does involve such materials is asource of many complaints regarding the exposure of children to inappropriate sexually explicit material.the federal communications commissionthe federal communications commission (fcc) has promulgatedrules requiring all television sets with picture screens 13 inches or largerto be equipped with the vchip, a technology that enables the blocking ofthe display of television programming based on its rating. (the rating isencoded in the program broadcast, and the vchip blocks programs fromthe set based on the rating selected by the parent.) ratings identify programming with sexual, violent, or other material parents may deem inappropriate (box 4.3). however, despite much political support for the vchip initiative, its use remains relatively uncommon in u.s. households.an annenberg study, media in the home,60 found that while 40 percent ofparents have access to the vchip or similar blocking technologies, onlyhalf of them use it. only 50 percent of parents are aware of the contentratings associated with the vchip, and only 10 percent can correctly identify the age ratings for programs watched by their children. (this surveyalso found that although parents are more concerned about childrenõstelevision use than their use of any other medium, over half of the children surveyed (57 percent) had a television in their bedroom.)the fcc has issued regulations governing practices in the paypercall industry, which includes dialaporn services. for example, fccregulations require use of credit cards, access codes, or scrambling asways to prevent minors from accessing such services.the fcc is responsible for the development of guidelines for òindecent materialó broadcast on the public airwaves. such guidelines includedefinitions of indecency (such as the famous òseven dirty wordsó61 or thedescription or depiction of sexual or excretory organs or activities in a60media in the home 2000: the fifth annual survey of parents and children, a national pollconducted for the annenberg public policy center of the university of pennsylvania, philadelphia, and released on june 26, 2000. available online at <http://www.appcpenn.org/mediainhome/conference/report39.pdf>.61see footnote 10.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.111legal and regulatory issuesbox 4.3vchip ratings rating categories for programs designed solely for children¥tvy (all childrenñthis program is designed to be appropriate for all children.) whether animated or liveaction, the themes and elements in this programare specifically designed for a very young audience, including children from ages 2to 6. this program is not expected to frighten younger children.¥tvy7 (directed to older childrenñthis program is designed for childrenage 7 and above.) it may be more appropriate for children who have acquired thedevelopmental skills needed to distinguish between makebelieve and reality.themes and elements in this program may include mild fantasy or comedic violence, or may frighten children under the age of 7. therefore, parents may wish toconsider the suitability of this program for their very young children. note: for thoseprograms in which fantasy violence may be more intense or more combative than inother programs in this category, such programs will be designated tvy7fv.rating categories for programs designed for the entire audience¥tvg (general audienceñmost parents would find this program suitable forall ages.) although this rating does not signify a program designed specifically forchildren, most parents may let younger children watch this program unattended.the program contains little or no violence, no strong language, and little or no sexual dialog or situations.¥tvpg (parental guidance suggestedñthis program contains material thatparents may find unsuitable for younger children.) many parents may want to watchit with their younger children. the theme itself may call for parental guidance and/orthe program contains one or more of the following: moderate violence (v), somesexual situations (s), infrequent coarse language (l), or some suggestive dialog (d).¥tv14 (parents strongly cautionedñthis program contains some materialthat many parents would find unsuitable for children under 14 years of age.) parentsare strongly urged to exercise greater care in monitoring this program and are cautioned against letting children under the age of 14 watch unattended. this programcontains one or more of the following: intense violence (v), intense sexual situations(s), strong coarse language (l), or intensely suggestive dialog (d).¥tvma (mature audience onlyñthis program is specifically designed to beviewed by adults and therefore may be unsuitable for children under the age of 17.)this program contains one or more of the following: graphic violence (v), explicitsexual activity (s), or crude indecent language (l).source: adapted from information available online at <http://www.vchipeducation.org/pages/under.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.112youth, pornography, and the internetmanner that is patently offensive to an average viewer or listener) andregulations that prohibit broadcast of such material during times thatchildren are likely to be listening or watching.finally, under the childrenõs internet protection act, the fcc is responsible for promulgating and enforcing regulations to implement thecipa.624.2.9international dimensionstoday, the internet is a global medium that presents challenges totraditional systems of national governance that are based on the existenceof geographical borders.63 because different nations have different sensitivities toward various types of material (e.g., hate, politics, sexually explicit materials), international consensus on an appropriate regulatoryenvironment for materials on the internet is hard (if not impossible) toobtain, and few attempts have been made to do so beyond the outlawingof child pornography.given this state of affairs, the behavior of foreign parties (e.g., contentproviders, isps, foreign citizens) is difficult to affect directly through theapplication of u.s. law. nevertheless, foreign institutional parties (i.e.,nonindividual foreign players) often operate through the use of facilitiesand equipment subject to u.s. jurisdiction, and how the united states willbe able to use this jurisdiction has yet to be seen.4.3law enforcement, training, and educationthe effectiveness of a statutory framework for regulating the accessof minors to sexually explicit material depends on a number of factors.one factor, of course, is the extent to which it can withstand constitutionalchallenge. but assuming that it is constitutional, factors such as enforcement, training, and education are also relevant.for example, testimony to the committee from the department ofjustice in october 2000 indicated that it was department policy to prosecute obscenity cases where major producers and major distribution ofobscenity are involved, rather than local cases in which community standards are at issue. moreover, the departmentõs priorities at the time wereto prosecute matters related to the production and online distribution of62see <http://hraunfoss.fcc.gov/edocspublic/attachmatch/fcc01120a1.pdf>.63for more discussion, see computer science and telecommunications board, nationalresearch council, 2001, global networks and local values, national academy press, washington, d.c.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.113legal and regulatory issues64for example, pursuing an online sexual predator of children through a sting operationis a personnelintensive enterprise. because a sexual predator works slowly to build up arelationship of trust with his victims, law enforcement officials must operate in a similarfashion. participating in such an enterprise is timeconsuming. in any event, the number ofpotentially lawbreaking interactions far outstrips any plausible enforcement efforts thatcould be made.child pornography and the luring of minors into illegal sexual activity,with the consequence that federal obscenity prosecutions had declinedsignificantly. this policy emphasis, as described, indicated a significantdifference from the emphasis of the previous administration, which hadprosecuted obscenity cases with greater vigor.this is an important point. in the 1980s, the department of justiceundertook an aggressive approach to the prosecution of obscenity. asnoted in chapter 3, many of the most graphic forms of sexually explicitmaterial that can now readily be found on the internet (including graphicdepictions of sexual intercourse both heterosexual and homosexual, fellatio, cunnilingus, anal intercourse, incest, and bestiality) would have fallenwithin the prosecutorial policies of the department of justice in the 1980s. by the mid1990s, however, prosecutorial attention began to shift toconcerns about child pornography and sexual predators of children. because resource limitations inevitably constrain what investigators andprosecutors can do,64 this shift of attention led to a substantial reductionat both the national and local levels in the number of prosecutions for thesale, production, or exhibition of traditional obscenity.today, the conventional wisdom seems to be that community standards about sexually explicit material may well have changed to the pointthat only the most hardcore depictions could any longer be classified aslegally òobscene.ó but this is speculative. because of the relative dearthof obscenity prosecutions in recent years, it is in fact impossible to say forcertain that a more aggressive prosecutorial strategy directed at onlineòobscenity,ó as legally defined by the supreme court in miller, could nothave a significant impact on the availability of such material on the internet. whether the current state of affairs with respect to obscenity prosecutions is due to changes in community standards or a mere lack of prosecutions is an open question. (this point is discussed further in section 9.1.)moreover, the concept of material that is òobscene for minorsó hasnot been fully developed. although this concept was recognized by thesupreme court in ginsberg, it has rarely been applied since. in aclu v.reno, the court made clear that any effort to regulate such material mustbe careful not to interfere with the right of adults to gain access to material that is constitutionally protected for them. but with a more creativeyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.114youth, pornography, and the internetuse of technology to develop effective and simple age verification processes, this concept could take on a more significant role in the future, atleast with respect to commercial web sites.another key implementation issue in law enforcement is interagencycooperation and citizen involvement. jurisdiction for antiobscenity andantichildpornography efforts is shared among the fbi, the u.s. customsservice, and the u.s. postal service, as well as state and local law enforcement authorities. in addition, the national center for missing and exploited children (ncmec) has responsibility for providing technicalassistance and training to federal, state, and local law enforcement inidentifying and investigating cases of child exploitation.an example of bureaucratic impediments to coordination can be seenin the relationship of the ncmec to law enforcement agencies. one ofthe ncmecõs functions is to take reports from the field on child pornography, provide analysis on these cases, and then relay those reports to lawenforcement agencies of jurisdiction. to expedite law enforcement actionin cases involving ongoing exploitation of a child (and hence calling forimmediate intervention by law enforcement to prevent further exploitation), it is desirable that the ncmec analysis forwarded to law enforcement agencies contain as much information as possible on the allegedperpetrator. thus, the ncmec, as a congressionally mandated quasilawenforcement agency, would benefit from access to information in the fbiõscrs records systems, fbi investigative files, the national crime information center (ncic), the interstate identification index system within thencic, the fbiõs sex offender data base, state motor vehicle registrationand driversõ license systems, the wantedpersons index within ncic, andthe national law enforcement telecommunications system (nlets).however, it does not currently have such access.finally, training is an issue. no case is brought unless a prosecutor iswilling and able to bring such a case, and prosecutors and investigatorsvary in the knowledge and ability they bring to the enforcement of lawsrelated to sexually explicit material. for example, a prosecutor must befamiliar with the concept of òcommunity standardsó relevant and essential to a successful prosecution. in the united states, the ncmec provides training to law enforcement agencies in all aspects of missing andexploitedchild cases. training topics include child sexual exploitationinvestigations, responding to missing and exploited children cases, response planning, and policy development.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.1155.1children and how they use mediathe term òminorsó spans an enormous developmental range. specialists in child development distinguish between infancy, early childhood, childhood, preadolescence, early adolescence, and late adolescence.table 5.1 summarizes some important characteristics of different ageranges.as a general rule, young children do not have the cognitive skillsneeded to navigate the internet independently. knowledge of searchstrategies is limited if not nonexistent, and typing skills are undeveloped.these factors tend to limit young childrenõs potential exposure to sexually explicit material on the internet until about age 10, the transition fromchildhood to the preadolescent years.the years between preadolescence and late adolescence can be turbulent times in which youth struggle to develop their own identities.they are eager to be heard, seen, and taken seriously but often lack theexperience and maturity to make responsible choices consistently. theytest boundaries in developing their emerging adult personalities, andthey take risks that adults would deem unwise. they are often sociallyuncertain, and they value peer approval highly. and, in pre and earlyadolescence, hormonal changes generally stimulate their interest insexual matters. because of the intensely personal nature of such matters(both sexual and social), the òatadistanceó nature of internet communication and the anonymity with which one can seek out a great variety5children, media, and exposureto sexually explicit materialyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.116youth, pornography, and the internettable 5.1 some important dimensions of child developmentagecharacteristicsinfancy (02)¥preverbal and early language skills emerging¥lacks framework for assimilating and understanding sexualconcepts¥information needs can generally be met by primary caregivers and others in childõs immediate environmentearly childhood¥finds it difficult to distinguish between fantasy and reality;(35)is more easily frightened by òscary thingsó¥continues to lack cognitive framework for assimilating andunderstanding sexual concepts, though sexual behaviorsuch as masturbation may occur¥information needs can generally be met by those in childõsenvironment and easily accessible resources such aschildrenõs books¥begins to have empathy for otherschildhood (69)¥increasing ability to distinguish between fantasy and reality¥typing and writing skills emerging, but poor at youngerages (e.g., misspellings common)¥decisionmaking skills on the internet (as in many areas oflife) not well developed¥some emerging information needs require reference booksand other materials to support researchpreadolescence¥much better ability to distinguish between fantasy and(1012)reality¥better able to use inferential reasoning skills¥decisionmaking skills developing in more abstract waydue to metamemory skills (knowing about knowing,knowing how to know, i.e., strategy)¥typing and spelling skills still problematic¥sexual development beginning for many or at least for theirpeers; sexuality becoming more interesting; likely asensitive period for exposure to sexual content¥information needs expanding and increasingly requirematerials that are not in the immediate physicalenvironmentearly adolescence¥abstract cognitive skills in place that are the same ones that(1315)adults have, though skill set not fully developed¥decisionmaking skills and reasoning skills betterdeveloped than in preadolescence, but often impulsive;faith in own decisionmaking skills (especially in the face ofparental positions) may well exceed actual skill¥age of puberty, growing awareness of sexual developmentand highly curious about his or her own sexuality; somebecome sexually active with intercourse; most will havesome kind of sexual experience (e.g., kissing)¥information needs are broader and relate to the world atlarge, and the availability of some external sources isimportant(continues)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.117children, media, and exposure to sexually explicit materialof information on the internet are highly appealing to very social butalso sensitive individuals.note also that adolescence is a cultural inventionñin earlier times,people aged 13 and 14 were regarded as small adults. children andteenagers had jobs. many older minors (minors by todayõs standards)were getting married, having sex, and raising their families. put anotherway, these older minors had the rights and the responsibilities of adulthood. also, there is some debate in the scientific literature about howrebellious adolescents are. for example, even in later adolescence, youthoften agree with their parents on very important decisions such as whereto go to college. the stormandstress view of adolescents is tied to particular theoretical views, namely eriksonõs psychoanalytic theory, but notso much to social learning theory, which argues for more continuity indevelopment.american youth from preadolescence to late adolescence are also intense consumers of various media. as do other individuals, youth usemediañincluding the internetñfor a variety of purposes, for example,news, education, entertainment, information, stimulation, relief fromboredom, and emotional arousal. media use is heavy among adolescents,with television, music, teen magazines, and movies as well as the internetand video games being important elements.television use tends to peak at about age 12 and decreases duringmiddle and late adolescence, and use of other mediañmusic, music videos, magazines, and the internetñincreases during this period. further,there are some gender differences and differences of socioeconomic statuslate adolescence¥highly aware personally of sexual issues and may well be(1618)sexually active (80 percent have intercourse by age 20; themean age of first intercourse is approximately 17 1/2 yearstoday)¥decisionmaking skills and reasoning ability improved overearly adolescence¥physically and cognitively mature¥legal rights approaching those of adults, though rights mayvary by state¥historically, many were married and having children at thisage¥information needs extensive in scope and depth andcommonly require access to a wide range of resourcesbeyond the individuals in their immediate environmenttable 5.1 continuedagecharacteristicsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.118youth, pornography, and the internet(ses). adolescent girls read teen magazines and watch soap operas morethan boys do, while boys play video games and watch television morethan girls do. lower ses tends to correlate with more watching of entertainment television,1 and african americans watch more television thanother americans, even when ses is controlled for.2 children and adolescents also prefer watching programs with characters from their own ethnic group.3american adolescents use various forms of media primarily becauseof their entertainment value. but media use also helps to socialize adolescents into various adult roles and relationships, contributes to the formation of their individual identities as adolescents, provides assistance incoping with their problems and emotional mood states, and helps to assimilate them into various youth subcultures. for example, private, solitary use of both music and television by adolescents is important in providing them an opportunity to deal with the stress and intense emotionsof this stage of development. teen girls use their bedrooms to read magazines, watch television, listen to music, do their homework, and talk onthe phone. for such girls, the bedroom is a place where they use media tohelp them make sense of themselves and their lives. preference for certain kinds of music and films helps to connect youth from across thecountry and the world into a common youth subculture. in short, mediaare part of the process by which adolescents acquire, or resist acquiring,the behaviors and beliefs of the social world and the adult culture inwhich they live.most childrenõs media useñincluding time on the computer andonlineñdoes not involve parental supervision. many children have radios, cd players, a television, and even a computer in their rooms. as aresult, many parents are not in a position to monitor their childrenõsmedia activity, nor can they readily provide any feedback or support forchildrenõs online activities.the kaiser family foundationõs report kids and media at the new millennium: a comprehensive national analysis of childrenõs media use (1999)described the childrenõs media landscape, identifying how much time1a.c. huston and j.c. wright. 1997. òmass media and childrenõs development.ó pp.9991058 in handbook of child psychology, 5th ed., vol. 4, w. damon, i. sigel, and k. renniger,eds. wiley, new york.2g. comstock, 1991, television and the american child, academic press, orlando, fla.; j.condry, 1989, the psychology of television, erlbaum, hillsdale, n.j.; and huston and wright,1997, òmass media and childrenõs development.ó3j.e. brand and b.s. greenberg. 1994. òminorities and the mass media: 1970õs to 1990õs.ópp. 273314 in media effects: advances in theory and research, j. bryant and d. zillmann, eds.erlbaum, hillsdale, n.j.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.119children, media, and exposure to sexually explicit materialyoung people spend with media and what types of media draw theirattention. the average child spends about 5.5 hours daily using media,including television, radio, cds, or the computer. young people often usemore than one type of media at the same time (e.g., listening to a cdwhile surfing the internet) which means that children do a lot of parallelprocessing in their media use. children aged 8 to 14 tend to spend morehours using media than do teens aged 14 to 18. this is likely because ofthe busier and more diverse schedules of older teens.4perhaps surprisingly, time using the computer in all venues averagedonly 31 minutes per day for children aged 8 to 18, with only a portion ofthat time devoted to online and internet activities. television, by far, wasstill the most commonly used form of media, and this age group had thetelevision on an average of 3.25 hours per day. in this study 62 percent ofchildren had a computer at home. of families living in affluent communities in which the community income averaged above $40,000, 81 percenthad computers compared to 49 percent of families in communities withan average income under $25,000. schools seemed to mitigate some ofthese differences, often providing access for children who did not have apersonal computer in their homes.5of the 31 minutes spent on the computer in recreation, children usedthe computer primarily for games but did spend some time in chat rooms,sending email, and surfing web sites. of the group of children whoreported using the computer the previous day, games occupied the majority of their recreational time online. the 8 to 13yearolds using acomputer in the previous day logged the longest average recreation timeson the computer (over 1 hour), spending 32 minutes playing games, 14minutes looking at web sites, 11 minutes in chat rooms, and 8 minutessending emails.6 note also that time spent online may increase in thefuture as the result of two factors: a greater dependence on webbasedinformation sources and more interaction with online electronic devices(e.g., nintendo games) that are not online today.the amount of time children spend using computers and going onlineis likely to increase as computer use continues to penetrate homes andschools. for example, a 2002 survey by the national telecommunicationsand information administration found that 89.5 percent of all childrenaged 5 to 17 use computers, and 58.5 percent of all those children use the4donald f. roberts, ulla g. foehr, victoria j. rideout, and mollyann brodie. 1999. kidsand media at the new millennium: a comprehensive national analysis of childrenõs media use.the henry j. kaiser family foundation, menlo park, calif.5roberts et al., 1999, kids and media at the new millennium.6roberts et al., 1999, kids and media at the new millennium.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.120youth, pornography, and the internetinternet.7 the report also found that internet use is particularly high forteens and preteens (75.6 percent of 14 to 17yearolds and 65.4 percent of10 to 13yearolds, up from 51.2 and 39.2 percent, respectively, in 1998).furthermore, computer usage (and possibly internet usage as well) variesby age: in one national survey, 26 percent of 2 to 7yearolds reportedusing a computer out of school the day before compared to 44 percent of14 to 18yearolds.8according to a survey by grunwald associates, family decisions topurchase computers and to obtain internet access were based on parentalperceptions of their childrenõs educational needs.9 while children andyouth are most likely to use the internet for schoolwork, an important(and large) percentage of their online time is spent for other purposes,including email, chat, and entertainment.10 a report by the pew internetand american life project found that about half of regular internet usersof any age (an estimated 52 million) use the internet for information onhealth issues such as diseases, clinical trials, treatment, and nutrition, aswell as for assistance in making healthrelated decisions.11 according tothe kaiser family foundation, about two out of three young people (aged1524) have used the internet to search for health information, and 25percent say they get òa lotó of health information online.12 these datasuggest that the internet is of great use to adolescents seeking healthrelated information (including information related to sexual health).5.2sexuality in culturethis report is concerned with the protection of children from inappropriate sexually explicit material on the internet. but children share acultural space with adults, and so it is helpful to understand a contempo7national telecommunications and information administration. 2002. a nation online:how americans are expanding their use of the internet. u.s. department of commerce,washington, d.c. available online at <http://www.ntia.doc.gov/ntiahome/dn/html/anationonline2.htm>.8roberts et al., 1999, kids and media at the new millennium.9see <http://cyberatlas.internet.com/bigpicture/demographics/article/0,,5901 390941,00.html> for a summary of the grunwald study. the full study is available online at<http://www.grunwald.com/survey/index.htm>.10national telecommunications and information administration, 2002, a nation online.11susannah fox and lee rainie. 2000. the online health care revolution: how the webhelps americans take better care of themselves. pew internet and american life project,november. available online at <http://www.pewinternet.org/reports/pdfs/piphealthreport.pdf>.12victoria rideout. 2001. generation rx.com: how young people use the internet for healthinformation. the henry j. kaiser family foundation, menlo park, calif. available online at<http://www.kff.org/content/2001/20011211a/generationrx.pdf>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.121children, media, and exposure to sexually explicit materialrary society in which sexual images and references are common. mediaimages of sexuality abound, and the children of today are exposed to awide range of images through many media, including entertainment television (especially sitcom and dramatic programming in primetime broadcasts, soap operas, music videos, and talk shows), magazines, advertising, film and movies, and news.13¥in primetime broadcast television, references to heterosexual intercourse have increased and have become much more explicit in the last20 years. the dominant messages of these references suggest that sexualbehavior typically takes place between two adults who are not married toeach other and that sexual intercourse does not have the consequenceswith which intercourse may be associated in real life (e.g., pregnancy,sexually transmitted diseases). talk about sex is more common than thedepiction of sex, and sexual intercourse is often implied by context andpartial nudity rather than being portrayed explicitly (that is, with fullnudity) on the screen. some programs on cable networksñespeciallyprograms carried late at nightñoften push the envelope further.¥movies (many of them rrated, and usually available in theaters,on paytv channels, and in video rentals) contain more frequent andmore explicit portrayals of sexual behavior than broadcast tv. as in tv,the most frequent sexual activity shown is unmarried sexual intercourse.sex is often depicted in the context of profanity, alcohol and drug use, andnudity. and sex is often mixed with violence in an attempt to seek furthercommercial success.¥newsstands routinely carry adult magazines whose imagery rangesfrom that depicting simple frontal nudity to very graphic, sexually explicitacts.¥soap operas have a long history in broadcast entertainment. thesexual behavior portrayed usually involves unmarried sexual intercourseand extended and passionate kissing, with prostitution, rape, petting, andhomosexuality occurring less often. discussions and portrayals of safesex and contraception are infrequent, though recent soap operas appearto refer increasingly to òtaking sexual precautionsó and have focusedmore on pregnancy, both wanted and unwanted, than in previous years.¥music videos are increasingly common, and many of the visualelements are implicitly or explicitly sexual. these videos often combinesexuality with violence or aggression, and with objectification and sex13material in the list below has been adapted from aletha c. huston, ellen wartella, andedward donnerstein, 1998, measuring the effects of sexual content in the media: a report tothe kaiser family foundation, the henry j. kaiser family foundation, menlo park, calif.available online at <http://www.kff.org/content/archive/1389/>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.122youth, pornography, and the internetrole stereotyping. visual presentations of sexual activity are common,and a majority of music videos containing violence also contain sexualimagery. rap music is particularly explicit about both sex and violence;mtv frequently shows combinations of aggression, sexrole stereotypes,and sexual imagery; country music videos also use sexual images, butcommon themes include breakups and divorce, dating, and romantic love.¥informational magazines are an important source of informationabout sex, birth control, and sexually transmitted diseases for many teens,especially teen girls. a significant fraction of the sexual content in teenmagazines is devoted to sexual health, with other topics including a focuson decision making about becoming sexually active. magazines incorporate a substantial amount of information about sexual issues into their articles and serve as an important source of information for young readers.although sexual images and behavior are common in the media described above, most of those media generally do not portray sexuallyexplicit material involving full frontal nudity. rather, they are importantelements of a culture at large that seems to accept such portrayals ofsexuality.on the other hand, media portrayals of easy and loose sexuality arenot generally reflected in the actual sexual behavior of americans, and infact the statistics on actual sexual behavior have changed far less over thelast 30 years than media portrayals of sexual behavior. for example,americans do have more sexual partners in their personal histories thanthey had two decades ago; nevertheless, most americans report that inthe past year they had zero or one sexual partner. the reason for thisphenomenon seems to be that on average, americans are marrying laterbut are nevertheless engaging in monogamous sexual activity prior tomarriage.14although 80 percent of individuals have intercourse by age 20, themean age of first intercourse has dropped only from age 18 for those bornin the period from 1933 to 1942 to age 17 1/2 years for those born two andthree decades later. furthermore, teenagers have intercourse only sporadically during the teen years. for example, 19yearold men surveyedin 1978 had sex on average four times in the past 4 weeks, while a comparable group surveyed in 1988 had sex three times in the past 4 weeks.1514robert t. michael et al. 1995. sex in america: a definitive survey. warner books, pp. 8891. sex in america: a definitive survey is based on a scholarly volume by edward o.laumann et al., 1995, the social organization of sexuality: sexual practices in the united states,university of chicago press.15michael et al., 1995, sex in america, p. 94.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.123children, media, and exposure to sexually explicit material5.3the role of media in providinginformation on sexuality to youth16it is hardly news that adolescents are very interested in matters of asexual nature and, beginning in early adolescence, go through a developmental process in which they begin to look for information on sex andtheir bodies as they begin to develop a sense of themselves as sexualbeings.most people would agree that in an ideal world, young people wouldseek out their parents for information on sexuality. parents and childrenwould be able to talk about sex, sexuality, and relationships in a mutuallyrespectful manner in an atmosphere of shared values. in this world,children could raise questions without fear and parents could answerthem without embarrassment, anger, or apprehension.however, in practice, parents are often reluctant to talk to their children about sex. when they do, the information they provide is oftenmore about physiological changes than about the emotional terrain thataccompanies sexuality or about managing oneõs own sexuality appropriately and healthfully. adolescents are trying to find out if their bodies aredeveloping normally, and they also begin to have questions about relationships and how to manage sexual interactions. they want answers topersonal and even embarrassing questions such as, am i normal? is mybody normal? am i developing appropriately at the right speed? what isa tampon and how do i use it? how do you date? how do you kiss? howdo you say no without hurting someoneõs feelings? what is a sexuallytransmitted disease? how do you use contraception? in addition, because it is often difficult for parents to talk about passion and desire andother such matters with their children, young people sometimes find itdifficult to òbuy intoó a clinical discussion.17 considering that youngpeople are often surrounded by media images of sexuality that are com16the discussion in section 5.3 is based largely on aletha c. huston, ellen wartella, andedward donnerstein, 1998, measuring the effects of sexual content in the media: a report tothe kaiser family foundation, the henry j. kaiser family foundation, menlo park, calif.available online at <http://www.kff.org/content/archive/1389/content.html>.17j.d. brown, k.w. childers, and c.s. waszak, 1990, òtelevision and adolescent sexuality,ó journal of adolescent health care 11: 6270; v. strasburger, 1989, òadolescent sexualityand the media,ó adolescent gynecology 36: 747773; j. strouse and r.a. fabes, 1985, òformalversus informal informational sources of sex education: competing forces in the sexualsocialization of adolescents,ó adolescence 20: 251263; and b.m. king and j. lorusso, 1997,òdiscussions in the home about sex: different recollections by parents and children,ójournal of sex and marital therapy 33: 5260.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.124youth, pornography, and the internetpletely centered around desire, it is not hard to understand why parentsand children often do not communicate effectively about sex.18sex education provided in schools also does not provide a comprehensive picture. indeed, sex education in schools is sufficiently controversial that its content is very tightly prescribed in terms that will generate the least amount of political argument and heat. for example, 14states have required that sex education (if it is taught) must teach abstinence or abstinence until marriage. these states do not, however, alsorequire that schools teach information about other forms of contraception,though abstinencebased curricula do emphasize contraceptive failurerates.19in practice, if parents and schools are not providing young peoplewith answers to the questions that they actually have, many will turnelsewhere to get additional information about sexuality. these othersources include their friendsñwho often have much misinformation toshareñas well as the media.20 the media may be a particularly appealingsource of information for adolescents because it can be accessed anonymously.21 one can imagine (or perhaps even recall) the types of reactionsand resulting feelings of embarrassment that might accompany questioning a peer or parent about sexuality (e.g., from a peer, òyou mean youdonõt know that,ó or from a parent, òwhy are you asking that?ó). theanonymity of the media, and of the internet especially, offers a way toobtain information about very sensitive matters about sexuality andsexual health and allows the adolescent to avoid embarrassing faceto18for example, one survey indicated that 72 percent of mothers believed that they hadtalked with their teenagers about sex, while only 45 percent of those teens agreed. see j.jaccard and p. dittus, 1993, òparentadolescent communication about premarital pregnancy,ó families in society 74(6): 329343.19m. sutton, j.d. brown, k. wilson, and j. klein, 2001, òshaking the tree of knowledgefor forbidden fruit: where adolescents learn about sexuality and contraception,ó sexualteens, sexual media, j.d. brown, j.r. steele, and k.w. childers, eds., erlbaum, hillsdale,n.j.; j.d. brown and s. stern, òsex and the media,ó encyclopedia of communication and information, macmillan, new york, in press; and kaiser family foundation, 2000, sex educationin the u.s.: policy and practice, report no. 3049, available online at <www.kff.org/content/2000/3048/issue percent20update.pdf> (october 3, 2001).20sutton et al., 2001, òshaking the tree of knowledge for forbidden fruit;ó brown andstern, òsex and the media,ó in press.21as one data point, consider that sexual health information is rated by online youth asòvery important for people their ageó in larger percentages (84 percent) than any other typeof online information. (information about drugs and alcohol are regarded as very important by 75 percent of online youth.) see rideout, 2001, generation rx.com: how young peopleuse the internet for health information.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.125children, media, and exposure to sexually explicit materialface encounters.22 (a major disadvantage of mediañespecially internetmediañas a source of sexual information is that its accuracy is often notverified. schoolage children may be far less cognizant of this fact thanwould be appropriate, and they are likely to search out information, awareof the advantages of anonymity but unaware of the disadvantages ofpotential inaccuracy.)in the absence of other comfortable venues for seeking information,media sources help to fill information gaps for young people, providinginformation about topics that parents and schools are not discussing. asearly as 1980, studies documented the strong influence of the media on anindividualõs sexual selfevaluation and the lack of influence exerted byfamily variables.23 given the increasing role of the internet as a source ofreliable information for young people as they conduct research for schoolpapers and seek homework help, one can imagine that the mediaõs influence will only increase. in fact, more recent studies have documented thatthe mass media is a particularly significant resource for sexual information for adolescents.24research on print media suggests that turning to the media for information on sexuality is also a normative behavior among teens. the majority of adolescent boys have seen at least one issue of playboy, while girlstend to turn to womenõs magazinesñfor example, seventeen magazine foryoung teens, and for girls older than 14 glamour and cosmopolitan. magazines like glamour provide very explicit information on topics such asrelationships with boys and content devoted to sex, flirting, and variousromantic aspects of relationships.the fact that young people often turn to the media to help deal withsome of the issues associated with their changing selves has both positiveand negative dimensions. on the one hand, many young people may find22on the flip side, the anonymity of the internet is highly attractive for children activelyseeking sexually explicit materials for fantasy purposes. this anonymity provides a freedom to explore a wide range of material without having to reveal oneõs identity or toengage an adult to assist in the search. consequently, the embarrassment or shame that heor she might feel is absent (though some of those to whom the committee spoke expressedconcerns about ògetting caughtó), and with it many of the social inhibitions against seekingsuch content.23j.a. courtright and s.j. baran. 1980. òthe acquisition of sexual information by youngpeople,ó journalism quarterly 1: 107114.24brown et al., 1990, òtelevision and adolescent sexualityó; strasburger, 1989, òadolescent sexuality and the mediaó; strouse and fabes, 1985, òformal versus informal informational sources of sex education: competing forces in the sexual socialization of adolescentsó; king and lorusso, 1997, òdiscussions in the home about sex: differentrecollections by parents and children.óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.126youth, pornography, and the internetreassurance that their curiosity about sexuality, and the changes in theirbodies, are normal and they need not feel ashamed of their changingphysiques. television and movies in particular, and to some extent printmedia, may provide information about òscriptsó for romantic interactionby depicting scenes in which these activities take place.25 teens can watchto see how other people resolve these situations and make judgments asto whether they feel this is an appropriate path to resolution for theirsituations.26 in searching the internet, young people also have a verygood chance of finding valid and responsibly presented information onsexual health from reliable sources such as the surgeon general,27 plannedparenthood,28 or the american social health association,29 all of whichcan be reassuring and also may help young people to be more responsiblein the choices they make with regard to their sexuality.on the other hand, using the media as a primary source for information about sexuality has a variety of risks. it can create unrealistic expectations for oneself. for example, bodies portrayed in the media as sexuallyattractive are often unattainable (e.g., very thin physiques for girls andwelldefined, sizable muscles for boys), and a young person who perceives his or her body as not fitting into these norms may be troubledrather than reassured.30 another study found that virgin adolescents whobelieved that media characters experienced high levels of sexual satisfaction were less satisfied with their own state of virginity.31 still another25l.j. heinberg and j.k. thompson. 1995. òbody image and televised images of thinnessand attractiveness: a controlled laboratory investigation,ó journal of social and clinicalpsychology 14: 325338. a script is a set of expectations about how certain kinds of interaction will unfold and about how one will act in those interactions. more discussion can befound in chapter 6.26national research council and institute of medicine. 2001. nontechnical strategies toreduce childrenõs exposure to inappropriate material on the internet: summary of a workshop.board on children, youth, and families and computer science and telecommunicationsboard. joah g. iannotta, ed. national academy press, washington, d.c. see also thediscussion by jane brown on pp. 2126, c. pardun, 2001, òromancing the script: identifyingthe romantic agenda in topgrossing movies,ó sexual teens, sexual media, j.d. brown, j.r.steele, and k.w. childers, eds., erlbaum, hillsdale, n.j.27see <http://www.sexualhealth.com/>.28see <http://www.plannedparenthood.org/health/>.29see <http://www.plannedparenthood.org/health/>.30heinberg and thompson, 1995, òbody image and televised images of thinness andattractiveness: a controlled laboratory investigation,ó l. hofschire and b. greenberg,2001, òmediaõs impact on adolescentsõ body dissatisfaction,ó sexual teens, sexual media.31s.j baran. 1976. òsex on tv and adolescent selfimage,ó journal of broadcasting 20: 6168.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.127children, media, and exposure to sexually explicit materialstudy found that adolescents were most likely to be dissatisfied with theirfirst sexual experience (intercourse) if they relied on media messagesabout sexuality.32 perhaps more important, media sources often depict ina positive light behavior that is inconsistent with the stated values ofmany parents and other adults. the messages about sexuality containedin the traditional media romantic script tend to be irresponsible and potentially emotionally and physically unhealthy. these sources answeradolescentsõ questions about sexuality with messages that do not alwaysrepresent safe or healthy choices. adultoriented sexually explicit material may òup the anteó in that the messages are very explicit and overt,and certainly this type of material can be found easily online.5.4dimensions of exposure and accessto the internet5.4.1venues of accessas noted in chapter 2, individuals obtain access to the internetthrough an internet service provider (isp). however, it is quite commonfor many individuals to have more than one. for many youth, multiplevenues for access to the internet are likely, with home, school, and libraryaccess as perhaps the most common channels but with many others aswell, all of which have (potentially) different isps and thus may offerdifferent terms of service. for example, youth are likely to have access tothe internet at the homes of a friend, in which the operative rules ofsupervision and/or access are most likely to be those governing the friend.internet cafes are open to anyone willing to pay access fees by the hour.museums (especially those with afterschool or weekend programs) oftenprovide internet access and operate under less stringent rules than dolibraries or schools. many youth afterschool programs and other communitybased programs are providing internet access and courses on howto use the internet. even commercial establishments are beginning toprovide terminals for internet access.33the most frequent venues for youth internet use are home (74 percent) and school (73 percent). almost as many youth use the internetfrom someone elseõs household (68 percent). public libraries account for a32huston et al., 1998, measuring the effects of sexual content in the media: a report to thekaiser family foundation.33see, for example, <http://www.eetimes.com/story/oeg20010412s0040> and <http://siliconvalley.com/docs/opinion/techtest/ml071201.htm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.128youth, pornography, and the internetmuch smaller fraction of internet useñonly 32 percent of youth used alibrary for internet access in the last year. internet usage is frequent, with76 percent using the internet in the week prior to being interviewed, andwith an average frequency of 3 to 4 times per week. on the other hand, 61percent reported that their typical internet usage is an hour or less on atypical dayñ26 percent reported spending 1 to 2 hours on a typical day.34one important distinction to make about different venues is the degree to which any given venue is private (or can be made so). a personwishing to view material that may be subject to social sanction is highlyunlikely to do so where he or she can be seen doing so. for example, aninternet access terminal in a mall that faces a walkway with many passersby is unlikely to be the venue of choice for viewers interested in becomingsexually aroused (though it might well be the preferred venue for someone intending to shock those passersby). by contrast, someone withunsupervised access at home (e.g., in a bedroom with a lockable door) isnot subject to social sanctions, and thus can view material free of suchconstraints.note also that the availability of multiple venues of private and/orunsupervised access means that venuespecific approaches are easily circumvented. a child denied access to various types of content at school,for example, is likely to seek it in another venue where it is more easilyavailable. for this reason, approaches to protecting children from exposure to inappropriate material that are venuespecific are not likely to beeffective in serving their stated purpose.5.4.2sources and channels of exposuresexually explicit material can be made available to youth from a variety of different sources and in a variety of ways. one major distinctionthat often drives the means by which sexually explicit material is madeavailable is whether the source carrying such material is doing so forcommercial purposes or has no financial motivations. the commercialonline adult entertainment industry that makes sexually explicit materialavailable for profit is generally thought of as the most significant sourceof sexually explicit material that may be regarded as inappropriate forminors. as described in chapters 1 and 3, the type of content on suchweb sites includes images equivalent to those viewed in music videos34joseph turow with lilach nir. 2000. òthe internet and the family: the view of u.s.parents,ó in children in the new media landscape: games, pornography, perceptions, cecilia vonfeilitzen and ulla carlsson, eds. unesco international clearinghouse on children andviolence on the screen, sweden.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.129children, media, and exposure to sexually explicit materialand those seen in rrated movies, as well as other images that are extraordinarily graphic, are sexually explicit, and cater to specialized sexualtastes. in most cases, the images that are available for free serve as òteasersó for subscription web sites that contain much more of the same. lessgraphic but still sexually suggestive images may sometimes be found onweb sites associated with firms with a significant òbricksandmortarópresence that are using the web essentially as an advertising medium todraw attention to their products and services (for example, frederickõs ofhollywood and victoriaõs secret).noncommercial carriers of sexually explicit content are much morevariedñas varied as the motivations for carrying such content. forexample:¥child pornography is often carried by individuals who are notmotivated by the prospect of financial reward. rather, these individualsare often part of a community in which the ethos is that òto get pictures,you must contribute pictures.ó¥friends sharing pictures onlineñthe online equivalent of showinga friend a purloined centerfold prior to the internetñare not motivatedby financial reward or even by a community ethos.¥electronically sending a sexually explicit picture to someoneanonymously for purposes of harassment is generally not motivated bythe prospect of financial reward.¥newsgroups containing sexually explicit material do not exist asthe result of any financial reward inherent in their existence. instead,they provide a convenient method for exchanging material according to amuch less rigid ethos than that which governs those who exchange childpornography.¥people engage interactively in òcybersexóñonline realtime dialogwith someone (usually textbased) that interactively describes sexual behavior and actions with oneõs online partner for erotic purposes and expression. the intent can vary: sometimes, such interactive chat providesfodder for a masturbatory fantasy. in other cases, it is simply a òhackóñmaking fun of someone else for taking cybersex seriously. in still othercases, it is a prelude to facetoface meetings and a possible sexual connection. (interactive chat of a nonsexual sort is also a key element of predatory connections that entice young people to meet facetoface with otherusers, an action that may put them in potential physical danger.)¥individuals often have personal profiles or web pages on the internet, which in general are intended to be found by others. for thoseseeking sexual contact, either in person or online, these profiles may besexually provocative and explicit, so as to draw attention from those similarly interested.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.130youth, pornography, and the internet¥individuals with exhibitionist tendencies find the internet an easyway to satisfy such desires without the expectation of making money inthe enterprise.the channels through which individuals can be exposed to such content are also diverse. because the internet is not merely a repository ofweb sites to be passively browsed, but rather a dynamic and interactivesystem, the opportunity for users to be exposed to inappropriate contentis not limited to viewing commercial web sites alone. for example:¥bulletin boards or newsgroups may contain explicit imagery orgraphic language and may center on inappropriate themes.¥òspamóñemail that is unsolicitedñcan contain links to inappropriate sexually explicit images. spam is often associated with operators ofadult web sites seeking to increase traffic to their sites. as noted inchapter 2, participants in chat room conversations and users of im software often receive links to such sites.¥publicly accessible user òprofilesó associated with a screen nameor a login name are used to provide information about the owner of thatname, and often contain links to web sites. sometimes, the operator of anadultoriented web site will use a sexually provocative screen name todraw attention to the profile, and include a link to that site. someone whoreads the profile will often click on the link, thinking that the profileõsowner is an individual and with the expectation of receiving personalinformation. because such links often do take the user to a web site withpersonal information about the owner, this expectation is not unreasonable. but when the profile owner is the operator of an adult web site, thelink takes the userñunexpectedlyñto one containing sexually explicitmaterial.¥open chat rooms in which internet users can communicate via textmessages in real time are a participatory public forum in which the normsof behavior and communication are often outside of societal norms ofdecency regarding the representation and discussion of sexuality, aggression, and intergroup relations.35¥instant messages (ims) are another kind of interactive form thatrelies on textbased, realtime interaction. however, they are based on a35note also that there can be private chat rooms, in which those who participate do so byinvitation or because they know of the chat roomsõ existence. for the most part, such chatrooms are not generally subject to intrusions from uninvited guests. some high schoolstudents to whom the committee spoke commented that òwhen they were youngeró theyparticipated in public chat rooms, but as they had become older, they found private chatrooms more congenial and better matched to their interests and needs.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.131children, media, and exposure to sexually explicit materialonetoone interaction (and hence are more private, unlike a chat room),and as a general rule, ims require at least one party to have some priorknowledge of the otherñnamely the other partyõs screen name. (as notedin chapter 2, screen names or email addresses, which are sometimes thesame thing, can be found in public chat rooms, searches for profiles withparticular characteristics, and harvesting email addresses from publicpostings.) note that depending on the technology, ims can also allowtransmission and receipt of images and sounds, enabling both realtimevoice interaction, videoconferencing, and image exchange on a peertopeer basis, without the need for sending email or going to a web site.¥peertopeer networks enable file sharing between individuals. insuch networks, the files themselvesñthe information content of interestto end usersñalways remain on client systems and never pass through acentralized server (such as one that would host a web page). instead, thepeertopeer network gives end users the ability to search for particularfiles of interest and to initiate a direct transfer between the users willing toshare (and receive) files without the payment of a fee.36 in addition, peertopeer file transfers (as with file transfers effected through email) bypasscontent filtering, although the function itself can be blocked by certainfilters. box 5.1 highlights one recent report on the use of peertopeernetworks for obtaining sexually explicit material.the role of usenet is important as well. as a broad generalization, thefrequency with which minors access sexually explicit content throughusenet is low, especially if these individuals are younger than high schoolage. the reasons are that usenet often requires some technical sophistication to use (and is generally textbased), and that the sexually explicitcontent on the world wide web is much easier to obtain and more interesting in addition. (to the extent that minors do use usenet, it tends to befor the downloading of information objects such as popular music, blockbuster movies, and pirated software.) this should not be taken as anassertion that young people never make use of usenet, but the committeebelieves that the primary use of usenet with respect to sexually explicit36in napsterlike peertopeer filesharing networks, a central server holds a publiclyaccessible index to the files available from end users (but not the files themselves). (napsterwas originally designed to handle sharing of digital music files, but there is no particularreason that the files in question must be music filesñand indeed, extensions of the napsterprotocol can handle other file types.) other peertopeer filesharing networks, such asgnutella, eliminate even the centralized server index function. users of gnutellalike systems are connected in a web (rather than to a centralized index), and a query from one usergoes to an immediate circle of possible respondents. if not satisfied, the query then goesfrom those respondents to other respondents. furthermore, such queries are highly anonymous, though file transfers between end users are not.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.132youth, pornography, and the internetbox 5.1the use of peertopeer networks forobtaining sexually explicit materiala report issued in july 2001 by the minority staff of the special investigationsdivision of the house committee on government reform drew several conclusionsabout the use of peertopeer networks. using the terminology òinternet filesharingprograms,ó the report found that internet filesharing programs are rapidly gainingusers and that these programs provide free access to thousands of pornographicvideos and images. some peertopeer networks are established for the purpose ofexchanging such content, while others are created for purposes such as music exchange but nevertheless contain some of these videos and images. further, it foundthat the number of children using filesharing programs is unknown, but is believedto be high.the inference drawn from the report by the public media was that a large numberof children are gaining access to pornography through internet filesharing programs,but the report never states such a conclusion explicitly. based on data regardingpopular search terms in internet filesharing systems,1 the report did conclude thatone of the major uses of internet filesharing programs is to exchange pornographicmaterials, such as adult videos.the report further concluded that children in search of music on internet filesharing programs are directed to pornographic files. this conclusion was based onthe fact that a search for òbritney spearsó videos on one filesharing service resultedin òhitsó more than 70 percent of which were videos with pornographic titles.searches for other popular musicians, such as christina aguilera and madonna, alsoproduced significant numbers of pornographic files.source: childrenõs access to pornography through internet filesharing programs, preparedfor rep. henry a. waxman and rep. steve largent, minority staff, special investigations division, committee on government reform, u.s. house of representatives, july 27, 2001.1for example, the report noted that on one day sampled by the special investigations division, 6 of the top 10 searches were for òporn,ó òsex,ó òxxx,ó and other terms intended to elicitpornography. one search for the term òpornó on a particular filesharing system yielded over25,000 entries, more than 10,000 of which were video files.material tends to be among adultsñand it is a prime channel for theexchange of child pornography and other highly òextremeó material.5.4.3extent of exposurein 2000, the crimes against children research center (cacrc) conducted a nationally representative, interviewbased survey with 1,501youths aged 10 to 17 who use the internet regularly (box 5.2). this surveymeasured the extent to which young people came in contact with sexuallyexplicit material, received sexual solicitations from other users, and wereyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.133children, media, and exposure to sexually explicit materialdistressed by the incident.37 twentyfive percent of youth reported having had at least one unwanted exposure to sexual pictures in the yearbefore the survey was taken. these figures are approximately consistentwith findings of a kaiser family foundation/npr survey taken in 2001.38in this survey, 31 percent of children aged 10 to 17 with computers athome reported seeing a òpornographicó web site, even if by accident.breaking down by age, 45 percent of those aged 14 to 17 had seen such asite, compared with 15 percent of those aged 10 to 13. another study bythe kaiser family foundation found that among teens (aged 15 to 17)online, 70 percent say they have accidentally come across òpornographyóon the web, though 77 percent said they have never come across it orcome across it ònot too often.ó39one in 5 young people reported receiving a sexual solicitation orapproach in the last year, and 1 in 30 received an aggressive sexual solicitation.40 (in the lexicon of the cacrc study, a solicitation is defined as a37david finkelhor, kimberly mitchell, and janis wolak. 2001. youth internet safety survey. crimes against children research center, university of new hampshire. see <http://www.ncjrs.org/txtfiles1/ojjdp/fs200104.txt>.38see <http://www.npr.org/programs/specials/poll/technology/>.39victoria rideout. 2001. generation rx.com: how young people use the internet for healthinformation. the henry j. kaiser family foundation, menlo park, calif. available online at<http://www.kff.org/content/2001/20011211a/generationrx.pdf>. note that the use ofthe term òpornographyó in a survey questionnaire is subject to all of the problems discussed in chapter 1 regarding the definition of òpornography.ó as that discussion indicates, different people have different understandings of what counts as òpornographic,ó soone party (but not another) might regard a victoriaõs secret advertisement, the swimsuitissue of sports illustrated, or a site devoted to gay and lesbian rights as òpornographic.ó theauthor of generation rx.com (personal communication, march 2002) spoke with a 14yearold girl who reported that a lot of kids her age had seen òpornó movies. when asked toprovide an example, she said, òyou wouldnõt believe how many of them have seen american pie.ó (òamerican pieó and òamerican pie 2ó carry movieindustry ratings of r, whichindicate admission forbidden for minors without a parent or guardian. the enforcement ofsuch ratings varies across communities and even across theaters within an individual community, and even if enforcement were uniform, the ratingñby assumptionñindicates thatminors can obtain access to such movies with parental permission and consent verified bythe parentõs presence.) perhaps the most that can be said from a survey based on anundefined term such as òpornographyó is that those who reported coming across òpornographyó on the internet have some sexually oriented concept in mind, even if that concept(and hence the material in question) may vary definitionally (and substantially so) fromperson to person.40note also that these figures may well underrepresent the actual incidence of solicitations, because many youth who know that adults are concerned about such solicitationsmay worry that reporting such incidents could lead to greater parental restrictions on them.since many older teens think they can deal with such situations, they may not think theyare worth reporting.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.134youth, pornography, and the internetrequest to engage in sexual activities or sexual talk or to give personalsexual information that was either unwanted or made by an adult whetherwanted or not. an aggressive sexual solicitation is a sexual solicitationinvolving offline contact with the perpetrator through regular mail, bytelephone, or in person or attempts or requests for offline contactñall ofwhich constitute a potential risk of physical safety for young people.)girls in the survey were targeted for sexual solicitations and approachesbox 5.2the youth internet safety surveyin the period from august 1999 to february 2000, the crimes against childrenresearch center at the university of new hampshire conducted the youth internetsafety survey, a telephone survey of a representative national sample of 1,501 youngpeople, ages 10 through 17, who use the internet regularly (defined as using theinternet at least once a month for the past 6 months at home, school, a library, orsome other place). parents or guardians were interviewed first for about 10 minutes,and if they consented, young people were interviewed for about 15 to 30 minutes,with the interviewer taking care to preserve privacy and confidentiality during theyouth interview.youth survey participants were 53 percent male and 47 percent female. ethnically, they were 73 percent nonhispanic white, 10 percent african american, 3percent american indian or alaskan native, 3 percent asian, and 2 percent hispanicwhite; 7 percent were in other ethnic categories, and 2 percent did not answer.seventyfive percent of the households approached completed the screening necessary to determine their eligibility for participation in the survey. the completion rateamong households with eligible respondents was 82 percent. five percent of parentsin eligible households refused the adult interview. another 11 percent of parents completed the adult interview but refused permission for their child to participate in theyouth interview. in 2 percent of eligible households, parents consented to the youthinterview, but youth refused to participate. an additional 1 percent of eligible households were in òcallbackó status when 1,501 interviews were completed.the final sample consisted of 796 boys and 705 girls. this is not a representativesample of all youth within the united states because internet use is not evenly distributed among the population. internet users tend to have higher incomes and moreeducation than noninternet users, and, among lower income groups, internet usersare more likely to be white, although this racial difference disappears at higher income levels. while boys are somewhat more likely than girls to use the internet, thedifference is small and is attributable to boysõ propensity to play computer games.the sample for the youth internet safety survey generally matches other representative samples of youth internet users.source: david finkelhor, kimberly mitchell, and janis wolak. 2001. youth internet safetysurvey. crimes against children research center, university of new hampshire. see <http://www.ncjrs.org/txtfiles1/ojjdp/fs200104.txt>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.135children, media, and exposure to sexually explicit materialat almost twice the rate of boys (66 percent compared with 34 percent,respectively).in general, the young people participating in this study were not verydistressed by these experiences. notably, only 6 percent of youth reportedthat accidentally viewing a sexually explicit image was distressing tothem, and 75 percent of youth who had experienced an online solicitationwere not very upset or afraid. (another survey by the kaiser familyfoundation found that of online youth aged 15 to 17 who have beenexposed to pornography, 45 percent reported being upset by the experience, with 55 percent saying that they were not at all upset or ònot tooupset.ó41) more young people were very or extremely upset by aggressive solicitations (36 percent), and 25 percent were very or extremelyafraid. younger users (aged 10 to 13) were more distressed by solicitations than were older usersñalthough 22 percent of youth surveyed were10 to 13 years old, they reported 37 percent of the distressing episodes.this may suggest that younger users have not learned coping strategiesfor such incidents and have a more difficult time shrugging off suchsolicitations and that preadolescents are the age group most emotionallyvulnerable to sexual solicitations.the cacrc and kaiser reports are generally consistent with whatthe committee heard during its site visits. for example, the children towhom the committee spoke during site visits (mostly older adolescents)were in general not particularly concerned by exposure to sexually explicit material. some were upset by what they saw, but the large majoritybrushed it off. (in general, there was a correlation with ageñthose in the16 to 17 age bracket tended to be much less bothered by sexually explicitmaterial than those aged 14 to 16.)of course, selfreporting can be questioned on the grounds that theseteenagers would not have been likely to tell a group of adults about anabiding interest in sexually explicit material or about being upset by suchexposure (it would be too òuncooló to do so). on the other hand, whattodayõs adults remember about their own searches of sexually explicitmaterial in their own youths does not necessarily apply to the youth oftoday. todayõs social environment, compared to that of 30 to 40 yearsago, is a more sexual one, and much of the material that todayõs adultssought as teenagers is much more freely available and is thus arguablymuch less of a òbig problemó than in the past.41rideout, 2001, generation rx.com: how young people use the internet for health information.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.136youth, pornography, and the internet5.5internet exposure to sexually explicit material, solicitations, and harassmentthe impact on children of internet exposure to sexually explicit content must be seen in the context of a much greater availability and widerrange of sexual content than in the past. although it has long been normative behavior for adolescents to seek out images that are sexually explicit (e.g., viewing oneõs first national geographic and playboy were oncerites of passage for many boys), adolescents are bombarded with sexualcontent in everyday media sources that are to some extent difficult toescape. images meant to tantalize are embedded in most advertising intelevision, billboards, and print media, and programming such as musicvideos, soap operas, and movies contains highly sexualized images andcontent. carrying original material and content from many forms ofmedia, the internet also has a broad range of sexual content.for many it would appear that the range of contentñincluding nudity, romance, and depictions of sex and intercourse, as well as a varietyof sexual proclivities (rape, bondage, bestiality, and so on)ñseems to belarger and more accessible than what was easily available in the past.such changes lead some to speculate that there may be a wider range ofsocial mores and a greater permissiveness about sexuality today.42given both a broad range of sexually explicit material on the internetand the numerous ways in which this content can be viewed and accessed, it is worth considering two broad categories of how young peoplecome into contact with this content. exposure to sexually explicit material on the internet can occur inadvertently or intrusively (as when oneuser deliberately seeks to expose another user to this content), or it canoccur as a result of a young personõs deliberate choice to seek and viewsexually explicit material.table 5.2 summarizes the various types of inappropriate sexually explicit materials and experiences discussed in this report.42one suggestion of such a wider range comes from the case of a utah videostorechainowner who was indicted in 2000 for selling obscene material. at trial, his attorney soughtand obtained records demonstrating a large consumption of erotic video through the payperview channels of a local hotel chain and through cable and satellite television providers. according to these records, residents of utah countyñby all accounts a highly conservative area of the nationñare larger per capita consumers of such material than the rest ofthe nation. thus, his attorney argued, the community standards of utah county in factwere not breached by the sales of erotic video, which could not be held to be obscene underthose standards. the chain owner was acquitted on all counts. see timothy egan, 2000,òerotica inc.ña special report: technology sent wall street into market for pornography,ó new york times, october 23.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.137children, media, and exposure to sexually explicit materialtable 5.2 types of inappropriate internet material or experiencetypes of material or experiencecharacterizationinappropriate sexually explicitwith a few exceptions, such materials are generallymaterialdelivered to a user for passive noninteractiveviewing (e.g., through a web site or via email).child pornographya category of speech unprotected by the firstamendment, involving material visually depictingminors engaging in sexually explicit conduct,including actual or simulated sexual intercourse,bestiality, masturbation, sadistic or masochisticabuse, or the lascivious exhibition of the genitals orpubic area of the minor.obscenitya category of speech unprotected by the firstamendment, involving sexually explicit material thatthe average person, applying contemporarycommunity standards, would find, taken as a whole,appeals to the prurient interest, depicts or describes,in a patently offensive way, sexual conductspecifically defined by the applicable state law, andlacks, when taken as a whole, serious literary, artistic,political, or scientific value.material obscene witha category of speech involving material that meetsrespect to minorsthe legal test of obscenity as applied in the context ofexposing minors to such material. under the firstamendment, material in this category is protectedfor adults, though distribution to minors can beregulated.òoffensiveó materiala broad category of speech involving material thatsome party or another finds offensive to his or hersensibilities (e.g., socalled òindecentó material). ifoffensive material does not fall into one of the abovecategories, it is protected for both adults and minorsunder the first amendment.inappropriate interactioninteraction is by definition interactiveñthe user is anwith othersactive participant in a dialog with another humanbeing.sexual solicitations fromsolicitations in the absence of physical meetings canstrangersbe bothersome or frightening to young people.however, if such solicitations lead to facetofaceencounters with predators, the consequences can becatastrophic.harassment (victim thereof)a young person can suffer as the victim of onlineharassment. such harassment can take the form ofthreats, taunts, insults, or the public posting ofdisparagingly altered images (e.g., a composite of ahead shot grafted onto a picture of an animal) andmay be delivered anonymously or with an identityassociated with it.other inappropriate materiala broad category, generally protected under the firstamendment, into which various parties have placedmaterials promoting hate and racism, violence (e.g.,bomb making), religious cults, and so on.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.138youth, pornography, and the internet5.5.1deliberate search for sexually explicit materialdeliberate access results from a childõs conscious choice. for example, a child learns of a web site providing sexually explicit materialsthat does not require a password, and uses an internet browser to viewthat web site. or he or she may search for sexually explicit material usinga search engine, typing in terms likely to return links to such material(such as òsex picsó). or a minor in a chat room might broadcast a message to other chat room participants asking for pictures with explicitsexual content. or he or she may visit a chat room named so as to attractvisitors interested in sexual dialog. or he or she may sign up to be on amailing list known to send sexually explicit images to its members viaemail.eight percent of those surveyed in the cacrc survey acknowledgedchoosing to seek out xrated internet sites.43 less than 1 percent said theyhad used a credit card without permission. of youth who said theytalked online with people they did not know in person, 12 percent hadsent a picture to someone they met online, and 7 percent had willinglytalked about sex online with someone they had never met in person. fivepercent had posted a picture of themselves for general viewing; elevenpercent had posted some personal information in a public internet space,mostly their last name. twentyseven percent of email users knew thatthey had posted their email address in a public place on the internet.some of the paths for deliberate and inadvertent exposure to sexuallyexplicit material on the internet are described in box 5.3.5.5.2inadvertent exposure to or intrusionof sexually explicit materialinadvertent exposure occurs through no deliberate action on thechildõs part. in the reference scenario described in chapter 2, the studentintends to search for information on a particular (innocuous) topic, butbecause the term he uses to search is ambiguous, information on morethan one topic is returned to the user. a poor search strategy or misspellings in the terms used for a search can also result in the inadvertentreceipt of sexually explicit material: links to sexually explicit materialmay be returned even if they were not desired by the child. a child may43even though the survey was anonymous and privacy was guaranteed to the surveyrespondents, such figures are likely to understate the true incidence of such behavior, because of concerns that promises of anonymity might not be kept and reluctance to admitthis activity to anyone (anonymous researcher or not).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.139children, media, and exposure to sexually explicit materialmisspell the address of a web site, and the mistakenly spelled web address points to an adultoriented web site that has obtained the misspelling.44 or domain names that are most likely innocuous may have beenappropriated by owners of adult web sites.45 confusion between .comand .gov or .edu suffixes can also be exploited to the advantage of thebox 5.3some paths for deliberate and inadvertent exposure to sexuallyexplicit material on the internetdeliberate exposure¥searching for sexually explicit terms in a search engine and clicking on thelinks returned¥receiving email with sexually oriented content after subscribing to a mailinglist known to provide such content¥going deliberately to a web site that the user is told contains sexually explicitmaterial¥trading sexually explicit stories and images among friends and acquaintances through email and other forms of online interactioninadvertent exposure¥receiving unsolicited email containing sexually explicit material or links tosuch material (as the result of having been in a chat roomñthereby displaying emailaddressesñor subject to some other technique of òharvestingó email addresses)¥improperly guessing the address of a web site and receiving inappropriatematerial as a result¥searching for terms with both sexual and nonsexual meaning in a searchengine and clicking on the links returned (some of which may contain sexuallyoriented material)¥mistyping a request for information or the address of a web site¥clicking on a link without really knowing what is to be expected at the site towhich the link refers44note that exploitation of misspellings is a timehonored tradition in marketing. one ofthe most famous stories in this area involved the at&t 1800operator advertisingcampaign for collect calls. by dialing 1800operator, the caller was connected toan at&t operator. mci owned the number 1800operater (note the misspelling)and took enough of at&tõs business that at&t discontinued the ad campaign andswitched numbers (business week, june 13, 1994, p. 78).45for example, the name of an indoor professional football team in texas with a .comsuffix leads to an adultoriented web site.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.140youth, pornography, and the internetadult web site owner.46 a user may also mistype the address of a website, or improperly guess the address of a web site,47 and receive inappropriate material as a result. from time to time, email containing sexuallyexplicit material can be misaddressed.intrusion occurs when another party òpushesó such material on thechild even though he or she has not asked to receive it. spam email withlinks to web sites containing inappropriate sexually explicit material isone example. web sites that have popup windows that open as quicklyas a user can close them are another way this exposure can occur. asstated earlier, users can also send ims to each other and attach images orprovide a link to a sexually explicit web site.inadvertent exposure is not an uncommon experience. according tothe cacrc survey, one minor in four (about 25 percent) had at least oneinadvertent exposure to sexually explicit images in 1999, with the majority of these exposures occurring to youth 15 years of age or older. in thevast majority of cases (94 percent), the images involved naked persons; ina substantial minority of the cases (38 percent), they involved peoplehaving sex. about 8 percent of the images involved violence, in additionto nudity and/or sex. the children who inadvertently viewed these images saw them while searching or surfing the internet (71 percent), andwhile opening email, or clicking on links in email or ims (29 percent).48most of these exposures (67 percent) happened at home, but 15 percenthappened at school, and 3 percent happened in libraries.for those surfing the web, the inadvertent exposures happened as theresult of searches (47 percent), misspelled addresses (17 percent), andlinks in web sites (17 percent). and, in 26 percent of these exposedwhilesurfing incidents, youth reported that they were brought to another sexsite when they tried to exit the site they were in. for those receiving email that resulted in inadvertent exposure, 63 percent were associatedwith an email address used solely by the individual; for 93 percent of theinadvertent exposures resulting from email, the sender of the email wasunknown to the individual.46for example, the new york times reported on a childrenõs financial web siteñdesignedto teach children about moneyñthat had been closely associated with a web site offeringadultoriented sexually explicit material. the original web site for children, produced byernst & young, was located at <http://www.moneyopolis.com>, while the adult web sitewas located at <http://www.moneyopolis.org>. see susan stellin, 2001, òpornographytakes over financial site for children,ó new york times, october 26.47a common method of guessing the address of a web site is to try òwww.searchterm.com,ó where òsearchtermó is a term of interest to the user.48in 17 percent of all incidents of unwanted exposure, the youth said they did know thesite was xrated before entering, but it is not clear to what extent inadvertent exposureresulted from curiosity or navigational naivete despite prior knowledge of the siteõs xratednature.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.141children, media, and exposure to sexually explicit materialnote that the line between deliberate access and inadvertent exposure is not always clear. for example, many search engines return links toweb pages that include a few lines of text associated with each page. ifthe child intends to search for an innocuous topic, but uses a search termwith ambiguous meaning (e.g., òbeaveró), a number of links to sexuallyexplicit pages may be returned, along with those few lines of text. if thattext includes terms such as òhot sexó and òxxx,ó careful users can avoidsuch materials.5.5.3sexual solicitations and approachesabout 3 percent of youth internet users surveyed by the cacrcreceived an aggressive sexual solicitation, a rate of exposure far lowerthan the rate of exposure to sexually explicit material. in addition, 5percent of youth internet users were approached sexually, e.g., by beingasked sexual questions in a way that caused them to be very or extremelyupset or afraid. girls were aggressively solicited or approached at almosttwice the rate of boys, and most of those individuals solicited (77 percent)were 14 or older.the cacrc survey found that adults were responsible for 34 percentof the aggressive solicitations, with most of the adult solicitors reported tobe aged 18 to 25. about 4 percent of all solicitors were believed to be olderthan 25, and 67 percent of all solicitors were believed to be male. childrenmade 48 percent of the aggressive solicitations. however, in almost all ofthe cases where the surveyed youth gave an age or gender for a perpetrator, the youth had never met the perpetrator in person, thus leaving theaccuracy of the identifying information in question. (for perspective, areport of the university of pennsylvania center for the study of youthpolicy found that 47 percent of confirmed sexual assaults on children(defined as those under the age of 18) were committed by relatives and 49percent were committed by acquaintances, such as a teacher, coach, orneighbor, while only 4 percent of sexual assaults were committed bystrangers.49)the concern with solicitations is based on a troubling pattern of behavior that often characterizes a childõs online conversation with a solicitor in a chat room or via instant messaging. in a typical interaction between predator and victim, the predator begins with dialog that is entirelyinnocuous.50 over time (perhaps weeks or even months), the predator49richard j. estes and neil alan weiner. 2001. the commercial sexual exploitation ofchildren in the u.s., canada, and mexico, university of pennsylvania, school of social work,center for the study of youth policy, philadelphia, september 18.50see, for example, kenneth v. lanning, 2001, child molesters: a behavioral analysis, 5thedition, national center for missing and exploited children, alexandria, va.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.142youth, pornography, and the internetgrooms his target, seeking to build rapport and trust. no single piece ofdialog is necessarily sexual or even suggestive, but as the victim begins totrust the (anonymous) predator, conversations become increasingly personal. a young adolescent is strongly motivated by the need to separatefrom parental authority and to gain acceptance for his or her growingadulthood. further, he or she is usually inexperienced in dialog withadults (especially adults with cunning and guile) and is likely to be relatively honest in sharing his or her emotional state or feelings. the predator plays on this need for acceptance and a childõs naivete. sexuallyexplicit dialog and/or material is unlikely to be a part of this dialog in itsearly stages, and may never emerge. when it does, it is introduced gradually and slowly in order to reduce the inhibitions of the victim and makehim or her more likely to be willing to meet.5.5.4harassmentin addition to encountering sexual solicitations and inadvertent exposure to sexually explicit material, youth on the internet are subject toother threatening or offensive behavior directed toward them, includingthreats of assault aimed at them, their friends, family, or property, as wellas efforts to embarrass or humiliate them. six percent of regular youthinternet users experienced feeling either worried or threatened becausesomeone was bothering or harassing them online, or because someoneused the internet to threaten or embarrass them by posting or sendingmessages about them for other people to see. boys and girls were targeted about equally, while about 70 percent of the episodes involvedyouth 14 and older. nearly twothirds (63 percent) of those harassingyouth were other juveniles, and almost a quarter of harassment perpetrators lived within a 1hour drive of the youth. the primary forms ofharassment were ims (33 percent), chatroom exchanges (32 percent), andemails (19 percent). about 12 percent included an actual or attemptedcontact by telephone or regular mail, or in person. according to thecacrc, an important feature of harassment is that, more than sexualsolicitation, it involves people known to the youth and people known tolive nearby. some of the threatening character of these episodes stemsfrom the fact that the targets do not feel completely protected by distanceand anonymity, and that the harasser could actually carry out his or herthreats.5151d. finkelhor, k.j. mitchell, and j. wolak. 2000. online victimization: a report on thenationõs youth. crimes against children research center and the national center formissing and exploited children, alexandria, va.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.1436the research base on the impact ofexposure to sexually explicit material:what theory and empirical studies offerthe empirical research base for understanding the impact of sexuallyexplicit material on children (discussed in section 6.2) is not extensive, forreasons described in box 6.1. thus, reliable information in this domain ishard to obtain, and in the absence of reliable information, controversyabounds (as discussed in chapter 7). material in this chapter is derivedlargely from the kaiser family foundation report, measuring the effects ofsexual content in the media: a report to the kaiser family foundation, 1998. 16.1theoretical considerationsa number of psychological theories suggest some of the impact thatmedia exposure might have on young people. these theories sometimesconflict, and so theoretical predictions regarding the developmental impact of exposure to sexually explicit material are not always consistentwith one another. it is also possible that more than one theory may bevalid or useful in understanding psychological phenomena. furthermore,the impact of such exposure will depend on the individual, the context inwhich the exposure occurs, and the social structure in which the youngperson is engaged, as well as other factors.1aletha c. huston, ellen wartella, and edward donnerstein. 1998. measuring the effectsof sexual content in the media: a report to the kaiser family foundation. the henry j. kaiserfamily foundation, menlo park, calif. available online at <http://www.kff.org/content/archive/1389/content.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.144youth, pornography, and the internetit is important to note that young people are not passive recipients ofmedia content.2 they select what they watch and interpret material usingtheir own experiences and frames of reference. thus, while some theoriesmay focus on how content may affect young people in general and cansuggest ways in which certain content can lead to positive or negativeoutcomes, all theories acknowledge that this is an interactive process thatcan yield many different outcomes depending on the person and the2see, for example, henry jenkins, òcongressional testimony on media violence,ó testimony presented before the u.s. senate commerce committee, washington, d.c., may 4,1999. available online at <http://mediaintransition.mit.edu/articles/indexdc.html>.box 6.1reasons for a sparse research base on the impactof sexually explicit material on childrenethical and legal considerationsethical and legal considerations limit experiments that would demonstrate the impact that exposure to sexually explicit material has or does not have on young people.for example, consider a study design that called for children to be shown sexuallyexplicit material in order to identify short and longterm effects of exposure:¥a researcher might run afoul of legal restrictions that limit the showing ofsexually explicit material to minors.¥it is generally regarded as unethical to conduct studies that might place participants at risk, even if there is no evidence that it would do so. in general, all thatis required is a wellarticulated concern about risk, a condition that is clearly met forexposing children to sexually explicit material (e.g., the behavior might be imitated).¥research involving children without parental consent is regarded as unethical. furthermore, a high rate of parental refusal of consentñlikely in the case ofresearch involving exposing children to sexually explicit materialsñundermines theextent to which such research can be generalized, and limits its value.for these reasons, such a study would be unlikely to be initiated. however, itshould be noted that such studies are routinely performed when images of violencerather than images of sexual activity are at issue.increasing conservatism of institutional review boardsresearchers have been able to skirt this issue by measuring the impact of mediacontent of which society is more tolerant. for example, it might be possible for aresearcher to study the impact of sexually oriented material or violent material onyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.145the research base on the impact of sexually explicit materialsituation.3 the following list describes several prominent theories thatconceptualize the underlying mechanisms through which media exposure may affect young people. none of these theories suggest that viewing sexually explicit material will always have a particular outcome.rather, they imply that multiple factors, such as childrenõs media use andinterpretation of material, affect (and greatly complicate the analysis of)outcomes. these theories are considered in light of sexually explicit material, though they are by no means limited to this type of content alone.3huston et al., 1998, measuring the effects of sexual content in the media: a report to thekaiser family foundation.young people if the researcher uses media content that the participants would likelywatch as a part their normal viewing patterns (e.g., shows on primetime television orprograms on during afterschool hours that are targeted to young people).this approach, however, can be foreclosed as human subjects review boardsbecome increasingly more conservative and universities grow more cautious aboutthe possibility of a future lawsuit. for example, dorothy singer, codirector of theyale university family television research and consultation center, was not permitted by her institutional review board to conduct a study that would have measured the impact and shortterm behavioral responses of children watching the powerrangers. ironically, shortly after singer was prevented from doing this study,a local television station videotaped childrenõs activities on the playground afterwatching a power rangers episode.lack of research fundingprivate foundations such as the henry j. kaiser family foundation have supported several recent reports on the media.1 support from foundations is extremelyimportant and provides the possibility of stimulating new and creative research.however, private funding is rarely stable enough to support longitudinal research,and a foundationõs direction often changes in focus every few years. federal fundingis therefore a precondition for developing a field of knowledge in a systematic andcumulative manner; such support would contribute to longitudinal, developmentalstudies and nationally representative tracking surveys to stay abreast of changingpatterns in childrenõs media use and media impact. however, federal funding in thisareañespecially with respect to sexual behaviorñhas been essentially absent.1huston et al., 1998, measuring the effects of sexual content in the media: a report to thekaiser family foundation; d.f. roberts, u.g. foehr, v.j. rideout, and m. brodie, 1999, kids andmedia at the new millennium, the henry j. kaiser family foundation, menlo park, calif., available online at <http://www.kff.org/content/1999/1535/>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.146youth, pornography, and the internet¥psychoanalytic theory. psychoanalytic theory4 predicts potentiallypositive effects from exposure to sexually explicit material presented inmedia. in psychoanalytic theory, two major drives are sex and aggression. these drives must be released in some way, and one path thatpsychoanalytic theory develops for drive reduction is fantasy in the formof catharsis. more specifically, in catharsis, sexual drives can be releasedthrough fantasy experiences with sexual material, thereby reducing thedrive state.¥arousal theory. zillmannõs arousal theory focuses primarily on theimmediate effects that sexually explicit material may have on behavior.5television content, for example, can produce emotional and physiologicalarousal (i.e., activation of the nervous system as opposed to sexualarousal), and increased levels of arousal are likely to produce some typeof behavior. however, zillmannõs theory does not imply what thesebehavioral outcomes will be. rather, arousal theory states that the personality of the viewer, the environmental circumstances, and oneõs frameof reference for interpretation will determine the ensuing behavior.6 inthe context of zillmannõs theory, arousal is nonspecific. thus, otherfactors will determine whether sexually explicit material will result inbehavior that is sexual, aggressive, or altruistic. in media research, autonomic arousal, which is related to emotional experiences, is often thefocus of inquiries.an adaptation of arousal theory has been used to understand thepossible implications of repeated exposure to sexually explicit material.one possibility is that, in a similar fashion to desensitization to violentmaterial, a viewer continually exposed to sexually explicit material willhabituate to that type of content and become desensitized to it as well.becoming physiologically or emotionally aroused in the near future wouldthen require different material, perhaps more explicit depictions. an alternative outcome is that a viewer who has habituated to material willsimply grow uninterested in it, an outcome mentioned by a number ofmale students interviewed by the committee during site visits who asserted that they initially used the internet to view adultoriented websites a great deal but that they soon became bored with such material.habituation does wear off, so a viewer might return to similar material4freudian theory is historically the foundation of psychoanalytic thought. see, for example, calvin s. hall, 1954, a primer of freudian psychology, the world publishing company, new york and scarborough, ontario.5d. zillmann. 1982. òtransfer of excitation in emotional behavior,ó in social psychophysiology, j.t. cacioppo and r.e. petty, eds., guilford, new york.6huston et al., 1998, measuring the effects of sexual content in the media: a report to thekaiser family foundation.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.147the research base on the impact of sexually explicit materialonce this has occurred, or the viewer might not return to regularly viewing material because the viewer has lost interest.7¥social learning theory. in banduraõs social learning theory,8 youngpeople can learn about sexuality from observing others depicted in themedia. specifically, they may observe the mechanics of sexual behavior,but they will also learn about the contexts in which behaviors occur, themotives and intentions behind the interactions represented, and the consequences for those participating in those behaviors. the messages implicit in media portrayals of sexuality may be particularly powerful whenthe participants are attractive, are shown as powerful, are rewarded insome way for their actions, or represent characters with whom the youngperson identifies. in this theory, the behavioral implications are not shortterm reactions; rather, this information is used when the young personbecomes engaged in a similar realworld sexual situation.social learning theory implies three major impacts on an observer: (1)imitation, in which the observer copies a novel behavior that has beenseen before; (2) disinhibition, in which a behavior that was previouslyinhibited is now acted on because there are no negative consequences forthe action; and (3) response facilitation, in which a socially desirable behavior increases in frequency as one observes another perform it. 9 sociallearning theory separates learning a behavior from performing it. that is,knowledge about how to act in a certain way does not mean that one willdo so. performance requires some form of reinforcement for action totake place. therefore, in contrast to cognitive approaches, social learningtheory is based on reinforcement and traditional learning theory approaches. for example, for a person to imitate a sexual behavior or tohave a sexual behavior disinhibited, there must be situational contingencies and reinforcements to support the behavior that has been observed.over time, bandura increasingly incorporated cognitive mechanismsinto his theory. attention to information, retention of that knowledge,production of the learned behavior, and the motivation to do so werealways key elements of his theory, but he added to it the concept of selfefficacy, the belief that a person can control the events around him or her.he reframed his theory as social cognitive theory to emphasize cognitiveelements, but the mechanistic element of reinforcement remained a keyfacet of his approach.107sandra l. calvert. 1999. childrenõs journeys through the information age. mcgrawhill,boston.8a. bandura. 1971. social learning theory. general learning press, new york.9calvert, 1999, childrenõs journeys through the information age.10calvert, 1999, childrenõs journeys through the information age.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.148youth, pornography, and the internet¥cognitive approaches: information processing theory. information processing theories are focused on cognitive constructs that develop as a function of experiences. media provide one such venue for these experiences.based on experiences, children construct scripts (also known as schemas),which are learned expectations that guide perception, memory, and inferences. these scripts are used to predict how one is to act and how otherswill act.11 stereotypes about sexual behavior are one type of sexual script.young children have very few sexual schemas, but as a growing repertoire of expectations develops, these schemas shape future perceptions,memories, and interpretations. both sexual content in the media and reallife experiences shape an individualõs schema. as a result, sexual contentin the media may have a greater impact on individuals who do not havereal sexual experiences. media that depict sexuality that is safe and positive may help to develop healthy sexual schemas, while content that ispermissive of sexual violence or other negative sexual encounters couldhelp to construct sexual schemas that are not beneficial forñor may evenbe harmful toñthe young person.12theories on schemas and scripts for sexual interactions suggest thatany understanding of how the media shape this type of developmentmust include a careful analysis of the messages conveyed by the circumstances of sexual activity, as well as of the types of communication, negotiation, and decision making that occur before, during, and after depictions of sexuality. it also involves a close examination of the preexistingschemas that the individual brings to the media situation.¥cultivation theory. in the field of communications, gerbner describes cultivation theory, a paradigm based on how media content interfaces with the person who is experiencing it.13 media messages that areoften depicted can shape the beliefs of viewers, a process that is not unlikethe development of schemas. for gerbner, there are two main effects ofmedia exposure: (1) mainstreaming, in which dominant cultural messages come to be taken as true, even if they are not; and (2) resonance, inwhich media messages that resonate with oneõs own experiences have avery strong impact on the viewer. in this approach, heavy exposure tosexual material in the media leads to a view of sexuality based on thepredominant media message. if that media message rings true with anindividualõs own life, that message will be further enhanced.1411huston et al., 1998, measuring the effects of sexual content in the media: a report to thekaiser family foundation.12calvert, 1999, childrenõs journeys through the information age.13g. gerbner, 1966, òon defining communication: still another view,ó journal of communication 16(2): 99103; g. gerbner, 1972, òcommunication and social environment,ó scientific american 227(3): 152160.14calvert, 1999, childrenõs journeys through the information age.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.149the research base on the impact of sexually explicit material¥uses and gratification theory. in the field of communications, usesand gratification theory emphasizes the reasons people have for viewingand interacting with various media content. essentially, individuals usethe media for various needs, including information, entertainment, companionship, escapism, and exploration of various aspects of their ownsexuality.15 from this perspective, knowing why a young person choosesa particular type of media content is essential to understanding what theimpact of that content will be.6.2empirical workas noted above, there are few empirical studies on the impact ofsexually explicit media on young people. however, researchers havebeen able to conduct empirical studies using media content other thansexually explicit materialñresearch on violent material is one such example. this is because our society has more permissive attitudes aboutallowing young people to view violent material than about allowing themto see sexually explicit material. for research purposes, a few studies ofsexually explicit material have used collegeage viewers as a way of understanding the impact this material may have on children.16 note,however, that a college student differs considerably in cognitive, physical, and social maturity compared with a primary or middleschoolstudent.6.2.1violenceseveral correlations have been observed in studies of violent mediacontent and children: exposure to such content is correlated with desensitization, increases in hostility, imitation and disinhibition, and fear andanxiety responses. desensitization (described in arousal theory) occurswhen an emotional response to a stimulus is diminished after repeatedexposure to that stimulus. this can be adaptiveña doctor who becomesaccustomed to seeing blood and does not have the strong emotional response he or she experienced in medical school can more effectively helppatients. the media, however, create fantasy exposures to content that15huston et al., 1998, measuring the effects of sexual content in the media: a report to thekaiser family foundation.16e.i. donnerstein and d.g. linz, 1986, òmass media sexual violence and male viewers:current theory and research,ó american behavioral scientist 29(5): 601618; d. zillmann andj. bryant, 1982, òpornography, sexual callousness, and the trivialization of rape,ó journalof communication 32(4): 1021; d. zillman and j.b. weaver, 1999, òeffects of prolonged exposure to gratuitous media violence on provoked and unprovoked hostile behavior,ójournal of applied social psychology 29(1): 145165.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.150youth, pornography, and the internetcan cause arousal and, over time, desensitization that is not necessarily(and often not) adaptive. for example, a child who sees a graphic, violentimage might become angry or frightened. if this image is a representationand not an actual event, then the typical reactions of òfight or flightó arenot appropriate or functional. with repeated exposure, the child maycease to have these emotional responses.17 research has shown that desensitization to media violence can result in reduced arousal and emotional disturbance while witnessing actual violence, greater hesitancy tocall an adult to intervene in a witnessed physical altercation, and lesssympathy for victims of abuse and assault.18emotional expressions of hostility, fear, and anxiety are also measured within arousal theory. increases in hostility can correlate withwatching violent content in the media. in one study, college studentswho watched violent films for 4 days were more likely to interfere withanother individualõs future employment chances (an antisocial act).19repeated viewing of violent material seemed to create an enduring hostile mental framework that discouraged viewers from interacting positively with others, even those who had not provoked them.young people of a wide range of ages sometimes experience fear andanxiety as a result of exposure to television.20 results can range fromnightmares and temporary sleep disturbances to more lasting effects, suchas a fear of swimming in the ocean, after watching the movie jaws.21 the17calvert, 1999, childrenõs journeys through the information age; j. cantor, òmedia violenceand childrenõs emotions: beyond the ôsmoking gunõ,ó paper presented at the annual convention of the american psychological association, washington, d.c., october 5, 2001,available online at <http://joannecantor.com/emotions2sgl.htm>.18v.b. cline, r.g. croft, and s. courrier, 1973, òdesensitization of children to televisionviolence,ó journal of personality and social psychology 27(3): 516546; f. molitor and k.w.hirsch, 1994, òchildrenõs toleration of reallife aggression after exposure to media violence: a replication of the drabman and thomas studies,ó child study journal 24(3): 191207; and c.r. mullin and d. linz, 1995, òdesensitization and resensitization to violenceagainst women: effects of exposure to sexually violent films on judgments of domesticviolence victims,ó journal of personality and social psychology 69(3): 449459.19d. zillman and j.b. weaver, 1999, òeffects of prolonged exposure to gratuitous mediaviolence on provoked and unprovoked hostile behavior,ó journal of applied social psychology 29(1): 145165.20j. owens, r. maxim, m. mcguinn, c. nobile, m. msall, and a. alario, 1999, òtelevisionviewing habits and sleep disturbance in school children,ó pediatrics 104(3): 552 (abstract), available online at <http://www.pediatrics.org/cgi/content/full/104/3/c27> (may25, 2001); m.i. singer, k. slovak, t. frierson, and p. york, 1998, òviewing preferences,symptoms of psychological trauma, and violent behaviors among children who watchtelevision,ó journal of the american academy of child and adolescent psychiatry 37(10): 10411048.21k. harrison and j. cantor, 1999, òtales from the screen: enduring fright reactions toscary media,ó media psychology 1:117140.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.151the research base on the impact of sexually explicit materialspecific types of content that lead to fear will depend on the childõs developmental level. for example, preschoolage children are most disturbedby grotesque, visual images, such as monsters, whereas children in elementary school are more likely to be frightened by realistic images inwhich the danger they perceive could actually happen. teenagers tend tobe more frightened by abstract components of a story. data from studiesduring the persian gulf conflict showed that elementary school childrenbecame frightened by images of exploding missiles, whereas teen viewerswere more afraid of the idea that the conflict could spread. materialfrightening to a teenager may not even be processed by a younger child,who may not understand the abstract concepts that are less readilyvisualized.22social learning theory suggests that children learn through observation and modeling of behaviors and actions, and it is often used to explainthe phenomenon of children imitating what they see on television or infilms. there are numerous studies documenting a correlation betweenmedia exposure to violence and childrenõs aggressive behaviors. for instance, a study in israeli middle schools after the introduction of the worldwrestling federation to israeli television documented the widespreadimitation of acts demonstrated on this show that resulted in numerousplayground injuries,23 and a juvenile was recently tried and convicted forhomicide against a small girl in what the juvenile claimed was an imitation of professional wrestling moves.24it is unknown if responses to media violence are cumulative (e.g.,attitudinal changes resulting from repeat exposure) or instantaneous (e.g.,fear responses due to seeing the òwrongó movie at the òwrongó developmental moment), if they are temporary or lasting (e.g., a few nightmaresor a lasting fear of specific animals or situations), how the impact ofexposure to media violence varies with the kinds of violence being seen,and how the context of viewing violence (e.g., news reports vs. òslasherómovies) may have differential effects on children. furthermore, additional research is needed before extrapolating results from this research22j. cantor, 1998, òmommy, iõm scaredó: how tv and movies frighten children and what wecan do to protect them, harcourt brace, san diego, calif.; j. cantor, m.l. mares, and m.b.oliver, 1993, òparentsõ and childrenõs emotional reactions to televised coverage of thegulf war,ó pp. 325340 in desert storm and the mass media, b. greenberg and w. gantz,eds., hampton press, cresskill, n.j.23donnerstein and linz, 1986, òmass media sexual violence and male viewers: currenttheory and researchó; zillman, 1982, òtransfer of excitation in emotional behavioró; d.lemish, 1997, òthe school as a wrestling arena: the modeling of a television series,ócommunication 22(4): 395418.24òboy gets life for ôwrestleõ killing,ó st. petersburg times, march 10, 2001. availableonline at <http://www.sptimes.com/news/031001/state/boygetslifeforwr.shtml>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.152youth, pornography, and the interneton violent material to sexually explicit material, although research onviolence may be relevant to sexually violent content.6.2.2sexually violent materialresearch on the effects of viewing sexually violent images has focusedon collegeage viewers. effects observed in these studies were similar toeffects seen in studies on violence without sexual content. studies of youngadults (aged 18 to 20) watching an hour of the equivalent of an rrated filmcontaining sexual violence have demonstrated desensitization effects immediately after viewing. levels of physiological arousal decreased withadditional viewing after the first hour. furthermore, viewers shown adocumentary on battered women after an hour of watching a sexuallyviolent film demonstrated less empathy toward the victims, and gave lowerevaluations of how injured the woman was and how painful the experiencemay have been. attitudinal changes have also been observed, with bothmen and women more likely to display callous attitudes toward femalevictims, such as stating that a rape was the fault of the victim or that shebrought it on herself.25 women viewers do have slightly different responsesfrom men, and although both show desensitization, women also tend toexperience an increase in fear after watching sexually violent content,26 inlarge part because they are likely to be the victims of rape.although changes in attitude and arousal levels were measured inthese studies, it is not clear to what extent these changes may be lasting.for example, normal arousal responses tend to return after 24 hours, andthe òlongtermó changes in attitudes are based on studies that followsubjects for only a few weeks after viewing the material.27zillmannõs arousal theory suggests that sexually explicit content doesnot lead to any specific or consistent behavioral outcome in viewers. although sexually explicit content may produce emotional or physiologicalarousal, behavioral outcomesñwhich might include sexual expression,aggressive behavior, or altruismñdepend on the personality of theviewer, the environment, and context in which the material was viewed.2825e.i. donnerstein and d.g. linz. 1986. òmass media sexual violence and male viewers:current theory and research,ó american behavioral scientist 29(1):601618.26c. krafka, d. linz, e. donnerstein, and s. penrod. 1997. òwomenõs reactions to sexually aggressive mass media depictions,ó violence against women 3(2):149.27see, for example, d.g. linz, e.i. donnerstein, and s.m. adams, 1989, òphysiologicaldesensitization and judgements about female victims of violence,ó human communicationresearch 15(4):509522; d.g. linz, e.i. donnerstein, and s. penrod, 1988, òeffects of longterm exposure to violent and sexually degrading depictions of women,ó journal of personality and social psychology 55(5): 758768.28huston et al., 1998, measuring the effects of sexual content in the media: a report to thekaiser family foundation.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.153the research base on the impact of sexually explicit materialfrom the perspective of social learning theory, one can argue that behaviors that are learned are not necessarily performed.6.2.3exposure to nonviolent sexual materialmost studies of the impact of sexually explicit material in the mediaon adolescentsõ sexual attitudes and practices have been limited to thesexual content in mainstream media. youth exposed to content involvingsexual relations outside of marriage rated such behavior as significantlyless objectionable than did their peers who viewed either sexual relationsbetween married partners or nonsexual relations between adults,29 a finding consistent with social learning theory (i.e., disinhibition) or arousaltheory (i.e., desensitization). viewing music videos increased the acceptability of premarital sex for teenagers as compared to teenagers who werenot similarly exposed.30 in some studies, youth exposed to explicit sexualcontent that did not involve violence did not become desensitized,31 whilein others, large amounts of experimental exposure to such material ledmen (and to some extent women) to be more callous toward gender relationships, more likely to overestimate the prevalence of certain kinds ofnonmainstream sexual behavior such as sadomasochism and bestiality,less likely to be offended by sexually explicit material, less likely to support restrictions on the distribution of sexually explicit materials, andmore likely to support lighter sentences for convicted rapists.32many media messages suggest to adolescents that they should bethinking about sexual activity, and engaging in it early. frequent televi29j. bryant and s.c. rockwell. 1994. òeffects of massive exposure to sexually orientedprimetime television programming on adolescents moral judgment,ó pp. 183195 in media, children, and the family: social scientific, psychodynamic, and clinical perspectives, d.zillmann, j. bryant, and a.c. huston, eds., erlbaum, hillsdale, n.j.30l.e. greeson and r.a. williams, 1987, òsocial implications of music videos for youth:an analysis of the content and effects of mtv,ó youth & society 18(2): 177189; j.s. strouse,n. buerkelrothfuss, and e.c. long, 1995, ògender and family as moderators of the relationship between music video exposure and adolescent sexual permissiveness,ó adolescence 30(119): 505521.31d.g. linz, e.i. donnerstein, and s. penrod, 1988, òeffects of longterm exposure toviolent and sexually degrading depictions of women,ó journal of personality and socialpsychology 55(5): 758768; d.g. linz, e.i. donnerstein, and s.m. adams, 1989, òphysiologicaldesensitization and judgments about female victims of violence,ó human communicationresearch 15(4): 509522.32regarding callousness toward gender relationships, they were more likely to agree thatòpickups should expect to put outó and òa woman doesnõt mean ônoõ unless she slaps you.óregarding lighter sentences, those with large amounts of experimental exposure recommended incarceration times that were 53 percent as long as those with no exposure at all.see d. zillmann and j. bryant, 1982, òpornography, sexual callousness, and the trivialization of rape,ó journal of communication 32(4): 1021.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.154youth, pornography, and the internetsion viewers are less likely to believe that marriages are happy or lasting,prompted perhaps by the depiction of married couples who are not happy,not having sex, or having sex with a person other than their spouse.33compared to nonviewers, soap opera viewers appear to believe thatsingle mothers have relatively easy lives, with good jobs, high levels ofeducation, significant leisure time, and freedom from poverty. they werealso more likely to believe that the male friends of a single mother will beimportant in her childrenõs lives.34in one study, teenagers frequently viewing television with a high degree of sexual content were more likely to engage in sexual intercoursethan those who viewed television with a smaller proportion of sexualcontent, though it is unclear whether viewing such content contributes toa teenõs decision to engage in intercourse, or instead, whether those whoare already engaging in sexual activity are more likely to seek out suchprograms.35 a longitudinal study found no strong or consistent evidencefor links between the amount or sexual content of television viewing bychildren and the initiation of sexual activity.36 other studies have suggested that frequent viewers of mainstream television programs tend tohave more negative attitudes toward remaining a virgin and that becoming a nonvirgin is a priority.37many studies indicate that the media seem to have an effect on attitudes, although it is difficult to assess whether these attitudes are longlasting, the extent to which attitudes are related to behavior, and the degreeto which the media, compared with other sources of experience in a youngpersonõs life, are influential in shaping the choices a young person makes.for example, although studies have shown that viewing fashion magazinestends to cause lower selfscoring by girls on body image indices, not allgirls become anorexic. in one study in which early adolescent females wereasked to keep journals about what they observed in the media about love,sex, and relationships, the participantsõ experience was extremely important in shaping how they interpreted and reacted to sexuality in the33n. signorielli. 1991. òadolescents and ambivalence toward marriage: a cultivationanalysis,ó youth and society 23(1): 1125.34m. larson. 1996. òsex roles and soap operas: what adolescents learn about singlemotherhood,ó sex roles: a journal of research 35(1/2): 97121.35j.d. brown and s. newcomer. 1991. òtelevision viewing and adolescentsõ sexual behavior,ó journal of homosexuality 21(1/2), 7791.36j.l. peterson, k.a. moore, and f.f. furstenberg. 1991. òtelevision viewing and earlyinitiation of sexual intercourse: is there a link?,ó journal of homosexuality 21(1/2): 93119.37brown and newcomer, 1991, òtelevision viewing and adolescentsõ sexual behavioró;strouse et al., 1995, ògender and family as moderators of the relationship between musicvideo exposure and adolescent sexual permissiveness.óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.155the research base on the impact of sexually explicit materialmedia.38 one prepubertal 12yearold did not want to see sex in the media,while other girls who were beginning to think about relationships werevery interested in the romantic heterosexual script. girls who had beensexually active were more critical of the mediaõs portrayal of sexual interaction and the roles male and females should take (according to these representations). experience, development, and age made enormous differencesin the types of reactions girls had to media depictions about sex.6.2.4caveats and cautionsalthough some literature exists on traditional forms of media (e.g.,television, radio, magazines), the empirical research that examines theimpact on children of exposure to nonviolent sexual material is extremelylimited.39 social mores and ethical issues generally prevent u.s. scientistsfrom studying the impact of media on sexual behavior (box 6.1). becausethere are so few studies in this area, the empirical research that does existmust be viewed with caution, and in particular must not be viewed asmaking statements or supporting conclusions that go beyond the researchdesigns employed.¥correlational studies do not permit one to make causal inferences.for example, in the studies mentioned in footnote 37, it is possible that athird factor, such as different values and beliefs about sexual activity, isactually responsible for the trend in attitude described and that televisionviewing is an extraneous variable.¥some researchers have attempted to avoid the complications ofstudying minors by observing the impact of sexually explicit material oncollegeage viewers. these studies seek to extrapolate the impact thismaterial may have on younger populations. it is not clear to what extentthis generalization is appropriate because younger individuals have verydifferent developmental needs and experiences than do collegeage students. some research has suggested that collegeage students viewingsexually explicit material may develop more callous attitudes towardwomen and female sexuality, but it has not been clear to what extent theseattitudes are lasting.4038sarah keller, 2000, òhow do early adolescent girls use media to shape their romanticidentities?,ó unpublished doctoral dissertation, university of north carolina, chapel hill.39for instance, a kaiser family foundation report reviewed existing research on the media, finding no more than 15 empirical studies on this topic. see huston et al., 1998, measuring the effects of sexual content in the media.40donnerstein and linz, 1986, òmass media sexual violence and male viewers: currenttheory and researchó; zillmann and bryant, 1982, òpornography, sexual callousness, andthe trivialization of rape.óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.156youth, pornography, and the internet¥experimental studies typically examine impact on time scales ranging from minutes to days (in a small number of cases, effects are measured 3 to 6 weeks after the experimental treatment). for example, viewing a television program may change a personõs immediate state byinducing arousal, leading to inhibition of impulses, or activating thoughtsor associations, and in doing so might have immediate influence on oneõsbehavior. however, such studies do not provide an empirical basis fordetermining impact over longer time scales (e.g., months to decades), andin particular cannot provide a sound empirical basis for claims of longterm deviant sexual behavior resulting from exposure to sexually explicitmaterial in oneõs youth.societal impact is better assessed using longitudinal data that measures longterm effects. experimental studies do not address longtermimpact, and there is significant debate and disagreement over whetherresults of such experiments can be extrapolated to the long term. forexample, some studies of collegeage students suggest that males viewingsexually violent movies displayed more callous attitudes toward femalevictims.41 however, these attitudes were tested immediately after viewing the film and several weeks later with no further followup. longerterm effects have simply not been measured. there also is little information as to how other experiences might interact with and mitigate some ofthese negative attitudes.¥it is difficult to generalize clinical research to broader populationsbecause of the sampling issue. those who seek or obtain clinical treatment for criminal sexual behavior, for example, are hardly a representative sample of the population that may or may not have been affected bythe viewing of sexually explicit material in their youth.¥empirical studies examining the impact of exposure to other media content (e.g., studies of the impact of viewing violence) cannot beextrapolated with confidence to the sexual domain. studies that measurethe impact of violent material are sometimes used to speculate about theimpact of sexually explicit material on the basis that learning processesthat underlie both types of content are similar. although one can envisionsimilarities between the effects of watching violent and sexually violentmaterial, the impact of content that is sexually explicit but not violent maybe very different. no research is available to establish the extent to whichit is appropriate to extrapolate from studies of one type of media contentto other types.41donnerstein and linz, 1986, òmass media sexual violence and male viewers: currenttheory and researchó; zillmann and bryant, 1982, òpornography, sexual callousness, andthe trivialization of rape.óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.157the research base on the impact of sexually explicit material¥crosscultural studiesñto which researchers sometimes turn toidentify possible connections between exposure to sexually explicit material and behavior, and which are made necessary by ethical and legalconstraints in doing research in this area in the united statesñhave limited applicability. for example, crosscultural studies of youth being exposed to nudity and explicit material at a relatively young age do notshow higher levels of sexual addiction or teen pregnancy in europeancountries compared with the united states. however, european childrenalso receive early, frequent, and comprehensive sex education in a waythat is not typical in the united states. this could suggest that such education offers a useful context for interpreting sexually explicit material. itmay also suggest that sexually explicit material does not have the type ofimpact on behavior that some may fear.6.3factors affecting the impact on minorsof exposure to sexually explicit materialthe phrase òimpact on minors of exposure to sexually explicit materialó used by itself obscures a number of important differentiating factors,because òimpact,ó òminors,ó òexposure,ó and òsexually explicit materialóall have a wide range of meaning. without considering these differences,an overly simplistic analysis is inevitable. consider each of these terms inturn.6.3.1impactas noted above, impact can be measured in the short term or longterm. its magnitude can be large or small (and people with differentvalues will differ on whether a given change in a certain dimension islarge or small). and a particular impact may be desirable or undesirable.(the desensitization of a teenager who has been viewing sexually explicitbehavior on an adult web site can be regarded as undesirable, if onebelieves that such depictions should be shocking and socially unacceptable, or as desirable, if one believes that a desensitized individual willsimply ignore such images in the future.) moreover, òimpactó may not beconfined to the direct results of exposure to sexually explicit material (forexample, impact may also include the punishment that a teenager mightreceive for viewing such material).6.3.2minorschildren from birth to 17 or 18 vary widely in maturity and developmental perspective. the broad range of cognitive, social, emotional, andyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.158youth, pornography, and the internetmoral reasoning and developmental abilities encompassed by this agerange means that a 6yearold will react differently than a 16yearold tosexually explicit content. the youngest children may not find such images remarkable or memorable because they do not have the cognitiveabilities or understand the social meaning of explicit images. in contrast,because they are becoming curious about sex and are experiencing changing bodies and a changing social landscape, those in the 9 to 12 age rangemay be more vulnerable to disturbing portrayals of sex and sexual activity. (for perspective, note that the mean age of first intercourse is around17 1/2 years of age, as discussed in section 5.2.)among the adolescents to whom the committee spoke, those in highschool (the 11th and 12th grades) were much less concerned about exposure to sexually explicit material on the internet than were middleschoolstudents. indeed, the 11th and 12th graders noted that they were exposedto similar material in every other part of their lives, and they now found itmore annoying than upsetting. by contrast, the middleschoolers wereless nonchalant and tended to be more concerned about such material.6.3.3gendergender is also likely to influence the impact of sexually explicit material on young people in part because it will influence how and with whatcharacters young viewers identify. this is not to suggest that girls willonly identify with female characters and boys with male characters, butthe gender of the viewer will certainly affect how one interprets the treatment of characters. in addition, some research suggests that girls andboys select different types of media (e.g., glamour has a broad femalereadership) and use them in different ways. for example, some studiessuggest that girls use the media to gain insight about interpersonal relationshipsñin one study girls who viewed a video about teen pregnancyreflected more about the content than boys.42in the context of viewing sexually explicit material (especially images), the overwhelming majority of such material is oriented towardmale consumers, with females being the object of sexual activity, andboys tend to be more interested in visual depictions of sexual images thanare girls.43 put another way, preadolescent and adolescent males are42m. thompson, k. walshchilders, and j.d. brown, 1993, òthe influence of family communication patterns and sexual experience on processing of a movie video,ó pp. 248263 inmedia, sex and the adolescent, b.s. greenberg, j.d. brown, and n.l. buerkelrothfuss, eds.,hampton press, n.j.43for example, men demonstrate greater interest in visual sexual stimuli than do women(j.m. bailey, s. gaulin, y. agyei, and b.a. gladue, 1994, òeffects of gender and sexualyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.159the research base on the impact of sexually explicit materialmore likely to view online adultoriented sexually explicit material thanare females of the same ages.446.3.4special needsthe experiences of minors encompass a very wide range, and certainsegments of the population may be more susceptible to influence andimpact than others. for example, one site visit of the committee took it toa residential school for young girls who had been sexually abused. staffat the school expressed to the committee the concern that for these girls,sometimes at the start of a very long recovery process fraught with psychological and emotional pitfalls, even one exposure to a sexually violentor abusive imageñespecially if they were not prepared for itñcould behighly damaging to them and to their recovery.6.3.5exposureone dimension of exposure is the type of stimulus involvedñvisual,still or moving, textual, and so on. a second dimension is the intensityand duration of exposureñ3 hours per day, every day, for 5 years isobviously different from once for 3 minutes in the last 2 years. mostresearch in this area, sparse though it is, has focused primarily on theimpact of exposure patterns that are quite frequent and deliberate ratherthan incidental or inadvertent and rare, and have involved primarily visual stimuli.a third dimension of exposure is the context in which it occurs. inparticular, parental involvement in adolescent television viewing and dialog about the meanings conveyed in depictions of sexual activity caninfluence the relationship between viewing and sexual behavior. for example, one study showed that adolescents who did not talk with theirparents about television were more likely to have sexual intercourse thanthose who did.45 the style with which families communicate about theorientation on evolutionarily relevant aspects of human mating psychology,ó journal ofpersonality and social psychology 66(6): 10811093). in the context of sexual fantasy, visualimagery is also more important for men than for women (b.j. ellis and d. symons, 1990,òsex differences in sexual fantasy: an evolutionary psychological approach,ó journal ofsex research 27(4): 527555). one caveat: these studies were conducted using adult subjectsrather than minors.44in surveying adults, a nielsen media survey found that about twothirds of the users ofsexually explicit internet sites are male. see commercenet/nielsen media, 1998, internetdemographic study, june.45peterson et al., 1991, òtelevision viewing and early initiation of sexual intercourse: isthere a link?óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.160youth, pornography, and the internetmedia also seemed to influence the way adolescents interpret sexual content in the media.46a fourth dimension of exposure is whether exposure has been voluntary or involuntary, as discussed in sections 5.5.1 and 5.5.2. most of theresearch known to the committee regarding exposure to sexually explicitmaterial has involved voluntaryñand hence anticipatedñexposure. thus,little is known empirically about the impact of involuntary and unanticipated exposure. given that inadvertent exposure to sexually explicit material on the internet generally occurs at some point, an important question isthe nature and extent of the impact of a surprise encounter.6.3.6the type of sexually explicit materialthere is a very wide range of material that different people regard assexually explicit, including photos of models in bathing suits, coupleshaving intercourse, group sex scenes, sadomasochism, gay and lesbiansex, and erotic texts of the kama sutra or the joy of sex, as well as scholarlyworks such as those of masters and johnson.47 as noted above, the impact of images depicting sexual violence is likely to be different from theimpact of images depicting nonviolent and consensual sex; presentationof the material is also likely to affect the nature of the impact (e.g., thedifference in portrayal of sexuality in playboy compared to that in ourbodies, ourselves).along the lines of presentation, realism in the media (or at least thatwhich young people perceive as being believable portrayals of sexuality)may be more influential than depictions that seem less realistic. depictions of sexuality that are realistic but romanticized or idealistic mayencourage young people to have unrealistic expectations of sexuality andmay induce or influence young people to adopt these portrayals as guidesto sexual behavior and romantic relationships.4846thompson et al., 1993, òthe influence of family communication patterns and sexualexperience on processing of a movie video.ó47see, for example, william masters and virginia johnson, 1966, human sexual response,little, brown and company, boston; william masters and virginia johnson, 1970, humansexual inadequacy, little, brown and company, boston.48huston et al., 1998, measuring the effects of sexual content in the media: a report to thekaiser family foundation.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.1617.1challenges to parentsone of the strongest challenges that many parents face with respect totheir childrenõs exposure to sexually explicit material is their own ambivalence toward it. such parents assert that they object to their children viewing sexually explicit material, but in the conduct of their own lives tolerateit and may even seek it out. this is not to say that all parents who assertsuch objections behave inconsistently with their stated positions, but thefact that the adult entertainment business is as profitable as it is suggeststhat at least some parents say one thing and do another. and, even if theydo not seek it out, many parents are active and by and large willing participants in a culture that glorifies the particular style of sexual engagementand interaction that is illustrated in the media. thus, it is important toconsider what messages parents are delivering to their children.a second point to be considered is that traditional nuclear familiesare increasingly less common. according to the u.s. census, the numberof women living with their own child but without a husband grew by 25percent from 1990 to 2000. the number of unmarriedpartner homesincreased by 60 percent in this period. furthermore, even in nuclearfamilies, stayathome parentsñwho might provide supervisionñare inthe minority. of married women with children aged 6 to 17, 39 percentworked outside the home in 1960, 49.2 percent in 1970, and 77.1 percent in1999.1 also, there are samesex couples living together openly in virtually7beyond the science: perspectiveson impact and the public debate1for the 1960 figure, see òemployment status of women, by marital status and presenceand age of children: 1960 to 1998,ó statistical abstract of the united states: 1999, table no.659, p. 417, available online at <http://www.census.gov/prod/99pubs/99statab/sec13.pdf>. for the 1970 and 1999 figures, see òemployment status of women, by marital statusand presence and age of children: 1970 to 1999,ó statistical abstract of the united states:2000, table no. 653, p. 409, available online at <http://www.census.gov/prod/2001pubs/statab/sec13.pdf>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.162youth, pornography, and the internetevery county in the united states, suggesting that social attitudes abouthomosexuality may be becoming more tolerant.overall, while parents enjoy broad discretion to raise their children asthey see fit, it is likely that nonparental influences on children have increased over the past several decades. for example, the extent to whichchildren are engaged with various media has increased considerably.schools have been asked to take over responsibilities for many activitiesfor which parents have been traditionally responsible, ranging from serving breakfast to providing sex education.the internet itself presents particular challenges for parents that arenot posed by other media. the generation gap with respect to the internetis large and profound. perhaps for the first time, childrenñas a groupñare more knowledgeable than their parents about an increasingly pervasive technology.2 these òdigital childrenó3 have never known a worldwithout personal computers, and many have been exposed to the internetfor a very large fraction of their lives (box 7.1). they also have the timeand the inclination to explore the limits of the technology. the result isthat, compared to their parents, they are more knowledgeable about howto do things on the internet and with other forms of information technology, and more knowledgeable about what things can be done and whatexperiences can be had on the internet. in practice, such expertise makesthe teenager rather than the parents the inhouse expert on computers,and such reliance on the teenagers whom one is trying to guide andparent presents interesting challenges not generally faced by parents inthe past.testimony to the committee provided one very clear example of thisphenomenon. a teenager, knowing that her mother would òfreak outó atthe online solicitations and invitations to view commercial sexually explicit material that she was receiving,4 simply set up an aol account forher mother with parental controls set to òyoung teen,ó thereby blockingher mother from receiving such material. her mother, not knowing whatwas being blocked, expressed surprise that her online experience wasmuch less intrusive than she had been led to believe.2the childrenõs partnership. 1999. the parentsõ guide to the information superhighway:rules and tools for families online, second ed. available online at <http://www.childrenspartnership.org/> (october, 5, 2001).3don tapscott. 1998. growing up digital: the rise of the net generation. mcgrawhill.4this testimony is consistent with a study undertaken by the girl scout research institutefinding that ò30 percent of girls (responding to the study) had been sexually harassed in achat room, but only 7 percent told their mothers or fathers about the harassment, mostfearing their parents would overreact and ban computer usage altogether.ó see whitneyroban. 2002. the net effect: girls and new media. girl scout research institute, new york.available online at <http://www.girlscouts.org/about/pdfs/neteffects.pdf>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.163beyond the science: perspectives on impact and the public debatebox 7.1experiences on the internet and with computersthe following information was obtained in a survey of 500 teenagers aged 12 to17 that was conducted by family pc magazine in the fall of 2000.usage¥80 percent spend 1 to 5 hours a week on email.¥75 percent spend 1 to 5 hours a week online doing homework and research.¥66 percent spend 1 to 5 hours a week web surfing.¥31 percent have a computer in their room.the teenagers surveyed had been online for an average of 3.7 years.life with a computer at home¥63 percent said they had to compete with parents or siblings for computertime.¥75 percent said families had a computer before they turned 12.¥9 percent said the computer came home before they were born.interacting with people online¥38 percent preferred telephone contact to stay in touch with friends, while 33percent preferred online mechanisms.¥83 percent used email to stay in touch with distant friends and relatives.¥84 percent used instant messaging and email to communicate with otherpeople for any purpose.¥44 percent used chat rooms, but only 10 percent used chat rooms regularly.¥32 percent thought it was easier to say personal things online versus facetoface.online friendships¥33 percent met someone online with whom they still keep in touch.¥21 percent arranged to meet their efriend in person.¥girls were more likely than boys to arrange a facetoface meeting (26percent versus 14 percent).computer educationof the teens surveyed, 55 percent had taken a computer class, including¥62 percent of boys and¥51 percent of girls.source: a field guide to wired teens. 2000. digital research inc., kennebunkport, maine.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.164youth, pornography, and the internetmaking parenting in the age of the internet even more challenging isthe fact that some realworld lessons do not carry over well to cyberspace.for example, most parents have told their children to ònever talk to strangers.ó as evidenced by many new penpal relationships between youngpeople in remote parts of the world, this kind of òcommunication withstrangersó can be an invaluable learning experience that allows youngpeople to develop awareness of global issues and even a global sense ofcommunity. however, a sense of online community can also be extremelymisleadingñespecially to neophyte internet usersñin creating a sense ofsafety and trust that is in fact unwarranted.rules of behavior in cyberspace are sometimes different than in reallife, and new behaviors and traditions are created. these online socialmores are often a mystery to parents, though their children may be quitecomfortable with them. for example, technology enables multitasking toa much greater degree than has been possible in the past (e.g., conductinga number of conversations via instant messages and telephone simultaneously),5 whereas a rule that governs many, though not all, adult interactions with other people is one of paying full attention.issues with a long history in the real world play out differently incyberspace. parents who once fought with kids about messy rooms andtelephone time must now deal with conflicts over computer usage as well.childrenñwho always resisted the notion of sharing diaries with theirparentsñmust contend with the possibility that their email might bemonitored or the history of their web visits viewed. academic plagiarism is much easier in an internet environment and thus is arguably moretempting. sorting out truth from fictionña task that has always beenimportantñis more important than ever before given the nearinfinitediversity of content on the web. bullyingñalways a problem in somecontexts in real lifeñhas its online analogs in harassment, and is sometimes protected by the anonymity provided by the internet.finally, there is often a large gap in what parents perceive their children are doing on the internet and what these children report they areactually doing (table 7.1). this, too, reflects an alltoocommon and moregeneral disconnect between parental perceptions of their childrenõs behavior and what they actually do.65katie hafner. 2001. òteenage overload, or digital dexterity?,ó new york times, april 12.6for example, in april 1998, the partnership for a drugfree america released a studyindicating that many babyboomer parents òare seriously underestimating the reality ofdrugs in their childrenõs lives.ó in support of that claim, the study noted that¥38 percent of parents said their teenagers might have been offered drugs; 59 percent ofteenagers reported having been offered an illicit substance.¥21 percent of parents acknowledged the possibility that their teenager might have triedmarijuana; 44 percent of teens said theyõd done so.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.165beyond the science: perspectives on impact and the public debatenone of these challenges obviate a parental role, or even a role forother adults, in ensuring a safe and appropriate internet experience.while some children may know the technology better than their parents,parents and other adults still have important roles to play in shaping thevalues of their children and in teaching critical thinking and moral skillsthat allow children to make informed and ethical choices according to thevalues that are important to them. in short, the parental role is still centralin teaching children to protect themselves on the internet.table 7.1 parentsõ lack of knowledge about the internet activities oftheir teenage childrenparents who believe childchildren who reportactivityis doing this activitydoing this activityposting personal online17 percent45 percentprofilesahaving private email68 percent81 percentaccountsacorresponding with30 percentmore than 50 percentstrangersawhile using the internet,67 percent of parents78 percent say theysomeone else is regularlyreport that someoneuse the internetin the roombelse is in the roomwhen they arewhile their childrenaloneare onlineusing the internet at home76 percent63 percentfor schoolwork at leastonce a weekbapenn, schoen, and berland associates. 2000. web savvy and safety: how kids and parent differin what they know, whom they trust, september. available online at <http://www.microsoft.com/presspass/press/2000/nov00/safetywebsitespr.asp>.bnational school boards association (no date available). safe and smart: overview of research and guidelines for childrenõs use of the internet.ó available online at <http://www.nsbf.org/safesmart/fullreport.htm>.¥33 percent of parents said they believed their teenagers viewed marijuana as harmful;18 percent of teens viewed trying marijuana as risky.¥45 percent of parents believed their child might have friends who smoked marijuana;71 percent of teens said they had friends who used it.source: partnership for a drugfree america. 1998. the boomerrang: baby boomers seriously underestimating presence of drugs in their childrenõs lives. available online at <http://www.drugfreeamerica.org/newscenter/pats/pats1.asp?ws=pdfa&vol=1&grp=newscenter&cat=national+surveys&top=articles&pyear=1997&pname=pats199x.asp&pnum=9>. more recent data from the partnership for a drugfree america, as yet unpublished, indicate similar trends.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.166youth, pornography, and the internet7.2speculations and other perspectiveson possible impactas the discussion in chapter 6 indicates, the research literature on theimpact of sexually explicit material on young people is sparse and inconclusive. nevertheless, there are a variety of views on the potential negative impact that exposure to sexually explicit material might have onchildren, some of which are illustrated in box 7.2. further, there is noreason to suppose that all negative impacts are necessarily manifested insciencebased research studies.one issue of concernñmentioned by many parents in the committeeõssite visits as being far more troublesome to them than the issue of exposure to inappropriate sexually explicit materialñis the fear that childrenwill be physically victimized by someone whom they met through theinternet. among many of the students with whom the committee spoke,meeting someone facetoface whom they had initially encountered onlinewas a common and accepted part of life, more common among girls thanboys. some of these facetoface encounters occurred at parties, othersoneonone at malls, and in one case at a personõs home. most studentsknew that they should not give out personal information, such as realnames and addresses, but they were generally overconfident in their ability to make judgments in potentially dangerous situations. for example,the committee spoke to one teenage girl who appeared to understand thatpeople often lie online, that meeting internet acquaintances facetofacecan be dangerous, and that things are not always what they seem. however, when asked if she would meet someone from the internet, she said,òsureñif i had any doubts about him, i would never do soñand i only doit with people i know are okay.óanother type of negative impact that has not yet been studied is thedamage that results from online attacks on the character of an individualyouth. for example, from time to time, the facial image (a head shot) of astudent may be grafted onto a sexually explicit image using a softwarepackage such as photoshop. distribution of such a doctored image can bequite harmful to the student whose face is on the image, perhaps in partbecause in many cases, it is someone in the young personõs physical community who has spread the rumor or image and the receiving audienceare other students or friends also in the young personõs physical community. on the committeeõs site visits, a number of students reported problems with online (and anonymous) harassment in the form of spreadingrumors about oneõs character and sexual behavior or threatening someone with bodily harm.77such behavior is similar in some ways to the use of the bathroom wall at school as aplatform for someone writing nasty comments about a classmate, but electronic communiyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.167beyond the science: perspectives on impact and the public debatecation allows such rumors to be forwarded and disseminated much more rapidlyñwith allof the attendant negative consequences.box 7.2views of the advocatessexually explicit materials are bad for societyantipornography advocates believe that pornography is linked to a variety ofsocially destructive behavior, such as rape, child molestation, and sexual dysfunction.1 furthermore, pornography is seen as disseminating dangerous misinformationabout sexual relations and as promoting medically risky sexual practices, especiallyamong adolescent boys, who are large consumers of sexually explicit material. oneindividual often quoted by those in the antipornography camp is park elliot dietz,who has written:pornography is a medical and public health problem because so much of it teachesfalse, misleading, and even dangerous information about human sexuality. . . . aperson who learned about human sexuality in the òadults onlyó outlets of americawould be a person who had never conceived of a man and a women marrying oreven falling in love before having intercourse, who had never conceived of tenderforeplay, and who had never conceived of procreation as a purpose of sexualunion. instead such a person would be one who had learned that sex at mostmeant sex with oneõs children, stepchildren, parents, siblings, pets, and withneighbors, plumbers, salesmen, burglars, and peepers.2antipornography advocates argue further that exposure to pornography thatcombines erotic images with violent images normalizes sexual assault and desensitizes men to rape. for example, they point to correlations between states in whichlarge amounts of pornography are sold and high rates of rape, and between greaterinclinations toward sexual coercion and being raised in home in which fathers readpornographic magazines and talked about watching xrated movies. they also drawon clinical studies of sex offenders and selfdescribed pornography addicts. forexample, they note that a large fraction of sex offenders, child molesters, and thoseconvicted of sexual assault are avid consumers of pornography. as for children, antipornography advocates argue that child pornography normalizes and promotes thesexual abuse of children. graphic imagery is used to persuade children that sexualactivity is normal and that other children willingly participate in such activities.many of these advocates believe that viewing pornography, even for a moment,can have dire consequences. for example, american family online believes that1views of the òantipornographyó advocates can be found online at <http://www.cwfa.org/library/pornography/199806pppoison.shtml> and <http://www.chuckiii.com/reports/socialissues/pornography.shtml>. the material in this section is derived from content found online at<http://www.cwfa.org/library/pornography/199806pppoison.shtml> and <http://www.chuckiii.com/reports/socialissues/pornography.shtml>.2closing statements of the meese commissionõs final report. see attorney generalõs commission on pornography. 1986. final report. u.s. government printing office, washington,d.c., july.(continues)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.168youth, pornography, and the internetòpornography is dangerous, and viewing it (even for a moment) can set off a terriblechain of events.ó3 the american family association stated that òted bundy startedon his road to perversion and murder by innocently looking at ônudieõ magazines asa boy. it only took one time for him to become hooked.ó4in addition, some commentators argue that even shortterm exposure to certainsexually explicit materials has longlasting physiological effects. for example, jodihoffman, founder of restore americaõs moral pride, wrote, òsomeone on this list...has made numerous attempts at convincing us that pornography ôdoes no harmõ tochildren. . . . studies have shown that an event which lasts even so much as threetenths of a second, within five to ten minutes has produced a structural change in thebrain. exposure to porn causes actual brain damage, especially in a child.ó5feminist antipornography advocates believe that pornography degrades womenby portraying them as sexually insatiable objects of male pleasure in a world ofsexual inequality, and that pornography contributes to male contempt for womenthat can ultimately lead to sexual violence and rape.finally, antipornography advocates argue that pornography eliminates from sexual acts the emotional intimacy needed to promote healthy relationships by reducingwomen and children to sex objects to be used on demand. consumption of pornography is seen as the first step toward sexual addiction. drawing on arousal theory,they argue that consumers of pornography are compelled to partake of more frequentòdosesó of more varied and more extreme pornography in order to obtain the samesexual high. eventually, they argue, the individual must act out the scenes beingdepicted to obtain the sexual highsñand that the scenes depicted are obviously bad.such individuals thus become incapable of natural sexual relationships.sexually explicit materials have benefits for societya different set of views is expressed by those who believe that the widespreadavailability of sexually explicit materials has benefits for society.one writer argues that the insistence on limiting such availability demonstratesrestrictive attitudes toward sexual expression, and that òsocieties which hold restric3see <http://www.afo.net/help/block/default.htm>.4see <http://www.afajournal.org/archives/24060000438.asp>.5see <http://www.inetone.com/cypherpunks/dir.1997.10.301997.11.05/msg00377.html>.box 7.2 (continued)still a different kind of negative impact of childrenõs exposure tographic, adultoriented, sexually explicit material is attributable not somuch to the material per se as to the fact that exposure to such materialmay occur in a setting when a parent is not available to place the materialinto context, to explain why viewing such material is inappropriate, or toimpart parental values with respect to viewing such material. in thisview, children exposed to such material lose the opportunity to hear froma responsible adult making a critical point about the social assumptionsunderlying such images and portrayals and about values in society.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.169beyond the science: perspectives on impact and the public debatetive attitudes towards sexual issues tend to breed child abuse.ó6 she asserts that suchlegislated limitations add to òthe cultural squeamishness towards sex, which alreadyappears to play a major role in child sex abuse,ó and that when òchildren think thatsex is taboo, they will remain silent about being abused. if they think that they aredoing something dirty because they are being abused, they will feel guilty, responsible for the abuse, they wonõt speak up and theyõll continue to be abused.ó shefurther claims that restricting the availability of such materials is potentially hazardous for all women and children, citing the danish experience in which òpornography was made freely available in denmark in the late 60õs,ó resulting òin the incidence of sex crimes [and] sexual violence towards women and children, [dropping]markedly.ó òfar from causing harm,ó she continues, òpornography appears to havea cathartic effect on peopleõs sexuality. the denmark experience of the 1960õs teaches us that the incidence of sex crimes appears to lower dramatically when pornography is made freely available.óanother writer concluded that òafter thorough review of the existing research oneffects of pornography and violent material on the viewer, we can answer this question simply: there is no known harm caused by the actual viewing of pornographicmaterials, and results of aggression studies in relation to violent material have beenunable to demonstrate any changes in behavior in children after viewing such materials.ó7 she adds, òas of yet, no research has indicated a causal relationship betweenthese materials and antisocial behavior that is said to justify censorship.ófinally, according to another view, òresearch attempting to demonstrate a causallink between images and violence has not been able to show such a link. researchon offenders demonstrates that poverty, actual violence, and abuse in the personallives of offendersñand not media imagesñare the crucial factors in creating atendency toward violence and criminal behavior.ó8 in addition, òresearch on serious sex offenders demonstrates that rapists and abusers have been taught repressivemessages about sex, masturbation, and pornography, and that antipornography activism actually exacerbates the problems that lead to sexual assault and abuse.ó6patricia petersen, speech given on may 28, 1999, available online at <http://www.efa.org.au/campaigns/may28/bris/pp.html>.7carol avedon, 1994, censorship wonõt reduce crime, libertarian alliance pamphlet no.24, available online at <http://www.capital.demon.co.uk/la/pamphlets/censcrim.txt>.8frequently asked questions about òfeminists against censorship,ó available online at<http://www.mit.edu/activities/safe/data/feministsagainstcen>.a related point was made by a mother who voiced concern becauseher preadolescent son was worried that something was wrong with himbecause he was interested in sexual pictures. she felt that his interest wasa normal part of growing up but didnõt know how to talk to him about it.finally, some parents at the committeeõs site visits said that they sawno problem at all regarding their childrenõs exposure to sexually explicitmaterial, even though they recognized in general terms that there arealways some bumps in the path of any child who is growing up. onemother (of two daughters and no sons) told the committee that she didnõtyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.170youth, pornography, and the internetknow she might have a problem with her daughters until she spoke withthe committee and realized the issues the committee was investigating.however, it was not clear from what these parents said whether they didnot know what kinds of material were available on the internet, or if theydid know about the nature and extent of that material and were notbothered by it.as for other potential negative impacts on children, the lack of asubstantial base of sciencebased research allows only speculation. onepossibility is that the sexual behavior depicted on adult web sites and inother adultoriented material may be emotionally disturbing to the minorhimself or herself. to the extent that the dynamic range of sexual activityfound on the internet is broader than the range found in mainstreamsociety, one might suppose that an inexperienced or nałve minor could bedisturbed by images drawn from the more extreme end of the spectrum.someone disturbed by such images might report, for example, that he orshe is unable to get such images out of mind, or that he or she had nightmares involving such images.several youth who spoke to the committee reported that they werehighly upset when they inadvertently encountered sexually explicit material on the internet, but not because of its content per se. rather, theywere most concerned and worried about the reaction of their parents tosuch an eventñómy mom would freak out if she thought i was looking atthis stuff!ó in a couple of cases, such material had a negative impact onthe individual because his parent reacted vehemently with punishmentand censure.a related issue was the concern of these youth that their parents orteachers would not believe that they had encountered sexually explicitmaterial by accident. a number of parents who testified at committee sitevisits echoed this concern, noting that they had not believed their childrenwhen they (the children) had said that they had happened upon suchmaterial accidentallyñand that the reason for their disbelief was thatthey had never encountered it personally themselves.active participation in a certain kind of online culture may affect theparticipants because they are participating in it, as opposed to viewing it.for example, to protect themselves online, many youth obey the rules laiddown by responsible adults about not giving out their real names andaddresses onlineñthey lie about such information rather than withhold it.to the extent that they participate in cybersex, which for the most partrelates to only the physical aspects of sexual interaction, they are involvedin an interaction (often with strangers) that arguably facilitates detachedsexual activity without an emotional or personal context. in such a context,sex talk in chat rooms and in instant messaging (often known as òcybersexó)is constructed in public (in chat rooms) and in private (in instant messages),youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.171beyond the science: perspectives on impact and the public debateis linked to strangers, has little to do with relationships, is explicit, and isoften associated with the degradation of women. to the extent that responsible adults believe that it is inappropriate to promote lying and emotionally detached sexual expression, these connections to such online culturesmay be regarded as damaging and destructive.a second common type of conversation in a chat room is òtrash talkóthat insults and demeans others. public chat rooms provide a meansthrough which individuals with no prior association (i.e., strangers) caninteract with one another and provide no means for independently ascertaining the identity of any given participant. when chat rooms are unmonitored (and most are unmonitored8), it is common to see explicitsexual exchanges, joking about physical violence and assaults, degradation of others, aggression, and exchanges involving racial stereotypes andprejudice. online propositions to engage in cybersex are common, especially for those with identifiably female screen names.the young people to whom the committee spoke had experiencedsuch online behavior. consequently, many had stopped participating inchat rooms. others just ignored obnoxious or offensive ims, or blockedthe senders to prevent them from further contact. it is a further problemthat many parents have never been in a chat room and are entirely uninformed about the types of communication that occurs in many of them.the research regarding chat room behavior is sparse. for example,there are as yet no studies that compare the impact of sexually explicitweb sites to participation in a chat room, or that examine the impact ofchat rooms oriented toward sexually explicit interaction and dialog. because such channels are interactive, participants have greater control overwhat happens in the course of dialog, and other research on the media hassuggested that interactive forms of media in which participants havegreater control over the activity have greater influence and impact on theparticipants than those that are less participatory in nature.9finally, it is worth mentioning impacts on society as a whole. to thecommitteeõs knowledge, such impact has never been the subject of scientific research, and indeed may not be amenable to measurement. it is8some chat rooms are monitored. for example, a number of online services providemonitoring services for chat rooms specifically intended for young users. monitors havethe ability to send warnings, suspend users for certain amounts of time, terminate accounts,and send email to master accounts (presumably seen by parents), and these abilities are infact used to sanction misbehavior. monitors specifically watch for inappropriate conduct inthe chat room, though effectiveness depends on the attentiveness with which the monitorwatches the conversation.9s.l. calvert and s. tan. 1994. òimpact of virtual reality on young adultsõ physiological arousal and aggressive thoughts: interaction versus observation,ó journal of applieddevelopmental psychology 15(1): 125139.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.172youth, pornography, and the internetnonetheless important to acknowledge that interactions and behavior thatresult in reduced respect for human life and human dignity can damagethe common good and be negative for society. if internet exposure toexploitative sex and violence helps to desensitize youth to assaults onhuman life and human dignity, then society, whose future is these children, will be correspondingly weakened. objectionable speech and images on the internet, from which children should be protected or able toprotect themselves, do not represent values that strengthen society. thepoint of protecting childrenñbefore, during, or after the age of the internetñis to give them time to internalize principles and convictions consistent with those of their parents and the other responsible adults aroundthem, and to participate in a patient process that leads to the building of astronger society.7.3rhetorical concerns and issues of public debatethe research base described in chapter 6 contrasts with many of therhetorical points made in public debates over the issue of childrenõs viewing of sexually explicit material. for example, some individuals whobelieve that exposure to òpornographyó is harmful to children regularlycite the most extreme examples of sexual behavior to which most peoplewould object (e.g., sadomasochism, bestiality), but ignore the fact thatsome of what they would want to make inaccessible to children has beenroutinely available in national geographic and playboy magazine for decades. their opposite numbers in the political debate point to the desirability of disseminating information about preventing sexually transmitted diseases, but ignore the fact that such information is widely availablein other forums and that much of the sexually explicit material on theinternet has nothing to do with such issues.it is likely that both sides could reach agreement on the undesirabilityof exposing children to depictions of the most extreme and most graphicexamples of sexual behavior, in the sense that most of those on each side,acting as individual parents, would prefer to keep their children awayfrom such material, regardless of their age. however, they would partcompany on whether government should play a role; and, as importantly,they would be unlikely to agree on whether material that is less extremein nature is inappropriate or harmful.a great deal of sexually explicit material falls into the category overwhich consensus among diverse groups is not easily forthcoming. forexample:¥sex education is highly contentious, and some public schools avoidteaching anything about this topic because parents have such differentyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.173beyond the science: perspectives on impact and the public debateperspectives on what information is appropriate to provide to youngpeople. some parents feel that providing young people with informationon birth control is unacceptable because it conveys a permissive attitudeabout premarital sexual activity, and some believe that it increases thefrequency of sexual activity in minors. others feel that providing information related to sexual health and even access to birth control in schoolsis socially responsible because it may help to reduce the rates of transmission of sexually transmitted diseases and teen pregnancy by providing aplace for young people to obtain information that they would not getfrom their parents, and cite studies suggesting that sex education does notlead to increased sexual activity.10¥some materials address sexuality in a manner that is meant toexplore various dimensions of sexual desire, and these materials inevitably lead to differences of opinion about what behavior should be regarded as ònormal,ó òhealthy,ó or appropriate even for fantasy. the depiction of nontraditional scripts about how people interact romanticallyand sexually can help to broaden the choices that people make. (thetraditional script depicts romantic heterosexuality in which the male character is active and powerful both in pursuit of a female partner and insexual activity itself. the female character is portrayed as passive and coyand her power derives from luring a male partner.) instead of turning tosuch a traditional scene from a movie for perspective on how coupleshandle intimacy, a young person could go to the american social healthassociationõs teen sexual health web site <www.iwannaknow.org> andjoin a monitored chat room with other teens to talk anonymously aboutsexuality. the chat room supervised and facilitated by an expert in sexualhealth could be a more productive learning experience than the messagesa young person receives from a highly romanticized scene from a movie,though others might argue that such chats could give them ideas that theymight not otherwise have.¥other materials depict what it means to be lesbian or gay in sexualorientation; what for some people is a description of positive feelings10for example, the surgeon generalõs call to action to promote sexual health and responsiblesexual behavior noted that òprograms that typically emphasize abstinence, but also covercondoms and other methods of contraception, have a larger body of evaluation evidence thatindicates either no effect on initiation of sexual activity or, in some cases, a delay in theinitiation of sexual activity. this evidence gives strong support to the conclusion that providing information about contraception does not increase adolescent sexual activity, either byhastening the onset of sexual intercourse, increasing the frequency of sexual intercourse, orincreasing the number of sexual partners.ó see david satcher. 2001. the surgeon generalõscall to action to promote sexual health and responsible sexual behavior. office of the surgeongeneral, rockville, md. available online at <http://www.surgeongeneral.gov/library/sexualhealth/default.htm> (july 9, 2001).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.174youth, pornography, and the internetabout oneõs orientation is for others an endorsement of a perverse lifestyle.having two samesex people identified as a couple or depicting them askissing is very offensive to some people, whereas these activities are accepted without a second thought when a couple is heterosexual.¥as mainstream media content grows more sexually suggestive(e.g., lingerie advertisements, the sports illustrated swimsuit issue), individuals uneasy with such change might well regard such content asinappropriate.11¥content drawn from mainstream art and science has been calledpornographic. for example, a plaque carried on pioneer 10, the first spaceprobe to leave the solar system, was called pornographic because it included engravings of nude human figures.12 on some of the committeeõssite visits, various parties objected to internet images of classical greekstatues of the human body and leonardo da vinciõs vitruvian man.¥sexually explicit discussions may also be useful for minors whowish to remain celibateñsuch discussions might occur among such likeminded individuals in dealing with questions such as how to manageoneõs sexual desires without succumbing to peer and media pressure.extreme sexually explicit imagery to create sexual desire on the onehand, and responsible information on sexual health on the other, are arguably unrelated and, many would argue, easily distinguished. but muchcontent is not so easily categorized. while some extreme sexually explicitmaterial meets legal tests for obscenity (and therefore does not enjoy firstamendment protection), less extreme material may not. material regarding sexual health, mainstream erotica, lingerie advertisements, and models in swimsuits generally do enjoy such protection, at least for adults and11for example, according to fcc commissioner michael j. copps, òhundreds of americans have registered their displeasure at the victoriaõs secret program, and the promotionaladvertising that preceded it, that aired on network television [on november 15, 2001].ó bycoppsõs characterization, most of the complainants thought some of the material was indecent, and many were angered because the program and ads were run during a time in theevening when children were likely to be watching and when indecent programming maynot be aired in accordance with fcc rules. see <http://www.fcc.gov/speeches/copps/statements/2001/stmjc128.txt>.12for example, one newspaper published the images on the plaque, but erased the nipples,saying that ò[a] family newspaper must uphold community standards.ó another newspaper affiliated with a religious denomination said that the plaque should have had prayinghands rather than nudes. and a major newspaper printed the image in full, but received aletter from a reader that said, òi was shocked by the blatant display of both male and femalesex organs. . . . isnõt it enough that we must tolerate the bombardment of pornographythrough the media of film and smut magazines? isnõt it bad enough that our own spaceagency officials have found it necessary to spread this filth even beyond our own solarsystem?ó see william poundstone. 1999. carl sagan: a life in the cosmos. henry holt andcompany, new york.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.175beyond the science: perspectives on impact and the public debateoften for children. is it good or bad to know about and to see nonmainstream sexual behavior? knowledge about such behavior mightcreate an aversion to it, a desire for it, or simply a person better informedabout it. content and information that fall outside the realm of extremesexually explicit imagery are thus likely to be the source of greatest contention, and different people fear that such content would or would notfall under regulatory efforts aimed at reducing the exposure of minors tomaterial that is or may be sexual in nature.describing material as òinappropriateó is valueladen, in that onepersonõs definition of inappropriate will be different from that of another.one parent may feel that exposure of children to violence is much moreharmful than exposure to sexually explicit material, while another mayfeel the reverse. moreover, some parents believe that exposure to sexually explicit material poses moral danger (distinct from physical or psychological harm and danger) to their children, while others do not.7.4judgments in the absenceof a reliable research basereliable informationñthe outcome of rigorous researchñcould, inprinciple, indicate how, if at all, exposure to sexually explicit materialupsets minors, whether and how it changes their attitudes and/or theirbehaviors, and so on. but these effects are neither good nor bad absenta consideration of values. it is oneõs values that provide the basis fora determination of whether these effects are good or bad, desirable orundesirable.consider, for the sake of argument, as a hypothetical example that isnot demonstrated in the research literature, that there is a reasonably firmconsensus that brief exposure to sexually explicit material does not changesexual behavior but that individual attitudes become more accepting of avariety of sexual behaviors. one person might say that this outcome isbad or wrong if childrenõs attitudes toward certain sexual behaviors havebecome more accepting, even if their behaviors donõt change. anothermight strongly approve of the same attitude change. a third personmight object to such material as tasteless, crude, vulgar, or worse. each ofthese judgments would be informed according to his/her value system.13however, the research concerning the impact of exposure to sexuallyexplicit material on children across their entire development span is not13such differences also occur among larger social groups. for a discussion of such differences between nations, see computer science and telecommunications board, nationalresearch council, 2001, global networks and local values, national academy press, washington, d.c.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.176youth, pornography, and the internetrobust. while the charge to the committee, and much of the public debate,has been predicated on the assumption that exposure to òpornographyóhas negative effects on children, the committee has heard from a varietyof analysts and scholars presenting a range of both experimental andclinical work in this area, and it has reviewed the literature as describedabove. what has been demonstrated is that there is no scientific consensus on the nature or extent of the impact of exposure to sexually explicitmaterial on children. furthermore, emotions run so high in this area andstrongly held values relating to it are so intertwined with assessments ofimpact that even good empirical evidence is unlikely to change manyminds.in the absence of reliable empirical evidence, some people will say,òbecause the scientific evidence is lacking, we must not act precipitously.óothers will say, òeven if the scientific evidence is lacking, we must actimmediately.ó in each case, oneõs values and prior predispositions have astrong influence on oneõs assessment of a phenomenon. an individualpredisposed to believe that there is a significant negative impact or thatthere is no significant negative impact will thus require very strong evidence to change his or her mind. individuals and communities will ofcourse include as a part of their decisionmaking processes their ownsubjective evaluations and judgments of the impact of inappropriate material on children.thus, one sees in the public debate that judgments about the impactof inappropriate sexually explicit material on children are closely tied tothe values of those making the judgments. controversy is inevitablewhen these values are strongly held (as one would expect for valuesconcerning sexuality and children) and in conflict with those of others.even definitions of òpornography,ó which itself has no legal definition, or inappropriate sexually explicit material, may differ based on oneõsworld view and values (e.g., one community may object to images ofscantily clad individuals, whereas another may only be concerned aboutexposure to images that are more explicitly sexual, such as those depicting intercourse).the increasing cultural and social heterogeneity of the united statesimplies the coexistence of different sets of values. a range of differentvalue sets was demonstrated to the committee, and the committee heardfrom individuals representing a wide spectrum of views on the impact ofsexually explicit material on children. these views range from the beliefthat such exposure is òvery negative, wrong, and harmfuló to minors toònot particularly negative, wrong, or harmful.ó this diversity of values isreflected within the committee itself, but it depends strongly on whattype of sexually explicit material is being considered.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.177beyond the science: perspectives on impact and the public debateas the discussion in section 7.3 suggests, there is some set of explicitmaterial involving depictions of òextremeó sexual behavior that the committee does believe would be highly inappropriate for viewing by childrenñthis judgment would not be made so much on scientific grounds(as the committee knows of no reliable scientific studies that address thispoint) as on a sense that such exposure would offend the committeeõscollective moral and ethical sensibilities.however, for other, less extreme sexually explicitly material, the general publicñand the committee itselfñwould reflect a range of beliefsabout its propriety for children and the extent and nature of its impact onchildren. thus, if the committeeõs task were to come to consensus on thenature and extent of the impact on children of this type of less extreme butstill sexually explicit material, the committee would be deliberating for along time indeed. in short, even with the best of intentions, intelligentindividuals with different values working with highly uncertain knowledge are likely to disagree on both likely outcomes and the desirability orundesirability of those outcomes.but coming to a consensus on the impact of exposure to such sexuallyexplicit material on children is not the task of the committee. as noted inchapter 1 and in the preface, the committeeõs task is to provide a clearexplication of factors that enter into choices about appropriate approachesto protecting children from inappropriate sexually explicit material onthe internet. to the extent possible, this explication strives to providereliable information about these different approaches, and it is intendedto address that charge with analysis that is as valueneutral as possible.14in the end, however, values must enter into the process of selectingappropriate approaches to the issue of children and inappropriate sexuallyexplicit material on the internet. in particular, the weights that a decisionmaker assigns to various characteristics of a given approach are determined by his or her values. one who believes that the impact of suchmaterial on children is òvery negativeó will put different weights on thevarious factors related to approaches to protection that are articulated inchapters 8 through 13 and come to very different conclusions than someone who believes the impact is ònot very negative.ó to illustrate with a14the committee recognizes that valueneutral analysis, especially in controversial areas,is in practice not possible. for example, values are implicit in the choice of dimensionsalong which approaches may be analyzed. indeed, they are implicit in the use of the wordòprotectó in the committeeõs legislative charge, which assumes that harm and danger necessarily flow from childrenõs exposure to òpornographicó material. nevertheless, along thecontinuum ranging from more valueneutral to more valueladen, the committee sees itstask as more aligned with the former than the latter.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.178youth, pornography, and the internetsmall but important example: one who believes that the impact of sexuallyexplicit material on minors is very negative is likely to weight the partialprotection offered by filters heavily, and to give much less weight to the factthat filters also screen out some appropriate and useful information. onewho concludes that the impact of sexually explicit material is not verynegative is likely to place the opposite weights on these factors.it is with this discussion in mind that this report includes the materialpresented in chapter 6, though it is sparse and inconclusive. for mattersthat concern parents and communities, an inadequate knowledge basecannot be used as a rationale for doing nothing. but the knowledgeavailable, sparse and inconclusive though it is, helps to provide contextthat frames the choices of parents, teachers, librarians, administrators,and makers of public policy.7.5concluding observationsthe distinction between voluntary or involuntary exposure to sexually explicit material is important. the research base described in chapter 6 focuses mostly on the impact of voluntary exposure to sexuallyexplicit materialñit is in the nature of most psychological research thatthe subjects of research consent to being exposed to various stimuli. and,as noted above, there is little reliable evidence on the impact on childrenof exposure to sexually explicit material. however, it is true that somesuch material has the potential to shock or surprise some people notexpecting to be exposed to it, even if many children who accidentallyencounter sexually explicit material report that they are not particularlybothered by the experience (section 5.4.3).the committee believes that there is a reasonably strong social consensusñone reflected in its own deliberationsñthat involuntary exposure to sexually explicit material is clearly inappropriate and undesirableand should not be occurring, regardless of oneõs views on the impact ofvoluntary exposure, and it is particularly inappropriate and undesirablein the context of minors being exposed to such material or when involuntary exposure is the result of intentionally misleading or deceiving aminor.to the extent that risk does exist (as indicated by reactions of childrento such experiences), it is likely that it is largest for children in an agegroup who are old enough (namely preadolescents) to engage in unsupervised internet activity but young enough that they have not been exposed to very much sexual stimuli. very young children are unlikely tohave the technical sophistication needed to explore the internet in a waythat exposes them to sexually explicit material (e.g., they are less likely touse search engines than to stick with a set of prescreened ageappropriateyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.179beyond the science: perspectives on impact and the public debatesites) and even if exposed to sexually explicit material are unlikely to havethe worldly knowledge that labels such material as inappropriate. adolescentsñespecially the older onesñare sexually mature, have been exposed to a great deal of culture and media that are suffused with sexualmessages, and are often engaged in sexual activity (including intercourse).such individuals are as likely to close a screen containing sexually explicitimages as to explore it further.on balance, there is no scientific research consensus supporting aclaim that exposure to sexually explicit material doesñor does notñhavea negative physical, emotional, or psychological impact on children, nor aconsensus regarding the existence of a causal relationship between exposure to sexually explicit material and longterm behavioral outcomes ingeneral. (of course, what happens in the case of any specific individual isoutside the scope of such research in any event.) further, the committeehas not established specific definitions of what constitutes inappropriatesexually explicit material, though it remains confident that there is somesignificant set of sexually explicit material on which it could reach consensus regarding inappropriateness.the inconclusive results from the sparse scientific literature regarding the impact of exposure to sexually explicit material on children arereflected in a wide spread of committee member views on this subject aswell. although chapter 6 includes a review of empirical research thatexplores this topic and a discussion of developmental theories that pointto how one might incorporate a scientific framework into making decisions about the strategies to use to guide childrenõs internet use, there isnot a consensus either in the science or in the committee on which to basedefinitive and authoritative conclusions on the impact of sexually explicitmaterial on children or on the appropriate parental, school, library, orsocietal response for all children. what this report can offer is data on andcareful analyses on a number of factors (e.g., how children use the internet, means by which children come in contact with internet content, developmental theory about a childõs cognitive and emotional growth) thatindividuals and communities can consider in formulating a careful approach to this issue.it is important to keep in mind the difference between a scientificassessment that exposure to certain kinds of sexually explicit material isharmful and a stance that exposure to such material is morally wrong. amoral stance and a scientific consensus are entirely different concepts.each is important to discourse and action, but they have entirely differentepistemological underpinnings, and even if there were a scientific consensus that exposure to such material had no negative impact, one couldstill make a moral and ethical judgment that such exposure should beavoided simply because it was wrong. a good illustration is found in theyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.180youth, pornography, and the internetcommitteeõs views on this subjectñdespite a wide range of views on theunderlying science regarding the impact of exposure to sexually explicitmaterial on children, there is nevertheless some significant set of sexuallyexplicit material that the committee would unanimously regard as inappropriate and objectionable for children.a nation of communities with very different moral beliefs may neverbe able to come to a stable consensus on public policy if moral knowledgeand values are the primary determinants of policymaking outcomes.because science incorporates at its core techniques intended to safeguardthe process against the influence of personal beliefs, it offers a more valueneutral form of knowledge, and as such offers a form of knowledgearound which public consensus can be built. in the case of inappropriatesexually explicit material on the internet, there is no scientific consensuson the impact of exposure to such material, and so informed decisionsabout practices and policies cannot be based on empirical evidence. whatscience can offer in this case is a careful analysis of how, when, and whereyoung people come into contact with various types of inappropriate material. this knowledge can significantly improve local and perhaps evennational dialogs on what approaches could be employed to safeguardchildren on the internet.the committeeõs task is to explicate the factors that should be takeninto consideration in determining a course of action, as well as to offerexamples of existing approaches that some communities have used toaddress the issue. thus, its findings and conclusions about the factorsthat communities should consider as they formulate policy and practicesdo not require either a scientific or committee consensus on the impact ofexposure to inappropriate sexually explicit material on children. judgments about impact necessarily affect oneõs calculus in weighing differentfactors (and hence on deciding upon recommended courses of action), butthey do not necessarily affect what the relevant factors are. research(existing or future) that helps to say when, where, and in what circumstances exposure may put children at risk can help people to make decisions about what types of approaches may be the most beneficial andcosteffective, and the committeeõs review of current research is outlinedin chapter 6.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.part iiyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.182youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.183this chapter provides a general framework for understanding what itmeans to protect youth from inappropriate material. part of the complexity of the task is seen in the observation that òprotectó and òinappropriatematerialó are terms without clear and unambiguous definition.8.1the identification of inappropriate material8.1.1in principlethe determination that particular material is inappropriate for children begins with a human judgment. the judging party can be a parent,a teacher, a librarian, the child himself or herself, the creator of the material, the carrier (distributor) of that material, a thirdparty rating service,or a government agency.given a particular universe of material (e.g., a set of images), it islikely that any group of judges will agree on some material as òappropriateó and some as òinappropriate,ó and that there will be some materialabout which the judges will disagree. of course, depending on the particular judges involved, the term òinappropriateó could include a verylarge variety of material, including some or all sexually explicit material,bombmaking recipes, extremist material, birth control information, hatesites, and the platforms of particular political or social groups. indeed,judgments about inappropriateness are closely tied to the values of thosemaking the judgments.8approaches to protection frominappropriate materialyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.184youth, pornography, and the internetthe general pattern would not change even when judgments are confined to a specific area such as sexually explicit material. some materialwould be unanimously classified as inappropriate, some would be unanimously classified as not inappropriate, and some would be indeterminate. judges drawn from different segments of the u.s. public woulddisagree strongly about whether certain materials were inappropriate forchildren, and what is obscene or obscene with respect to minors, in california may well be different from what is obscene or obscene with respectto minors in tennessee because the community standards of californiamay be different from those of tennessee. in other words, as the supremecourt has made clear, the determination that material is obscene, or obscene with respect to minors, depends on criteria that are extrinsic to thematerial itself.in the absence of universal criteria, the most relevant standard forvalidity or accuracy is the standard of the individual(s) responsible formaking decisions about inappropriateness on behalf of the child. thus, itis often said that the best protection against children being exposed toinappropriate material on the internet is the presence and guidance of aresponsible parent or guardian while the child is using the internetñthereason is that when such an adult is involved, his or her standards can betrusted as the basis for good judgments for the childõs welfare.when the presence and guidance of a responsible parent or guardianduring internet use are not possible, protection depends on the judgmentof a proxy. the proxyõs judgments must then be evaluated against thestandard of the responsible adult who would otherwise make such decisions for the child. the proxy may be another adult such as a teacheracting in loco parentis, the board of a public library system, anothertrusted adult, an internet service provider, a developer of filtering software,1 a local jury deciding an obscenity case, the u.s. congress, or a statelegislature. but whatever the proxy, the validity of the proxyõs assessments about inappropriate material is indicated by its consistency withthe judgments of the party responsible for deciding on behalf of the child.different proxies have different methodologies for determining inappropriateness. a proxy that uses one reviewer is likely to have a differentset of consistencies than an agency that has a hundred reviewers. theformer is likely to have a higher reliability than the latter, while the latteris more likely than the former to establish a standard for accuracy orvalidity that reflects the larger population from which those reviewers aredrawn.1the developer of software builds into a tool assumptions about what content is appropriate (and for whom) and also establishes the standard of accurate performance that thetool will meet.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.185approaches to protection from inappropriate materialmoreover, even if agreement can be obtained on particular content(e.g., that a given image is inappropriate), it is hard to define clear rulesabout how to identify òsimilaró material in a consistent manner. putdifferently, it is difficult to articulate a set of rules that clearly defines aspecific class of òinappropriateó material that is both sufficiently inclusive(includes most or all material that is inappropriate) and sufficiently exclusive (excludes most or all material that is appropriate).given a need for proxies, how does a proxy make reasonable judgments about what sexually explicit material may be inappropriate for viewing by children at any age? to answer this question, it is important todistinguish conceptually between reliability (or consistency) and validity.the most common example to illustrate the distinction between reliability and validity is that of a shooter aiming at a target and firing multiple rounds. reliability is a measure of the repeatability of the shooterõsaim. a tight cluster of shots indicates high repeatability (reliability).however, reliability says nothing about how close that cluster of shots isto the actual target. for that, validity indicates the accuracy of thoseshots: a small distance between the center of the cluster and the center ofthe target indicates high accuracy (validity). validity means that one ismeasuring what one claims to be measuring. a highly reliable measuremay not be valid, and a highly valid result may not be reliable.2in determining whether certain material is inappropriate, reliabilityrefers to the reproducibility of an assessment that a given piece of material is inappropriate. to test for reliability, one might ask an individual toevaluate a collection of materials several times under different circumstances. if this individualõs judgments were generally consistent, he orshe would be said to be a reliable judge. because the same person mayclassify a given piece of material differently depending on his or hermood or from one day to another or what else he or she might have seenor read during that period of time, an individualõs reliability as a judgecannot be taken for granted.reliability is even more difficult when multiple people are involvedin judging content. different people may classify a given piece of materialdifferently even if they are ostensibly using the same rules for classification. thus, to determine the reliability of a group of judges, one might askthem to evaluate a collection of materials; if their judgments were generally consistent with each other, this group would be said to make reliablejudgments. key to this process is an agreedupon operational specification of how to make a judgment.2for practical purposes, a variable with low reliability (i.e., with a wide spread) is hard touse for empirical work. however, it can still be highly valid in the formal sense of the term,even if it is not useful.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.186youth, pornography, and the internetthis definition of reliability implies that machine assessment (a givenversion of software running on a given computer) is inevitably morereliable (or consistent) than human assessmentñgiven the strictly algorithmic process, the reliability of machine assessment is 100 percent.3 thereliability of human assessment is likely to be considerably lower, evenwhen the same rules of classification apply to all assessments, simplybecause people interpret the same rules differently.validity is a more problematic concept because there is no universallyaccepted standard (no ògold standardó) for what counts as inappropriate.in other words, there are no universally accepted criteria that definewhether something is obscene or inappropriate for viewing by children.these comments do not exclude the possibility of broad agreementover many possible decisionmaking parties in a particular instance characterized, for example, by child pornography, just as even the worstmade rifle can make bullõs eyes for a particular target with a very largebullõs eye. rather, the accuracy of a rifle is best tested against a targetwith a very small bullõs eye, so that variations in accuracy can be readilyobserved. similarly, the validity of a process for making judgments aboutinappropriateness is best indicated by examining judgments of òquestionableó material about which people do not hold similar views.reliability and validity (as measured from the perspective of a responsible adult) are the primary determinants of a ògoodó proxy for thatadult. because different proxies have different methodologies, an individual faced with the responsibility for deciding inappropriateness for achild can, in principle, choose to adopt the approach used by a trustedproxy. thus, in principle, an individual (e.g., a parent) might choose totrust the judgments of disney, the american civil liberties union, thechristian coalition, or another organization that has a wellknown reputation for espousing a particular set of views or values.8.1.2in practicegiven the general principles described above, three methods can beused in practice to identify inappropriate material. the decisionmakingparty, whether machine or human, can¥make a realtime assessment of the material in question based on the content of the incoming information. this approach would require the decision3this statement must be qualified if the assessment software relies on elements thatchange over time. for example, the assessment software may rely on a database that isupdated from time to timeñwith new or additional data, the results of the assessment of,say, a given image may well vary.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.187approaches to protection from inappropriate materialmaking party to screen each item of information immediately prior to thechildõs viewing of it. items judged to be appropriate are immediatelypassed to the child, while items judged to be inappropriate are not.¥rely on a tag or label associated with the material in question. labelscan contain either a description of the material or a judgment about thematerial. (in principle, a label can be created by the content creator or byanother party.) if the label contains a description, the description is ahighly condensed description of the material with respect to dimensionsof content likely to involve judgments of inappropriateness. thus, thelabel might indicate òimage contains frontal nudityó because decisionmakers are likely to want to make decisions based on the presence orabsence of frontal nudity. by contrast, the label would not indicate òimage contains people,ó because that fact is not likely to be the basis onwhich judgments about inappropriateness are likely to be made. alternatively, the label may contain a judgment about the material (e.g., inappropriate for those 14 and under). in this case, the label represents a timedelayed judgment of content that has been made by a third party.¥examine the source of the material. some sources can be trusted toprovide only appropriate material; others provide a large volume of inappropriate material.4 rather than assessing the material itself (an effortthat may be unduly timeconsuming), the evaluation is based on thesource. note that relying on an evaluation of the source is, in essence,reliance on a labelñthe name of the source is the label, and material fromthat source is rejected or accepted depending on the particulars of thesourceõs identity.a second dimension of identifying inappropriate material in practiceis a consequence of the size of the internet. the volume of information onthe internet is so largeñand changes so rapidlyñthat it is simply impractical for human beings to evaluate every discrete piece of information forinappropriateness. moreover, the content of some existing web pageschanges very rapidly, and new web pages appear at a very rapid rate.5this fact leads to one of two approaches. one is based on an automated, machineexecutable process for identifying inappropriate content4sources of adultoriented, sexually explicit material are generally consistent in their offeringsñsuch content is available on their web sites today, and will be available tomorrow(if they are still in business). yet the content on one such site is often generically similar tothat on another site, so òbrand loyaltiesó that keep viewers coming back are hard for anyone business entity to establish. the most successful commercial entities are those thathave been able to establish such loyalties.5no data was available to the committee on the first point, but on the second point, thenumber of publicly accessible web pages increased by 300 million in the period from july tooctober 2001 (according to the google statistics on the number of pages indexed).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.188youth, pornography, and the internet(generally used for evaluating content òon the flyó); such processes areless expensive than manual processes for screening content, but as a rule,they result in judgments that are less valid than those of human evaluators. automated approaches must be based on machineexecutable rulesthat are abstracted from human judgmentsñsuch abstraction inevitablymisses nuances in those human judgments and reduces their validitycompared to that of humans. reliance on labels depends on the labelõsaccuracy, and only a humanõs action binds a particular label to a givenpiece of material. and, the identity of a source may not be an adequateindicator of material coming from it.the second approach is the humanperformed explicit identification ofspecifically appropriate material and the exclusion of everything else (or itsreverseñthe explicit identification of specifically inappropriate materialfor exclusion and the inclusion of everything else). this approach is expensive. the first variant runs the risk that large volumes of appropriate material will be excluded, but is likely to result in a very low fraction of inappropriate material being displayed. the second variant captures only some(perhaps a large fraction) of the inappropriate material on the internet, butallows a large volume of appropriate material to pass.in practice, a combination of approaches can be used as wellña combination would rely on an automated search for material that might beinappropriate, but would rely on a human judgment for the final determination. in this case, inappropriate material not identified in the automated search does not reach a human decision maker and so it mistakenlyidentified as appropriate. to the extent that the threshold of identification is set so that a greater volume of possibly inappropriate material isidentified (so as to reduce the likelihood that inappropriate material is notmistakenly identified), the volume of material that is subject to actualhuman judgment is increasedñin which case the issues regarding humanreview discussed in the previous paragraph obtain.8.2dimensions of òprotectionóin the context of òprotecting youth from inappropriate material orexperiences,ó the term òprotectó has a number of plausible definitions.òprotectionó can mean:¥preventing children from deliberately finding inappropriate material or experiences (e.g., searching out an adultoriented web site);¥preventing children from being inadvertently exposed to such material or experiences (e.g., receiving an unsolicited email containing aninappropriate image or text); and/or¥developing in the child skills that enable him or her to cope conyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.189approaches to protection from inappropriate materialstructively with such exposure should it occur and making available asupport infrastructure that reduces the harm or injury that might resultfrom being exposed to such material or experiences.the approaches needed to implement these definitions of protectiondiffer but are not mutually exclusive. protecting children from deliberateexposure is a very different enterpriseñand entails very different costsñcompared with protecting children only from inadvertent exposure,though approaches to each may have common elements. further, teaching a child to cope constructively is likely to be helpful in the event thatother protection measures fail.the primary difficulty of protecting children and youth against deliberate exposure is the fact that many adolescents, especially boys, arehighly motivated to seek out sexually explicit materials, including material that is ostensibly limited to adults. absent a significant change intheir desire for such materials, their motivation often enables them toovercome many obstacles in their path, whatever the nature of thoseobstacles.òprotectionó has other important dimensions. the extent to which achild can be protected is an important element of the debate. it is easy tosay that 100 percent protection is impossibleñbut such a statement begsthe question of what ò80 percent protectionó might mean. does it meanthat the child is exposed to inappropriate material 20 percent as much asanother child who does not have such protection? should the evaluatorrely primarily on the number of incidents of exposure? or are otheraspects of the exposure, such as its nature or duration, important as well?an important challengeñas yet unresolvedñis to articulate appropriatemetrics of protection.a key dimension of protection is the issue of false positives and falsenegatives. in deciding whether a given piece of material is appropriate orinappropriate, it is inevitable that some material will be designated asinappropriate when it should have been designated as appropriateñerrors of this type are false positives. on the other hand, some material willbe designated as appropriate even when it should have been designatedas inappropriateñerrors of this type are false negatives.perfect protection (ò100 percentó) is possible only at the cost of manyfalse positivesñand is in fact simple to provide. a cable with an air gapin it (or, equivalently, disconnecting from the internet) will provide 100percent protection in the sense that it will screen out all inappropriatematerial. but it will also block all appropriate content as well. in the realworld, those wishing to provide protection (e.g., parents, school administrators, and so on) must balance the rate of false positives against the rateof false negatives.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.190youth, pornography, and the interneta third dimension of òprotectó might refer to measures taken to ensure that the child suffers no ill effects from being exposed to inappropriate material. this approach recognizes that absolute protection from inappropriate material is impossible to achieve (except at the cost of totaldisconnection) and that nurturing a child who is able to place inappropriate material into context, to evaluate and make good judgments about it,and to deal with it appropriately is an important element of the overallgoal of keeping children from harm.the relevance of these different definitions and dimensions of òprotectódepends on the developmental maturity of a child. the range from birth to18 spans a very broad developmental range in a psychological sense. whatmay be developmentally inappropriate for a very young child may not beinappropriate for a teenager. it can be taken as a given that teenagers will bemore interested in sexual matters than will young children, and a site providing a detailed scientific description of human reproduction, for example, maybe more appropriate for the former than the latter. parents and other responsible adults may thus wish to consider developmental factors in weighing thecosts and benefits of different approaches to protection.for example, at very young ages, one might be inclined to shieldchildren from any internet exposure at all (e.g., confining a very youngchildõs computer experience to cdroms). as he or she matured, a nextstep might be to allow online experiences only in environments that werespecially created for children. then, at a further stage of maturity, onemight seek to educate oneõs child in safe internet use and use technologyto screen out objectionable material. finally, one might simply allowunconstrained internet access but keep an eye on the childõs internet activities. the assumption underlying such a progression is that as the childmatures, his or her judgment and capability for responsible action grows,and different kinds of òprotectionó are necessary. (all of these optionsare discussed in subsequent chapters.)in the context of protecting children from pornography and perhapsother types of material as well, it is also important to distinguish betweenprotecting children from being exposed to pornography (the subject ofthe discussion above) and protecting children from participating in pornography (which is the ultimate and primary rationale for laws thatstrictly proscribe child pornography). the discussion below and in chapters 9 through 13 focuses primarily on protection from exposure, butaddresses protection from participation as appropriate.8.3the time line of protective actionsactions can be taken at a variety of times. actions can be taken toprotect a child before potential exposure to inappropriate material, at theyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.191approaches to protection from inappropriate materialmoment of that exposure, and after that exposure. for example, as chapter 10 discusses, various education and media literacy strategies may helpthe child to decide not to be exposed to inappropriate material. suchstrategies must obviously be implemented before exposureñthat is, thechild must begin to learn (internalize) norms of appropriate conduct andbehavior. at the moment of potential exposure, tools such as filters (described in chapter 12) are relevant, because they can help to block exposure to such material. and, after exposure, a variety of measures (e.g.,getting help, reporting to a responsible adult) can help to mitigate anynegative effects that may result from such exposure.8.4differing institutional missionsof schools and librarieseven the same community, libraries, and schools often have verydifferent policies regarding the need for filtering. in some communitiesvisited by the committee, schools had implemented filtering for all schoolbased internet connections, whereas the public libraries in that same community did not have filters.to understand why such differences might arise, consider the different purposes served by public schools and libraries. a public schoolserves the primary purpose of providing academic instruction for individuals who have not attained the age of majority. parents send theirchildren to school in the legally enforceable expectation that school personnel will take responsible care to protect them from harm and to provide adequate instruction (i.e., that they will act in loco parentis).by contrast, a public library serves the primary purpose of providinga broad range of information to the entire community in which it is based.this community includes children, but also includes adults, and the information needs of the communityñtaken as a wholeñare generally muchmore diverse than those of children and youth in school.6 thus, giventhese differing purposes, it is not at all unexpected that school and libraries have different needs and might take different approaches in seeking6for example, the position of the american library association is that òlibrarians believein supporting a wide variety of information needs,ó and emphasis should be placed òon thepatronõs right to choose,ó an emphasis that is òconsistent with [the library] professionõscommitment to intellectual freedom.ó further, òlibraries rarely limit what can be read ina library. librarians do not search patronsõ bookbags for titles the library would notpurchase, or police reading tables to see if patrons are reading materials consistent withlocal collectiondevelopment policies. in a similar vein, many libraries offer open access tothe internet, so that the patron may choose what to read.ó see <http://www.pla.org/publications/technotes/technotesfiltering.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.192youth, pornography, and the internetto protect children and youth from inappropriate internet material andexperiences.approaches of schools and of libraries for protecting children andyouth from inappropriate internet materials and experiences must be assessed against this backdrop. some elements of these approaches will besimilar, but it is also to be expected that other elements will be differentbecause of differences in fundamental purpose.8.5the politics of protection andinappropriate materialñwho and when?within this framework of different dimensions of òprotectionó andòinappropriate material,ó a range of approaches to the definitional process can be identified. one approach, rarely stated but often implicit asthe motivating force behind certain policy positions, is the idea that aparticular definition of òinappropriateó is appropriate for all communities. underpinning this approach is the view described in box 7.2 inchapter 7 that inappropriate materialñand in particular, sexually explicit materialñcan be so dangerous that even a single exposure of achild can result in very harmful consequences. examples to supportthis point of view tend to be drawn from the more extreme sexuallyexplicit material found on the internetñand not coincidentally materialthat tends to arouse revulsion in a large segment of the population.thus, òprotectionó of children must be as airtight as possible, and falsepositives that improperly classify appropriate material as inappropriateare preferable to false negatives that improperly classify inappropriatematerial as appropriate.7 note also that if one believes that even oneexposure of a child to such material is likely to have longlasting andprofoundly negative effects on his or her development, then nothingless than perfection suffices. for such individuals, technologies thatseek to isolate and wall off a child from untoward influences are likelyto have considerable appeal.a second approach asserts that individual communities have the right(and obligation) to define for themselves what is inappropriate. believersin this philosophy reject the notion that there are, or that there should be,universal standards of inappropriateness. to buttress their view, theytend to draw on examples of material that many people would not findinappropriate or offensiveñinformation that can be characterized as moreòmainlineó than òextreme.ó they tend to doubt that exposure to sexually7child pornography is an area where a similar philosophy has led to strong legal protections against the harms of child sexual abuse that typically define the material.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.193approaches to protection from inappropriate materialexplicit material will have a damaging impact on most children, and thusare willing to accept false negatives as the cost of avoiding false positives.for those who believe in the resilience of children when given appropriate guidance, social and educational strategies that teach a child how tomake good decisions about such material and how to cope with it shouldexposure occur are likely to have more appeal than approaches that relyprimarily on technology.these two approaches represent polar opposites. in practice, mostpeople fall somewhere in between. that is, they might well say that sometypes of material should indeed be universally prohibited, regardless ofcommunity standards (e.g., child pornography), but conclude that forother types of sexually explicit material, communities should be free todecide for themselves.a third approach, in general independent of those described above,focuses on empowering children to protect themselves. this approachcalls for adult definition of inappropriate material (and could be definedeither universally or on a communitybycommunity basis, but in anyevent would ideally account for developmental maturity) but focuses onthe child rather than the adult as the primary decision maker. this doesnot mean that adults have no role, or that protective mechanisms areinappropriate, but rather that reliance on externally driven protectivemechanisms can be reduced as the childõs judgment increases. (the appropriate analogy would be that externally driven protective mechanismsfor a child whose judgment is developing and maturing serve the samerole as òtraining wheelsó serve for someone learning to ride a bicycle.)under this approach, the goal is not to protect the child from exposure asan end in itself, but rather to educate the child to cope well with offensiveor inappropriate materials. this approach is based on the idea that in afree and pluralistic society, one will inevitably be exposed to material thathe or she may find disturbing, offensive, or distasteful, and that the bestway to deal with such situations is to develop coping mechanisms throughexperience.it is also important to consider the time scale over which politics isconducted. in one site visit to a state generally regarded as politically andsocially conservative, discussion with those familiar with the local community revealed a difference in the politics associated with schools (whichdid have filtering for all its schools) and libraries (which did not). themembership of the school board had changed relatively suddenly, on thetime scale of a year (one election), whereas the membership of the libraryboard changed very slowly. thus, filtering could be driven by new members of the school board, whereas library board membership was morestableñand thus changes to policy took longer to implement in the absence of sustained and demonstrable public concern.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.194youth, pornography, and the internet8.6techniques of protectionchapters 9 through 13 address the challenges of protecting childrenagainst exposure from inappropriate sexually explicit material. this section introduces some general concepts for protection that underpin morespecific approaches:¥blocking inappropriate material refers to techniques that prevent achild from being exposed to material that has been judged to be inappropriate. blocking protects against both deliberate and inadvertent exposure. however, all material that is not explicitly identified as inappropriate (òblacklistedó material) is treated as appropriate. blocking can becircumvented by defeating the blocking mechanism, by gaining access tomaterial that is generically equivalent to the blocked material, or by accessing that material in a venue that is not blocked.8¥restricting a child to appropriate material refers to techniques thatgive a child access only to material that is explicitly judged to be appropriate for him or her. children cannot reach inappropriate material because the only material they can reach has been judged as appropriate. allmaterial that is not explicitly identified as appropriate (òwhitelistedómaterial) is treated as inappropriate. restrictions can be circumvented bydefeating the restriction mechanism or by accessing nonwhitelisted material in a venue that does not restrict the user. the key difference between blocking and restricting is that blocking allows access to everything that has not been blocked, whereas restricting gives access only towhat has been approved.¥warning a child of impending exposure to inappropriate material leaveshim or her with an explicit choice to accept or decline a viewing. warningprotects against inadvertent exposure to inappropriate material, but notagainst deliberate exposure. as with blocking, all material that is not explicitly identified as inappropriate is treated as appropriate. however,circumvention is unnecessary, because the ultimate decision about whetherto access the material is made by the child.¥suggesting appropriate material to a child provides direction but doesnot foreclose the exercise of choice. the child may disregard such suggestions, but such suggestions can influence him or her to proceed in òappro8note the existence of ògray.ó ògrayó may be material that, while not exactly inappropriate for children, is regarded as not particularly helpful to themñówasteoftimeó material.for example, one could imagine some schools putting web sites that relate to games, sports,entertainment, and celebrities on a òblack listó because spending time on such sites andwith such material would not be regarded as having educational value. on the other hand,creative teachers may well be able to extract educational value from such sitesñand blocking such material might reduce the educational opportunities available.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.195approaches to protection from inappropriate materialpriateó directions. suggestions are, of necessity, more limited than theentire universe of material that might be regarded as appropriate, andthus tend to focus on material that is regarded as being of particularlyhigh value.¥deterring the access of children to inappropriate material depends ontwo factors: detection of access and subsequent penalty. detection can beovert or covert, and penalties can vary across a very broad range, fromsocial sanction to incarceration. deterrence relies on a choice of the individual involved to refrain from accessing inappropriate material, a choicemotivated by concern over being detected and of the subsequent penalty.thus, deterrence is directly relevant to preventing or reducing deliberateaccess to such material. (however, if the threat of punishment makes theindividual more careful, inadvertent access may be reduced as well.) thethreat of a penalty being imposed for an inappropriate use detectedthrough monitoring a childõs internet access is an example of an approachthat relies on deterrence.¥educating a child about accessing inappropriate material has two components. one is much like deterrence, except that the motivation is different. whereas deterrence depends on the possibility of detection and punishment, education is an integral part of helping a child choose to refrainfrom accessing inappropriate material by inculcating an internal sense ofpersonal responsibility. the second component is education about theinternet and the development of critical thinking that can help the child toconduct searches that are less likely to turn up inappropriate material andto recognize inappropriate material more effectively.¥helping a child to cope with exposure to inappropriate material recognizes that some exposure to such material is likely for most internet users.coping strategies are especially useful for children inadvertently exposedto inappropriate material and may involve ways of putting such materialinto context, understanding the difference between fantasy and reality,and so on.¥keeping a child òon task.ó in an environment in which time limits oninternet access can be enforced, children can be given specific tasks toaccomplish. if they are held responsible for these tasks (as they might bein, for example, a school setting), they will simply have less time to seekout activities that are inappropriate.¥reducing the accessibility of inappropriate material to children can result from a variety of actions, including making inappropriate materialharder to find and reducing the amount of inappropriate material on theinternet. supplyside actions have a different structure and are discussedfurther in chapter 9.¥reducing the appeal of deliberate contact with inappropriate material.this approach leaves the essential content of such material untouched butyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.196youth, pornography, and the internetmakes the userõs engagement with the material (and only such material)more difficult, cumbersome, and inconvenient.it is important to note that the techniques discussed above are notmutually exclusive. for example, a message indicating that access to material has been blocked can also be accompanied by suggestions for alternative but appropriate material instead. indeed, combining some techniques may enhance effectiveness; such instances must be determined ona casebycase basis.8.7approaches to protectionsociety has responded to concerns about the possibility that childrenand youth might be exposed to inappropriate material in a number ofways. for example, consider the following:¥by legislative mandate, a òvchipó is contained in every new television sold in the united states. the purpose of the vchip is to giveparents greater control over the television content to which their childrenare exposed.¥in many communities, parents have the explicit right to òopt outóof schoolprovided sex education for their own children.9¥members of a community often complain to schools or public libraries about materials (usually books) that the complainants feel shouldnot be available to the public, and especially to children. the content ofsuch materials covers a wide rangeñhomosexuality, drugs, religiouscults, bomb making, human sexuality, and race relations, to name a few.in some cases, schools and libraries do remove material found to be offensive by members of the local community.however, these examples do not illustrate a social consensus on theirappropriateness or desirability. for example, most parents do not use vchips in controlling their childrenõs television usage (box 8.1) and do not9for example, section 51550 of the california education code states,no governing board of a public elementary or secondary school may require pupils toattend any class in which human reproductive organs and their functions and processesare described, illustrated or discussed, whether such class be part of a course designatedòsex educationó or òfamily life educationó or by some similar term, or part of any othercourse which pupils are required to attend. . . . opportunity shall be provided to eachparent or guardian to request in writing that his child not attend the class, [and] no childmay attend a class if a request that he not attend the class has been received by theschool.available online at <http://www.leginfo.ca.gov/cgibin/waisgate?waisdocid=07839714985+0+0+0&waisaction=retrieve>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.197approaches to protection from inappropriate materialbox 8.1the vchipaccording to a study of the kaiser family foundation, parents are deeply concerned about sex and violence on tv. more than 80 percent of parents are concerned that their children are being exposed to too much sex and violence on tv.sixtythree percent are òa great dealó concerned and 18 percent are òsomewhatóconcerned about too much sexual content; 59 percent are òa great dealó and 23percent òsomewható concerned about violent content. nearly half of parents believethat exposure to sexual content on tv contributes òa lotó to kids becoming involvedin sexual situations before theyõre ready, and the same proportion believe exposureto violence on tv contributes òa lotó to violent behavior in children.however, while 40 percent of all parents own a tv equipped with a vchip, feware using it. only 7 percent of all parents have used a vchip to control their childrenõs television viewing. of those parents with a vchip, half (53 percent) donõtknow it, about a third (30 percent) choose not to use it, and one in six (17 percent)have used it to block shows they donõt want their children to watch. of all parentswho know they have a vchip, about a third (36 percent) have chosen to use it.of the parents who know they have a vchip but do not use it, half say the reasonthey havenõt programmed their vchip is that an adult is usually nearby when theirchildren watch tv; a quarter (25 percent) say itõs because they trust their children tomake their own decisions. just 2 percent say itõs because they think their childrenwould find a way around it, and just 1 percent say it is because they see the vchipas a form of censorship.far more parents have used the tv ratings system than the vchip. about half (56percent) of all parents say they have used the tv ratings to make decisions aboutwhat shows their children will watch. this is similar to the percent of parents whohave used the advisories on music (50 percent) or video and computer games (59percent). a much larger proportion of parents (84 percent) have used the movieratings. about a quarter of all parents (28 percent) say that they use the tv ratingsòoften.ó furthermore, most parents (92 percent) who have used the ratings find themuseful. about half of the parents who have used the ratings (48 percent) say they areòveryó useful. this is similar to how parents assess the usefulness of the movieratings (53 percent say òveryó useful) and the advisories for cds (52 percent òveryóuseful) and video games (52 percent).however, parents have mixed views as to whether tv ratings accurately reflectthe content of shows. of the parents who have used the tv ratings, half say thatfrom what theyõve seen, most shows are being rated in a way that accurately reflectstheir content; however, 40 percent say most shows are not being rated accurately.furthermore, many parents donõt understand what the tv ratings mean. for example, most parents of children aged 2 to 6 cannot say what the ratings for youngchildren mean. just 43 percent can define the rating tvy7, 31 percent can definetvy, and only 14 percent can recognize that fv stands for fantasy violence. moreparents do understand agebased ratings, with 62 percent knowing what tv14means, 63 percent what tvg means, 74 percent what tvpg means, and 47 percent what tvma means. nevertheless, more parents say the contentbased ratingsprovide the most useful information.source: adapted from kaiser family foundation, 2001, parents and the vchip 2001, thehenry j. kaiser family foundation, menlo park, calif., available online at <http://www.kff.org/content/2001/3158/summary.pdf>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.198youth, pornography, and the internetremove their children from sex education classes in school.10 in the caseof removing materials from libraries, a formal hearing process often guarantees that removal will have a high political profile in the communityinvolved, and constitutional issues arise as well.nevertheless, there is one example of action taken in this area that thecommittee believes provides a helpful analogy. in particular, many communities deal with the issue of preventing minors from reading and viewing adultoriented magazines available at a newsstand through a numberof steps. children are taught by parents not to seek out such magazines,and parents refrain from leaving such magazines lying around the house(social and educational measures). in the stores, adult magazines areplaced on the highest shelves, so that they are harder for shorter people toreach (a social measure). they are sealed in plastic, so that browsing themin the store is more difficult (a technology measure). an opaque òbellybandó obscures the picture on the front (another technology measure).the picture itself, while sexually suggestive, does not depict either overtsexual activity or the genitalia of the models (a public policy measure). apurchaser of such magazines must usually make the transaction facetoface with the operator of the newsstand, who can generally distinguishbetween a 12yearold boy and an adult and whose very presence helps todeter some minors from even seeking to make such a purchase (anothersocial measure). and the operator of the newsstand may be subject toprosecution if he knowingly sells an adult magazine to a minor understate and local laws that prohibit such sales to minors (another publicpolicy measure).all of these measures combine into an approach to the sale of adultmagazines that has not absolutely prevented minors from viewing theircontents, but there is not much controversy about the approach, imperfectthough it is. in other words, there is a rough social consensus that thisapproach is for the most part not unreasonable, either in its implementation or its philosophy. it provides some protection, though the protectionis not absolute, and the burden it places on magazine vendors and adultconsumers is not particularly significant. further, the protection that itdoes provide is adequate for publishers and vendors of adult magazinesto be able to plausibly assert that they are taking reasonable steps to keepsuch material out of the hands of children.10when given a choice, only 1 to 5 percent of parents remove their children from comprehensive sexual education classes. see kaiser family foundation. 2000. sex education inamerica: a view from inside americaõs classrooms. the henry j. kaiser family foundation,menlo park, calif.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.199approaches to protection from inappropriate materialhow should one view approaches to protecting children from inappropriate sexually explicit material on the internet? while the discussionof the corner newsstand above is helpful in understanding how to thinkabout this issue, cyberspace is unlike a corner newsstand in many ways,and much of the controversy about inappropriate sexually explicit material on the internet arises because of the differences between the cornernewsstand and cyberspace. nevertheless, a reasoned approach to protection in cyberspace also relies on the three generic elements mentionedin the corner newsstand issueñsocial and educational measures, technology, and public policy.there is a broad consensus that the ideal approach for keeping kidssafe on the internetñin any dimension one wishes to considerñis thepresence of a trusted, responsible adult providing guidance, pedagogy,and supervision along with encouragement and understanding. but as apractical matter, many children are likely to have some degree of unsupervised access to the internet or other online services (e.g., because of theinfeasibility of continuous parental monitoring of childrenõs internet use).while parents with the education, resources, and time to understand anddeal with the problem may approach the ideal described above, otherswho do not have these benefits also seek solutions to what they see as areal problem.it is thus not unreasonable to consider a combination of protectiveelements whose use can reinforce one another, though the closer one canget to the ideal described in the preceding discussion, the better. forexample, parents can place computers at home in public places so thatthey can better supervise the internet use of their children. schools andlibraries can teach children to avoid behavior that can lead to inadvertentexposure to inappropriate sexually explicit materials. technology can beused to create internet environments for very young children in which allcontent is specifically designed to be ageappropriate and educational.public policy measures may be able to reduce the amount of adultoriented, sexually explicit material that is accessible without some kind ofage verification. (all of these elements, and others, are discussed in thefollowing chapters.)the possibility of such synergistic effects should not be taken to meanthat one particular combination of protective elements is right in all cases.furthermore, no combination of protective elements will be free of tradeoffs, both within the space of protecting children and youth from inappropriate sexually explicit material on the internet and with respect tohow this space interacts with other societal issues. thus, the appropriatecombination of protective elements will vary substantially across different communities and styles of parenting, and it is important that parentsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.200youth, pornography, and the internetand communities retain the ability and authority to determine what isbest for their childrenñand how to make those tradeoffsñin accordancewith their own values.chapters 9 through 13 address a variety of options for public policies,strategies, and tools, and some of the benefits of coordinating their use.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.201this chapter presents a variety of legal and policy options that thecommittee considered and discussed during its deliberations regardinghow best to protect children from inappropriate sexually explicit materialon the internet. however, it should be kept in mind that the legal andpolicy environment today (as this report is being written) is highly fluidand rapidly changing. court cases are being heard, and legislation ispending on areas such as privacy, elimination of spam, and protectingkids on the internet. furthermore, even if some of these legal and policyoptions are helpful for regulating sources of sexually explicit materialwithin the united states, a substantial number of sources outside thedirect enforceable jurisdiction of u.s. law will remain. this fact mightwell limit the success of u.s. legal and policy options for regulatingsources of sexually explicit material.table 9.1 provides an overview of the public policy options describedin this report.9.1vigorous prosecutions of obscene materialwith all of the difficulties described in chapter 4 in defining obscenity,it is still the case that material deemed obscene is not protected by the firstamendment. federal and state obscenity laws impose criminal and civilpenalties on the production, distribution, and sale of obscene matrial. inrecent years, however, obscenity prosecutions have been relatively rare.such prosecutions can be very difficult, especially in the context of the9legal and regulatory toolsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.202youth, pornography, and the internettable 9.1 examples of advantages and disadvantages of variouspublic policy options for protecting children from inappropriatesexually explicit material on the internetone illustrative advantageone illustrative disadvantagevigorous prosecution ofexisting obscenity lawsimposition of civilliability for disseminationof obscene materialsrequired use of ageverification systems bycommercial suppliers ofadultoriented sexuallyexplicit materialrequired use of òtextonlyófront page to ensure thatfirst page of web site is theòwarningó page aboutmaterial inside being foradults onlyrequired labeling ofmaterial that is obscenefor minorsprohibitions on spamcontaining material that isobscene for minorsprohibitions on mousetrapping to web sitescontaining material that isobscene for minorsstricter enforcementof recordkeepingrequirementswould clarify existinguncertainties about thefeasibility of obscenityprosecutionswould enable privateparties to take actionthrough the court systemwhen prosecutorialresources are limitedwould reduceinadvertent access tosexually explicit materialfrom adultorientedcommercial web siteswould place a minimalburden on contentproviderswould reduce unsolicited emailed advertisements for adultorientedmaterialwould improve navigational experience forinternet userswould increase costs ofcompliance with suchrequirements; mightreduce number ofcommercial entitiesunwilling to behaveresponsiblywould require personneland resources that might beused for other law enforcement activity that may be ofhigher prioritywould generally requiresome showing of individualized harm, which may bedifficult to demonstratewould not reduce access forchildren willing to lie abouttheir ageswould require positivemarket response for success(e.g., browsers must be capable of recognizing labels,parents must configurebrowsers accordingly)contentbased restrictionwould make regulationmore problematic on firstamendment groundsregulatory target may beuncertainwould require personneland resources that might beused for other law enforcement activity that may be ofhigher prioritycurrently under judicial review;see discussion in section 4.2.4youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.203legal and regulatory toolsinternet, where community standards, jurisdictional, and international issues abound.nevertheless, vigorous enforcement may help to persuade operatorsin the adult online industry to change their behavior to act more responsibly in denying access to children. it may also reduce to some extent thenumber of operators of web sites carrying obscene material by puttingsome of them out of business and changing the costbenefit calculus forother òmarginaló operators who would choose to exit the business in adifferent regulatory climate.note that a reduction in the number of web site operators providingsuch materials is not likely to reduce greatly the ease with which one canfind such material. the reason is that search engines operate in such away that a given search is more or less independent of the number of suchsites. thus, if there are 100,000 such sites today, a reduction to 10,000 siteswould not significantly increase the difficulty of finding such material (oreven reduce the likelihood of coming across it inadvertently).1 thus, it islikely that the second effectñpersuading operators to behave more responsiblyñwould be larger in magnitude.it is also important to note that the problem of defining which comstreamlined process forhandling reports ofviolationsselfregulation (e.g.,vigorous enforcement ofisp terms of service)would facilitate citizenreporting of childpornography; wouldreduce interagencyimpediments tocooperation in suchprosecutionswould likely lead tofaster òtake downó ofmaterial posted inviolation of terms ofservice (which generallyincludes material that isobscene or childpornography)might increase false alarmsand screening effortrequiredwould require vigorousmonitoring effort on part ofisptable 9.1 (continued)one illustrative advantageone illustrative disadvantage1strictly speaking, the results of a search do depend on the number of web pages beingsearched: the more pages in the index, the less often the search engine reindexes/researches the net for updates and changes. thus, web pages that have recently been addedto the internet are less likely to be found when the number of pages in the index is large.however, this is a relatively small effect.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.204youth, pornography, and the internetmunityõs standards should govern obscenity prosecutions for material onthe internet is at issue in current litigation regarding the child onlineprotection act of 1998 (copa). as noted in chapter 4, the supremecourt held on may 13, 2002, that copaõs reliance on òcommunity standardsó to identify what material is òharmful to minorsó did not by itselfrender the statute substantially overbroad for first amendment purposes,but was silent on the extent and nature of the community in question.the court of appeals reasoned that in dealing with the internet, unlike other forms of communication, the material is immediately availablein all jurisdictions without regard to conventional geographical boundaries. if local community standards govern the definition of material thatis obscene for minors, then providers will be liable to criminal prosecution if the material they make available violates the standards of anyjurisdiction in the nation. in such a situation, providers will censor themselves by providing only that sexually oriented material that is not obscene for minors in the most conservative community in the nation. thecourt of appeals concluded that such a situation would violate the firstamendment rights of both providers and of citizens of all of the othercommunities in the nation. this same issue would arise with respect totraditional obscenity prosecutions for material presented on the internet.it should also be noted that even if the supreme court upholds thethird circuit court of appeals in this instance, this does not necessarilymean that all legislation intended to serve the same goals as copa will beunconstitutional. for example, one possible solution to this problemwould be to require the government in a prosecution of obscenity on theinternet to prove that the material is obscene (or obscene for minors)under both national and local community standards. the use of the national standard would avoid the problem that concerned the third circuit court of appeals, and the use of the local standard would be necessary to ensure that the material was in fact unprotected in the particularjurisdiction in which the prosecution takes place. in any event, this issueis currently pending.more vigorous prosecution of federal and state obscenity lawsñregardless of the outcomeñwould help to clarify whether the current state ofaffairs with respect to obscenity prosecutions is due to a liberalization inòcommunity standards,ó a lack of willingness to undertake prosecutions,or some other factor or factors. thus, such prosecution could help to establish more uptodate benchmarks for the field, a development that wouldprovide muchneeded guidance for law enforcement professionals dealingwith such issues. finally, vigorous enforcement of laws against false anddeceptive advertising and business practices (an example of which is described in section 3.4.2) could help to reduce exposure to inappropriateyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.205legal and regulatory toolssexually explicit material that results from mousetrapping, takeovers ofspam that advertises adultoriented, sexually explicit sites, and so on.finally, note also that despite the supreme court ruling overturningthe provisions of the child pornography prevention act relating tocomputergenerated imagery (discussed in chapter 4), there is no bar tothe prosecution of material that is obscene, whether or not it involvescomputergenerated images. thus, if material depicts a child engaged insexual activity, the full weight of the obscenity laws continues to applyshould that material be foundñthrough the miller testsñto be obscene.9.2civil liability for presenting obscenematerial on the internetbecause prosecutors have not been inclined in recent years (i.e., throughout most of the 1990s) to commit substantial resources to obscenity prosecutions, an alternative is to allow private individuals to bring civil actions fordamages against individuals or businesses that purvey obscenity on the internet. under such a regime, any person who finds obscenity on the internetcould sue the web site operator for civil damages. this use of the conceptof òprivate attorneys generaló is not unknown in the law. but it is exceptionally rare.ordinarily, one cannot bring a civil action for damages without showing some legally cognizable harm to the wouldbe plaintiff that has notbeen suffered by other persons generally. for example, if x drives his carin excess of the speed limit, he cannot be sued for damages by people whowere not individually damaged by his speeding. similarly, people cannotsue for damages a murderer, a thief, or a drug dealer, without a showingof particularized, specific harm to them as individuals. although the ideaof essentially creating a òbountyó by authorizing such suits has someappeal, it is generally not consistent with the standards of the u.s. legalsystem or the basic goals of u.s. system for civil actions. and althoughcivil actions for damages are familiar in the realm of expression (for example, civil actions for defamation), they have always required a showingof individualized harm.a further difficulty is the potential for abuseñusing the court systemmerely to harass providers of material that one group or another findsobjectionable.9.3options for dealing with material that is obscene for minorsin recognition of the special problems posed by the exposure of children to sexually explicit material, the supreme court held in ginsberg v.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.206youth, pornography, and the internetnew york that the government can constitutionally prohibit òthe sale tominors . . . of material defined to be obscene on the basis of its appeal tothem whether or not it would be obscene to adults.ó in other words, thegovernment can prohibit children from having access to certain types ofsexually explicit material that it cannot constitutionally ban for adults. asnoted in chapter 4, this doctrine works best in those situations in which itis possible to separate children from adults, for as the supreme court hasalso observed, the government òmay not reduce the adult population . . .to reading only what is fit for children.ó thus, in decisions like reno v.aclu, the court has made clear that the government may not prohibitmaterial that is òobscene as to minorsó on the internet unless it can do soin a way that does not unduly interfere with the rights of adults to haveaccess to such material.further, there is a very wide developmental range from birth to the ageof legal majority. the very concept of speech that is obscene for minors hasnever been well defined, but presumably its content varies with the age ofthe minor. this creates a problem for any unitary definition for the term.furthermore, what is obscene, either for adults or for children, turns in parton community standards. but as noted in chapter 4, it is difficult to defineor identify community standards when one deals with the internet. thismay, or may not, present a constitutional problem depending on the restrictions that are imposed on such material (see below).although an outright prohibition of material that is obscene for minors would therefore be unconstitutional, more finely tuned proposals,such as those described below, may pass constitutional muster.9.3.1age verificationin the child online protection act of 1998 (copa), congress soughtto remedy the deficiencies in the communications decency act of 1997(cda) that led the supreme court unanimously to invalidate the cda inreno v. aclu. (see chapter 4.) copa declares it unlawful to communicate on a commercial web site material that is obscene for minors bymeans of the world wide web if the material is available to minors.copa states that it will be an affirmative defense if the defendant, ingood faith, takes reasonable measures to restrict access to the material byminors by requiring a credit card, an adult access code, an adult personalidentification number, or other appropriate proof of age. as of april2002, the constitutionality of copa is currently pending before the supreme court of the united states in ashcroft v. aclu.as noted above, one issue in this case is whether the use of localcommunity standards in the context of the internet is consistent with thefirst amendment. another issue is whether the requirement of age veriyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.207legal and regulatory toolsfication passes constitutional muster. for example, in a book store onecan require proof of age to purchase a book that is obscene for minors,thus providing access to adults while denying access to children. copaattempts to establish a similar basis for differentiation between adults andminors on the internet. because the implementation of age verification onthe internet requires the use of technology, the objection to copa is thatit imposes significant costs on the web site operator and/or the adultviewers and that by potentially creating a permanent record it violateslegitimate privacy interests and chills the freedom of adult viewers.if the supreme court upholds the constitutionality of copa in ashcroft v. aclu, this will appreciably advance the interests of those whoseek to prevent minors from gaining access to material that is deemed tobe obscene for minors. it will not necessarily meet all of their concerns,however. first, copa applies only to material that is obscene for minors.the precise definition of this concept remains largely undeveloped, and itis not clear how far it will reach. second, copa applies only to materialon the world wide web. it does not apply to chat rooms or email. third,copa applies only to commercial web sites. it does not apply to noncommercial sites. these three limitations on copa were necessary tomeet the concerns of the supreme court in reno v. aclu in invalidatingthe cda. fourth, copa will be effective only to the extent governmentactually prosecutes violations with sufficient vigor to have a significantdeterrent effect. the lack of internet obscenity prosecutions in recentyears raises questions about whether such prosecutions will occur. fifth,copa applies only to web sites in the united states. for jurisdictionalreasons, federal legislation cannot readily govern web sites outside theunited states, even though they are accessible within the united states.because a substantial percentage of sexually explicit web sites exist outside the united states, even the strict enforcement of copa will likelyhave only a marginal effect on the availability of such material on theinternet in the united states. thus, even if the supreme court upholdscopa, copa is not a panacea, illustrating the real limitations of policyand legal approaches to this issue. the committee also notes that, even ifcopa is constitutional, this does not necessarily mean it is good publicpolicy. the concerns raised against copa could at least arguably lead tothe conclusion that it is insufficiently effective to justify its costs, whetheror not it is consistent with the first amendment.if the supreme court invalidates copa because age verification procedures in the context of the internet are too burdensome on the firstamendment rights of adults, this will make it very difficult to regulatematerial that is obscene for minors in this environment. in the next fewsections, the committee presents several legal and regulatory approachesthat might be available even if the supreme court invalidates copa.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.208youth, pornography, and the internet9.3.2plain brown wrappers and age verificationmany commercially oriented adult web sites subject the viewer to anassortment of òteaseró images that are intended to entice a viewer to payin order to see more such images. in many cases, the teaser images include material that may be obscene. to prevent minors from viewingsuch materials, it might be possible to grant such web sites a statutoryòsafe harboró immunity from prosecution under obscenity laws if theprovider places the web site behind a òplain brown wrapper.ó2 such aònoticeó page would contain an appropriate warning indicating that going past this notice page should be done only if the viewer is older than18, and that going past this notice page constitutes certification that theuser is indeed older than 18.3 the notice page would contain no images,or perhaps images that are obscured in the same way that the covers ofadultoriented magazines are obscured in the newsstands.the purpose of the notice page is to ensure that anyone who reachesthe sexually explicit web pages of a site has actually read the notice andagreed to its terms. however, many sites today have notice pages and itis still often possible to reach sexually explicit pages on those sites throughsearch engines that index the pages behind the notice page. thus, byclicking on a link that may be returned by a search engine, the user circumvents the notice page entirely.to prevent such circumvention, it is necessary to prevent search engines from indexing the pages behind the notice page, and a standardprotocol for accomplishing this task is described in chapter 2 (box 2.2).for a site that uses this protocol (the òrobots.txtó protocol), a web indexerfor a search engine cannot reach the pages behind the notice page, and sosearch engines cannot return links to those pages and thus users cannotaccess them directly. thus, the only way that a user could reach thecontents of the adult web site would be to go through the notice page.this approach would reduce inadvertent access to teaser images onadultoriented sites, and thus provide a greater level of denial of suchaccess than is currently in place. of course, this approach would not2the reason for this approach (of granting immunity from prosecution under obscenitylaws rather than obsceneforminors laws in exchange for using age verification technologies and òplain brown wrappersó) is that if it were constitutional to prosecute a web siteoperator under obsceneforminors laws, the government would simply do it. however, ifsuch prosecutions are found to be unconstitutional, then the web site is immune from suchprosecutions regardless of what it does with respect to age verification technologies andòplain brown wrappers,ó and thus an incentive of a different sort is needed to persuadethem to adopt such measures. in this case, the incentive is to grant another, differentbenefitñnamely, immunity from obscenity prosecution.3the age of 18 is an age that denotes legal emancipation for a minor, but there is noparticular reason that the age could not be some other number.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.209legal and regulatory toolsprevent access by individuals under 18 who are willing to lie about theirage. to deal with such individuals, it may be possible to add to the plainbrown wrapper an age verification requirement. that is, in order to getpast the notice page, proof of age would be required.4 (a discussion ofage verification technologies is contained in chapter 13.) such a provision might be constitutional, even if copa is declared invalid, becausethe use of age verification is encouraged by the offer of immunity fromprosecution for obscenity, but is not legally required.9.3.3labeling of material that is obscene for minorsanother possibility would be to require any commercial provider ofmaterial that is obscene for minors to label that speech in a machinereadable manner that enables parents and others to technologically blockthe access of minors to such material (section 12.1 has further discussionof this approach). because this approach focuses only on a categoryof speech that can constitutionally be restricted for minors, and doesnot prohibit adults (or even minors) from accessing it, it may not beunduly burdensome. and if the market responds appropriately, the proposal provides parents with a reasonable degree of control over whattheir children see.if the labeling requirement is found to present constitutional difficulties, a less speechrestrictive approach would be to grant safeharbor immunity from prosecution under òobscene for minorsó and obscenity lawsfor those who voluntarily label their materials in an appropriate manner.9.3.4prohibiting spam that is obscene for minorsa third approach would be to prohibit any person from sending onthe internet commercial spam that includes material that is obscene forminors. this is less intrusive on first amendment interests than copabecause it deals only with commercial advertising and it involves sendinginformation to individuals who have not requested it or sought it out.4the use of age verification technologies poses a significant privacy issue. indeed, in thecases of the cda and copa, the courts reviewing these acts found that these requirementswere unreasonable given the current state of technology and that age verification measuresimpose significant burdens on web sites because the verification measures require sitevisitors to provide personal information. because users are reluctant to provide this information and are discouraged from accessing sites that require such disclosures, the imposition of age verification requirements may chill or inhibit adults from accessing nonobsceneweb sites, both because they might not wish to give personal information and because theymay not be able to prove their age. these measures, the courts found, would diminishaccess to protected speech and thereby impose significant expense on commercial sites.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.210youth, pornography, and the internethowever, this approach is potentially more problematic than copa because it restricts the sending of such material to adults as well as to children. unlike copa, it does not attempt to differentiate between them.in general, the supreme court has held that the government cannotprohibit the sending of constitutionally protected material (including commercial advertising) to individuals who have not expressly asked not toreceive it. in bolger v. youngs drugs products corp.,5 for example, thecourt invalidated a federal statute prohibiting the mailing of unsolicitedadvertisements for contraceptives because the interest in shielding òrecipients of mail from materials that they are likely to find offensiveó is notsufficiently substantial to justify the restriction of òprotected speech.óthe most plausible distinction between the law invalidated in bolger anda ban on sending through the internet commercial spam that includesmaterial that is obscene for minors is that material that is obscene forminors is constitutionally protected for adults, but not for children. thismay not be a sufficient distinction to make a constitutional difference.more modest versions of this proposal, more likely to withstand constitutional scrutiny, would prohibit any person from sending commercial spamthat includes material that is obscene for minors (a) without appropriatelabeling (e.g., having a warning on the email subject containing a message like ònot appropriate for children under 16 years of ageó), or (b)without prior age verification, or (c) after the recipient has objected toreceiving such material in the past.it is important to note that for speech to be regulated under the commercial speech doctrine, it must consist of advertising. thus, to the extentthat the constitutionality of the alternatives noted above turns on thecommercial speech doctrine, noncommercial spam or spam that does notconsist of advertising could not be restricted.it is also worth noting that most spam concerning sexually explicitmaterial does not consist of the sexually explicit material itself, but oflinks to web sites that have such material embedded within them. thus,the recipient of the email must affirmatively take some action actually toreach the web site (e.g., clicking on the link). from a constitutional perspective, there is a significant difference between òinflictingó sexuallyexplicit material on individuals who do not want to be exposed to it andproviding those individuals information about how to find such material.even if the former can be regulated, the latter may warrant greater constitutional protection.this observation may be especially important in applying the commercial speech doctrine. from a constitutional perspective, there is a5463 u.s. 60 (1983).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.211legal and regulatory toolsdifference between giving individuals information about how to obtainan unlawful thing and actually providing them with the thing. makingillegal the mere providing of the link might pass constitutional muster if(a) the material at the link could be determined to be illegal (as it couldsometimes be under obscenity laws) and (b) the party providing the linkis essentially an accomplice under the criminal law. requirement (b)would not be met merely because someone provided information abouthow to find obscene material. however, it would be met if the spammeris also the operator of the web site containing obscene materials (or if thespammer is hired by the web site operator), because the spam could beregarded as an advertisement for an illegal product and the provider orsender punished on that basis.note that a variety of legislative proposals have appeared with theintent of reducing the problem of spam emails. for example, one federalproposal calls for prohibiting senders of unsolicited commercial electronicmail from disguising the source of their messages, and giving consumersthe choice to cease receiving a senderõs unsolicited commercial electronicmail messages.6 this proposed legislation prohibited senders from including materially false or misleading header information and deceptivesubject headings in commercial email, required the inclusion of a validreturn address in commercial electronic mail so that the recipient couldindicate a desire not to receive further messages from the sender, andpenalized further transmissions of email once such a desire had beenindicated. states have also sought to regulate spam, as illustrated inbox 9.1.still another possibility for regulating spam is a mechanism similar tothat for regulating the telephone calls of telemarketers.7 thus, it might befeasible for a central clearinghouse to register and maintain specificemail addresses or perhaps even entire domain names as a òdo not spamódatabase. the clearinghouse would also be configured to provide database results automatically. any party sending spam would be required tocheck the òdo not spamó database and eliminate from its mass mailing alladdresses contained in the database. not doing so (and the proof wouldbe the receipt of a spam by someone contained in the database) wouldsubject the sender to some civil liability and/or classaction suit. (note6hr 718, the unsolicited commercial electronic mail act of 2001, passed the house onapril 4, 2001.7at present, a customer request to refrain from calling must be honored only by thespecific company to which the customer has given notice. as this report goes to press, thefederal trade commission is proposing to create a centralized national òdo not callóregistry that would enable consumers to eliminate most telemarketing calls simply by registering with a central òdonotcalló list maintained by the ftc. see <http://www.ftc.gov/opa/2002/01/donotcall.htm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.212youth, pornography, and the internetthat a mechanism of this sort that was specifically aimed at senders ofsexually explicit spam would be much more suspect under the firstamendment because it would not be contentneutral.)9.3.5prohibiting the practice of mousetrapping to web sitescontaining material that is obscene for minorsanother approach may be to prohibit the practice of mousetrappingat sites that contain material that is obscene for minors without prior ageverification. even if the court finds copa unconstitutional, it may bethat the act of directing children to material that is obscene for minorswithout their consent or any affirmative act on their part would be upheld. the act of mousetrapping involves not only exposing individuals tomaterial they would prefer to avoid, but rather actually taking over theirfreedom of choice and effectively compelling them to view such material.whether or not all mousetrapping can or should be restricted, a reasonable case can be made for prohibiting operators of web sites from sendingbox 9.1the washington state experience with antispam lawsin 1998, the washington state legislature passed the unsolicited commercialelectronic mail act, rcw 19.190.020, which prohibits unsolicited electronic mailthat advertises consumer products with a false or misleading subject line or returnaddress. such email is more commonly known as òspam.óin june 2001, the washington supreme court unanimously upheld the constitutionality of the stateõs antispam email law. the decision involved a lawsuit filed bythe attorney generalõs office on october 22, 1998, against an oregon man, jasonheckel, and his company, natural instincts, of violating the stateõs new antispam lawby sending unsolicited commercial email. while the subject of the emails was topromote a forsale booklet titled òhow to profit from the internet,ó the subject headerwas allegedly òdid i get the right email address?óña ploy to entice recipients todownload and read his entire message. in addition, the email allegedly contained aninvalid return email address to which recipients were unable to respond.in march 2000, king county superior court judge palmer robinson dismissedthe case against heckel and his company on grounds that the state law violated thecommerce clause of the u.s. constitution. but in its ruling overturning judge robinsonõs dismissal, the washington supreme court found that ò. . . the only burdenthe act places on spammers is the requirement of truthfulness, a requirement thatdoes not burden commerce at all but actually ôfacilitates it by eliminating fraud anddeception.õ òthe case will be remanded to the superior court for trial.source: adapted from <http://www.wa.gov/ago/releases/relspam060701.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.213legal and regulatory toolschildren without warning or choice to sites that will expose them to material that is obscene for minors. a more modest variation would be torequire at least a warning before mousetrapping a viewer to a site containing material that is obscene for minors.9.4enforcement of recordkeeping requirementsone element of the federal obscenity laws (18 u.s.c. 2257, as discussed in section 4.2.2) involves a recordkeeping requirement intendedto ensure that performers and models depicted in sexually explicit scenesare older than 18. more active enforcement of this provision may betterprotect minors from participation in the creation of child pornography.8assuming that strict enforcement of this provision can withstand constitutional scrutiny, such enforcement might also have the effect of increasing the rate at which the adult online web industry consolidates.compliance with the regulation would increase the expenses of such providers, and would be likely to drive out of business the smallscale òquickbuckó enterprises, while the established adult content providers wouldsimply absorb those expenses as a cost of doing business. (at the sametime, as a matter of constitutional doctrine, the intent behind enforcementis highly relevant. if these laws are enforced with the intent of driving outof business otherwise legal business operations, such enforcement mightwell raise constitutional questions.)as described in chapter 3, representatives from the online adult industry testified to the committee that attracting children was not in theirbusiness interest. taking this testimony at face value, and assuming thatthe òquick buckó providers are the ones that are not discriminating intheir attraction of traffic to their sites (i.e., not distinguishing betweenadults and minors), then enforcement of 18 u.s.c. 2257 might result in awithering of the irresponsible enterprises, leaving behind businesses thattake more seriously their responsibilities to deny access of their wares tominors. note also that the issue of recognizing òsexually explicit conductó is far simpler than recognizing obscenity, a fact that would simplifyconsiderably the task of prosecution.98this point is likely to be most relevant in the context of web sites that depict òbarelylegaló models engaged in sexually explicit behavior. thus, the child pornography at issueis most likely to be images of an older minor engaged in sexual activity.918 u.s.c. 2257 defines ôõsexually explicit conductõõ as actual sexual intercourse, includinggenitalgenital, oralgenital, analgenital, or oralanal, whether between persons of the sameor opposite sex; bestiality; masturbation; sadistic or masochistic abuse; or lascivious exhibition of the genitals or pubic area of any person.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.214youth, pornography, and the internet9.5streamlining the processof handling violationsprosecutors seeking to enforce child pornography laws rely to a significant extent on lay person reporting of child pornography. that is, lawenforcement officials may come across such material in the course of theireveryday work, but citizens filing complaints about such material are amajor source of leads and tips.in an internet environment, the most natural way to file such complaints is likely to be electronic. for example, a concerned citizen lodginga complaint with law enforcement officials should provide the route towhich the material came to the citizenõs attention and a description of theimage. because images are hard to describe in words, a copy of the imagewould be desirable to include in the complaint. indeed, in the case ofchild pornography, such a copy so forwarded might be the only tangibleevidence that law enforcement officials could obtain, as child pornography sites are generally highly transient (and by the time law enforcementofficials are able to act on such complaints, the site may be gone). however, if the citizen files an electronic complaint with a copy of the suspectimage, he or she may be in technical violation of statutes that prohibit theelectronic transmission or distribution of child pornography, even thoughit is being transmitted to law enforcement authorities or the nationalcenter for missing and exploited children (ncmec) and even thoughsuch evidence might be crucial for the investigation and prosecution ofthe offender by law enforcement. instead, complainants must often gothrough a cumbersome and inconvenient procedure to file such a report.10a similar problem affects the ncmec. despite the ncmecõs role inproviding technical assistance to law enforcement in the investigation ofchild pornography, it does not enjoy the same immunity enjoyed by lawenforcement authorities to receive, possess, and store complaints of childpornography, and it does not have the authorization to transfer evidenceof child pornography from the ncmec to other designated law enforcement agencies outside the cybertipline (ctl) system and sometimeseven within the ctl system.1110for example, to report a suspected violation through the ncmec, they must providethe relevant url where the image can be found and a textual description of the image. inan online environment, it would be much simpler and easier for the citizen to simply forward the image.11the cybertipline, operated by the ncmec, is a national reporting mechanism for useby citizens to report to law enforcement authorities apparent instances of sexual exploitation of children; possession, manufacture, and distribution of child pornography; onlineenticement of children for sexual acts; child prostitution; childsex tourism; and child sexualmolestation. see <http://www.cybertipline.com> for more information.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.215legal and regulatory toolsrelief for the first problemñi.e., allowing citizens to report suspectedchild pornography to the ncmec without fear of prosecutionñcouldenable and encourage more citizen action in this area, while relief for thesecond problem would enable the ncmec to proactively forward suchevidence to law enforcement outside the ctl system.9.6selfregulatory approachessuccessful selfregulatory approaches are based on the fact that thefirms in an industry are generally willing to abide by a common code ofbehavior, though as noted in chapter 4, such a willingness may reflect adesire to stave off legislation or other regulation that these firms wouldfind more onerous. one example of selfregulation with respect to certainmedia content is the willingness of private producers of tv content toprovide ratings of their content that can be processed by the vchip.today, a large number of reported instances of child pornographyremain on internet service provider (isp) servers because law enforcement lacks the resources to investigate every report. an approach used ineurope with some success is employed by the european inhope hotlines. under the inhope approach, european isps support a nongovernmental organization, staffed by trained specialists to identify childpornography and funded by the isps, whose role is to advise internetservice providers of possible postings of child pornography.12 (throughinternet òhotlines,ó this organization takes tips from the public, butscreens them for credibility.) such advisories do not have any bindingeffect on isps, but in fact many isps cooperate with such advisories bytaking down the offending material because these advisories providemore authoritative advice than that provided by members of the public.13in a u.s. context, such a function could be provided by the ncmec,which currently lacks the authority to provide such advisories.a second facet of possible selfregulatory efforts might include prominent placement of the ctl reporting icon on adultoriented web sites.today, many such web sites provide links to information on filteringproducts, and some even have a banner that says òfight child pornography.ó it would be simple for these sites to add the ctl icon, which hasproven quite useful in reporting online child pornography.12note also that the fact of private support by the isps is the key component of the òselfregulatoryó dimension of this approach as viewed by the council of europe.13note that the private terms of service to which users must conform as a condition of anispõs service agreement with the user grant isps considerably more latitude in the exerciseof such òtakedownó authority than would be possible if they were agents of governmentand hence constrained by legal and constitutional barriers.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.216youth, pornography, and the internetanother dimension of selfregulation is the willingness of isps toenforce the terms of service to which users must agree. to the extent thatthese terms of service prohibit posting or sending of inappropriate material, harassment, or other inappropriate behavior (and most terms of service do contain some restrictions along these lines), isps have the authority to take quick action against offending users without waiting for legalaction.a third example of selfregulation could be set by the commercialsources of adultoriented, sexually explicit imagery that provide much ofthe content for smaller òaffiliates.ó in particular, they could build intotheir contracts with affiliates conditions that require those affiliates toengage in responsible behavior. thus, as one possibility, affiliates couldbe required contractually to put their content behind the internet equivalent of òplain brown wrappersó with age verification. the firms thatsupply them with content would be in a position to check on them andpenalize them if they did not (by cutting off a content source).9.7general observationsin its consideration of various public policy options to help shieldchildren and youth from inappropriate sexually explicit material on theinternet, the committee realizes that the viability of many proposals depends on how makers of public policy make certain tradeoffs. proposalsthat depend on regulating a certain type of content (namely, sexuallyexplicit speech) are inherently more suspect on first amendment groundsthan proposals that regulate speech independent of content.for example, the committee believes that spam containing materialthat is obscene for minors should not be sent to children. but laws banning such email to minors are potentially problematic in an online environment in which it is very difficult to differentiate between adults andminors. at the same time, a ban of all spam regardless of content may beseen as too broad because it affects many other interests.the committee also believes that it would be desirable for adult website operators who exhibit material that is obscene for minors to use ageverification systems so that children would not be able to access suchmaterial. however, in an online environment in which it is very difficultto differentiate between adults and minors, it is not clear whether this canbe achieved in a way that does not unduly constrain the viewing rights ofadults. thus, as one illustrative example, the government might offer agrant of immunity from prosecution under obscenity laws to web siteoperators who use age verification systems to prevent minors from accessing such material. in this instance, the tradeoff is helping to protectyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.217legal and regulatory toolschildren from exposure to certain kinds of inappropriate sexually explicitmaterial in return for limitations on possible obscenity prosecutions.enforcement of obscenity laws also presents tradeoffs. increasedprosecution of obscenity would likely require increased resources, andthose resources must be taken from some other activity. if, as is likely, theother activity represents prosecutions of other crimes, policy makers mustmake the judgment that it would be wise to pursue more obscenity prosecutions rather than other criminal prosecutions, or that more prosecutions for obscenity would necessarily be the best use of additional resourcesñif such resources are available. such judgments are complexand require a careful weighing of many competing factors well beyondthe scope of this report.several other general observations follow below:¥while the foundation of protecting children from inappropriateinternet materials and experiences continues to be social and educationalstrategies to instill ethics of responsible choice and coping strategies forinadvertent exposure, public policy has a role in shaping the environmentin which children exercise their choices.¥actions to remove illegal material from the internet can occur muchmore quickly if the authority to do so is based on the terms of privatecontracts (such as terms of service) rather than the requirements of public law.¥obscenity prosecutions are often difficult to undertake, becausecommunity standards are often not knowable in advance of an actualtrial. by contrast, child pornography is based on standards that are ofteneasier to identify (e.g., is this material sexually explicit? versus does thismaterial violate community standards?) and as such is easier to prosecute, all else being equal. nevertheless, more aggressive prosecution ofallegedly obscene materials, even if not always successful, would help toclarify the status of this instrumentality.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.218a preadolescent boy using an internetenabled computer in class issurfing the internet. on his search engine, he comes across a link to aweb site. he raises his hand and tells his teacher, òi think i am about togo somewhere that i shouldnõt go.ó the teacher stops the class and asksthe student to explain to the class why he thought his surfing might havebeen about to take him to a place that he should not have gone.10.1foundations of responsible choicelinda roberts, then at the department of education, told the committee the story described above. the boy involved is arguably less vulnerable to being exposed to inappropriate material on the internet than if heused any technological blocking mechanism for protection. the reason isthat his òfiltering mechanismó has been internalizedñand he has internalcriteria for deciding what might constitute inappropriate material.in other words, a child who faces a free choiceñand chooses responsible and ethical options over othersñis protecting himself. thus, theissue at hand is one that relates to the sense of ethics and responsibilityand the character underlying a free (and often unaided) choice. indeed, ithas been frequently mentioned to the committee that those who reallywant to obtain inappropriate sexually explicit material on the internetwill generally find ways of doing so, circumventing all technological measures to curtail access to such material. for determined individuals with10social and educational strategiesto develop personal andcommunity responsibilityyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.219social and educational strategiesthe technical skills to do so, only a conscious choice to refrain from suchseeking will reduce his or her access to these materials.almost by definition, a child is not yet fully mature, even if, as in thecase of adolescents, their physiology may be fully capable of sexual engagement. no maturing child is immune to temptation. no curious childis safe from the cyberspace equivalents of touching the hot stove, tumbling into the unprotected swimming pool, and getting into any ònicemanõsó car.children need supervision. they also need love. parents and teachersprovide both. children need significant adult reference pointsñsignificant adults who, in fact, function as reference works. they are there toanswer questions and point inquiring minds in the direction of òrightó (inthe sense of sensible, ethical, correct, and ageappropriate) answers. experimentation is part of the discovery process; reckless endangermentis not.as children develop morally and ethically, they internalize principlesand values that work from within to prompt external actions. once internalized, they support òhabitsó and facilitate habitual behavior. thus therole of ethical and moral education is to articulate guiding principles forthe child that can be freely chosen and, once internalized, serve to promptappropriate behavior. a person of character is a principled person. significant adultsñparents, teachers, coaches, counselors, clergyñarticulateand explain principles to the young, and the learning role of the latter is toassimilate them.the problem of developing character is compounded by the important role of community. in real life, the presence of a supportive community is generally regarded as a major positive factor in the development ofan individualõs sense of social responsibility and responsible behavior.but in an online environment (especially an anonymous one), a sharedsense of communityñwith all of the attendant rights and responsibilitiesñis hard to develop among individuals who see the internet in purelyinstrumental terms.1 anonymity in particular (as would be true in anenvironment that does not require individual logins, and as is true formuch web surfing) enables individuals to escape responsibility and toavoid negative consequences for inappropriate behavior.2in any event, encouraging youngsters to become principled personsis no easy task. one path to a principled life focuses on the internalization1see, for example, robert putnam, 2000, bowling alone, simon & schuster, new york.2true anonymous web surfing is possible only if one takes special measures to be anonymous. nevertheless, the perception that one is anonymous on the internet even withouttaking special measures is strong, and in any case, a perception of anonymity (or at leastprivacy) can result simply from having a screen that no one else can see.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.220youth, pornography, and the internetof family values, family traditions, and shared meanings within the family that can help to shape the developing character of a child, and helpòexplainó why a given youngster chooses to do this or avoid that. forthose who are religious, this can include faithbased values in this internalization process. these principles and values can serve to help a childjudge what is or is not reasonable in a context broader than the immediacy of pleasure and pain, of ògetting caughtó or ògetting away with it.óindeed, an approach based primarily on punishment presupposesthat children engaging in inappropriate behavior will be caught misbehaving. as a practical matter, detection of such behavior will often notoccur, especially if those children seek to remain undetected. while thefear of punishment will deter some children, others often do things forwhich they might be caught and punished in spite of that possibilityñfear of punishment is not enough to deter these children from things theyreally want to do. moreover, the research literature indicates that thethreat of punishment per se is not an effective approach to helping individuals internalize codes of behavior.3 while such a threat is sometimeseffective in deterring undesirable behavior, individuals who find themselves free of the threat often revert to the undesired behavior.these comments do not detract from the positive role that punishment or discipline may play as one element of an approach to education. itis entirely appropriate to impose sanctions for the deliberate violation ofrules if such rules have been explained clearly and discussion with children about their rationale and purpose has been entertained. but explanation and discussion are essential for putting these rules into context asappropriate reflections of parental values.every parent has the difficult task of determining where trust endsand neglect begins. they want to trust their children, and their childrenñparticularly in the teen yearsñwant to be trusted. but parents donõt wantto be negligent, and their offspring often find it difficult to appreciate thetugofwar within a parentõs heart between the desire to trust and the fearof neglect. though parents might wish otherwise, there is no clear andsimple line of demarcation.for example, as noted in section 10.4, parents can insist that childrennot have access to a computer in the privacy of their bedrooms. better tohave it outside in the hall, or downstairs in the family roomñto have it, inother words, in a place where casual passersby can appear at any time. itis not that the children arenõt trusted; it is simply an acknowledgment that3see, for example, m.l. hoffman, 1988, òmoral development,ó in developmental psychology: an advanced textbook, 2nd ed., m.h. bornstein and m.e. lamb, eds., erlbaum, hillsdale,n.j.; and g.h. brody and d.r. shaffer, 1982, òcontributions of parents and peers to childrenõs moral socialization,ó developmental review 2: 3175.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.221social and educational strategieschildren are children and are more likely to do the right thing when theyknow they might be observed.by extension, the character issue touches what is commonly referredto as òsocially responsible business.ó this is an area of practical, appliedbusiness ethics. as in any other industry, those in the adult entertainment industry have a social responsibility not only to provide return toshareholders but also to behave in ways that promote the good of society.because societyõs best hope for a better future lies with its children, allbusinesses have responsibilities for helping and not hindering the youngalong a safe path to mature character development.one dimension of that responsibility is to engage in business linesand practices that uphold human dignity and refrain from exploitation.but a perhaps more important dimension is to help create an environmentin which children can play, learn, and explore without fear of comingacross material that is inappropriate for them. thus, for example, entirelyapart from legal requirements to do so, those in the adult online industryhave important ethical and moral responsibilities to keep their materialaway from children, even if that has some negative financial implications.10.2definition of a social or educational strategyfor purposes of this report, social or educational strategies are coordinated plans of action that seek to develop in young people the ability tomake responsible and safe choices about internet use, to make good decisions about content to be viewed, to reduce their exposure to inappropriatematerial, and to mitigate the consequences, if any, of viewing inappropriatematerial. these strategies include activities that educate parents and youngpeople on internet use and address a variety of issues arising from onlineuse, such as how to reduce exposure to inappropriate material and how togive young people skills to mitigate any possible effects they might experience from encountering sexually explicit or inappropriate material online.through its deliberations and on the basis of testimony and otherinformation received, the committee has found that social and educational strategies are foundational for childrenõs safe, effective, and appropriate use of the internet. this is not to say that technology plays noroleñindeed, many technological tools can support the development andteaching of skills, attitudes, and ethical codes of behavior that will enableyoung people to use the internet appropriately. rather, exclusiveñoreven primaryñreliance on technological measures for protection wouldbe an abdication of parental and community responsibility and is likely tobe ineffective as well.table 10.1 provides an overview of the social and educational strategies described in this report.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.222youth, pornography, and the internet10.3contextual issues for socialand educational strategiesnew technology often does not live up to its promises. one reason isthat because technology changes rapidly for everyone, technology toolsdeveloped to solve problems exposed by other technological developments may be quickly rendered obsolete. but a more important reason isthat the underlying issues are social. it is true that the internet may havetable 10.1 social and educational strategies for protecting children onthe internetdescriptionone illustractive, inperson supervision of childõsinternet usehelp provided by sibling or peer mentoracting as guide to childõs use of theinternetstatement explicating in detail whatconstitutes acceptable and unacceptableuse of the internet and whatconsequences flow from the latterexplicit instruction on what constitutessafe internet behavior and how torecognize dangerous, inappropriatesituationsfacility in using critical reasoning skillsto obtain information sought and toevaluate the content of information thatis receivedcontent specifically designed to appealto children that is noncommercial andeducational and/or positive inorientationinitiatives featuring media spots andpublic service announcements about thenature of the internet, the potentialdangers of internet activity for children,and parental options for exertinginfluenceparental supervisionpeer assistanceacceptable use policies (aups)internet safety education (ise)information and media (i/m) literacycompelling contentmedia campaignsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.223social and educational strategiesexacerbated public concerns about the access of young people to inappropriate sexually explicit material, but the internet is more a symptom thanthe basic issue. furthermore, those who really want to disseminate inappropriate materials or find inappropriate materials on the internet haveproven adept at circumventing technologybased solutions. as the technology improves, so also do its circumventers, in a neverending game ofaction and reaction. this pattern is repeated in almost every instancewhere technology is used to thwart undesirable behavior.ildren onone illustrative advantageone illustrative disadvantageprobably not feasible to provide constantactive supervision of childõs internetaccess, especially as child gets olderolder sibling may lead younger one intotrouble; nonfamily peer mentors mayspend little time with childinfractions of aup may not bediscovered; without concerted attention,may become just one more form to befilled outno obvious forum in most existingcurricula to include iseno obvious forum in most existingcurricula to include i/m literacychild market not preferred by mostbusinesses because adult market is morelucrativeabsent followthrough in other nonmedia channels, significant constructivebehavioral changes in parents areunlikelyprovides closest connection to the valuesthat the parent wishes to impart to childprovides guidance and influence to whichchildren may be more responsive (compared to parental advice or assistance)provides clear behavioral guidelines forchild about what should and should notbe doneprovides clear guidance for child abouthow to conduct himself or herself on theinternetemphasizes critical reasoning skills thatare valuable in many contexts other thaninternet useavailability of such material would helpto divert childrenõs attention frominappropriate materials and experiencescan contribute a basic awareness of theissues in a broad segment of thepopulationyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.224youth, pornography, and the internetthe committee believes that the fundamental issue is how to teach ayoung person to make wise choices, to stay in control of his or her onlineexperiences, to be critical and skeptical about the underlying messages inadvertising and romanticized and sexualized images, and to report otherusers soliciting personal information or harassing them. a young personwho has been taught effectively about such matters will bring that trainingto any device that he or she uses and in any venue that offers online access.an analogy might be drawn to children and swimming pools. swimming pools pose some threat to the safety and wellbeing of children. butswimming pools provide benefits to their ownersñand childrenñin manydifferent ways. technologyñin the form of fences around pools, poolalarms, and locksñcan help protect children from drowning in swimmingpools. however, teaching a child to swimñand when to avoid poolsñis afar safer approach than relying on locks, fences, and alarms to prevent himor her from drowning. does this mean that parents should not buy fences,alarms, and locks? of course notñbecause they do provide some benefit.but parents cannot rely exclusively on these devices to keep their childrensafe from drowning, and most parents recognize that a child who knowshow to swim is less likely to be harmed than one who does not. furthermore, teaching a child to swim and to exercise good judgment about bodiesof water to avoid has applicability and relevance far beyond swimmingpoolsñas any parent who takes a child to the beach can testify.note also that social and educational strategies are the only way to dealwith young people determined to seek out inappropriate material. thosewho are determined are bound to find ways to circumvent any technological measures; to the extent that social and educational strategies can reducethe desire and motivation for seeking out inappropriate material or engaging in inappropriate activities, such behavior can be reduced. when technological protection does not work, or when it is not present, the individualinvolved must rely on his or her own internal resources to cope with theissue, whether it is in choosing to refrain from ògetting into troubleó orknowing how to cope with whatever trouble arises.in designing social and educational strategies, developmental issuesare critical. for example, very young children are generally not capable ofhandling a full range of unconstrained choices. however, as they gradually mature, it is usually appropriate to give them a wider range of choicesand increasing amounts of responsibility. of course, the nature and scopeof increased freedoms to choose are not generally based solely on age, butfor most young people, age is a relevant factor in teaching them increasingly mature and responsible behavior.44in some ways, the developmental issue is similar to that of learning to drive. licensesfor driving an automobile in all states are graduated to some extent (learnerõs permit andyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.225social and educational strategiesfor example, one timehonored practice of good parenting is to teachchildren to make responsible decisions by sharply constraining their choicesat first and then broadening the universe of choices as they grow moremature and more capable of making informed and wise decisions. ofcourse, under these circumstances, children may make some mistakes andinjudicious choices. but when the universe of choices is limited to thosethat are at least minimally acceptable, children have a chance to learn howto make good choices by exercising choice. further, the decisionmakingskills they acquire in doing so can be carried over to their later livesñinwhich the universe of choices is not composed exclusively of safe options.a major point to be considered about social and educational strategies is that they are not simple to implement. they require forethought,planning, and extensive followthrough. they can be costly, both in termsof dollars and in terms of time. often, they conflict with other pressingneeds. for example, most k12 curricula are already overloaded, andinformation and media literacy curricula must compete for time in theschedule with physical education, sex education, consumer literacy, and avariety of other pressures on the curriculum. pediatricians, who can speakwith youth about safety and puberty, and must complete health forms tobe submitted to schools, have limited time with each of their young patients. parental efforts must compete with making sure that childrenclean their rooms, do their homework, get to the soccer or basketballgame on time, avoid unhealthy use of drugs and alcohol, and so on.on the other hand, if the problem of exposure to inappropriate materials and experiences is as severe and consequential as many parentsbelieve it to be, there is no particular evidence indicating that the cost ofsuch programs is exorbitant. moreover, the benefits that accrue fromeffective social and educational strategies go far beyond protecting children and youth from inappropriate sexually explicit material. they haverelevance to many situations that individuals are likely to encounter, bothonline and offline, and will help them to navigate their internet experiences with confidence and wisdom.10.4parental involvement and supervisionthere is a broad consensus that the best approach to protecting youngpeople on the internet from inappropriate material and online predatorsfull driving privileges), and in some cases more finely (e.g., teens with solo driving privileges only during the day). while the notion of government licensing for using the internetis not particularly appealing or sensible, the idea of agebased expectations for appropriateinternet use makes developmental sense. parents may wish to consider what skills andknowledge related to the internet they want their children to have before they give themdifferent degrees of unsupervised internet access.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.226youth, pornography, and the internetis the attentive presence of a responsible parent, teacher, librarian, ormentor who is available to provide help and guidance, and to intervenewhen necessary. while this image does characterize some family situations, parents in most families are pressed for time. parents in many families today face long workdays, long commutes, and considerable workrelated overnight travel. singleparent households are common, as arefamilies in which both parents work full time. these facts suggest thatcontinual inperson supervision of a childõs internet usage by a parent isnot likely to be achieved by many families.notwithstanding limits on the time that parents have available, parents can still take actions in the home setting that can help their childrento develop a sense of safe internet use. no one action is definitive, andnothing effective can be done just once, but no sensible parent has everimagined that the task of parenting and of teaching oneõs children theskills in navigating through any aspect of life would be easy.¥parents can develop a basic understanding of what is on the internet andwhat their children can do with it. the internet world that most adults inhabitis far more workcentered than the one inhabited by most children, whichfocuses on social interaction, entertainment, and spontaneous play to a fargreater degree. (this suggestion is not much different from the advicegiven in a noninternet context that parents should be aware of the moviesand tv shows and music that engage a childõs attention.)such understanding is useful from two perspectives. parents who donot know what their children can do and see on the internet may beoverly complacent about the dangers to their children. also, parents whodo not know the routes through which their children can be exposed tosuch inappropriate material and dangerous experiences may be excessively fearful because they lack perspective on the ease or frequency withwhich such exposures might occur. it is noteworthy that a pew internetand american life survey found that parents who do not use the internetthemselves generally tend to be more concerned for their childrenõs internet safety than parents with more online experience.5parents also learn from more experienced parents, childcare workers, and pediatricians, about ageappropriate òharm preventionó steps totake in homes: remove lead paint; install childresistant clips on drawerswhere chemicals, knives, or guns are kept; install childresistant coversfor electric outlets; teach children never to use the stove without an adult5pew internet project. 2001. teenage life online: the rise of the instantmessage generationand the internetõs impact on friendships and family relationships. pew internet and americanlife project, washington, d.c. available online at <http://www.pewinternet.org/reports/reports.asp?report=36&section=reportlevel2&field=level2id&id=217>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.227social and educational strategiespresent; obtain and use bicycle helmets; and so on. inquiries to thesemore experienced and knowledgeable individuals could result in analogous recommendations to new parents regarding internet safety.¥computers can be located in such a way that private, solitary viewing bychildren is not possible. for example, computers located in private bedrooms cannot be supervised as easily as computers in public spaces (e.g.,in family rooms or dens). when the potential exists for a responsibleadult to happen across a screen displaying possibly inappropriate material while the child is there, the child is likely to be motivated to refrainfrom deliberate misbehavior. moreover, if the child encounters something upsetting or inappropriate by mistake, it is more likely that he orshe can obtain help more quickly and spontaneously. also, if a computeris located in a public space, the adult supervisor can more easily wanderover to inquire about what the child is doing.¥parents and their children can discuss household rules and expectationsfor a childõs use of the internet. issues to discuss may include:6ñwhen and under what circumstances internet use is permissible,ñthe amount of time that a child may spend using the internet,ñthe types of activities and web sites that are acceptable andunacceptable,ñwhat information may be given out or disclosed when using theinternet, andñwhat should be done if the child becomes uncomfortable in using the internet.it may also be helpful for parents and children to discuss expectationsfor the use of the internet at school. depending on a given familyõs values,a schoolõs acceptable use policy may allow certain web sites or activitiesto which a parent might object.¥parents can explicitly provide instruction and guidance to their childrenabout inappropriate activities and explain why their viewing of sexually explicitmaterials may be inappropriate. parents at one committee site visit went sofar as to argue that the best way to educate children about inappropriatesites was to show them some inappropriate sites and engage in a conversation with them about why they were inappropriate. for these parents(and for a number of those who testified to the committee as well), theproblem posed by sexually explicit material was not inherent in the sexualexplicitness of the material itself, but rather the lack of a responsiblypresented explanatory context. in other words, the concern was not so6this list is derived from nancy willard, 2001, òsupporting the safe and responsible useof the internet by students: a childrenõs internet protection act planning guide,ó centerfor advanced technology in education, college of education, university of oregon, available online at <http://netizen.uoregon.edu/documents/cipa.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.228youth, pornography, and the internetmuch that exposure to the material itself would be harmful, as the factthat without good explanations for why the material was inappropriate,children would get the wrong messages from it.¥parents can set limits for how much time a child may spend online.when time is constrained, people are more likely to concentrate on theactivities that they value most highly. to the extent that children seek outinappropriate material out of idle curiosity, these are the activities thatare most likely to be curtailed in the presence of time limits.¥parents can become more aware of tools and programs for internet safetyalready available to them. for example, parents may not know about theresources of getnetwise (box 10.1) or about the suggestions on thechildrenõs partnership web site on strategies they can use at home toguide their childrenõs internet use (box 10.2). parents may also notknow about the educational programs offered by their local libraries orby nonprofit groups in their area and as such are missing other opportunities to receive training and assistance in this effort (box 10.3 provides an example).¥parents can learn to deal with the fact that their children may be moreadept technologically than they are. it is accepted wisdom that many childrenñespecially adolescentsñknow more about technology than do theirbox 10.1getnetwisegetnetwise is an industrysponsored organization whose purpose is to create asafe, rewarding, and enjoyable experience for children online. getnetwise is a userfriendly, family empowering, online resource that contains aggregated and syndicated content, organized into four themes:¥internet safety guideñresources based on agelevel, risk area, and technology;¥tools for familiesña comprehensive guide to consumer products that allowfamilies themselves to monitor internet use, filter unwanted content, or control computer use;¥how to report online troubleñinformation on recognizing and resolvinginternet crime with links to law enforcement offices and childrenõs advocacy groups;¥guide to kids contentñpointers and information about online content that iseducational and helpful for kids.getnetwise is intended to be a resource for those seeking to be wise onlineparents, and seeks to provide help to anyone involved in raising childrenñparents,grandparents, educators, caregiversñeveryone concerned with the routine responsibilities of raising children in the digital age.source: for more information, see <http://www.getnetwise.org>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.229social and educational strategiesbox 10.2agebased tips for guiding childrenõs homeinternet use from the childrenõs partnershipages 2 to 3: computers need not play much of a role in the youngest childõs life.however, it doesnõt hurt for very young children to see family members usingcomputers and enjoying themselves online. tips:¥put your child in your lap as you òplayó on the computer.¥look for books and childrenõs video programs like sesame street that includeimages of children and family members using a computer.ages 4 to 7: while serious computer use isnõt a priority for these youngsters,children at this age can begin to make greater use of computer games andeducational products. tips:¥spend as much time as you can with your child while he or she uses thecomputer.¥show lots of tangible results and achievements. for example, print work yourchild has done on the computer.¥share an email address with your child, so you can oversee his or her mailand discuss correspondence.ages 8 to 11: at this age, children can begin to directly experience and appreciate more fully the potential of online experiences. for instance, children canbegin to use online encyclopedias, download pictures for school reports, or haveemail pen pals. tips:¥set very clear rules for online use and clear consequences if they are broken.¥teach children to let you know if they encounter anything scary or unusualonline.¥discuss some of the unique aspects of behavior in cyberspaceñlike anonymity and what it means for your child and for others.ages 12 to 14:at this age, young people can use the more sophisticated researchresources of the information superhighway, accessing everything from the libraryof congressõs collection to magazines and newspapers to archives from aroundthe world. tips:¥since children of this age are more likely to explore on their own, set up clearparental rules, limits, and periodic checkins.¥set clear rules about which chat rooms are acceptable for your teenager, andhow much time can be spent there.¥be sure your children understand the actions that can be taken if peopleharass them online or do anything inappropriate.¥pay particular attention to games that your teenager might download or copyas some of these games are extremely violent.(continues)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.230youth, pornography, and the internetages 15 to 18:the internet provides a rich resource for older teens, includinginformation about job opportunities, internships, and colleges; applications tocreate multimedia reports; and specialized help with foreign languages and otherschool subjects. tips:¥ask your teenager for help researching topics of interest to the family (followup on a family discussion, planning a family vacation, and so on).¥talk to your teenager about new things online and encourage discussion ofnew experiences.¥make sure your teenager knows the legal implications of online behavior.¥watch time limits to make sure your teenager is still pursuing a wellroundedset of activities.¥if your teenager is especially interested in computers, encourage him or her tohelp younger children with their online explorations (e.g., at the local boys or girlsclub).source: wendy lazarus and laurie lipper. 1998. the parentõs guide to the information superhighway, the childrenõs partnership. may. a complete copy of the guide is available at <www.childrenspartnership.org>.box 10.3an illustrative internet safety program for parentsthe internet and your child is a comprehensive internet safety and educationprogram for adults in many states, including alaska, california, colorado, connecticut, georgia, idaho, indiana, kansas, new jersey, north dakota, oregon, texas,and washington. taught by volunteer law enforcement officers and computer professionals, the program offers 7 hours of instruction covering:¥computer hardware and software basics,¥windows basics,¥getting connected to the internet,¥internet addressing,¥newsgroups,¥email,¥hacking,¥protecting your privacy,¥internet fraud,¥sex crimes,¥internet chats,¥filtering and blocking unwanted sites with software, and¥searching the internet for information on you or your child.source: see <http://www.theinternetandyourchild.org/>.box 10.2 (continued)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.231social and educational strategiesparents, and this often makes parents feel inadequate or incapable of providing guidance or setting boundaries about their childrenõs internet activities. yet, while many children have superior technical skills, parents arestill role models capable of exerting strong influence over the social, moral,and ethical development of their children. furthermore, a noteworthybody of research indicates that parental involvement in their childrenõsmedia activities is beneficial for young peopleõs development.7 to copewith a lack of technical knowledge, parents can learn about the technology,as described above. they can also learn about the technology from theirchildren, and learn to listen nonjudgmentally so that the child will feelfreer to explore situations in which parental input may be helpful.¥parents can be aware that their children are often more confident in theirabilities to handle themselves online than their actual abilities warrant. forexample, a study by the girl scout research institute found that girlssometimes òrely too much on their own judgment in making decisionsabout how to behave online. when asked how they know what is safe orunsafe behavior on the internet, 84 percent of online respondents citedtheir own common sense. by contrast, 51 percent of these girls cited learning from parents, 46 percent said television and the media, 29 percent saidteachers, 29 percent said friends, and 4 percent said, ônothing is that badonline because it is not really real.õó8 in one committee site visit, a girl ofabout 15 said that she would never meet anyone facetoface if she feltuncomfortable about him (or her). she also said she knew that people liedall the time online. but 30 seconds later she said that she could tell whenpeople were lying and that she trusted her instincts.¥parents can set good examples for responsible internet use. for example, a parent who views sexually explicit imagery online may wellleave traces of such viewing available for his or her child to find later.this may be quite all right if the parent would not object to his or her childseeing such material. but a parent who would object would not be wise toundertake activities that would raise questions in his or her childõs mind.also, a parent who demonstrates a disregard for the privacy of his or herchildren may find that they are less than careful with respect to marketersand survey takers about sensitive family information such as income orbuying practices. put another way, if a parent tracks a childõs onlinebehavior and the child has no privacy, then the child may not respect7national research council and institute of medicine. 2001. nontechnical strategies toreduce childrenõs exposure to inappropriate material on the internet: summary of a workshop.board on children, youth, and families and computer science and telecommunicationsboard, joah g. iannotta, ed., national academy press, washington, d.c.8whitney roban. 2002. the net effect: girls and new media. girl scout research institute,new york. available online at <http://www.girlscouts.org/about/pdfs/neteffects.pdf>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.232youth, pornography, and the internetfamily privacy if and when opportunities arise to profit from other familymembersõ private information.a second example arises with the idea of parental review of the sitesvisited by youngsters on the internet. if children know this is happening, willthey welcome it as a necessary ògovernoró of their choices, or resent it as aviolation of their privacy and an indication that they are not trusted? atyounger ages, they are likely to not object, but as children get older, theyoften develop a sense of personal space about which they are very protective.the difficulties of engaging in effective parental communications withchildren are significantñand parents who think they are talking effectively with their children about internet use may not in fact be doing so.for example, a survey taken by the kaiser family foundation and national public radio in 2001 noted that parents were more likely than theirchildren to think that they have rules in place about what their childrencan do on the computerñthat is, about threefourths of all parents interviewed said that they have such rules, but only half of all children interviewed agreed.9 further, only 38 percent of older children (aged 14 to 17)said that their parents know òa lotó about the things they do on theinternet and the web sites they visit.the discussion above regarding things that parents can do to promote and facilitate the safety of their children on the internet is presentedonly in outline form, and the committee does not believe that, by themselves, these guidelines and tips provide an actionable agenda. to be areal guide for concrete action, much more in the way of specifics is needed.however, to the committeeõs knowledge, there is no comprehensivecurriculum for parental education about the internet. many of todayõsworkshops emphasize what parents must be afraid of, but they omit affirmative steps that parents can take. as one example, the list above suggeststhat parents talk to their children about what counts as inappropriate material. but such conversations can be very awkward for parents. what aresome sample dialogs or approaches that a parent might use to raise thesubject? providing such dialogs is beyond the scope of this report, butresources must be made available to help parents address such issues.box 10.4 provides some speculations on ideas for promoting parentaleducation (and internet safety education, which is discussed in section10.8.1).9see <http://www.npr.org/programs/specials/poll/technology/>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.233social and educational strategies10.5peer assistancefor certain topic areas, many and perhaps most youth learn as muchfrom peers or nearpeers (e.g., siblings) as they do from parents, teachers,and other adult figures. indeed, a department of justice report finds that[f]or many children, having an older youth to talk to and spend timewithñsomeone who provides encouragement and friendshipñcanmean the difference between dropping out of school and graduating, orbetween getting involved with drugs and developing the strength andselfconfidence to resist such pressures. youth involved in mentoringprograms, in fact, have been shown to be less likely to experiment withdrugs, less likely to be physically aggressive, and less likely to skipschool than those not involved in such programs. peer mentors providethe important extra support that many younger people need to make itthrough a difficult period in their livesñwhen peer pressure and thedesire to fit in are strong influences. . . . peer mentoring programs matcholder youth with young students in oneonone relationships to provideguidance for the children. through this special relationship, peer menbox 10.4speculations on ideas for promoting parentaleducation and internet safety education¥television and other massmarket entertainment programming that providesrole models for parents interacting with their children in ways that enhance internetsafety¥interviews on tv and radio talk shows during which concrete tips on internetsafety can be provided to parents¥short courses on internet safety offered by schools, libraries, and communitycenters¥links to training in computer ethics and codes of responsible behavior¥discounts for internet service provider subscriptions for parents who complete a program of online training in internet safety¥awards to youth of various ages for achieving ageappropriate levels of internet proficiency, to include appropriate safety knowledge and education. such a program might be modeled on the physical fitness awards given to youth on behalf ofthe presidentõs council on physical fitness and sports1¥graduated privileges for internet use at school as a function of the safetyinstruction a student has completed¥government or foundation support for developing internet safety curricula forparents and youth1the program is known as the presidentõs challenge. more information can be found onlineat <http://www.fitness.gov/challenge/challenge.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.234youth, pornography, and the internettors provide advice and support and serve as role models for youngerpeople who need help.10of course, mentoring is also beneficial for the older youth in that theyare put in a position of responsibility and often rise wonderfully to thetask. older youth may be more likely to stay out of trouble and make evenbetter decisions because they know that they have someone watching andpotentially imitating their behavior.given research supporting the notion that peer or nearpeer mentoringof youth may be quite helpful to some young people in avoiding crime anddrugs and staying in school, it is not unreasonable to suppose that suchrelationships may be helpful in promoting appropriate use of the internet.for example, a program of the chicago public libraries trains college student volunteers to help users with computer technology in the library.they receive a week of training, and then they wander the floors of thelibrary to help young users on the internet. for example, they providesurfing suggestions that steer users to educational sites. these young userslearn about the internet but also have the opportunity to interact withsomewhat older college students who serve as role models. not incidentally, these volunteers also provide monitoring of usage that helps to keepchildren away from inappropriate or nonenriching internet material.older siblings can be a particularly rich source of peer assistance. forexample, in a number of site visits, older adolescents often expressedconcern about the internet experiences of their younger siblings, and triedto help them stay out of trouble on the internet by providing advice andguiding them to appropriate sites.note also that summer programs (e.g., camps) could also provideinternet safety instruction in an environment where youth are relaxed.camp counselors are often older youth and may be able to provide semistructured mentoring and guidance.peer assistance works best when there is a broad consensus amongthe peers that certain behavior is inappropriate or unsafe. thus, peerassistance is likely to be most effective in steering children away from,say, wouldbe child molesters or racist or hate sites. however, if the peerassisters themselves do not believe that exposure to adultoriented, sexually explicit material is a big deal (as may be the case for some individuals), they are less likely to be as vigilant or zealous in their efforts toprovide assistance.10see office of juvenile justice and delinquency prevention, 1999, mentoringña provendelinquency prevention strategy, u.s. department of justice, washington, d.c., availableonline at <http://www.ncjrs.org/html/youthbulletin/99074/mentor*.html> (where ò*óranges from 1 through 8).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.235social and educational strategies10.6acceptable use policiesan acceptable use policy (aup) is a set of guidelines and expectationsabout how individuals will conduct themselves online.11 aups are increasingly common in schools, and they are applicable to home and library use as well (especially when internet access is conditioned on accepting terms that accompany a library card). aups vary, but they almostalways contain provisions against viewing sexually explicit web sites,and perhaps other kinds of material (e.g., instructions for bomb making,hate sites). aups can also address outgoing material, such as childpostedemail and web sitesñsuch provisions are generally directed toward thepossibility that one child might create and disseminate sexually explicitpictures as well as harass, defame, and stalk other children. furthermore,aups must be acknowledged explicitly by those affected. an example ofone schoolõs aup is provided in box 10.5.the theory of the aup is that by making young people responsiblefor the content they create and the behavior that they demonstrate, theywill learn to be responsible for making good choices about the òpathsóthey choose in cyberspace, thereby learning skills that are relevant andhelpful in any venue of internet usage. of course, for an aup to beeffective, deliberate violations cannot go without response or sanction(e.g., loss of internet privileges, call to parents, detention if violationsoccur in a school context, grounding if in a home context). accidentalviolations should be seen as an opportunity to educate the user abouthow to avoid such content in the future, how to remove it from the screen,and if necessary how to report it to an internet service provider.furthermore, aups must be read, and young people must take themseriously. in a number of site visits, students appeared relatively ignorant of what their schoolõs aup stated. a number of teachers noted thatthey believed aups were not generally read, because they were simplyone of a large number of forms that students had to bring back signed.(this is consistent with recent research suggesting that students often donot recall the content of the aups they signed earlier in a school year, andwith the finding that some who signed them do not even remember having done so).12 thus, some explicit attention in the school, library, orfamily to the aup is warranted to underscore its importance.11the term òaupó is sometimes applied by internet service providers to their rules ofuse; more generally, such rules are known as terms of service. terms of service for isps arenot intended to govern childrenõs use of the internet, but rather are put into place to protectthe isp from legal liability and conduct (such as sending spam) that reduces networkefficiency.12janet w. schofield and ann l. davidson. 2002. bringing the internet to school: lessonsfrom an urban district. josseybass, new york, pp. 319320.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.236youth, pornography, and the internetas a rule, aups are most effective when they are developed in conjunction with parents, community members, teachers, school library media experts, school administrators, and students. aups developed jointlywith the school and community are more likely to incorporate the particular sensibilities of parents and can be designed to address specificconcerns, resulting in higher degrees of buyin, acceptance, and legitibox 10.5acceptable use policy of eau claire,wisconsin, area school districtthe eau claire area school district offers a good example of policies that establisha set of expectations about the manner in which students and staff will use schoolnetworks and technologies. this acceptable use policy sets rules about a number oftopics and includes guidelines to facilitate safety online, as well as respect for copyrighted materialñrelevant to preventing students from using the internetõs resources toplagiarize material. it forbids use of the internet for activities that are not in support ofthe educational objectives of the school district. what follows is the eau claire areaschool districtõs acceptable use policy, the full text of which can be found online at<www.ecasd.k12.wi.us/departments/technology/network/inetpol.html>.use of the internet and other computer networksthe internet is an electronic network connecting thousands of computer networks and millions of individual subscribers all over the world. access to theinternet will allow students to explore the rich resources of thousands of university libraries, governmental databases and other online sources while exchangingelectronic mail with internet users throughout the world. instructional and librarymaterials are routinely evaluated by school district personnel prior to purchase inorder to ascertain that such materials are consistent with district goals and guidelines and that they support and enrich the curriculum. however, use of the internet, because it may lead to any publicly available fileserver in the world, mayopen classrooms to electronic information resources which have not beenscreened by educators for use by students. some items accessible via the internetmay contain material which is inaccurate, defamatory or offensive. access to theinternet and other computer networks requires that school officials developguidelines for use. such guidelines should address the teacherõs responsibility fortraining and guidance, the studentõs responsibility for appropriate use, and theprincipalõs responsibility for supervising the use.internet and other computer networksñuse guidelinesthe following guidelines define òappropriate useó of the internet.1.all use of school resources to access the internet must be in support of andconsistent with the educational objectives of the eau claire area school district.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.237social and educational strategies2.transmitting any material in violation of any u.s. or state regulation orschool board policy is prohibited. this includes, but is not limited to, copyrightedmaterial and material that is threatening or obscene.3.hate mail, harassment, discriminatory remarks and other antisocial behaviors are unacceptable in internet and other network communication.4.all information accessible via the internet should be assumed to be privateproperty and subject to copyright protection. internet sources should be creditedappropriately, as with the use of any copyrighted material. example: the columbia guide to online style http://www.columbia.edu/cu/cup/cgos/idxbasic.html5.users have a responsibility to respect the privacy and property of other users. users should not intentionally seek information about, obtain copies of, ormodify, files, data or passwords of other users.6.for their own safety, users should not reveal any personal information, suchas addresses, phone numbers, or photographs.7.employing the internet for commercial purposes is prohibited.8.users should not expect that files stored on district servers will always beprivate. school and network administrators may review files and communications to maintain system integrity and to ensure that the network is being usedresponsibly.teachers will inform students of what is considered appropriate use of the internet, describing student privileges, rights and responsibilities. as much as possible,teachers will guide students toward materials which have been reviewed and evaluated prior to use. the use of home pages, bookmarks, lists of web sites, andcataloging web sites in the library system will help match internet resources to thecurriculum.because computer use is essentially an individual experience, however, primary responsibility for appropriate use of the internet resides with the student. a useragreement form will be signed by the student and parent prior to their use. failureto follow appropriate practices may result in disciplinary action including loss ofthe individualõs access to the internet.principals will supervise the use of the internet and other computer networksin their schools. procedures will be put in place to ensure that students receiveappropriate instruction and supervision in the use of the internet and othercomputer networks.note: the committee makes no representation that this acceptable use policy does or does notcomply with the requirements of the childrenõs internet protection act that schools and librariesreceiving erate funding must adopt and implement an internet safety policy.macy. for example, one community may be more concerned about theexposure of young people to sexually explicit material while anothermight worry more about the consequences of young people spendingtime in chat rooms. the development of an aup through extensive community involvementñincluding those affectedñcan sometimes be painful, but the process offers the community a chance to consider the balanceyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.238youth, pornography, and the internetit wants to try to strike between entirely unregulated internet access andmorerestricted use. such discourse can prevent future tensions amongcommunity members (e.g., students, teachers, parents, library patrons) byallowing difficult and potentially contentious issues to be resolved. notealso that the contents of an aup are likely to need updating as the concerns of the community evolve. thus, some mechanism for periodic review is an essential aspect of aup formulation.in addition, how an aup is presented to the community can affect itssuccess. if it is presented in the absence of explanation or context, neitherstudents nor parents are likely to understand its rationale for being. thus,contextsetting activitiesñsuch as parents being given some instructionon using the internet (e.g., section 10.4)ñmight well accompany the introduction of an aup to the community.while increasingly common, aups do raise a number of issues.¥to what extent, if at all, should an aup for a young person set theexpectations for adult behavior and use? an argument for similarity isthat an aup gains in legitimacy (with all of the desirable consequencesfor behavioral adherence) when it is seen to be uniformly applied. anargument for difference is that the legitimate needs of adult supervisors(parents, librarians, teachers, and so on) are different in some ways fromthose of childrenñwhile harassment may never be appropriate for anyone to engage in, adults may need access to a different set of informationon web sites than do children.¥aups that do not differentiate between the needs of younger andolder children are likely to be overconstraining or underconstraining toone group or another. for example, older adolescents may need access toa different set of information on web sites than primary school childrendo. an aup that imposes on these older children restrictions that aredesigned for younger children does not provide a realistic code of behavior for these older children.¥an aup states behavioral goals. but after policy statements havebeen distributed and signatures on aup forms gathered, a key questionremainsñto what extent are students and library patrons in fact complying with a given aup? some estimate of compliance can be derived fromdata about violations, a point that suggests that such data must be keptand tabulated if a broad understanding of an aupõs effectiveness is to beachieved. but walkby monitoring may be of limited effectiveness simplybecause the personnel are not available in sufficient numbers to checkusage regularly, and children themselves may not be entirely forthcoming if they violate the policy deliberately. (in this regard, the problemraised by aups is similar to those raised by any honor code.) however,technical tools for monitoring web usage in the aggregate (without indiyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.239social and educational strategiesvidual tracking of users) can provide important information on conformance to an aup. this point is discussed further in chapter 12.¥many users of aups are drawn to them because they provide abroad òcatchalló for behavior that may be objectionable but not explicitlylisted as inappropriate. for example, the prohibitions on viewing sexually explicit adult web sites complement the restrictions imposed by filters that block many but not all such sites. thus, a student who takesadvantage of underblocking in a filter to reach a sexually explicit adultweb site is still subject to sanctions for violating the aup. of course, thelogical complement to this argument is that a student who gets intotrouble for violating an aup may well argue, òif it was against policy,why wasnõt it filtered?ó a student who does not understand the limitations of technology may therefore feel that he or she has been treatedunjustly for violating an aup.¥more generally, aups must clearly specify what material or behavior counts as inappropriate if they are to be useful as guides to behavior. actions taken to penalize inappropriate behavior or access to inappropriate materials may well be subject to legal challenge in the absenceof clear specifications.¥to what extent, if any, does the existence of an aup shield a schoolor library from liability? to the committeeõs knowledge, there is not abody of case law that establishes the existence and use of aups as part ofa defense against liability for improper use of school or library computerfacilities. however, in the case law of discrimination and harassment, thecourts have established13 that the existence of internal policies or practicesis an important element of an affirmative defense against such allegations,14 and the logic of this case law might carry over to the use of aups.¥aups define responsibilities that users have. a complementaryissue is the nature and scope of rights that users have. in particular, aquestion arises regarding the extent to which an individual has rights toobtain information that go beyond what a parent might be willing togrant. what kinds of information, if any, would be in this category?many librarians and others acting in a supervisory but nonparental rolewould argue that it is important for a children (especially older adolescents) to have access to some such information. some examples offeredby these individuals include information about other races and cultures,13faragher v. city of boca raton, 524 u.s. 775 (1998).14lauren b. edelman, christopher uggen, and howard s. erlanger. 1999. òthe endogeneity of legal regulation: grievance procedures as rational myth,ó american journal of sociology 105(2): 406454.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.240youth, pornography, and the internetother religions, evolution, contraception, homosexuality, guns, and prevention of sexually transmitted diseases.15the childrenõs internet protection act (discussed in chapter 4) requires that many schools and libraries develop an òinternet safety planóthat addresses òaccess by minors to inappropriate matter on the internetand world wide web; safety and security of minors when using electronic mail, chat rooms, and other forms of direct electronic communications; unauthorized online access by minors, including ôhackingõ and otherunlawful activities; unauthorized disclosure, use, and dissemination ofpersonal information regarding minors; and measures designed to restrict minorsõ access to materials harmful to minors.ó16 note the strongsimilarity between the mandated internet safety plan and what is coveredin most aups.10.7afterthefact strategiesit is highly likely that children will, from time to time, encounterinappropriate sexually explicit material. thus, it is reasonable to considerwhat a child might do after such exposure in order to minimize whateverdeleterious effects, if any, might occur.perhaps the most important point for adults to keep in mind is thatmany children may be better able to handle exposure to inappropriatematerial than adults give them credit for. as noted in chapter 5, most ofthe older teenagers with whom the committee spoke reported that todaymuch of the sexually explicit material they encountered online was not abig deal to them. even younger teenagersñin particular the teen cyberangels17 who testified to the committeeñseem to have been exposed tosuch material without apparent harm.nevertheless, parents and other adults do have a responsibility tohelp children cope with inadvertent exposure to inappropriate internetmaterial or experiences. one obvious strategy is for a child so exposed, if15in practice, it would be quite difficult for a parent to make an individual decision aboutevery accessible web page of information or every book in a library to which a child hasaccess. but the notion does underlie an important thought question: assuming that thisarray of decisions could be encoded on a smart library card, so that the child could neverhave access to information to which a parent objected, how would parents, librarians, andteachers wish to proceed?16p.l. 106554, ¤ 1(a)(4), 114 stat. 2763 (2001). a good summary of the provisions of thecipa can be found online at <http://www.cybertelecom.org/cda/cipatext.htm#1712>.17these teenagers were members of teenangels, a group of specially trained 13 to 17yearold volunteers for the cyberangels online safety organization (see <http://www.cyberangels.com>).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.241social and educational strategieshe or she is upset, to seek assistance from an adultñparent, teacher, andso on. however, for the child to be willing to seek assistance, the adultmust not penalize him or her for doing so. recall that many teens reported to the committee that they had been upset in their first accidentalencounters with sexually explicit material on the internet not because ofthe scenes depicted, but because of their concerns about parental (over)reactions. schools, too, have been known to overreact, and it should benoted that children talk to parents and other adults more freely if conversation can occur in an open and accepting rather than in a punitive orjudgmental environment. thus, such encounters should be regarded asteachable moments in which the child can learn from the adults aroundhim or her.a second strategy is to seek help independently, though knowinghow to obtain help is sometimes difficult. for example, some isps provide methods for reporting of spam email, whether they involve inappropriate sexually explicit material or other kinds of material, harassinginstant messages (ims), email, or offensive chat room dialog. however,one would be well advised to understand the mechanics of how to gethelp before one encounters a problem.a third empowering strategy is to provide the child with instructionon how to report the offensive material to an appropriate party. forexample, if offensive material is passed by a filter, it might reduce thechildõs feeling of being victimized if he or she could report it to the partiesdetermining the filtering policy. in the context of schools, a student whois inadvertently exposed must have a clear and safe path for reportingsuch an incident. by doing so, he or she can avoid allegations of intentional access as well as help the school better understand how such accidental access occurred and how it might be better prevented in the future.another dimension of afterthefact strategies involves the possibilitythat a young person is being ògroomedó by a predator. parents should beaware that such engagements can happen in spite of their admonitions totheir children to avoid strangers. thus, it is particularly important tomaintain open channels of communication in which a child can shareexperiences and feelings about being online. note also that a youngperson may feel guilty about turning on an online friend.18 also, in somecases, a teenager may well tell a peer about intentions to meet with someone that he or she has met online. thus, peers and older teens can oftenplay a role in helping their friends and siblingsñby trying to talk themout of going to a meeting or alerting an adult.18in this context, the term òturning on joeó means reporting to responsible authority thatjoe wants to meet, even if joe has told the child not to tell anyone.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.242youth, pornography, and the internetnote that afterthefact strategies are consistent with the discussion insection 12.4 about instant help.10.8education10.8.1internet safety educationin the physical world, safety education for children involves thingssuch as teaching children how to cross the street safely, how to deal withstrangers approaching them, and how to react when there is a fire in thehouse. such strategies are taught to children so that they will be betterable to avoid situations in which they might be harmed, and to deal withthese situations better if they should find themselves in one.safety education for children on the internet has similar goals. whilemany students to whom the committee spoke said that they learned to besafe on the internet through experience, explicit internet safety education(ise) provides children with dos and donõts that decrease the likelihoodthat they will have an unsafe experience online. it also provides strategiesfor children who do happen to encounter unsafe situations.19 ise is anapplication and extension of the critical thinking and judgment skills thatparents and teachers and communities hope to instill in children to copewith other dangers in life. further, it requires awareness of the dangersso that they will not be surprised when they encounter them. threeexamples of ise include the following:¥for young people who might encounter a stranger online, it ishelpful for them to know about how sexual predators and hate grouprecruiters typically operate. in particular, they obtain as much personalinformation as possible and then, armed with such information, providecompliments, positive statements, and other flattery in order to build anemotional bond with their target. an example might be that if the youngperson says that he does not have many friends, the stranger might sayòthat is hard to believe,ó or òyour peers are really missing out, but you areprobably too mature for them,ó and so on. young people, often taught tobe polite to others, should understand explicitly how such a òseductionóprocess works, what to expect, how to recognize it, and how to deal withthe situation, and may need to be taught how to be assertive online inending contact with another user or declining and/or blocking instantmessages from users who harass them.19for purposes of this discussion, òunsafeó is construed broadly. that is, an unsafeinternet experience is defined here as one that makes the child feel uncomfortable, or onethat an adult would feel was inappropriate and potentially harmful for the child.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.243social and educational strategies¥recognizing an impending access to inappropriate materialñespecially material of an adult natureñis a helpful skill as well. for example, while most experienced web surfers know how to use the fewlines of text accompanying a link that is returned by a search engine,novice surfers do not. for these individuals, identifying some of the keywords that flag sexually explicit adultoriented material and how they aredisplayed in a search engineõs òreturned linksó may be helpful. similarstrategies are likely to be useful when processing unsolicited email thatseeks to draw attention to adultoriented web sites.¥knowledge of when it is appropriate to provide personal information online is increasingly important. imparting such knowledge involvesteaching children about what information is private as well as their rightand responsibility to protect that kind of private information from others.for example, if one is doing registration online for classes at oneõs school,it is perfectly appropriate to provide personal information such as name,address, and the like. but for a teenager to provide such information to astranger in a chat room is far less wise, and children of all ages would bewell advised to refrain from giving out such information without explicitparental permission.¥knowledge of how one might recognize unsolicited commercialemail (spam) without opening it would enable children and youth todelete much of it and thereby reduce their potential exposure to inappropriate material.20 knowledge of how to behave on the internet so as toreduce vulnerability to spam would reduce the volume entering theirmailboxes.note that the introduction of any particular lesson in ise should betied to a sense of the childõs developmental level. for example, being ableto identify impending access to inappropriate material is a helpful skillwhen a child starts to use the internet without active and continuousadult parental supervision. but whether this skill is helpful or should beintroduced prior to this point is less clear.20for example, one can often identify spam on the basis of the subject line and the purported sender of the mail. (an email from hotsexybabe@example.com with the subject lineòbest porn on the netó is highly likely to be spam containing links to adultoriented, sexually explicit material.) such email can be easily deleted without being read, and an informed user who chooses to read the email is reading sexually explicit material more orless voluntarily. on the other hand, some spam senders anticipate such behavior on thepart of the user by forging sender addresses (the mail appears to be from support@example.com and use misleading subject lines (e.g., òabout your email programó). spam from suchparties cannot be identified as sexually explicit in nature, and a user who reads such mailwill be exposed to its content involuntarily.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.244youth, pornography, and the internetin some ways, nonschool programs are well suited for ise (box 10.6provides one example). for example, a number of girl scout merit badgesrelated to computers and the internet could easily and naturally accommodate a requirement for internet safety. afterschool or summer programs, in which computer usage is likely to be less structured (and thushave more potential for students getting into internet trouble), are a goodvenue in which to learn and exercise ise skills in a supervised environment. religious education programs, which already deal with ethics, caninclude some internet safety instruction as well.as discussed in section 7.1, parents are often far less knowledgeableabout technology than are their children. similarly, teachersñespeciallythose at the high school levelñoften know less about the internet thantheir students.21 because many elements of good ise depend on sometechnical knowledge (though framed in an appropriate context), effectiveise depends on these adults obtaining the necessary skills themselves.workshops for parents, preservice professional education in teachersõcolleges and library schools, and inservice programs for professionallyactive teachers and students all have a role in imparting such skills toadults.finally, a number of interactive games and programs seek to teachbox 10.6an example of a library offering for internet safety educationthe chicago public libraryõs home page for kids and teens is designed to be asafe portal to the web. in addition to childappropriate resources such as the teenedition, homework help, good reads and great books, and resources for parents,teachers, and youth librarians, it also contains an interactive quiz that poses onequestion at a time that can be answered with a yes or no button that calls up thecorrect response as well as feedback about the question. for example, the secondquestion in the quiz is, if i see stuff on the internet that makes me uncomfortableshould i keep it a secret? depending on your answer you get either a bouncing stargraphic if you answer correctly or a òdangeró sign if you answer incorrectly. bothanswers are accompanied by the following text: òif you are at home, tell your parentsright away if you come across any information that makes you feel uncomfortable. ifyou are at the public library, tell a librarian and then leave that page right away.ósource: see <www.chipublib.org/008subject/003cya/sign/sign.html>.21schofield and davidson, 2002, bringing the internet to school: lessons from an urban district.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.245social and educational strategieschildren internet safety and responsible web use. these include netsmartz,22 surfswell island,23 and missing.24see box 10.4 for some ideas on promoting internet safety education.10.8.2information and media literacyinformation literacy refers to a set of abilities that enables people toòrecognize when information is needed and have the ability to locate,evaluate, and use effectively the needed information.ó25 an informationliterate individual is able to determine the information needed, find theneeded information effectively and efficiently, evaluate the informationreceived, and assess its sources critically; incorporate selected information into his or her knowledge base; use information effectively to accomplish a specific purpose; understand the economic, legal, and social issuessurrounding the use of information; and access and use information ethically and legally.26media literacy, a newer term, expands on information literacy in twoprimary ways.27 first, media literacy extends to information presented inall forms of media, not just print. information literacy was never specifically restricted to print, but in practice it is often understood in that primary context. second, and more importantly, media literacy includes theability to produce and communicate information for the benefit of others.also, some analysts believe that media education is focused on information conveyed by and through the mass media, such as newspapers, tele22see <http://www.netsmartz.org>. netsmartz was developed by the ncmec.23 see <http://disney.go.com/family/surfswell2001/index.html>. surfswell island wasdeveloped by the disney corporation.24see <http://www.livewwwires.com/index2.htm>. missing was developed by livewwwires, a canadian organization that seeks to promote internet safety among youth.25american library association. 1989. presidential committee on information literacy. finalreport. american library association, chicago. available online at <http://www.ala.org/acrl/nili/ilit1st.html>.26this set of abilities is taken with a few modifications from <http://www.ala.org/acrl/ilintro.html#ildef>.27more information on media literacy can be found from the following sources, fromwhich parts of the discussion in this paragraph are derived:¥<http://www.ci.appstate.edu/programs/edmedia/medialit/article.html#what ismedia literacy>.¥<http://interact.uoregon.edu/medialit/fa/mlarticlefolder/defharvard.html>.¥<http://interact.uoregon.edu/medialit/fa/mlarticlefolder/defresponse.html>.¥david considine. 1994. telemedium: the journal for media literacy 41(2) (strategiesfor media literacy inc. and the national telemedia council, madison, wisc.).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.246youth, pornography, and the internetvision programs, and the like.28 others add to the definition an understanding of the role that audiences play in creating meaning from theinformation found in media content.29the need for information and media literacy was raised by most ofthe teachers and librarians with whom the committee spoke. in general,they saw young peopleñtheir studentsñas being far too uncritical intheir acceptance of information found on the internet, and they felt that itis important for students to develop the skills usually associated withinformation and media literacyñespecially with respect to skills relatedto critical evaluation.30in some cases, they regarded the harm that could come to studentsfrom uncritical acceptance of information on the internet as much moredetrimental than anything they might see in the way of sexually explicitimagesñhate and racist sites (e.g., featuring holocaust denial) and sitespromoting cults were often mentioned. (of course, all of these teacherswere working in a filtered internet environment, and this assessmentmight have been different if filters had not been present.) informationand media literacy offers a set of cognitive skills that can protect againstmisleading information or a disturbing image by teaching young peoplehow to recognize underlying messages, criticize them, and develop productive counternarratives.skills related to the critical evaluation of information are not explicitly related to reducing the exposure of youth to inappropriate sexuallyexplicit material on the internet. after all, if the concern is that youngpeople are viewing graphic sexual images, one does not need particularlysharp skills to determine if a picture is truly sexually explicit. by contrast, it is often necessary to pay close attention to the content of otherkinds of web sites in order to determine the meaning of the informationcontained therein. (thus, it is often easier to make a determination thatsomething may be sexually explicit, compared to a determination that it isinappropriate in some other wayñsexual images can be identified at aglance, whereas racist or hate text must be read.)28barry duncan et al. 1989. media literacy resource guide. ontario ministry of education,toronto, ontario, canada.29rick shepherd. 1993. òwhy teach media literacy,ó teach magazine, oct./nov. (quadrant educational media services).30whether these teachers and librarians actually spent the time in class to teach information and media literacy in anything but the most cursory fashion is a different matter.indeed, many teachers ignore such matters because they are not seen as part of the discipline they are teaching. nevertheless, the comments of these teachers and librarians indicated at least an awareness of the need for information and media literacy.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.247social and educational strategiesthough the skills of critical evaluation tend to be more useful inhelping youth to deal with other types of material that may be inappropriate, once an exposure to sexually explicit images has occurred, criticalevaluation is still relevant. for example, the sexually explicit imagesfound on adultoriented web sites generally do not provide òsafer sexómessages. a good understanding of the role that sexual imagery plays inmodern media could provide occasion for useful reflection. critical evaluation thus provides skills that youth can use to help deal constructivelywith exposure to inappropriate material.skills related to finding information are perhaps more relevant to thetask of reducing exposure to sexually explicit material. for example,performing an effective web searchñthat is, one that retrieves relevantinformation and minimizes the amount of undesired informationñrequires the selection of the right set of keywords, familiarity with booleanlogic, choosing the right search engine for the topic, and knowing how tonavigate through a browser so that it is easy to enter and exit web sites,databases, and other online resource tools. such skills can help to reducethe likelihood that a searcher might come across inappropriate materialinadvertently. for example, if a search engine returned a link to a website that the searcher had learned to recognize would likely contain adultoriented sexually explicit material rather than information on reproduction or sexually transmitted diseases, he or she could simply refrain fromaccessing that site.programs in media literacy generally focus on understanding mediamessages in context. that is, the òfaceó content of a media message isonly one aspect of it. a medialiterate individual understands how toevaluate the truthfulness and reliability of a media message, and alsoknows to ask about the motivations and intent of the party or partiesresponsible for distributing that message. (some such literacy is provided in consumer education programs and materials, such as those provided by consumer reports.)the significance of such literacy in the context of evaluating contentfound on the world wide web is obvious, where a good deal of webcontent is not reliable or accurate by any standard. but media literacyalso has relevance to an adolescent who may be exposed to inappropriatesexually explicit materials, either deliberately or inadvertently. media literacy can help a young person ask questions such as:¥why are these pictures being shown to me?¥is what i am seeing a true and realistic image of what sex is like?¥why are other people drawn to these images?¥what important things are not being shown in these images?youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.248youth, pornography, and the internet¥what are the circumstances that led the individuals being depictedinto their being photographed?¥could an adult help me better understand what iõm seeing?in short, media literacy can help to promote a more detached, moreevaluative, and more reflective view of media, messages, and oneõs ownself. by doing so, it may well strengthen impulse control and empathy,and help lead one to question oneõs own behaviorñand is likely to reducethe exposure resulting from impulsive behavior.information and media literacy also addresses the responsible placement of information on the internet, for example on web sites and in email. thus, the creation of information must be undertaken in a responsible manner that communicates what the creator intends. responsibilitymight, for example, include the notion that the posting of composite photographs (e.g., face of a classmate pasted onto a naked body withoutpermission) constitutes unethical and inappropriate behavior. repeatedemails to a party (e.g., one person asking another for a date) can beregarded as harassment if the subject of the emails has requested a cessation of such emails.the research base for understanding the effectiveness of informationand media literacy training and education is thin, but two experimentalstudies provide evidence that suggests beneficial effects in the short run.one study provided some information and media literacy instruction toelementary school children viewing violent cartoons.31 this instructionasked them to think about the feelings of the victim of violence throughout the episodeñand those who received such instruction did not experience a desensitizing change in attitude toward violence nor did they findthe cartoon to be as funny as those not receiving such instruction. another study focused on girls in their early teens, instructing them in howto think critically about media messages regarding how women shouldthink about romance, love, and sexuality.32 they responded by criticizingthe media because they felt the media encouraged them to focus too muchon romance and trying to attract men. if such studies can be generalized,helping youth to understand how and why sexually explicit adultori31a.i. nathanson and j. cantor. 2000. òreducing the aggressionpromoting effect ofviolent cartoons by increasing childrenõs fictional involvement with the victim,ó journalof broadcasting and electronic media 44: 125142.32sarah keller, òhow do early adolescent girls use media to shape their romanticidentities?ó unpublished doctoral dissertation, university of north carolina, chapel hill,2000. some of the results from this dissertation can be found in national research counciland institute of medicine, 2001, nontechnical strategies to reduce childrenõs exposure to inappropriate material on the internet: summary of a workshop.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.249social and educational strategiesented materials are produced and consumed may be of some assistance inhelping to òinoculateó these youth to some of the effects of such materials.as with much education, information and media literacy is likelypursued best in a oneonone context. by talking to a student searchingfor information on a particular topic, adults can teach him or her effectivesearch strategies for such information. once a number of sources arefound, talking to the student about how to evaluate those sources canhelp to develop critical thinking skills. of course, oneonone interactionis also laborintensive, and a oneonone format is less feasible in situations in which many students must be served. in such situations, groupand inclass instruction can also be helpful.for application in a mass education environment, a variety of schoolshave adopted educational standards that address certain information andmedia literacy skills. for example, the state of wisconsin has adoptedlearning standards that call for fourth graders to be able to use web sitesthat have been preselected and bookmarked by the teacher, eighth graders to know effective search strategies, and twelfth graders to be able toevaluate internet content for validity and reliability as well as to assessthe search engines for effectiveness and the way in which they returninformation.3310.8.3collateral issuesinternet safety education and information and media literacy can beregarded as elements of a comprehensive approach to education in whichthe use of technology is fully integrated with pedagogical goals. although a full discussion of education that is well integrated with technology is beyond the scope of this report, the following points are worthconsideration:¥internet safety is only one dimension of productive and appropriate use of the internet. it is also a dimension of appropriate use thatyoung people learn not to use the internet for socially detrimental and/orillegal purposes. for example, harassment conducted online is no lessserious than harassment conducted offline. the use of a computer topenetrate another computer, even if that second computer has weak security, is analogous to walking into someone elseõs house without permission, even if the door is unlocked. in short, responsibility is also animportant dimension of oneõs internet use.33see <http://www.dpi.state.wi.us/dpi/standards/pdf/infotech.pdf>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.250youth, pornography, and the internet¥professional development for educators using the internet is important and must go beyond the mere mechanics of how to use a searchengine and how to send email. that is, educators must learn how theinternet can support pedagogical objectives as well as how to teach internet safety.34 both preservice and inservice teacher training is thuscalled for.¥ethical and legal behavior on the internet and in using technologyis a part of the technology education standards developed by the international society for technology in education for students, teachers, andadministrators.35 to the extent that technology education becomes animportant part of k12 education, issues related to ethical and legal behavior will have to be addressed.¥to integrate technology into schools, an adequate technology infrastructure is necessary. for a variety of reasons, todayõs informationtechnology is not well adapted to the needs of k12 education. developing a generation of information technology adapted for the special needsof schools is the focus of a national research council project in progressas this book goes to press.3610.9compelling and safe contentin various site visits, teachers reported to the committee that their mosteffective strategy for dissuading students from engaging in inappropriateactivities on the internet was to keep students òon taskóñfocused on activities relevant to the educational task at hand. often, teachers prepared for aclass by compiling a list of helpful web sites appropriate for that class.such a list, combined with restrictions on the amount of time students wereallowed to use school internet facilities, resulted in òstudents not havingtime to get into trouble,ó according to these teachers.a generalization of this strategy would call for the creation of internetcontent that is compelling and educational for young people, so compelling that they are less inclined to spend their time searching for inappropriate material or engaging in inappropriate or unsafe activities. materialthat is productive, stimulating, and developmentally beneficial could include more web sites devoted to sexual health and education so that34for example, the cybersmart! program is a professionally developed curriculum for k8 students and supports teachers in educational efforts to introduce responsible and effective internet use. for more information see <http://www.cybersmartcurriculum.org>.35see <http://www.iste.org>.36see <http://www7.nationalacademies.org/ilit/> for information on the nrc projecton improving learning with information technology.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.251social and educational strategies37sandra calvert et al. 2001. òchildrenõs online reports about educational and informational television programs,ó journal of applied developmental psychology 22(1): 103117.curious adolescents could obtain reliable information on sexuality ratherthan, or at least before, finding sexually explicit material that lacks information or that depicts unprotected sex or other unsafe sexual practices.an analogy can be drawn to the development of highquality television programming for children. an example of commercially supportedprogramming in this domain is nickjr, a component of the nickelodeonnetworkõs programming. nickjr is supported by advertising revenuesand is popular among its target audience,37 suggesting that highqualitytelevision programs can be of interest and of educational value to somechildren, that associated web sites that support these messages may beequally valuable for their development, and that this kind of programming can be viable in the commercial marketplace. note also that thenickjr web site also has quality software, derived from its tv programming, that is oriented toward preschoolaged children.on the other hand, commercial sources of content depend on a financial base that relies almost exclusively on ratings, which implies that theircontent must be oriented toward mass markets (for example, their contentis more commonly òactionorientedó with more violent material that moreeasily draws an audience, and cannot economically be tailored to nichemarkets). further, because the production and airing of commercial material are often subsidized by getting children to buy products, it is generally less expensive to develop childoriented commercial material; children also like a flow back and forth between television and online content,giving commercial content a further appeal. major commercial sourceshave the resources to experiment with different approaches to their onlineofferings, an important characteristic in a new environment in which successful formulas for engaging children with healthy web content arelargely unknown. from their physicalworld presence, they also havebrand recognition (e.g., disney, nickelodeon, and sesame street) thatenables many parents to trust the content they provide.because noncommercial sources do not rely on mass markets forfinancial viability, they can execute more readily on their mandate toeducate. for example, the content of noncommercial programming canbe tailored more finely to smaller ageappropriate ranges, or to topics andapproaches that are more highly specialized. while noncommercial programming does not in general have the mass market appeal of muchcommercial programming, the availability of noncommercial programming would tap into the needs of a number of smaller markets, potentially meeting demand that is not manifested in a commercial environyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.252youth, pornography, and the internetment. the committee also believes that the presence of noncommercialsources such as pbs changes the environment for commercial providersby creating greater incentives for commercial providers to do more interesting and creative programming and raising the standard of quality.(this change in the environment is at least as important as the qualityprogramming for which it is directly responsible.) box 10.7 describessome possible noncommercial content developers.in the internet arena, yahooligans is a yahoosponsored òkids areaówith sections on sports, news, jokes, games, chat, bulletin board postings,and online specialinterest clubs. it also provides resources for education(oriented toward school work), sports, computers, and entertainment, aswell as information for parents, teachers, and children for internet safety.the theory is that young people would choose to go to these sites andportals voluntarily, which in turn would keep them away from adultmaterial.the approach of creating content that specifically appeals to childrenhas a number of benefits. one major appeal is that the evaluation ofeducational web sites is more feasible than trying to evaluate online content as a whole. because the volume of material to be evaluated is so muchsmaller, considerable effort (hours rather than seconds) can be expendedbox 10.7potential noncommercial developers of content for children and youth¥childrenõs museums and science centers: information and contentorientedweb sites are often part of their outreach services.¥nonprofit educationally related groups such as the jason foundation andglobal school network.¥government agencies: a number of agencies have sites or web pages that areoriented toward children. examples include the federal resources for educationalexcellence (<http://www.ed.gov/free>) and nasa (<http://www.nasa.gov/kids. html>).¥universities have a mission to disseminate information to the general public.finally, corporate support can be noncommercial in nature as well. for example, mci/worldcom supports an effort known as the marcopolo project (<http://marcopolo.worldcom.com/>). the materials found on the site are not tied to childoriented products and hence do not seek to entice children to acquire dolls or playing cards or other toys. blue webõn (<http://www.kn.pacbell.com/wired/bluewebn/index.html>) is supported as a public service by pac bell and consists of a searchabledatabase of about 1,000 outstanding internet learning sites categorized by subjectarea, audience, and type (lessons, activities, projects, resources, references, andtools). other firms, such as scholastic inc. and classroom connect, offer some freeeducational content as a leadin to other products and services available for a fee.education world, an educational publication, offers a portal with access to educational content; this site is supported by advertising, but the advertising is directedtoward adults rather than children.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.253social and educational strategiesto produce an evaluation that is thorough, rigorous, feasible, and cangrapple with the extent to which a site is developmentally appropriate,relevant to young peopleõs needs and interests, and userfriendly.38 inaddition, the availability of good web sites that attract the attention andinterest of young people relieves to some extent the burden on parents toprovide direction. these educational web sites could also include information on online safety as well as other educational content.good content can also draw on a scientific understanding of the developmental needs and milestones of children in cognitive, social, emotional, and moral dimensions. for example, based on such research,schools in wisconsin have developed internetrelated educational objectives that students must meet by the end of certain years and that teachskills such as effective searching and how to evaluate online content fortruthfulness and validity.it appears to be quite difficult, however, to find business models thatcan independently support the development of such content for the internet. one of the ironies of the internet is that adult entertainment is one ofthe very few businesses that have been able to make a profit on the internet, while markets for highquality internet content for children languish.experience in the wake of the dotcom meltdown illustrates that buildingany internetbased business is difficult, but it appears to be especiallydifficult to create good offerings for children. some of the key challengesinclude:¥limited bandwidth. even at broadband speeds, most children findcontent coming over the internet frustrating. (adults do as well.) videoor animation, especially over a dialup connection, can be quite jerky,making it virtually unwatchable by many children. furthermore, othermedia such as tv, video games, and pcbased software offer content thattends to be much more watchable, and the instant response that theseother media offer places internet content at a significant disadvantage.content can be designed to work well over the internet. nevertheless, itis likely that content creators will be making creative sacrifices in order to38in the committeeõs december 2000 workshop, sarah keller described the evaluationprocess of the asha web site, <www.iwannaknow.org>, a project in which she is currently involved. this process began with a content analysis that compares the informationavailable on the site to the recommendations established by the sexual information andeducation council, siecus, a recognized authority on sex education. the analysis wasused to create an online survey to measure the siteõs impact on teen knowledge, attitudes,and intended behaviors. the site was evaluated using the american library associationõsrecommendations on navigability, accuracy, authority, currency, and objectivity (see<www.ala.org/internettoolkit>).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.254youth, pornography, and the internetobtain viewabilityñplacing such content at a disadvantage with respectto content carried in other media.¥privacy concerns. online businesses that are directed at childrenmust comply with a variety of regulations emanating from the childrenõsonline privacy protection act (coppa). while such regulations havebenefits, coppa has also imposed costs on such businesses that they didnot previously incur,39 and it is likely that the added costs of complyingwith coppa have increased the operating burden felt by some developers of material for younger children and resulted in a smaller volume ofsuch material.¥safety concerns. the newness of the internet and the media publicity regarding untoward internet experiences (e.g., abductions resultingfrom internetenabled interactions) have made many parents fearful ofallowing their younger children on the internet.¥financing. even in the highflying days of venture capital, it washard to develop plausible business models for how an internet serviceoriented toward children would eventually be profitable. advertisers areoften uninterested in targeting children online, and web sites that offertraffic that consists mostly of children are not in high demand.finally, creating compelling and safe content de novo is not the onlyway to assemble collections of such material. portals and web sites thatlead to developmentally appropriate, educational, and enjoyable materialon a broad range of appealing topics (not just sex and sex education)would help to keep young people away from inappropriate sexually explicit material (as well as other types of inappropriate material) by providing a venue that children preferred. lists of appropriate web sitessuitable for classroom or inhome use are a òpoormanõsó analog to thesekinds of portalñteachers and/or parents can create lists of interestingand appropriate web sites for easy browser access by bookmarking them,and even a list of such sites on paper would be helpful in many circumstances. also, school districts and libraries are creating portals to educationally oriented web sites to help students do their work.10.10public service announcementsand media campaignsbecause many adults do not know much about the need for internetsafety, or about the nature and extent of dangers on the internet, they39for example, coppa requires a parent to send a note through the postal service or tofax a form to document parental permission for answering questions that ask for personalinformation, both of which are timeconsuming, inefficient, and costly to process.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.255social and educational strategiesoften do not know what they do not know. thus, they can be complacentand do nothing about protecting their children on the internet, or they canexaggerate the dangers, believing from media scare stories that òpornographyó and sexual predators on the internet are as ubiquitous as commercials on television or radio.by themselves, public service announcements (psas) and media campaigns cannot provide comprehensive education about complex topics.however, they are ideal for relatively simple messages. for example, thelate 1980s saw a major public awareness campaign offering the message,òitõs ten oõclock. do you know where your kids are?ó a similar campaigntoday for internet safety might offer a message like, òwhat did your kidsdo online today?,ó or òyou, too, can learn about protecting your kids onthe internet!ó or òwould you let a stranger in your childõs bedroom?ó toencourage the placement of computers in public parts of the home.since the mid 1990s, a number of concerned companies in the internetpublishing industry have sought to demonstrate their interest in educating the public at large about the dangers that the internet can present tochildren. these industrysponsored selfpolicing programs include americalinksup, which ran roughly from december 1997 to october 1998, andgetnetwise, which started in the spring of 1999 and still exists today.americalinksup was spawned by the internet online summit: focuson children held in washington, d.c., in december 1997. the conferenceconsisted of a day of clinton administration, congressional, and internetindustry leaders speaking to the importance of establishing a publicprivate partnership to protect the public interest and obviate the need forintroducing legislation to regulate the internet. one of the outcomes wasamericalinksup, which was funded primarily by several major mediacompanies, including aol, time warner, and the walt disney company, to demonstrate corporate commitment to raising public awarenessabout the importance of parents monitoring their childrenõs activities onthe web and of children being aware of the dangers that can be encountered when surfing the web. americalinksup created television andradio psa spots that were designed to target parents and children asseparate demographic groups. abc television network, abc radio network, turner broadcasting system, and lifetime television all providedair time pro bono during august and september of 1998 to broadcastthese psas. despite the fact that the psas were very emotionally evocative, americalinksup most likely had minimal impact due to the limitednature of any media campaign that has virtually no media budget.operated under the auspices of the nonprofit internet educationfoundation, getnetwise was in many ways the successor to americalinksup, and is supported by a wide range of internetrelated corporations and public service organizations. getnetwise had a larger agendathan simply promulgating childrenõs safety on the internet; it extended toyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.256youth, pornography, and the internet40thomas e. backer and everett m. rogers, eds. 1993. organizational aspects of healthcommunication campaigns: what works?, sage, newbury park, calif.promoting how families could enjoy the internet together, as well. getnetwise launched a major web site designed to be the focal point on theweb for all internet public interest information. getnetwise.org still is inoperation today, although the initial publicity campaign surrounding itslaunch in mid1999 has diminished, as has awareness of the initiative.overall, despite the significant amount of energy and resources expended to produce the psas for americalinksup and to launch the website and public relations campaign for getnetwise, there is little evidencethat either of these industry initiatives has had a major impact on diminishing the safety problems presented by the internet for children. if anyconclusion can be drawn from the programs, it is that, while they do offervalue (although that is difficult to measure) by raising peopleõs awareness, it is difficult to sustain interest among industry participants overany extended period of time. for such campaigns to be most effective,companies must believe it is in their commercial interest to finance them(i.e., there must be a threat of some harm, such as potential governmentalregulation or loss of revenues, or some promise of benefit, such as greaterpublic awareness of their concerns for the welfare of children). to trulymake a difference, public awareness campaigns must be funded on anongoing basis and be part of a multifaceted umbrella program that makesinternet safety the responsibility of all key stakeholders in promotingchildrenõs safety on the internet.another possibility is that strategies, along the lines of current campaigns to discourage drug and tobacco use among children, could bedesigned to discourage children from seeking out sexually explicit materials. such strategies are likely to be controversial, in the sense that theywould call public attention to sexually explicit materials. moreover, mostof the literature suggests that health communication campaigns, such asantismoking and antidrug media campaigns, are least effective whenthey are not conducted in concert and coordination with appropriate communitybased supports.4010.11findings and observations about socialand educational strategies1.social and educational strategies directly address the nurturing ofcharacter and the development of responsible choice. because such strategies locate control in the hands of the youth targeted, children may makeyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.257social and educational strategiesmistakes as they learn to internalize the object of these lessons. but explaining why certain actions were mistaken will help children to learn thelessons that parents and other adults hope that they will learn.2.though education is difficult and timeconsuming, many aspectsof internet safety education have been successful in the past several years.while it is true that internet safety education, acceptable use policies, andeven parental guidance and counseling are unlikely to change the desireof many adolescent boys to seek out sexually explicit materials, parentsare more aware of some of the other dangers (such as meeting strangersfacetoface) and know more about how to protect their kids then everbefore. (this is true even though more needs to be done in this area.)children are better educated about how to sense whether the person onthe other end of an instant message is òfor real.ó many of them havedeveloped strategies for coping, and children with such strategies increasingly understand the rules of the game better than many parents.little of this was true 5 years ago.3.social and educational strategies are generally not inexpensive,and they require tending and implementation. adults must be taught toteach children how to make good choices in this area. they must bewilling to engage in sometimesdifficult conversations. and, social andeducational strategies do not provide a quick fix with a high degree ofimmediate protection. nevertheless, they are the only approach throughwhich ethics of responsible behavior can be cultivated and ways of coping with inappropriate material and experiences taught.4.social and educational strategies have relevance and applicabilityfar beyond the limited question of òprotecting kids from porn on theinternet.ó for example, social and educational strategies are relevant toteaching children to:¥think critically about all kinds of media messages, including thoseassociated with hate, racism, senseless violence, and so on;¥conduct effective internet searches for information and navigatewith confidence;¥evaluate the credibility and motivation of the sources of the messages that they receive;¥better recognize dangerous situations on the internet;¥make ethical and responsible choices about internet behaviorñand about noninternet behavior as well; and¥cope better with exposure to upsetting and disturbing experiencesand material found on the internet.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.258there are a number of tools for protecting children from inappropriate internet material and experiences. most common are filters that attempt to block certain types of content, but tools for monitoring usage,verifying age, and protecting intellectual property fall into this domain aswell. while each of these tools offers some degree of protection, there aremany factors that enter into choices about what technology, or technologies, should be used, or whether technology is appropriate at all.11.1technologybased toolsas in many other areas of life, the internet is an arena in which manyadults (mostly parents) attempt to stay aware of their childrenõs activitiesand some young people, particularly adolescents, attempt to evade parental oversight. technologybased tools for protecting children fromexposure to inappropriate internet material and experiences promiseòhardó security against unknown threats and offer to compensate forparental lack of knowledge about how to understand and control theinternet usage of their children. because they appear to promise suchsecurity, it is easy to believe that all that must be done is to install thetechnology and then one can forget about the problem.to be fair, technology vendors rarely make such claims explicitly.but the rhetoric of public discourse about technology solutions to òtheproblemó most definitely has such a tone. indeed, the advocacy of technologybased solutions has much of the same tone as commercials in11a perspective ontechnologybased toolsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.259a perspective on technologybased toolswhich cereal is seen to be òpart of a balanced breakfast,ó a qualification ofapproximately 1 second in a 30second commercial extolling the virtuesand pleasures of the cereal.moreover, technology that helps to create a problem and technologythat helps to solve it are another instance of the familiar measure/countermeasure game. in banks, better safes inspire bank robbers to developbetter methods for cracking safes, which in turn inspire still better safes.when safes become too hard to crack, bank robbers can turn to hightechfraud as a way of draining money from banks, starting the cycle all overagain in a different domain. this implies that no technological solution isdurable.the desire for simple, inexpensive, decisive technologybased solutions is understandable. but as noted in chapters 8 and 10, a stronginfrastructure of social and educational strategies that help children develop an internal sense of appropriate behavior and response is foundational for childrenõs safety on the internet. technologybased tools canserve useful roles in much the same way that òtraining wheelsó have auseful role in teaching children to ride bicycles. in addition, technologycan strengthen the positive effects of good parenting, and serve as abackup for those instances in which parents are temporarily inattentive(as all parents are from time to time).for purposes of this report, tools are defined as information technology devices or software that can help to reduce the exposure of childrento inappropriate material and experiences on the internet. these devicesor software can be installed in any one of a number of locations. materialon the internet originates at a òsource.ó it is then transmitted through avariety of intermediate points and is finally displayed on the userõs screen.inappropriate material can be identified at any point before the materialappears on the userõs screenñallowing some appropriate action to betaken at any of these points. box 11.1. describes in greater detail some ofthe points of content identification and control.it is also worth noting that there are technological and business pressuresthat are likely to ameliorate the problem. these include the following:¥the development of most industries follows a pattern of innovation, copycat, and then shakeout. the wide proliferation of adult websites suggests that the industry is in its copycat phase. if the industrycontinues on the traditional trajectory, shakeout in the industry is likely tooccur in the future. if so, the remaining players are likely to demonstratemore corporate responsibility in differentiating children from adults ingiving access to their products and services, although noncommercialsources of sexually explicit material are likely to be unaffected by thistrend.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.260youth, pornography, and the internet¥decentralization of the internet (discussed in section 2.1.2) is anenabler for a variety of technologybased tools that can be deployed byend users (e.g., individual families, schools, and libraries) to increase therange of options available to help parents and other responsible adultsfulfill their responsibilities.¥some technological developments, such as the trend away fromopen chat rooms to closed instant message rings, will make it more difficult for spammers and molesters to find individual victims.¥as todayõs children become parents, the generational divide intechnical knowledge and sophistication may begin to close.these comments should not in any sense be taken to mean that technologybased tools themselves are useless or unnecessary, and the remainder of this chapter, as well as chapters 12 and 13, describe how suchtools might be useful. nevertheless, the statements immediately aboveare collectively a message that not all technology or business trends bodeill with respect to the exposure of children and youth to inappropriatesexually explicit material and experiences on the internet.box 11.1points of content identification and control¥source or creator. note the different levels of socially responsible behaviorpossible on the part of content creators, publisher, and providers.ñproduces content and labels it accuratelyñproduces contentñproduces content and puts entries in search engine databases that would appeal to childrenñproduces content and labels it inaccuratelyñsends to email inbox of childrenõs accountsñengages in mousetrapping¥recipientñrecipient (including the recipientõs judgment)ñrecipientõs adult alliesñrecipientõs young allies¥intermediaries (e.g., transporter, host, archive)¥other potential points of interventionñdevice manufacturerñdevice òinstalleró or òconfigureróñdistributor or publisherñsearch engine onlyñinternet service provider onlyñbrowser onlyyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.261a perspective on technologybased tools11.2contextual issues for technologybased toolsall tools to protect someone from inappropriate content require judgments about what content should be deemed inappropriate. while alldecisions about what is inappropriate are derived from human judgments,the decision regarding any given content can be made by a computerprogram that seeks to mimic these human judgments (and examines thecontent itself as it is coming into the computer) or by people who examinethat specific content, generally in advance (and sometimes far in advance)of an actual attempt to access this content.not all tools, or even a given type of tool, are equally adept at identifying all kinds of inappropriate material. for example, for reasons described in chapter 2, the identification of certain types of inappropriatesexually explicit materialñe.g., that which is found on adult web sitesñis considerably easier from a technical standpoint than the identificationof other types of sexually explicit material or other types of content thatmay be judged inappropriate (e.g., material on bomb making, hate speech,religious cults).chapters 12 and 13 address several generic categories of tools. butbefore turning to those tools, it is helpful to make a number of commentsthat apply across most technological options for protection.¥the party that decides that a given tool is appropriate is almostalways the party that must manage its use. management of a tool includes decisions about setting it up initially, maintaining it, and configuring it so that it does the appropriate things in the particular environment.it also entails decisions about the appropriate users (i.e., the children oryouth in question) and when and under what circumstances they aresubject to the restrictions imposed by the tool. further, the decisionmaking process for considering the use of a given tool must consider awide variety of factors that may include some emanating from externalsources (e.g., government).¥technology solutions are brittle, in the sense that when they fail,they tend to fail catastrophically. in general, the catastrophe is not thatthey suddenly allow the child to access all possible kinds of inappropriatematerial (though this can sometimes happen), but rather in the suddenviolation of expectation that the given technology would not fail. a childwho has not been educated about what to expect and how to deal withproblematic material found on the internet, but has been òprotectedó bytechnology alone, will not have the coping skills needed to deal with suchexposure.¥ease of use is a major factor in implementation of any technical tool.tools do not provide effective protection if they are so difficult to use thatyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.262youth, pornography, and the internetthey go unused, and the complexity of a toolõs setup and ongoing maintenance is a major factor in a toolõs suitability. as a general rule, the òdefaultósettings of a tool are the ones that are most often used. and, there is adistinct tradeoff between simplicity of use and customizability to a userõsspecific preferences. customization may, for example, require a user tospecify preferences in many different domainsñpartial frontal nudity isacceptable while full frontal nudity is not (except in images of classical art);violence is acceptable, while religious cults are not, and so on. but a user,faced with such choices, often tends to opt for the simplest solutionñwhichis likely to be ònot okó for all of the specified domains because of thedefaults built into the software by the vendor. further, the wide variety ofcomputing environments often forces vendors into requiring a òsetupó procedure to adapt the tool to the userõs particular hardware/software configuration. and, because of the constantly changing nature of the internet,the tools must constantly be updated in order to remain current and valid.this puts the onus on the user to acquire a fair degree of technical knowhow. unless this step can be made easy for the user, only the most skilledor dedicated users will bother to use such a tool.¥as a general rule, most technologybased tools can be circumvented with sufficient effort. furthermore, the history of informationtechnology suggests that a method of circumvention, once discovered, isoften proliferated widely.1 not everyone is privy to such information, ofcourse, but those who care about the topicñand about circumventionñcan usually find it with a relatively small effort. what technology can dois to pose barriers that are sufficient to keep those who are not stronglymotivated from finding their way to inappropriate material or experiences, and the fact that technology can be circumvented does not meanthat it will always be circumvented. for many people, circumvention willnot be worth the effort. for others, the circumvention techniques will notalways be available. still others may not receive the word on circumvention. sometimes, circumvention may be illegal even if feasible. for suchreasons, technologybased tools have utility even though circumventiontechniques exist. nevertheless, as most parents and teachers noted intheir comments to the committee, those who really want to have access to1specifically, when the circumvention is based on a software technique (as it has usuallybeen to date), the circumvention can be easily broadcast at very low cost to many individuals. when changes to hardware are involved (as happens relatively rarely), proliferation ofsuch changes is more difficult. a number of high school students told the committee thatonce one of them finds a circumvention of some sort, he or she shares it with other interested students almost immediately. for example, a high school student developed a way tobypass his school districtõs filtering system, and publicized it by sending an email to everyteacher and administrator in the district. see <http://www.salon.com/tech/feature/2001/06/14/netfiltering/index1.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.263a perspective on technologybased toolsinappropriate sexually explicit materials will find a way to get them, andtechnology is relatively ineffective in the long run against those who arestrongly motivated. from this point it follows that the real challenge is toreduce the number of children who are strongly motivated to obtain inappropriate sexually explicit materials. this, of course, is one focus of thesocial and educational strategies described in chapter 10.¥tools can and do improve over time as more effort is put intoresearch and development. some improvements are possible with betterdesign and implementation of known technologies. other improvementsawait advances in the underlying technologiesñand may eventually beincorporated into technologybased tools. however, almost by definition, technological improvements are likely to be evolutionary rather thanrevolutionary, and so it is unwise to base any approach to protectingchildren and youth from inappropriate internet materials and experienceson the hope of revolutionary technological breakthroughs.¥tools such as filters that are implemented on the local client machine (i.e., at the receiverõs point of interaction) tend to be easier to circumvent than those elsewhere (e.g., those embedded in the network or inthe enterprise that provides service). the reason is that tools colocatedwith the receiver are more readily accessible to the potential circumventer,and thus more subject to inspection, manipulation, and unauthorized orimproper alteration or disabling. moreover, tools that run on the clientmachine add an additional layer of complexity that can make a computerless reliable and more prone to lockups and system crashes.¥because currently deployed technologies do not yet support accesspolicies to be associated with an individual rather than a workstation, asimple change of venue (i.e., a movement of the child or youth to anotherplace where the web can be accessed) is often all that is necessary to defeatthe most effective technological tools for protection. a change of venuemay be a deliberate attempt to avoid technologically imposed restrictions,as in the case of students using home computers with internet access tobypass filtered access at schools. alternatively, it may be entirely accidental, in the sense that a venue that the minor uses for reasons of convenienceon some occasions, for example, may not offer the same technological toolsin its computing environment as the ones that he usually uses.¥one of the principles underlying the architecture of the internet isthat to the extent possible, functionality resides at the end points of acommunication, rather than in the middle. thus, to the extent that endtoend encryption is used, onthefly content identification by the contentcarrier (e.g., the internet service provider (isp)) is impossible, and therefore interdiction based on such identification is impossible. (in practice,this fact gives the interdictor of content only two choices: to allow allunknown traffic to pass, or to block all unknown traffic. allowing allyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.264youth, pornography, and the internetunknown traffic to pass is likely to permit some inappropriate contentthrough, while blocking all unknown traffic is likely to block some appropriate content.)¥as with social and educational strategies, informed decisions aboutthe use of technologybased tools (whether to use them and if so, whichone(s)) must take into account the developmental stage of the children forwhose benefit they would be deployed. some tools are most appropriatefor younger children, who are presumably more impressionable, less experienced in the ways of the world, and less skilled in the use of information technology, and for whom the consequences of exposure to inappropriate material of any sort might be considerable. other tools, perhapsallowing more discretion on the part of the user, might be more appropriate for older youth that are more experienced and mature.¥improvements in technology can be rapidly deployed compared tothe time scale on which social and educational strategies change. that is,communities may be involved in the decision to use technologybasedtools, but do not generally get involved in the technical design or implementation of those tools, which are usually within the discretionary purview of the tool designer and vendor. by contrast, social and educationalstrategies for a community (though usually not for individual families)are often extensively debated, and once debated, an extensive trainingeffort is then needed to promulgate a new approach.¥the deployment of technological tools entails some financial cost,both initially and in ongoing costs. thus, one potential social inequity isthat those lacking in resources will be denied the benefits of varioustoolsña òdigital divideó issue.2 advocates of using tools might argue2for example, in 2000, 54 percent of public schools with access to the internet reported thatcomputers with access to the internet were available to students outside of regular schoolhours, and secondary schools were more likely than elementary schools to make the internetavailable to students outside of regular school hours (80 percent compared with 46 percent).large schools (1,000 or more students) were more likely than mediumsized and small schoolsto make the internet accessible to students outside of regular school hours (79 percent compared with 53 and 49 percent, respectively). in addition, schools with the highest minorityenrollment reported internet availability outside of regular school hours more frequentlythan schools with the lowest minority enrollment (61 percent compared with 46 percent).such statistics suggest that schools do provide a considerable amount of outofclass internetaccess for many studentsñand it is likely that many of these students do not have internetaccess at home. (statistics are taken from a. cattagni and e. farris, 2001, internet access inu.s. public schools and classrooms: 19942000, nces 2001071, office of educational researchand improvement, u.s. department of education, washington, d.c. a kaiser family foundation/npr poll taken in 2001 found that schools are playing an important role in equalizingaccess to computers for kids. specifically, african american children and children fromlowerincome households are considerably less likely to use a computer at home than arewhite kids or kids from higherincome families, whereas virtually the same percentage ofall kids have used a computer at school. see <http://www.npr.org/programs/specials/poll/technology/>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.265a perspective on technologybased toolsthat it would be desirable for all people, rich and poor, to enjoy the protection benefits that such tools confer, but if economics make such equityimpossible, better for some to enjoy such benefits than for none to do so.on the other hand, detractors of tools, especially of tools whose use ismade mandatory, can argue that laws such as cipañwhich make the useof filters mandatory in exchange for erate fundingñforce the problemsof filters on the poor.11.3the questions to be asked of each toolchapters 12 and 13 discuss seven major types of technology that canbe used to protect or limit childrenõs exposure to inappropriate sexuallyexplicit material on the internet. these include filtering, adoption of specialized domain names, surveillance and monitoring, age verification technologies, instant help, tools for controlling spam, and tools for protectingintellectual property. to provide the basis for a systematic understanding of each of these tools, the committee found the following set of questions useful.¥what is it? the answer to this question provides a clear descriptionof the tool and a discussion of its variants. while the need for a cleardescription may be obvious, the public debate has often been hamperedby a lack of common understanding about exactly what option is beingdiscussed.¥how well does it work? what are the benefits that the product isintended to offer? as noted in chapter 8, òprotectionó is a term withmultiple possible meanings, and not all options provide the same kind ofprotection. only after the nature of the protection offered has beenestablished is it meaningful to ask about the toolõs effectiveness. notethat effectiveness is a multidimensional concept, and efforts to reduce atoolõs effectiveness to a single metric are generally not useful.¥who decides what is inappropriate? all options presume some definition of inappropriate material, and such definitions reflect the values heldby the decisionmaking party involved. indeed, as indicated in chapter5, there are few universally held and objective standards for defining orrecognizing inappropriate material. an understanding of the locus ofdefinitional control is thus important, because who òshouldó be responsible for decisions about what is inappropriate for a child is at the centerof much controversy. advocates can be heard for the responsible partybeing the child, the childõs parents, the childõs teacher, a representative ofthe school, the city council, the state legislature, the u.s. congress, thesupreme court, local juries, and so on.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.266youth, pornography, and the internet¥how flexible and usable is it? it is rare that a given implementation ofan option is perfectly matched to the needs of its user, and the details ofimplementation may make a given product unsuitable for a user, even if,in general, the philosophy underlying the product is consistent with auserõs needs. (an example is the ease with which userenabled òoverridesó of product settings is possible.) a product may also have otherfeatures that enhance or detract from its usability. note also that peopleare usually of two minds about the flexibility of a product. on the onehand, they generally believe that a product with greater flexibility can becustomized to their needs to a greater extent. on the other hand, theyfind the actual exploitation of a productõs flexibility to be a chore that theytend to avoid. as a result, the most common use of any technology tool isin its default òout of the boxó configuration. (thus, for practical purposes, it is fair that any assessment of a tool place great weight on whatthe tool does out of the box.)¥what are the costs entailed and infrastructure required to use it? protection against inappropriate material does not exist in a vacuum, and ingeneral, an infrastructure is necessary to support the longterm use of atool that provides maximum protection consistent with the userõs otherfunctional requirements. costs should be understood broadly, and theyinclude financial costs, ease of implementation, ease of use, false positives and false negatives, interference with the functions being served inthe chosen environment, and lack of transparency about the option inoperation.¥what are the implications of using it? it is rare that the adoption of anoption will have no side effects, and understanding the possible unintended consequences (which may be desirable or undesirable) may affectjudgments about a toolõs desirability.¥what is its future? some technologies whose effectiveness is limited today may increase in effectiveness tomorrow as research progresses.or, the technology necessary for a certain type of a tool might exist butnot be implemented in any product now on the market. and, differentenvironmental circumstances may lead to different levels of effectivenessñwhich is especially true of tools or strategies whose effectivenessincreases as others make use of them.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.267this chapter discusses tools for the end user, here the party responsible for making decisions on behalf of the child or youth in question.thus, the òend useró may be a parent in the case of a home or family, amaker of school policy (e.g., a school principal or a school district), amaker of policy for a public library (or library system), or some othersimilar individual or body. the focus on tools for end users is importantbecause such tools are intended to empower end users by providing awide range of options for the children in their care, more or less regardless of what other internet stakeholders do or do not do. (the only exception concerns instant help, in which the user is the child seeking help.)table 12.1 provides a preview of this chapter.12.1filtering and contentlimited accessfilters are at the center of the debate over protecting children andyouth from inappropriate sexually explicit material on the internet. agood filter allows a specific filtering policy to be implemented with accuracy, has enough flexibility, and can be implemented with a minimum ofundesirable side effects. box 12.1 describes the dimensions of choice thatgetnetwise identifies for filters.12.1.1what is filtering and contentlimited access?today, internet access is largely unrestricted. that is, a user whodoes not take some explicit action to limit the content to which he or she is12technologybased tools for usersyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.268youth, pornography, and the internettable 12.1 technologybased tools for the end userone illustrativeone illustrtype of toolfunctionadvantagedisadvantcan be configured to denyaccess to substantial amountsof adultoriented sexuallyexplicit material fromcommercial web sitesprovides high confidence thatall accessible material conformsto the acceptability standardsof the access providerseparates content characterization (e.g., sexually explicit ornot) from decisions to block;multiple content raters can beusedrarely prevents child fromreaching appropriate materialthat might have beenmistakenly flagged asinappropriatecan provide useful informationabout whether or notacceptable use policies arebeing followedcan reduce the volume ofinappropriate emailssignificantlyprovides guidance for childwhen it is likely to be mosteffective, i.e., at time of needblock òinappropriateó access toprespecified content; typicallyblocks specific web pages, mayalso block generic access toinstant messages, email, andchat roomsallow access only to contentand/or services previouslydetermined to be appropriateenable users to make informeddecisions about content prior toactual accessexamine a childõs actions by anadult supervisor in real time orafter the factwatch the collective actions ofa group (e.g., a school) withoutidentifying individualsinhibit unsolicited emailcontaining sexually explicitmaterial (or links to suchmaterial) from entering childõsmailboxprovide immediate help whenneeded from an adultnote: the òend useró is generally the adult supervisor who makes decisions on behalf of achild. (this is true in all cases except for instant help, in which the user is the child seekinghelp.)filtercontentlimitedaccesslabeling ofcontentmonitoringwith individualidentificationmonitoringwithoutindividualidentificationspamcontrollingtoolsinstant helpyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.269technologybased tools for usersvoluntary versusone illustrativeinvoluntarydisadvantageexposureprotects against both deliberate andinadvertent exposure for sites that areexplicitly blocked; can be circumventedunder some circumstancesvery low possibility of deliberate orinadvertent exposure, given that allmaterial is explicitly vettedlikelihood of exposure depends onaccuracy of labels given by labelingpartywarnings can help to deter deliberateexposure; ineffective against inadvertentexposurewarnings can help to deter deliberateexposure; less effective againstinadvertent exposuremostly relevant to inadvertent exposure(i.e., unsought commercial emailcontaining sexually explicit material)mostly relevant to inadvertent exposurein typical (default) configuration,generally denies access to substantialamounts of web material that is notadultoriented and sexually explicitmay be excessively limiting for thosewith broader information needs thanthose served by the access providereffectiveness depends on broadacceptance of a common labelingframeworkpotential loss of privacy zone for childdoes not enable individual accountability for irresponsible actionsamong users concerned about losingpersonalized email, reduced tolerancefor false positives that block genuinelypersonal emails incorrectly identified asspamrequires responsive infrastructure ofhelpersyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.270youth, pornography, and the internetbox 12.1getnetwise questions about filtersdoes the product control:¥access to web pages?¥use of email?¥access to chat rooms?¥movement of files in and out of your computer (ftp)?¥access to newsgroups (usenet)?¥access to various forms of instant messaging?¥access to other internet capabilities?how are standards of òinappropriatenessó managed?¥by the company alone?¥by the user selecting categories to be filtered from a list of preset categories?¥by the user developing his or her own list of material to be filtered, based onthe companyõs list of material to be filtered as a starting point?¥by the user adding to or subtracting from the companyõs list of material to befiltered?¥by the user developing his or her own list of material to be filtered, startingfrom scratch?to what extent can the criteria for determining inappropriateness be reviewed?can the user review¥the list of keywords?¥the list of filtered urls (web page addresses)?¥the companyõs criteria for filtering a web page?on what basis does the company determine what content is inappropriate?¥pics ratings (an independent rating system)?¥using the web page address (url)?¥human review of web sites?¥a list of keywords?¥a list of keywords combined with an analysis of the context in which theyappear?what are the categories of inappropriate material? these might include, for example,violence/profanitypartial nudityfull nuditysexual actsgross depictionsquestionable/illegal andgamblingalcohol and tobacco.intolerancesatanic/cultdrugs/drug culturemilitant/extremistsex educationyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.271technologybased tools for usersexposed has access to any content that the internet provides through webpages, email, chat rooms, and the like. this report uses the term òfilteróto refer to a system or service that limits in some way the content to whichusers may be exposed. the vast majority of filters block access to contenton specific web sites (though these sites may be specified as a class).other filters also block access on the basis of keywords appearing eitherin a userõs query to a search engine or contained in the abouttobe displayed web site.1 some filters provide the capability to block morebroadly, so that an individual may be denied access to other commoninternet services, such as interactive services (e.g., email, chat rooms),usenet newsgroups, file downloading, peertopeer connections, or evenecommerce with credit card usage.users who wish to use a filter have a number of technical options:¥clientside filters. filters can be installed on the devices (today,desktop and laptop personal computers) that serve as the internet accesspoint for the end user. clientside systems are installed as local software,in the same way that any other software is locally installed, except thatstandard uninstallation (which would disable the filter) can be done onlyby someone with the appropriate password. the party with the appropriate password is also generally responsible for configuring the profile ofthe system for those they are seeking to protect from inappropriate materials. a common personal use is a clientside filter installed at home by aparent wishing to protect children from inappropriate material. clientside filtering is also feasible in an environment in which only some accesspoints in a local area network must be filteredñfor example, in a libraryattempting to segregate òchildrenõs areasó from areas for all patrons.¥contentlimited internet service providers. as a feature of their offerings, a number of isps provide internet access only to a certain subset ofinternet content. contentlimited isps are most likely to be used by organizations and families in which the information needs of the childreninvolved are fairly predictable. today, such dedicated isps are a niche1the actual content of a list of such keywords is usually held as proprietary informationby the vendor of the filter. however, such lists include a variety of òfourletter wordsóassociated with sex, reproduction, and excretory functions, words such as òsex,ó ònaked,óand so on. other words that might be singled out for inclusion include òbomb,ó òbondage,ó òfetish,ó òspunk,ó òvoyeurism,ó òbabe,ó òerotica,ó ògay rights,ó ònazi,ó òpot,ó òwhitepower,ó ògirlz,ó and òhardcore pornography.ó (these examples are taken from lisa guernsey, 1999, òsticks and stones can hurt, but bad words pay,ó new york times, april 9.)also, a more sophisticated form of filtering is based on the analysis of word combinationsand phrases, proximity of certain keywords to certain other keywords, the presence ofvarious urls, and so on. in some cases, textbased analysis may also be combined with theanalysis of images on the web page in question. as a rule, tools based on this moresophisticated filtering are not broadly marketed today.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.272youth, pornography, and the internetmarket and typically have subscriber bases in the thousands to tens ofthousands. all subscribersñwhich are often families and less often institutionsñare subject to the same restrictions. some contentlimited isps,intended for use by children, make available only a very narrow range ofcontent that has been explicitly vetted for appropriateness and safety.thus, all web pages accessible have been viewedñand assessedñforcontent that is developmentally appropriate, educational, and entertaining. (this approach is known as òwhite listingóñall content from sourcesnot on a white list are disallowed,2 as discussed in section 2.3.1.) chatrooms and bulletin boards are monitored for appropriate content, andthose violating rules of chatting or message posting are disinvited, forcibly if necessary. email and instant messages (ims) can be received onlyfrom specified parties and/or other users of the system. other contentlimited isps, intended for use by both children and adults, allow access toall content that is not explicitly designated by the isp as inappropriate.monitoring and limits on email are less strict or nonexistent.some services allow multiple òlogin namesó or òscreen names.ó ascreen name is an online identity, similar to a cb radio òhandle.ó eachonline session uses a single screen name, and families can choose not togive the adult or òadministrativeó screen name password to youth. anonline account may have multiple screen names, and a user with appropriate privileges (usually associated with paying for the master account)can create arbitrary screen names at will for himself or someone else onhis account as long those names are not already in use. with each namecan be associated unrestricted access or more limited access to onlinecontent (which may include both internet and proprietary content). inthe case of america online (aol), a parent can identify the age of thechild for whom he or she is setting up a screen name. aol then puts intoplace default limitations based on the age of the child, which the parentcan then adjust if necessary. such limitations might include, for example,web access only to ageappropriate content or to everything except explicitly mature themes, receipt of email only without file attachments orembedded pictures, and access only to chat rooms intended for children(or no chat room access at all).¥serverside filters. serverside filtering is useful in institutional settings in which users at all access points within the institutionõs purview2note that sources on a white list can be specified in advance or identified as appropriatebecause a source contains one or several ògood wordsó that may be found on a ògoodwordó list. for an example of the latter, see gio wiederhold, michel bilello, vatsala sarathy,and xioalei qian, òa security mediator for health care information,ó pp. 120124 in proceedings of the 1996 american medical informatics association conference, washington, d.c.,october.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.273technologybased tools for usersmust conform to the access policy defined by the institution. serversidefiltering might be used by a school district that provides internet serviceto all schools in the district or a library system that provides internetservice to all libraries in the system. serverside filters are located onsystems other than the client.3 an institution may contract with an isp toimplement its filtering policy, or it may install a filter in the server thatmanages a local area network (e.g., that of a school district or a librarysystem).4 (note that there are no fundamental technological impedimentsto having filtering policies that differentiate between schools within adistrict, so that a high school might operate under a policy different fromthat for an elementary school. such differentiation is simply a matter ofcost.)¥search engine filters. in a special class of serverside filters are thosethat are today part of major search engines such as google, altavista, andso on. each of these search engines has the capability of enabling aninternet safety filter (hereafter òfiltered search engineó). when activatedby the user, these filters do not return links to inappropriate content foundin a search, but they also do not block access to specifically named websites (so that a user knowing the url of a web site containing inappropriate sexually explicit material could access it).5 other search engines areexplicitly designed for use by children. for example, lycos and yahooboth offer a special kidsoriented version of their generalpurpose searchengine that restricts the universe of a search to childappropriate areas.(this is the whitelist approach.)filters can be used to block certain incoming inappropriate information (an application that is the most common use of filters), to block accessto certain internet services (e.g., file downloads), or to block selected out3the distinction between serverside filtering and contentlimited isps is not a technicalone, because contentlimited isps use serverside filters. rather, the point is that serverside filtering provides a degree of institutional customization that is not possible with contentlimited isps, which tend to offer onesizefitsall filtering policies.4the use of serverside filters may degrade performance. in particular, a serverbasedfilter may rely on òproxy serversó that are unable to take advantage of the caching techniques that are often used by major internet providers to speed the retrieval of commonlyrequested pages. such a filter would be forced to retrieve information from its host serverand take whatever performance hit that might entail. in other cases, performance is improved because without irrelevant material taking up space in the cache, retrieval of relevant material is faster.5in practice, a responsible adult would set the filtering provision to the òonó setting, andsave the configuration. thereafter, other requests on that client to the search engine wouldencounter the òonó setting. the setting can also be turned òoffó through entering a password known only to the individual who initially set it (a possible problem if that person isthe teenager in the household who manages the familyõs information technology).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.274youth, pornography, and the internetgoing information. all technologyenforced methods for blocking accessto inappropriate information require a determination that certain piecesof content are inappropriate.6 content can be deemed inappropriate onthe basis of the methods discussed in section 2.3.1.many filter vendors establish lists of òsuspectó web sites (compiledas a list of specific urls and/or ip addresses) deemed sources of inappropriate content.7 the number of such sites may range from severalhundred thousand to 2 million. in addition, many vendors establish listsof keywords (typically hundreds of words) that represent inappropriatecontent. far fewer employ image analysis or statistical techniques toanalyze text.in addition, techniques for textual and image analysis can be used toidentify and block email containing inappropriate content and for blocking outgoing content as well. for example, the technology that identifiesinappropriate content by searching for keywords can also prevent thosewords (or some set of them) from being used in email messages or in chatrooms. (in this case, the adult supervisor can augment the keyword list toinclude certain phrases that should not appear, such as specific addressesor phone numbers.)filters are perhaps the most widely deployed of all technological toolsintended to protect children from exposure to inappropriate material.the majority of schools have deployed filters,8 while around 25 percent of6note that content that is transmitted through certain channels such as attachments to email, videoconferences, instant messages, or peertopeer networking (in a gnutellalikearrangement) is very difficult (arguably impossible) to block selectively, though a filter canblock all interaction through these channels. moreover, to the extent that the content oftraffic is determined interactively, neither labeling nor sites are likely to provide a sufficientbasis. the reason is that interactive sources, almost by definition, can support a variety ofdifferent types of interactionñthe best example of which is an online friend with whom onemay exchange sports trivia, conversation about school homework, and inappropriate sexually explicit material. only realtime content recognition has a chance of filtering suchcontent.7note also that the list of blocked sites often includes sites that could help users circumvent the basic filtering. thus, sites providing information on how to circumvent filters areoften included on the list, and a number of filters block sites that allow language translation(seth finkelstein and lee tien, 2001, òblacklisting bytes,ó white paper submitted to thecommittee, available online at <http://www.eff.org/censorship/censorware/20010306effnrc paper1.html>) or access to web archives (seth finkelstein, 2002, the preslippedslopeñ censorware vs. the wayback machine web archive, available online at <http://sethf.com/anticensorware/general/slip.php>).8according to the national center for education statistics, nearly threefourths of allschools use blocking or filtering software. see a. cattagni and e. farris. 2001. internetaccess in u.s. public schools and classrooms: 19942000. nces 2001071. office of educational research and improvement, u.s. department of education, washington, d.c. available online at <http://www.nces.ed.gov/pubs2001/internetaccess/>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.275technologybased tools for userslibraries filter at least some workstations.9 through aolõs parental controls (box 12.2), a substantial number of internetusing children enjoy thebenefits and endure the costs of filtering. however, as a percentage of allchildren using the internet, the fraction whose internet access is filteredapart from school usage is small.10it is noteworthy that filters are increasingly common in corporate andbusiness settings and thus affect the internet use of adults.11 many companies, driven primarily by concerns about productivity and time wastedon nonbusiness internet activities and about the possible creation of hostile work environments and the consequent liability, use filters to preventinappropriate use of company it facilities.1212.1.2how well does filtering work?denying access to inappropriate material through technological means,filters are intended to protect against both inadvertent and deliberate access. however, as discussed in section 2.3.1, all filters are subject to overblocking (false positives, in which filters block some appropriate material9by contrast, around 57 percent of public libraries do not filter internet access on any workstation, while about 21 percent filter access on some workstations. about 21 percent filter allworkstations. see norman oder. 2002. òthe new wariness,ó the library journal, january 15.available online at <http://libraryjournal.reviewsnews.com/index.asp?layout= article&articleid=ca188739>.10a survey conducted by family pc magazine in august 2001 found that of 600 familiessurveyed, 26 percent used parental controls of some kind. about 7 percent of those usingparental controls (about 1.8 percent of the total) used offtheshelf storebought filteringpackages. the rest used filtering offered by an internet service provider. (this study is notavailable in print, because it was scheduled for publication in october 2001, and ziff davis,the publisher of family pc, terminated the magazine before that issue was printed.)11for example, a survey taken by the american management association in 2001 foundthat 38 percent of the firms responding do use blocking software to prevent internet connections to unauthorized or inappropriate sites. seventy eight percent of the respondingfirms restricted access to òadultó sites with explicit sexual content, though it is not clearhow the remaining 40 percent are enforcing such restrictions. (the survey suggests thatthey are doing it by actively monitoring internet use.) see american management association. 2001. 2001 ama survey, workplace monitoring and surveillance: policies and practices.available online at <http://www.amanet.org/research/pdfs/emsfushort.pdf>.12potential overlap between the business market and the school and library filtering market raises the following operational concern: a blocked category may be defined by a vendor so that it is appropriate in a business environment, but that definition may not beappropriate in a school or library context. for example, information about sexually transmitted diseases, safe sex practices, and pregnancy may not be necessary in most businessenvironments (and hence an employer may have a legitimate business reason for blockingsuch information), but many would argue that older students using school facilities shouldnot be blocked from receiving such information.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.276youth, pornography, and the internetbox 12.2aolõs parental controlsaolõs parental controls provide a number of options for restricting in some waysthe privileges associated with a given screen name.1¥an online timer limits the amount of time a user can spend online.¥web access is provided at three levelsñunrestricted, unrestricted except forweb sites that are explicitly deemed inappropriate, and limited only to web sitesthat are explicitly deemed appropriate for children.¥im controls allow or prevent the userõs sending and receiving of instantmessages.¥email controls allow or prevent the userõs sending and receiving of email,and can further be set to allow email only from certain parties.¥chat controls can be set to allow the user to participate in any chat rooms,in only selected monitored chat rooms appropriate for children, or in no chat roomat all.¥download controls allow or prevent the userõs sending and receiving fileattachments (which may include images).¥newsgroup controls allow or prevent the userõs gaining access to usenetnewsgroups.aol parental controls distinguish between four categories: kids only, youngteen, mature teen, and 18+ (general access) categories.¥kids only (12 and under) allows access to ageappropriate features and content through aolõs kids only channel and the rest of the internet (when accessedthrough aol). feebased services such as shopping, instant message notes, access tomember profiles and all chat rooms, home pages based on aol, and links to websites obtained in email are blocked.¥young teen (13 to 15) allows access to ageappropriate interactive featuresand information on aol and the rest of the internet (when accessed through aol).feebased services such as shopping, instant message notes, access to member profiles as well as private and member chat rooms, home pages based on aol, andlinks to web sites obtained in email are blocked.¥mature teen (16 to 17) gives the most freedom compared to other childrenõscategories, and allows access to most interactive features and information on aoland the rest of the internet (when accessed through aol). web sites with explicitlymature content are blocked. internet newsgroups and feebased services are blocked.¥general access (18+) allows full access to all features and content on aoland the rest of the internet.source: america online.1a screen name is an online identity, similar to a cb radio òhandle.ó an individual mayhave multiple screen names, and a user with appropriate privileges (usually associated withpaying for the master account) can create arbitrary screen names at will for himself or someoneelse on his account as long those names are not already in use.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.277technologybased tools for usersfrom the user) and underblocking (false negatives, in which filters passsome inappropriate material to the user). while the issue of underblockingand overblocking should not, in and of itself, rule out filters as a useful tool,the extent of underblocking and overblocking is a significant factor in understanding and deciding about the use of filters.13there is no agreedupon methodology for measuring a filterõs effectiveness, as might be indicated by an overblocking rate and an underblocking rate (discussed in section 2.3.1).14 filter vendors sometimes provide estimates of overblock and underblock rates, but without knowingthe methodology underlying these estimates, the cautious user must beconcerned that the methodology is selected to minimize these rates. (thediscussion in box 2.7 illustrates some of the problems in estimating theserates. note further that the lists of blocked web pages change constantly,with both additions and subtractions made regularly.)underblocking results from several factors:¥new material appears on the internet constantly, and the contentsof given web pages sometimes change. when content changes, the judging parties must revisit the sources responsible for the content they provide frequently enough to ensure that inappropriate information does notsuddenly appear on a previously trusted source or that the inappropriatematerial remains on the web pages in question. technology is availablethat can indicate if a page has changed (thus flagging it for human assessment), but not to tell if it continues to be developmentally and educationally appropriate. vendors of filtering systems generally provide updatesfrom time to time, but there is inevitably a lag between the time inappropriate material first appears and the time that item is entered into the listof blocked sites. (contentbased filtering systems are not subject to thisparticular problem.)¥the algorithms (i.e., the computational techniques) used to identify inappropriate material are imperfect. for example, the emergence of13note also that legal challenges brought against the mandated use of filters in institutional settings have relied significantly on the existence of underblocking and overblockingas inherent flaws in the technology that make filters unsuitable for such use.14for òbakeoffsó comparing internet filters, see christopher d. hunter, 2000, òinternetfilter effectiveness: testing over and underinclusive blocking decisions of four popularfilters,ó social science computer review 18 (2, summer), available online at <http://www.copacommission.org/papers/filtereffect.pdf>; karen j. bannan, 2001, òclean it up,ópc magazine, september 25, available online at <http://www.pcmag.com/article/0,2997,a%253d12392,00.asp>; and òdigital chaperones for kids,ó consumer reports, march2001. for a critique of the consumer reports analysis, see david burt, 2001, òfiltering advocate responds to consumer reports article,ó february 14, available online at <http://www. politechbot.com/p01734.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.278youth, pornography, and the internetnew slang for sexual acts will thwart filters based on keyword recognitionuntil the new slang is incorporated into the filtering criteria. anotherpossibility is that the use of clothed people having sex may thwart imagerecognition algorithms based on the assumption of searching for nakedpeople.¥sites with adultoriented content are often given names that areclose in spelling to the names of legitimate sites. for example, <http://www.whitehouse.com> is often reached by people intending to reach<http://www.whitehouse.gov>. while most filtering programs havefixed this specific problem, closebutnotidentical names can pop up for alarge number of legitimate generalpurpose sites.overblocking arises from three factors:¥content may be less than clearcut, especially in the context ofmachineassisted understanding. as noted in chapter 2, both text andimages can be ambiguous.15 moreover, the precise definition of whatshould be blocked is inevitably subject to the vagaries of individual judgments. for reasons discussed below, filter vendors generally have moreincentives to block ambiguous information than to allow it to pass, a factthat leads to overblocking.¥information on the internet is updated constantly. thus, a site thatmay have been blocked for good reason in the past may post new information that does not meet the criteria for blocking. as in the case ofunderblocking, until records of the site are updated in the filter, that filterwill continue to mark such sites as inappropriate even if the informationcontained therein is perfectly innocuous.15two particularly egregious examples include beaver college and online biographies of individuals who have graduated magna cum laude. beaver college in pennsylvania recently changed its name to arcadia college because its name was beingfiltered out (òbeaveró has crude sexual connotations in american english slang). beaver college spokesman bill avington was quoted in wired as saying, òwe have a lot ofevidence that people arenõt able to get our information in high schools because of webfilters in the librariesó that block out sites with òbeaveró along with other presumedsmut words. he continued, òwith so many people using the net as the initial means tolook at colleges, thatõs a serious disadvantage.ó in addition, he claimed that filterssometimes block email from beaver college staffers to prospective students. (see craigbicknell, 2000, òbeaver college not a filter fave,ó wired, march 22, available online at<http://www.wired.com/news/politics/0,1283,35091,00.html>; and cnn story, 2000,òbeaver college changes oftderided name to arcadia university,ó november 20,available online at <http://www.cnn.com/2000/us/11/20/embarrassingbeaver.ap/>.the òmagna cum laudeó problem was demonstrated when filtering software blockedaccess to all biographies of copa commissioners who had graduated magna cum laude(see <http://www.cdt.org/speech/filtering/001002analysis.shtml>).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.279technologybased tools for users¥a site (or a given web page) may contain both appropriate andinappropriate material. if the filter cannot separate appropriate frominappropriate, it will usually block (overblock) the entire site or page.the above three factors are basic to the fundamental imperfection ofthe filtering process. a fourth factor that can lead to overblocking resultsfrom the ways in which some filtering systems are implemented. if afilter blocks sites on the basis of the ip addresses of adultoriented, sexually explicit sites, and those sites are hosted on a server that makes use ofipbased virtual hosting (described in chapter 2), other nonadult siteshosted on that server (and sharing those ip addresses) will be blocked.16note an important distinction between overblocking and an overlybroad scope of blocking (i.e., an overly broad blocking policy). overblocking is inadvertent and results from the inability of the automatedsystems for blocking to perfectly track human decision making. themodel human decision maker, examining overblocked material, wouldconclude that the material should in fact have been free to pass. anexample would be a search for òbeaver damsó that results in pages beingblocked because the word òbeaveró is present on the page.an overly broad policy is more subjective, and results from a disagreement between the end user and the human decision maker aboutwhat information the end user should be allowed to receive. from the16the magnitude of overblocking due to ipbased virtual hosting is unclear. one estimate (art wolinksy, 2001, òfiltergate, or knowing what weõre walling in or wallingout,ó multimedia schools, may/june, available online from <http://www.infotoday.com/mmschools/may01/wolinsky.htm>) suggests that such overblocking far outstrips overblocking for other causes. however, a number of factors should be considered in assessing the potential impact of ipbased virtual hosting:¥most large sites are not hosted on virtual hosting services. furthermore, large sites tend tobe more heavily promoted and are often more likely to appear in a prominent position in asearch engineõs result list. thus, large sitesñwhich typically account for the web requests ofmost usersñare much less likely to be improperly blocked than smaller sites.¥many virtual hosting services ban adultoriented, sexually explicit material and othermaterial that they regard as offensive as well, and they enforce their acceptable use policiesvigorously. thus, the amount of sexually explicit material hosted overall by such services islikely to be small. (but, if such a service does host even one site containing inappropriatesexually explicit material and that fact is picked up by a filtering vendor that uses ipbasedfiltering, it will exclude all of the acceptable sites on that host. all of the acceptable sites thatare improperly blocked will stay blocked until the hosting service eliminates the inappropriate site and the fact of elimination is communicated to the vendor.)¥different implementations of filtering (e.g., use of namebased filtering) can lead to thesame intended result without the overblocking caused by ipbased filtering. as a rule, theprimary reason for wishing to use ipbased filtering is technicalñwhen a hosting service isused primarily for adultoriented, sexually explicit material, ipbased filtering reduces theamount of storage and processing needed by the filter.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.280youth, pornography, and the internetperspective of the end user, a certain piece of material is blocked inappropriately. however, upon examination of that blocked material, the human decision maker concludes that the blocking decision was proper. forexample, a student may wish to search for information on marijuana. butweb sites containing the word marijuana may be blocked because of apolicy decision to block information about drugs.17the effectiveness of a filter also depends on whether its use is enforced at all sites available to a child. in a specific venue, filters will blocksome material that some parties deem inappropriateñand there is a reasonable argument to be had over whether the blocking that occurs isworth the cost of overblocking. but it is impossible for a filter deployed ina school to block material sought in a cybercaf” or at home, and filteringlimited to schools and libraries will not prevent the access of children toinappropriate sexually explicit material if they are determined to searchfor it and have other venues of access. the most common unfilteredvenues are home internet access or internet access provided at a friendõshome. (filtering at home is not the norm,18 even though a significantfraction of u.s. youth do have internet access at home,19 a point wellrepresented by the adolescents to whom the committee spoke during itssite visits.)filters that are not based on realtime contentbased identification ofinappropriate content can be circumvented by users in a number ofways,20 both direct and indirect:17the distinction between overblocking and an overly broad scope of blocking is furthercomplicated by the fact that from time to time, a given site can be used for multiple purposes. most filters include adultoriented web sites in their òto be blockedó categories.however, a high school student undertaking, for example, a study of the economics of theadult online industry might have an entirely legitimate purpose for seeking access to suchsites. more generally, any student wanting to study a controversial issue and needing toconsult sources for different sides of an argument may well find that advocates of one pointof view or another are blocked because they are regarded as òinappropriateóñwhere, inpractice, òinappropriateó is likely to mean òcontroversial.ó18 see footnote 10.19according to grunwald associates, 17.7 million children aged 2 to 17 had internet accessfrom home in the last quarter of 1999. (the web site <http://cyberatlas.internet.com/bigpicture/demographics/article/0,,5901390941,00.html> provides a summary of the grunwald study. the full study is available online at <http://www.grunwald.com/survey/index.htm>.) the u.s. census indicates about 65.7 million children in the united states inthis age bracket, for a percentage of about 27 percent.20many filtering products, especially those on the client side, are easily breakable byknowledgeable users. see michael j. miller, 2001, òwhen does web filtering makesense?,ó pc magazine, september 25, available online at <http://www.pcmag.com/article/0,2997,s%253d1499%2526a%253d12632,00.asp>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.281technologybased tools for users¥it may be possible to defeat the filter itself. when this occurs, aspecific web page that the filter should block is made accessible to theuser. defeating the filter may sometimes be accomplished by:ñuninstalling the filter;ñobtaining the privileges needed to disable the filter. while suchprivileges are intended for the parental supervisor (and are usually passwordenabled), the ability of youth to obtain privileges is not uncommonin households in which the resident teenager serves as the de facto systemadministrator because of superior technical knowledge);ñaccessing the web page indirectly through a proxy server,21 atranslation service, an anonymizing service, or some other route;ñfinding a click route to the page other than the one that was directly blocked; and/orñmanipulating the reload/refresh and back/forward keys.note that defeating a filter can be more difficult when the filter isserverbased, because the circumventer does not have direct access to thesystem on which the filter resides. further, note that because a childoriented contentlimited isp would most likely be chosen by families interested in filtering for fairly young children (say, 10 and younger), thelikelihood that the ispõs restrictions could be circumvented is substantially lower than it would be if users included older youth.in addition, inappropriate material (sexually explicit and otherwise)can flow to a child through routes other than web sitesñpeertopeer filetransfers such as those available through gnutella, email attachments,and so on. while some filters can be set to block the use of such routes,such blockage is indiscriminate and insensitive to the content carried onthese routes.¥the user can obtain information that is generically similar to theinformation on the blocked web page. as a general rule, information notassociated with a specific source is resident on many locations on theworld wide web, and the likelihood of all of those locations being blockedis low. these comments apply particularly to sexually explicit material,especially material containing images. an individual seeking explicitimages for the purpose of sexual arousal is not particularly sensitive towhich of hundreds or thousands of images on as many web pages can beretrieved.21a proxy server is a server that happens to be accessible from the client machine. theuse of a proxy server, which can channel all requests òaroundó a serverside filter, canenable circumvention. many local area networks, however, are configured in such a way asto prevent the use of proxy servers.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.282youth, pornography, and the internetit is also true that the content provider could provide ways of circumventing filters. for example, misspelled sexual words (e.g., òpormography,óòdicck,ó ò0rgyó) may be used in a siteõs metatags to circumvent filters thatsearch for keywords. as a general rule, though, commercial vendors ofsexually explicit material argue that they are not economically motivated toexpend a lot of effort to get through these filters, because children are unableto pay for such material. those providing other types of content withoutcommercial intent may be more likely to attempt to circumvent filters.many of these methods of circumvention do not apply to filters thatare based on realtime contentbased identification of inappropriate content. however, filters that are based on realtime contentbased identification are not nearly as commonly available as filters based on lists ofinappropriate sites and keywords. furthermore, the technology of contentbased identification is relatively sophisticated compared to that required for developing lists of sites and keywords, and hence is moredifficult to implement properly.the effectiveness of labelbased filters depends on the ubiquity oflabels for internet content and the willingness of the user to decide whichlabels indicate content that should be blocked. labelbased filters, such asthose that incorporate picscompliant labels, are built into the major webbrowsers, internet explorer (ie) and netscape. however, picscompliantlabels are not in wide use as of this writing (may 2002; but see section12.1.5). both ie and netscape provide the user with the option of allowing or blocking unlabeled material, with the consequence that users ofthese browsers can either have access only to a very small segment of theweb (if unlabeled material is blocked) or enjoy minimal protection frominappropriate material (if unlabeled material is allowed). for this reason,labelbased filters today do not work particularly well in reducing exposure to inappropriate material unless one is willing to tolerate a very highrate of overblocking. whether they will work more effectively in thefuture depends on the extent to which internet content will be labeled.while filters are designed to reduce childrenõs access to inappropriatematerial on the internet, there are some interesting psychological andsocial phenomena related to their use. in most of the schools and librariesthat the committee visited, teachers, librarians, and administrators toldthe committee that filters played a very small role in protecting studentsand library users from inappropriate material, largely because most ofthese students and library users had unfiltered internet access somewhereelse (usually at home). (of course, for the significant fraction of studentswithout nonschool access, such comments did not apply.22) neverthe22u.s. public schools are increasingly providing internet access to students outside regularschool hours. for example, 80 percent of public secondary schools provided such a service inyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.283technologybased tools for usersless, the school or library filter served a useful political purpose in forestalling complaints from the community about òpublic facilities beingused for shameful purposes.ó23 in virtually every school the committeevisited, avoiding controversy and/or liability for exposing children toinappropriate sexually explicit material was the primary reason offeredfor the installation of filters.24in a public library setting, filters have also been used to prevent thedisplay of material that would be regarded as offensive to other patronswalking by. for example, one technique used to shock other patrons is todisplay an adultoriented web site on a public internet terminal and toòhideó it behind the terminalõs screen saver (which places some innocuous image on the screen on top of whatever is on the screen). when anunsuspecting user clears the screen saver image, he or she is suddenlysurprised by a sexually explicit image.25teachers and librarians can derive substantial benefit from filters.for example, most schools and libraries have acceptable use policies(aups, as discussed in chapter 10) that forbid use of school or librarycomputer resources for certain purposes, such as viewing sexually explicit sites. in the absence of a filter, a teacher or librarian must confrontthe user and inform him or her that such use violates the aup. for many,such confrontations can be unpleasant and can provoke anxiety. to the2000. in addition, schools with high minority enrollments provided internet availability outside of regular school hours more frequently than schools with lower minority enrollments(61 percent versus 46 percent), a figure consistent with the notion that minority students mayrely on schools to provide access more than do nonminority students. see a. cattagni and e.farris. 2001. internet access in u.s. public schools and classrooms: 19942000. nces 2001071.office of educational research and improvement, u.s. department of education, washington, d.c. available online at <http://www.nces.ed.gov/ pubs2001/internetaccess/>.23indeed, in one community, the public library system provided filters for 10 to 20 percent of its internet access points but made no special attempt to guide children toward thesefiltered workstations. nevertheless, the presence of these filters on 10 to 20 percent of itsworkstations was sufficient to allow it to assert to the community that òthe library providesfiltered access,ó an assertion that seems to have met the concerns of local government.24in the site visits of the committee, committee members explicitly avoided leading questions regarding the motivation for use. so, when teachers said, òour school has filtersó(which was true in all schools visited), committee members asked, òwhy do you havethem?ó òwhat is the benefit having filters?ó it is in this context that teachers said òtoreduce exposure to liability.ó for the most part, the committee believes that given theoverall context of all of the comments received in this manner (e.g., the accessibility of theinternet in unfiltered nonschool venues for a large number of students), the avoidance ofliability was indeed a primary or at least a very important reason for having filters inschools. nevertheless, the committee recognizes the possibility that responders felt theprotection benefits were so obvious so as not to need mentioning.25of course, a filter is not the only way to solve this particular problemñit would bealmost as effective to install software that would clear the browser cache and return to thelibraryõs home page after a short period of inactivity.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.284youth, pornography, and the internetextent that a filter reduces the possibility of a student or library patronviewing such sites, it also reduces the frequency of such confrontations.in addition, given community pressures for teachers and librarians tosupervise or monitor the use of internet resources by students and libraryusers, filters reduce the burden on teachers and librarians to police usageand free time for other, more productive activities. finally, many teachers and librarians are themselves uncomfortable in viewing certain typesof inappropriate material26ñand in the committeeõs informal discussionsin its site visits, this was especially true for many sexually explicit images.even apart from the claimed benefits of preventing exposure to inappropriate material, filters can offer children other benefits. in the schoolenvironment, teachers reported that filters helped them to keep studentsòon taskó while doing schoolrelated internet work by reducing the distractions that might otherwise be available to them (the students); box12.3 provides some data on the extent to which filters may keep studentson task. a number of younger students with whom the committee spokeduring various site visits thought that the parental use of filters (generallyaolõs parental controls) was a positive indication of their parentsõ concern, independently of whether they felt the filters were effective. (according to the kaiser family foundation, about twothirds of teenagersand young adults support the childrenõs internet protection act whenprovided with a description of it. this view does not vary among thosewho go online a lot or who have been denied access to web sites becauseof filtering.27)because they confine the user only to material explicitly consideredappropriate, childoriented contentlimited isps provide the greatest degree of protection for children. by design, their approach seeks to minimize underblocking at the expense of overblockingñall questionable exposure is blocked or at least monitored. for example, they evaluate foreducational or developmental benefit every web page that is accessible toa child. under these circumstances, the likelihood of exposure to inappropriate content is very low, especially with respect to sexual imagery.interactive dialog in chat rooms and on bulletin boards is monitored, sothat the first posting or sending of inappropriate messages can be censured. (such censure also provides observers with a lesson in the conse26in a preliminary finding issued in may 2001, the equal employment opportunity commission found that pornography downloaded on library computers was intended to create asexually hostile work environment for a group of minneapolis librarians. see michael bartlett,2001. òno internet filtering is sex harassment for librariansñeeoc,ó newsbytes, may 25.available online at <http://www.newsbytes.com/news/01/166171.html>.27victoria rideout. 2001. generation rx.com: how young people use the internet for healthinformation. the henry j. kaiser family foundation, menlo park, calif. available online at<http://www.kff.org/content/2001/20011211a/generationrx.pdf>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.285technologybased tools for users46 s60 s48 s51 s58 s52 s44 sbox 12.3student use of filtered internet access at schoolhow do students actually use filtered internet access at school? one study examinedthe usage in schools in which a given filtering system was used. in particular, the 300 mostfrequently accessed sites were examined, and these 300 sites accounted for òroughly halfóof the total page views. for each instance of access to these 300 sites, the perpageviewing time was recorded, with the results shown below in the table below.fraction offraction of overaverage timetotal pageall time spentspent on siteviewson all 300 sitesin this category56.8 percent14.2 percent10.6 percent10.5 percent5.0 percent1.5 percent1.4 percent51.7 percent20.0 percent(41.4 percent)9.5 percent(19.7 percent)10.0 percent(20.7 percent)6.2 percent(12.8 percent)1.9 percent(3.9 percent)0.7 percent(1.4 percent)according to these data, inschool web access to sites related to ecommerce, chat andmessage board services, and recreational activities accounted for 20 percent of student activity. if access to portals and search engines is spread out proportionately over all othercategories, noneducational internet accesses accounted for 40 percent of student activity.noting that these data are derived from schools in which a filtering system was in place, it islikely that the filter inhibited to some extent student use of inappropriate (and hence noneducational) sites, and so in the absence of the filter, the fraction of student internet accessesspent on noneducational activities might have been higher than 40 percent. these datasuggest that the presence of the filter does not keep students òon taskó for much of theirinternet time, but it is unknown what would have happened if the filter had not been present.source: n2h, inc. analytic services. 2000. k12 internet use, n2h2 winter quarter, learnings report. available online at <http://web.archive.org/web/20000930212613/www.n2h2.com/edwhite/edwhite.pdf>.portals and search (sites that attemptto branch out and connect users withcontent)instructional reference and computing(sites that could be used for specificinstructional purposes by teachers orstudents, general research and reference resources, and computer network resources)music, games and fun (sites geared toentertainment and leisure)commerce and eservices (commercial sites offering products or onlineservices)news and sports (online versions ofnational news, sports magazines, localnews)business and finance (financial newssites and online brokerage firms)communities (sites providing contenttargeted to specific demographicgroups and typically containing a largeamount of usergenerated content suchas chat and message boards)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.286youth, pornography, and the internetquences of such behavior.) the identities of email and im senders is notmonitored, but because they are restricted for the most part to users of theservice, the universe of those who might engage a child in email or imdialog is much smaller than on the entire internet. perhaps of equal orgreater benefit, at least from the perspective of some adults, is that thecontent accessible to kids has definite educational or developmental value,rather than being simply not inappropriate.12.1.3who decides what is inappropriate?filtering is based on the premise that a party or parties other than thechild himself or herself decides what content is inappropriate. in general,the first pass at determining potentially inappropriate content is the vendor of the filter or the contentlimited isp. for those who choose to acceptwithout change this determination (as is the case with subscribers to contentlimited isps or those who do not wish to customize further), thisinitial determination stands.for example, a school that installs a filter without additional customization accepts the determination of the vendor about what is or is notappropriate. even if it does undertake customization, it uses the vendorõsdetermination as its point of departure, and detailed editorial control on asitebysite basis for all sites in the vendorõs database is not possible inpractice.to accommodate those who wish to customize the characterization ofinappropriate material for their own individual or institutional needs,filter vendors usually offer two options (which may be combined or implemented by themselves):¥the characterization of inappropriate material can be divided intocontent categories with labels such as pornography, sex education, hatespeech, violence, weapons, cults, and so on. (for example, a list of inappropriate urls or keywords flagging inappropriate content might begrouped into such categories.) these filters then provide the user withthe option of blocking or accepting content by category, so that a user can,for example, block only pornography and hate speech while accepting allother content categories. categorybycategory blocking obviously reduces the list of blocked urls to a subset of the original list.¥some filters enable the end user (or, more precisely, the endusersupervisor who knows the appropriate password) to create a local òexceptionsó list, which specifies additional urls to be blocked or urls thatshould be allowed even if they are on the blocked list. for example,despite the filter, a child may view a url that the supervisor deemsinappropriate. a filter with this option enables the supervisor to add thatyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.287technologybased tools for usersurl to the list of blocked sites. if a child is blocked from viewing aparticular site, it may be apparent from the description accompanying theoriginal link (e.g., as displayed by a search engine) or from the site namein the link that the site should not be blocked. in this case, a òuser overrideó can be used to unblock the site. for practical purposes, the numberof such sites that are either added to or subtracted from the original list issmall compared to the size of the original list.the vendorõs characterization of inappropriate content is quite significant, as it is at the very least the primary point of departure for a userõscustomization (described below) even when such customization is possible.28 filter vendors have many incentives to err on the side of overblocking and few to err on the side of underblocking. based on its sitevisits, the committee believes that the reason is that schools and libraries,which are the largest users of filters for purposes of this report, tend toreceive many more complaints from parents and the community aboutsites that are not filtered (i.e., complaints about underblocking) than aboutsites that are filtered improperly (i.e., complaints about overblocking).2928one concern raised by analysts such as nancy willard is that filter vendors sometimeshave strong connections to religious organizations, and that the social and cultural valuesespoused by these organizations may drive the vendorõs characterization of inappropriatecontent. for example, willard finds that òmost of the companies have filtering categories inwhich they are blocking web sites . . . known to be of concern to people with conservativereligious valuesñsuch as [web sites involving] nontraditional religions and sexual orientationñin the same category as material that no responsible adult would consider appropriatefor young people.ó she also notes that òbecause filtering software companies protect theactual list of blocked sites, searching and blocking key words, blocking criteria, and blockingprocesses as confidential, proprietary trade secret information it is not possible to prove ordisprove the hypothesis that the companies may be blocking access to material based onreligious bias.ó at the same time, willard finds that while òinformation about the religiousconnections can be found through diligent search, such information is not clearly evident onthe corporate web site or in materials that would provide the source of information for localschool officials,ó though she acknowledges openly that òit is entirely appropriate for conservative religious parents or schools to decide to use the services of an isp that is blocking sitesbased on conservative religious values. it is equally appropriate for parents to want theirchildren to use the internet in school in a manner that is in accord with their personal familyvalues.ó see nancy willard, 2002, filtering software: the religious connection, center for advanced technology in education, college of education, university of oregon, available onlineat <http://netizen.uoregon.edu/documents/religious2.html>.29as with so many other ònulló observations, the absence of complaints about overblocking can be interpreted in many ways. one interpretation is, of course, that overblocking simply does not occur very much (and/or that filters do not block a great deal ofuseful and appropriate information). but information collected through site visits is notconsistent with this interpretation, and testimony to the committee suggests other explanations as well. for example, the relative lack of complaints may be partly explained by theyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.288youth, pornography, and the internetin the various site visits conducted by the committee, only a few students or parents reported making a formal complaint to the school about asite needed for research or schoolwork that was blocked by a schoolõs filter,even though they (mostly high school students) often reported that information on the blocked sites might have been useful for legitimate academicresearch purposes.30 (the same was not true with most teachers, whoreported that educationally relevant sites were blocked regularly. still, in anumber of cases, they were able to use their supervisory privileges to obtain access to blocked sites.) and, given that schools and libraries installfilters largely to forestall complaints, it is clear that filters that do not generate complaints would be highly preferred.as for labelbased filters, the labeling party can be either the contentcreator or any third party. however, it is the adult or adults directlyresponsible for determining what a child should or should not see whomake the actual decision about how content labeled in a certain mannershould be handled.because the vendorõs philosophy regarding inappropriate material isthe primary determinant of what will and will not be blocked, trust is afundamental element in the userõs selection of a filter. that is, the userplaces considerable trust in the vendorõs judgment about what is and isnot appropriate (or in the case of labeling, places trust in the labels determined by various content raters). thus, a person who wishes his or herreligious values to be reflected in the content that is accessible to his or herchildren might choose a filter or a contentlimited isp that is sold by afirm with similar religious commitments. a person who wishes his or herchildrenõs internet experience to be limited to positive, developmentallyfact that filters for institutional use are increasingly flexible (see section 12.1.4). if blockedpages that are needed for educational purposes, for example, can be obtained quickly (e.g.,in a matter of minutes), the issue of overblocking need not be as salient. (one school systemtold the committee that a filter used previously had not allowed such flexibility and hadresulted in a large number of complaints from teachers and students. other faculty andlibrarians in other locations told the committee that unblocking sites was cumbersome anddifficult.) a second reason for the lack of complaints is likely to be the fact that once a filteris in place, the expectation of users is that access will be filtered. the committee heardstories of a number of complaints regarding filtering when filters were first installed, but inmost such instances, the complaints ceased after a few months. students without homeinternet access seemed to accept a schoolõs filtering policy as a given, and simply adaptedto it, even if they were prevented from accessing valuable information. one librarian toldthe committee that a blocked web page was analogous to a book that was not present in thelibrary, and that the alternative approaches to obtaining the information were similar tousing interlibrary loan. students with internet access at home have no particular reason orincentive to complain aside from issues of efficiency or convenience.30in general, when students encountered blocked sites at school, they simply went toanother venue to reach those sitesñmost of the students to whom the committee spoke hadunfiltered home access.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.289technologybased tools for usersappropriate, and educational material may choose a filter or a contentlimited isp that explicitly screens content for such criteria, rather thananother vendor that might screen content for inappropriateness.finally, òviewpoint discriminationó (discussed in chapter 4) generally cannot be practiced by public institutions, but the law in this area iscurrently unclear. in particular, it is not clear how a court would decidewhether a public institutionõs use of a particular filter vendorõs determinations of inappropriate material constitutes such discriminationñforinstance, where the line is drawn between viewpoint discrimination andcontent discrimination, and what weight should be given to the extent towhich the institution relied upon the filter vendorõs settings. it is also notclear to what extent public schools, as opposed to public libraries, mayengage in certain kinds of viewpoint discrimination.12.1.4how flexible and usable is the product?serverside filters can be easier to use than clientside filters, if onlybecause they do not require installation on the client. nevertheless, almost all filters allow some degree of customization to a parentõs (or otheradult supervisorõs) requirements. filters can (but do not necessarily) allow flexibility in many dimensions:¥changes to the criteria used for blocking. sites or keywords to identifyinappropriate material can be added or subtracted by the end user: when afilter program erroneously blocks a site, or fails to block something the userdeems inappropriate, the parent or other administrator of the program cancreate an exception list that deletes or adds the site from or to the black list.an important consideration is the extent to which the blocking criteria areknown to the user. while nearly all filter vendors provide a list of categories that are blocked, very few provide a public list of all of the sites on theirdefault òto be blockedó list,31 and to the committeeõs knowledge, no filter31in general, they protect the list by encrypting it and had hoped that the digital millenniumcopyright act (dmca) would outlaw reverse engineering to decrypt such lists. however, onoctober 27, 2000, the u.s. copyright office issued its final rule implementing the anticircumvention provisions of the dmca. the statutory provisions of dmca prohibit the circumvention of technical measures that prevent the unauthorized copying, transmission, or accessing ofcopyrighted works, subject to this rulemaking of the copyright office. the final rule establishestwo exceptions to the anticircumvention provisions, one of which allows users of internetcontent filtering programs to view lists of web sites blocked by such software. the copyrightoffice recognized a first amendment interest in access to this information and stated the needfor circumvention in this instance òsince persons who wish to criticize and comment on themcannot ascertain which sites are contained in the lists unless they circumvent.ó this exceptionto the dmca rule may have an impact on the ongoing public debate about filters. in march2000, two programmers who revealed the list of thousands of web sites blocked by the internetfiltering program cyberpatrol faced charges of copyright violation.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.290youth, pornography, and the internetvendor provides a list of the objectionable words sought in keywordsearches. most companies that do not release the list of blocked sites regardsuch lists as intellectual property and argue that the nonrelease protectsthe effort that went into creating them. however, if users of these productsdo not know the criteria explicitly, they will know that sites are blockedonly when access to those sites is blocked and they are told that they havebeen blocked. thus, they cannot make an a priori determination of such afilterõs fitness for use.¥ease of making authorized changes. a filter to which anyone canmake changes would not be very useful. in general, the ability to makechanges is restricted to òauthorized parties.ó the effort and time neededto implement a change can vary. some filtering systems allow individuals (e.g., teachers, librarians) with the appropriate password to add orsubtract a site or a keyword essentially instantaneously. others requirethe submission of a request to the filter vendorñwhich then evaluates therequest and implements it or not at its discretion, a process that may takedays or even longer. for educational purposes, the former is likely to bemuch better than the latter. on the other hand, increasing the effortneeded to implement a change is likely to reduce the number of changesto the original filtering policy, an outcome that may be regarded as abenefit for those who want to enforce a uniform policy, or who have littlefaith that adult supervisors will act judiciously.¥granularity of content categories. different vendors divide òinappropriateó material into different categories, using more or fewer categoriesdepending on their intended user base. categories may be divided intosubcategories (e.g., òsexó might be divided into òpornographyó and òsexeducation,ó or nudity might be differentiated as òfull frontal nudityó versus òpartial nudityó).¥age or grade differentiation. as discussed in chapter 5, informationthat is inappropriate for one age or grade level may not be inappropriatefor older ages or higher grade levels. (specifically, the information needsof high school students are typically different from those of students inmiddle school.) some filters allow more or less restrictive filtering depending on age or grade.¥individually configured filtering policies. in a home context, a parentmight wish to have different filtering policies (or none at all) for childrenof different ages. (such differences would reflect the parentõs belief thatolder children with more maturity and a broader scope of informationneeds might also require broader and less restricted internet access.) tosupport different filtering policies, a filter would require the child to loginto the system so that the childõs individual filtering profile could beused. individual policies can also support age or grade differentiationñrequiring a student to log in with his or her grade (or associating a gradeyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.291technologybased tools for userswith an individual login). in a library context, an ageappropriate filtering policy might require the system to ask the user if he or she were over18, and if under 18, ask the user to enter his or her age, thus providing theinformation necessary to set an ageappropriate policy.many filtering products add a variety of features meant to offer parents, teachers, and others even further control. some of these include:¥time windows for blocking. under some circumstances, the inappropriateness of a site may depend on the time of day. for example, in aschool environment, sites referring to games and media entertainmentmay be inappropriate during school hours (because they constitute òofftaskó material) but appropriate in an afterschool program in which internet usage may be less restricted.¥records or logs of attempted access to inappropriate materials. to understand patterns of usage, records of attempted access may be kept.note that such records, if individual logins are not used, can reflect attempted usage only from a given access point; further, if individual loginsare not used, no records can be matched to individuals.¥bidirectional filtering. some filters enable the blocking of certainoutgoing userentered information, such as phone numbers, addresses,foul language, and so on. such blocking can be used to promote thesafety of children and to enforce prohibitions against giving out suchinformation. in addition, some filters can block certain types of internetaccess entirely: instant messages, email, chat rooms, file transfers, and soon. as noted in chapters 2 and 5, email, chat rooms, and instant messages allow the child to send as well as to receive, and thus to engage intextbased interaction with other parties. file transfers allow images,video clips, and sound files to be sent and received. usenet newsgroupsñsimilar to bulletin boardsñcontain a great deal of content that is unmoderated and inappropriate for children by the standards of manyadults.in general, flexibility adds to the complexity of the filterñusually inits initial configuration and sometimes for its use. for example, there isdebate about whether consumers prefer less nuanced granularity andsimpler choices, or prefer to have detailed control over their filtering.some products have garnered praise for offering a simple agebyagedefault set of parameters on what to block that may then be overriddenwith more levels of nuance.in a number of filterusing sites visited by the committee, the flexibility of an installed product (especially the ability to unblock selected websites) was not used by administrators and teachers. in some cases, theyyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.292youth, pornography, and the internetwere simply unaware of the capability; in others, they lacked either thetime or the knowledge to do so. in still other cases, the ability to unblocksites was limited to districtlevel administrators (rather than the localadministrators or teachers). during site visits, a number of teachers toldthe committee that requests sent to districtlevel administrators to override sites often met with resistance, and were slowly acted on and oftenrefused. furthermore, to the extent that flexibility is tailored for differentindividuals (e.g., for middle school students versus high school students),identification of these individuals is requiredñand the appropriate policymust be mapped to the access points of those individuals.an additional dimension of functionality is the provision of explanations for blocking. a site that is blocked for no apparent reason has alower perceived legitimacy than a site that is blocked for a stated reason.for example, many filters tell the user that a site has been blocked becauseit falls into category x, where x may be pornography, sex education,weapons, violence, and so on. by contrast, a site that is blocked simplywith the message òaccess deniedó does not provide the child with usefulfeedback, and may increase his or her motivation to go to a nonblockedaccess device to retrieve the information. note that filtered search engines provide the lowest level of transparency of allñbecause a filteredsearch engine never returns even a link to content that is deemed inappropriate, the user has no way of knowing what has been filtered out or eventhat anything has been filtered out.12.1.5what are the costs of and the infrastructurerequired for filtering?financial costsas with all technology deployments, the financial costs of using filters can be divided into acquisition costs and maintenance costs. acquisition costs can be quite low, especially for serverbased filters in which aninstallation of the filter at each access point need not be undertaken.maintenance costs of serverside filters are usually absorbed into a peryear perseat charge.however, payments to the vendor are not the only cost, as some onsite effort must be made to ensure that filters are working properly. onsite technical support is generally necessary. management of the environment must be taken into account as wellñin particular, teachers,librarians, and parents may be faced with managing requests to unblocksites that are blocked. in an institutional environment, there are costs ofteaching the responsible adults what the filter can and cannot do, andproviding training that familiarizes them with operating in a filtered enyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.293technologybased tools for usersvironment. when filtering impedes their own legitimate searches for information, they must know how to obtain that information despite thepresence of filtering. and, for those institutions that rely on centralized(e.g., districtbased) administration of the unblocking function, the stafftime needed to manage these decisions can be significant (and hencecostly).use of contentlimited isps appears to entail fewer financial coststhan the use of serverside or clientside filters. because the major sellingpoint of using a filtered isp is that the user gets to delegate to anotherparty all of the responsibilities of deciding upon and enforcing a filteringpolicy, it is likely that users will be comfortable for the most part with thedefault policy of the filtered isp. thus, the costs of filtered isps for thisclass of users will be relatively small. also, filtered isps makes the cost ofupdating the filtering algorithm or database invisible to most users.one trend pushing toward the lowering of filtering costs is that thebasic technology of filtering is increasingly available in certain commonhardware products. for example, a variety of hardware routers for homeor small office use (generally to support a small local area network at ahome or office site) have native sitebased filtering capabilities (that is,they have the ability to exclude traffic from specified sites). some alsohave the ability to search for objectionable keywords embedded into siteurls. if trends toward hardwarebased filtering continue, such filteringmay well become ubiquitous. if and when vendors of these hardwareproducts provide these routers with lists of sites to be blocked, with updates as a service to purchasers, the cost may well drop significantly.restrictions on information flowas noted in chapter 5, it is likely that in most communities therewould be a rough consensus on some kinds of sexually explicit materialon the internet that should be made unavailable to children. but on otherkinds of sexually explicit material, such consensus would be unlikely.moreover, some of such material would undoubtedly constitute protectedspeech according to established first amendment interpretations.the discussion in section 12.1.2 points out that overblocking is inherent in any process that makes decisions about what to filter (so isunderblocking, but underblocking is not a restriction on information).thus, for inappropriate sexually explicit material that might loosely beclassified as òfor adults only,ó some material that should not be placedinto this category will beñand will therefore be improperly blocked.filter vendors often provide options for blocking entire categories inaddition to the category of sexually explicit material: violence, weapons,prochoice and antiabortion material, gay and lesbian lifestyles, and soyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.294youth, pornography, and the interneton. much of the material in these categories does not fit the legal definition of material that is òobscene with respect to minors,ó but based in thedefault setting of many filters, would be blocked anyway. while thisrestriction is not a legal problem in the context of home use, it may presenta problem in publicly funded institutions, which are constrained by therequirements and current interpretations of the first amendment.32in an educational context, the restrictions on information flow associated with filters may lead to substantial problems for teachers and librarians who are trying to develop useful and relevant educational activities,assignments, projects, and so on. indeed, some teachers reported to thecommittee during site visits that sometimes their lesson preparations werehampered by the fact that their internet access was filtered at school. inother cases, when they prepared a lesson plan at home (with unfilteredinternet access), they were unable to present it at school because a sitethey found at home was inaccessible using school computers.restrictions on information flow may also reduce the benefits of theinternet as an information retrieval mechanism. specifically, one of theadvantages of the internet is that it facilitates the comparison of howdifferent sources treat a given topic. while it is true that there are oftenmany unblocked sources for basic information (and hence blocking anyone of these sources may not be critical in this context),33 advanced workin which the specific source providing information affects its presentationor credibility is more adversely affected by overblocking. such might alsobe the case when alternative political points of view or analyses may beblocked as being inappropriate.psychological costsanother potentially major cost of filters is that their use reduces opportunities for young people to practice responsible behavior on theirown. that is, to the extent that filters work as they are intended (i.e., theyblock rather than discourage access to material that may be inappropriate), children have fewer opportunities to chooseñand thus fewer oppor32a study by the kaiser family foundation found that among teenagers aged 15 to 17who have sought health information online, 46 percent reported that they experiencedblocking from sites that they believed were nonpornographic. for example, 15 percent ofthose who were blocked reported that they were searching for information on sexual healthtopics. see rideout, 2001, generation rx.com: how young people use the internet for healthinformation.33because of keyword filtering, sites containing certain keywords may be blocked. however, synonyms to these keywords may not be filtered, and sites with these synonyms willnot be blocked.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.295technologybased tools for userstunities to learn how to make responsible decisions. such children maywell have greater difficulty in developing internal standards of appropriateness. in addition, while some youth have reported that the use offiltering by their parents makes them feel loved, others have reported thatit makes them feel untrusted by their parents.filters also create forbidden fruitñin this context, specific contentthat is made (more) desirable simply because it is inaccessible. a common response to forbidden fruit is to engage in more active and determined efforts to obtain it. given the technological sophistication of someteenagers, these efforts often succeed. even worse, from the standpoint ofminimizing exposure of children to such material, the results of technicalcircumvention efforts are often widely circulated, with the ultimate effectof greater exposure to inappropriate material rather than less, at leastwithin the immediate circle of individuals close to those with the necessary skills.the introduction of filters may also serve to create resentments andresistance among the children to whom they are targeted. that is, because filters are explicitly intended to limit oneõs freedom of access, it isentirely possible that introducing filters, especially into an environmentin which unrestricted access was the rule, would create tensions and anger in the children against those responsible for the decision. this dynamic is likely to be most significant in a family environment, in whichparental rules are generally negotiated to some extent with children.finally, unfair treatment of youth can result from the use of filters. ayoung internet user, knowing that the web sites she or he is viewing arefiltered, can make the reasonable assumption that what is not filteredconforms to parental or organizational policy (e.g., an acceptable usepolicy, as discussed in chapter 10), and thus that access to those unfiltered sites is not restricted. however, because filters inevitably allowsome inappropriate material to pass, this may not be a good assumption,and a child who relies on a filter that allows objectionable material to beviewed can get into trouble with parents or organizational authority.infrastructurebecause a critical issue in filtering is the extent of underblocking andoverblocking, users are well advised to test in advance what may beimproperly blocked or passed. apart from this predeployment testing,source or contentbased filters require minimal infrastructure. however,labelbased filters require content providers or third parties to cooperatein labeling content. to develop such an infrastructure, providers andthird parties must have incentives to label content. the minimal successyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.296youth, pornography, and the internetof labeling schemes for internet content to date suggests that the presentenvironment does not provide such incentives.34note also that labeling by third parties entails essentially the sametype of effort that must be undertaken by filter vendors to develop lists orcriteria for inappropriate content. for labeling to be useful, a large volume of information must be examined and rated; otherwise, the user isleft with the choices described in section 12.1.3.recognizing that the primary impediment to the success of ratingschemes is the extent to which internet content is currently not labeled,the internet content rating association (icra) has undertaken a globaleffort to promote a voluntary selflabeling system through which contentproviders identify and label their content using predefined, crossculturalcategories (box 12.4). icra is a global, nonprofit organization of internetindustry leaders committed to making the internet safer for children whilerespecting the rights of content providers.according to icraõs chief executive officer, icra hopes that over thenext several years the most popular web sites and portals, those accounting for the most internet traffic, will have labeled with icra. if theseefforts are successful, icra labels will be associated with sites that account for a large fraction of web traffic, though not necessarily with alarge fraction of existing web sites. the operators of these sites willencourage their business partners and the sites they host to use icralabeling. (however, because these sites do not in general have a businessrelationship with other web sites that might turn up through use of theirsearch engines, these other web sites cannot be expected to be labeled ingeneral.)another approach is to mandateñby government fiatñthe labelingof all web content. but such an approach involves a number of significantissues:¥such compelled speech raises important first amendment issues.¥the enforcement of label accuracy is complex. even labels createdby the content owner may be inaccurate.¥the volume of web information is so large that a government mandate requiring labeling would impose an enormous expense on contentproviders.34it is interesting to note that industry labeling initiatives in other media have been moresuccessful and widely accepted and used; these other media include movies (through thempaa), tv (through a joint effort of the motion picture association of america, the national association of broadcasters, and the national cable television association), andsoftware cdroms and games (through the interactive games developers association).one reason for this success is that the volume of content produced in these media is muchsmaller than the volume of content produced for the web.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.297technologybased tools for usersbox 12.4the labeling system of the internet content rating associationthe internet content rating association (icra) labeling system takes the presence or absence of the following factors into account in generating content labels:violencesexual violence/rapeblood and gore, human beingsblood and gore, animalsblood and gore, fantasy characters(including animation)killing of human beingskilling of animalskilling of fantasy characters (includinganimation)deliberate injury to human beingsdeliberate injury to animalsdeliberate injury to fantasy characters(including animations)deliberate damage to objectsnone of the abovecontextñthis material . . .¥appears in a context intended tobe artistic and is suitable for youngchildren¥appears in a context intended to beeducational and is suitable for youngchildren¥appears in a context intended to bemedical and is suitable for youngchildren¥appears only in a sportsrelatedcontextlanguageexplicit sexual languagecrude words or profanitymild expletivesnone of the abovechatchatmoderated chat suitable for childrenand teensneither of the abovenudity and sexual materialerections or female genitals in detailmale genitalsfemale genitalsfemale breastsbare buttocksexplicit sexual actsobscured or implied sexual actsvisible sexual touchingpassionate kissingnone of the abovecontextñthis material . . .¥appears in a context intended tobe artistic and is suitable for youngchildren¥appears in a context intended to beeducational and is suitable for youngchildren¥appears in a context intended to bemedical and is suitable for youngchildrenother topicspromotion of tobacco usepromotion of alcohol usepromotion of drug usegamblingpromotion of weapon usepromotion of discrimination or harmagainst peoplematerial that might be perceived assetting a bad example for youngchildrenmaterial that might disturb youngchildrennone of the abovesource: see <http://www.icra.org>).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.298youth, pornography, and the internet¥web content can be posted in many different national jurisdictions,and it would be easy for content creators and providers to evade such amandate by moving offshore.apart from governmentrequired content labeling, the widespreaduse of labels will turn on private incentives. incentives can be positiveñby labeling, a content provider or creator could receive some financialbenefit, either directly or by attracting more parties to its content. however, the committee did not see a compelling business case for how content providers or creators can benefit commercially from labeling, andtestimony to the committee indicated how difficult it is to develop childfriendly internet businesses. or, incentives can be negativeñby labeling,a content provider or creator might receive immunity from prosecution(for example, for obscenity) for the content being labeled (e.g., as adultsonly). such a safe harbor might be particularly applicable in labeling ofsexually explicit material (as discussed in section 9.3).to date, childcentered contentlimited isps are small enterprises, andmany efforts to establish a viable business model for providing good,attractive, and educational content for kids have foundered, as noted inchapter 10.35 thus, it is an open question whether children will be able totake advantage of consistent, dependable, longterm service of this naturenote also that because content is explicitly vetted for appropriateness, itis likely that the content offered by such isps would be more limitedñand hence more suitable for younger children whose information needsare generally less than those of older children.by contrast, certain internet portals, such as yahoo and lycos, havesearch engines that search only within the appropriate (and educational)childoriented universe of content. available for free, these search engines return only links to appropriate and educational content, and aslong as the child does not surf outside these links, a responsible adult canhave confidence in his or her childõs activity.12.1.6what does the future hold for filtering?imageonly filteringvisual imagery often results in a highly visceral impact compared totextual descriptions of the same image. as discussed in section 6.3.3,males tend to respond to visual sexual imagery more than females do.35of course, entrepreneurs in other areas are also struggling to find viable longterminternet business models.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.299technologybased tools for usersand, as a general rule, sexually explicit text does not generate nearly thesame controversy that sexually explicit imagery generates.36a filter that blocks images on web pages that have been determinedto be inappropriate rather than all of the content of the web pages themselves is thus well suited to meet this concern. most of todayõs filtersblock specific web pages, based on criteria established by their filteringpolicies. but there is no technical reason that the filter could not insteadblock all images contained on those web pages, while passing through alltext on those pages. (however, icons and text rendered in image format,such as those in banner advertisements and sidebars, would be blocked aswell. and, concerns about overbreadth of blocking would remain, so thatgiven images of the greek gods, leonardo davinciõs vetruvian man,paintings by rubens, and michelangeloõs david might still be blocked.)such a filter addresses many of the concerns raised by students, teachers, and librarians about children who need information that would otherwise be blocked by a pageblocking filter; as a general rule, such information is presented textually and would be passed by an imageblockingfilter. of course, to the extent that the concerns of filter advocates involvetext, an imageblocking filter is not helpful.a more sophisticated approach to filtering of embedded imageswould involve analyzing them. very small images are likely to be onlyicons, and very small images (say 200 x 200 pixels) do not convey muchexcitement. the content of larger images could be analyzed using technology described in section 2.3.1 and appendix c, and if found to besexually explicit, those images would be blocked (subject to all of thedifficulties inherent in image recognition).selective degradation of serviceas discussed in chapter 8, it is possible to reduce the appeal ofdeliberate contact with inappropriate material. such an approachchanges the yes/no approach to filtering to one in which the user canstill gain access to material that might have been improperly classifiedas inappropriate, but only at some cost. two easy technical methods todo so are slowing down the speed with which images of offensive content are displayed or reducing the visual resolution (or the audio fidel36in the future, it may be possible that other kinds of content (e.g., sound files associatedwith sexually explicit content) will be regarded as being as objectionable as images. (recallthat òdialapornó services had some appeal for adolescent youth, and that the availabilityof such services to minors created significant controversy in the early 1990s.) if that futurecomes to pass, the media containing such particularly objectionable content might also beselectively blocked (e.g., by blocking all sound files on sexually explicit web pages).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.300youth, pornography, and the internetity) of such images. presuming that such content can be identified, achild who must wait a few minutes for an image to be displayed is likelyto lose patience with it. such a tactic is most relevant if the child knowsthat the image being sought is inappropriateñit reduces the immediategratification usually available from internet downloads, and it increasesthe risk of being discovered in the act. (it also provides more time forthe child to reflectñdo i really want to do this? am i being responsible?) similarly, an image of significantly reduced resolution is far lessappealing than one with high resolution. another possible approachdepends on penalizing the user after viewing inappropriate content byautomatically logging out, freezing the computer so that a reboot isnecessary, or simply delaying for several minutes the childõs accessingof other internet content.approaches that depend on degradation of service force the child tomake decisions about whether the cost and inconvenience of access are worththe appeal of accessing content that adults might deem inappropriate.bundling filters with other functionalityfilters are a specialpurpose tool. parents and others who purchaseand install filters or filtering services thus can be assumed to feel that theproblems raised by unfiltered internet access are worrisome enough towarrant such efforts. however, other individuals may be concerned butreluctant to foster resistance or resentment that their introduction mightgenerate (as discussed under òpsychological costsó in section 12.1.5).for such individuals, associating filters with packages that provide otheruseful features may make it easier to obtain the benefits of filtering. forexample, parents wishing to obtain filtering services might subscribe to acontentlimited isp, and òselló it to their children on the basis of additional content that the isp would make available to them.warning rather than blockingbuilt into any filter is a specification of content that should be blocked.instead of blocking access, a filter could warn the child of impendingaccess to inappropriate material, but leave it to his or her discretionwhether or not to access the material. because the child does havechoices, such a feature would have pedagogical advantages with respectto helping children to make responsible choices, assuming an environment structured in a way to facilitate such assistance. (a feature towarn of impending access to inappropriate material might or might notbe combined with logging of such accessña point discussed in section12.2 below.)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.301technologybased tools for usersopportunities for internet safety educationbecause childoriented contentlimited isps are oriented toward providing information especially for kids, they provide unique opportunitiesfor internet safety education. for example, these opportunities mightinclude material that provided context for children and explained concepts about judging the value and or validity of the site being flagged orblocked.future prospectsover time, filtering is likely to gradually improve, decreasing bothunderblocking and overblocking. however, these improvements will almost certainly be incremental rather than revolutionary, and users wouldbe well advised to view with some skepticism claims of revolutionaryimprovement. (for example, the phenomenon of blocking breast cancersites because a user performed a search for òbreastó is now rare. however, the reason this particular error is no longer frequent is that manyusers complained about it, and breast cancer sites were specifically takenoff the black list.37)one goal is quite unlikely to be metñthe generation of a class ofobjectionable or inappropriate material from a single example. it wouldbe highly desirable for a user who has received an objectionable image(for example) to be able to tell a filtering program, òi donõt want to see anymore stuff like this.ó but what counts as òlike thisó is virtually impossibleto generalize from one example, which is why even the best trainingsystems today require hundreds or thousands of samples of objectionablematerial to offer any hope of even a minimally adequate categorization ofmaterial.12.1.7what are the implications of filtering use?todayõs filters cannot be the sole element of any approach to protecting children from inappropriate sexually explicit material on the internet37the first widespread instance of such blocking occurred in 1995 when a major onlineservice provider blocked all sites containing the word òbreast,ó including those dealingwith breast cancer. in the wake of widespread complaints, the service provider in questionquickly restored access to breast cancer sites. since then, this particular problem has occurred only rarely, as a number of techniques described in section 2.3.1 can be used toavoid problems arising from simpleminded keyword matching. still, the problem has notbeen eliminated entirely, and a recent instance of a web site involving breast cancer beingblocked was brought to the committeeõs attention in january 2002 (personal communication, bennett haselton, peacefire.org). in this instance, the reason for such blocking apparently arises from the use of ipbased virtual hosting.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.302youth, pornography, and the internet(or any other inappropriate material), and it is highly unlikely that tomorrowõs filters will be able to serve this role either. but they can be auseful element, as long as their limitations are kept in perspective. inparticular, with or without filters, internetusing children will have opportunities for encountering some nonzero amount of inappropriatematerial, and thus regardless of the benefits that filters do confer, theywill have to internalize codes of conduct and appropriate online behaviorif they are to be safe.using a childoriented contentlimited isp is approximately analogous to allowing a child to watch only selected videos on television, ratherthan broadcast or cable television. and, as in that case, the use of such apractice is most likely appropriate for fairly young children. however, asa childõs internet information needs outgrow what a kidfriendly servicecan provide, he or she will have to turn to other sources. other sourcesñby definitionñwill provide information that is less thoroughly vetted,and will likely involve exposure of the nowolder child to some inappropriate information; however, an older child may well be better able tocope with inadvertent exposures to such material. furthermore, there isno guarantee that the point at which a childõs information needs outgrowa kidfriendly service will coincide with the point at which he or she cancope well with such exposure, and it is likely that the former point occursearlier than the latter point.as for server and clientside filtering, it is helpful to regard suchfiltering as òtraining wheelsó for children on the internet as they learn tomake good decisions about what materials are and are not appropriate fortheir consumption. an adult who explains the purpose of the filter to thechild (and different explanations are appropriate at different ages), andwho can provide some inperson guidance when the child first encounters blocked material, is in a much better position to help the child internalize the rules than an adult or institution that simply installs the filterwith no explanation or rationale either before or after the fact. indeed, thelatter situation is what the detractors of filters have in mind when theyargue that the use of filters can lead to a false sense of security: a filteruser (parent, library, school), knowing that a filter is in place, will then betempted to assume that all is well, and then fail to exercise appropriateoversight or to take other measures when such oversight or other measures would still be necessary.underlying much of the concern about the deployment of filtersñeven on a voluntary basisñis a fear that the creation of a technical infrastructure that supports filtering will inexorably, over time, lead to evenstronger pressures for formal content regulation (a socalled òslipperyslopeó argument).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.303technologybased tools for usersfurthermore, even without the pressures for formal content regulation, those advocating the free flow of information are concerned thatauthorities (parents, schools, libraries, businesses, and others) will findthe use of filters irresistible to block any kind of content or informationthat they find objectionable, and not just for children. (just such a sequence of events was related to the committee in one of its site visits: acountywide library system installed filters to block sexually explicit material from all patrons, not just children, though the concerns were firstraised in the context of childrenõs access to such material.)12.1.8findings on filters1.filters have some significant utility in denying access to contentthat may be regarded as inappropriate. however, many of todayõs youthhave access to unfiltered internet venues (e.g., at home, at a friendõshouse), and school and library filters do not block content accessed fromthese other venues.2.all filtersñthose of today and for the foreseeable futureñsuffer(and will suffer) from some degree of overblocking (blocking content thatshould be allowed through) and some degree of underblocking (passingcontent that should not be allowed through). while the extent of overblocking and underblocking will vary with the product (and may improve over time), underblocking and overblocking result from numeroussources, including the variability in the perspectives that humans bring tothe task of judging content.3.filters are capable of blocking inappropriate sexually explicit material at a high level of effectivenessñif a high rate of overblocking is alsoacceptable. thus, filters are a reasonable choice for riskaverse parents orcustodians (e.g., teachers) who place a very high priority on preventingexposure to such material and who are willing to accept the consequencesof such overblocking. (for example, these individuals may be more inclined to take such a stance if the children in question are young.) suchconsequences may include the blocking of some material that would bemistakenly classified as inappropriate sexually explicit material, and/orthe blocking of entire categories of material that are protected by the firstamendment (a consequence of more concern to publicly funded institutions such as public libraries than to individual families).4.automated decision making about access is generally inferior todecision making with a responsible adult involved in the decisionmaking process. furthermore, to the extent that the content of concern is inmultimedia formats and unaccompanied by textual descriptions, automated decision making is subject to a high degree of overblocking (idenyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.304youth, pornography, and the internettifying content as objectionable when it is benign) and underblocking(identifying content as benign when it is objectionable).5.to the extent that internet content is created or produced in realtime (e.g., a live videoconference over webcams), it will be impractical toinsert a human reviewer into the decision making process about whetheraccess to that content should or should not be grantedñthus weakeningthe role that filters play.6.overblocking must be distinguished from overly broad blockingpolicies. overblocking is a mistakeñcontent is blocked that should nothave been blocked, even in the judgment of the human being responsiblefor identifying content that should be blocked (the censor). overly broadblocking policy represents a disagreement with that human being inwhich the content seeker asserts that certain content should be accessibleand the censor believes that content should be blocked.7.based on information gathered in its site visits, the committee believes that filters are deployed by schools and libraries at least as much forpolitical and management reasons as for the protection of children, because the deployment of filters enables staff to pay more attention toteaching and serving library patrons.8.because most filters are deployed to forestall complaints, and complaints are more likely to be received about underblocking rather thanoverblocking, filter vendors have more incentive to block content thatmay be controversial than to be careful about not blocking content thatshould not be blocked.9.transparency of operation is important, in the sense that filtersthat inform a user that a site is being blockedñand that provides thereason for blockingñare more likely to be seen as legitimate than thosethat do not provide such information.10.the use of blocking filters does not promote the development ofresponsible choice in children. with removal of the option of makingcertain choices, children are denied an opportunity to chooseñand hencedo not learn appropriate decision making skills from the fact of blocking.11.filters are a complement to but not a substitute for responsibleadult supervision. using filters without adult supervision and/or instruction for users in what constitutes appropriate behavior is not likelyto result in children learning what is or is not appropriate behavior. furthermore, filters cannot guarantee that inappropriate material will not beaccessed.12.2monitoringtools that provide monitoring of the internet activities of childrenhave been proposed by some as an alternative to filters in certain conyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.305technologybased tools for userstexts.38 tools for monitoring have not received nearly the same attentionas filters, but are potentially controversial as well. box 12.5 describes thedimensions of choice that getnetwise identifies for monitoring tools.12.2.1what is monitoring?monitoring, as a way of protecting youth from inappropriate content,relies on deterrence rather than prevention per se. in some cases, it is thethreat of punishment for an inappropriate act that has been caughtthrough monitoring that prevents the minor from behaving in an inappropriate manner. in other cases, òcatching someone in the actó canprovide an important òteachable momentó in which an adult can guideand explain to the child why the act was inappropriate, and why thiscontent is on the internet.monitoring a childõs use of the internet is a generic approach that canbe implemented in both technical and nontechnical ways. adult supervision of internet use, a nontechnical strategy, is discussed in chapter 10.but the technical methods for monitoring someoneõs use of the internetare many.¥the simplest means of monitoring are built into the browser or theoperating system. parents and other monitors do not need to rely on anyadditional technology to do this simple monitoring.38john schwartz. 2001. òschools get tool to track studentsõ use of internet,ó new yorktimes, may 21.box 12.5getnetwise questions about monitoring toolsdoes the product allow the user to review or monitor¥email?¥online chat?¥the web sites that have been visited?¥instant messaging sessions?¥offline (noninternet) computer use?can the product operate¥without the knowledge of the child being monitored?¥alongside a filter?¥to warn children when they attempt to access inappropriate material?youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.306youth, pornography, and the internetñthe major internet browsers have a òhistoryó file that indicates allof the sites visited most recently. (the time frame for which such historiesare kept can be adjusted by the userña typical default time frame is 20days.) such a history file can be easily viewed by an adult supervisor, astep that requires no additional technology and very little computer savvy.on the other hand, older kids may be knowledgeable enough to erase thehistory file (it takes just one click) or even to forge a history file withenough innocuous entries to allay suspicion.ñmost browsers make use of a temporary òcacheó that contains images that have been displayed on a userõs screen. inspection of this cachecan show most of the images that have appeared recently on a userõsscreen.ñcookie files can indicate the sites with which a child has interacted,as well as who has received information from the child. in windows, forexample, the cookie file is found in the windows program directory andcan be viewed using any text editor.¥commercially available monitoring systems go a step further:ñcertain devices and programs can capture all of the keystrokesmade by a child. thus, comments or input made by a child can be recorded for future inspection.ñthe workstation of a supervising adult can be set up to captureand/or display the contents of a childõs monitor in real time. thus, asupervisor (e.g., a teacher or librarian) could monitor what appears on achildõs screen from his or her office.ñemail is generally not encrypted in storage, and thus may be readable by an adult who is responsible for a child.monitoring tools can provide a variety of functions, enabling a responsible adult to review incoming and outgoing email, instant messageand chat room dialogs, web pages accessed, and so on. further, suchtools may or may not provide notification to the child that monitoring isoccurring.a monitoring tool can also use technology to identify inappropriatematerial (the same technology that filters incorporate) so that it can provide a warning to the child when he or she is about to be exposed toinappropriate material. the child can then decide whether or not to heedthat warning. if the child does not, the monitoring tool may or may notprovide a record of that access. warnings can also be accompanied bymaking a log of access to such exposures or notifying a responsible adultabout such access.depending on the tool selected, monitoring tools can be used at homeand in libraries or schools. one distinguishing characteristic is that monitoring tools generally require human responses to detections of access toyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.307technologybased tools for usersinappropriate information, or at least the threat of such a response. thus,a parent or librarian or teacher must be involved to talk to the minorengaged in inappropriate behaviorñand in institutional contexts the costof reviewing access logs and following up on these reviews would likelybe substantial.for monitoring to be effective, usage must be tied to specific individuals. thus, in an institutional setting, individual loginsñwhich tend to bemore common in higher grades than in lower onesñare necessary if monitoring information is to be acted on after the fact of inappropriate usage.39(if immediate action is taken, individual login information is not needed,since an adult can simply walk over to the internet access point and talk tothe child in question.) the same is true in a home setting, especially withmultiple individuals accessing one computer. indeed, without the abilityto associate a given web access (for example) with a given child, individualized guidanceñor punishmentñcannot be provided.as with filters, monitoring is also increasingly common in corporateand business settings.4012.2.2how well does monitoring work?because monitoring tools do not place physical blocks against inappropriate material, a child who knowingly chooses to engage in inappropriate internet behavior or to access inappropriate material can do so if heor she is willing to take the consequences of such action. however, thetheory of monitoring is that knowledge of monitoring is a deterrent totaking such action.note, however, that unless warnings are given repeatedly and in different forms, users are known to habituate rapidly to themñand behaveas though they had never been given.41 warningsñin and of them39note also that individual logins are a necessary though far from sufficient aspect ofmaintaining computer, network, and system security. in the absence of individual logins, itis essentially impossible to hold any specific individual responsible for actions that mightcompromise security. for more discussion, see, for example, computer science and telecommunications board, national research council, 1997, for the record: protecting electronic health information, and 1991, computers at risk: safe computing in the information age(national academy press, washington, d.c.). thus, there are advantages for institutions toconsider individual logins for reasons entirely apart from protecting their youth from inappropriate material.40see, for example, associated press, 2002, òim monitoring grows in popularity,ó april12. available online at <http://www.msnbc.com/news/737956.asp?0si=#body>.41see computer science and telecommunications board, national research council, 1996,cryptographyõs role in securing the information society, kenneth w. dam and herbert s. lin,eds., national academy press, washington, d.c.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.308youth, pornography, and the internetselvesñare not likely to deter inappropriate access in the long run. thesame habituation may not be true, however, of warnings or monitoringassociated with a human presence. an adult supervisor who forces anonroutinized interaction with a child has a far better chance of capturing his or her attention.browser histories log web sites that have been viewed, though tolearn the actual content of these sites, the adult supervisor must eitherexamine these web sites or make inferences about their content on thebasis of the siteõs url. keystroke monitors are equally capable in monitoring web sites, email, and anything else that requires user input. monitoring of screens being used by children, if done on a large scale (i.e.,many screens being supervised by one person), in practice monitors access to inappropriate imagery. text also can be monitored remotely, butin this case, the adult supervisor cannot tell at a glance if the text containsinappropriate material, and thus must spend more time in reading thattext to make a judgment.because monitoring leaves the choice of access up to the child, inadvertent access to inappropriate material is possible. (for this reason, monitoring is arguably less appropriate for children whose decision makingcapabilities have not matured.) but the child also retains the choice togain access to information that may be relevant to his or her informationneeds, and thus the problem of overblocking described in section 12.1.2does not exist.judgments about the effectiveness of monitoring are mixed. monitoringñcoupled with punishmentñhas deterrence effects at least in the shortterm and at least for some fraction of youth. but because the decisionmaking party is the youth, rather than an adult (e.g., the filter vendor),denial of access to inappropriate material cannot be assured. moreover,as with filters, a change of venue will often suffice to eliminate overtmonitoring.a critical dimension of monitoring is the kind of adult response thatis coupled to a detection of inappropriate access or behavior. if an adultoffers guidance and explanation rather than punishment (as is most appropriate if a violation is accidental), the youth may learn how to differentiateñfor himself or herselfñappropriate from inappropriate actions. tothe extent that this is true, protection from inappropriate material may beextended to nonmonitored venues and for much longer periods of time.(on the other hand, once clear explanations for rules have been provided,punishment for intentional infraction of rules is entirely appropriate fordemonstrating that infraction carries consequences.)another critical dimension is whether monitoring is covert or overt.covert monitoring, if undiscovered, is more likely to provide informationabout what the child is doing òwhen left to his or her own devices.ó and,youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.309technologybased tools for usersif undiscovered, the individual being monitored will not change venues.but covert monitoringñby definitionñcannot deter, because the youth inquestion must be aware that monitoring is happening if it is to have aneffect on his or her behavior.moreover, undertaking monitoring covertly leaves the question ofwhat the responsible adult should doñif anythingñin the event thatmonitoring reveals that the child is behaving inappropriately. if the adultdoes nothing except watch, learning that is directly coupled to inappropriate access or behavior cannot occur, and the inappropriate behaviormay well continue. yet, if the adult does respond to such a revelation, heor she may be forced to disclose the fact of monitoring, with all of theattendant consequences (e.g., a child who reacts negatively because theadult is changing the rules from what was expected).in principle, an adult could act without disclosing the fact of monitoringñfor example, the adult may draw the child into a general discussionof appropriate internet behavior without reference to any specifics thatmight be associated with the childõs behavior. however, many adults arelikely to find it difficult to act on such information without revealing thesource.overt monitoring can deter. but it can also have negative effects, asdescribed below.if monitoring is coupled to explanations and guidance about appropriate and inappropriate behavior, there is some potential that this application can promote the longterm development and internalization ofappropriate behavioral norms. but the explanation and guidance areessential. if, as is much more likely in an institutional setting and inmany home situations, the primary or exclusive consequence of detection of inappropriate access is punishment, such learning may well notoccur. even more destructive would be punishment resulting from inadvertent access to inappropriate material, as one can easily imaginemight be imposed by an adult supervisor who did not believe an assertion by his or her charge that the inappropriate web page was viewedby accident.finally, as with filtering, monitoring can be circumvented by a changeof venue in which monitoring is not present.12.2.3who decides what is inappropriate?decision making is shared between adults and youth. it is the responsibility of responsible adults (e.g., parents and school officials) toprovide general guidelines about what constitutes inappropriate materialor behavior. however, it is the responsibility of the youth to interpretyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.310youth, pornography, and the internetthese guidelines. and it is the interaction between adult and youth thatcan provide guidance in any particular instance.for those products that identify inappropriate material, the relevantdecision makers are the same as those for filtering.12.2.4how flexible and usable are products for monitoring?given the burden imposed on responsible adults when all access ismonitored, some monitoring products make a record only when inappropriate material has been accessed. of course, such a product requiresdefinitions of inappropriate materialñand all of the discussion above insection 12.1 is relevant to such definitions.monitoring can also be intermittent. for example, a product may takea òsnapshotó of a given computer screen that records its contents at random intervals that average once an hour. in this case, the auditing burdenis directly proportional to the frequency of screen capture and the numberof screens being monitored. monitoring software that never records thescreen when web content from an innocuous site is shown further reduces the number of snapshots that need to be reviewed.realtime display of a childõs screen can be performed at any level ofresolution desired. in the instance when the supervisorõs monitor displays simultaneously òscreen shotsó of multiple user screens (e.g., all ofthe monitors in use by a class), each image appears in a smaller òthumbnailó version that makes reading most text on those screens difficult orimpossible while at the same time usually enabling the supervisor todetermine if an image is being displayed. moreover, many inappropriatesexually explicit images are easy for humans to recognize even at lowresolution and/or smaller size. the product might then offer the supervisor the chance to òzoom inó on this screen shot for closer examination,and perhaps capture the image for documentation purposes.records of access may be kept or not, and if kept, at different levels ofdetail. for example, recorded screen images can be kept at high resolution, enabling the reading of words on the screen, or at low resolution,enabling only a general identification of pictures that may be on the screen.keystrokes can be recorded for differing lengths of time, enabling a supervisor to know in detail what the minor has done. and, some monitoring packages allow the tracking of timing and sequencing of access thatwould help administrators to distinguish between intentional and unintentional access.tools for monitoring web usage in the aggregate (without individualtracking of users) can provide important information on whether usageconforms to acceptable use policies. such tools would not compromiseindividual privacy (indeed, individual logins would not even be reyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.311technologybased tools for usersquired), but would provide data on the web sites children visited and theinternet activities in which children engage. such data could then bereviewed to determine the extent to which a given audience is in factconforming to an aup.if the system is configured to not monitor web browser windowswhere the same page has not been on the screen for at least some period oftime, perhaps 15 seconds, and to never monitor email where the sameincoming item has not been on the screen for at least that period of time,then the young person may not have the anxiety that òthe adults willdiscover i inadvertently saw this material, but wonõt believe it was unintentional.ó youth will know that as long as they quickly determine thatthe content is inappropriate, and exit that web site or that email, norecord will be established and no adult will know. to the committeeõsknowledge, current monitoring software does not have this òdo not capture within threshold feature,ó as it opens a potential loophole: a studentclicking through a series of pages of inappropriate web content, as longas each page is on the screen for less than the threshold time.12.2.5what are the costs and infrastructurerequired for monitoring?financial coststhe primary financial cost of monitoring is the human effort andlabor needed to monitor usage. monitoring records can be extensive, andin the absence of automated tools to flag questionable accesses, the examination of extensive audit records is both tedious and timeconsuming.(recording screen images frequently for a large number of users alsoconsumes hard disk space at a rapid rate.)a second cost in the institutional setting is that the effort needed tomanage individual logins is significant. login names and passwordsmust be managed, and procedures must be set up to deal with childrenwho lose or forget passwords, passwords that become known to otherindividuals, revocation of passwords and login names, and so on.42psychological and emotional costspunishment that is given soon after undesirable acts are initiated ismore effective in deterring a repetition of such behavior than is punishment administered long afterward, suggesting that monitoring systems42for more discussion, see cstb, nrc, computers at risk, 1991, and for the record, 1997.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.312youth, pornography, and the internetare unlikely to build positive habits in students unless feedback is received more quickly than may be practical in most situations. (feedbackis needed in minutes or hours, whereas review of access logs may takedays or weeks. on the other hand, realtime monitoring can provideopportunities for feedback to the child when the offense occurs.) to beeffective in deterring undesirable behavior, punishment must be consistent, which suggests that intermittent monitoring, which saves time andenergy, will not be conducive to helping students learn to resist the temptation of seeking out inappropriate materials. to be a component ofeffective discipline also requires that the basis for punishment (or consequences) not be seen as arbitrary authority but rather an explanation forwhy certain behavior is unacceptable.a second point is that monitoring and privacy can be antithetical.while the desirability of privacy as an element of an appropriate developmental environment is a cultural issue, most of western society placesprivacy in high regard, especially for adolescents who are at a developmental stage during which they often seek some separation from theirparents. a need for privacy is an essential component of separation asadolescents begin to create their own identity, an identity that includes anunderstanding of himself or herself as a sexual person.43 there are somepersonal issues that adults want to keep to themselves because they areembarrassed or have other feelings or behaviors that they do not want toshare generally. many children (especially adolescents) have those samefeelings. to deny them that personal freedom by constant electronic monitoring may convey a lack of trust by an adult community that tells themthat there is no personal space that belongs to them and them alone.monitoring can easily be regarded by youth as a violation of privacyand an unwarranted intrusion that demonstrates a lack of trust, and onecommon unfortunate consequence is that when mistrusted, an individualoften proceeds to act in ways that justify that mistrust. certainly parentsdo monitor their childrenõs activities, but the balance of how much children and adolescents are watched varies, depending on characteristicssuch as age, gender, maturity, and parenting practices. in general, achildõs need for personal freedom increases as he or she grows older.43according to a survey by the kaiser family foundation in 2001, teenagers place a highvalue on privacy with respect to their internet usage: 76 percent of online youth agreed thatòlooking up information online is good because i can look things up without anybodyknowing about it.ó where looking for health information is concerned, 82 percent said thatconfidentiality is very important. a sizable minority of young people are concerned aboutthe privacy of their online searches for information, with 40 percent saying they are worriedthat the computer might keep track of what they do online. see rideout, 2001, generationrx.com: how young people use the internet for health information.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.313technologybased tools for usersfurthermore, children who are constantly watched by parents haveless opportunity to develop their own internal controls about their ownbehavior. they have less opportunity to confront the challenges of lifethat ultimately develop character, for it is that struggle that makes us whowe are. parents cannot always watch their children. it is then that theeffectiveness of socialization is put to the test, for it is what children do inthe absence of a parent or an adult that tells of their character. a childwho has not internalized parental values may well attempt to break therules whenever an adult is not watching, for the rules are outside, notinside, the child. by contrast, a child who has internalized those rulesgenerally follows them, regardless of whether they are being watched.sometimes they will fail, but they can also learn from those mistakes.at the same time, the level of privacy that students can expect inschoolñin using a computer as well as in other aspects of school lifeñisdifferent from what they can expect at home, and school computer systems are not private systems. the expectation of privacy when studentsuse computers in schools is more limited, as demonstrated by a variety ofactions that have been supported in court decisions, including searches ofstudent lockers, backpacks, and so on. thus, provided that students havebeen given notice that their use is subject to monitoring, the use of monitoring systems raises fewer privacy concerns.in libraries, privacy expectations have traditionally been fairly high.that is, libraries have traditionally protected the materials used by theirpatrons, and have even resisted the efforts of law enforcement authoritiesto investigate such use. thus, monitoring in a library contextñeven withexplicit noticeñmay violate such privacy traditions.note also that technological monitoring has a different psychologicalrelationship to the one being monitored than does inperson oversight.consider, for example, a student using an internet access terminal in theschool library. in one scenario, a school librarian walks the floor periodically; if she sees something suspicious on the studentõs screen, she walksover and asks, òwhat are you doing?ó in a second scenario, the screen onthe internet access terminal is displayed on the school librarianõs terminal(in her office) for several seconds at random intervals ranging from onceevery 5 minutes to once every 20 minutes. five or ten seconds before theimage of the screen is transmitted to the librarianõs terminal, an unobtrusive but noticeable warning flashes on the studentõs terminal to indicatethat monitoring is about to take place. in addition, the display on thelibrarianõs terminal is blurred so that words cannot be read, but blurredimages can appear, and no records of the screen on the terminal are kept.if the school librarian sees something going on that warrants attention,she can leave her office, walk over to the student, and ask, òwhat are youdoing?óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.314youth, pornography, and the internetfor most people, the first scenario feels like responsible supervision.however, reactions to the second scenario are decidedly mixed, despitethe fact that the monitoring system described does nothing that the librarian does not do. what accounts for this mixed reaction?one factor is that the person being monitored from the librarianõsoffice would have no particular assurance, beyond the sayso of the librarian, that any of these assertions would be true. however, where themonitoring takes place by walking the library floor, it can be seen that thelibrarian is not taking photographs of the library patrons or their screens.but more importantly, the fact of technological monitoring is also likely tochange the nature of the relationship between school librarian and student. in the first scenario, the interaction between librarian and student isa human one, and the events have unfolded for the reasons that onewould expectña chance encounter that leads to an open question. but inthe second scenario, the school librarian approaches the student withapparent foreknowledge of what the student is doing, and the question ismore disingenuous than open. an additional point is that the foreknowledge provided by the monitoring system invites the librarian to jump toconclusions about what the student is doing, and she will be less likely togive the student the benefit of the doubt when she does engage him.under such circumstances, a useful educational experience is less likely tooccur than if she approached the user with an open mind.infrastructurewhile filters can be installed on the client side without the cooperation of any other party, realtime monitoring requires a mechanism fordisplaying the contents of one monitor on another. when tools for monitoring are used on a large scale, a sufficient number of responsible adultsis necessary to provide inperson intervention. (how many adults arerequired depends on how thorough the monitoring is.)an alternative is afterthefact review of behavior or actions, a process that requires storage of logs, screen snapshots, and so on, and automated tools to flag suspect behavior. the administrative burdens can besharply reduced if the records reflect only potentially suspect accessesand exposures rather than all internet use.12.2.6what does the future hold for monitoring?as noted above, one major difficulty with monitoring is the effortneeded to review audit trails. thus, there is a role for automated toolsthat can review audit trails to identify patterns of behavior that are worthfurther investigation. for example, tools could be available that:youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.315technologybased tools for users¥identify problematic viewing, resulting from accessing knownproblematic sites or by analyzing material on web sites for inappropriatecontent;¥determine how long someone stayed on inappropriate sites or inwhat sequence sites were accessed; and¥notify responsible adults in real time of access to inappropriatesites (e.g., in a home context, notification might consist of a light flashingon a monitor carried by the parent when a child using the web is accessing a potentially inappropriate site, or an email sent to a parent). alternatively, a request for access to a potentially inappropriate site can be transmitted to a responsible adult for approval within a certain period of time(e.g., 1 minute). if approval arrives, access can be granted and the decision remembered by the system.some of the functionality described above is available in some monitoring products today, but it is far from common.12.2.7what are the implications of using monitoring?in general, our society subjects criminals to a high degree of monitoring because they have proven untrustworthy. for the most part, individuals follow societal rules, not through constant monitoring and theinvasion of privacy, but because they have learned to internalize the values underlying those rules. put another way, if laws were followed onlybecause of police monitoring and enforcement, then we would need asmany police as other people to maintain law and order.children make mistakes, and criminals make mistakes, but to be a childis not to be a criminal. nevertheless, active supervision of children is oftenappropriateñnot because they are criminals but because it is the responsibility of adults to teach them how to internalize the appropriate values and tobecome better at avoiding inappropriate behavior as they mature.for example, responsible parenting always entails monitoring children in inverse proportion to their capability and maturity, somethingonly a parent can ultimately determine. but as noted in section 12.2.5, thewise parent couples monitoring with education and discussion in supportof helping the child internalize the parentsõ values, an outcome that willhelp him or her (or them) to behave appropriately whether parents arewatching them or not. parents have rights to what might be called theòimposition of sanctions,ó which, like any other part of parenting, fails ifused alone.44 as always, the density of loving wisdom in a parentõs44even these rights have limits. parents, for example, cannot subject their children toabuse in the name of discipline.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.316youth, pornography, and the internetactions is everything, and it is the nature of the existing parentchildrelationship, the intent of the monitoring process, and how it is carriedout that counts in understanding its ultimate implications.is the monitoring of children and adolescents a step in the erosion ofprivacy for all citizens? many people believe that it is, and point to othermeasures that they find equally disturbingñemployers who track thebehavior of their employees, and commercial online sites that track thebehavior and clicks of those who pass through them. the monitoring ofchildren raises special concerns because of the fear that a younger generation will grow up never having known a world in which they had rightsto privacy, and thus never realizing what rights they might have lost.others argue that such fears are overplayed, pointing to social andcommercial benefits of increased customization of information deliveryand an assumed lack of government interest in the affairs of ordinarypeople, as well as the fact that schools are expected to act in loco parentiswith respect to the students in their care. indeed, some believe that itwould be a positive development in society if adults in all venues feltsome responsibility for looking after the welfare of children and for supervising children when they are in a position to do so.45 resolvingthis question is beyond the scope of this study, but noting the questionraised by monitoring of children is certainly not.4612.2.8findings on monitoring1.monitoring that warns when exposure to inappropriate materialmay occur is an alternative to filtering and eliminates the problem ofoverblocking associated with filtering.2.overt monitoring in concert with explicit discussion and educationmay help children develop their own sense of what is or is not appropriate behavior. monitoring coupled primarily with punishment is muchless likely to instill in children such an internal sense. in general, thesimple presence of monitoring equipment and capabilities (or even theassertion of such capabilities) may create a change in behavior, thoughthe change in behavior is likely to be restricted to the situation in whichmonitoring occurs.3.because human intervention is required on a continuing basis,monitoring is more resourceintensive than filtering. for the same reason, monitoring is more likely to be construed as a violation of privacythan are other techniques that simply block access.45in this instance, there are debates about the role of technology in supervising childrenvis‹vis an inperson adult doing so.46a current cstb study on privacy in the information age will address these issues.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.317technologybased tools for users4.covert monitoring leads to an entirely different psychologicaldynamic between responsible adult and child than does overt monitoring. (furthermore, because people habituate to warnings, childrenmay respond to overt monitoring as though it were covertñi.e., morenegatively.)12.3tools for controlling or limiting òspamóòspam,ó email that is similar to the òjunk mailó that an individualreceives through the post office in the brick and mortar world, is sentñunsolicited and indiscriminatelyñto anyone with a known email address. email addresses can be purchased in bulk, just as regular mailinglists can be purchased: a typical rate for buying email addresses is 5million addresses for $50. alternatively, email addresses can be foundby an email address òharvester.ó (see box 12.6 for more details.) spambox 12.6activities that result in spam mailin an informal test, a cnet study identified a variety of behaviors that were likelyto result in spam mail being sent to users. in this test, the researcher opened 12 freeemail accounts (and monitored some older ones), dedicating each to one typicalonline activity (including the activity of doing nothing). he also provided an emailaddress on a number of òsignupó sites, posted messages on message boards aroundthe web, registered domain names, and visited chat rooms. over the course of a fewmonths, he checked to see which activities attracted the most unsolicited email toan account, and then he tried to figure out how to remove the spam.his conclusions were that posting messages on certain message boards run byunscrupulous operators and participating in aol chat rooms (even those that werenot sexually oriented) or in an online lottery were activities that resulted in the greatest volume of spam mail (as much as 10 spam messages per day). activities such asregistering a new domain and placing email links on oneõs own web site resulted inintermittent spam emailñmonths with nothing, and then sudden bursts. some common activities (including shopping online, registering at member sites, subscribing toan email newsletter, signing up for a free email account (and doing nothing with it,not even registering in an online directory), and registering software online) oftenthought to generate spam in fact resulted in virtually no spam at all.the researcher also found that while many spam messages offered a way toremove oneself from spam lists (òonly the most egregious porn spamó did not), hefound that many of the offered optout processes did not necessarily work (e.g., optout links were invalid). he found that clicking unsubscribe links did result in elimination of spam, but also noted that his experience may not be typical.source: adapted from matt lake, 2001, òwe reveal the riskiest email behaviors on thenet,ó july 26, available online at <http://cnet.com/software/03227888866023721.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.318youth, pornography, and the internetrefers to any form of unsolicited email a person might receive, some ofwhich might be sent by publishers of adultcontent web sites. a typicalspam message with sexual content would contain some òcomeonó wordsand a link to an adultoriented web site, but would in general arrivewithout images.policy issues associated with spam are addressed in chapter 10.12.3.1what are technologies for controlling spam?technologies for controlling spam fall into two categoriesñtools thatseek to conceal the email address (because if an email address is notknown, spam cannot be sent to it) and tools that manage spam once it hasbeen received. whether an individual can implement such tools varieswith the isp and/or email service used.to conceal email addresses with certain isps, one can create differentlogin names. for example, online services such as aol enable a user tocreate more than one login name that can serve as an email address. anindividual can thus use this special login name for activities that mightresult in spam (e.g., for participating in a chat room). this special namebecomes the attractor for spam, and mail received at that address can bedeleted at will or even refused. a number of services (some free, somenot) automate this process, enabling users to create specialpurpose addresses that can be turned off or discarded at will. in addition, emailsystems may allow a user to disallow all email except email from aspecified list of preferred addresses and/or domain names.to manage spam that does reach the userõs mailbox, a number oftools are available. most of these tools depend on the isp or the use of anemail program with filtering capabilities (e.g., eudora, netscape messenger, microsoft outlook). spam email can be identified and blocked onthe basis of:¥content. contentbased analysis examines the text, images, andattachments to emails to determine its character. (the technology forcontentbased analysis is much like that for contentbased filtering, asdescribed in section 2.3.1.)¥source. email being received from a particular email address or aparticular domain name may be defined as spam after a few exampleshave been received. aol mail controls are based in part on identifyingcertain sources as spam sources.¥addressees. for the most part, spam mail is not explicitly addressedto a specific individual. instead, a spam email is addressed to a largenumber of people in the òblind copyó field. (on the other hand, òblindyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.319technologybased tools for userscopiesó (bcc: foo@example.com) sent to an individual and email sentthrough mailing lists to which an individual has subscribed also make useof the hidden address technique.) mail filters (e.g., one based on òprocmail,óa mail processing system for unix and some other platforms) can check andfile or delete an email if it arrived at the userõs location via blind copyaddressing. (steps can be taken to set up exceptions for mailing list messages and bcc: messages from legitimate correspondents.)users can also take a number of procedural measures. for example,web sites often ask for information from the user. by inserting falseinformation (e.g., indicating an income lower than is actually true), it issometimes possible to avoid marketing attacks based on demographicinformation consistent with the group being targeted by the marketers.internet service providers also take measures to limit spam. for example, aol limits how fast other users can repeatedly enter and exit chatrooms, because a pattern of repeatedly and rapidly entering and exitingchat rooms can also be an indication that someone is harvesting emailaddresses. most isps also have lists of known spammers from which theyrefuse to carry traffic.12.3.2how well do spamcontrolling technologies work?spamcontrol technologies for dealing with email that has arrived inoneõs mailbox suffer from the same underblocking and overblocking issues that are discussed in section 12.1.2. one important issue is that spamoften contains links to inappropriate sexually explicit material rather thanthe actual material itself, and no contentscreening spamcontrolling toolknown to the committee scans the content for links that may be embedded in an email.that said, some spamcontrolling technologies are highly effectiveagainst spammers. those that restrict the email that can be received to agiven set of senders are very effective (i.e., do not accept mail unless thesender is on a list of permissible senders or from specific domains). on theother hand, they also sharply restrict the universe of potential contacts, somuch so that a user may fail to receive desired email. (for example, afriend who changes his or her sending email address will not be able toreach someone who has identified a white list of preferred senders.)ispbased or emailservicebased spam filters are partially effective.for example, the researcher mentioned in box 12.6 found that the spamfilter on one popular free email service reduced the volume of spam byabout 60 percent, though it still passed more than one message per day.spam filters that are based on content analysis techniques have all of theproblems with false positive and false negatives that web filters have.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.320youth, pornography, and the internet12.3.3who decides what is spam?some spam filters have preconfigured lists of known spammers. butin general, it is the user who must decide what is spam and what is not.of course, the difficultyñespecially for a childñis to recognize spamwithout opening the email. in some cases, it is easy to recognize from theheader or subject line. but many spam messages reveal themselves onlywhen they are opened. (note also that one personõs spam is anotherpersonõs service or information. unsolicited notices for ski vacations ormaterial on a local political candidate may be useful to some individualsand useless to others.)12.3.4how flexible and usable are products for controlling spam?because many isps filter out spam for most users, users of those ispsneed not take any action at all to reject spam. however, when spam leaksthrough the isp filters (or if email is not filtered for spam at all), as istypical of most email, the user must take action.note that unsolicited email, and the resources and attention it consumes, is not limited to sexually explicit email for youth. it would bereasonable to assume that the number of parties sending unsolicited email, the frequency with which they send it, and the volume that theysend will all increase. therefore, approaches to this problem are likely tobe developed, regardless of the concerns about youth and sexually explicit material. however, this can easily turn into another race: as betterspamdiscriminating technologies are invented, alternative ways of wrapping the unsolicited email are invented, and the cycle continues.12.3.5what are the costs and infrastructure requiredfor using spamcontrol products?spam can be controlled in a variety of locations. when control islocated at the receiver, locally installed software spam filters can help toprocess and eliminate spam. conceptually, the cost of local spam filters issimilar to that for content filters. however, spam filters must be integrated into software for processing email in general.control points based in the network (or an isp) are both more complex and more comprehensive. some isps have extensive capabilities fordetecting the sending of spam mail (e.g., by monitoring the volume of email sent in a given time interval), preventing the òharvestingó of emailaddresses, and so on, and developing these capabilities entails substantialeffort.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.321technologybased tools for usersindividual organizations often incur cost in configuring software andservers to stop spam from going through their own internal networks.such efforts are often undertaken to help manage internal bandwidthmore effectively.finally, there may be costs incurred for infrastructure that may beneeded to support legislative efforts to curb spam. for example, onemethod for dealing with junk mail and phone telemarketers is to establisha clearinghouse where people can register their names, addresses, andphone numbers. but the effectiveness of this approach is based on the factthat it is in the marketerõs selfinterest to refrain from wasting phone andmail effort and time on people unlikely to buy. because sending spam isso much cheaper than mail and phone calls, a similar approach is unlikelyto work effectively without some kind of legal cause of action that can betaken against those who ignore the clearinghouse. (policybased solutions are discussed in chapter 9.)12.3.6what does the future hold forspamcontrolling systems?there has been an acceleration of commercial organizations introducing their messages into schools, although almost always after signing anagreement with the school board (which agreement usually includes newfunds flowing to the school to supplement the budget). however, schoolsmay wish to install some mail filtering before the marketing departmentof some softdrink manufacturer decides to send email to students justbefore lunch, promoting its product while also, to prevent uproar, givingòthe spelling word of the day,ó òthe math hint of the day,ó or whatever.it is easier for the school district to add another item to the spam filterthan to have its lawyer sue the sender of the emails. as in the case of ageverification technologies, expanded use of òmail deflectionó beyond issues of sexually inappropriate material may warrant the trouble of installing spamcontrolling systems.12.3.7what are the implications of usingspamcontrolling systems?as described in chapter 9, legislative efforts to curb spam do havesocietal implications.12.3.8findings on spamcontrolling technologies1.spamcontrolling technologies generally do not allow differentiation between different kinds of spam (e.g., hate speech versus inappropriyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.322youth, pornography, and the internetate sexually explicit material). rather, they seek to identify spam of anynature.2.spamcontrolling technologies that filter objectionable email havemore or less the same screening properties that filters have. that is, theydo block some amount of objectionable content (though they do not generally screen for links, which are often transmitted in lieu of actual explicitcontent). however, they are likely to be somewhat less effective thanfilters at preventing such email from being passed to the user becauseusers are likely to be more apprehensive about losing email that is directed toward them than about missing useful web sites, and thus wouldbe more concerned about false positives.3.behavioral and procedural approaches to avoiding spam (ratherthan filtering it) have at least as much potential as spamcontrolling technologies to reduce the effect of spam. however, using such approachesadds somewhat to the inconveniences associated with internet use.12.4instant helpthe technologies discussed in sections 12.1 and 12.2 are intended toprevent the exposure of children to inappropriate material. instant helpis a tool to deal with exposure after the fact.12.4.1what is instant help?the philosophy underlying instant help is that from time to timechildren will inevitably encounter upsetting things onlineñinappropriate material, spam mail containing links to inappropriate sexually explicitmaterial, sexual solicitations, and so on. when something upsetting happens, it would be helpful for a responsible adult to be able to respondpromptly. an òinstant helpó function would enable the minor to alertsuch an adult and appropriate action could then ensue, could provideanother channel to law enforcement through which threats, and solicitations, and obscene materials or child pornography could be reported.to the best of the committeeõs knowledge, there are no commerciallyavailable tools that provide instant help. but current technology couldeasily support an instant help function. for example, a secure oneclickcall for help47 could be:47security for this òoneclickó button is an important element of helpñthe functionalityof the button must not be disabled, as it is in mousetrapping (when the òbackó button sendsthe user to a new adultoriented web site).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.323technologybased tools for users¥on isps, an òalwaysontopó button that would connect the userdirectly to a trained respondent;¥on internet browsers, a òpluginó represented by a button on thetoolbar;¥on search engines, an icon that would always be displayed on theresults page;¥on email readers, an òi object to this emailó button on the toolbar;¥on a computer desktop, a button that activates an application thatallows a remote helper to take over control of the userõs machine andview the screen.these buttons might be as simple as an icon for the cybertipline(ctl) that would serve as an easily accessible channel for the public touse in reporting child pornography. the ctl icon has proven to be aneffective tool in reporting obscene or child pornography because it isuserfriendly and is the most direct method to report such images to theappropriate law enforcement authority. because the ctl icon was builtfor the sole purpose of interfacing with the public to facilitate reporting tolaw enforcement computerassisted crimes against children, it is moreeffective than other mechanisms for such reporting.depending on the context of the technology through which the user iscoming into contact with inappropriate content or interactions, a widerange of functionality is possible once the button is clicked. for example,òinstant helpó on a browser or an isp could immediately connect the userto a helper who provides assistance. to provide context, an image of thescreen could be transmitted to the helper. such assistance might be mostuseful if the user encounters a solicitor or inappropriate conversation in achat room or an instant message. or, if a user encounters inappropriatematerial, the last several web pages viewed could be shared with thehelper, who could assist the user in whatever action he or she wished totake (e.g., sending urls to the cybertipline). for internet access on alan, instant help could be configured to summon assistance from a responsible adult within the lan, such as a teacher or a librarian.instant help would be applicable in both home and institutional contexts. implementing instant help functionality must be undertaken byservice providers and technology vendors. but such functionality is nothelpful without a human infrastructure to assist those seeking helpñthehuman infrastructure may be provided by the isp, a parent, a school, alibrary, or even an expanded national center for missing and exploitedchildren (ncmec).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.324youth, pornography, and the internet12.4.2how well might instant help work?by providing assistance to the minor, instant help could potentiallyreduce the negative impact that may result from exposure to inappropriate material or experiences. such exposure can come from either deliberate or inadvertent access, but in practice instant help is more likely to beuseful in the case of inadvertent access. instant help obviously does notenable the user to avoid inappropriate material but does provide a meansfor trying to cope with it. it also provides opportunities to educate children about how to avoid inappropriate material or experiences in thefuture, and it might lead to the creation of more civil norms online. itprovides immediate assistance in the case of aggressive solicitations andharassment. finally, it might lead to greater law enforcement activity ifthe materials involved are obscene or constitute child pornography.metrics of effectiveness that indicate the extent to which children arenot exposed to inappropriate materials do not apply to instant help.rather, effectiveness is better assessed on the basis of the quality of theassistance that helpers can provide, and the responsiveness of the instanthelp function. assistance that arrives 20 minutes after the user has pressedthe instant help button is obviously much less helpful than if it arrives in5 seconds, and of course, human helpers must be trained to handle a widevariety of situations.a specialist trained to provide this kind of help to youth, or a peerwith special training, could potentially be more effective than the childõsown parent or teacher or librarian. however, because this approach hasnever been implemented on a wide scale, staffing needs for instant helpcenters are difficult to assess. in many urban areas, crisis interventionhotlines (focused on helping people subject to domestic abuse, or feelingsuicidal, struggling with substance abuse addictions, and so on) exist, butthere are none known to the committee that give training to their volunteer staffs concerning childrenõs exposure to sexually explicit material onthe internet.12.4.3who decides what is inappropriate?unlike other tools, the locus of decision making in the context ofinstant help rests with the minor. the minor decides what is upsettingand determines the situations in which he or she needs help.12.4.4how flexible and usable is instant help?the purpose of an instant help function is to ensure that somethingcan be done with very little difficulty. thus, the flexibility and usabilityof an instant help function are paramount.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.325technologybased tools for usersfor example, individual parents, libraries, or schools could customizewho is contacted when the instant help button is pressed. thus, a familywith strong religious ties could set instant help to alert helpers from agroup associated with their religious tradition, while a school districtcould set the instant help button so that in the elementary school, a message went to a staffer in that building and in the middle school, to a stafferin the middle school building. this is in some sense analogous to thenational phone emergency number 911 going to a local 911 dispatch center based on the exchange from which 911 was dialed.12.4.5what are the costs and infrastructurerequired for instant help?the infrastructure and institutional cooperation needed for instanthelp to work successfully are considerable. vendors must be willing touse precious screen space to provide instant help buttons. the infrastructure of helpers must be developed and deployed. for an isp, such aninfrastructure might well be expensive; for the ncmec or law enforcement agencies, it would be very expensive. but for a school or library (oreven for responsible adult guardians), the infrastructure of helpers mayalready be in place.48the costs are roughly proportional to the size of the helper infrastructure; helpers (who could be volunteers) must be trained in how to respond to a call for help.note also that a skilled adult predator or even adolescents bent onmischief could create a flood of diversionary instant help requests so thatthe responding individuals would become backlogged, during which timethe predator could attempt to continue an interaction with a young person. thus, some mechanism for protection from òflooding attacksó wouldbe needed by any responding center that serves a large number of anonymous end users or devices.12.4.6what does the future hold for instant help?to the committeeõs knowledge, instant help functionality has not beenimplemented anywhere, and it remains to be seen if children would actually use it if and when they are confronted with inappropriate material or48it is true that in schools or libraries a child should be able to request help from theseindividuals without instant help features. the primary advantage of clicking an instanthelp icon is that it can be done privately and without drawing attention from other users.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.326youth, pornography, and the internetexperiences that upset them. thus, some smallscale piloting of the concept to evaluate how it might work is likely to be very helpful before anymajor effort to implement instant help is considered.12.4.7what are the implications of using instant help?a potential downside of a òlowcostó implementation that wouldrequire the child to describe the material and how he or she got there isthat the child might be forced to focus more on the inappropriate material, perhaps causing at least discomfort to the child who may be better offif transferred back to appropriate activities as soon as possible. such anegative outcome could be avoided if the inappropriate material could beautomatically transmitted to the helper. (since the material may well notbe present on the childõs screen when he or she contacts the helper, theautomatic display of material might have to retrieve the last severalscreensñthis may be a difficult technical task under some circumstances.)in cases where a new type of offensive material or communicationbegins to occur for the first time on the internet, the first instant helpresponse center to identify this new material could share that informationwith schools and parents, other instant help response centers, youth (aswarnings), or even filtering vendors. in that sense, instant help mightharness all youth who use it to improve the monitoring of the internet fornew offensive material or communication. dissemination of the insightsof the staff of an instant help center should be considered a networkedresponse, as opposed to the response of assisting a child when requested.the internet technical community has experience with networked response in the cert system to propagate information about worms, security holes, and the like.12.4.8findings on instant helpas the committee is unaware of any implementation of instant helpthat fits the description above, there are no findings to report.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.327complementing the discussion of chapter 12 on tools for the enduser, this chapter focuses on tools for other internet stakeholders, such asinternet service providers, content providers, or operators of adultoriented web sites. as a general rule, these tools are most relevant to entitiesthat have some commercial reason for existingñthey have less relevanceto noncommercial sources of sexually explicit material (e.g., individualswith exhibitionist preferences, friends sharing sexually explicit images,and so on).table 13.1 provides a preview of this chapter.13.1a .xxx toplevel domain13.1.1what is a .xxx toplevel domain?a .xxx toplevel domain (tld) would be reserved for those entitiesproviding adultoriented, sexually explicit material.1 for example, www.foo.xxx would name a site on which such content would be found, andany pages within it (e.g., www.foo.xxx/example1) or any subdomains(e.g., www.fetish.foo.xxx) would be assumed to have similar content aswell. a key element of proposals for .xxx is whether the use of .xxx would13technologybased tools availableto nonend users1ò.xxxó is pronounced as òdotxxx.óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.328youth, pornography, and the internettable 13.1 technology tools for use by nonend userstoolfunctionone illustrative advantageone illustrprovides a way of identifyingadultoriented sexually explicitmaterial from these sites withminimal effortenables sites that wish to beknown for providing sexuallyexplicit material to selfidentify, thus making inadvertent access to such sites lesslikelyprovides high assurance thatmaterial from .kids web sites isappropriate for childrenplaces a major obstacle in thepath of minors seeking adultoriented sexually explicitcontent from commercial sitesreduces dissemination ofillegally copied sexuallyexplicit images, whichconstitute a significant amountof the adultoriented materialavailable onlinerequires that web sites withadultoriented sexually explicitcontent must have a .xxx suffixgives any content provider theoption of selecting a domainname with a .xxx suffix.kids domain names reservedfor site with contentappropriate for childrenseeks to ensure that someoneseeking to access adultorientedsexually explicit content isactually an adultprovides tools for contentowners to help controldissemination of images theyown.xxx domain(mandatory).xxx domain(voluntary).kids domainage verificationtechnologiestools forprotectingintellectualpropertybe voluntary or mandatory. if use were mandatory, all providers of adultoriented content would be required to place such content on a web pagewith the .xxx tld, and penalties would be established for not doing so.today, assignment of domain names in some tlds is done on apurely voluntary basis, whereas for other tlds, an adjudicating bodydetermines eligibility. for .com, .net, and .org, registrars of domain namesperform a strictly administrative function; for the .edu, .mil, .gov toplevel domains, some institutional entity decides that an organization is oris not eligible. however, regardless of the tld involved, the content thata domain name owner wishes to place on its web site is not necessarilyrelated to the assignment of the domain name to that owner, and there isno requirement today for such a relationship.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.329technologybased tools available to nonend userstageone illustrative disadvantagevoluntarey versus involuntary exposuresimilar to filtering; prevents both kindsof exposure to .xxx domains, but is notuseful against materials not found in.xxx domainssimilar to filtering; prevents both kindsof exposure to .xxx domains, but is notuseful against materials not found in.xxx domainssee discussion in text of contentlimitedinternet service providerswhen implemented, can prevent bothdeliberate and inadvertent access forminors, although if user is willing to lieabout age, may not be able to protectagainst deliberate accessnot applicablerequires difficulttoobtain clearlyspecified and international standard forwhat constitutes material that must beplaced in .xxx domainsmay lead to stronger political pressuresfor mandatory inclusion in .xxx domain;also likely to leave many web pagescontaining objectionable materialsunidentified as such, thus facilitatinginadvertent accessrequires difficulttoobtain clearlyspecified and international standard forwhat material is appropriate forchildren; does not allow for agebaseddifferentiation among childrenlittle applicability to noncommercialsources of sexually explicit materialhard to use against noncommercialsources of sexually explicit material thatdo not depend on web distribution (e.g.,usenet, peertopeer networking)proponents of a .xxx domain argue that it would provide an easy wayof recognizing material presumed to be inappropriate for children, obviating the need for a laborious inspection of web pages for such contentand simplifying the filtering task by simply blocking access to sites in the.xxx domain.the institution authorized to establish new toplevel domains is theinternet corporation for assigned names and numbers (icann), a nonprofit corporation that was formed in october 1998 to assume responsibility for the ip address space allocation, protocol parameter assignment,domain name system management, and root server system managementfunctions previously performed under u.s. government contract by theinternet assigned name authority (iana) and other entities.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.330youth, pornography, and the internetif and when a .xxx tld is established, it would remain for productvendors to build software that would provide users with the option ofrejecting all domain names ending in .xxx. parents, schools, teachers, andother concerned adults would then have to be willing to exercise theoptions enabled in the software.13.1.2how well would a .xxx toplevel domain work?in essence, the use of a .xxx tld amounts to a label to identify contentas inappropriate or appropriate for children that is based on the source ofthat content. thus, from the standpoint of the end user, all of the pros andcons of labelbased filtering described in chapter 12 apply to the use of a.xxx domain.a .xxx domain would be intended to facilitate the blocking of accessto sexually explicit material. thus, in principle, itñalong with filtersñwould help to protect against both deliberate and inadvertent access.from a filtering perspective, the effectiveness of such schemes dependson the reliability of the assumption that adultoriented, sexually explicitmaterial will be confined to a .xxx domain.by definition, a .xxx domain name is reserved for sexually explicitmaterialñand is thus irrelevant for any other material that is nonsexualin nature. it is likely that certain parties will have some incentives toplace their content in such a domain.2 after all, they wish their content tobe found, and segregating it into an adultoriented tld helps to make itfound. (indeed, a concentration of adultoriented web sites may in factprovide children and adults with a òtargetrichó environment in whichthey could much more easily seek out sexually explicit material.) on theother hand, a .xxx domain does not deal at all with the issue of peertopeer transfers, email attachments, and so on. for example, college students may post collected sexually explicit material on various servers runby universities or public web hosting servicesñand there is no guaranteethat all sexually explicit material will be contained on web sites in the.xxx domain, even if all commercial adultoriented providers choose tocooperate.2for example, seth warshavsky, president of the internet entertainment group, an adultentertainment company, told the u.s. senate commerce committee in 1998 that he wouldlike to see a .adult domain: òweõre suggesting the creation of a new toplevel domain calledô.adultõ where all sexually explicit material on the net would reside.ó see òcongress weighsnet porn bills,ó cnet article, february 10, 1998, available online at <http://news.cnet.com/news/01005200326435.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.331technologybased tools available to nonend userstwo issues related to a .xxx tld are whether the use of the tld ismandatory or voluntary, and whether there is an adjudicating body thatmonitors the content contained in one or another of these tlds.3 today,no web site owner is forced to use a given tld, and there is no adjudicating body that determines if the content on a web site matches its tld.for a .xxx domain, these two issues are related. mandatory use of a.xxx domain for sexually explicit material would imply creating a bodywhose role was to decide what content must be placed into a .xxx domain,and thus would affect all domain name owners, not just those associatedwith adultoriented content. however, because òharmful to minorsó lawsare communityspecific, a single body might be tempted to use a òlowestcommon denominatoró approach to such decisions. thus, some organizations and firms would be forced to use a .xxx domain even if they didnot believe their content was adultoriented and sexually explicit. (stigmatization might also result from forced placement into a .xxx domain,with the .xxx tld becoming a de facto ghetto into which all controversialmaterial is placed.) coupled with filters that block web sites with a .xxxsuffix, this approach would lead to a bias in favor of overblocking. on theother hand, in the absence of an adjudicating body, or if the use of a .xxxdomain is voluntary, adultoriented, sexually explicit material could easily be found on non.xxx domains. filters designed to block sites basedsolely on the .xxx tld designation would be ineffective against suchcontent, and so commercial sites uninterested in differentiating betweenchildren and adult traffic could take advantage of the lack of the .xxxtld. a voluntary .xxx domain might also reduce filter overblocking,since operators of sites with sexually explicit material that was not oriented towards adult entertainment (e.g., museums, medical schools)would not choose a .xxx domain name and hence would be less likely tobe blocked.a finalñand criticalñquestion for the mandatory use of a .xxx tld ishow it would apply internationally. that is, how would u.s. law be ableto compel foreign web site owners to use a .xxx domain?4 (such a question is particularly relevant given the commonness of full frontal nudityin many mainstream foreign publications and web sites.)3an adjudicating body refers only to an entity that could make such a determination. awide range of entities fit such a characterizationñfrom an organization or agency established with a charge to make such determinations to a court or jury instructed to make suchdeterminations in accordance with applicable law.4a particularly thorny issue in this regard concerns the implications of such efforts forattempts by foreign governments to enforce their laws on web sites based in the unitedstates. for more discussion, see computer science and telecommunications board, national research council, 2001, global networks and local values, national academy press,washington, d.c.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.332youth, pornography, and the internet13.1.3who decides what material should beconfined to .xxx web sites?for voluntary use (in the absence of adjudicating bodies), only theorganization in question makes decisions about what material is adultoriented and sexually explicit. for nonvoluntary use requiring an adjudicating body, the adjudicating body makes decisions about what shouldand should not be placed in each domain, thus raising the question ofwhat communityõs standards would be used by the adjudicating bodyand how they would be determined.13.1.4how flexible and usable are schemesbased on a .xxx toplevel domain?the usability of schemes based on .xxx would depend in large part onwhether or not domain names with these suffixes contain the contentimplied by the tld (as described above).another issue is whether the .xxx tld would receive icann endorsement. a number of schemes have been proposed to circumventicann in the establishment of other tld names. such proposals havebeen controversial, because they violate principles that have been regarded by many as integral to the smooth operation of the internet. inparticular, a nonendorsed tld name might not be uniformly accessiblefrom every internet access point (and today only a very small percentageof web users could access sites based on nonendorsed tlds), and undersome circumstances, a user seeking to access a site based on a nonendorsed domain name might wind up at different web sites dependingon the location from which it was accessed.513.1.5what are the costs and infrastructurerequired for a .xxx toplevel domain?for .xxx domain names, the adjudicating body must make decisionsabout every web page that is posted on the internet, because it mustdecide if such material belongs in a .xxx domain name. such a task isdaunting, and it is virtually impossible that an adjudicating body coulddo so. more likely, it would undertake what sampling it could do atreasonable expense and would examine non.xxx sites that were reportedas having sexually explicit content.5this point is discussed in more detail in a computer science and telecommunicationsboard report on domain name systems that is currently in preparation.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.333technologybased tools available to nonend usersin addition, a .xxx domain would pose a number of technical difficulties.6 an adult web site may reside on a .xxx domain, and indeed maywish to reside on such a domain. however, consider the example of auniversityñwhich hosts a wide variety of content, some of which isdeemed to be adultoriented and sexually explicit by the adjudicatingbody. web pages for such content willñby assumptionñreside underneath the .edu domain of the university. under a .xxx domain name,another separate category in the domain name service tree must be maintained by the university. alternatively, a university could require thatprojects containing such content set up their own web servers in the .xxxdomain, which does not involve a high cost. project web sites under the.edu domain could contain links to the web sites in the .xxx domain.a second technical difficulty is the fact that the domain name serviceof the internet supports page redirection. that is, the owner of the sitewww.safeforkids.com has the technical capability to force individualsintending to visit the www.safeforkids.com site to visit a .xxx web pageinstead, whether or not the owner of the .xxx web page wishes this redirection to happen.7 such a scenario raises a question of responsibility if aminor is channeled to the .xxx site. the owner of www.safe forkids.comhas no sexually explicit content on its site, but is responsible for directingthe minor to the .xxx site. the owner of a .xxx domain name may havetaken no actions to attract children to the .xxx site. who bears responsibility for this exposure?13.1.6what does the future hold fora .xxx toplevel domain?at least one legislative proposal has been offered to support the establishment of .xxx domains.8 as this report goes to press in may 2002,the prospects of these proposals are unclear.6see ò.xxx considered dangerousó online at <http://search.ietf.org/internetdrafts/drafteastlakexxx01.txt> for more discussion of these and other technical issues.7in redirection, the request from the userõs software (e.g., browser) arrives at the site whoseaddress was entered, but that site does not return content. instead, the site returns a standardinternet message saying, òthe content you seek is located at this address,ó and the userõs software immediately fetches data from that address. since the first system may send an addresswithout a symbolic host name, but rather with a numeric ip address, such as that in the messageòthe content you seek is located at http://111.222.333.444/awebpage.html,ó clientside filteringhas no clues that this is actually a host in the .xxx domain. redirection exists in the internetprotocols because organizations do change what systems host their content but still want theold wellpublicized urls to work, and because it can be used as part of load balancing: anearly overloaded server can redirect some percentage of requests elsewhere, potentially basedon the geographic location of the requester as inferred from the ip address.8see, for example, <http://www.adlawbyrequest.com/legislation/tldsex.shtml>, whichdescribes a proposal supporting .xxx.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.334youth, pornography, and the internet13.1.7what are the implications of usinga .xxx toplevel domain?the establishment of a .xxx domain, even if use is voluntary, wouldestablish a òbig fat targetó for subsequent regulatory efforts. in otherwords, even if its use is voluntary, it may not remain that way for long aspolicy makers take note of its existence.13.1.8findings on a .xxx toplevel domain1.a .xxx domain that is selected voluntarily may have some appealfor enterprises that are involved primarily in providing access to sexuallyexplicit material intended to arouse desire (i.e., what is often known asòpornographyó) and that use a distribution channel requiring the use ofdomain names. such enterprises are likely to use a .xxx domain as a partof their advertising strategies.2.a .xxx domain would have little effect on (a) sexually explicit material that is not intended to arouse desire but which some parties mayregard as inappropriate anyway, (b) a mixeduse domain (e.g., a university with a .edu web site with a faculty member who does research onhuman sexuality or studies the evolution of sexuality in art and mediaand wishes to post research materials on a university web site), or (c)sources of inappropriate sexually explicit material that are located outside the united states (if these sources do not wish to be identified with a.xxx domain).3.the use of a tld to identify inappropriate content would requiresoftware (e.g., web browsers) that can be configured to block contentcoming from .xxx sites. conceptually, this arrangement is identical tothat of filtering based on content, except that the task of developing blacklists and white lists is made much easier.4.the benefits associated with a .xxx domain would depend on theassociation of a tld with specific content. this fact raises the question ofan institutional entity that might be established to promote such association. if the benefits associated with a purely voluntary use of either domain are sufficient, then no such entity need exist. but if the affectedpublic requires higher confidence in the association between tld andcontent, such an entity may be required, and that entity would be venturing into difficult uncharted waters as it sought to determine whethercertain content should or should not be contained within a given tld. inthe case of a .xxx domain, the scope of its responsibility would be toensure that all sexually explicit material was hosted on a .xxx domain andnowhere elseñan entirely daunting task.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.335technologybased tools available to nonend users13.2a .kids toplevel domain13.2.1what is a .kids toplevel domain?a .kids toplevel domain would be reserved for those entities providing material intended and appropriate for children.9 that is, it would beexplicitly designed for the use of children, providing safe, lawful, andappropriate content (e.g., information and entertainment), services, andfacilities of especially high interest for them. further, it would safeguardthe privacy and safety of all children accessing .kids domain names.for example, www.foo.kids would name a site on which such contentwould be found, and any pages within it (e.g., www.foo.kids/example1)or any subdomains (e.g., www.nature.foo.kids) would be assumed to havesimilar content as well. in general, use of a .kids domain has been discussed in entirely voluntary terms, and it would make no sense to make itmandatory.proponents of a .kids domain argue that it would provide an easyway of recognizing material presumed to be appropriate for children,simplifying the filtering task by simply allowing access only to sites in the.kids domain. as in the case of a .xxx domain, product vendors wouldhave to build software that would provide users with the option of accepting only domain names ending in .kids. parents, schools, teachers,and other concerned adults would then have to be willing to exercise theoptions enabled in the software.13.2.2how well would a .kids toplevel domain work?because the use of a .kids tld amounts to a label to identify contentas appropriate for children that is based on the source of that content, allof the conceptual pros and cons of labelbased filtering described in chapter 12 apply to the use of .kids. however, in addition to the baselinequestion of the extent to which it would help to keep children away frominappropriate materials, a second question particularly relevant to a .kidsdomain is the extent to which it would succeed in providing appropriate,educational, and informative content and experiences for children.a .kids domain would be intended to promote access to childfriendlymaterial. to the extent that this occurs, children have less time availableto seek out inappropriate material. thus, a .kids domain alone may help9ò.kidsó is pronounced òdotkids.óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.336youth, pornography, and the internetto reduce deliberate access to inappropriate material but cannot addressthe problem of inadvertent access. a browser or internet service providerrestricting access only to .kids web pages effectively provides the samekind of protection as a contentlimited isp service.from a filtering perspective, the effectiveness of such schemes depends on the reliability of the assumption that material intended for children will be found on a .kids domain. it can be anticipated that manyfirms seeking to provide content for children will have incentives to obtain .kids domain names, because such a domain name would guaranteetheir audience. today, no web site owner is forced to use a given tld,and a web site operator can post anything on his or her web site. if thiswere true in the .kids domain, it could defeat the intent of keeping children away from inappropriate content.it is unlikely that those in the commercial enterprise of providingadultoriented, sexually explicit content would choose to place their materials in a .kids domain. furthermore, other enterprises, especially thoseoperating in the commercial mainstream, would select quite carefully thecontent they would place in a .kids domain. however, it is easy to imagine that if .kids domain names were as freely available as todayõs .comdomain names, certain parties would place inappropriate content of somekind on a web site with a .kids domain name.thus, the safety of a .kids domain name likely depends on the existence of some mechanism to ensure that the content available from anygiven .kids site matches the intent of the .kids domain. one such mechanism is an adjudicating body that decides what organizations would beeligible for a .kids domain name (so that .kids domain names would notbe as freely available as todayõs .com or .net names). further, the bodywould make decisions about specific content that would be eligible forplacement. the effectiveness of a .kids domain would depend, then, onthe wisdom of the judgments of the adjudicating body and the extent towhich it had the power to enforce its judgments. the bodyõs enforcementpower might depend on its ability to take away a .kids domain name froman owner found to be misusing it, or an acceptance of civil liability forfalse and deceptive advertising or business practices in that event (suggesting a possible role for the federal trade commission).the second question involves the extent to which a .kids domainwould succeed in providing appropriate, educational, and informativecontent and experiences for children. it is clear that commercial entitiesthat market their products and services to children would make significant use of a .kids domain. but as discussed in section 10.9, noncommercial entities could also have an important role to play in populating the.kids domain.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.337technologybased tools available to nonend users13.2.3who decides what material should beallowed in .kids web sites?in the absence of an adjudicating body for allocating domain names,only the organization seeking a domain name makes decisions about whatmaterial is appropriate for children. in the presence of an adjudicatingbody, the body makes decisions about what should and should not beplaced in each domain, thus raising the question of what standards shouldbe used by the adjudicating body and how they would be determined.an undetermined aspect of a .kids domain would be the developmental or age level that should govern placement. as noted in chapter 5,what is perfectly appropriate for a 16yearold may be inappropriate for a7 yearold. coupled with the fact that the information needs of smallchildren are generally less than those of older children, it would seem thatcontent for .kids would tend to be oriented toward younger children.one possibility for definition of web sites eligible for a .kids domainname is a site that is subject to the requirements of the child onlineprivacy protection act (coppa), that is, a site òdirectedó to childrenunder 13. to determine whether a site is òdirectedó toward children, thefederal trade commission (ftc) considers several factors, including òthesubject matter; visual or audio content; the age of models on the site;language; whether advertising on the web site is directed to children;information regarding the age of the actual or intended audience; andwhether a site uses animated characters or other childoriented features.ó10 if a .kids domain is indeed intended for use by children under13, the ftc definition of a site directed to children is one reasonable pointof departure for a working definition.13.2.4how flexible and usable are schemesbased on a .kids toplevel domain?the usability of schemes based on .kids depends in large part onwhether or not domain names with this suffix contain the content impliedby the tld (as described above). as with a .xxx domain, another issue iswhether these tlds receive icann endorsement. a number of schemeshave been proposed to circumvent icann in the establishment of othertld names, and the discussion above about a .xxx domain in this areaapplies identically here.10see federal trade commission, 1999, òhow to comply with the childrenõs online privacy protection rule,ó november. available online at <http://www.ftc.gov/bcp/conline/pubs/buspubs/coppa.htm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.338youth, pornography, and the internet13.2.5what are the costs and infrastructurerequired for a .kids toplevel domain?for mandatory adjudicating bodies to make decisions about content,an effort would be required that is proportional to the volume of information posted by entities with a .kids domain name.in addition, owners of web sites in a .kids domain face liability issues.the proposition that a .kids site is appropriate for children is the draw formany users. content deemed inappropriate by someone that is found ina .kids domain is likely to lead to lawsuits about false and deceptiveadvertising; if an adjudicating body is involved, it is likely to be named aswell. also, while the intent of a .kids tld is to make certain material easyto find for children, the existence of a .kids tld makes it easy to restrictchildrenõs access only to web sites in a .kids domain, even though muchother material might be both useful and appropriate for them.13.2.6what does the future hold for a.kids toplevel domain?at least one legislative proposal has been offered to support the establishment of a .kids domain.11 as this report goes to press in may 2002,the prospects of this proposal are unclear.13.2.7what are the implications of using a .kids toplevel domain?a web site can offer users more than passive viewing of content. if aweb site in the .kids domain offers opportunities for a child to interactwith other users on the site (e.g., through chat rooms, email, bulletinboards, and so on), adults seeking to interact with children, such as pedophiles, are likely to be drawn to the site as well because of the highlikelihood that a user will be a child. this fact is not likely to be reassuring to parents.a second implication is the following: if a .kids domain consists onlyof web sites explicitly designed for children, especially younger ones, itwould be highly restricted. in particular, it would not carry sites thatprovided information for a range of ages (e.g., information found in encyclopedias, which are not designed only for children). thus, a child restricted only to accessing a .kids domain may not have access to informa11see, for example, david mcguire, 2001, òbill would require icann to create ô.kidsõdomain,ó newsbytes, june 29. available online at <http://www.newsbytes.com/news/01/167478.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.339technologybased tools available to nonend userstion necessary to do certain homework assignments. (indeed, part of theappeal of internet access is the access that people have to a broader rangeof informationñand so restricting a user to a .kids domain reduces theinternetõs appeal.) such restrictions may be most appropriate for theyoungest internet users.13.2.8findings on a .kids toplevel domain1.a .kids domain may have some appeal for enterprises whose businesses are involved primarily in providing access to childfriendly andappropriate material. such enterprises are likely to use a .kids domain asa part of their advertising strategies.2.the use of a tld to identify childappropriate content could require software (e.g., web browsers) that can be configured to accept onlycontent coming from .kids sites. conceptually, this arrangement is identical to that of filtering based on content, except that the task of developing white lists is made much easier.3.the use of a .kids tld would also be useful as an indicator ofappropriateness for children even in a nonfiltering context, because itwould enable parents and other responsible adults to determine a siteõsappropriateness at a glance.4.the benefits associated with a .kids domain would depend on theassociation of a tld with specific content. this fact raises the question ofan institutional entity that might be established to promote such association. if the benefits associated with a purely voluntary use of eitherdomain are sufficient, then no such entity need exist. but if the affectedpublic requires higher confidence in the association of tld and content,such an entity may be required, and that entity would be venturing intodifficult uncharted waters as it sought to determine whether certain content should or should not be contained within a given tld. in the case ofa .kids domain, the scope of its responsibility would be to ensure that thematerial on web sites in a .kids domain was in fact childappropriate.13.3age verification technologiesbecause much of the political debate centers on the access of childrento inappropriate sexually explicit material on the internet, it is natural toexamine online methods that can be used to differentiate between adultsand children. age verification technologies seek to distinguish adultsfrom children and to grant access privileges only to adults. age verification technologies seek to accomplish in cyberspace what a clerk checkingan id card or driverõs license accomplishes in an adult bookstore.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.340youth, pornography, and the internet13.3.1what are age verification technologies?age verification technologies (avts) seek to establish that a givenindividual is or is not an adult, and based on that determination, aninformation provider (generally a commercial web site host) allows/denies access to certain material or allows/prevents a transaction to be completed. the structure of a typical commercial adult web site is a homepage (http://www.adultsite.com) on which are presented a number ofsexually explicit òteaseró images that are immediately available to anyonearriving on that page. other content is accessible only after the user paysfor access or enters a special password to gain access.as a rule, the home page of an adultoriented, sexually explicit website has a number of other options that the user might subsequentlychoose:¥a òfree touró in which additional teaser images are presented,perhaps on a number of additional pages;¥a òsignup nowó button, which will take the user to a subscriptionpage where he is invited to provide a credit card number; and¥a òprovide access codeó field, in which the user can enter an accesscode that has been provided previously or through some other source.in other cases, the home page may not have any images at all, or haveonly obscured but suggestive images, with a warning that says, òif youare under 18, please exit by clicking here.ó in addition, the site maydisplay boilerplate language that seeks to immunize the site owner againstcharges that he has made sexually explicit adult content available to children (box 13.1 contains an example); in these cases, the user may enter thesite only by passing through this boilerplate language. clicking the òenteró button is taken to be the userõs assurance that he or she agrees withthe conditions of use, which include stipulations about age.as the structure of the canonical adult web site indicates, the simplestage verification technology is a web script that asks the userõs age, and inmany cases, such a request suffices. a similar situation obtains with onlineforms and profiles that users are often asked to fill out; such profiles ofteninclude entries for age. but because young people are sometimes willingto lie about their age, stronger age verification is generally necessary. ingeneral, systems for age verification are based on the technologies described in chapter 2.age verification technologies are implemented by parties who wishto restrict the access of their online products or services to adults. (inaddition to limiting access to adultoriented, sexually explicit materials,avt infrastructure may also be useful to individuals who sell alcohol,youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.341technologybased tools available to nonend userstobacco, or other adultonly products over the internet.) however, thedeployment of an age verification technology may not indicate a desire toverify ageñin particular, consider credit cards that serve the dual function of age verification and payment medium. because credit cards aretoday the simplest medium for online exchange of funds, the use of creditcards is just as likely (indeed, far more likely) to indicate a desire to bepaid as a desire to restrict adultsonly products and services to adultsalone.13.3.2how well do age verification technologies work?in general, avts protect against deliberate access to sexually explicitmaterial that is being sold. however, they provide no protection againstnoncommercial sexually explicit material (e.g., an exchange of sexuallyexplicit images between two friends), or against deliberate or inadvertentaccess to òteasersó on adult web sites. avts also provide benefits bothfor the owner of an adult web site (who can operate with less fear ofbox 13.1boilerplate disclaimerthe following disclaimer indicates the conditions to which a potential visitor to aweb site containing adultoriented, sexually explicit material might be asked toagree.this website contains sexuallyoriented adult content which may include visualimages and verbal descriptions of nude adults, adults engaging in sexual acts, andother audio and visual materials of a sexuallyexplicit nature.permission to enter this website and to view and download its contents is strictlylimited only to consenting adults who affirm that the following conditions apply:1. that you are at least 18 years of age or older, and that you are voluntarilychoosing to view and access such sexuallyexplicit images and content for yourown personal use.2. that you intend to view the sexuallyexplicit material in the privacy of yourhome, or in a place where there are no other persons viewing this material who areeither children, or who may be offended by viewing such material.3. that you are familiar with your local community standards and that thesexuallyexplicit materials which you have chosen to view and/or download fromthis website are well within the contemporary community standards of acceptanceand tolerance of your community for sexuallyexplicit materials of that nature.if all of these conditions apply to you, you are given permission to enter. if any ofthese conditions do not apply to you, you are not given permission to enter and viewthe contents of this website and you should now exit.source: see <http://www.karasxxx.com>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.342youth, pornography, and the internetrunning afoul of the law) and for society (which can reduce the frequencyof children coming into contact with adult material or making transactions reserved for adults only).avts protect primarily against deliberate access to sexually explicitmaterial for which adult web site operators require payment. to beeffective, age verification technologies must be deployed in front of anycontent that is inappropriate for childrenñin other words, a user musthave to pass through an adult verification screening (thus verifying thathe or she is an adult) before he or she has access to adultsonly content.material behind an avt screen is inaccessible to most search enginesñand thus cannot be found inadvertently. however, this simpletoachievesafeguardñplacing a òplain brown wrapperó around an internet adultweb siteñis often not implemented even by those sites that require acredit card to get past the teaser pages.the effectiveness of avts is mixed, though they clearly do eliminatesome significant percentage of children who would otherwise gain accessto sexually explicit material. factors that reduce the effectiveness of creditcards as avts include the placement of highly explicit material beforecredit card numbers must be submitted, possession of credit cards bychildren (but see box 13.2), and the availability of parental credit cardsthrough the rifling of a parentõs wallet or purse. on the other hand, theuse of credit cards is convenient for both user and vendor, and access canbe granted in a matter of a few minutes.as noted in chapter 2, avts that rely on public records indicatingage provide a higher level of assurance regarding age. but the highestlevel of assurance is provided by coupling these public records with theuse of the postal service to authenticate the userõs identity, and thus thishighest level of assurance is incompatible with rapid initial access. inaddition, because not everyone has a driverõs license or is registered tovote, vendors that rely on avts based on public records have a smalleraudience than they would otherwise have. (in other words, these avtsexclude individuals who would be entitled to gain access.)avts also presume that an adult has not left the access device without logging out. if he or she does not log out, the next userñwho may bea childñwill automatically have access to all of the content that wasaccessible to the adult.finally, the age of adulthood differs from state to state. because it istechnically difficult to make geographical distinctions among points towhich content is delivered, in practice most web site owners choose 18 asthe threshold age above which they will allow access, even if in somestates 16 or 17 would be perfectly acceptable and legal. in these cases,those individuals are denied access for no legal reason.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.343technologybased tools available to nonend users13.3.3who decides what is inappropriate?the web site owner is the primary decision maker about whether ornot the site contains material that is inappropriate for children. if so, theweb site owner deploys avts to prevent access by children. however,there have been legislative attempts to promote the use of avts, as described in chapter 4.because it is the web site owner that makes the decision to use avts,many sites containing what some people consider inappropriate materialwould not see any need for age verification (e.g., victoriaõs secret). as abox 13.2visa buxx prepaid visa cardsvisa buxx is a prepaid, reloadable visa card that teens can use everywhere visais accepted. spending is limited to the amount of money parents load onto the card.when a teen makes a purchase with the visa buxx card, the purchase amount isdeducted from the card balance. at their discretion, parents can add money to thecard or can set up a regularly scheduled automatic transfer to the card as they wouldin giving a child an allowance.a visa buxx card is used in exactly the same manner as a regular visa card, andtransactions with the visa buxx card are processed as though it were a credit card.recognizing that merchants may question a teenagerõs use of a visa buxx card thatlooks like a visa card, visa tells teens that if a merchant asks for identification, theyshould present their school id if available; and that otherwise, the merchant shouldensure that the signature on the back of the card matches the signature on the salesreceipt.with respect to using the visa buxx card at inappropriate places that are online,visa advises parents to discuss how and where the teen can use the card. parents arealso able to review teen spending online using the visa buxx web site, and visa canemail a parent whose teen uses the card at a merchant associated with a code thatindicates the merchant may sell products and services considered inappropriate forteen use. however, not all merchants listed in this designation fit the general description of the category, and so it is up to parents to address with the teen any issuesrelated to the use of the card.the visa buxx card is similar to prepaid telephone calling cards, except that itcan be used to pay for any item or service, rather than just telephone service. visabuxx purchases are not anonymous, but there is no reason that, in the future, anonymous prepaid cards issued by visa or mastercard would not be as available asprepaid telephone calling cards. moreover, there is no reason for a vendor to discriminate in the sale of these cards on the basis of age, and it will thus be harder touse such cards as an indication of adult status.source: adapted from information on the visa buxx card available online at <http://www.visabuxx.com/learnmore/faqs.cfm>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.344youth, pornography, and the internetpractical matter, avts will be used to differentiate adults and childrenonly when the site contains material that the site operator believes isobscene with respect to minors.13.3.4how flexible and usable areproducts for verifying age?more rigorous age verification procedures often, but not always, increase the òhassle factoró that users face. for example, the highest degreeof reliability is available when public records can be checked and anaccess code sent to the postal address associated with those records. however, such a requirement also prevents adults from gaining the immediateaccess that is possible with certain other methods.13.3.5what are the costs and infrastructurerequired for age verification?financial coststhe costs of using avts fall primarily on web site owners and onadult users.psychological and emotional costsavts may entail a loss of privacy for the adult user, both perceivedand real. in a facetoface transaction with a clerk checking a driverõslicense, there may be some embarrassment, but as a general rule, the clerkdoes not make a record of the license and does not record the titles of thematerial being purchased or rented. as importantly, the user can see thatthe clerk is not doing so. when an online avt is used, the reasonableassumption would be that records are being kept (whether or not they arein practice), and so the user has a plausible reason to be concerned that hisname is associated with certain types of material.the privacy problem is exacerbated by how some avts work. forexample, an age verification system (avs) often provides a code numbercertifying age, which the user enters into the age verification field on anadult web site. usually, the web site then contacts the avs to check thevalidity of this number (which will expire if the user does not maintainhis avs membership). thus, the avs has a complete record of all of theadult sites visited using its age credential.furthermore, avts that rely on public records generally have accessto the age information recorded therein. thus, the age of a user is madeavailableñeven though that provides more information than is needed tosatisfy statutory requirements.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.345technologybased tools available to nonend usersnote also that commercial trends are pointing increasingly towardthe customization of computer and device behavior and function to specific users (who may be one of many using a particular device). to theextent that this is true, age information may be associated with suchfunctionality. at the same time, for many hosts, there are few incentives and not much of a business case to go to the expense of deployingavts.it should be noted that legislation such as the child online protectionact (discussed in chapter 4) does not require personal identificationñtheavts specified in the legislation are intended as a way to screen out mostminor children, not to obtain the identity of users. however, the transaction between site operator and credit card company inevitably entails someexpense for the credit card company, and so the credit card company is notlikely to be willing to process such requests if no revenue results from itñtherefore, the site operator will submit only transactions that are associatedwith an actual purchase, rather than a simple age verification request, andpurchases are necessarily connected with personal identity.infrastructurethe primary infrastructure issue is the deployment of avts amonghost sites. avts can play a meaningful role in reducing the access ofchildren to adultoriented material only to the extent that they are indeedwidely deployed. (if they are not, they render only a small amount ofcontent unavailable, and the generic equivalent of that material is almostcertainly available elsewhere.)depending on the kind of avts involved, other cooperating institutions or individuals are necessary.¥avts that rely on public records indicating age obviously depend onthe availability of those records from public agencies. given that there is somecontroversy about the widespread commercial availability of such records,their continued availability from public agencies cannot be taken for granted.¥avts are often built into parental controls, and parental controlsmust be deployed by the adults responsible for youth. in practice, todayõsinfrastructure for internet access means that all access points (computers)that a given youth might use must have the appropriate parental controls.13.3.6what does the future hold for age verification systems?improvements in avss depend primarily on the development anddeployment of an infrastructure to support age verification, rather thanthe technologies themselves. for most commercial online transactions,youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.346youth, pornography, and the internetthe age of the consumer is not particularly relevant, assuming that theconsumer has the ability to pay for the products or services being offered.thus, there appears to be no generalpurpose need for a pervasive infrastructure for age verification.this suggests that if improved avss are to be available for vendors ofadultonly services and products, the infrastructure required for verifying age must either be (a) a subset of an infrastructure that can be used forbroader purposes, or (b) deployed by those vendors.in case (a), a number of scenarios are possible. for example, smartcard technology enables a higher degree of security in authentication thando passwords, which are easily compromised. a òsmart cardó is a smallphysical hardware device (typically the size of a credit card) containingreadonly nonvolatile memory and a microprocessor that can be insertedinto a card reader attached to a computer. in most scenarios, the individual user carries the card and inserts it into an internet access point thatrequires such a device. the memory provided on the device can storeinformation about the user, including his or her age, preferences for material to be blocked, and so on. software installed on the computer, and onweb sites visited, would check the smart card for dates of birth whennecessary, and if the user were underage for certain types of material,would refuse to grant access to that material. however, computing andinternet access technology has not developed in this direction, and thecosts of converting to such an infrastructure specifically for this purposeare entirely prohibitive.if, for other reasons, such technologies become common on personalcomputers and other devices that can be used to access the internet, thoseoffering adultonly products or services would be able to require a smartcardenabled age verification as a condition of access. even today, one firmseeks to offer òsmartó library cards on which parents can indicate theirpreference for their children to have filtered or unfiltered internet access inthe library.12 nevertheless, the effectiveness of such an approach dependson the vendorõs decision to deny access to those who are unable to presenta smart card, for whatever reason (including the lack of a card reader on aninternet access point or a legitimate adult customer who lacks the smartcard). such a decision runs quite counter to business incentives to achievethe maximum exposure of a product or service being sold.another scenario is that a vendorõs knowledge of a userõs age maywell provide business benefits and more lucrative marketing opportunities. routine collection of age information may well occur in the futurewith tools that provide automated policy preference negotiation (e.g.,12see <http://www.libraryguardian.com>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.347technologybased tools available to nonend userspassport and similar products13). however, age information collected inthis manner may well not be verified (as it is surely not when a child isasked online to reveal his or her age).in case (b), the current òadult checkó services available are an example of a vendorsupported infrastructure. however, for the most part,the adultcheck services used by those providing sexually explicit material are based on credit cards. (one might argue that credit cards arethemselves an infrastructure on which adult check services build.) moreeffective verification services that are dedicated to serving these vendorsare likely to entail additional expense.todayõs credit cards do not distinguish between minor and adultowners. but it is technically feasible for credit cards issued to youth to betagged with an entry in the credit card companyõs database saying òdonot authorize payment for sexually explicit material.ó the downside ofsuch an approach is the processing burden that it imposes on the creditcard companyõs systems.given widespread concerns for privacy, it may also be possible todevelop avts that provide a greater degree of privacy for individualusers. in particular, the legal requirement that age verification technologies are seeking to meet is not the age of the user but rather whether on agiven day he or she is over 18 (or whatever the age of majority is).finally, despite the limitations of avts based on credit cards, theycould be much more effective if they were systematically coupled withòplain brown wrappersó around the content that is inappropriate for children. chapter 9 described elements of a regulatory approach that can beused to encourage the deployment of avts in front of all content that isregarded as inappropriate for children.13.3.7what are the implications of usingage verification systems?widespread avts may compromise the privacy of adult viewing.also, some avts enableñindeed requireñsystematic tracking of all sites13passport (specifically, kids passport) is a service offered by microsoft that is intended toenable parents to decide whether their children can use services provided by participatingweb sites that collect and/or disclose personally identifiable information. these services caninclude newsletters, discussion groups, penpal programs, wish lists, and contests. parentscan provide consent for three levels of accessñno consent (child can use the web site but notservices that collect or disclose personal information), limited (third party can collect personalinformation but is not allowed to share or display it), and full (third party can collect and/ordisclose personal information according to its privacy policy). for more information, see<http://kids.passport.com> and <http://www.microsoft.com/presspass/features/2000/0208passport.asp>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.348youth, pornography, and the internetthat use a given age certification, thus allowing a dossier of visited adultsites to be compiled. thus, they may inhibit free flow of information andcreate a chilling effect on the freedom of adults who wish to access lawfulthough perhaps controversial material.widespread requirements to present documents certifying oneõs ageraise many of the same concerns that national id cards raise. in particular, while acknowledging that verification of oneõs adult status is necessary from time to time, the concern is that a diversity of methods anddocuments for certifying oneõs adult status willñin the name of simplicityñlead easily to a single document indicating age, and perhaps otherpersonal information. once such a document exists, it becomes very easyto insist on the use of this document as the necessary documentation for awide range of societal benefits, such as employment, health care, gunownership, and so on. much as the social security number has evolvedinto a de facto universal identifier, such a document could well becomethe basis for national databases that track all of the significant activities ofall those with this documentñand all of the concerns about loss of privacy and government/private sector abuse emerge in full force.13.3.8findings on age verification technologiesone approach to protecting children from inappropriate sexually explicit material on the internet is based on being able to differentiate between children and adults in an online environment, and avts are a toolavailable for doing that.1.those wishing to verify age with very high levels of confidencerequire that a document with proof of age can be associated clearly andunambiguously with the specific individual in question.14 over the internet, there is no mechanism known to the committee that accomplishesthis task on a short time scale (seconds or minutes).152.as a practical matter, avts will be used to differentiate adults andchildren only when the site contains material that the site operator believes is obscene with respect to minors.3.mechanisms that prevent age verification on short time scales arelikely to have a significant negative impact on sales and would be an14compared to credit cards, avts based on public record databases do provide a somewhat higher level of assurance of an alleged adult status (see finding #4 in this section).but if these public record avts do not also use an offline method to verify identity, they aresubject to many of the same problems associated with the teenager use of credit cards thathave been pilfered from a parentõs wallet.15this finding refers only to the first time the individual needs age verification. in subsequent interactions, the individual can generally use the certification that was previouslyprovided.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.349technologybased tools available to nonend usersimpediment for adults seeking commercial adultoriented products andservices.4.avts based on credit cards do provide some significant obstaclesto children seeking deliberate access to inappropriate sexually explicitmaterial. however, as credit cards (and prepaid cards usable as creditcards) are increasingly marketed to adolescents as young as 13, such avtswill become less useful. furthermore, parents that have explicitly allowed their children to have credit cards or prepaid cards may be morelikely to trust the viewing behavior of their children as well.5.the underlying technology to support widespread, highconfidenceage verification does exist, but its implementation could be very expensive,and its use would raise a myriad of important privacy concerns.13.4tools for protecting intellectual propertythe widespread use of tools for protecting intellectual property mayhelp to reduce the exposure of children to inappropriate sexually explicitmaterials that may have been taken from subscription adultoriented websites.13.4.1what are tools for protecting intellectual property?a variety of technologies have been developed to protect intellectualproperty. for example, some rights management technologies enable animage to be transmitted to a given user but increase quite substantiallythe difficulty of printing, forwarding, or saving it.16 (box 13.3 describessome rights management technologies.) other tools compare an image ortext found on a web site to a known and properly owned image or text(presumably the property of its creator or subsequent rights holder), andallow the flagging of nearmatches that may indicate improperly derivedworks.the primary users of rights management tools would be content providers with proprietary content.13.4.2how well do tools for protecting intellectual property work?as noted in chapter 3, the online adult industry is highly stratifiedñandincludes a relatively small number of wellestablished firms and a much16it is of course true that one can always take a photograph of a screen, and then dealwith it as one would prefer. but disabling systemprovided capabilities for printing, forwarding, and saving goes a long way to protecting content.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.350youth, pornography, and the internetlarger number of òflybynightó operators, many of whom illegally use copyrighted content from established firms. wide use of rights managementtechnologies could significantly reduce the flow of new content to these firms.there is some reason to believe that these smaller firms and operating entitiesare also the parties that are least responsible about keeping children awayfrom their adultoriented content.17 to the extent that this is true, drying upthe supply of new content for these firms will increase the likelihood of ashakeout in the industry that will increase the prominence of the more established firms at the expense of these smaller ones.box 13.3rights management technologiesrights management technologies fall into two generic categories: technologiesto prevent (or increase the difficulty of) an unauthorized use of an information object(e.g., an image, an audio file, a book, a movie), and technologies to facilitate afterthefact detection of unauthorized use.technologies intended to prevent (or increase the difficulty of) an unauthorizeduse of an information object (prevention technologies) generally rely on encryptiontechniques. for practical purposes, an encrypted information object bears no resemblance to the original, useful, unencrypted information object. thus, such technologies rely on the authorized source of the object distributing the encrypted information object to anyone who wants it, but restricting the decryption key (withoutwhich the encrypted object is useless) to authorized parties only.once the encrypted object is decrypted, it is usableñand if special precautionsare not taken, the receiver can distribute it freely. thus, prevention technologies relyon decrypting the object as close as possible to the point of use, and/or restricting theability of the user to copy, email, forward, or print the decrypted object. for example, an image viewer might allow the display of an image but disable the functionality of the operating system to copy that displayed image to temporary files.technologies to facilitate afterthefact detection of unauthorized use (detectiontechnologies) embed into the unencrypted information object additional informationthat allows its creator to be identified. an example of such a technology is a digitalwatermarkña digital pattern that is inserted into an image that does not alter itsquality but is also not easy to remove. such transparent watermarks have obviousadvantages from the standpoint of providing images that lack visible copyright markings and are as visually attractive as possible.more discussion of these technologies can be found in the cstb report the digital dilemma.11computer science and telecommunications board, national research council, 2000, thedigital dilemma: intellectual property in the digital age.17for example, the smaller ones are likely to derive some considerable fraction of incomefrom raw traffic, thus giving them little incentive to screen out children. see chapter 3 formore details.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.351technologybased tools available to nonend usersa more mature adult industry (consisting of established firms ratherthan the òflybynightersó) is likely to have more concerns about the protection of intellectual property as well as being more likely to take actionsto restrict the access of children to their products. with a reduction in thecontent available to flybynight firms that are less likely to take actionsrestricting the access of children, certain types of adult content will be lessaccessible to children. the reduction is likely to mean a lower degree ofinadvertent access, but the ease of deliberate access to generic adult content is likely to be unaffected to a significant extent.approaches based on tools to protect intellectual property of the adultentertainment industry are relevant only to content originating there, andhave no applicability to content for which no intellectual property rightscan be legally asserted.a second benefit of tools that detect possible thefts of intellectualproperty is in the prosecution of child pornography. as noted in chapter 4, obscenity and child pornography differ in a number of key respects,and one of the most important differences is that while a legal determination that an image is obscene depends on factors extraneous to the imageitself (i.e., on community standards), a legal determination that an imageconstitutes child pornography does not. thus, once an image has beendetermined to be child pornography, images that are substantially identical to it (e.g., cropped images, images with shading superimposed on top)can also be determined to be child pornography. thus, images suspectedof being child pornography can be automatically compared (e.g., by awebcrawling òspideró) to databases of known child pornography.18 sucha technique will not identify new images of child pornography, but sincea substantial amount of child pornography is òrecycled,ó application ofthis technique is still relevant.the impact of rights management tools (rmts) on reducing access ofchildren to adultoriented material depends on their widespread use, butin any case is an indirect one. the primary purpose of an rmt is toprotect intellectual propertyñand the secondary effect may well be toreduce the volume of adultoriented materials available to children.13.4.3who decides what is inappropriate?this question is not applicable in this context.18see, for example, testimony of mark ishikawa, ceo of bay tsp to the copa commission, on august 4, 2000. available online at <http://www.copacommission.org/meetings/hearing3/ishikawa.test.pdf>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.352youth, pornography, and the internet13.4.4how flexible and usable are productsfor protecting intellectual property?from the standpoint of the end user, the primary usability issue is theextent to which different content providers use the same rmts. if everyweb site uses a different òhomegrownó rmt, the user interfaces forviewing content are likely to be differentñand thus the user will have touse different methods for viewing different web sites. this limiting caserepresents the greatest degree of inconvenience for the user.13.4.5what are the costs and infrastructurerequired for protecting intellectual property?an approach based on the protection of intellectual property requiresclientside software and hardware to perform rights management. whilein principle any individual content provider could simply downloadrights management software to a user to protect its intellectual property,the effort required to do so is large. a widely deployed rights management system would be something on which many content providers couldrely to protect intellectual propertyñand some infrastructure software,such as windows media player, is beginning to incorporate such features.alternatively, the content providers in the adult industry could developtheir own rights management system and require that their content bedisplayed through it.an essential element of infrastructure for the use of tools to protectintellectual property is an enforcement mechanism. the enforcementmechanism is technical if the technology prevents content from beingimproperly copied. however, such systems sometimes affect the userõsexperience, making systems slower and less convenient to use and tocustomize for his or her needs. content providers who insist on usingsuch systems then must deal with customer dissatisfaction that arises as aresult. when the technology facilitates or enables the detection of piratedmaterials, a procedural or organizational or legal mechanism is needed toprevent further pirating and/or to deter others from doing the same. forexample, if pirated materials are found on the bulletin board of an internet service provider, the isp has to be willing to take down pirated material if intellectual property rights are to be respected.13.4.6what does the future hold for tools for protecting intellectual property?as of this writing (may 2002), a variety of technology vendors are inthe early stages of developing rights management metadata systems, byyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.353technologybased tools available to nonend users19computer science and telecommunications board, national research council. 2000.the digital dilemma: intellectual property in the digital age. national academy press, washington, d.c.20computer science and telecommunications board, national research council, 2000,the digital dilemma: intellectual property in the digital age.themselves (e.g., xmcl from realnetworks and others (http://www.xmlcl.org)) and as part of broader content standards (e.g. mpeg21). at the same time, peertopeer technologies such as gnutella demonstrate that if a single copy of content can be placed on the network with norights management wrapping or marked as òunlimited and untrackeduse by anyone,ó it can become widely distributed rapidly.a more detailed discussion of the future of tools for protecting intellectual property is beyond the scope of this report. a report by the national research councilñthe digital dilemmañaddresses this point ingreater detail.1913.4.7what are the implications of tools forprotecting intellectual property?discussing the implications of tools for protecting intellectual property is beyond the scope of this report. a cstb studyñthe digital dilemmañaddresses these implications in substantial detail.2013.4.8findings on tools for protecting intellectual property1.purloined content accounts for a significant fraction of sexuallyexplicit material on the internet, though reliable data on this point is hardto obtain. tools for protecting such content as the intellectual property ofits creators thus have some potential to limit the number of web sites andchannels through which such content might be obtained.2.to the extent that the rightful owners of this content are firmssufficiently established to be willing to take steps to deny children accessto their material, it is in the interest of children that the intellectual property rights of these parties are respected. owners and operators of adultweb sites will have to take the initiative to enforce intellectual propertyprotection if this approach is to prove viable.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.part iiiyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.356youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.35714.1framing the issuethe internet has enormous potential to contribute to public welfareand private wellbeing. one dimension of that potential involves the useof the internet to enhance and transform education for the nationõs youth,and many public policy decisions have been taken to provide internetaccess for educational purposes. easy access to the internet (and relatedonline services) has many advantages for childrenñaccess to educationalmaterials; collaborative projects, publications, online friendships, and penpals; access to subject matter experts; recreation, hobby, and sports information; and so on.while such potential for contributing to the nationõs welfare in general and to the education of its children in particular is recognized, theinternet also presents to the public a wide variety of concerns. this fact initself should not be surprisingñfew powerful and widely deployed technologies have been used solely for socially beneficial purposes. but theinternet poses many challenges for which there are no precedents, andmuch of the controversy about inappropriate sexually explicit material onthe internet arises because of these differences.14.1.1social dimensionswhat is the issue to be addressed? although the nominal title of theproject was òtools and strategies to protect kids from pornography on14findings, conclusions,and future needsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.358youth, pornography, and the internetthe internet and other inappropriate material,ó a key fact is that òpornographyó is a term whose meaning is not well specified. people nevertheless use the term as though it did have a wellspecified meaning, and theyoften fail to recognize that what one may consider pornographic, anothermay not. for this reason, the committee chose the term òinappropriatesexually explicit materialó when in common parlance it might have usedthe term òpornography.ó using the former term keeps in the foregroundthe question of òinappropriate according to whose standards?óinternet exposure of children to sexually explicit material is only onedimension of exposure, albeit important, because sexually explicit material and other sexual content exist in a wide variety of other commonlyaccessible media such as video cassettes, magazines, and cable television.further, concerns over obscenity may well be a proxy for the desire tosuppress access to other sexually explicit or sexually oriented content thatwould not be judged legally obscene.internet exposure of children to inappropriate sexually explicit material is also only one dimension of inappropriate or potentially dangerousactivities in which youth may engage. the internet is also a medium thatcan facilitate facetoface meetings between people who do not know eachother prior to their internet contact, and when there is a great disparity ofexperience and age between these parties, the younger lessexperiencedperson could be more subject to exploitation and physical danger. othertypes of material may also be judged by various parties to be inappropriate for children. some of the approaches to protection from sexuallyexplicit material may be applicable to such other material.the views of people about òpornographyó on the internet and what todo about it reflect a broad range of values and moral commitments. whatis pornographic to some people may be simply mainstream advertising toothers; what is morally wrong to some may be entirely acceptable to others;what is legal to show to minors in one community may be regarded aswholly inappropriate by those in another community; and what counts asresponsible choice according to one set of values may be irresponsible behavior according to a different set of values. approaches taken to protectchildren should be flexible enough to honor that diversity.14.1.2developmental dimensionschildren from birth to the age of legal majority pass through a widerange of developmental stages as they mature into adults (and furthermore the age of legal majority is not statutorily uniform). the impact ofany given piece of sexually explicit material is likely to vary widely withage or, more importantly, level of maturity, and the approaches taken toyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.359findings, conclusions, and future needsprotect children of a given maturity level should take into account thecharacteristics of their level of maturity. moreover, the experiences ofindividuals can influence how sexual content affects them, especially considering that increasing numbers of adolescents, who are still legally minors, are sexually active. finally, age usually affects the extent to whichchildren can understand dangers and engage in safe behavior.the information needs of children that the internet can and shouldmeet also change with the developmental stage of the child in question.for example, juniors and seniors in high school have a much broaderrange of information needs (i.e., for doing research related to their education) than do those in the third grade or in junior high school. this, inturn, leads to the question of how to provide older children with access toa broader range of material while preventing younger ones from accessing material that is not deemed appropriate given their developmentallevel.14.1.3legal dimensionsas a matter of law, sexually explicit material that is òobscene withrespect to minorsó must be made available to adults without restriction,though it can be restricted for minors. certain other sexually explicitmaterials (obscenity, child pornography) enjoy no first amendment protection at all. material that is determined to be obscene or obscene withrespect to minors must pass certain tests, including tests related to community standards. for both classes of material, the community standardsfor making such determinations likely change over time, and in recentyears, mores about sex and consumption of sexually explicit material mayhave changed in such a way as to reduce (but not to eliminate) the scopeof both categories.thus, there is in practice considerable ambiguity about what shouldfall into these categories, and the fact that community standards are integral to the application of the law in this area means that material cannotbe determined to be obscene or obscene with respect to minors solely onthe basis of the material itself. over the past decade, the number offederal obscenity prosecutions has been very small compared with thosein previous years, thus complicating to a significant degree the concept ofòcommunity standards.ó the first amendment is relevant regarding theextent to which and circumstances under which public institutions ofvarious types can restrict access to particular types of information.finally, in the public policy domain, u.s. regulation of sexually explicit material is most likely to have an effect on commercial sourcesinside the united states, and far less effect on sources located abroad.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.360youth, pornography, and the internet14.1.4technical dimensionsmaking some material available to adults but not to children requiresthat providers have a reasonably reliable way of differentiating betweenthem. in the physical world, such differentiation can often be accomplished with reasonable ease (e.g., by checking a driverõs license or otheridentification). but in the internet context, rules based on age differentiation are highly problematic and technically difficult to enforce. contentproviders must also have a clear understanding of the difference betweenmaterial that is and is not inappropriate for children.although many of the issues concerning internet access to varioustypes of material that may be regarded as inappropriate arise for othermedia as well, the internet changes significantly the convenience andanonymity of access, thus reducing certain constraints that may be operative in other media. for example, online chat rooms and instant messages(ims) have few analogs in the physical world, and these are channelsthrough which a great deal of communication between strangers can occur. for this reason, special attention to the internet dimensions of theissue may be warranted.the adult online industry notwithstanding, inappropriate sexuallyexplicit material is available from many noncommercial online sources.thus, approaches that focus primarily on access to inappropriate sexuallyexplicit material provided by the adult online industry (widely seen asthe crux of todayõs problem) are likely to have limited relevance to problems arising from noncommercial sources.for a great deal of inappropriate sexually explicit material (specifically, material accessible through web sites), a reduction of the number ofweb sites containing such material, in and of itself, is not likely to reducethe exposure of children to such material. the reason is that a primarymethod for obtaining access to such material is through search engines,and the likelihood that a search will find some inappropriate material fora given set of search parameters is essentially independent of the number ofweb pages represented in that search. that said, if the number of such websites is small enough that no web site operator can flout the rules of responsible behavior with impunity,1 regulation of their behavior (through public1in this context, responsible behavior refers to actions taken to reduce the likelihood thatchildren will obtain access to inappropriate sexually explicit material. to illustrate, onemethod of inducing web site operators to act responsibly is to establish codes of behaviorto which they must adhere under pain of government enforcement actions (whether civil orcriminal). by definition, such an approach requires government action, and with a plethoraof operators, the likelihood of being the target of government action is very smallñhencethe number of operators must be reduced to a òsufficiently smalló number. a secondillustration of inducing web site operators to act responsibly is to create disincentives foryouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.361findings, conclusions, and future needspolicy and/or selfregulatory approaches) becomes significantly easier,and enforceable codes of responsible behavior can have a significant impact on the extent to which operators of web sites that contain adultoriented, sexually explicit material make their products and services accessible to children.14.1.5economic dimensionsthe adult online industry is one of the primary sources of sexuallyexplicit images (e.g., on òteaseró home pages) that are accessible withoutany attempt to differentiate between adults and children. such teaserpages allow potential customers to sample what would be available withpayment, but children have easy access to the free content. the sexuallyexplicit material provided by the adult online industry is available tochildren through a variety of routes, including mistyped web site addresses, links returned by search engines in response to search terms withsexual connotations, and spam containing links to adult web sites.the revenue models of the adult online industry suggest that broadexposure is needed to attract potential customers, and so the industryengages in tactics that seek to generate the broadest possible audience.moreover, these tactics to gain exposure cannot be used at low cost if theyare to differentiate between adults and children. the result is that children can be òswept upó in the industryõs reach for larger audiences ofpotentially paying customers.the adult online industry is only one component of supply. the lowcost of creating and maintaining a web site means that the production ofsexually explicit material is now within the financial reach of almost anyone. for example, web cameras can be purchased for under $100, enabling anyone so inclined to produce a video stream of sexually explicitmaterial.in the internet environment, an astronomically large volume of material is available for free, including art, literature, science, advertising, andirresponsible behavior. in this method, the key is to associate disincentives with a largenumber of parties so that irresponsible web site operators will feel the pressure of thosedisincentives, for example, by establishing causes of action allowing those affected by irresponsible behavior to take action against such operators. (one example in a different domain is the establishment of liability (and an associated bounty) for junk faxes, an actionthat dramatically reduced the number of such faxes.) whether or not these or other actionscan in fact reduce the number of web sites to a òsufficiently smalló number is an openquestion, especially in a context in which u.s. actions are unlikely to affect web sites operated by foreigners. note that these illustrations are just thatñillustrationsñand their inclusion in the report is not intended to signal endorsement or rejection by the committee.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.362youth, pornography, and the internetgovernment information, as well as sexually explicit material of every variety. restricting what any individual may access (or protecting him or herfrom certain kinds of material) will inevitably impose additional costs onusers. such costs may include denial of access to useful information andloss of privacy for those wishing to access certain kinds of information.14.2on the impact on children of exposure tosexually explicit material and experiencesas described in chapter 6, factors such as certain ethical and legalconsiderations, an increasing conservatism of university review boardsthat approve research studies involving human subjects (institutional review boards), and a lack of research funding have contributed to a paucity of research regarding the impact on children of exposure to sexuallyexplicit material. furthermore, the extant scientific literature does notsupport a scientific consensus on a claim that exposure to sexually explicitmaterial doesñor does notñhave a negative impact on children, andthere is no adequate research base for understanding the impact of sexually explicit material of various kinds and how different approaches toprotection may vary in effectiveness and outcome.it is important to consider why many young people search for adultoriented sexually explicit material in the first place. adolescents go tothese sites for many of the same reasons that adults do. human beingsare sexual. sexuality is a part of identity, and a facet of identity that is afocus during adolescence when youth come of reproductive age. it is notsurprising that many childrenñespecially preadolescents and olderñarecurious about sex, and adolescents who are sexually mature are lookingfor information about sex and are making choices in this arena. in otherearlier eras, they might well be married, but today in western culturemarriage among those in their early and midteens is frowned upon. tothe extent that adults (parents and families, schools, libraries) provideaccurate information and guidance about sexuality in its biological, psychological, emotional, and social dimensionsñand information and guidance that is responsive to the situations that their children are facingñitcan be argued that young people will be less drawn to searching for adultoriented sexually explicit material.this is not to say that parents are wrong to be concerned about theirchildrenõs exposure to sexually explicit material. there is no reason tosuppose that all negative impacts from exposure are necessarily shown ormanifested in sciencebased research studies. the moral and ethical values of parentsñwhether or not religious in orientationñand a desire tobe involved in providing context and guidance for a child exposed to suchmaterial are important and understandable drivers of such concerns.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.363findings, conclusions, and future needsthe committee believes that it would not be difficult to come to aconsensus on the undesirability of some set of sexually explicit materialinvolving depictions of extreme sexual behavior. that is, such a set couldbe developed by constructionñimage after image could be shown to agroup of individuals drawn from a broad cross section of the community.(in some ways, the committee consists of just such a group.) under thisprocedure, the images that everyone on the committee deemed inappropriate for children would constitute the setñand the set would be substantial in size. such a consensus would not be based so much on scientific grounds (as the committee knows of no reliable scientific studies thataddress this point) as much on a sense that such exposure would offendits collective moral and ethical sensibilities. furthermore, the committeebelieves that a significant fraction of this set would likely be deemedobscene if prosecuted.yet, the fact that such a set could be defined by construction does notmean that it is possible to craft unambiguous rules that define this setwithout capturing material that would either be protected speech underexisting first amendment precedents or unobjectionable to some numberof group members. and, in the absence of such rules, disagreement isinevitable over what else other than òsimilaró material should be captured in any definition.the story is quite different for child pornography. in contrast to thediversity of views about what material must count as obscenity or obscene with respect to minors (and hence a diversity of views on whatharm might result to children from being exposed to such material), thereis a much broader social consensus that child pornography results inharm to the children depicted in such images and that child pornographyis morally wrong as well.2 over the past decade, the incidence of childpornography has risen as new communications channels such as the internet have facilitated the exchange of child pornography.a similar argument applies to sexual predation. by design, the internet facilitates contact between people who do not know each other. whilemuch that is good and valuable and safe can come from interactions withstrangers, parents rightly have some concern when their children talk tostrangers in an unsupervised manner. these concerns arise in the physical world, and they are magnified in the online environmentñwhere therange of personality types and intentions is both less known and less2the social consensus is strongest when children are used to create sexual imagery. however, the breadth of the legal definition of child pornography has also led to the attemptedprosecution of works of art that involve children in various states of nudity (e.g., the worksof jock sturges), and it is fair to say that there is less of a social consensus around suchmaterial.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.364youth, pornography, and the internetcontrollable. further, the internet has enabled potential predators to seekout a wider range of vulnerable children.the committee believes that the issue of facetoface meetings between children and their internet acquaintances is very different fromthat of being exposed to inappropriate material on the internet becausethe potential dangers that facetoface meetings entail are much greater.furthermore, while the majority of children report that they brush offaggressive solicitation encounters or treat them as a relatively minor annoyance, a significant minority do report being upset or disturbed bythem (see section 5.4.3). in addition, even when children were distressed by such encounters, a large fraction of them did not report the incident toparents or other authorities.finally, the committee believes that there is a consensus regardinginvoluntary exposure to sexually explicit material. regardless of oneõsviews on the impact of voluntary exposure to sexually explicit material,the committee believes that there is a reasonably strong consensusñindeed, one reflected in its own deliberationsñthat involuntary internetexposure to sexually explicit material is inappropriate and undesirableand should not be occurring, and it is particularly inappropriate andundesirable in the context of minors being exposed to such material.314.3on approaches to protectionmuch of the debate about òpornography on the internetó focuses onthe advantages and disadvantages of technical and public policy solutions.4 technology solutions seem to offer quick and inexpensive fixesthat allow adult caregivers to believe that the problem has been addressed,and it is tempting to believe that the use of technology can drasticallyreduce or even eliminate the need for human supervision. public policyapproaches promise to eliminate sources of the problem.in the committeeõs view, this focus is misguided: neither technologynor public policy alone can provide a completeñor even a nearly completeñsolution. as a rule, public policy aimed at eliminating sources ofsexually explicit material can affect only indigenous domestic sources,3are there any circumstances under which involuntary exposure might be beneficial?perhaps. consider a situation in which discussions about sex made a child uncomfortable.it might still be a reasonable thing for a concerned parent to have a conversation about sexwith his or her child. needless to say, this kind of situation does not occur frequently in thecontext of internet media.4the discussion in this section (section 14.3) is complementary to the findings and general observations in chapters 8 through 13, but does not repeat them systematically. readers are urged to consult those chapters for more specific findingsñespecially about technologybased tools such as filters and monitoring programs.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.365findings, conclusions, and future needsand a substantial fraction of such material originates overseas. nor istechnology a substitute for education, responsible adult supervision, andethical internet use.for these reasons, the most important finding of the committee is thatdeveloping in children and youth an ethic of responsible choice and skillsfor appropriate behavior is foundational for all efforts to protect themñwith respect to inappropriate sexually explicit material on the internet aswell as many other dangers on the internet and in the physical world.social and educational strategies are central to such development, buttechnology and public policy are important as wellñand the three can acttogether to reinforce each otherõs value.social and educational strategies are a primary focus of the committeebecause most children are likely to be confronted, on occasion, with material that theyñor their parentsñregard as inappropriate, or find themselves in online situations that are potentially dangerous. parents mustbalance their concerns about exposure to harmful things on the internetagainst the benefits gained from exposure to positive things on the internet, and the question of how children can learn to handle and defendthemselves becomes the primary issue. social and educational strategiesthat promote and teach responsible decision making are at the core ofsuch defense.social and educational strategies are also important for teaching children how to recognize and avoid situations that might expose them toinappropriate material or experiences. though technology has a role toplay here as well, developing òstreet smartsó about how to avoid troubleis likely to be a far more reliable and robust approach to protection.in short, a child who responsibly chooses appropriate materials toaccess and appropriate things to do on the internet and who knows whatdo to about inappropriate materials and experiences should he or shecome across them is much safer than a child whose parents and schoolteachers rely primarily on technology and public policy to solve the problem for them. moreover, social and educational strategies to promote andteach responsible choice have applicability far beyond the limited question of òprotecting kids from porn on the internet,ó because they arerelevant to teaching children to think critically about media messages, toconduct effective internet searches for information and to navigate withconfidence, and to evaluate the credibility of the information they receive.social and educational strategies are not quick or inexpensive, andthey require tending and implementation. adults must be trained toteach children how to make good choices on the internet. they must bewilling to engage in sometimesdifficult conversations. and, becausesocial and educational strategies place control in the hands of the youthtargeted, children may make mistakes as they learn to internalize theyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.366youth, pornography, and the internetobject of these lessons. however, by understanding why certain actionswere mistakes, children will more effectively learn the lessons that parents and other adults hope that they will learn. virtually all of the highschool students to whom the committee spoke said that their òinternetsavvyó came from experience, and they simply learned to cope with certain unpleasant internet experiences. they also spoke of passing theirnewfound expertise down to younger siblings, hence becoming thenew de facto educators for younger kids in the òsecond wave of digitalchildren.ótechnologybased tools, such as filters, can provide parents and otherresponsible adults with additional choices as to how best to fulfill theirresponsibilities. though even the most enthusiastic technology vendorsacknowledge that their technologies are not perfect and that supervisionand education are necessary when technology fails, tools need not beperfect to be helpfulñand used properly (an important caveat), they canbe an important aspect of comprehensive programs for internet safety.first, technology can help to create a childrearing environment thatparents can moderate and shape according to their values and the maturity of their children. in an internet context, a controlled and moderatedenvironment does not mean that a childõs every keystroke and mouseclick are preprogrammed forever. but it does mean that the child canexercise choices within safe limits set by parents or other responsibleadultsñand as a child learns more and develops greater maturity, thoselimits can be expanded in ways that allow greater freedom of choice andthat may at some point entail greater risk taking as well.an example of a technologymoderated environment for internet access might call for the provision of internet access in young childhoodthat is explicitly limited to childfriendly content (i.e., access based onòwhite listsó), strongly filtered internet access in middle childhood (i.e.,access based on extensive òblack listsó), less filtered internet access inpreadolescence and early adolescence (i.e., access based on a slow reduction in the number of categories deemed inappropriate), and monitoredinternet access in middle to late adolescence (i.e., unfettered internet access but accompanied by warnings about inappropriate material). parents wishing to provide a more riskfree environment might delay theintroduction of less restrictive measures; those wishing to promote a morefree flow of information to their children might accelerate the introduction of less restrictive measures.second, technology can help to keep parents and other responsibleadults informed about what their children are doing online. of course,the circumstances of obtaining such information matter quite a bit. anintent to provide guidance that helps the child make informed and responsible choices relies on the presence of openness about the presence ofyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.367findings, conclusions, and future needsmonitoring. on the other hand, an intent to òcatchó the child in doingsomething wrong is likely to result in behavior that simply reduces theflow of information to the parent, such as the child obtaining internetaccess in a venue that is not monitored.third, technology offers many desirable benefits: speed, scalability,standardization, and reduced cost. because nontechnical approaches takevaluable time from parents, teachers, and others that is badly needed toaddress many other issues related to raising responsible young people, itwill often be the case that a mix of nontechnical strategies and technologybased tools provides the most costeffective way to protect childrenon the internet.choosing the right combination of social and educational strategiesand technologybased tools depends a great deal on the nature of theproblem that parents, teachers, and librarians are trying to solve. forexample, recall from chapter 8 that deliberate access and inadvertentexposure to inappropriate sexually explicit materials pose different protection problems. recognizing that responsible adults have to deal withboth problems, the fact remains that certain tools and certain strategiesare more appropriate for the former than the latter, and vice versa. toolsthat warn of impending exposure to inappropriate material rather thanblocking are better suited to dealing with the problem of inadvertentexposure.one important point arising from the relative preponderance of malesrelative to females as consumers of adultoriented sexually explicit material(chapter 3) is that adolescent males are probably much more likely to seekout such material deliberately. if so, social and educational strategies thataim at reducing the desire of such individuals to seek out such materialmay well be more relevant to male children than to female children.as for the role that public policy can play in protecting children,regulation may help to shape the environment in which these strategiesand tools are used by reducing at least to some extent the availability ofinappropriate sexually explicit material on the internet. public policy canhelp to influence the adult online industry to take actions that better denychildrenõs access to their material and/or influence others in the privatesector to support selfregulatory or selfhelp measures. furthermore,through prosecution of violators of existing laws that prohibit the transmission of obscene material, public policy can help to some extent toreduce the number of providers of such materials.successful law enforcement depends on many factors, including appropriately formulated statutes, adequate resources, and a willingness toenforce existing law and regulation. in the internet safety arena, theparticipation of citizens (e.g., reporting illegal activity) is also an essentialelement of law enforcement. proper training of law enforcement personyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.368youth, pornography, and the internetnelñincluding those who take complaints, those who investigate complaints, and those who prosecute casesñat federal, state, and local levelsremains critical to effective law enforcement. finally, public policy (orthe threat of regulation) can also encourage and promote selfregulatoryefforts that contribute to certain public policy goals, such as internet service providers taking down materials posted in violation of the terms ofservice to which users agree as a condition of use.coping with noncommercial sources presents different issues to lawenforcement authorities. in order to attract customers, commercial sourcesmust draw attention to themselves, which means that their activities arehard to conceal from law enforcement authorities. but noncommercialsources such as peertopeer filesharing networks may present no easilyaccessible target for legal action (and under many circumstances can operate invisibly to law enforcement). to address noncommercial sources, lawenforcement officials must conduct what amount to òstingó operations.5such operations are controversial, are personnelintensive, and may notoffer large leverage, as noncommercial sources are likely to have significantly smaller audiences than commercial sources.table 14.1 contains an illustration of how social and educational strategies, technology tools, and public policy can work together.14.4tradeoffs and complexityafter more than a year of intensive study of the issue, the committeewas struck by its extraordinary complexity. such complexity manifestsitself in many ways, but nowhere more prominently than in understanding the tradeoffs involved in the development of any comprehensiveapproach to protecting children on the internet from inappropriate materials and experiences.5one example of a òstingó operation is an exercise in which a law enforcement officialassumes an online identity corresponding to that of a minor, and engages potential predators seeking to entice a minor for the purpose of initiating a sexual encounter. a secondexample is the use of customer lists belonging to an online service that provided childpornography, lists confiscated after the service itself was convicted of child pornographycharges. in this latter case, known as operation avalanche, law enforcement officials continued to operate the online serviceõs web site and sent email to subscribers offering themthe opportunity to purchase child pornography. those who responded received controlleddeliveries of child pornography made by investigators, and search warrants were executedon the residences of those customers immediately after the deliveries were made (see abcnews, 2001, òan avalanche of child porn: investigators use subscription list to trackdown pedophiles,ó november 14, available online at <http://abcnews.go.com/sections/business/techtv/techtvavalancheporn011114.html>).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.369findings, conclusions, and future needsthe nature of tradeoffs is such that doing òbetteró with respect to onegoal implies doing less well with respect to some other goal or goals. inthe present instance, any approach that improves protection for childrenand youth from inappropriate internet material or experiences is almostcertain to have a negative impact on other values or goals that most parents or communities would generally find appropriate and desirable.note that these latter values and goals may also be associated with children and the internet.two points must be made about the existence of tradeoffs. first, theexistence of such tradeoffs is not an argument, per se, against attempts toòdo betteró at protecting children and youth from inappropriate internetmaterial or experiences. second, the fact that tradeoffs exist for anygiven method suggests that a mix of methods may well be more effectivethan exclusive or primary reliance on any one method.to illustrate these tradeoffs, the next few sections discuss tradeoffsthat decision makers must address in considering the use of social andeducational strategies, technologybased tools, and public policy actions.table 14.1 an illustration of mutual reinforcementimpact on suppliers ofimpact on potential consumersinappropriate materialof inappropriate materialbusiness decisions and ethics(e.g., isps can choose to refrainfrom carrying usenetnewsgroups with a largeamount of child pornography)labeling material so thatparents and others can easilyascertain the appropriatenessof that material for theirchildrenshape the environment byreducing deceptive practices(e.g., mousetrapping, spam,capturing of misspelled websites)teach children to make choicesto stay away and to targetsearches more precisely toreduce chances of inadvertentexposure; teach parents howto educate their children aboutthese strategies and to monitorwhat their children are doingonlinehelp guide children toappropriate sites and help toprevent access to inappropriatesites, consistent with parentalvalues and preferencesprovide support for social andeducational strategies (e.g.,new standards of learning fork12, outreach to parents toeducate them about theinternet)social/educationalstrategiestechnologybased toolspublic policyyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.370youth, pornography, and the internet14.4.1social and educational tradeoffsthe committee has identified social and educational strategies to teachchildren and youth how to make good decisions about using the internetas foundational for any approach to protection. but socialization andeducation are inherently processes that operate over a long time scaleñthus, they cannot be expected to demonstrate immediate results. furthermore, they are not simple to implement, and they require forethought,planning, and extensive followthrough. they can be costly, both in termsof dollars and in terms of time.perhaps the most important tradeoff associated with using socialand educational strategies is that they may conflict with other pressingsocial and educational needs. for example, most k12 curricula are already overloaded, and information and media literacy curricula mustcompete for time in the schedule with physical education, art, music, sexeducation, consumer literacy, and a variety of other pressures on thecurriculum. education in these areas is also important, and passionateadvocates can be found for all of them.because the amount of time in a curriculum is more or less fixed,there are only three possibilities. one is that something must be removedif something else is added, and the elimination of any given subject area isalways controversial, if only because the importance of one subject areamust be weighed against the importance of another. a second possibilityis that by increasing the efficiency of education in the existing areas ofstudy (so that the same ground can be covered in shorter amounts oftime), time can be made available to add information and media literacy.but increasing efficiency is an enormously difficult problem, and in practical terms, it is not clear how to do so. the third logical possibility is toobtain the needed time for information and media literacy by trimmingthe instructional time devoted to existing subject areas. the risk in thisapproach is that coverage of those latter areas may become inadequate asa result.the dilemma is no easier to resolve in the family context, where family time together is at a high premium in many families. parental effortsto supervise children and youth using the internet must compete withmaking sure that children clean their rooms, do their homework, get tothe soccer or basketball game on time, avoid unhealthy use of drugs andalcohol, work parttime jobs, and so on. the difference in knowledgeabout technology and its uses between many parents and their childrenfurther inhibits informal candid discussion about issues related to theinternet. siblings and friends charged with providing peer assistancemay also play tricks on children to get them into trouble.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.371findings, conclusions, and future needsfinally, educational strategies to teach children and youth to refrainfrom seeking out inappropriate sexually explicit materials face a powerful challenge in that many adolescents, especially boys, are highly motivated to seek out such materials. some children do let educational effortsòroll off their backsó and are not influenced by them, and although education and socialization are the only approaches that have the chance ofreaching all or most children or that have any chance of reducing a childõsdesire for such materials, the expectations for such education and socialization should not be unrealistic.14.4.2technology tradeoffsone technology tradeoff is illustrated in the balance that users oftechnologybased tools must strike between two concernsñshielding thechild from inappropriate material and experiences against enabling childcentered control over the flow of information to him or her. one canincrease shieldingñbut only at the expense of reducing a childõs discretionary control over and access to information.a related tradeoff is the issue of false positives and false negatives.while false positives and false negatives in general trade off against eachother, even when human beings are actively involved in making judgments about the appropriateness of material to be shown to children, thetradeoff is most stark when technology is used to assess appropriateness,and a fundamental reality of technology is that it does not provide anaccurate and inexpensive way to assess content. as a general rule, increasing the probability that a device or system will identify inappropriate sexually explicit material as such also increases the probability thatsome notinappropriate material will also be improperly identified asinappropriate. if false positives are generally tolerable (i.e., one is generally willing to pass up useful information as the price of protecting againstinappropriate material, as might be the case for many riskaverse parents), then the automated assessment of content does have significantutility.still another technological tradeoff arises because of tensions betweenflexibility and ease of use. products that are flexible can be customized tothe needs of individual users, and most people say that they want flexibleproducts. yet, a highly customizable product involves many decisionsfor a user to make, and many users find the actual exploitation of aproductõs flexibility to be a chore. as a result, the most common use ofany technology tool is in its default òout of the boxó configuration. thus,for practical purposes, it is fair that any assessment of a tool place greatweight on what the tool does out of the box. against that standard, manyyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.372youth, pornography, and the internettools for protecting children from inappropriate internet material andexperiences place a far greater emphasis on labeling internet material andexperiences as inappropriate than on carefully selecting whether appropriate material might be labeled as inappropriate. that is, if it might beinappropriate, it is labeled and flagged as such. filters thus favor overblocking rather than underblocking, while monitors are likely to flag morematerial as questionable rather than less.this systematic bias in favor of overcaution provokes anxiety in manypeople. for example, to the extent that technologybased tools are preferred instruments of government policy, concerns arise that governmentmay be implicitly endorsing a lesser degree of information flow to thepublicñand to childrenñthan would be the case in the absence of technologybased tools. it is also an empirical observation about many toolson the market identifying certain kinds of information as inappropriatefor children that their supporters and advocates are perceived as supporting an underlying political agenda. finally, political pressures and mandates to deploy technologybased tools distort the market, in the sensethat they create artificial demand for solutions to problems that communities do not perceive to exist to a significant degree (if they did, theywould deploy these tools without such a mandate).even the protection itself that technology offers with respect to protecting children and youth from inappropriate material involves a potential tradeoff. to the extent that technologyimposed limits on choicework as intended (i.e., to block rather than discourage access to materialthat may be inappropriate), children and youth lose an opportunity toexercise responsible choice, and hence an associated chance to learn howto make responsible decisions. for younger childrenñwho tend to beless good at decision making than older childrenñthe consequences ofbad choices may be more serious, because of their relative inexperienceabout life and their greater impressionability; for such children, opportunities for unconstrained decision making and choice are not appropriateunder most circumstances.on the other hand, children who develop internal standards of appropriateness can be safer in those situations in which theyñor theirparents and guardiansñcannot rely on technology to protect them. thisis important given the increasing ubiquity of internet access points inmany venues. when responsible and respected adults and mentors talkwith these older children about responsible decision making and establish sanctions for inappropriate choices, they create an environment thatencourages and supports responsible choice, which in turn is likely to beconducive to the development of positive habits. such habits are mostimportant as adolescents reach the age of majority, when they will haveyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.373findings, conclusions, and future needsthe rights of adults and no constraints relative to internet access. on thispoint, parents must decide how to proceed.14.4.3public policy tradeoffsas noted in chapter 9, the viability of many public policy proposalsdepends on how policy makers make certain tradeoffs between the goalof helping to shield children and youth from inappropriate sexually explicit material on the internet and other desirable societal goals. forexample, the committee believes that spam containing material that isobscene for minors should not be sent to children. but laws banning suchemail to minors are potentially problematic in an online environment inwhich it is very difficult to differentiate between adults and minors. (indeed, regulation that depends on regulating a certain type of content(namely, sexually explicit speech) is inherently more suspect on firstamendment grounds than are proposals that regulate speech independent of content.) on the other hand, a ban of all spam regardless ofcontent may be seen as too broad because it affects many other interestsñfor example, those parties with a commercial interest in using emailchannels to advertise nonsexual goods and services.the committee also believes that it would be desirable for adult website operators who exhibit material that is obscene for minors to use ageverification systems so that children would not be able to access suchmaterial. however, in an online environment in which it is very difficultto differentiate between adults and minors, it is not clear whether denying access based on age can be achieved in a way that does not undulyconstrain the viewing rights of adults. thus, as one illustrative examplefrom section 9.3.2, the government might offer a grant of immunity fromprosecution under obscenity laws to web site operators that use age verification systems to prevent minors from accessing such material.6 inthis instance, the tradeoff is helping to protect children from exposureto certain kinds of inappropriate sexually explicit material (such a measure would help to reduce the inadvertent discovery of such materialfrom commercial web sites) in return for limitations on possible obscenity prosecutions.aggressive enforcement of obscenity laws also presents tradeoffs.increased prosecution of obscenity would likely require increased re6more specifically, immunity for adult web site operators from prosecution under obscenity laws would be granted if (a) they take actions to prevent their content from beingindexed by search engines, and (b) they provide a plaintext front page that warns usersthat the site they are about to enter has adultoriented content and an òexitó button to achildfriendly site if the user acknowledges being under 18.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.374youth, pornography, and the internetsources, and those resources must be taken from some other activity. if,as is likely, the other activity represents prosecutions of other crimes,policy makers must make the judgment that it would be wise to pursuemore obscenity prosecutions rather than other criminal prosecutions, orthat more prosecutions for obscenity would necessarily be the best use ofadditional resourcesñif such resources are available. such judgments arecomplex and require a careful weighing of many competing factors wellbeyond the scope of this report.14.5takeaway messages for different partiesin the committeeõs judgment, the bottom line on reducing the exposure of children to inappropriate material and experiences on the internetis that those who rely exclusively, or even primarily, on technology andpublic policy will find that the resulting protection will rest on uncertainand shifting groundñand is likely to fail their children when exposure toinappropriate material or dangerous situations occurs. if one installstools and/or passes legislation in the hope that they will òtake care of theproblem,ó and that in doing so oneõs responsibilities will thus be adequately discharged, children are highly likelyñeventuallyñto encounter inappropriate material or experiences on the internet in some venue,whether by accident or on purpose. and such an encounter will come asa disturbing surprise to the parent, teacher, librarian, or public policymaker who feels that he or she has done all that needed to be done. in theend, responsible choiceñwhich is foundational for safe internet use bychildrenñis closely tied to the values that parents and communities wishto impart to their children, and that influence judgments about the propermix of education, technology, and public policy to adopt.box 14.1 describes some of the behavioral aspects of internet safetyfor children that families, schools, and libraries might wish to teach.14.5.1parentsparents have a primary responsibility for guiding children into maturity. they have responsibilities to their children in the physical world,and they have corresponding responsibilities in cyberspace. with respectto internet usage, developing maturity implies the ability to make safe,responsible, and morally appropriate choices about what to do and whatto see on the internet and a facility for coping constructively with inappropriate or objectionable experiences.box 14.2 describes one possible òbest practicesó scenario focused onthe home. in addition, parents might wish to keep the following points inmind.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.375findings, conclusions, and future needsbox 14.1some aspects of internet safety for childrenthere are a variety of sources of good advice for children about internet safety.1the following points summarize some of the most important things to keep in mind.¥donõt give out personal information without parental permission to anyonethat you know only from the internet. that includes your real name, your address,telephone number, parentsõ work address and/or telephone number, or the nameand location of your school. it also includes your picture, which is information thatis in fact about as personal as you can get. if you need to give out a name, make oneup, or use your login or screen name. donõt use your real name as a login or screenname.¥report to your parents, a responsible adult, or an older sibling anything thatmakes you uneasy or uncomfortable. donõt wait to look around or exploreñreportit immediately. thereõs nothing wrong with seeking out help for an experience thatmakes you feel uncomfortable.¥never meet anyone in person that you first met through the internet withoutparental permission and their accompanying you to a facetoface meeting. if youdo meet the person (even with parental permission and presence), do it in a publicplace.¥realize that many people in real life are very different from how they seemonline. many people find it easier to lie in an online environment, are very good atit, and rely on the fact that you have no way to check on what they say. someonewho claims to be 5' 4", blond, and female and sends you a picture to òconfirmó thatcould be a 6' 2" blackhaired male who happened to have a picture of a girl that hefound online.¥talk with your parents (or teachers) about their expectations and group rulesfor going online. establish mutually agreeable rules for when and how long you canbe online, and identify appropriate areas and helpful web sites for you to visit. ifyou want to do something that is not covered by these rules, talk to your parents orteachers about it.¥donõt talk to or engage with people that you donõt know. if you get emailfrom an address you donõt recognize, delete it without opening it. if you get aninstant message from someone whose name you donõt recognize, cancel it. stayaway from chat rooms without having an adult present.¥treat others respectfully in an online environment. one good rule to followis that you should not say or do anything with someone that you would not wantyour parents to find out about. teasing, hurting, threatening, or being mean tosomeone else is inappropriate and wrong, whether it is online or in personñand iswrong even if you are anonymous to the other person.1see, for example, <http://disney.go.com/legal/internetsafety.html>, <http://www.safekids.com/kidsrules.htm>, and <http://www.getnetwise.org/safetyguide/>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.376youth, pornography, and the internet¥when children are young, a wider and more extensive range ofprecautions and a limited range of choices are appropriate. however, aschildren mature, precautions can generally be relaxed and the range ofchoices expanded. if technology is used to limit access, consider the ageappropriateness of the limits you wish to impose.¥interactive dialog (whether through email, instant messages, voiceand/or video, chat rooms) with strangers is a much greater potentialthreat to a childõs wellbeing than other things that he or she is likely toencounter on the internet. account for the fact that children often overestimate their ability to make good judgments about the intentions of peoplewhom they do not know.¥an environment in which your child will feel comfortable talkingto you is more likely to result in conversation about potentially seriousbox 14.2an illustrative òbest practicesó scenario for the homein a òbest practicesó scenario focused on the home, parents provide instructionand supervision about internet use. in particular, computers would be located inpublic family areas rather than in rooms that are conducive to private use (e.g., achildõs bedroom). parents would have gone beyond their work experiences with theinternet and learned about the materials and experiences to which their childrenmight plausibly be exposed, keeping in perspective a balance of the internetõs positive and negative aspects. for example, they would have spent some time sitting bytheir childrenõs sides surfing the internet or exploring their online service with them.they would have educated themselves about appropriate and useful web sites andconsulted their childrenõs teachers about how internet use could support their childrenõs education. they would also have spent time without children in attendancesurfing the web so that they could experience firsthand some of the ònotsodesirableó content in instant messages and chat rooms and on web sites. they wouldhave talked with their children about both the benefits and the dangers of the internet, and provided clear guidance about what material and activities were inappropriate and explanations for what made them inappropriate. they would ask theirchildren to report any experiences that made them (the children) feel uncomfortableor in which they encountered an inappropriate experience or unsuitable material,and promise to refrain from being upset with their children should such happen.they would also keep that promise, and when their children reported inappropriatematerial or experiences, they would counsel rather than punish them. parents wouldalso set time limits for how much time a child may spend online. when time isconstrained, people are more likely to concentrate on the activities that they valuemost highly. to the extent that children seek out inappropriate material out of idlecuriosity, these are the activities that are most likely to be curtailed in the presenceof time limits. parents would be willing to learn about technology from their children and would not feel awkward about asking their children technologyrelatedquestions. furthermore, older and more experienced siblings would be encouragedto supervise, encourage, and guide younger siblings.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.377findings, conclusions, and future needsissues. if they are afraid of your reaction to what they tell you, they willbe less likely to tell you when they encounter things that might make youuncomfortable. thus, think in advance about what you will say and dowhen your child is exposed to material that you regard as inappropriate.¥for most people (children included), instant messages and chatdialogs are no different than telephone conversations, mail, or diary entries. reading logs of chat room or im dialogs is likely to be seen in thesame way as listening in on a childõs telephone conversations or reading achildõs diary. for some parents, the cost of violating a childõs privacy isworth the gain of learning what is on a childõs mind. for others, the costof violating a childõs privacy is too high a price to pay under most ordinary circumstances. a related question is that of the extent to which achildõs rights to information go beyond what a parent is willing to grant.some parents are willing to state explicitly that their children should beable to obtain information on certain subjects, even if it would make them(the parents) uncomfortable, while others find such a notion to be unacceptable. thus, consider your own philosophy regarding privacy andinformation rights for your children.¥the policies of your childõs school, library, and friendsõ familiesregarding internet use and access have an effect on your childõs internetexperience. coordinate the internet experiences available at home and atschool, the library, or at the homes of friends (if you approve of thosepolicies), or provide an alternative for your child (if you disapprove ofthem).¥children often copy what their parents say verbally and actuallydo behaviorally. if you believe that the viewing of sexually explicit material is inappropriate for your children, explain to your children why suchbehavior is inappropriate for them and set a good example in your ownhousehold.¥illegal or inappropriate behavior or material can be reported to theresponsible authorities. for example, the national center for missingand exploited children provides onestop reporting to law enforcementauthorities of child pornography found online by the general public(http://www.cybertipline.com or 18008435678). local law enforcementagencies (e.g., state or town police) are often recipients of complaintsrelated to online solicitations of children for sexual purposes, and thefederal bureau of investigation and the u.s customs service have authority in this matter as well. certain online services provide mechanisms for reporting inappropriate activity. for example, aol provides away for users to notify aolõs òcommunity action team,ó which has theresponsibility of enforcing aolõs terms of service. among other things,aolõs terms of service forbid vulgar language and disruptive behavior inchat rooms or instant messages and email and instant messages thatyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.378youth, pornography, and the internetcontain requests from strangers for passwords, credit card numbers, orother personal information.finally, the committee believes that a parental lack of knowledgeabout internet culture and the diversity of possible internet experienceshas beenñand continues to beña source of both complacency (becausesome do not know what on the internet may be of concern to them andtheir children) and excessive fear (because they do not know enough to beable to place these dangers in proper perspective). for this reason, parental education about the internet continues to be an important part of acomprehensive program of internet safety education for children.14.5.2teachers and librariansteachers have a responsibility for educating students and for providing a safe environment in which learning can occur. libraries have aresponsibility for providing the communities they serve with a broadrange of useful materials appropriate for their needs. box 14.3 and box14.4 describe possible òbest practicesó scenarios for schools and libraries,respectively. in addition, teachers, school administrators, and librariesmight wish to keep the following points in mind.¥the educational and informational needs of young people at various agesñfrom kindergarten to the seniors in high schoolñvary enormously, and the internet content that is made available to students atbox 14.3illustrative òbest practicesó scenarios for schoolsin a òbest practicesó scenario for schools, the internet and information technology are used to support learning and are integrated into the regular curriculum astools for learning. studentsñand parentsñwould actually read acceptable use policies (aups). discussions about aups between students and parents would occur.some instructional time would be spent on teaching students what it meant to comply with aups. enforcement of aups would be sufficiently flexible that inadvertentviolations would be seen as teaching opportunities rather than automatically beingconsidered occasions for punishment. internet safety instruction would be a prerequisite for schoolprovided internet access. some instruction in media literacy wouldbe integrated into the curriculum at all levels as an essential dimension of scholarship and learning. selected older students would serve as computer and internettutors and guides for younger students. teachers would be offered professionaldevelopment opportunities by their school district to understand the importance ofmedia literacy on the internet and how to teach it. the pta would offer programs toparents or guardians wanting to know more about internet safety and guidance onmaintaining open communication between parents and adolescents.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.379findings, conclusions, and future needsthese various stages of development must be matched to their needs,skills, and maturity. furthermore, teachers and librarians have an important role in educating parents about the internetñits benefits and its dangersñand they are sources of advice about how to cope with the dangersthat the internet may pose.¥transparency is a virtue, both for adult supervisors and child internet users. transparency can include an understanding of why a givensite is or is not regarded as inappropriate, access to detailed informationabout what is deemed inappropriate, knowledge of instances when actions are being monitored or influenced, and the ability for onsite adultsupervisors to override nonlocal decisions about inappropriateness.¥the total cost of technology solutions, rather than just the initialdeployment costs, must be evaluated. specifically, technology generallyentails continuing costs of maintenance and upgrade, as well as humanstaff members to ensure that the technology is being used appropriatelyand is serving its intended functions. for example, staff may be needed toprocess requests for filtering overrides (if filtering is in place) or to process parental complaints (if filtering is not in place).¥efforts to provide educational outreach to parents must account forbusy family schedules as well as, perhaps, a certain resistance among someto deal with technologybased issues with which they are unfamiliar. forexample, outreach activities requiring parents to go far out of their waybox 14.4illustrative òbest practicesó scenarios for librariesin a òbest practicesó scenario focused on the library, libraries offer internet safetyinstruction to both parents and children. software would be installed to òclearóbrowser histories and caches so that a new user would not be able to view anythingseen by the previous user. libraries would also offer users a variety of choicesregarding filtered or unfiltered access. internet access points inside childrenõs areaswould ask the age of the childñyoung children (e.g., those below 10, although thisage is arbitrary) would receive a notice that they were being given filtered access,while older children would be offered an unbiased choice of filtered and unfilteredinternet access. (in this context, òunbiasedó means that neither filtered nor unfilteredaccess is the default. instead, prior to internet use, a user would specifyñin privateñan explicit choice of filtered or unfiltered access. in this way, a user whowishes to gain private and unrestricted access to information could do so withouthaving to be embarrassed or feel uncomfortable about having to ask for unfilteredaccess, and a user who wished to not be exposed to certain kinds of material coulddo so without having to acknowledge to someone that he or she might be uncomfortable with such material.) in any event, information on the filtering policy wouldbe conspicuous and available so that users would have a general idea of what wasblocked.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.380youth, pornography, and the internettend to be poorly attended; conversely, parents would be more inclined toattend programs that are conveniently located and scheduled consistentlywith the communityõs work hours. one program described to the committee during the first workshop involved taking computers to venues thathad little to do with technology such as a gardening class or music festival.by demonstrating how the technology could have useful applications evenin such venues, a context arises naturally in which it is possible to raiseissues related to young people, the internet, and parenting. also, coordination with volunteer organizations outside schools and libraries may makemore resources available for these outreach efforts. pta organizations, forexample, are well suited to provide such outreach efforts.14.5.3industryvarious components of industry can make a major contribution to theinternet safety of children. the segments of industry relevant to the issueinclude isps and online service providers, makers of access devices suchas personal computers, software vendors, content providers, and the adultonline industry.¥isps and online service providers could:ñprovide easily understood and implemented parental controls. asnoted in chapter 11, flexibility is often not used because presenting arange of options is confusing to the parent trying to configure a system.on the other hand, a single òonesizefitsalló approach does not take intoaccount the needs of individual children. one approach to simplifyingparental controls, implemented by some service providers, is to set default measures depending on the age of a child, while giving the parentthe ability to adjust these defaults appropriately.ñdesign and provide educational and childfriendly areas. chapter10 discusses a number of means to concentrate childfriendly and compelling content that would attract childrenõs online attention. to achievecritical mass, such content would be designed to be broadly appealingover a wide variety of topics, including information on relationships,sexual health, and other topics of interest to adolescents.ñprovide a uniform channel for user complaints about child pornography and/or obscene material. such a channel (which could be assimple as a link to the cybertipline) could easily be placed on the complaints or customer service page of the service provider.ñrefrain from carrying material that they believe to be illegal, suchas suspected child pornography. (as discussed in chapter 4, the ògoodsamaritanó provisions of the communications decency act remain inforce and largely immunize providers exercising such control over conyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.381findings, conclusions, and future needstent from liability for failures in such control.) for example, on their ownauthority, isps could refrain from carrying usenet newsgroups known tocarry large amounts of child pornography.¥makers of access devices such as personal computers could:ñprovide inthebox internet safety tips and best practices. manysuch brochures published by reputable organizations are available forfree, and òoutoftheboxó information relevant to internet safety could bea valuable route to greater publicity for such efforts.ñprovide configuration options for children in a household. atgreater cost, the initial machinesetup configuration process could bemodified to ask the device owner or administrator if children are expected to use the device. if so, the process could guide the owner oradministrator through a setup process for specifying parental controls forthe use of the device. (for example, the setup process might specifycertain limits on internet access if a child logs into the device.)¥software vendors could:ñdevelop software to prevent mousetrapping. recall that mousetrapping (discussed in chapter 3) refers to the phenomenon in which auser who tries to leave a sexually explicit site is automatically forwardedto another such site. some programs are available today to block òpopupó advertisements, and these work to prevent mousetrapping as well.however, these programs must be invoked before the popup ad ormousetrapping occurs, and they also disable some useful features of websites. a òpanic buttonó could be installed that is always available on theuserõs screen, and if a user is mousetrapped, clicking on the òpanic buttonó should close all current browser windows.ñdevelop software to help configure computers to be childfriendly.such software would operate in lieu of the childoriented setup routinesdescribed above.ñintegrate labelbased filtering options into web browsers (see below).ñinclude in software regularly used by adults tips for their childrenõsinternet safety. for example, upon initial installation of a software product, the software setup program could ask if the user wanted to view ascreen of internet safety tips for children, and if so, could display suchtips or direct him or her to an appropriate web site.ñprovide content creation tools that have been adapted to speed theprocess of content developers creating labels that can be used by picsbased filtering schemes.¥content providers could:ñparticipate in labeling schemes. as discussed in chapter 12, theyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.382youth, pornography, and the internetsuccess of a labeling scheme depends primarily on its widespread adoption. in october 2001, aol time warner, yahoo, and microsoft networkannounced their adoption of the content labeling system of the internetcontent rating association.ñintegrate educational and entertainment value into content developed for children. if children are to use content voluntarily, such integration is likely to enhance its appeal for both children and parents.ñadd links to ageappropriate sexual and emotional health contentto web sites visited by older youth. as noted in section 14.2, many olderyouth are interested in information that relates to their sexuality. giventhis fact, it makes some sense to provide reliable and appropriate information to meet this need, rather than leaving them on their own to findunvetted information that may be of questionable value or to seek outadultoriented, sexually explicit content that depicts sexual behavior inways that are demeaning or disturbing.¥the adult online industry could:ñtake more effective steps to keep children from accessing theirproducts. for example, operators of adult web sites could set up theirhome pages without sexually explicit material (i.e., the cyberequivalentof a brown paper wrapper around an adult magazine), and use therobot.txt protocol (described in chapter 2, box 2.3) to prevent indexing ofpages (even free teaser pages) that contain such material. thus, childrensearching the web would never find the sexually explicit material directly(though they might be directed to an adult siteõs home page).ñstop the practice of involuntary mousetrapping. for example, itwould be simple to offer a user seeking to leave a web site a choice aboutwhether or not to be redirected. such a simple step could do much toreduce the perception of irresponsible behavior on the part of the adultonline industry.ñuse contracts to require more responsible behavior among affiliates that use content provided by commercial sources of adultoriented,sexually explicit imagery. for example, a contract between a contentprovider and an affiliate might require that the affiliate would have to putits content behind plain brown wrappers and so on, and the firms thatsupply content would be in a position to penalize them if they did not (bycutting off a content source).finally, the information technology industry should not be discouraged from undertaking serious technologybased efforts to help parentsand other responsible adults to improve and enhance the safety of theirchildrenõs internet experiences and to reduce the amount of inappropriate material to which they may be exposed. indeed, as a primary benefiyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.383findings, conclusions, and future needsciary of the internet age (as well as being instrumental in creating it), theinformation technology industry arguably has a special responsibility tohelp safeguard children on the internet. developing more discriminatingfilters, enabling parental controls, supporting research of the type described in section 14.6, and adopting and promoting labeling schemes area few of the ways that the it industry has sought to discharge its responsibilities in this area, and a further enhancement and strengthening ofthese types of effort can only expand the range of options that parents andother responsible adults can exercise.14.5.4makers of public policypublic policyñat the local, state, and federal levelsñhelps to shapethe environment in which internet access occurs. but because the scope ofpublic policy actions areñby definitionñpervasive throughout the community to which those actions are relevant, public policy makers mustproceed judiciously.public policy actions are most effective when they are based on reliable science rather than anecdote, and when they reflect a strong social,ethical, and moral consensus. for example, the sentiment that child pornography and sexual molestation of children are wrong is shared bypeople among a very broad spectrum of political views. thus, it is reasonable to say that these are serious national problems, and addressingthem continues to be an important task for the nation. furthermore, thescale of these problemsñalready largeñis increasing, and in any eventoutstrips the resources available to deal with them.by contrast, public policy makers should tread lightly when it comesto other areas in which a consensus is not so apparent. for example, thecommittee heard from parents who did not trust the federal governmentto take actions to reduce childrenõs internet exposure to inappropriatematerials. the striking aspect of this sentiment was that it was expressedby both conservative and liberal parents.public policy makers should also be wary of cheap, easy, or quick solutions. as the discussion in chapter 12 on filtering demonstrates, such òsolutionsó may not fix the problem that they seek to solveñat least not to theextent that they would enable resources and attention to be turned elsewhere. it is true that the cost of social and educational strategies tends at firstblush to be considerably larger than the costs of protective technologiesñbutthe benefits that accrue are also correspondingly higher. students will bemore able to avoid problematic experiences and material of their own volition, and will be better able to cope with them when they occur.finally, it is necessary to underscore the fact that public policy can gofar beyond the creation of statutory punishment for violating some apyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.384youth, pornography, and the internetproved canon of behavior. certainly, legal sanctions are one possible public policy option, and such sanctions act both to punish those who behavein a way contrary to law and to deter others from conducting themselvesin a similar way. options such as more vigorous prosecution of existingobscenity laws are discussed at length in chapter 9. but public policy canbe used much more broadly and can shape the internet environment inmany ways. for example, public policy can be used to:¥reduce uncertainty in the regulatory environment. uncertainty inthe regulatory environment is often inhibiting to business plans. forexample, prior to the enactment of the ògood samaritanó section of thecommunications decency act (discussed in section 4.2.3), at least onecourt case (stratton oakmont v. prodigy) had suggested that an isp exercising editorial control over messages posted on its bulletin boards in accordance with its acceptable use policy was subject to liability as a publisherfor content available through the isp that was inconsistent with its acceptable use policy. this precedent gave isps incentives to refrain from exercising editorial control, and the good samaritan provisions of the communications decency actñnever overturned in the courtsñeliminatesuch liability.¥promote media literacy and internet safety education. promotioncan include:ñfunding the development of model curricula for media literacyand internet safety. there are political sensitivities related to the federalgovernmentõs role in education, which is a local responsibility, but developing models and giving grants are both wellaccepted federal practicesin the area of education.ñencouraging and supporting professional development for teachers on internet safety and media literacy. professional development forteachers seeking to use the internet for pedagogical purposes is sparsecompared with the need,7 but internet safety and media literacy do notaccount for more than a very small fraction of the sparse support that isavailable.ñsupporting outreach to educate parents, teachers, librarians, andother responsible adults about internet safety education issues. grantscould also be made available to nonprofit and community organizationsto run internet safety programs. in addition, given the gap in knowledgebetween adults and their children, a mediabased educational outreachcampaign has some potential for reducing this gap. for example, public7u.s. department of education. 2001. teachersõ tools for the 21st century: a report on teachersõuse of technology. available online at <http://nces.ed.gov/pubsearch/pubsinfo.asp?pubid=2000102>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.385findings, conclusions, and future needsservice announcement campaigns could help to inform parents of onlineissues related to their children (tv ads, enclosures in phone and/orinternet bills). another part of media outreach might be the creation of anational òchildrenõs safety dayóña day in which the media would highlight all that can be done to improve childrenõs safety and wellbeing, andadults would take concrete steps to review safety issues with children.internet safety education could well be one aspect of such a day.¥support the development of and access to highquality internetmaterial that is educational and attractive to children in an ageappropriate manner. public support for the development of pbs programminghas a long tradition of providing such material in the tv medium, andwith the dearth of comparable material for children on the internet, suchsupport could have a substantial impact. in addition, educational portalsthat organize existing safe and educationally appropriate content (seecomments under section 14.5.3) would improve the accessibility of thatcontent to diverse audiences.¥support selfregulatory efforts by private parties. for example,public policy can provide financial or legal incentives for isps and contentproviders to behave in responsible ways. it can also coordinate and facilitate private efforts to selfpolice the internet environment (analogous tothe rating efforts of the music and game industry). such selfpolicingrelies on the public at large to report possibly illegal material or behavior,isps to take actions consistent with their termsofservice provisions, andinformation exchange mechanisms to ensure that all parties have the information needed to take appropriate action.¥support research in areas that are relevant to the issue of internetsafety. some of the relevant areas are the impact of exposure to sexuallyexplicit material on children at various ages; the internet use patterns ofchildren; and the inpractice effectiveness of various social and educational strategies, technologybased tools, and public policy at federal,state, and local levels at increasing the safety of childrenõs internet experiences. of special interest is the possibility of research and developmentinto technologies specifically designed to accurately identify sexually explicit material and thereby enhance and improve the effectiveness of toolsthat can help to reduce the exposure of children to inappropriate internetmaterials and experiences.8 as discussed in chapter 2, the general informationretrieval problem is a very difficult one to solve. however, research intended to focus on the identification of sexually explicit materialmay progress more rapidly than work on the more general problem. the8nonindustrial support for such research may be justified on the grounds that, as discussed in chapter 12, there is little market incentive for more accurate methods for identifying sexually explicit materials (and hence for more accurate filtering).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.386youth, pornography, and the internetreason is that in seeking to identify sexually explicit material (rather thanarbitrarily selected material), one might be able to make use of heuristicmethods and clues signaling the presence of sexually explicit content thatare not available for use in the general case.9¥support efforts to enable families and other private parties to exercise greater latitude of choice in the internet experiences of the childrenfor whom they are responsible. for example, parents and others lack agood evaluative guide to technologybased tools and must assess theclaims of vendors on their own. this report helps to provide a frameworkfor understanding how to think about such tools but does not providespecific product guidance. publicly available assessments of specific toolsrated multidimensionally according to common criteria could help parents and others select tools that are appropriate for their own situations.finally, makers of public policy must keep in mind the internationaldimensions of the internet. this does not mean that u.s. actions shouldnot be undertaken, or that they will be wholly ineffective, but expectations for the impact of such actions must necessarily be moderated compared to the case in which the united states is the only significant actor.14.6research needsas the length of this report suggests, the problem of protecting children from inappropriate material and experiences on the internet is complex. reliable information in a number of areas is needed. indeed,throughout its work, the committee was concerned about the lack of reliable and valid sciencebased information for many dimensions of theproblem it was addressing. such information would have helped tostrengthen committee deliberations.¥the effectiveness of technologybased tools and social and educational strategies in practice should be examined and characterized. chapter 12 discusses one aspect of evaluating the performance of filters, basedon a òheadtoheadó comparison of how filters performed in blockinginappropriate materials. but protection of children is a holistic enterprisethat must account for the totality of their internet experienceñwhich suggests the need for an examination of all of the tools in all of the venues inwhich children use the internet. the same is true for understanding howsocial and educational strategies affect the behavior of children òon theground.ó9note that more effective technology in this area could be used for the benefit of thosewho want to block such material and of those who want to search more precisely for it.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.387findings, conclusions, and future needs¥given the inadequate scientific basis for understanding how mediaexposure to sexually explicit material affects children, more research inthis area is needed. systematic research on u.s. children may not bepossible, for all of the reasons described in chapter 6, but crossnationallongitudinal studies in countries similar to the united states may shedsome light on these issues. in addition, it may be possible to conductresearch to study exposure to such material that occurs in the course ofchildrenõs use of the internet (which is likely to include both accidentaland deliberate exposure). a further dimension of media research is theimpact of media exposure on the development of personal character inyouth.¥it seems reasonable that providing highquality, ageappropriateinformation about sex and sexual health addressing the physical, emotional, social, and psychological issues on the minds of children wouldhave a dampening effect on the urge of many adolescents to search forinappropriate sexually explicit materials. to test this proposition, longitudinal studies of children and adolescents who receive such informationwould be helpful.¥there is a need for research and development directed toward acomprehensive curriculum that provides in detail what parents need toknow in order to handle the issue of internet safety with their children.such a curriculum would provide specifics on what a parent might dooperationally.¥a better understanding of the population of online sexual predators might help government efforts to prevent sexual predation. if, forexample, a large percentage of online sexual predators were alreadyconvicted child molesters, that fact might argue for longer prison termsfor such felons, closer supervision of their activities after release, and/orprohibitions on their use of online resources.14.7conclusionthe internet offers enormous potential to enhance the intellectual,educational, social, and personal development of children. those whotake actions to address the concerns described above must bear in mindthe potential benefits that the internet offers. thus, any òappropriateómix of actions should be seen as balancing competing goals and valuesrather than endorsing the absolute supremacy of any one goal or value.furthermore, evolution with respect to technology and the ebusinessenvironment, as well as possible changes in community standards governing obscenity, means that there are no foreseeable technological òsilver bulletsó or single permanent solutions to be crafted. rather, anyapproach adopted to protect children must adapt to changing circumyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.388youth, pornography, and the internetstances. while technology and public policy have important roles to play,social and educational strategies that impart to children the character andvalues to exercise responsible choices about internet use and the knowledge about how to cope with inappropriate material and experiences iscentral to promoting childrenõs safe internet use.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.appendixesyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.390youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.391plenary meeting of july 1719, 2000national research council2001 wisconsin avenuegreen buildingwashington, d.c.monday, july 17presentation of chargedean hoffman, u.s. department of justicelinda roberts, u.s. department of educationpanel: considering the extent of the problemdavid finkelhor, university of new hampshiremichael marshall, microsoft (retired)john rabun, national center for missing and exploited childrenjeff richards, internet allianceprimer on the first amendmentgeoffrey stone, university of chicagopanel: first amendment perspectivesbruce taylor, national law center for children and familiesrobert flores, national law center for children and familiesainformationgathering sessionsof the committeeyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.392youth, pornography, and the internetelliot mincberg, people for the american waymarvin johnson, american civil liberties unionpaul mcmasters, the freedom forumtuesday, july 18panel: technological issuesmilo medin, excite@homepaul resnick, university of michiganbhavani thuraisingham, mitrepanel: library perspectivesmarilyn mason, independent consultantcarol roddy, ohio public library information networkjudith krug, american library associationwalter minkel, cahners business informationcaroline ward, ferguson library and outgoing president of american library association services for childrenpanel: school perspectiveslynne schrum, university of georgialinda braun, leo: librarians and educators onlinecarrie gardner, milton hershey schoolmaribeth luftglass, fairfax county schoolspanel: community perspectiverobin raskin, family pcparry aftab, cyberangelsbruce watson, enough is enoughplenary meeting of october 1820, 2000georgetown holiday innmirage room ii2101 wisconsin avenue, n.w.washington, d.c.wednesday, october 18panel: perspectives on child developmentjeff mcintyre, american psychological associationmary anne layden, university of pennsylvaniayouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.393appendix ademonstrations: sexually explicit material on the internet (closed session)panel: understanding the obscenity statutesgovernmental perspectivesterry lord, child exploitation and obscenity section, u.s. department of justicekenneth neu, federal bureau of investigationdaniel armagh, national center for missing and exploited childrennongovernmental perspectivesrob showers, gammon & grangebeth farber, federal public defenderrobert peters, national obscenity law center, morality in mediajon katz, marks & katz, llcquestions for the panels¥given a policy to prosecute obscenity cases, what factors determine whether or not to pursue a case? how does the exposure of a minorto obscene materials affect a decision to prosecute?¥how are community standards for determining obscenity set?¥would a case of internet obscenity be prosecuted differently fromone associated with a neighborhood bookstore? why or why not?¥how has policy regarding enforcement of obscenity laws changedover the years at the local, state, and federal level?¥what approaches would be most effective in dealing with onlineobscenity? (to include but not be limited to any or all of the following:technological tools such as filters, community practices, legislation orregulation)thursday, october 19panel: perspective of isps (general purpose, family friendly)steve ensley, american family onlinemike chilton, dotsafeginny wydler, america onlinequestions for the panel¥how do you decide what is appropriate material for minors toaccess? how does this differ by age?youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.394youth, pornography, and the internet¥please comment on the exposure of minors to sexually explicitmaterial online by source, i.e., explicitly sought, inadvertently accessed,or pushed actively by another party.¥how do you limit exposure for minors to sexually explicit materialonline? what strategies or tools appear most successful? what strategiesor tools have limited success? why?¥is there a òrangeó for access for minors? how is it determined?¥what approaches would be most effective in limiting the exposureof minors to sexually explicit material on the internet?¥unsolicited or bulk emails are sent to minorsõ accounts but maycontain links to sexually explicit sites. how might these mailings beeliminated or better targeted to adults?panel: perspectives of education associationsjulie underwood, national school boards associationarthur sheekey, council of chief state school officersquestions for the panel¥what are your primary concerns about the exposure of minors tosexually explicit material online?¥how are your members responding to the issue?¥how should the risk of exposure to inappropriate sexual contentbe balanced against the risk of denying access to helpful or educationalmaterial that might be inappropriately blocked?¥what approaches to limit the exposure of minors to online sexuallyexplicit material are appropriate for schools, communities, libraries, andfamilies?panel: perspective of teenagersbrittany and yves, teenangels, new jersey, with parry aftab, cyberangelsalex, thomas jefferson high school for science and technology, alexandria, virginiaquestions for the panel¥do you think that adults (parents, teachers) understand enoughabout the internet to provide supervision?¥how easy is it to circumvent actions intended to prevent someonefrom reaching sexually explicit material online?¥what do you think are the best ways to protect minors from inappropriate internet content?youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.395appendix a¥have you ever seen pornography online? how did it happen? forinstance, was it sent to you? did you accidentally access a message containing a link? did you mistype a url and get an adult site?¥what have you done when you have gotten sexually explicit material online? have you told anyone? who? what happened?¥do you think you get a lot of bulk or unrequested emails containing sexually explicit material?¥have you ever been made uncomfortable by someone in a chatroom or by an instant messenger message? what happened? what didyou do?¥do you know how to protect yourself when you go online? wheredid you learn these rules?discussion of copa commission report (closed session)friday, october 20panel: adult entertainment industry representativesdanni ashe, danniõs hard drivej.t. edmond, flying crocodilegloria leonard, free speech coalitionlarry lux, playboy onlinegerard van der leun, penthouse.comquestions for the panel¥what is your perception of the issue of minorsõ exposure to sexually explicit material online? how are your members/clients respondingto the issue? how broad is your membership base compared to theuniverse of providers of such material?¥what are the most appropriate means for distinguishing betweenadults and minors in an online context?¥how should/can the current regime of limiting the exposure ofminors to sexually explicit print and tv and movies be extended to theinternet domain?¥what are the most appropriate approaches to limit the exposure ofminors to online sexually explicit material? what strategies or tools appear most successful? what strategies or tools have limited success? why?¥unsolicited or bulk emails are sent to minorsõ accounts but maycontain links to sexually explicit sites. how might these mailings beeliminated or better targeted to adults?¥what approaches would you like to see adopted or developed tolimit the exposure of minors to online sexually explicit material?youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.396youth, pornography, and the internet¥what technologies might better target likely audiences for adultentertainment?overview of bertelsmann report, protecting our children on the internetjack balkin, yale universitypublic workshop of december 13, 2000georgetown university conference centersalon h meeting room3800 reservoir road, n.w.washington, d.c.note: the proceedings of this workshop are summarized in an nrcreport entitled nontechnical strategies to reduce childrenõs exposure to inappropriate material on the internet: summary of a workshop (national research council and institute of medicine, board on children, youth, andfamilies and computer science and telecommunications board, joah g.iannotta, ed., national academy press, washington, d.c., 2001).nontechnical strategies that can be used to protect children on the internet:what are the roles of policies, parents, schools, libraries, and communities?linda roberts, director, office of educational technology and senioradviser to the secretary, u.s. department of educationanne thompson, program commissioner, national ptaquestions for discussion¥how does one define nontechnical strategies for protecting kidsfrom inappropriate material on the internet?¥what nontechnical approaches are used in the home, classroom,and community settings?¥what is the role of parents in making nontechnical strategies effective, and what do parents need?¥how effective have current policies been in encouraging schoolsand communities to develop nontechnical strategies?an extended panel on bringing developmental considerations to bear on theimpact of inappropriate material on the internetpart i: effects of exposure to pornographic and other inappropriate material on the internetjane brown, professor, school of journalism and mass communications, university of north carolina at chapel hillyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.397appendix ajoanne cantor, professor, university of wisconsin, madisoned donnerstein, dean and professor, department of communication,university of california, santa barbaramoderator/discussant: sandra calvert, committee member and professor of psychology, georgetown universityissues for discussion¥what types of inappropriate material do young people encounter,and how do they come in contact with it?¥what is the potential impact on children of viewing sexually explicit and other forms of inappropriate material in the media?¥is impact dependent only on the type of material or also on thesource (e.g., static image on the internet, picture from a magazine, activeimages from television)?¥what are the limits of this research, and to what extent can wemake comparisons among the effects of viewing different types of inappropriate material (e.g., sexually explicit vs. violent vs. hate speech)?part ii: developmental considerations for determining appropriate internet use guidelines for children and adolescentspatricia greenfield, professor, department of psychology, universityof california, los angelesjames youniss, professor, life cycle institute, catholic university ofamericadorothy singer, senior research scientist, department of psychology, yale university, and codirector, yale university family televisionresearch and consultation centerissues for discussion¥how are emotional, cognitive, social, and moral development affected by the media landscape created by childrenõs access to and use ofthe internet?¥what types of material may be harmful according to childrenõsgrowth and developmental needs, and how may harmful effects changewith age and developmental milestone?¥how do parents and educators balance giving young people theresponsibility of exploring the internet with protecting them from material that may be disturbing?¥how should developmental issues shape nontechnical strategiesto protect kids from inappropriate material, and what nontechnical strategies will most benefit childrenõs development?youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.398youth, pornography, and the internetpush and pull on the internet: childrenõs use and experiencesdon roberts, thomas more storke professor, department of communication, stanford universitysarah keller, assistant professor, health communication, department of communication, emerson collegemoderator/discussant: janet schofield, committee member, professor of psychology and senior scientist at the learning research and development center, university of pittsburghquestions for discussion¥how are children using the internet, in what settings are childrenlogging on, and are there differential patterns of use according to age,gender, and ethnicity?¥what are childrenõs experiences while online, both positive and negative?¥how are children pulled into material that they might not otherwise view, and what effect might this have?¥how are young people driving their experiences on the internet,and how can young people be encouraged to stay in charge of their onlineexperiences?innovative approaches and existing efforts to use nontechnological strategies to protect children on the internetlaurie lipper, director, the childrenõs partnershipkathy boguszewski, instructional technology consultant, wisconsindepartment of public instructionmary dempsey, commissioner, chicago public librarynancy willard, director, responsible netizen research, center foradvanced technology in education, university of oregoneileen faucette, founder and coordinator, pta live onlinemoderator/discussant: winnie wechsler, committee memberquestions for discussion¥what are some of the nontechnological strategies that might beused by educators, librarians, parents, and local communities to ensurechildrenõs safe and appropriate use of the internet?¥what types of inappropriate material do these strategies address, andhow do they protect against the potential harm this material might cause?¥who has been responsible for implementing and monitoring theseapproaches?¥how can these approaches be tailored to different venues (e.g.,home, school, library)?youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.399appendix abridging research, policy, and practiceellen wartella, dean and professor, college of communication, university of texas, austinlaura gurak, associate professor, rhetoric; faculty fellow, law; anddirector, internet studies center, university of minnesotabetty chemers, deputy administrator, office of juvenile justice anddelinquency preventionquestions for discussion¥what research is needed to develop new nontechnical strategiesfor protecting children from inappropriate material on the internet?¥are regulations needed to protect children on the internet, andwhat policies might encourage children to use the internet in safe andappropriate ways?¥how should nonprofit organizations, educational institutions, government agencies, and parents be working together to create a safe environment for kids to use the internet?¥how should we be thinking about linking research, policy, andpractice?plenary meeting of march 79, 2001excite@home450 broadwayredwood city, californiawednesday, march 7basic concepts in information retrievalnick belkindavid d. lewishinrich schutze, center for the study of language and information,stanford universitydavid forsyth, university of california, berkeleyray larson, university of california, berkeley, school of informationmanagement and systemsissues for discussion¥stability of content categorization¥automatic text categorization¥machineaided text understandingyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.400youth, pornography, and the internet¥vision and image recognition¥search engine technologyfilterssusan getgood, surf control inc.james wang, pennsylvania state universitybennett hazelton, peacefirequestions for discussion¥what techniques can be used to identify sexually explicit material?¥how do filter vendors select the content they screen?¥what flexibility do their products offer?¥what is involved in circumventing the filtering provisions?¥how is the performance of a product measured? (rates of falsepositives, false negatives)authentication and age verificationeddie zeitler, lambert and associatesfred cotton, search.orgdeirdre mulligan, university of california, berkeleybusiness modelsmodels for kidfriendly and kidsafe internet businessesbrian pass, mediaoneirv shapiro, edventions inc.questions for discussion¥what are the primary challenges of building a business based onthe idea of attracting kids to safe and appropriate internet content?¥what is the business case for firms operating in this space?¥what role do responsible adults (parents, teachers, librarians, andso on) play?¥how do you deal with the issue of inappropriate material?business models based on advertising and ad trackingchris kelly, excite@homeyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.401appendix aquestions for discussion¥how do business models based on the sale of web advertising work?¥what techniques are used to filter out those with a low probabilityof buying from those with higher probabilities of buying?¥what drives the cost structure of such businesses?thursday, march 8rights management technologydavid maher, intertrust inc.john blumenthal, @stake inc.issues for discussion¥the technology of digital rights management systems¥infrastructure needed to support rights management systems¥application of rights management systems to restricting distribution of materialusenet newsgroups and the world wide webdan geerdevelopmental progression and sexualityjohn gagnon, suny stony brookpepper schwartz, university of washingtonelizabeth casparian, independent consultantquestions for discussion¥how does developmental progression affect the appropriatenessof exposing a minor to sexually explicit material?¥what types of material may be harmful according to childrenõsgrowth and developmental needs, and how may harmful effects changewith age and developmental milestone?¥how should developmental issues shape efforts to protect kidsfrom inappropriate sexually explicit material?approaches to regulating sexually explicit material on the internetlarry lessigyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.402youth, pornography, and the internet.xxx domains (by videoconference)donald eastlake, motorolapublic testimony from birds of a feather session with the 2001 conference oncompters, freedom, and privacy, by videoconferencesite visit to austin, texas, april 34, 2001attendees from the national research councillinda hodgemarilyn masonherb lin (staff)daniel llata (staff)tuesday, april 3pflugerville: john connally high schoolsession with teachers, administrators, school librarians, and technologistssession with studentscepeda branch librarysession with librarians and technical managerssession with youth group leaders, teachers, and program directorsopen session at the courtyard marriott hotel northparents and pta membersschool board membersother adultswednesday, april 4visit to settlement homepanel session with studentspanel session with teachers and school administratorssite visit to greenville, south carolina, april 1718, 2001attendees from the national research councilfather william j. byronlinda hodgebob schlossherb lin (staff)daniel llata (staff)youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.403appendix atuesday, april 17mauldin middle schoolwilliam harner, district superintendentsession with studentssession with teachers and school administratorsw. jack greer library of mauldinbeverly james, executive director of greenville county librarysystemsession with librarians and technical managersphillis wheatley associationsession with youth group leaderssession with studentsopen session at w. jack greer library of mauldinboards of trustees, greenville county library systemrepresentatives of school district of greenville countyptsa representativeswednesday, april 18greenville senior high academy of academic excellenceginger stuart, interim principalsession with studentssession with teachers and school administratorssite visit to salt lake city, utah, april 2627, 2001attendees from the national research councildavid forsythgeoffrey stonegail pritchard (staff)joah iannotta (staff)thursday, april 26utah education network (uen)sessions with uen administrators and technologistsmeeting with paula houston, complaints ombudsman, obscenity and pornography, office of the utah attorney generalyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.404youth, pornography, and the internetsalt lake city librarysession with librarians and technical managerssession with library teen advisory panelopen session at salt lake city libraryfriday, april 27tooele high schoolsessions with studentssession with teachers and school administratorssite visit to san diego, california, may 23, 2001attendees from the national research councillinda hodgejanet schofieldwinnie wechslerherb lin (staff)gail pritchard (staff)wednesday, may 2rancho bernardo high schoolsession with students from the high schoolsession with students from bernardo heights middle schoolsession with high school teachers, school administrators, and schoollibrarianscasa familia community programsession with casa familia staffsession with casa familia studentssession with casa familia youth group leaders, instructors, and technical managersel cajon librarysession with librarians and technical managersopen session in el cajon library community roomthursday, may 3lincoln high schoolsession with high school studentsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.405appendix asite visit to blacksburg, virginia, may 89, 2001attendees from the national research councildick thornburghsandra calvertlinda hodgerobin raskinherb lin (staff)gail pritchard (staff)tuesday, may 8blacksburg middle schoolsession with studentssession with teachers and school administratorschristiansburg high schoolsession with librarians and technical managerssession with instructional supervisors and teachers of technologycoursesblacksburg electronic villagediscussion with directorwednesday, may 9blacksburg high schoolsession with teachers and school administratorssession with studentssite visit to coral gables, florida, may 31june 1, 2001attendees from the national research councilnick belkinherb lin (staff)d.c. drake (staff)thursday, may 31coral gables high schoolsession with students (mostly juniors and sophomores)session with teachers and school administratorsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.406youth, pornography, and the internetboys and girls club, kendall branchsession with studentssession with administrators and instructorsopen session at coral reef senior high schoolpta representativesother parentssite visit to redding, shelton, bristol, kent, andhamden, connecticut, june 12, 2001attendees from the national research councildan geerlinda hodgefriday, june 1joel barlow high school in redding, connecticutpanel session with parents and community membersshelton intermediate school in shelton, connecticutsession with teachers, school administrators, librarians, technical managers, and resource officerssession with middle school studentsbristol board of education offices in bristol, connecticutsession with principals, teachers, public librarians, students, and technical managersopen session at kent center school in kent, connecticutsession with local education policy makers and parentssaturday, june 2connecticut state pta officesession with parentsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.407acceptable use policy (aup) is a set of guidelines and expectations abouthow individuals will conduct themselves online.adolescent is generally an individual older than 13 but younger than theage of majority or 18, whichever is smaller.adult is an individual who has attained the age of majority. note thatòadultó is a term with legal significance and also with social significance.the age of majority varies by state and even by context (e.g., a 19yearold can vote but not drink alcohol in many states).adult verification service is a service provided to businesses that validatesthe adult status of certain customers. often, but not always, a creditcard is used to provide assurance of oneõs adult status.algorithm is a stepbystep problemsolving procedure, especially an established computational procedure for solving a problem in a finitenumber of steps.authentication is the process of confirming an asserted identity with aspecified, or understood, level of confidence. the mechanism can bebased on something the user knows, such as a password, somethingthe user possesses, such as a smart card, something intrinsic to theperson, such as a fingerprint, or a combination of two or more ofthese.avi is a format for online video. a file named òexample.avió is likely tobe a fullmotion video that can be played on a computer.bandwidth refers to the amount of data that can be transmitted in a fixedamount of time. for digital devices, bandwidth is usually expressedbglossary and acronymsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.408youth, pornography, and the internetin bits per second (bps) or bytes per second. a standard dialupconnection to the internet, for example, typically has a bandwidth ofaround 56 k (or 56,000 bits per second).binary refers to a number system that has just two unique digits. computersoperate on the binary numbering system (binary code), which consists ofjust two unique numbers, 0 and 1 (or, as some like to think of it, òonó andòoffó).bit (or binary digit) is the smallest element of computer storage. it is asingle digit in a binary number (0 or 1).black list, in internet filtering technology, is a list of web sites (or urls)to which access from a given workstation or user has been specificallyforbidden. contrast with white list.boolean logic refers to a system of logic based on operators such as and,or, and not. in many search engines, search terms are linked withthese boolean operators to formulate more precise queries.broadband is a term used commonly to refer to communications or webaccess that is faster than dialup (56 k). such access would includecable modems and digital subscriber lines.browser software is the actual computer program used to view documents on the world wide web (e.g., netscapeõs navigator or microsoftõs internet explorer).bulletin board is a computer system used as an information source andforum for a particular interest group. the bulletin board typicallyholds postings made by various participants and replies to thosepostings from other participants.byte is the common unit of computer storage. it is made up of eight bits(or binary digits). a byte holds the equivalent of a single character,such as the letter a, a dollar sign, or a decimal point.cache refers to a place to store files locally for quicker access. caches areused to speed up data transfer and may be either temporary or permanent. memory and disk caches are used in every computer tospeed up instruction execution and data retrieval.cert is the computer emergency response team based at carnegiemellon university.chat is realtime conferencing between two or more users on the internet.chatting is usually accomplished by typing on the keyboard, notspeaking, and each message is transmitted directly to the recipient.chat room is a virtual room where a chat session takes place. technically,a chat room is really a channel, but the term òroomó is used to promote the chat metaphor.child is used in the report to denote a broad category of individuals whoare younger than adult.click (or mouse click) is a way of making a selection online.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.409appendix bclient is an application that runs on a personal computer or workstationand relies on a server to perform some operations. for example, an email client is an application that enables one to send and receive email.clientserver model is a network architecture in which each computer orprocess on the network is either a client or a server. servers arepowerful computers or processes dedicated to managing disk drives(file servers), printers (print servers), or network traffic (network servers). clients are pcs or workstations on which users run applications.clients rely on servers for resources, such as files, devices, and evenprocessing power.clientside refers to any operation that is performed at the client workstation. contrast with serverside.content provider is an organization or individual that creates information, educational, or entertainment content for the internet. a contentprovider may or may not provide the software or network infrastructure used to access the material.cookie is a message given to a web browser by a web server. the browserstores the message in a file (generally called cookie.txt). the messageis then sent back to the server each time the browser requests a pagefrom the server. cookies are often used by web sites to track usersand their preferences.cost per acquisition (cpa) refers to an advertising model in which anadvertiser pays a web site operator for displaying an ad based on thenumber of new subscriptions the ad generates.cost per click (cpc) refers to an advertising model in which an advertiser pays a web site operator a certain amount (e.g., $0.05) each timea user clicks on one of the advertiserõs ads on the operatorõs web site.cost per mille [thousand] (cpm) refers to an advertising model in whichan advertiser pays a web site operator each time the advertiserõs ad isdisplayed (e.g., $3 per 1,000 displays).crawlerñsee spider or web crawler.cybersex referes to online realtime dialog with someone (usually textbased) that interactively describes sexual behavior and actions withoneõs online partner for erotic purposes and expression.cyberspace is a termñcoined by william gibson in his 1984 novel neuromancerñthat refers to the internet or to the online or digital world ingeneral.cybertipline is the program operated by the national center for missingand exploited children for reporting child abuse and child pornography.database is a collection of information organized in such a way that users(often both people and computer programs) can quickly select desired pieces of data.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.410youth, pornography, and the internetdialup is the most common method for accessing the internet. it involves making a connection from a userõs computer (by using a modem) over a standard phone line to an internet service provider. contrast with òalwaysonó access methods such as cable modems or dsllines.digital subscriber line (dsl) is a term used to denote a class of technologies that use copper phone lines to establish highspeed internet connections between telephone switching stations and homes or businesses (a socalled òlastmileó technology).domain name service (dns) is an internet service that translates domainnames into ip addresses. for example, the domain name òwww.nationalacademies.orgó might translate to ò198.105.232.4.ódownload refers to the act of copying data (usually an entire file) from amain source to a peripheral device. the term is often used to describethe process of copying a file from an online service to oneõs owncomputer.email is short for òelectronic mail,ó the transmission of messages overnetworks.encryption is any procedure used in cryptography to convert plain textinto cyphertext to prevent anyone but the intended recipient fromreading the data.file attachment is a method by which users of email can attach files tomessages (e.g., one might send a relative a digital picture of a newborn in an email announcing his or her birth).filter (or filtering) is a type of technology that allows internet material oractivities that are deemed inappropriate to be blocked, so that theindividual using that filtered computer cannot gain access to thatmaterial or participate in those activities.gnutella is file sharing system on the internet that lets users search forsoftware and documents on the gnutellanet, a loose federation ofusers and organizations that make a wide variety of information available to the world at large. gnutella is also an example of peertopeernetworking.graphics file is a file that holds an image. jpeg and gif are two popularformats for image files.hard disk is a computerõs primary storage medium, and it is usually afixed component within the computer itself. contrast with òfloppyódisks, which are temporary, disposable, and removable.harvester is an automated program that is designed to collect emailaddresses by scanning web sites, bulletin boards, and chat rooms(among other things).history file refers to the list most web browsers maintain of downloadedpages in a session so that users can quickly review everything thatyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.411appendix bhas been retrieved. however, history files can be cleared or alteredeasily.hypertext markup language (html) is the authoring language used tocreate documents on the web. web pages are built with html codes(usually called òtagsó) embedded in the text; these tags define pagelayout, fonts, and graphic elements, as well as hypertext links to otherdocuments on the web.hypertext transfer protocol (http) is a communications protocol usedto connect clients and servers on the web. httpõs primary functionis to establish a connection with a web server and transmit htmlpages to the client browser.icq (òi seek youó) is a conferencing program for the internet. much likeaolõs instant messenger service, icq provides interactive chat andfile transfer, and can alert users when someone on their predefinedlist has come online.icra is the internet content rating association (www.icra.org).image recognition/analysis (or òrecognitionó) is the process throughwhich a computer can identify an image (e.g., this graphics file contains an image of a naked woman).information retrieval refers to the processes, methods, and proceduresused to selectively recall recorded data from a database.instant message (im) is a twoway, realtime, private dialog between twousers. a user initiating an im sends an invitation to talk to another(specific) user who is online at the same time. instant messaging isvery popular today, because unlike participation in chat rooms, onetends to talk to people whom one already knows. note also that imsare often used in conjunction with chat roomsña user in a chat roomcan send an im to someone else in the chat room (because he or shesees the other partyõs screen name or òhandleó), thus establishing aprivate communication.intellectual property refers to the ownership of ideas and control overthe tangible or virtual representation of those ideas.internet is a decentralized global communications network connectingmillions of individual users and machines.internet protocol (ip) is a part of the tcp/ip suite of protocols that allows the various machines that make up the internet to communicatewith each other.internet relay chat (irc) is another conferencing system used on theinternet. however, unlike in instant messaging, users do not communicate directly with each other; rather, the server broadcasts all messages to all current users of a particular channel.internet service provider (isp) is an organization or company thatprovides access to the internet. examples of nationallevel ispsyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.412youth, pornography, and the internetinclude america online (aol), earthlink, and microsoft network(msn).internet telephony refers to twoway transmission of audio over the internet. internet telephony allows users to employ the internet as thetransmission medium for telephone calls. it is also commonly referred to as voiceoverip (voip).ip address is an identifier for a computer or device on a tcp/ip network.networks using the tcp/ip protocol route messages based on the ipaddress of the destination. the format of an ip address is a 32bit numeric address written as four numbers separated by periods. eachnumber can be zero to 255 (e.g., ò1.160.10.240ó could be an ip address).keystroke log is a method for recording each keystroke made by a useron a given computer.link (or hyperlink) is a reference or pointer to another document. clicking on (or selecting) a link on a web page generally takes one to thedocument being referenced (e.g., clicking on a link to the nrcõs homepage will open the nrcõs home page document in the userõs browser).local area network (lan) is a computer network that spans a relativelysmall area. most lans are confined to a single building or group ofbuildings. however, one lan can be connected to other lans overany distance via telephone lines and radio waves.log is a file that lists actions that have occurred. for example, webservers maintain log files listing every request made to the server. seealso keystroke log.login refers to the way that computers recognize users. logins are alsocommonly referred to as user names. generally, the combination of acorrect login (or user name) and password is required to gain accessto networked computers.megabyte (mb) is the term used to denote 1 million bytes (or, moreprecisely, 1,048,576 bytes).meta tags are elements within html code that allow page creators todescribe the content of web pages. meta tags are often read andindexed by search engines.metadata is a component of data which describes the data. it describes thecontent, quality, condition, or other characteristics of data. for instance,in the head section of most html documents, many web page creatorsencode information about the title, author, date of creation or update, andkeywords relating to or descriptions of the documentõs content.minor is a term generally used in a legal context to denote individualswho are younger than adults.modem is a device that enables a computer to transmit digital data overanalog telephone lines.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.413appendix bmoderated newsgroup is a mailing list in which all postings are òmoderatedó by a specific individual with the authority and power to rejectindividual postings that he or she deems inappropriate.mousetrapping is a technique that forces a user to remain on a specificweb site by not allowing the user to leave the site. whenever the usertries to leave the site by closing the browser window or going to anew url, the site that is mousetrapping will automatically open anew browser window with its url or not allow the browser to go tothe new url.mpeg is a term that refers to the family of digital video compressionstandards and file formats developed by the motion picture encodinggroup (hence, mpeg). the term is also often used to refer to the filesof digital video and audio data available on the internet.multimedia refers to applications that combine text, graphics, fullmotion video, and/or sound into an integrated package.napster was initially an application that gave individuals access to oneanotherõs music (mp3) files by creating a unique filesharing systemover the internet.net is a short term for internet.newsgroup is an online discussion group. on the internet, there areliterally thousands of newsgroups covering every conceivable interest (e.g., see <http://groups.google.com>).offline refers to the time that a user is not connected to the internet.contrast with online.online refers to the time that a user is connected to the internet. contrastwith offline.overblocking refers to a situation where internet filtering software blocksaccess to resources that authorities did not intend to block. contrastwith underblocking.password is a secret series of characters that enables a user to access a file,computer, or program. on multiuser systems, each user must enterhis or her correct username/password combination before the computer will respond to commands.peertopeer network is a communications network that allows all computers in the network to act as servers and share their files with allother users on the network. gnutella is one example of peertopeernetworking on the internet. contrast with clientserver.pixel is the smallest discrete element of an image or picture on a computermonitor (usually a singlecolored dot).platform for internet content selection (pics) is a system for rating thecontent of web sites that has been endorsed by the world wide webconsortium.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.414youth, pornography, and the internetplugin is an auxiliary program that works with internet browser software to enhance its capability (e.g., realnetworkõs realplayer ormicrosoftõs media player).portal is a web site or service that offers a broad array of resources andservices, such as email, search engines, subject directories, and forums. yahoo! is an example of a portal.precision is a measure of the effectiveness of information retrieval and isoften expressed as the ratio of relevant documents to the total numberof documents retrieved in response to a specific search. for example,using a web search engine, if a search retrieves 100 documents, butonly 30 of them are truly relevant to the search, the precision wouldbe 30 percent. contrast with recall.probabilistic algorithm is an algorithm that works for all practical purposes but has a theoretical chance of being wrong.proxy server is a server that sits between a client application, such as aweb browser, and a real server. it intercepts all requests to the realserver to see if it can fulfill the requests itself. if not, it forwards therequest to the real server. proxy servers can also be used to filterrequests to prevent users from accessing specific web sites.push transfer refers to a form of data delivery in which data is automatically delivered to the userõs computer without the userõs having tomake a request for the data.realtime audio/video refers to communication of either sound of imagesover the internet that occurs without delay in real time, much like atelephone conversation.recall is a measure of the effectiveness of document retrieval expressedas a ratio of the total number of relevant documents in a given database (or on the web) to the number of relevant entries or documentsretrieved in response to a specific search. however, determining asearchõs recall can be problematic because it is often very difficult todetermine the total number of relevant entries in all but very smalldatabases. contrast with precision.remote viewing is the capability of system administrators (whether theybe information technology òhelpdeskó personnel or teachers in a classroom) to view what is being displayed on a given workstation orcomputer from their own location.scanner is a device that can copy text or illustrations printed on paperand translate that information into a form a computer can use.screen name is an alias (or short nickname) chosen by a computer user toemploy when accessing his or her online service or network account.see also login.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.415appendix bsearch engine is program that searches documents (or indexes of documents) for specified words or phrases and returns a list of the documents where those items were found.server is a computer (as well as the software that is running on thatcomputer) that delivers (or serves up) web pages.serverside refers to any operation that is performed at the server. contrast with clientside.smart card is a small physical hardware device (typically the size of acredit card) containing readonly nonvolatile memory and a microprocessor that can be inserted into a card reader attached to a computer. in most scenarios, the individual user carries the card andinserts it into an internet access point that requires such a device. thememory onboard the device can store information about the user,including his or her age, preferences for material to be blocked, andso on. software installed on the computer, and on web sites visited,would check the smart card for dates of birth when necessary, and ifthe user were underage for certain types of material, would refuse togrant access to that material.spam generally refers to unsolicited email, particularly unsolicited email of a commercial nature.spider is a computer program that automatically retrieves web documents. they are often used to feed pages to search engines for indexing. another term for these programs is web crawler.streaming media refers to a technique for transferring data in such a waythat it can be processed as a steady and continuous stream (as opposed to the userõs needing to download the entire file before beingable to view or listen to it).surfing (or web surfing) is a metaphor for browsing the contents of theweb.tcp/ip (or transmission control protocol/internet protocol) is the suiteof communications protocols used to connect machines on the internet. tcp/ip allows different hosts on the internet to establish a connection with each other and exchange streams of data.teaser refers to web pages or portions of web sites that are intended toentice users to spend more time at a given web site or become payingcustomers.thumbnail is a miniature display of a page or image. thumbnails enableusers to see the layout of many items on the screen at once.toplevel domains are the major subdivisions within the internetõs domain name service (dns). examples of top level domains includeñamong othersñ.com, .gov, and .edu.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.416youth, pornography, and the internettraffic refers to the load on a given web site or resource. a hightrafficweb site, for instance, receives many visitors or requests for data.traffic forwarding is the practice whereby one web site forwards trafficto another web site and may receive a fee for doing so.underblocking refers to a situation whereby internet filtering softwaredoes not block access to resources that authorities intended to block.contrast with overblocking.uniform resource locator (url) is the address of documents and otherresources on the world wide web. the first part of a url indicateswhat protocol to use to access the document (e.g., òhttpó or òftpó),while the second part specifies the domain name where the resourceis located (e.g., www.example.com) as well as the directory and thename of the requested document.usenet is a worldwide bulletin board system that can be accessed throughthe internet or through many online services. it contains more than14,000 forums, called newsgroups, that cover almost every imaginable interest group.vchip is an electronic circuit or mechanism in a television that parentscan use to block programs they consider inappropriate for their children. vchips can be configured to block all programs of a givenrating.virtual hosting refers to the ability of internet service providers or web siteoperators to òhostó web sites or other services for different entities onone computer while giving the appearence that they exist on separateservers. for instance, with virtual hosting, one might have web sitesfrom two separate, distinct organizations residing on and being servedfrom one particular server (with one particular ip address).web is a shortened form of world wide web (www).web crawler is a computer program that automatically retrieves webdocuments. they are often used to feed pages to search engines forindexing. another term for these programs is spider.web page hosting refers to the ability of internet service providers, companies, or other organizations to act as a server of web pages.webcam is a video camera that is used to capture periodic images orcontinuous frames to a web site for display.webtv is a service that makes a connection to the internet via a userõstelephone service and then converts the downloaded web pages to aformat that can be displayed on a television.white list, in internet filtering technology, is a list of web sites (or urls)to which access from a given workstation or user has been specificallyapproved. contrast with black list.workstation refers to a computer connected to a network (often theinternet).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.417appendix bworld wide web (www) refers to the set of all the information resources that can be accessed via http.world wide web consortium (w3c) is one of the main standards bodiesfor the world wide web. the w3c works with the global communityto help establish international standards for client and server protocols that enable communications on the internet.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.418c.1information retrieval technologiesinformation retrieval, a function that supports people who are actively seeking or searching for information, typically assumes a static orrelatively static database of digital objects against which people search.these digital objects may be documents, images, sound recordings, andso on.the general information retrieval problem is one of making a decisionabout which objects in the database to show to the user. systems forinformation retrieval seek to maximize the material that a person sees thatis likely to be relevant to his or her information problem, and to minimizethe material that is not relevant to the problem.an information retrieval system works by representing the objects ina database in some wellspecified manner, and then representing theuserõs information problem (òinformation needó) in a similar fashion.the retrieval techniques then compare needs with objects.a key aspect of object representation is the language used to describethe objects in question. typically, this language (more precisely, a òmetalanguageó) consists of a vocabulary (and sometimes precise grammar)that can characterize the objects in a form suitable for automated comparison to the userõs needs.the representation of information objects also requires interpretations by a human indexer, machine algorithm, or other entity. whenpeople are involved, the interpretation of a particular text by one personcselected technology issuesyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.419appendix cis likely to be different from that of someone else, and may even be different for one person at different times. as a personõs state of knowledgechanges, his or her understanding of a text changes. everyone has experienced the situation of finding a document not relevant at some point,but quite relevant later on, perhaps for a different problem or perhapsbecause we, ourselves, are different. such subjectivity means that decisions about representation will be inconsistent. an extensive literature oninterindexer consistency indicates that when people are asked to represent an information object, even if they are highly trained in using thesame metalanguage (indexing language), they might achieve 60 to 70percent consistency at most in tasks like assigning descriptors.1machineexecutable algorithms for representing information objectsor information problems do give consistent representations. but anyone such algorithm gives only one interpretation of the object, out of agreat variety of possible representations, depending on the interpreter.the most typical way to accomplish such representations is throughstatistically based automatic indexing. techniques of this sort index(represent) documents by the words that appear in them, deleting themost common (articles, prepositions, and other function words), conflating different forms of a word into one (e.g., making plural and singular forms the same), and weighting the resulting terms according tosome function of how often they appear in the document (term frequencyñthe more occurrences, the greater the weight) and how manydocuments they appear in (document frequencyñthe more documents,the lower the weight).a consistent result in information retrieval experimentation is thatautomatic indexing of the sort just described gives results that are at leastas good as human indexing, and usually better. performance is evaluatedby a pair of measures, recall and precision.2 this result is often stated asmeaning that automatic indexing is better than manual indexing, becausemanual indexing is so much more expensive than automatic. but it isimportant to keep in mind another consistent information retrieval result,that the sets (or lists) of documents that are retrieved using one technique1l.e. lawrence, 1977, interindexer consistency studies 19541975: a review of the literatureand summary of study results, university of illinois, graduate school of library science,urbanachampaign; k. markey, 1984, òinterindexer consistency tests: a literature review and report of a test of consistency in indexing visual materials,ó library and information research, 6(2): 155177; l. maichan, 1989, òinterindexer consistency in subject cataloging,ó information technology and libraries 8(4): 349357.2òrecalló measures how complete the search results are, and is the proportion of relevantdocuments in the whole collection that have actually been retrieved. òprecisionó measureshow precise the search results are, and is the proportion of retrieved documents that arerelevant.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.420youth, pornography, and the internetare different from those retrieved by another technique (both relevantand nonrelevant documents).having constructed representations of both the information objectsand the personõs information problem, the information retrieval system isin a position to compare these representations to one another, in order toidentify those objects that match the information problem description.technologies for accomplishing this are called search or retrieval techniques.because people in general cannot specify precisely what it is that they donot know (that for which they are searching), because people cannot represent accurately and completely what an information object is about, andbecause relevance judgments are inherently subjective, it is clear that suchtechniques must be probabilistic, rather than deterministic. that is, anydecision as to whether to retrieve (or block) an information object is always a guess, more or less well informed. thus, in information retrieval,we cannot ever say with confidence that an information object is (or isnot) relevant to an information need, but can only make judgments ofprobability (or belief) of (non)relevance.it can be easily seen that many of the problems that information retrieval faces are also problems that information filtering must face. although filtering aims to not retrieve certain information objects, it stillmust do so on the basis of some representation of those objects, and somerepresentation of the person for whom the filtering is done. filteringworks by prespecifying some information object descriptions that are tobe excluded from viewing by some person or class of persons. thus, itdepends crucially on having an accurate and complete representation ofwhat is to be excluded (this is analogous to the query or informationproblem representation), and also accurate and complete representationsof the information objects that are to be tested for exclusion. just as ininformation retrieval, making the exclusion decision in information filtering is an inherently uncertain process.c.1.1text categorization and representationautomatic text categorization is the primary language retrieval technology in content screening. text categorization is the sorting of text intogroups, such as pornography, hate speech, and violence. a text categorizer looks at a textbased information object and decides the propercategorization for this object. applications of text categorization are filtering of electronic email, chats, or web access; and indexing and datamining.the principal problem with text categorization is that text is ambiguous in many ways: polysemy, synonymy, and so on. for example, a bankyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.421appendix ccan be either a financial institution or something on the side of a river(polysemy). the context matters a lot in the interpretation.efficient automatic text categorization requires an automated categorization decision that identifies, on the basis of some categorization rules,the category into which an object falls. (note that if the rules are separated from the decision maker, the behavior of the decision maker can bechanged merely by changing the rules, rather than requiring the rewritingevery time of the software underlying the decision maker.) the decisionmaking software examines the text in the information object, and on thebasis of these rules, categorizes the object. the simplest decision rulesmight base the decision on the mere presence of certain words (e.g., if theword òbreastó appears, the object is pornographic). more sophisticatedrules might search for combinations of words (e.g., if the word òbreastóappears without the word òcancer,ó the object is pornographic), or evenweighted combinations of different words.decision rules are developed by modeling the kinds of decisions thatresponsible human beings make. thus, the first step in automated rulewriting (also known as òsupervised learningó) is to ask a responsibleindividual to identify, for example, which of 500 digital text objects constitute pornography and which do not. the resulting categorization thusprovides a training set of 500 sample decisions to be mimicked by thedecision rules.of course, the selection of the persons who provide the samples iscrucial, because whatever they do becomes the gold standard, which thedecision rules then mimic. everything depends on the particular personsand their judgments, but the technology does not provide guidance onhow to define the community or whom to select as representatives of thatcommunity.research indicates that supervised learning is at least as good as expert human rule writing.3 the effectiveness of these methods is far fromperfectñthere is always a high error rateñbut sometimes it is near agreement with human performance levels. still, the results differ from category to category, and it is not clear how directly it applies to, for example, pornography. as discussed below, there is an inevitable tradeoffbetween false positives and false negatives (i.e., attributing an item to acategory when it should not be; not attributing an item to a category whenit should be), and categories vary widely in difficulty. substantially improved methods are not expected in the next 10 to 20 years.3fabrizio sebastiani. 2002. òmachine learning in automated text categorization,ó acmcomputing surveys 34(1): 147.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.422youth, pornography, and the internetit is not clear which text categorization techniques are most effective.the best techniques are not yet used commercially, so there may be incremental improvements. nor is it clear how effective semiautomated categorization is, or whether the categories that are difficult for automatedmethods are the same as those that most perplex people.the simplest machine representation of text is what is known as theòbagofwordsó model, in which all of the words in an object are treatedas an unstructured list. if the objectõs text is, òdick armey chooses bobshaffer to lead committee,ó then a representative list would be: armey,bob, chooses, committee, dick, lead, shaffer. (a slightly more sophisticated version associates a count of the number of times each word occurswith the word itself.) note that in such a representation, the structure andcontext of the text are completely lost.thus, one weakness in the representation is due to the ambiguity oflanguage, which is resolved in human discourse through context. forexample, the word òbeaveró has a hunterõs meaning and a pornographicmeaning. other words, such as òbreastó and òblow,ó may be less ambiguous but can be used pornographically or otherwise. when contextis important in determining meaning, the bagofwords representationis inadequate.the bagofwords representation is most useful when two conditionsare met: when there are unambiguous words indicating relevant content,and when there are relatively few of these indicators. pornographic texthas these properties; probably about 40 or 50 words, most of them unambiguous, indicate pornography. thus, the bagofwords representation isreasonably well suited for this application, especially if a high rate of falsepositives is acceptable. however, in many other areas, such as violenceand hate speech, the bagofwords representation is less useful. (forexample, while a pornographic text such as the text on an adult web pageoften can be identified by viewing the first few words, one must oftenread four or five sentences of a text before identifying it as hate speech.)when fidelity of representation becomes important, a number of techniques can go beyond the bagofwords model: morphological analysis,partofspeech tagging, translation, disambiguation, genre analysis, information extraction, syntactic analysis, and parsing. for example, a technique more robust than the bagofwords approach is to consider adjacentwords, as search engines do when they give higher weight to informationobjects that match the query and have certain words in the same sentence.however, even with these technologies, true machineaided text understanding will not be available in the near term, and there always will be asignificant error rate with any automated method. approaches that gobeyond the bagofwords representation improve accuracy, which maybe important in contexts apart from pornography.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.423appendix cc.1.2image representation and retrievalimages can be ambiguous in at least as many ways as text can be.furthermore, there is no universal metalanguage for describing images.people who are interested in images for advertising purposes have different ways to talk and think about them than do art historians, even thoughthey may be searching for the same images. the lack of a common metalanguage for images means that special metalanguages must be developed for images for use in different problem domains.the process of determining whether a given image is pornographicinvolves object recognition, which is very difficult for a number of reasons. first, it is difficult to know what an object is; things look differentfrom different angles and in different lights. when color and texturechange, things look different. people can change their appearance bymoving their heads around. we do not look different to one anotherwhen we do this, but we certainly look different in pictures.today, it is difficult for computer programs to find people, thoughfinding faces can be done with reasonably high confidence. it is oftenpossible to tell whether a picture has nearly naked people in it, but thereis no program that reliably determines whether there are people wearingclothing in a picture.to find naked people, image recognition programs exploit the factthat virtually everyoneõs skin looks about the same in a picture, as long asone is careful about intensity issues. skin is very easy to detect reliably inpictures, so an image recognition program searching for naked peoplefirst searches for skin. so, one might simply assume that any big blob ofskin must be a naked person.however, images of the california desert, apple pies, and all sorts ofother things are rendered in approximately the same way as skin. a morerefined algorithm would then examine how the skin/desert/pie coloringis arranged in an image. for example, if the coloring is arranged inpatterns that are long and thin, that pattern might represent an arm, a leg,or a torso. then, because the general arrangement of body parts is known,the location of an arm, for example, provides some guidance about whereto search for a leg. assembling enough of such pieces together can provide enough information for recognizing a person.a number of factors help to identify certain pornographic pictures,such as those that one might find on an adult web site. for example, insuch pictures, the people tend to be big, and there is not much other thanpeople in these pictures. exploiting other information, such as the sourceof the image or the words and links on the web page from which theimage is drawn, can increase the probability of reliable identification ofsuch an image.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.424youth, pornography, and the internetbut it is essentially impossible for current computer programs to distinguish between hardcore and softcore pornography, because what constitutes òhardcoreó versus òsoftcoreó pornography is in the eyes of theviewer rather than the image itself. consider also whether the photographs of jock sturges, many of which depict naked children, constitutepornography. furthermore, in the absence of additional information, it isquite impossible for computer programs to distinguish between imagesthat contain naked people in what might be pornographic poses, whichare considered òhigh artó (e.g., paintings by rubens), and what someonemight consider a truly pornographic image.what computer programs can do with reasonable reliability today(and higher reliability in the future) is to determine whether there mightbe naked people in a picture. but any of the contextual issues raisedabove will remain beyond the purview of automated recognition for theforeseeable future.c.2search engines and other operationalinformation retrieval systemsinformation retrieval systems consist of a database of informationobjects, techniques for representing those objects and queries put to thedatabase, and techniques for comparing query representations to information object representations. the typical technique for representing information objects is indexing them, according to words that appear in thedocuments, or words that are assigned to the documents by humans or byautomatic techniques. an information retrieval system then takes thewords that represent the userõs query (or filter), and compares them to theòinverted indexó of the system, in which all of the words used to indexthe objects in the collection are listed and linked to the documents that areindexed by them. surrogates (e.g., titles) for those objects that most closely(or exactly) match (i.e., are indexed by) the words in the query are thenretrieved and displayed to the user of the system. it is then up to the userto decide whether one or more of the retrieved objects is relevant, orworth looking at.from the above description, it is easy to see that òsearch enginesó area type of information retrieval system, in which the database is somecollection of pages from the world wide web, which have been indexedby the system, and in which the retrieved results are links to the pagesthat have been indexed by the words in the userõs query.the basic algorithm in search engines is based on the òbagofwordsómodel for handling data described above. however, they also use somekind of recognition of document structure to improve the effectiveness ofa search. for example, search engines often treat titles differently fromyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.425appendix cthe body of a web page; titles can often indicate the topic of a page. if thesystem can extract structure from documents, then this often can be usedas an indicator for refining the retrieval process.many search engines also normalize the data, a process that involvesstripping out capitalization and most of the other orthographic differences that distinguish words. some systems do not throw this information away automatically, but rather attempt to identify things such assequences of capitalized words possibly indicating a place name or personõs name. the search engine often removes stop words, a list of wordsthat it chooses not to indexñtypically quite common words like òandóand òthe.ó4 in addition, the search engine may apply natural languageprocessing to identify known phrases or chunks of text that properlybelong together and indicate certain types of content.what remains after such processing is a collection of words that needto be matched against documents represented in the database. the simplest strategy is the boolean operator model. simple boolean logic sayseither òthis word and that word occur,ó or òthis word or that wordoccurs,ó and, therefore, the documents that have those words should beretrieved. boolean matching is simple and easy to implement. because ofthe volume of data on the internet, almost all search engines today include an automatic default setting that, in effect, uses the and operatorwith all terms provided to the search engine.all boolean combinations of words in a query can be characterized ina simple logic model that says, either this word occurs in the document,or it does not. if it does occur, then you have certain matches; if not, thenyou have other matches. any combination of three words, for example,can be specified, such that the document has this word and not the othertwo, or all three together, or one and not the other of two. however, if theuser does not specify the word exactly as it is stored in the index, then itwill not be processed appropriately, and in particular the word cannot bea synonym (unless you supply that synonym), an alternate phrasing, or aeuphemism.another strategy is the vector space model. a document is represented as an ndimensional vector, in which n is the number of differentwords in the text, and the component of the vector in any given directionis simply the number of times the word appears in the text. the measureof similarity between two documents (or, more importantly, between adocument and the search query similarly represented) is then given bythe cosine of the angle between the two vectors. the value of this param4note that the stop list is a likely place to put a filter. for example, if òbitchó wasincluded in the stop list, no web site, including that of the american kennel club web site,would be found in searches that included the word òbitch.óyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.426youth, pornography, and the interneteter ranges from zero to 1.0, and the closer the value is to 1.0, the moresimilar the document is to the query or to the other document. in thismodel, a perfect match (i.e., one with all the words present) is not necessary for a document to be retrieved. instead, what is retrieved is aòbest matchó for the query (and of course, less good matches can also bedisplayed).most web search engines use versions of the vector space model andalso offer some sort of boolean search. some use natural language processing to improve search outcomes. other engines (e.g., google) usemethods that weight pages depending on things like the number of linksto a page. if there is only one link to a given page, then that page receivesa lower ranking than a page with the same words but many links to it.the preceding discussion assumes that the documents in question aretext documents. searching for images is much more difficult, because asimilarity metric of images is very difficult to compute or even to conceptualize. for example, consider the contrast between the meaning of apicture of the pope kissing a baby versus a picture of a politician kissing ababy. these pictures are the same in some ways, and very different inother ways.more typically, image searches are performed by looking for text thatis associated with images. a search engine will search for an image linktag within the html and the sentences that surround the image on eithersideñan approach with clear limitations. for example, the words, òoh,look at the cute bunnies,ó mean one thing on a childrenõs web site andsomething entirely different on playboyõs site. thus, the words alonemay not indicate what those images are about.c.3location verificationtoday, the internet is designed and structured in such a way that thephysical location of a user has no significance for the functionality he orshe expects from the internet or any resources to which he or she is connected. this fact raises the question of the extent to which an internetuserõs location can in fact be established through technical means alone.every individual using the internet at a given moment in time isassociated with what is known as an ip address, and that ip address isusually associated with some fixed geographical location. however, because ip addresses are allocated hierarchically by a number of differentadministrative entities, knowing the geographical location of one of theseentities does not automatically provide information about the locationsassociated with ip addresses that it allocates. for example, the nationalacademy of sciences is based in washington, d.c., and it allocates ipaddresses to computers tied to its network. however, the academy hasyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.427appendix cemployees in california, and also computers that are tied to the academynetwork. the academy knows which ip addresses are in california andin washington, d.c., but someone who knew only that an ip address wasone associated with the academy would not know where that ip addresswas located.5under some circumstances, it can be virtually impossible to determine the precise physical location of an internet user. consider, for example, the case of an individual connecting to the internet through a dialup modem. it is not an unreasonable assumption that the user is mostlikely in the region in which calls to the dialup number are local, simplybecause it would be unnecessary for most people to incur longdistancecalling costs for such connections. furthermore, the exchange servingdialup modem access numbers can, in principle, employ callerid technology. however, the exchange associated with the telephone from whichthe dialup call originates may not be technologically capable of providing callerid information; this would be the case in some areas in theunited states and in much of the world. or the user might simply suppress callerid information before making the dialup modem call. inthese instances, the number through which the individual connects to theinternet does not necessarily say anything about his location at that time.internet access routed through satellites can be difficult to localize aswell. the reason is that a satelliteõs transmission footprint can be quitelarge (hundreds of square miles?), and more importantly is moving quiterapidly. localization (but only within the footprint) can be accomplishedonly by working with a detailed knowledge of the orbital movements ofan entire constellation of satellites.however, those connecting to the internet through a broadband connection can be localized much more effectively, though with some effort.for example, while a cable internet isp may assign ip addresses to usersdynamically, any given address must be mappable to a specific cablemodem that can be identified with its media access control address. whilesuch mapping is usually done for billing and customer care reasons, itprovides a ready guide to geographical addresses at the end userõs level.those who gain access through dsl connections can be located becausethe virtual circuit from the digital subscriber line access multiplexer is5while location information is not provided automatically from the ip addresses an administrative entity allocates, under some circumstances, some location information can beinferred. for example, if the administrative entity is an isp, and the isp is, for example, afrench isp, it is likelyñthough not certainñthat most of the subscribers to a french isp arelocated in france. of course, a large french company using this isp might well have branchoffices in london, so the geographical correspondence between french isp and frenchinternet user will not be valid for this case, though as a rule of thumb, it may not be a badworking assumption.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.428youth, pornography, and the internetmapped to a specific twisted pair of copper wires going into an individualõs residence. also, wireless connections made through cell phones(and their dataoriented equivalents) are now subject to a regulation thatrequires the network client to provide location information for e911 (enhanced emergency 911) reasons. this information is passed through thesignaling network and would be available to a wireless isp as well.in principle, the information needed to ascertain the location of any ipaddress is known collectively by a number of administrative entities, andcould be aggregated automatically. but there is no protocol in place topass this information to relevant parties, and thus such aggregation is notdone today. the result is that in practice, recovering location informationis a complex and timeconsuming process.to bypass these difficulties, technical proposals have been made forlocationbased authentication.6 however, the implementation of suchproposals generally requires the installation of additional hardware at thelocation of each access point, and thus cannot be regarded as a generalpurpose solution that can localize all (or even a large fraction of) internetusers.the bottom line is that determining the physical location of mostinternet users is a challenging task today, though this task will becomeeasier as broadband connections become more common.c.4user interfacesthe history of information technology suggests that increasingly realistic and humanlike forms of humancomputer interaction will develop.the immediately obvious trends in the nearterm future call for greaterfidelity and òrealismó in presentation. for example, faster graphics processors will enable more realistic portrayals of moving images, whichsoon will approach the quality of broadcast television. larger screens inwhich the displayed image subtends a larger angle in the eye will increasethe sense of being immersed in or surrounded by the image portrayed.goggles with builtin displays do the same, but also offer the opportunityfor threedimensional images to be seen by the user. virtual realitydisplays carry this a step further, in that the view seen by the user isadjusted for changes in perspective (e.g., as one turns oneõs head, theview changes).6see, for example, dorothy e. denning and peter f. macdoran, 1996,ó locationbasedauthentication: grounding cyberspace for better security,ó in computer fraud and security,elsevier science ltd., february. a commercial enterprise now sells authentication systemsthat draw heavily on the technology described in this paper. see <http://www.cyberlocator.com/works.html>.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.429appendix cspeech and audio input/output are growing more common. today,computers can provide output in the form of sound or speech that iseither a reproduction of human speech or speech that is computersynthesized. the latter kind of speech is not particularly realistic today but isexpected to become more realistic with more research and over time.speech recognition is still in its infancy as a useful tool for practical applications, even after many years of research, but it, too, is expected toimprove in quality (e.g., the ability to recognize larger vocabularies, abroader range of voices, a lower error rate) over time.another dimension of user interface is touch and feel. the òjoystickóoften used in some computerbased video games provides the user with akinesthetic channel for input. some joysticks also feature a force feedbackthat, for example, increases the resistance felt by the user when the stick ismoved farther to one side or another. such òhapticó interfaces can alsoñin principleñbe built into gloves and suits that could apply pressure invarying amounts to different parts of the body in contact with them.finally, gesture recognition is an active field of research. humansoften specify things by pointing with their hands. computerbased effortsto recognize gestures can rely on visual processing in which a humanõsgestures are viewed optically through cameras connected to the computer, and the motions analyzed. a second approach is based on what isknown as a dataglove, which can sense finger and wrist motion and transmit information on these motions to a computer.7product vendors of these technologies promise a user experience ofextraordinarily high fidelity. for example, it is easy to see how thesetechnologies could be used to enhance perceived awareness of othersñone might be alone at home, but through oneõs goggles and headphones,hear and see others sharing the same òvirtualó space. (in one of thesimplest cases, one might just see others with goggles and headphones aswell, but the digital retouching technologies that allow images to be modified might allow a more natural (though perhaps less realistic) depiction.)7see, for example, <http://www.ireality.com/wirelessannounce.html> for a 1997 product announcement by the general reality company.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.430d.1backgroundthe committee conducted site visits in a number of places, includingaustin, texas (april 34, 2001), greenville, south carolna (april 1718,2001), san diego, california (may 23, 2001), blacksburg, virginia (may 89, 2001), coral gables, florida (may 31, 2001), and various towns in connecticut (redding, shelton, bristol, kent, and hamden in the period june12, 2001). during these site visits, members of the committee spoke withstudents in junior and senior high school, as well as school teachers, administrators, librarians, and technologists. in addition, the committeespoke with public librarians (branch managers, childrenõs librarians, reference librarians) and technical managers from library systems. whenpossible, the committee also visited afterschool programs and other venues in which young people had internet access, and spoke with bothchildren and responsible adults. finally, the committee held a number ofopen sessions in which parents and other interested parties could talk tothe committee.d.2recurring themesthough the individuals to whom the committee spoke cannot be takenas being drawn from a representative population, a number of themes didoccur repeatedly during the various site visits.¥pornography was a concern of many students and school persondsite visit synthesisyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.431appendix dnel, but only one of many. teachers were more concerned about inaccurate and misleading information on the internet, and with keeping students in school òon task.ó both students and responsible adults werequite concerned about violence (especially òhowtoó sites) and hate.¥meeting people facetoface that one had encountered first onlinein a chat room or through instant messaging was a standard practice.while only a small a number of students acknowledged having done so,all thought it was an unremarkable, commonplace occurrence. in general, they recognized in an abstract manner the dangers of doing so, butthought that they could tell if they were dealing with an untrustworthyindividualñand said that they would never provide personal information to an individual they regarded as untrustworthy.¥high school students expressed a number of common sentiments,including the following:ñthey often needed for research purposes information on web sitesthat were blocked by the school filter (òimproper blockingó).ñthey rarely or never complained to teachers about such blockingbecause they could get information anyway through home access.ñmany of the sites improperly blocked by the school were neededfor senior high school purposes, but may have been appropriately blockedat the junior high school and elementary school levels.ñthey had been exposed to internet pornography, especially throughspam mail, but had no interest in receiving such mail and deleted it as fastas they could get it.ñthey were not particularly affected by internet pornography because the entire media environment in which they live is highly sexualized. however, a number of students noted that what was upsettingabout pornography was not so much the material itself as the likelihoodthat their parents would òfreak out.óñthey were frustrated by losing control of their computers, mentioning especially spam mail and mousetrapping.¥most of the schools that the committee visited had installed filters,and many libraries had done so as well. however, when asked whatbenefit filters offered their schools and libraries, teachers and librariansinvariably pointed to the political and management benefitsñnot a singleteacher or librarian said that his or her students or patrons were better offwith filters in place. the primary political benefit of filters was that theyeliminated parental complaints, while the primary management benefitwas that they eliminated the need for teachers and students to constantlymonitor student and patron usage.in schools, acceptable use policies (aups) were also common. however, students received little or no instruction in how to comply withyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.432youth, pornography, and the internetthem. students signed aups (sometimes with parental signatures required as well), but they noted that the aups were just one more form tobe filled out at the beginning of the year, and they were not given muchattention, were often not even read carefully, and generally were notinternalized in any meaningful way. in practice, aups seemed to be atool with which a school could discipline a student for some behavior thatwas not explicitly forbidden but that nevertheless was inconsistent withschool policy.in no school were media literacy and internet safety part of the formalcurriculum. librarians did note that they spent some time teaching students how to evaluate sources and credibility, but they were unable tospend more than a class period on this subject in the course of a year.¥most libraries with filters noted that the filters solved problemscaused by adults accessing pornography on the internet on public accessterminals and making a nuisance of themselves. furthermore, they madestaff more comfortable, because staff were no longer forced to confrontpatrons about violations of posted aups. librarians were also concernedwith staff having to make value judgments about what is and is not pornography, particularly when it comes to deciding what a customer canprint and receive; they donõt want to be òpolicemenó in the library; theybelieve the library should be used for educational purposes; and, theydonõt want to formally monitor what people are doing online.¥both parents and students commented on the gap in knowledgebetween them. for example, many students reported that they can changetheir parentsõ parental preferences (on aol) for themselves and haveaccess to their parentsõ accounts, or that their parents donõt know whatprivileges are associated with their screen names. in general, those students with home access have the most expertise, and hence the mostknowledge about how to circumvent adults, know what is available onthe net, and know where to find what they should not see. parents acknowledged the knowledge gap as well, pointing out that they were uncomfortable working in an area in which they could not presume superiorknowledge and experience and thus did not know how to properly instruct their children in this area. moreover, many did not know muchabout the nature of the issues their children face on the internet (apparently because of the significant differences between using the internet as asocial medium (the experience of their kids) and using it as a businessmedium (their own experience).in general, the parents to whom the committee spoke understood theresponsibility they had as parents to provide supervision. however, theywere also aware to some extent that providing supervision does not necyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.433appendix dessarily mean that a child will absorb the lessons that such supervision isintended to impart. they understood the timeintensive nature of appropriate supervision and knew that they (and especially other parents) wereunable or unwilling to provide supervision; nevertheless, they generallyexpressed considerable hesitation to involve the government in this problem (a view that was expressed by both liberal and conservative parents).youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.434ebiographiese.1committee membersdick thornburgh, chair, served as governor of pennsylvania, attorney general of the united states, and undersecretarygeneral of the unitednations during a public career that spanned more than 25 years. he iscurrently counsel to the national law firm of kirkpatrick & lockhart llp,resident in its washington, d.c., office. elected governor of pennsylvaniain 1978 and reelected in 1982, thornburgh was the first republican ever toserve two successive terms in that office and was named by his fellowgovernors as one of the nationõs most effective bigstate governors in a1986 newsweek poll. after his unanimous confirmation by the u.s. senate,thornburgh served 3 years as attorney general of the united states (19881991) under presidents reagan and bush. thornburgh took vigorousaction against racial, religious, and ethnic hate crimes, and his officemounted a renewed effort to enforce the nationõs antitrust and environmental laws. during his tenure as attorney general, thornburgh twicepersonally argued and won cases before the u.s. supreme court. alltold, thornburgh served in the justice department under five presidents,beginning as a united states attorney in pittsburgh (19691975) and assistant attorney general in charge of the criminal division (19751977),emphasizing efforts against major drug traffickers, organized crime, andcorrupt public officials. thornburgh was educated at yale university,where he obtained an engineering degree, and at the university of pittsburgh school of law, where he served as an editor of the law review.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.435appendix ethornburgh served as director of the institute of politics at harvardõsjohn f. kennedy school of government (19871988) and was a visitinglecturer at the george washington university law school (1995). thornburgh is a member of the board of directors of elan corporation, plc andserves on the boards of the urban institute, the national museum ofindustrial history, the dewitt wallace fund for colonial williamsburg,and the national academy of public administration. he is chairman ofthe state science and technology institute and vicechairman of the worldcommittee on disability. he also chairs the legal policy advisory boardof the washington legal foundation. he is a member of the americanbar foundation, the american judicature society, and the council on foreign relations.nicholas j. belkin is a professor at the rutgers university school oflibrary and information science. his research involves the developmentof theory, design principles, and systems that will lead to effective andhumane information support for human problem management. such aprogram entails understanding peopleõs problem situations, and how theyattempt to resolve them, in a variety of contexts; the nature and functionsof information support communication; and information representation,retrieval, and presentation appropriate to such contexts. these factorslead to specific research goals, which currently include characterizationand classification of human informationrelated problems; descriptionand an analysis of humanhuman information interaction and design ofhumancomputer information interaction; and classification of humaninformationseeking strategies and interactions with texts.the reverend william j. byron, s.j. teaches òsocial responsibilitiesof businessó in the mcdonough school of business at georgetown university, where he holds an appointment as distinguished professor of thepractice of ethics and serves as rector of the georgetown jesuit community. from 1982 to 1992, he was president of the catholic university ofamerica. prior assignments include service as president of the universityof scranton (1975 to 1982), dean of arts and sciences at loyola universityof new orleans (1973 to 1975), and various teaching positions in his fieldof economics and social ethics. father byron is the author of severalbooks, including quadrangle considerations (loyola, 1989; winner of thecatholic press associationõs 1990 best book award in education), andanswers from within: spiritual guidelines for managing setbacks in work andlife (macmillan, 1998); he also edited the causes of world hunger (paulist,1982) and take courage: psalms of support and encouragement (sheed &ward, 1995). he is a trustee of carefirst blue cross blue shield, loyolacollege in maryland, and the university of san francisco; he was a foundyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.436youth, pornography, and the interneting director and past chairman of bread for the world, a public memberof the board of commissioners of the joint commission for the accreditation of healthcare organizations, and an original member of the board ofdirectors of the federal commission on national and community service(now the council of independent collegesõ academic leadership award).father byron grew up in philadelphia, where he attended st. josephõspreparatory school. after service in the armyõs 508th parachute infantryregiment in 1945 to 1946, he attended saint josephõs university in philadelphia for 3 years before entering the jesuit order in 1950. he wasordained a priest in 1961.sandra l. calvert is director of the children and media project atgeorgetown university. she received her ph.d. in developmental andchild psychology from the university of kansas in 1982. dr. calvert is aprofessor of psychology, an associate member of the linguistics department, and a core member of the communication, culture, and technologyprogram at georgetown university. her research involves how information technologies, such as television and computers, influence childrenõsattention, memory, and comprehension. she is particularly interested inhow the forms of media (i.e., features such as action, sound effects, andlanguage) interface with how children think (e.g., visually or verbally) atdifferent points in their development. her recently published book,childrenõs journeys through the information age (mcgraw hill, 1999), provides a critical synthesis of the research on childrenõs social and cognitivedevelopment in relation to information technologies.david forsyth is associate professor of computer science at the university of california, berkeley. he is a renowned researcher in the area ofobject recognition; several of his papers describe systems for identifyinghumans and their activities in single images. he holds a b.sc. and m.sc.in electrical engineering from the university of the witwatersrand,johannesburg, and a d.phil. from balliol college, oxford. he has published more than 60 papers in computer vision and computer graphics.he is currently coauthoring computer visionña modern approach, agraduate textbook in computer vision; some 20 chapters are currentlyavailable on the web. he has served as a referee for all the main professional journals in the area, and he is currently program cochair for theieee computer vision and pattern recognition conference and a memberof the program committee for the european conference on computervision.daniel geer is chief technologist officer for @stake inc., a privatelyheld confidential ecommerce consulting firm. dr. geer previously servedyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.437appendix eas vice president and senior strategist for certco, as director of engineering at open market inc., and as chief scientist, vice president of technology, and managing director for openvision technologies. he has servedas a technical director within digital equipment corporationõs researchdivision and was for a number of years the manager of systems development for mitõs project athena, where he was the responsible manager forall technical development, including the x window system, kerberos,and others. he holds a b.s. in electrical engineering and computer sciencefrom mit and a sc.d. in biostatistics from harvard university.linda hodge of colchester, connecticut, is national pta presidentelect, 20002003. prior to becoming presidentelect, hodge was nationalpta vice president for programs, 19992001. she is a former nationalpta region 7 director, which included representing the states of alaska,hawaii, idaho, montana, oregon, washington, and wyoming. she hasalso chaired the national pta bylaws, technology/safety, and membership committees and is a former member of the executive, budget,and leadership committees, and the iod cultural arts subcommittee.hodge is a past president of hawaii state pta. hodge is a national ptahonorary life member as well as an honorary life member of fourteenstate ptas. included among her awards are the california pta honoraryservice award, the california pta continuing service award, and thevallejo school district award recognizing outstanding parent volunteers. outside of the pta, hodge serves on the board of directors of theflock theatre, a regional theater group serving connecticut, new york,and massachusetts. her volunteer activities have included serving on theboards of local girl scouts, boy scouts, little league, and youth centerorganizations. hodge holds an a.s. degree in computer science and iscurrently taking courses at eastern connecticut state university in business administration.marilyn gell mason has more than 25 years of management experience with 20 years as a chief executive in complex and highly politicalorganizations. she has served as director of two major urban librarysystems (cleveland public library and atlanta public library) and of the1979 white house conference on library and information services. shehas a demonstrated track record of providing the leadership and management expertise needed to bring about institutional innovation and changein short periods of time. she serves on the board of trustees of the councilon library and information resources and the board of directors of dataresearch associates inc., and has served on numerous national and international advisory committees. she has also directed research and management consulting projects and has published widely, most recently inyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.438youth, pornography, and the internetthe areas of strategic management and the integration of print and electronic information. she received her m.p.a. from harvard universityõskennedy school of government in 1978.milo medin is senior vice president of engineering and chief technology officer of excite@home. mr. medin oversees the development ofexcite@homeõs highspeed backbone. @homeõs performanceengineeredscalable network removes internet òtraffic jamsó and enables true endtoend management. in addition, the network employs replication and caching technologies that dramatically improve network efficiency. prior tojoining excite@home, medin served as project manager at nasa amesresearch center. during his tenure, he directed the nasa national research and education network project that, in combination with partnersat the lawrence livermore national laboratory, deployed a highspeednational atm infrastructure connecting major supercomputing and dataarchiving centers. he also supervised the primary west coast internetinterconnect network. in addition, he pioneered the global nasa scienceinternet project, providing network infrastructure for science at more than200 sites in 16 countries and 5 continents, including antarctica, and initially helped establish the tcp/ip protocol as an industry standard. before working at nasa, medin held various positions at science applications inc., programming supercomputers for defense program activitiesat the lawrence livermore national laboratory and los alamos national laboratory, under contract to the defense nuclear agency. medinhas a b.s. in computer science from the university of california, berkeley.john b. rabun was a founder and has been the vice president andchief operating officer of the national center for missing and exploitedchildren since april 1984. he administers the national clearinghouse, anonprofit organization in alexandria, virginia, with five branchesthroughout the united states, a staff of 154, and an annual budget of $38.5million, twothirds of which comes from congress via the department ofjustice. mr. rabun received a b.a. from mercer university in 1967, anm.s.w. from the university of louisville in 1971, and membership in theacademy of certified social workers in 1973. from 1973 to 1984, he wasa sworn juvenile officer, founded and managed the louisvillejeffersonco. kentucky exploited and missing child unit as the first police/socialwork special investigations team on child sexual exploitation. immediately before that, he was the executive director for the kentucky affiliateof the american civil liberties union. mr. rabun has provided consultation and technical assistance as a member of the international expertnetwork on selfregulation of internet content for child protection forthe bertelsmann foundation, gutersloh, germany, and incore (internetyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.439appendix econtent rating for europe), munich, germany, over the last 2 years. mr.rabun has authored numerous publications and frequently makes guestappearances on national tv and radio specials and news programs.robin raskin is a technology consultant with ziff davis media specializing in consumer technologies. she is regarded as one of the leadingauthorities on todayõs family and how they cope (or not) with technology.the former editor in chief and founder of familypc magazine, raskin hasbeen writing, lecturing, and consulting in the consumer technology arenafor the past 20 years. prior to launching familypc, raskin was the editorof pc magazine. her work as a freelance writer appeared in such magazines as pc world, pc week, infoworld, working mother, working woman,child, and newsday. raskin has authored six books about parenting in thedigital age and is a frequent guest on many of the morning news shows.raskin writes a syndicated column for usatoday.com and for thegannett news services, which appears in more than 150 newspapersaround the country. she is also the onair host for a òconnected familyótv broadcast that is distributed nationally, reaching 4 million to 6 millionviewers monthly. raskin resides in new york city and hudson valleywith her husband, three children, and a pile of everchanging computerequipment.robert j. schloss is research senior software engineer at ibmõs thomas j. watson research center. he holds an a.b. from yale university inmathematics and computer science. his work on digital endorsement,annotation, and reputation data as strategies for onthefly informationquality assessment, on personalization strategies for web content, and onmodular data interchange vocabularies began in the early 1990s. mr.schloss was a major contributor to the world wide web consortiumõspics (platform for internet content selection) recommendation (nowimplemented in major browsers, proxies, and web servers), including theability to filter using metadata provided by thirdparty rating/labelingagencies instead of, or in conjunction with, the metadata provided by thecontent owner. (pics was one technology considered by the courts inruling that the communications decency act section of the telecommunications reform bill was unnecessary.) mr. schloss cochaired the w3cõsfollowon effort on metadata interchange frameworks, the resource description framework data model and syntax (rdf), which became arecommendation in 1999. his work includes content sharing strategiesacross broadband, web, and wireless systems. his work (with others) onxml schema language is a base for the data description languageadopted for the mpeg7 standard for description of multimedia content.he has been on the program committee of the www conferences, teachesyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.440youth, pornography, and the internettutorials on metadata strategies at webnet and xml conferences, and isan ieee senior member and a member of computer professionals forsocial responsibility and acm. schloss resides in westchester county,new york, with his wife and teenage son.janet ward schofield is a professor of psychology and a senior scientist at the learning research and development center at the university ofpittsburgh. she is a social psychologist whose research during the last 25years has explored the impact of social and technological change in educational settings. this work has led to the publication of over 50 papersand three books, the most recent of which is bringing the internet to school:lessons from an urban district (josseybass, new york, 2002). professorschofield received a b.a. from harvard university, where she was electedto phi beta kappa, in 1968. she received her m.a. and ph.d. degrees insocial psychology from harvard university as well. she currently servesas a member of the board on international comparative studies in education of the national research council. she recently also served as amember of the governing body of the american psychological association, the council of representatives.geoffrey r. stone is university of chicago provost and harry kalven,jr. distinguished service professor of law. professor stone received hisundergraduate degree in 1968 from the wharton school of finance andcommerce of the university of pennsylvania. he then attended the university of chicago law school, where he served as editorinchief of thelaw review, was awarded his degree cum laude, and was elected tomembership in the order of the coif. following graduation in 1971, mr.stone served as law clerk to judge j. skelly wright of the u.s. court ofappeals for the district of columbia circuit. he spent the next year aslaw clerk to justice william j. brennan, jr. of the supreme court of theunited states. mr. stone was admitted to the new york bar in 1972 andhas been a member of the faculty since 1973. from 1987 to 1993, mr. stoneserved as dean of the law school. mr. stone has served on the boardof governors of the chicago council of lawyers, on the board of directorsof the american civil liberties union, illinois division, as a fellow ofthe american academy of arts and sciences, an exofficio member of theamerican law institute, a member of the executive committee of theassociation of american law schools, a member of the board of advisersof the national association of public interest lawñthe public servicechallenge, a member of the advisory board of the legal aid society, anda member of the advisory board of the chicago volunteer legal servicesfoundation. mr. stone has taught courses in constitutional law, civilprocedure, evidence, criminal procedure, contracts, and regulation of theyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.441appendix ecompetitive process. mr. stone has written a casebook with mr. sunsteinin the area of constitutional law. he has also written numerous articlesconcerning such matters as the freedom of speech and press, freedom ofreligion, the constitutionality of police use of secret agents and informants, the privilege against selfincrimination, the supreme court, andthe fbi. mr. stone is the editor, with david strauss and dennis hutchinson, of the supreme court review.winifred b. wechsler has been operating internet businesses targeted to children and families since 1995. most recently, she was executive vice president and general manager of internet and broadband services for lightspan inc., an educational software and internet servicescompany. prior to that, she was with the walt disney company for 14years, where she held various management positions. in 1995, she wasone of the founders of disney online and was responsible for the launchand growth of disney.com, which is currently the most visited destination for children and families on the web. she was also senior vice president of buena vista internet group (now walt disney internet group),where she set strategic direction, both internationally and domestically,for all of disneyõs internet properties. throughout, she has been concerned with the ways that commercial enterprises can create responsiblemethods for advertising and marketing to children on the web. prior toworking in the internet industry, she was a senior executive with thedisney channel for 10 years. she holds an m.b.a. from the whartonschool of the university of pennsylvania and a b.a. from wellesley college.e.2project staffherbert s. lin is senior scientist and senior staff officer at the computer science and telecommunications board, national research councilof the national academies, where he has been the study director formajor projects on public policy and information technology. these studies include a 1996 study on national cryptography policy (cryptographyõsrole in securing the information society), a 1991 study on the future ofcomputer science (computing the future), a 1999 study of defense department systems for command, control, communications, computing, andintelligence (realizing the potential of c4i: fundamental challenges), and a2000 study on workforce issues in hightechnology (building a workforcefor the information economy). prior to his nrc service, he was a professional staff member and staff scientist for the house armed services committee (1986 to 1990), where his portfolio included defense policy andarms control issues. he also has significant expertise in math and scienceyouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.442youth, pornography, and the interneteducation. he received his ph.d. in physics from mit in 1979.avocationally, he is a longtime folk and swing dancer, and a poor magician. apart from his cstb work, a list of publications in cognitive science, science education, biophysics, and arms control and defense policyis available on request.gail pritchard was a program officer at the computer science andtelecommunications board, where she contributed research and administrative skills to help produce such reports as cryptographyõs role in securing the information society, being fluent with information technology, andbuilding a workforce for the information economy. within the center foreducation, ms. pritchard has contributed to the reports developing a digital national library for science, mathematics, and engineering education andtransforming undergraduate education in science, mathematics, and engineering education. she also served as study director of two committeescharged with reviewing drafts of the most recent k12 mathematics andtechnology standards, and is currently a program officer with the committee on undergraduate science education and the committee on science education k12. prior to joining the nrc, ms. pritchard was aprogram specialist in the offices of the secretary and the university andscience education programs at the u.s. department of energy. ms.pritchard received a b.a. in liberal arts from st. johnõs college and anm.ed. from the university of virginia.joah g. iannotta is a ph.d. candidate at the university of minnesotaand a research assistant for the board on children, youth, and families ofthe institute of medicine and the national research council of the national academies. since joining the board, ms. iannotta has been involved in the development of a wide range of projects on topics includingadolescent risk and vulnerability, childrenõs development and computertechnology, and the social and economic benefits and losses of familyleave. she edited a report entitled nontechnical strategies to reducechildrenõs exposure to inappropriate material on the internet and is a coeditor of adolescent risk and vulnerability: approaches to setting priorities toreduce their burden, published by the national academy press. prior toher position on the board, ms. iannotta was a research fellow at the university of minnesotaõs tucker center for research on girls and women insport. in addition to conducting analyses of the social and cultural impactof sport on issues of equity, ms. iannotta coordinated the tucker centerõsòimage is everythingó program. this educational workshop introducedhigh school female athletes to a critique of the mediaõs often highly sexualized portrayal of female athletes and encouraged them to develop theirown action plans for addressing issues of equity in sports within theiryouth, pornography, and the internetcopyright national academy of sciences. all rights reserved.443appendix eschools and communities. ms. iannotta is finishing her doctoral work atthe university of minnesota in the department of kinesiology with aconcentration in sport sociology and a minor in feminist studies. herdissertation work uses qualitative research methodologies to uncoverstrategies collegiate coaches use to address issues of equity (e.g., racism,sexism, and homophobia) within womenõs athletics in order to createtolerant and cohesive climates on their teams in which all athletes canthrive and develop.janice m. sabuda joined the computer science and telecommunications board in august 2001. currently, she is focusing on two projects,privacy in the information age, and tools and strategies for protectingkids from pornography on the internet and their applicability to otherinappropriate content. she began her term with work on the globalnetworks and local values project (2001). prior to joining the nationalacademies, ms. sabuda worked as a customer service representative atecontributor.com, an online fundraising company, and as a producttrainer and research associate at a fairfax, virginia, prospect researchfirm. she received her b.s. in business administration from the stateuniversity of new york college at fredonia.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.445indexaacceptable use policies, 222223, 235240,282283, 378access control, 69, 110, 194. see also filters/filteringadult online entertainment industryfuture products and services, 6870, 8182mousetrapping, 74, 75, 7879, 80, 109,212213possible safe harbors for, 107, 208209,342practices, 71 n.1, 7479, 382383regulation, 7981size and structure, 7273, 79subscriber retention, 7273, 7677targeting children, 7879, 80, 8283, 104105verification services, 6365, 7879, 102,206209, 340349, 360advertising of sexually explicit material,38, 7476, 96, 109110, 129, 133 n.39,136. see also spamage verification, 6265, 7879, 102, 206209,216, 328329, 339349, 360altavista, 273ambiguities in language as related tofiltering, 5455, 138140, 278, 420421,422american family online, 167168american civil liberties union, 104american family association, 168american social health association, 126,173anonymizers, 66, 67, 164aol parental controls, 162, 272, 275, 276,284authentication technologies, 59, 6264, 346automated policy preference negotiation,346347bbagofwords model for matchingdocuments, 422bandwidth, 37, 73beaver college, 278 n.15best practices for homes, schools, libraries,374386biometric signatures, 62, 6465black lists of inappropriate material, 52, 54blocking inappropriate material, 5161, 100,103104, 162, 194, 273274, 279280bulletin boards, 130, 272, 284cchain letters, 109110youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.446indexchat rooms and online conversations, 40,44, 45, 119, 130, 138, 141142, 162 n.4,170171, 173, 272, 276, 284child pornography, 66, 71 n.1, 9394, 9799,113, 129, 132, 137, 205, 213, 214215,424childrenage/developmental considerations, 116118, 155, 157158, 193, 206, 229230,290291, 342, 358359first amendment protections, 8992internet usage, 117, 119120, 128, 136142, 163media usage, 115120monitoring online activities, 103 n.42,268269, 272, 284, 286, 291, 304317parental knowledge of, 118, 120, 164165rights, 9293sexual information from media, 123127specialneeds populations, 159targeting of advertising for sexuallyexplicit material, 7879, 80, 8283,104105technological sophistication, 49, 162163, 165venues for internet access, 3638, 127128, 280, 360content providers for adult web sites, 78,381382coping strategies for exposure toinappropriate material orexperiences, 135, 195counters for web traffic, 77credit cards as age verification technology,63, 64, 73, 74, 78, 110, 138, 271, 341,342, 343, 345, 349crimes against children research center,132, 134, 135, 138, 140142cultivation theory, 148cybersex, 129, 170171cybertipline, 214215ddepartment of education, 103deterrence as a form of protection, 195dialaporn services, 110digital convergence, 45disclosure of personal information, 104n.46domain names, 3839, 5455, 74, 109, 139140.kids toplevel, 328329, 335339.xxx toplevel, 327334, 354eemail, 40, 42, 74, 108109, 119, 138, 142,272, 274, 276, 281, 286erate program, 103education strategies. see social andeducation strategiesencryption, 65, 67executable dialer programs, 108exposure to inappropriate material andexperiencesage/developmental considerations, 135,157158deliberate, 137, 138, 139, 141142, 160,195196, 268269, 275, 341, 342dimensions of, 159160, 357358empirical research, 149157extent of, 132135first amendment protections, 8992gender and, 117118, 141, 158159impacts of sexually explicit materials,133, 135, 143180, 362364inadvertent, 133, 135, 137, 138141, 160,268269, 275, 341on internet, 133, 136142parental challenges, 161165passive vs. interactive, 25, 139, 328329routes to, 40, 128142, 281theoretical perspectives, 117, 143149types of materials and experiences, 128129, 136137, 159warnings, 194, 300, 340, 341ffbi sex offender database, 114federal communications commission, 103,110112federal trade commission, 80, 106, 107110file sharing (peertopeer), 40, 42, 129, 131,132, 271, 274, 281. see also peertopeer networks.filters/filteringclientside, 271, 302youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.447indexcombinations of methods, 52, 58, 300contentlimited isps, 37, 52, 131, 268269, 270272, 277, 280281, 282, 284,286288, 293, 301, 302defeating/circumventing, 280281, 282defined, 271by domain names and ip addresses, 5455, 279effectiveness, 51, 53, 56, 58, 6061, 275286, 303304flexibility and usability, 289292functions, 267275future prospects, 298301identifying sites to be blocked, 5159,286289information retrieval technologies and,54, 5556, 58, 274, 298299, 420labeling of content, 5658, 59, 209, 268269, 282, 288289, 295298liability issues, 100at libraries, 271, 273, 274275, 280, 282284, 379placement of, 56, 59, 103104,270273at schools, 273, 274, 280, 282284, 285search engine, 56, 59, 271, 273selective degradation of service,299300serverside, 59, 272273, 281 n.21,302statutes, 103104technologies, 5159, 267304tradeoffs in, 5859, 268269, 292298,301304vchip, 57, 61, 110, 111, 196, 197financial transaction mechanisms, 63, 6869, 73, 74, 78first amendment issues, 8496, 98, 100,102103, 293, 359flying crocodile inc. (fci), 72 n.3, 77flynt digital media, 81ggetnetwise, 228, 267, 270gnutella, 281good samaritan provisions ofcommunications decency act, 100google, 273grunwald associates, 120hhaptic (touchsensitive) content, 8182harassment, 66, 129, 137, 142, 162 n.4, 164,166hate speech and overt racism, 2223, 53holmes, oliver wendell, 85iinappropriate material and experienceschild as decision maker, 193, 194195,218221community standards, 192193differing views of, 175, 192identification of, 5159, 183188types of, 2225, 83, 137, 290indexing services (for adult web sites), 77information processing theory, 148information retrieval (and filtering)image analysis, 5556, 58, 274, 298299,423424location verification, 6668, 426428search engines, 39, 41, 56, 74, 108, 342,422, 424426technologies, 4951, 418424textual analysis, 54, 55, 58, 274, 418422user interfaces, 428429inhope hotlines, 215instant help, 268269, 322326instant messaging, 40, 4445, 130131, 140,141142, 272, 274 n.6, 276, 286institute of museum and library sciences,103intel corporation, 61intellectual property protection tools, 328329, 349353internetaccess devices, 3536, 381anonymity, 33, 35, 66applications running on, 4546benefits, 32, 294child predation, 24, 113, 141142, 166and communication, 33comparison to other media types, 3235,124125connectivity, 3132, 3638deliberate exposure, 137, 138, 139, 141142, 195196, 268269, 275, 341, 342digital information characteristics, 3132economic issues, 35, 47, 72, 73, 361362youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.448indexfunctionality, 3947inadvertent exposure, 133, 135, 137, 138141, 268269, 275, 341interactivity, 33, 34international nature of, 33, 4748, 112location verification, 6668, 426428nature, 3235passive vs. interactive exposure, 25peertopeer networks, 40, 42, 69, 131,132, 271, 274 n.6publishing, 35, 67, 102safety education, 222223, 230, 233, 240,242245, 301, 375, 379searching, 39, 41, 4951telephony, 45internet content rating association, 296,297internet explorer, 59, 282internet service providersbest practices, 380381contentlimited, 37, 59, 131, 268269,270, 277, 280281, 284, 301, 302liability, 100terms of service and selfregulation, 3638, 127, 215216ip addresses, 3839, 5455, 67, 139, 279ipbased virtual hosting, 5455, 279kkaiser family foundation, 118119, 120,135, 197, 284kids passport, 347 n.13llabeling of content, 5658, 187, 209, 268269, 282, 297law enforcement, training, and education,107109, 112113, 201205legal and regulatory issues. see firstamendment issues; regulatoryefforts; statutes and common lawlibraries and librarians, 37, 9495, 100, 103104, 127128, 140, 191192, 193, 271,273, 274275, 280, 346, 378380live entertainment group, 81location verification, 6668, 426428login names, 272lycos, 273mmedia access control (mac) address, 61meeting internet contacts facetoface. seechild predationmonitoringand development of selfdiscipline, 308309, 313and punishment, 308, 311and trust, 312defined, 305privacy implications, 312314techniques of, 305306mousetrapping, 74, 75, 7879, 80, 108, 212213movies, 5758, 81, 121, 133 n.39nnational center for missing and exploitedchildren, 114, 214215national crime information center, 114national law enforcementtelecommunications center, 114national telecommunications andinformation administration, 119120netscape, 59, 282network interface card, 61network solutions inc., 109nielsen/net ratings, 78oobscene for minorsdefinition, 107, 113114, 137, 294, 359labeling, 209prohibitions against spam andmousetrapping, 209213obscenitycivil liability for, 205community standards, 66, 97, 98, 99,107, 136 n.42, 137, 184, 203204, 206207, 359federal statutes, 9697first amendment issues, 8789, 9697,98, 137prosecution for, 112113, 201205, 216217record keeping on performers, 99, 213offensive material, 137overblocking, 5859, 275, 277, 278279, 284youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.449indexppagejacking, 108parental consent, 105107, 347 n.13parental controls, 162, 272, 275, 276, 284,345parental responsibility and involvement,110, 123, 161165, 184, 222223, 225233, 271, 374378, 379paypercall industry, 67, 110peer assistance, 222223, 233234peertopeer networks, 40, 42, 69, 131, 132,271, 274 n.6, 281. see also filesharingperipheral devices, 4647personal digital assistants, 81personal information, 104107, 129pew internet and american life project, 24,120plain brown wrappers, 208209, 216, 342planned parenthood, 126platform for internet content selection(pics), 57, 282playboy, 81, 125pornography and sexually explicitmaterial. see also child pornographyand community standards, 97, 98, 99,102103definitions, 2022, 8687, 97, 101102, 110,112, 133 n.39, 167168, 176, 357358differing views and perspectives, 2528,94, 166172, 176, 289and encryption, 65hardcore vs. softcore, 2526, 424identifying, 5159impacts of viewing, 143160, 166172obscene for minors, 107, 137, 209213,359and obscenity, 66, 8689, 9697, 98, 99,107, 136 n.42, 137, 201205, 359as proxy in political debate, 172180,282283, 373374range, 2122, 71, 128129, 136, 160sources, 136142privacy, 66, 93, 104107, 268269, 344protection. see also regulatory efforts;social and education strategies;statutes and common law;technologybased toolsapproaches, 196200, 218221, 364368dimensions, 188190first amendment and, 8992identification of inappropriate material,5159, 183188institutional mission and, 191192politics of inappropriate material, 2528,192194, 202203techniques, 194196, 206209time line of actions, 190191tradeoffs in, 368374proxy servers, 281 n.21psychoanalytic theory, 117, 146public policy, 202203, 373374, 383386public records, 6364, 342, 344, 345public terminals, 36, 37, 127128publius, 67rregulatory efforts, 80, 107112research needs, 386387restore americaõs moral pride, 168ssafe harbors for adult industry, 107, 208209, 342school environments, 37, 9596, 100, 103104, 124, 140, 162, 191192, 273, 274,280, 285, 378380screen names, 272search engines, 39, 41, 56, 74, 108, 138, 141,208, 271, 342, 422, 424426. see alsoaltavista, google, yahooselfregulation of internet content, 3738,81, 215216sex education, 122, 123127, 162, 172173sexual assaults, 141sexual orientation issues, 173174sexual solicitation, 132135, 137, 141142sexuality in culture and media, 2224, 120122, 123124, 126127, 157, 161smart cards, 62, 346social and education strategies, 110, 195.see also parental involvementacceptable use policies, 222223, 235240, 282283, 378afterthefact, 240242collateral issues, 249250compelling and safe content, 222223,250254youth, pornography, and the internetcopyright national academy of sciences. all rights reserved.450indexcontextual issues, 357358, 222225definition, 221223findings and observations about, 256257information and media literacy, 222223, 245249internet safety education, 222223, 242245, 301, 375, 379peer assistance, 222223, 233234public service announcements andmedia campaigns, 222223, 254256responsible decision making, 193, 194195, 218221tradeoffs in, 370371social learning theory, 117, 147, 151, 153software vendors, 381spam, 74, 109110, 130, 140, 209212, 268269, 317322stalking, 66statutes and common lawchild online protection act, 101103,206, 207, 209210, 345child pornography, 9799, 112, 205childrenõs internet protection act, 103104, 112, 284childrenõs online privacy protectionact, 104107child pornography prevention act of1996, 9798, 204, 205child protection and obscenityenforcement act of 1988, 99child protection restoration andpenalties enhancement act of 1990,99communications decency act, 9091,99100, 101, 102, 206federal trade commission act, 107sex crimes against childrenprevention act, 97 n.27state, 107telecommunications act of 1996, 99,103 n.41streaming media, video, and audio, 45, 62n.24, 81supervised learning, 421surgeon generalõs report on sexual health,126surveillance. see monitoringswimming pool analogy for protectingchildren, 224ttechnologybased tools, 258260. see alsofilters/filtering, monitoring, andchapters 12 and 13 more generallycontextual issues, 261265for nonend users, 327353questions to be asked about, 265266tradeoffs in, 371373for users, 267326text classification or categorization, 55,420421thirdparty billing processors, 77thornburgh, dick (chair), personalstatement, xvxviiitime limits for internet use, 195uunderblocking, 5859, 276277, 284unfair and deceptive trade practices, 81,107110university of pennsylvania center for thestudy of youth policy, 141usenet newsgroups, 40, 4243, 100, 129,130, 131132, 271, 276user interfaces, 428429user profiles, 130vvchip, 57, 61, 110, 111, 196, 197video games, 36, 5758, 119videoconferencing, 45, 274 n.6violent speech and imagery, 23, 121122,149153virtual reality, 69, 98voice interaction, 69wwhite lists for appropriate content, 52, 272,273world wide web, 39, 40, 4546, 7273, 101103consortium on metadata, 57yyahoo, 273youth internet safety survey, 134