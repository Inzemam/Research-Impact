detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/11258signposts in cyberspace: the domain name system and internetnavigation416 pages | 6 x 9 | paperbackisbn 9780309096409 | doi 10.17226/11258committee on internet navigation and the domain name system: technicalalternatives and policy implications; computer science and telecommunicationsboard; division on engineering and physical sciences; national research councilsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.committee on internet navigation and the domain name system:technical alternatives and policy implicationscomputer science and telecommunications boarddivision on engineering and physical sciencesthe national academies presswashington, d.c.wwwwwwwwwwwwwww.nap.edu.nap.edu.nap.edu.nap.edu.nap.edusignposts in cyberspacethe domain name system andinternet navigationsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the national academies press 500 fifth street, n.w. washington, d.c. 20001notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn fromthe councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsiblefor the report were chosen for their special competences and with regard for appropriate balance.support for this project was provided by the u.s. department of commerce andthe national science foundation under grant no. ani9909852 and by the national research council. any opinions, findings, conclusions, or recommendations expressed in this publication are those of the authors and do not necessarilyreflect the views of the national science foundation or the commerce department.international standard book number 0309096405 (book)international standard book number 0309549795 (pdf)cover designed by jennifer m. bishop.copies of this report are available from the national academies press, 500 fifthstreet, n.w., lockbox 285, washington, d.c. 20055, (800) 6246242 or (202) 3343313 in the washington metropolitan area. internet, http://www.nap.educopyright 2005 by the national academy of sciences. all rights reserved.printed in the united states of americasignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific and engineering research, dedicated to the furtherance of science and technology and to their use for the generalwelfare. upon the authority of the charter granted to it by the congress in 1863,the academy has a mandate that requires it to advise the federal government onscientific and technical matters. dr. ralph j. cicerone is president of the nationalacademy of sciences.the national academy of engineering was established in 1964, under the charterof the national academy of sciences, as a parallel organization of outstandingengineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsorsengineering programs aimed at meeting national needs, encourages education andresearch, and recognizes the superior achievements of engineers. dr. wm. a.wulf is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy ofsciences to secure the services of eminent members of appropriate professions inthe examination of policy matters pertaining to the health of the public. the institute acts under the responsibility given to the national academy of sciences by itscongressional charter to be an adviser to the federal government and, upon itsown initiative, to identify issues of medical care, research, and education.dr. harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology withthe academyõs purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by theacademy, the council has become the principal operating agency of both the national academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientific and engineering communities. the council is administered jointly by both academies and the instituteof medicine. dr. ralph j. cicerone and dr. wm. a. wulf are chair and vice chair,respectively, of the national research council.www.nationalacademies.orgsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.committee on internet navigation andthe domain name system: technicalalternatives and policy implicationsroger levien, strategy & innovation consulting, chairs. robert austein, internet systems consortiumstanley m. besen, charles river associateschristine l. borgman, university of california, los angelestimothy casey, university of nevada, renohugh dubberly, dubberly design officepatrik f•ltstr–m, cisco systemsperkristian halvorsen, hewlettpackard labsmarylee jenkins, arent fox, pllcjohn c. klensin, independent consultantmilton l. mueller, syracuse universitysharon l. nelson, washington state attorney generalõs officecraig partridge, bbn technologieswilliam j. raduchel, ruckus networkhal r. varian, university of california, berkeleystaffalan s. inouye, study director (through december 2004)charles n. brownstein, director (from january 2004)margaret marsh huynh, senior program assistantkristen batch, research associatevsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.computer science and telecommunications boardjeannette m. wing, carnegie mellon university, chaireric benhamou, benhamou global ventures, llcdavid d. clark, massachusetts institute of technology, chairemerituswilliam dally, stanford universitymark e. dean, ibm almaden research centerdeborah estrin, university of california, los angelesjoan feigenbaum, yale universityhector garciamolina, stanford universitykevin kahn, intel corporationjames kajiya, microsoft corporationmichael katz, university of california, berkeleyrandy h. katz, university of california, berkeleywendy a. kellogg, ibm t.j. watson research centersara kiesler, carnegie mellon universitybutler w. lampson, microsoft corporation, member emeritusteresa h. meng, stanford universitytom m. mitchell, carnegie mellon universitydaniel pike, gci cable and entertainmenteric schmidt, google, inc.fred b. schneider, cornell universitywilliam stead, vanderbilt universityandrew j. viterbi, viterbi group, llccharles n. brownstein, directorkristen batch, research associatejennifer m. bishop, program associatejanet briscoe, manager, program operationsjon eisenberg, senior program officerrenee hawkins, financial associatemargaret marsh huynh, senior program assistantherbert s. lin, senior scientistlynette i. millett, senior program officerjanice sabuda, senior program assistantgloria westbrook, senior program assistantbrandye williams, staff assistantfor more information on cstb, see its web site at <http://www.cstb.org>, writeto cstb, national research council, 500 fifth street, n.w., washington, dc 20001,call (202) 3342605, or email the cstb at cstb@nas.edu.visignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.prefaceviithe domain name system (dns), which was developed in the early1980s, provides a way of associating alphanumeric names, whichare easier for humans to use, with the numerical addresses thatdesignate every location on the internet. the system of dns servers distributed across the internet invisibly converts the namesñserving as signposts in cyberspaceñinto the numerical addresses required by networkrouters to reach the signposted locations.the mnemonic quality of domain names became a practical necessitywhen the rapid increase in the use of email and the world wide webcaused the number of internet users and uses to increase tremendously.web sites often became known to their visitors by their distinctive domain namesñfor example, pepsi.com or whitehouse.gov. carefully chosen domain names often enabled a searcher to navigate to a site simply byguessing (e.g., www.un.org). consequently, those signposts gained economic, social, cultural, and political value and they became the objects ofpride, competition, and dispute. it was fitting, therefore, that the dnsalso provided the nameñthe dotcom erañfor the period of the 1990swhen ògold rush feveró drove frenzied efforts to stake out and exploitvirtually every potentially valuable site on the web. inevitably, such efforts led to intense conflicts, especially disputes involving trademarks,which provided the impetus for the 1998 congressional mandate to initiate this study (see box p.1). however, the passage of time, the rapidevolution of the internet and the dns, the additional and differing interests of the funding agencies, and the logic of the committeeõs charter haveresulted in a report whose scope differs in some respects from the originalsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.viiiprefacecongressional request, but is as a result more responsive to the currentinterests of the reportõs sponsors and audience.current context and study taskalthough the initial feverish period of internet exploitation appearsto have passed, in its third decade the dns faces new challenges arisingfrom continued growth in the size and scope of the internet and from itsbox p.1excerpt from public law 105305sec. 6. study of effects on trademark rights ofadding generic toplevel domains(b) matters to be assessed in study.ñthe study shall assess and, as appropriate, make recommendations for policy, practice, or legislative changesrelating toñ(1) the shortterm and longterm effects on the protection of trademark rightsand consumer interests of increasing or decreasing the number of generictoplevel domains;(2) trademark rights clearance processes for domain names, includingñ(a) whether domain name databases should be readily searchable througha common interface to facilitate the clearing of trademark rights and proposed domain names across a range of generic toplevel domains;(b) the identification of what information from domain name databasesshould be accessible for the clearing of trademark rights; and(c) whether generic toplevel domain registrants should be required to provide certain information;(3) domain name trademark rights dispute resolution mechanisms, including how toñ(a) reduce trademark rights conflicts associated with the addition of anynew generic toplevel domains; and(b) reduce trademark rights conflicts through new technical approaches tointernet addressing;(4) choice of law or jurisdiction for resolution of trademark rights disputesrelating to domain names, including which jurisdictions should be available for trademark rights owners to file suit to protect such trademark rights;(5) trademark rights infringement liability for registrars, registries, or technical management bodies;(6) shortterm and longterm technical and policy options for internet addressing schemes and the impact of such options on current trademarkrights issues; and(7) public comments on the interim report and on any reports that areissued by intergovernmental bodies.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.prefaceixincreasing integration into almost every aspect of human activity almosteverywhere on the globe. the internet needs more signposts, in more languages, to satisfy more uses and users. and the dns has to be carefullydeveloped and managed to ensure that it can meet those needs while continuing to provide reliable, efficient, and secure service.furthermore, even if the dns successfully adapts and grows, users ofthe internet will confront new challenges in reaching the resources thatthey are seeking on the internet, whether they are educational, social, political, cultural, commercial, or recreational. the challenges will arise notfrom the absence of resources or of signposts for them, but from theirpresence in such volume and variety that navigating through the maze tofind the right ones may become too arduous or too complex for most users. reciprocally, those who put resources on the internet will want themto be easily found by their prospective users in the cluttered bazaar ofcompeting or confusing resources and signposts on the internet. thus, thelarger issue of the third decade of the dns is that of navigation throughthe internetñthe need for its users to find their way quickly and confidently to the resources they desire and for its resources to be easily andreliably found by the users they seek.this study builds on cstbõs prior work related to the internet, most notably on the internetõs coming of age and the digital dilemma.1 one of theimportant lessons from this prior work is that contentious issues in information technology policy (e.g., the domain name trademark issues as describedin public law 105305) are often much more complex and require analysisin a much larger context than a popular characterization of òus versusthemó would suggest. in the interval between the enactment of publiclaw 105305 and the initiation of this study, cstb was able to conductpreliminary background work to develop a statement of task (see box p.2)that addresses the congressional mandate but also ensures that the necessary larger context is included explicitly. moreover, the larger context wasnecessary to respond appropriately to the interests of the national science foundation, which joined with the u.s. department of commerce ascosponsors of this study.committee composition and processthe cstb convened a crossdisciplinary study committee comprisingcomputer scientists and engineers, information science/retrieval and1see computer science and telecommunications board (cstb), national research council (nrc), the internetõs coming of age, national academy press, washington, d.c., 2001;and cstb, nrc, the digital dilemma: intellectual property in the information age, nationalacademy press, washington, d.c., 2000.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.xprefacebox p.2statement of taskthis project will examine the future of internet navigation and the domain name system (dns) in light of the evolution and interaction of internetusage, information technology, the economy, and society. the original purpose of the dns was to provide identifiers for network objects that are moreeasily remembered and enduring than the numerical addresses and port numbers used by the network infrastructure. however, domain names are nowoften used for purposes for which they were not originally intended, such assearching, corporate identification, and marketing. and certain domainnames, especially those in the .com toplevel domain, have acquired substantial economic value, leading to conflict and competition over their ownership and a perceived scarcity of desirable names.the continuing increase in the number of internet users and sites, thedeepening integration of the internet into the economy and social processes, the growth in embedded computing devices, and the possible introduction of permanent personal and object identifiersñamong other factorsñpose challenges to the continued viability and usefulness of the dns,as currently constituted. this project will describe and evaluate emergingtechnologies and identify how they might affect the ability of users to findwhat they are seeking on the internet and the role of the dns. some of thetopics to be considered include extension of the dns through the additionof generic toplevel domains and multilingual domain names; introductionof new name assignment and indexing schemes (including alternate rootservers); adoption of new directory structures or services for locating information resources, services, or sites of interest; and deployment of improveduser interfaces.navigation experts, lawyers, public policy analysts, a graphic designer anddesign planner, economists, and business strategists. many but not all ofthe members were directly engaged with the dns or with internet navigation (see appendix a for the biographies of committee members). thecommittee members brought different and complementary perspectivesto the examination of the dns and internet navigation. in some cases,they also held views that strongly conflicted with those of other committee members. the conclusions reached and the recommendations developed by the committee are thus the products of a multidimensional examination of the issues and a careful negotiation of agreements amongmembers holding contrasting opinions. the sharp discussions and emailthreads fueled by the committeeõs diversity of experience and opinionhelped it to avoid overly simple conclusions or recommendations reflecting just one perspective. information gathering, discussion, argument,signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.prefacexixinegotiation, and compromise were the stages the committee passedthrough in addressing most of the topics.the committee did its work through its own deliberations and by soliciting input from a number of other experts (see appendix b for a list ofthose who briefed the committee) and from the international publicthrough an open invitation published on the web.2 it first met in april2001 and six times subsequently in plenary session. additional information was derived from reviewing the published literature, monitoring selected listservs and web sites, and obtaining informal input at variousconferences and other meetings. committee members and national rethe technologies that support finding information on the internet aredeployed within a complex and contentious national and internationalpolicy context. the òrightó to use a particular domain name, like any name,can often be disputed. these disputes include conflicts among commercialclaimants as well as conflicts between noncommercial and commercialclaimants. effective solutions must consider the potentially competing interests of domain name registrants and trademark holders; the different interests of stakeholders including businesses, from small firms to multinational corporations; educational, arts, and research institutions;notforprofit charitable and service organizations; government entities atall levels from town to nation; nationstates and international organizations; and individuals (i.e., the general public); as well as public interestssuch as freedom of speech and personal privacy.the projectõs report will examine the degree to which the options offered by new technology or new uses of existing technology can mitigateconcerns regarding commercial and public interests (which will include adiscussion of trademarkrelated issues), facilitate or impede further evolution of the internet, and affect steps being taken to enhance competitionamong domain name registrars, the portability of internet names, and thestability of the internet. for each of the prospective technologies, the finalreport is expected to characterize the institutions, governance structures,policies, and procedures that should be put in place to complement it andwill specify the research (if any) required to design, develop, and implement the technology successfully. also identified will be the options foregone or created by particular technologies and the difficulties associatedwith each technological alternative.2see òthe future of internet navigation and the domain name system: an invitation toindividuals worldwide to provide input to a study conducted by the u.s. national academy of sciences,ó available at <http://www7.nationalacademies.org/cstb/projectdnsinput.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.xiiprefacesearch council (nrc) staff made several site visits, which included participation in meetings of the internet corporation for assigned namesand numbers (icann), the internet engineering task force, and theworld summit on the information society. significant input was also derived from committee members during the course of their professionalactivities outside of the committeeõs work. during the editorial phase ofthe study, facts were checked for accuracy with either published sourcesor subject experts.at the outset of the study, some conflict and controversy were expected, given the intense debate about the dns and its associated institutions such as the icann and the rapidly growing interest in the use ofcommercially sponsored navigation services. we were not disappointed.however, the committee was able to achieve consensus in a number ofareas as described in the main text. moreover, the committee believes thatthis report represents a contribution to future discussions related to thedns by serving as a reference document containing much of the basic,relevant technical and institutional background material and many of thepolicy alternatives in as clear and objective a manner as possible.a number of committee members withdrew from the committee forvarious reasons. in a few instances, new employment or professional opportunities raised conflictofinterest concerns. several committee members were simply unable to participate in the committeeõs work because ofincreased professional or personal obligations.although the report refers to several companies, products, and services by name, such reference does not constitute an endorsement by thecommittee or the national academies.acknowledgmentsthe committee appreciates the support and guidance of its sponsors.the committeeõs initial contacts at the u.s. department of commerce werej. beckwith burr, amy page, and karen rose, and in the later portion ofthe study, cathy handley and robin layton. aubrey bush and georgestrawn were the committeeõs initial contacts at the national science foundation, with darleen fisher assuming this role during the final months ofthe project. the committee also appreciates the financial support of cstbõscore sponsors: the air force office of scientific research, cisco systems,the defense advanced research projects agency, department of energy,intel corporation, microsoft research, national aeronautics and spaceadministration, national institute of standards and technology, nationallibrary of medicine, national science foundation, office of naval research, and the vadesz family fund. additional financial support wasprovided by the national research council.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.prefacexiiiin addition, we would like to thank those individuals who provided valuable inputs into the committeeõs deliberations. those who briefed the committee at one of our plenary meetings are listed in appendix b. others whoprovided us with important inputs include ronald andruff (rna partners,inc.), carl bildt (ag global solutions and icann atlarge study committee), mason cole (snapnames), shari garmise (cleveland state university),carolyn t. hoover (dotcoop), cary karp (musedoma), kalpana shankar(university of california, los angeles), paul twomey (internet corporationfor assigned names and numbers), anastasia zhadina (robin, blecker &daley), and matthew zook (university of kentucky). we would also like toacknowledge those organizations that hosted committee meetings: aol timewarner, inc.; university of california, berkeley; university of california, losangeles; harvard university; and verisign, inc. thanks go, too, to jonathano. chan, consultant, for his help with a translation.the committee appreciates the thoughtful comments received from thereviewers of this report and the efforts of the nrcõs report review coordinator and monitor. the review draft stimulated a large volume of comments, each of which was taken into account during revision of the draft.many of the comments provided additional reference material and observations to bolster or counter the committeeõs earlier thinking, thus helpingthe committee to sharpen and improve the report. however, the reviewersare not responsible for the reportõs conclusions or recommendations, withwhich some of them may disagree, or for its structure and specific content.those are solely the committeeõs responsibility.finally, the committee would like to acknowledge the staff of the nrcfor their work. special appreciation is accorded to alan s. inouye, who asthe study director had overall staff responsibility for the conduct of thestudy and for the development and completion of this report. margaretmarsh huynh handled the administrative aspects of the project, such asorganizing meeting logistics. marjory s. blumenthal, as director of cstbthrough june 2003, and her successor, charles n. brownstein, providedthe committee with valuable administrative and technical guidance.cynthia patterson and kristen batch supplied research and writing support at various stages of the report drafting and revising process. thecommittee would also like to thank jennifer m. bishop, janet briscoe, andrenee hawkins of the cstb staff; susan maurizi of the nrcõs editorialstaff; liz panos of the staff of the division on engineering and physicalsciences; and janice mehler of the report review committee for theirsupport of the committeeõs work.roger levien, chaircommittee on internet navigation and thedomain name systemsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.acknowledgment of reviewersthis report has been reviewed in draft form by individuals chosen fortheir diverse perspectives and technical expertise, in accordance with procedures approved by the national research councilõs report reviewcommittee. the purpose of this independent review is to provide candidand critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meetsinstitutional standards for objectivity, evidence, and responsiveness to thestudy charge. the review comments and draft manuscript remain confidential to protect the integrity of the deliberative process. we wish tothank the following individuals for their review of this report:aristotle balogh, verisign, inc.timothy bray, textualityj. beckwith burr, wilmer, cutler and pickeringkc claffy, cooperative association for internet data analysisdavid d. clark, massachusetts institute of technologysteve crocker, shinkuro, inc.bruce croft, university of massachusetts, amherstleslie daigle, verisign, inc.graeme dinwoodie, chicagokent college of lawjoseph farrell, university of california, berkeleymichael froomkin, university of miamihector garciamolina, stanford universitymarti hearst, university of california, berkeleyxivsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.acknowledgment of reviewersxvrandy h. katz, university of california, berkeleybutler w. lampson, microsoft corporationf. thomson leighton, akamai technologies and the massachusettsinstitute of technologymichael lesk, rutgers universitylarsjohan liman, autonomicaclifford lynch, coalition for networked informationm. stuart lynn, independent consultant*tom m. mitchell, carnegie mellon universityivan png, national university of singaporefred b. schneider, cornell universitypaul vixie, paix.net, inc.tan tin wee, national university of singaporealthough the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the final draft of the reportbefore its release. the review of this report was overseen by alexander h.flax, independent consultant, and joseph bannister, university of southern california. appointed by the national research council, they wereresponsible for making certain that an independent examination of thisreport was carried out in accordance with institutional procedures andthat all review comments were carefully considered. responsibility forthe final content of this report rests entirely with the authoring committeeand the institution.*formerly, internet corporation for assigned names and numbers.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.xviicontentsexecutive summary11navigating the internet: concepts and context191.1the internet, 201.2the domain name system, 241.3internet navigation, 281.4the dynamics of change, 291.4.1increasing scale, 301.4.2technological progress, 301.4.3increasing economic value, 311.4.4increasing social value, 311.4.5internationalization, 321.5internet naming and navigation, 331.6objectives of this report, 351.7roadmap for this report, 372the domain name system: emergenceand evolution392.1origin of the domain name system, 392.2designing the domain name system, 422.2.1simple, mnemonic, and deeply hierarchical names, 452.2.2experimental features, 462.3deploying the domain name system, 47signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.xviiicontents2.3.1caching, 472.3.2lookup timeouts, 482.3.3convergence in electronic mail systems, 492.3.4the whois database, 522.3.5the dns as a production system, 532.4continuing growth and evolution of the internet asa technical infrastructure, 542.5economic and social value of domain names, 572.5.1demand for domain names and emergenceof a market, 572.5.2the rise of conflicts over domain names, 61trademark conflicts, 63beyond trademark conflicts, 67beyond secondlevel domain names, 702.5.3whois, 722.6globalization, 732.7administration of domain names, 743the domain name system: current state793.1operation of the domain name system, 803.1.1a new, remote query, 823.1.2local query, 843.1.3repeat query, 853.2architecture of the domain name system, 873.2.1name space, 873.2.2hierarchical structure, 873.2.3programs: bind and others, 883.2.4standards, 91dns zone data file, 92dns message format, 923.2.5functions and institutions, 93maintenance of the dns standardsñthe internet engineering task force, 93providing root name server softwareñinternet software consortium, inc., andother software providers, 953.2.6assessment, 953.3implementationñthe domain name system root zone, 963.3.1characteristics of the root zone, 97defining characteristics, 97critical characteristics, 97unique characteristics, 98signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.contentsxix3.3.2technical system of the root zone, 100the root zone file, 100the root name servers, 1003.3.3institutional framework of the root zone, 105approving the root zone fileñu.s. department of commerce and icann, 105maintaining the root zone fileñverisign, 108selecting the root name server operatorsñselfselection, 108operating the root name serversñthe root name server operators, 1093.3.4assessment, 1103.4implementationñthe toplevel domains, 1133.4.1characteristics of the tlds, 113cctlds, 113gtlds, 114recharacterizing tlds, 1163.4.2technical system of the tlds, 1203.4.3institutional framework of the tlds, 121selecting new tlds, 122selecting the organizations responsible for the tlds, 125selecting the tld registry operators, 129operating the tld registries, 1333.4.4assessment, 1333.5implementationñthe second and thirdlevel domains, 1343.5.1technical system of the second andthirdlevel domains, 1343.5.2institutional framework of the second andthirdlevel domains, 135selecting the organizations to register domains, 135registering domain names, 137resolving domain name conflicts, 1403.5.3assessment, 1503.6summary, 1504the domain name system: technology prospects1524.1improving the security of the domain name system, 1534.1.1mechanics of dnssec, 1544.1.2deployment of dnssec, 1564.2linking the telephone and internet naming system, 1584.2.1mechanics and operations of enum, 1604.2.2technical and public policy issues, 162signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.xxcontents4.2.3alternate models, 1634.3internationalizing domain names, 1644.3.1internationalizing domain names in applications, 165clientside support, 1674.3.2registries and registrars, 1694.3.3chinese, japanese, and korean scripts, 1704.3.4conclusions, 1734.4responding to domain name errors, 1734.4.1traffic aggregation, 1744.4.2site finder by verisign, 175technical issues, 176institutional issues, 1824.4.3conclusions, 1845the domain name system: institutional issues1875.1governance of the domain name system, 1895.1.1relationship to governance of the internet, 1905.1.2where should stewardship of the dns reside?, 1905.1.3alternatives, 192alternative a: existing intergovernmentalorganizationñinternational telecommunication union, 192alternative b: international treaty organization, 195alternative c: private organization withinternational participation, 1955.2management of the domain name system, 1985.2.1scope of icannõs authority, 1995.2.2composition of the icann board, 2005.2.3nature of icannõs management processes, 2025.2.4alternatives, 204alternative a: markle foundation proposal (2002), 204alternative b: nongovernmental organization andacademic icann study proposal (2001), 206alternative c: icann as registry for the root (2004), 208alternative d: new.net proposalñicann as a private trade association (2002), 211alternative e: center for democracy and technologyproposalñnarrowed scope with broadparticipation (2004), 212alternative f: reformed icannñnarrowed scope with broad participation (2003), 214summary of the alternatives, 2175.2.5conclusions and recommendation, 217signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.contentsxxi5.3oversight and operation of root name servers, 2195.3.1current situation: diverse autonomy, 219description, 219evaluation, 2215.3.2alternatives, 222alternative a: funding and regulation, 222alternative b: competitive market, 224alternative c: distributed root zone file, 226alternative d: doc relaxes mou requirement, 228summary of the alternatives, 2285.3.3conclusions and recommendations, 2295.4regulation of generic toplevel domains, 2305.4.1should new gtlds be added? if so, how manynew gtlds, and how fast?, 231technical and operational performance issues, 232user needs and economic issues, 234recommendations, 2385.4.2if new gtlds are to be added, what typesshould they be, and how should they andtheir operators be selected?, 239which types of gtlds should be added?, 240how should the operators of gtlds be selected?, 242what selection process should be used?, 2445.4.3recommendations, 2525.5oversight of countrycode toplevel domains, 2545.5.1current situation, 2555.5.2alternatives, 257alternative a: òthickó icann, 259alternative b: òthinó icann, 260alternative c: international oversight, 261alternative d: selfgoverning root managementorganization, 262comparison of the four alternatives, 2625.5.3conclusions, 2635.6resolution of conflicts over domain names, 2635.6.1assessment of the udrp, 2645.6.2proposed improvements to the udrp, 2685.6.3disputes concerning internationalized domain names, 2715.7provision and protection of whois data, 2735.7.1assessment of whois data issues, 273data accuracy, 274data privacy, 275signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.xxiicontents5.7.2whois and internationalized domain names, 2785.7.3conclusion and recommendation, 2796internet navigation: emergence and evolution2816.1the nature of internet navigation, 2826.1.1vast and varied resources for multiple purposes, 2826.1.2twosided process, 2836.1.3complexity and diversity of uses, users, and providers, 2856.1.4lack of human intermediaries, 2876.1.5democratization of information access and provision, 2886.1.6lack of context or lack of skill, 2906.1.7lack of persistence, 2916.1.8scale, 2946.1.9the sum of the differences, 2946.2internet navigation aids and servicesñhistory, 2956.2.1aiding navigation via the internet, 2966.2.2aiding navigation through the world wide web, 2986.3addendumñsearching the web versus searching libraries, 3087internet navigation: current state3137.1navigation aids and services, 3147.1.1direct access via a uniform resourcelocator or domain name, 3147.1.2direct access via hyperlinks, 3157.1.3direct access via bookmarks, 3167.1.4direct access via keywords, 3177.1.5direct access via metadata, 3197.1.6navigation via directory systems, 3247.1.7navigation via search engines, 326algorithmic search, 327monetized search, 330search engine marketing and optimization, 331the deep, dark, or invisible web, 332metasearch engines, 3357.1.8use of navigation aids, 3357.2internet navigationñinstitutional framework, 3387.2.1the commercial providers of navigation services, 3387.2.2the business of internet navigation, 3407.2.3the navigation services market, 345consolidation, 345innovation, 347signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.contentsxxiii8internet navigation: selected prospectsand issues3498.1technological prospects, 3498.1.1navigation service algorithms and operations, 3508.1.2navigation interfaces, 3518.1.3navigation to audio and visual materials, 3538.1.4making greater use of contextual information, 3558.1.5improving persistence, 3588.1.6understanding user behavior, 3608.2institutional issues, 3618.2.1regulation, 3618.2.2privacy, 3648.2.3trademarks and copyright, 365trademark, 366copyright, 3689the domain name system and internetnavigation371appendixesabiographies of committee members and staff377bspeakers at meetings and participants at site visits389signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.1executive summarymost people who use the internet rely on the domain name system (dns) and navigation aids and services to find the resources they seek or to attract users to the resources they provide. yet, although they perform well, both the dns and internet navigation services face challenges arising from technological change and frominstitutions with a wide variety of commercial, cultural, social, and political agendas. individually, or together, those pressures could force operational changes that would significantly reduce access to internetlinkedresources by segments of the user community, reducing the internetõsvalue as a global resource.this document reports the conclusions of an assessment of the currentstate and the future prospects of the dns and its interactions with internetnavigation, including its uses as a means of navigation itself and as an infrastructure for navigation by other means. the assessment is the result ofthe deliberations of a committee that encompasses a wide range of disciplines, experience, and viewpoints. the report is addressed to the technologists, policy makers, and others whose decisions will affect the future of thedns and internet navigation aids and services. the specific conclusionsand recommendations of the committee on internet navigation and thedomain name system appear throughout this summary in boldface type.domain name systemdomain names are commonly used to designate services and deviceson the internet, as a more memorable and more permanent alternative tosignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.2signposts in cyberspacethe numerical addresses employed by its routing computers. they are thevalued, often valuable, and often userfriendly names on the signpoststhat designate many things connected to the internet. consequently,which names are available, who controls their allocation, what is chargedfor their use, how their uses are managed, and the answers to many related questions are important to virtually everyone who uses the internet,whether as information seeker or provider.overall, the dnsõs technical system and institutional frameworkhave performed reliably and effectively during the two decades of thednsõs existence. the dns has coped with the extremely rapid expansionof internet usage driven by the wide deployment of the world wide webin the 1990s and the widespread adoption of email. the hierarchical, distributed structure of the dns technical system, operated collaborativelyby a group of mostly autonomous organizations, has proven to be scalable, reliable, secure, and efficient.the dns technical system can continue to meet the needs of anexpanding internet. early in the committeeõs assessment it became apparent that it would not be fruitful to consider alternate naming systems. as noted, the dns operates quite well for its intended purposeand has demonstrated its ability to scale with the growth of the internetand to operate robustly in an open environment. moreover, significantly increased functionality can be achieved though applicationsñsuch as navigation systemsñbuilt on the dns, or offered independently, rather than through changing the dns directly. hence, the needdid not seem to be to replace the dns, but rather to maintain and incrementally improve it. furthermore, given the rapidly increasing installed base and the corresponding heavy investments in the technicalsystem and the institutional framework, the financial cost and operational disruption of replacing the dns would be extremely high, ifeven possible at all.however, the continued successful operation of the dns is not assured; many forces, driven by a variety of factors, are challenging thednsõs future. required and desirable technologies to increase securityand enable the use of nonroman scripts for domain names are not beingincorporated into the technical system as quickly as many would like.there are persistent and substantial controversies concerning the structure and policies of the dnsõs institutional framework. moreover, therehave been many efforts to use the dns, because it exists and is so widelydeployed, for many purposes for which it may not be appropriate. in addition, national legislation and court decisions are addressing internet anddomain name issues with potentially conflicting consequences for the operation of the dns.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.executive summary3security challengeslike all public networked systems, the system of public domainname servers is threatened by a variety of purposeful attacks, both malicious and mischievous, by individuals or groups that aim to disable ordivert their operations. the operators of the dns are responding to thesethreats, but not all the desirable steps to ensure security have yet beenimplemented.denialofservice attacksdenialofservice attacks attempt to overwhelm key name servers andtheir links to the internet with so much traffic that they are incapable ofresponding to legitimate queries. the root name servers have the capacityand capability to respond to many times the normal number of queriesthey receive, and have alternate connections to the network if some areblocked. their ability to respond to attacks has been improved by someoperatorsõ recent addition of multiple distributed copies (called òanycastóservers) of the base name servers, increasing both capacity and connectivity. in anticipation of future denialofservice attacks and normalgrowth in demand, and to improve service globally, anycast server deployment should be expanded.physical vulnerabilitynotwithstanding the deployment of anycast servers and installationof backup servers at remote locations, the concentration of root nameserver facilities and personnel in the washington, d.c., area and, to alesser extent, in the los angeles area is a potential vulnerability. the needfor further diversification of the location of root name servers and personnel should be carefully analyzed in the light of possible dangers,both natural and human in origin.message alterationin response to the threat of alteration of messages being transmittedamong name servers, the technical community has developed dns security extensions (dnssec), which uses digital signatures to verify that thecontent of a message to or from a name server arrives unaltered and thatits origin is as stated. dnssec only gives assurance that what was sentwas not changed during transmission; it cannot and is not intended toassert that the message is factually correct. for example, dnssec has nosignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.4signposts in cyberspacecapability to guarantee that it is communicating the correct address for agiven domain name. the security of the dns would be significantlyimproved if dnssec were widely deployed among name servers forthe root zone and toplevel domains in particular, and throughout thedns in general.performance monitoringalthough some steps have been taken, more could be done to continuously monitor the performance and traffic flows of the dns so as toenable rapid detection of and response to attacks or outages.governance challengesthe dns works through the voluntary cooperation of its autonomous component entities. that cooperation, in turn, depends on theirtacit agreement on two principles that together enable the internet andthe dns to evolve and remain effective:¥universal open standards. the first principle is that the protocols andstandards defining operation of the internet and the dns will be openand established by the internet engineering task force (ietf), an international voluntary organization of technical specialists. this technical framework enables every device on the internet to connect to and communicatewith every other, and it has been critical to the success of the internet andthe dns. because changes in internet and dns protocols, standards, andpractices are matters of consequence beyond specific internet services, alterations to the functions of or modifications to established standards andpractices have traditionally been vetted by the ietf before being implemented.¥innovation at the edges. the second principle is that applicationsshould be offered by devices on the edges of the internet, rather than atthe internetõs internal nodes or on its links. in general, applications located at the edges have little effect on the stability of the internet, so thereis no need to regulate them. the dns is not, strictly speaking, internal tothe internet (the translation service is performed by computers at theedges), but functions as though it were. it can thus be thought of as a coreservice, which although not absolutely necessary, is extremely useful ingiving a relatively userfriendly face to internet resources, and for enabling access to those resources even when their internet addresseschange. moreover, it is a deeply embedded and ubiquitous service thatenables other services and functions, including most aids to internet navigation.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.executive summary5this tacit agreement governs the basic behavior of the many autonomous operators of the dns, but there is also a need for an authority tomake decisions about the allocation of limited resources central to dnsoperations. the most critical of these decisions are the determination ofwhich toplevel domains (tlds) shall appear in the root zone file of thedns, which organizations shall be designated as responsible for theiroperation, and the terms under which those organizations shall operate.the principal organizations that constitute this authority are, currently,the u.s. department of commerce (doc) and the internet corporation forassigned names and numbers (icann), although national bodies haveconsiderable influence over the operations of the associated countrycodetoplevel domains (cctlds). both the doc and icann face significantchallenges to their authority and legitimacy in management of the dns.stewardship of the dnsas the internet has become an increasingly important component ofthe international infrastructure, there has been growing pressure to introduce some form of international political control over the dns. this pressure comes both from existing international organizations seeking authority over the internet or the dns, and from individual countries that wouldlike to end the stewardship role of the united states.governance of the dns is part, but not all, of governing theinternet. efforts to leverage it to influence broader internet policy are,therefore, likely to be ineffective and could also be detrimental to thedns. many of the governance issues that concern governmentsñcontrolof spam and uses of the internet for illegal purposes; resolving the disparities between developed and developing countries in internet usage;protection of privacy, freedom of expression, and intellectual propertyother than domain names; and the facilitation and regulation of ecommerceñhave little or nothing to do with the dns per se. the dns wouldnot be an effective vehicle for addressing such issues. attempts to changethe dns or extend its management and administrative processes to do socould interfere with reaching agreements on the already contentious issues concerning the dns itself.governance of the dns is not an appropriate venue for the playingout of national political interests. one valued and essential quality of thedns institutional framework has been its relative freedom from directpressures arising from conflicts among competing national interests andpolicy agendas (apart from sovereigntyassociated issues such as cctlddelegations and redelegations). international disputes arising in other contexts have largely been kept away from the dnsñas they should be.for that reason: the committee does not support efforts to put thesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.6signposts in cyberspacedns directly under the control of governments or intergovernmentalagencies. in practical terms, the u.s. government, which must agree, hasnot supported turning dns stewardship over to other governments or aninternational organization, although that could change. although the 2005u.n.sponsored world summit on the information society (wsis) mayproduce proposals for a nongovernmental agentñan internationally negotiated convention or multistakeholder organizationñwith oversightor other influence over the dns, no proposal that can be evaluated foreither practicality or feasibility has yet (in june 2005) been made.one way to respond to concerns about the u.s. governmentõs role assteward of the dns is for it to transfer its stewardship role to a nongovernmental bodyñspecifically, icann. in the september 2003 revision of its agreement with icann, the doc stated its intent to transfer itsstewardship to icann if within 3 years icann is able to fulfill a mutually agreed set of tasks.if icann does not fulfill the agreed tasks, and a proposal for creationof a nongovernmental organization having internet governance responsibilities results from the wsis process before the transfer date, the doccould consider transferring the stewardship role to the proposed organization. that would entail comparing a notyetexisting organization toone with 8 years of experience and evolution.life without the stewardship of the u.s. government will openicann to political and commercial pressures. a freestanding icannwould lack the oversight and, importantly, the protection provided bythe u.s. governmentõs stewardship. if icann becomes steward of thedns, legitimacy based on the òconsent of the governedó would be theprincipal basis for its continued authority and its ability to resist inappropriate pressure from governments and other powerful interests. final responsibility for satisfying the needs of its constituencies in an equitable,open, and efficient manner would lie with its board.before completing the transfer of its stewardship to icann (or anyother organization), the department of commerce should seek ways toprotect that organization from undue commercial or governmental pressures and to provide some form of oversight of performance.legitimacy of icannicann is a work in progress; its longterm success is not assured. after a troubled start, it has introduced several innovations to the institutionalframework of the dns, including competition among registrars and an arbitral process for resolving disputes over domain names, the uniform domain name dispute resolution policy. in 2003 it had to undertake a majorreform of its own organization, stimulated by dissatisfaction with its operation under its initial structure. it is working on the revision of key decisionsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.executive summary7processes in response to complaints about their lack of transparency andfairness. furthermore, icann has been unable to conclude formal agreements with many of the organizations critical to its responsibilities, notablythe root name server operators and the vast majority of the cctld registries. nevertheless, through its responsibility for recommending changes inthe root zone file, which defines which tlds are in the dns and wheretheir operators are located on the internet, icann has been able to exerciseauthority over the coherence and stability of the dns.since its beginning, icann has been the subject of controversy andcontention flowing from the many diverse constituencies that have beenattracted to it and their correspondingly diverse views. the criticsõ concerns have been with icannõs scope, its organizational structure, and itsmanagement processes. the concern about scope has been principally theextent to which icann has exceeded its technicaladministrative responsibilities, for example, to regulate tld registry operations; but others havebeen disappointed by its unwillingness to take on broader issues. the structural concerns have included perceptions of imbalance in the historical composition of icannõs board, of failings in the board selection processes, andof inadequate representation of certain constituency groups. the processconcerns have been the perceived lack of transparency, effectiveness, accountability, and recourse in icannõs electoral and decision processes.icann is more likely to achieve perceived legitimacy by narrowing its scope and by improving its processes rather than by seeking anideally representative composition of its board. no composition of itsboard is likely by itself to confer the perception of legitimacy on icannamong all its possible constituency groups. a narrowing of scope andimprovement of processes are elements of the path that icann claims tobe following in carrying out its 2003 reform. however successful its reform, icann faces the challenge of reaching an effective modus operandi with three critical sets of participants in the dnsõs institutionalframework: the root name server operators, the generic tld registries,and the cctld registries.root name server operatorsno greater oversight of the root name server operators will be necessary so long as they continue to operate effectively and reliably and toimprove the dnsõs security, stability, and capability. the effective dailyoperation of the root, and therefore the dns, lies in the hands of the operatorsof the 13 critical root name servers. they have provided reliable and efficientservice as the internet has undergone rapid growth in the numbers of itsusers and providers. although the doc has assigned icann responsibilityfor the stability and security of the root name server system, icannõs authority has not been sufficient for it to manage or regulate the root namesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.8signposts in cyberspaceserver operators directly, nor is it clear that doing so is desirable or necessary.the real challenge to icann is to identify how it can best ensure the stabilityand security of the root name server system, given the longstanding autonomy of the operators and the effectiveness of their operations.more formal coordination of the root name server operators is desirable in the longer term. icann is currently the most appropriateorganization to assume the coordination role. although direct management or oversight may be neither necessary nor feasible, with continuedgrowth in the internet and demands on the dns, a more formal process ofcoordination of the root name server operators with icannõs facilitationwill become desirable so as to ensure rapid response to persistent securityneeds and to other challenges.the present independent funding arrangements for the root nameservers are advantageous and should continue, because the multiplicityof sources contributes to the resilience, autonomy, and diversity of theroot name server system. the root name server operators do not receivedirect compensation for the services they perform. while running a rootserver may only add an incremental cost in the range of tens of thousandsof dollars for an organization already operating a secure internet site, fullyloaded costs have been estimated at up to $1 million or more dependingon numerous factors including the number of locations, bandwidth requirements, and staffing levels. the costs are covered by each organization as part of other operations. although a central source of funds tocompensate all the root name server operators for their services mightappear desirable, it is likely to be accompanied by an unacceptable regulatory or control role for the funding organization and would reduce therobustness of the current arrangement.icann should work with the root name server operators to establish a formal process for replacing operators that directly engages theremaining root name server operators. under the process, icannwould be responsible for the final decision on the basis of recommendations from the root name server operators. one or more of the currentroot name server operators may withdraw for organizational or performance reasons, and it would be reasonable to have in place an agreedprocess to deal with such eventualities.generic toplevel domain registriesa major challenge to icann since its founding has been decidingwhether, when, and how to add generic toplevel domains (gtlds) and,if any are added, how many. it has faced strong pressures both to addgtlds and to stop, or at least moderate, the pace of such additions. thecommittee addressed the issue of gtld addition broadly in terms of bothsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.executive summary9effects and constituencies affected, but for simplicity the multidimensionalarguments for and against new gtlds were clustered into two groups:technical and operational performance, and user needs and economic benefits.considering technical and operational performance alone, the addition of tens of gtlds per year for several years poses minimal risk tothe stability of the root. however, an abrupt increase (significantly beyond this rate) in the number of gtlds could have technical, operational,economic, and service consequences that could affect domain name registrants, registries, registrars, and internet users.from the standpoint of user needs and economic benefits, neitherthe arguments in favor of nor those against additional gtlds are conclusive. thus, the decision to add gtlds is one requiring judgment andcannot be determined by formal analysis alone.if new gtlds are added, they should be added on a regular schedule that establishes the maximum number of gtlds (on the order oftens per year) that could be added each time and the interval betweenadditions. addition of gtlds should be carried out cautiously and predictably, so that on the one hand, the stability and reliability of the systemcan be protected, and on the other hand, those considering acquiring agtld can do so with a realistic view of future prospects.a mechanism to suspend the addition of gtlds in the event thatsevere technical or operational problems arise should accompany aschedule of additions. it should explicitly specify who has the authority to suspend additions and under what conditions.a neutral, disinterested party should conduct an evaluation of newgtlds approximately 1 or 2 years after each set of new gtlds is operational to make recommendations for improving the process for selecting and adding gtlds.if new gtlds are to be created, the currently employed comparative hearing or expert evaluation processes should not be assumed to bethe only processes for selecting their operators. in its addition of gtldsin 2000, icann used a comparative hearing process to select 7 from the44 applicants. in its 2004 addition of sponsored gtlds, icann used anoncompetitive process that replaces subjective judgments by its staffand board with judgments by expert groups that are insulated from lobbying, but whose decisionmaking processes are not transparent. by doing so, it has reduced a few of the potential sources of dissatisfaction withthe resultant selections compared with the process used in 2000. however, the question remains as to whether it is necessary for icann toqualify new gtlds, as this process does, on such matters as sponsorshipby a community, business and financial plans, and addition of new valueto the name space.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.10signposts in cyberspacefor creation of new gtlds, icann should consider alternate processes that are less reliant on expert, staff, or board judgments. one suchapproach would be prequalification of applicants only on technical capability, basic financial viability, and adherence to registrant protection standards and icann policies. (icann should establish requirements tominimize the dangers of domain name registrants losing their serviceñand the value invested in their domainsñif a registry fails and shouldcarefully consider possible side effects.) if the number of qualified applicants turns out to be less than the number of available slots, all would bechosen; if not, a marketbased selection processñan auctionñcould beused to select among them. because of the wide range of intents and corresponding designs of such processes, they must be carefully planned,drawing on the breadth of previous experience in the design of auctions.countrycode toplevel domain registriesresolution of icannõs role vis⁄vis the cctlds is one of the critical challenges to establishing an icann that is viewed as a legitimateand appropriate steward for the dns. although the cctlds represent243 of the 258 tlds, icann had formal agreements with only a dozen ofthe cctld operators as of june 2005.the cctlds as a group now operate only partially under the oversight of any higher authority, icann or government. a number ofcctlds are overseen by their national governments; some have established nongovernmental bodies to represent the local internet community and exercise varying degrees of oversight; some are completely autonomous nonprofit bodies that operate voluntarily to meet local internetcommunity interests; and some are commercial bodies with some contractual linkage to the national government.the only body that currently has an opportunity to exercise oversightover all the cctlds is icann. the principal way in which it exercisesthat authority is through recommendations to the doc about which organization should be delegated responsibility for a specific cctld. yetthis issue arises only when the present delegatee resigns or is challengedor a new cctld is established.the relationship between cctlds and icann has been difficult fromthe beginning of icann. first, a large number of the cctlds felt no needto contribute to icannõs budget, since they did not think that they received any corresponding benefits. second, many cctlds resentedicannõs major role in deciding on delegations and redelegationsñessentially a policy role that they felt would be better performed locally.they also believed that their position as one constituency within icannõsinitial domain names supporting organization, whose other constituensignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.executive summary11cies primarily addressed gtld issues, did not adequately reflect theirimportance.under its 2003 reorganization, icann attempted to respond to theirconcerns by replacing the domain names supporting organization withtwo organizations, the generic names supporting organization (gnso)and the countrycode names supporting organization (ccnso). icannintends thereby to draw the cctlds more actively into its operations andbuild a stronger basis for their support. furthermore, in april 2005icannõs governmental advisory committee issued a revision of itsòprinciples for the delegation and administration of country code toplevel domainsó to address many of the concerns expressed about them.if the creation of the ccnso does not result in increased participation by the cctlds in icann policy making, then icann may finditself subject to increasing pressures to constrain its role to that of gtldmanagement and root zone file record keeping and to turn cctld oversight over to some other organization. the success of the ccnso willdepend on its ability to attract an increasing number of members, bothfrom the large cctlds that are needed for financial and other support oficann and the smaller cctlds that can benefit from the support thaticann could offer them. even more critical is the refinement of the principles and processes for delegation and redelegation of cctld registriesand their acceptance by most of the cctlds.commercial challengesperhaps the most subtle, but still significant, challenge that the dnsfaces is that arising from the imperative faced by commercial operators ofparts of the dnsñthey must strive to increase their revenues and profitsin the face of competition. on the internet, increasing revenues generallymeans increasing traffic to oneõs service, sometimes by diverting it fromanother operatorõs service. this imperative raises the temptation to seektraffic and revenue by breaking or bending the fabric of tacit agreementsthat underlies the success of the internet and the dns.icann should strengthen its contracts with tld operators (especially the largest ones) to ensure that it has the authority to review proposed changes in their services that could have a detrimental effect onthe dns or on other services that depend on the dns. it should establishan open, transparent, and speedy process of review for such changes thatsolicits contributions from the technical community, other dns operators, other affected internet operations, and end users. a recent case inpoint is the unanticipated and unannounced introduction by verisign, acommercial registry, of a service, called site finder, that altered the conventional response to erroneous queries to the .com and .net tlds by returnsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.12signposts in cyberspaceing pointers to its own search page, rather than sending back an error message. after being called on by icann to suspend the service, verisign didso under protest and is currently seeking relief in the courts.tlds and other dns operators that do not have agreements withicann should voluntarily agree to adhere to published technical standards and to consult the technical community and conduct public review processes before introducing new services that could have a detrimental effect on the dns or on other services that depend on the dns.dispute resolution challengesarbitral domain name dispute resolution processes, rather than national courts, should continue to be encouraged as the initial and primary vehicle for resolving most disputes associated with the rights todomain names. the uniform domain name dispute resolution policywas implemented by icann in december 1999 and has been adopted byall registrars in nine of the generic toplevel domains, as well as voluntarily by managers of several cctlds. in addition, managers of other cctldshave adopted their own policies based on modified versions of the udrp.the udrp has generally satisfied the need for an effective and costefficient means of resolving disputes concerning domain names; however,it has weaknesses that should be addressed. the udrp has both positiveand negative aspects, which differ, however, depending on whether they arebeing considered from the perspective of the complainants or of the respondents. although many observers believe that the udrp has enabled speedyand fair resolution of domain disputes, others believe that the current systemis biased toward the interests of trademark holders. notwithstanding its perceived disadvantages, by early 2005 more than 9000 decisions concerningover 15,000 domain names had been rendered under the udrp.the feasibility and desirability of five specific udrp improvements should be further considered by icann:¥improving consistent use of arbitral precedents to enable similarissues to be addressed in a more consistent manner that also supportscasebycase knowledge building;¥establishing an internal appeals process that would review thesmall number of decisions that are clearly faulty or that cover a situationor issue for which competing bodies of precedent exist;¥using threemember panels. some analyses of udrp proceedingsindicated a significant difference in outcomes depending on whether theywere heard by onemember or threemember panels: threemember panels found for the complainant in a smaller percentage of the cases;signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.executive summary13¥improving panelist knowledge about the technology underlyingthe dns, the uses of domain names (beyond web sites), and the application of the policies and rules applicable to domain name disputes; and¥improving the nature and structure of incentives in the process.under the current funding structure, the revenue for panelists dependson the volume of cases, creating incentives either for haste or for marketing strategies and tactics to attract cases by defining lucrative niches.internationalization challengescontinuing and increased attention to internationalized domainnames (idns) is necessary. efforts to coordinate work across different countries, regions, and language groups should be undertaken toprevent the balkanization of the internet. of particular interest inmany countries is access to the internet and the dns using homecountry languages and scripts. unfortunately, the design of the dns, aswell as the general nature of multiscript environments, presents formidable technical and linguistic challenges for the accommodation of languages that use nonroman characters, which require compromises fortheir solution.some experts have argued for a major overhaul of the internetõs infrastructure to incorporate idns. however, pressure to act quickly reducedsupport for solutions that would require extensive changes in architectures or standards; the result was an effort led by the ietf that culminated in the internationalizing domain names in applications (idna)mechanism.1 the central goal of the idna scheme is to enable enduserviewing of idns without altering the dns protocols themselves, using aclientside set of procedures, implemented at the edge of the dns.however, the idna mechanism solved only part of the internationalization problem. remaining to be addressed are the questions of potentialconsumer confusion; conflict avoidance or resolution for similarappearing names; differences in interpretations for different languages; restrictions on registrations on a perdomain basis; implications for the udrpand the whois database (of information about domain name registrants);security issues raised by idns; and the implications of (and alternativesto) multilingual toplevel domains.1idna is described in patrik f−ltstrım, paul hoffman, and adam m. costello, òinternationalizing domain names in applications (idna),ó rfc 3490, march 2003, available at<http://www.rfceditor.org/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.14signposts in cyberspaceinternet navigationin contrast to the unique role played by the dns, navigation throughthe internet is not supported by a unique integrated technical system.among the many ways to navigate the internet, only two involve dedicated technical systemsñsearch engines and directories. moreover, theinstitutional framework of those technical systems is an open market, withmany, generally commercial, competitors offering navigation services,and specialized noncommercial services focused on nonprofit resourceproviders and seekers.finding and accessing a desired resource via the internet poses challenges that are substantially different from the challenges in navigating to resources in nondigital, nonnetworked environments.a wide range of navigation aids and services now permit large segments of the internet, particularly the world wide web, to be traversedrapidly and efficiently in ways previously unimaginable. they offerusers across the globe convenient access to much human knowledgeand experience and open an international audience to purveyors of content and services, no matter where they may be located.use of navigation aids and servicessurveys indicate a high level of satisfaction with navigation aidsand services at present.an analysis of navigation behavior, based on survey data from march2003,2 indicates that internet users tend to use preferred sites and servicesconsistently, visiting them repeatedly, using their bookmarks or remembered uniform resource locators (urls). search engines produced only13 percent of site referrals, navigation through entry of a known orguessed url or use of a bookmark produced 66 percent of referrals, andflow along hyperlinks produced 21 percent.according to a recent survey,3 residents of the united states con2the data were collected on march 6, 2003, by websidestoryõs statmarket from about 12million visitors to 125,000 sites using its proprietary analytical platform and were comparedwith figures from the previous year. reported in brian morrissey òsearch guiding moreweb activity,ó cyberatlas, march 13, 2003, available at <http://cyberatlas.internet.com/bigpicture/trafficpatterns/article/0,1323,59312109221,00.html>.3see deborah fallows, lee rainie, and graham mudd. òthe popularity and importance ofsearch engines,ó data memo, pew internet & american life project, august 2004, availableat <http://www.pewinternet.org/pdfs/pipdatamemosearchengines.pdf>. the resultscame both from a telephone survey of 1399 internet users and from tracking of internet useby comscore media metrix.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.executive summary15ducted 3.9 billion searches in june 2004, an average of 33 searches peruser. search engines have been used by 84 percent of u.s. residents whouse the internetñmore than 107 million people; on an average day, about38 million of the 64 million u.s. residents who are online use a searchengine. using search engines is second only to using email as the mostpopular internet activity, except when major news stories are breaking. avast majority of searchers say that they find the information they wantmost of the time, and more than twothirds consider search engines a fairand unbiased source of information. but only a third of searchers say theycould not live without search engines; about half say that, although theylike using search engines, they could go back to other ways of findinginformation.as the material accessible through the internet continues its rapidincrease in volume and variety and as its societal importance grows,internet navigation aids and services are likely to be challenged to deliver more precise responses, in more convenient forms, to more diversequestions, from more users with widely varying skills. efforts to improve the basic algorithms and operations of internet navigation serviceswill continue because of competitive pressures, evolving user requirements, and technological advances. among the specific areas where improvements are needed are query interfaces and results displays for desktop, portable, and collaborative devices; navigation of audio and visualmaterials; management of the navigation process; use of contextual information (while protecting privacy); and understanding the wide range ofnavigation behaviors of the highly diverse users who now seek resourceson the internet.as the internet has become the sole or most accessible location ofmany valuable resources, the importance has grown of ensuring that theywill persist indefinitely at the same url (or in an archive on the samesite) or, alternatively, that they will be preserved at another site wherethey can be readily found. ensuring persistence is primarily the responsibility of resource providers, while third partiesñnational libraries or private organizations such as the internet archiveñare undertaking somepreservation efforts.although commercial services can be expected to support substantialresearch and development on these topics, academic research and development activities have provided the innovative basic technologies formany successful navigation aids and services. public support of such academic research and development efforts should be continued.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.16signposts in cyberspacecommercial navigation servicesthe internet navigation services industry has financed the development and evolution of services that meet many of the needs of a widerange of searchers at little or no cost to them, especially when they areseeking commercial material. at the same time, it has provided advertisers with an efficient, costeffective means to gain access to potentialcustomers at the time that they are most interested in the advertiserõsproduct or service. the primary source of income for commercial internetnavigation services is selling advertising linked to search queries. consequently, as for many broadcast media, it is the content and service providers that are subsidizing usersõ access to navigation services so that theycan present advertisements to them at the time of their expressed interestin a topic.the major search services currently identify the results whose presentation in response to specified search terms is paid for by advertisers (socalled sponsored links or sponsored search listings) and set them off fromthe direct results of more neutral search algorithms. as long as the distinction is clear and users are aware of it, sponsored search listings shouldpresent few problems while providing the great benefit of free search services to the user.the potential for abuse exists, however. it would be possible, forexample, for a search service to accept payment for assured placementin the òtop 10ó of what would appear to be a neutral listing. shouldabuses grow, search services could find themselves under increasedpublic pressure for government scrutiny or facing more disputes andcriticism concerning such activities from other commercial entities.none of the navigation services have been accused of accepting paymentfor highly ranked inclusion of particular responses to queries, but somehave accepted payment to ensure inclusion, but not ranking, in the otherwise neutral listing. furthermore, the distinct placement and typographyof the sponsored listing could be weakened to the point that a casual userwould not be aware of its difference from the neutral algorithmic searchresults. thus far, competition among services, thirdparty evaluations, andthe perceived value to the user of search transparency have served as important forces constraining misbehavior of these kinds. although competition and the desire to be seen as useful by searchers are incentives for fair and open behavior, appropriate regulatoryagencies of the u.s. federal government and of other governmentsshould pay careful and continuing attention to the result ranking anddisplay practices of internet navigation services and their advertisers toensure that information can flow freely and that those critical practicesare fully disclosed. the behavior of commercial navigation services cansignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.executive summary17have a substantial influence on the kind, quality, and appropriateness ofthe information that internet users receive. although there is no evidencethat abuse has yet occurred, the potential for abuse is inherent in the navigation servicesõ ability to affect usersõ access to information for commercial or other reasons.in the future, competition among general navigation services ismore likely to take the form of rivalry among a small number of established large players rather than competition with a large number ofsmall newcomers. over the past 4 years, there has been considerable consolidation in the general search services market, which reflects the increasing importance of economies of scaleñthe considerable hardware andsoftware costs of developing and operating a search engine are independent of the number of users, whereas revenues from advertising are directly dependent on them. the result is that the barriers to entry are high,and only a company with substantial financial resources and technicalskills, such as microsoft or ibm, is in a position to introduce its own competitive general navigation service, as microsoft began to do in 2004.innovation, competition, and regulationthe importance of the internet as the infrastructure linking a growing worldwide audience with an expanding array of resources meansthat improving internet navigation will remain a profitable goal forcommercial developers and a challenging and socially valuable objective for academic researchers. consolidation of navigation services makesit difficult for innovative services to start small and build volume overtime unless they have a very large amount of patient investment capital.but, so long as no single service becomes dominant, each of the majorcompetitors will face continuing pressure to improve its offerings eitherthrough internal innovation or through the acquisition of innovative smallcompanies, paths they are currently actively pursuing.since competition in the market for internet navigation servicespromotes innovation, supports consumer choice, and prevents unduecontrol over the location of and access to the diverse resources availablevia the internet, public policies should support the competitive marketplace that has emerged and avoid actions that damage it.potential rulings in some jurisdictions could substantially reducethe abilty of search engines to sell keywords using the current automated methods. as with the domain name system, the most contentiousintellectual property issues affecting navigation services concern trademarks, specifically the sale of trademarked terms to advertisers as keywords whose use will bring up their advertisements. since there is noarbitral process, such as the udrp, by which such disputes could be resignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.18signposts in cyberspacesolved outside the courts and with worldwide effect, it seems likely thatconflicting court decisions in different jurisdictions, worldwide, will establish the potentially conflicting rules by which navigation services willhave to abide.the dns and internet navigationthe preservation of a stable, reliable, and effective domain namesystem will remain crucial both to effective internet navigation and tothe operation of the internet and most of the applications that it supports.despite the differences in the way in which they developed, the relationship between the dns technical system and internet navigation aidsand services is strong and fundamentalñthe dns has served as the stablecore on which the incremental evolution of the different navigation aidsand services has depended. the development of navigation services islikely to continue to relieve some of the commercial pressures on the dnsas users become increasingly comfortable with using them as their primary means to navigate the internet, but both the domain name systemand internet navigation aids and services will be significant elements ofthe internet for the foreseeable future.the demonstrated success of the dns and navigation aids and services in meeting the basic needs of all internet users should not be jeopardized by efforts to constrain or direct their evolution outside the openarchitecture of the internet, or to use them to enable control of the freeflow of information across the internet.the governance and administration of the dns should not becomea vehicle for addressing political, legal, or economic issues beyond thoseof the dns itself.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.191navigating the internet:concepts and contextthe internet is rapidly becoming everybodyõs neighborhood. just afew keystrokes take us to an online bookstore; several mouse clicksdeliver us to an online newsstand; only a bit more effort connectsus with distant friends or family. for many of us, seeking out a web siteor an email address is almost as important as finding the way to the library, a theater, the nearest mall, the bookstore, or the neighborhood playground. and for those who use the internet to deliver products or services, their clienteleõs ability to find them is essential to their success.navigating the virtual neighborhood has become a life skill for those needing something on the internet and a lifeordeath matter for businesseswith something to offer on the internet.to navigateñto follow a course to a goalñacross any space, a methodis needed for designating locations in that space. on a topographic map,each location is designated by a combination of a latitude and a longitude.in the telephone system, a telephone number designates each location. ona street map, locations are designated by street addresses. just like a physical neighborhood, the virtual neighborhood has addressesñ32 or 128 bitnumbers, called internet protocol (ip) addressesñthat define the specificlocation of every device on the internet. and also like the physical world,the virtual world has namesñcalled domain names, which are generallymore easily remembered and informative than the addresses that are attached to most devicesñthat serve as unchanging identifiers of those devices even when their specific addresses are changed. the use of domainnames on the internet relies on a system of serversñcalled name serversñthat translate the userfriendly domain names into the correspondsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.20signposts in cyberspaceing ip addresses. this system of addresses and names linked by nameservers establishes the signposts in cyberspace and serves as the basic infrastructure supporting navigation across the internet. it is called the domain name system (dns).this report is concerned with the domain name system and its interactions with internet navigation, including its uses as a means of navigation itself and as an infrastructure for navigation by other means. sincethe world wide web is the application running on the internet that contains the greatest number of locations to which most users want to navigate, this report often draws examples from the web. however, there areother applications that use the internet, not least email, and others thatare being developed for it. the dns supports most of them. unless otherwise specified, the information in this report, its conclusions, and its recommendations apply to the dns in its role as a basic infrastructure element of the entire internet, not just of the world wide web.the reportõs specific objectives and how it is organized to addressthem are spelled out in this chapter, which begins with an introduction tothe internet, the domain name system, and internet navigation, and withan examination of the forces affecting them. four basic concepts that areused throughout this reportñnames, navigation, technical system, andinstitutional frameworkñare defined and briefly described in box 1.1.1.1the internetthe internet, according to the national research council, is òa diverse set of independent networks, interlinked to provide its users withthe appearance of a single, uniform network . . . . the networks that compose the internet share a common architecture (how the components ofthe networks interrelate) and software protocols (standards governing theinterchange of data) that enable communication within and among theconstituent networks.ó 1internally, the internet comprises two types of elements: communication links, channels over which data travel from point to point;and routers, computers at the networkõs nodes that direct data arriving along incoming links to outgoing links that will take them towardtheir destinations. altogether, the internet is a complex network ofrouters and links, the latter varying in transmission medium (telephone lines, cable lines, optical fiber cable, satellite, wireless); serversand other hosts; and access equipment. links in the network may becharacterized by their transmission capacity (lowcapacity local lines1computer science and telecommunications board, national research council, theinternetõs coming of age, national academy press, washington, d.c., 2001, p. 29.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.navigating the internet: concepts and context21to very high capacity òbackboneó cables) and by their latency (shortlatency local fiber links to longtraveltime satellite links). data travelalong the internet in packets adhering to the standard transmissioncontrol protocol/internet protocol (tcp/ip) that defines the packetsõformat and header information.each router uses the origin and destination ip addresses in each arriving packet to determine which link to direct it along. a message from asender to a receiver may be broken into multiple packets, each of whichmay follow a different path through the internet. information in the packetsõ headers enables the message to be restored to its proper order at itsdestination.the origins and destinations of data transiting the internet are computers (or other digital devices) located at its òedges.ó they are, typically,connected to the internet through an internet service provider (isp) thathandles the necessary technical and administrative arrangements. a distinctive feature of the internet is that all the user services (such as emailor the world wide web) accessible through it are provided by applications running on computers located at its edges. the òcenteró of theinternetñits links and routersñprovides the critical connectivity amongthem. as a consequence of this architecture, most of the service innovation takes place at the edges, completely independently of the networkitself. it is an embodiment of the endtoend argument in systems design2that says that òthe network should provide a very basic level of serviceñdata transportñand that the intelligenceñthe information processingneeded to provide applicationsñshould be located close in or close to thedevices attached to the edge of the network.ó3a consequence of this architecture is that innovation at the edges iseased and facilitated, requiring no coordination with network architectsor operators, as long as the basic protocols are adhered to. conversely,innovation at the center of the network is difficult and often slow, since itrequires the cooperation of many providers and users. because of thehigher potential for inadvertent disruption as a side effect of a change atthe center of the system, difficult and timeconsuming effort must be devoted to testing and validating each proposed change. all such changeshave been subject to cooperative collaboration and agreement by theinternet engineering community since the earliest days of research andimplementation. (see òmaintenance of dns standardsó in section 3.2.5.)that principle has been a major factor in the successful design, development, and implementation of the technology.2see jerome h. saltzer, david p. reed, and david d. clark, òendtoend arguments insystem design,ó acm transactions on computer systems 2(4):277288, 1984.3cstb, nrc, the internetõs coming of age, 2001, p. 36.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.22signposts in cyberspacebox 1.1four basic conceptsnames and naming systemsnames and naming systems are everywhere in society. a license plateon a car, a serial number on a product, and a stock market symbol for acompany are a few examples of names that are used within formal namingsystems. each of these examples is a unique identifier, created according tothe specifications of a naming system, which is associated through strictnaming rules with a single automobile, product, or company. equally important are a host of informal or less strict naming systems, such as thenaming of people by families, the naming of streets or locations, or thenaming of files and directories on a personal computer. in these processes,there is no guarantee of unique names for objects.more generally, naming is used to distinguish individual objects withina broad class, the object space. the set of allowable names for objects inthat class is called the name space. a name is then a member of that setused to differentiate one member of the object class from another. a naming system is the combination of an object space, the name space that isapplied to it, the rules governing the assignment of names to objects, thefiles recording the assignments, and the administrative processes (if any)applying the rules and maintaining the files.navigation, navigation aids, and navigation servicesnavigation is the process of following a course from one place to another. in the narrow sense, the term is used to refer to a person or entity(e.g., a vehicle) being directed along a course from an origin to a specifieddestination. in the broader sense, navigation refers to following a courseon, across, or through (e.g., navigate a stream) or making oneõs way somewhere (e.g., lewis and clark navigating to the òwestern passageó or dr.livingstone navigating to the source of the nile). navigation involves a setof skills (e.g., reading a compass, using a search engine). the place towhich one wishes to navigate may be known explicitly (e.g., latitude andlongitude, a street address, a web site address) or only in general terms(e.g., source of the nile, sites with information about veteransõ benefits). inthe former case, navigation requires only the two steps of laying out a routeto the known location and following it. in the latter case, however, there isa prior step of identifying the desired location (or locations) through asearch process of some form.a navigation aid is anything that assists navigation, such as a map or acompass. in the physical world, navigation aids include a sextant and precision clock, and a compass and topographical map. in documentorientedenvironments, navigation aids include printed directories for the telephonesystem and card catalogs for library collections. human intermediaries alsocan serve as navigation aids in these environments, such as directory assissignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.navigating the internet: concepts and context23tance operators in the telephone system and reference librarians for libraryservices. in the internet, navigation aids include bookmarks and lists of favorites, hyperlinks, and restricted keyword systems, such as aol keywords.a navigation service is a navigation aid that is based on a complex technical system (see below). in the physical world, the global positioning system isa navigation service, as is an inertial navigation system. automated directoryassistance and online white pages are navigation services for the telephonenetwork, and online card catalogs are navigation services for libraries. in theinternet, directories and search engines are navigation services.internet navigation, navigation aids, and navigation services are discussed in greater detail in chapters 6, 7, and 8.technical systemsa technical system is an integrated set of engineered elements (components and practices) that delivers a specific service to users. some familiarexamples of technical systems are the telephone system, the air transportsystem, the electric power system, and the domain name system. in thecase of the telephone system, the engineered elements are organized in acomplex network that includes the switching facilities (both hardware andsoftware) that set up the circuits linking telephones for a call, the transmission lines that carry the calls, and the telephone instruments that originateand receive calls; the service it delivers is telephone connectivity; and theusers are people who want to communicate with others by voice, data, orfacsimile.the single technical system that is the domain name system is described and discussed in detail in chapters 2, 3, and 4; the technical systems that support internet navigation services are characterized morebroadly in chapters 6, 7, and 8.institutional frameworkan institutional framework is a collection of organizations and policieswhose decisions and actions enable a technical system to be constructed,operated, controlled, regulated, and improved. an institutional frameworkand its technical system are complementary to each other. each of theexamples of technical systems described above has a complementary institutional framework. the telephone system, for example, depends for itseffective and efficient development and operation upon a complementaryframework comprising equipment suppliers, operating companies, local,state, national, and international regulatory bodies, international standardsorganizations, and the technical community.the institutional framework of the dns is discussed in chapters 2, 3,and 5; that of internet navigation services, in chapters 6, 7, and 8.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.24signposts in cyberspacethe internetõs architecture has enabled it to respond very successfully tothe challenges of growth in the number of its users and in the capacity of itslinks and the complexity of their connectivity, as well as to provide a robustbase for the growth of services such as email and the world wide web.1.2 the domain name systemthe dns was put into place by technologists in the early 1980s whenthe internet provided basic noncommercial services to a small communityof specialists.4 the world wide web had not yet been invented. the dnsõsdesigners intended it to be a simple and stable way for users and applications to identify computers on the internet. they gave it a hierarchical structure so that the responsibility for maintaining the necessary informationtying domain names to ip addresses (and other data) could be distributedto the organizations actually managing the relevant networks and groupsof hosts across the edges of the network.5 they designed it as an invertedtree with the expectation that most domain names would lie severalbranches down, requiring relatively few names in the upper part of thetree. figure 1.1 illustrates the domain name systemõs role in support ofnavigation across the internet.6 complete domain names7 incorporate thenames of the nodes in the tree above them. so in figure 1.1, the domainname www.cstb.nas.edu designates the www leaf lying on the .cstbbranch, which lies on the .nas branch, which lies on the .edu branch.a number of factors, including the introduction of the world wideweb in the early 1990s, have transformed the internet community from asmall town into a great and rapidly expanding metropolis with an extremely large, highly diverse body of users, relatively few of whom arecomputer specialists. these users employ the internet as the communications backbone for a vast range of commercial and noncommercial purposes. as a result, the internet has expanded both in scale and in the scopeof its applications. because of the elegance of its technical design, the dnshas, thus far, been able to adjust to the expanded scale of the internet,evolving to meet the increased operational demand adequately. however,as a consequence of the growth in the scope of the internet, the dns isnow used in ways that were not anticipated when it was designed. these4chapter 2 describes the development of the domain name system.5chapter 3 describes the design and operation of the domain name system.6this depiction of the dns is highly simplified. more detailed descriptions of the dns areprovided in chapters 2 and 3.7formally, these are called òfully qualified domain namesó to distinguish them from partial domain names that describe the path only from some node below the root.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.navigating the internet: concepts and context25unanticipated uses have led, in turn, to a substantial increase in the number and complexity of the institutions responsible for its operation andmanagement and to less use than was originally expected of deep naminghierarchies and distributed, but localized, management of names. thisgrowth in institutional complexity has been driven primarily by the factthat domain names acquired increased value, which required mechanismsto deal with their allocation and control. their acquisition of increasedvalue followed from four developments:¥preference for short and memorable names.the first development wasa preference among users for short and memorable domain names, whichled to an unexpectedly unbalanced distribution of domain names. moredevices were named at the second or third level of the inverted tree,thereby widening it, rather than deepening it to the fourth and lower levels as had been anticipated. and although the implementation of the dnsoffered a range of generic toplevel domainsñsuch as .com, .net, .org,internetdomain namesystemuser1.what is the ip address of the domain name www.cstb.nas.edu?2.the ip address of www.cstb.nas.eduis 128.128.128.1283.retrieve the home page at 128.128.128.128.128.128.128.1284.here is the home page at www.cstb.nas.edu.internetdomain namesystemuser1.what is the ip address of the domain name www.cstb.nas.edu?2.the ip address of www.cstb.nas.eduis 128.128.128.128.3.retrieve the home page at 128.128.128.128.128.128.128.1284.here is the home page at www.cstb.nas.edu.figure 1.1the domain name system and internet navigation for the webñnavigating to www.cstb.nas.edu. the web site and ip address used are fictional.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.26signposts in cyberspace.gov, and .eduñfor a variety of reasons, .com became the preferred choice,further unbalancing the tree. even with the addition of new generic toplevel domains after the year 2000, memorable domain names within the.com domain remain the preferred choice for most businesses, many nonprofit organizations, and numerous individuals.8¥navigation role of .com.what led most directly to the growth inimportance of the .com domain was the second developmentñits selffulfilling role in navigation. for example, as commercial uses grew, usersseeking ibmõs site on the world wide web could guess www.ibm.comwith an expectation of success. that common behavior naturally led organizations and individuals to seek registration of domain names that usersmight be able to guess to find their site, which in turn improved the usersõchances of navigating by guessing. that users were inclined to use domain names to search for content of interest increased the desirability ofdomain names corresponding to generic words, such as òbusiness,óòjobs,ó or òsex.ó and the importance of having those names in the .comdomain was increased even more by the design of web browsers. recognizing user inclinations, designers made the default behavior of manyweb browsers when confronted by an incomplete domain name the automatic addition of .com to the end of it and www as the default prefix.9thus, domain names became not only the way of designating locations onthe internet, but also a principal means of navigating to them.10¥valuable secondlevel domain names.the third development was therecognition that certain domain names within the toplevel domainsñsecondlevel domain namesñare more valuable than most others. theresult was an aftermarket for domain names, generally in the .com toplevel domain, in which some have been resold for prices far greater thanthe nominal registration fee paid by the original registrant. furthermore,in an effort to protect their rights and prevent others from abusing them,trademark holders have sought to acquire many of the domain namesincorporating their trademarks and, given the likelihood of entry errors,words that are typographically close to them in all of the relevant toplevel domains. this effort has, in turn, led to competition among trademark holders with the same mark (though in different industries or regions) for the small number of memorable domain names incorporatingtheir marks. (individuals or groups with other legitimate claims to a8in mid2004 there were almost 27 million .com registrations compared with 4.4 millionfor .net and 2.8 million for .org. see also table 3.3.9browsers in 2005 no longer make this assumption. instead, they commonly assume thatthe entry is a search term.10the unique role of .com is elaborated on in chapter 2.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.navigating the internet: concepts and context27nameñsuch as those with the surname mcdonald11ñhave also assertedtheir rights to domain names incorporating trademarks.) it has also attracted speculators who rush to acquire potentially desirable domainnames (both trademarks and generic words) in order to resell them tothose for whom the value would be substantially greater than the registration fee.12¥marketing function.the value of domain names has been furtherenhanced by their widespread use in marketing materials as a secondary,or even primary (e.g., amazon.com), identifier of an organization. in thatrole they appear on stationery, in newspaper ads, on billboards, and onthe sides of buses. this marketing function of domain names is the fourthunanticipated development.because of these developments, the domain name systemñoriginallya modest technical system introduced to provide easytoremember andportable names for locations on the internetñhas become a critical toolfacilitating global communication by designating sources of information,products, and services as well as the email boxes of people and organizations throughout cyberspace. as a consequence, its simple original institutional framework, managed essentially by one person,13 has been replaced with a complex network of institutions comprising numerouspublic and private, commercial and noncommercial organizations thatregister domain names and operate name servers; and one nongovernmental organization with international scope that, with the authority andoversight of the u.s. government, provides technical coordination andestablishes some elements of global policyñthe internet corporation forassigned names and numbers (icann).11the new toplevel domain, .name, for registration by individuals was intended to meetthat need, although by mid2004 the companies involved with registrations in that domainhad not found business models capable of supporting those operations.12a case in point is the name business.com, which changed hands for $150,000 in 1997and was resold for $7.5 million in 1999. see jennifer mack, òbusiness.com: the $7.5 milliondomain,ó zdnet news, december 1, 1999, available at <http://zdnet.com.com/210011516999.html?legacy=zdnn>. however, in the aftermath of the dotcom bust, the prices realized in the aftermarket for domain names have also subsided substantially, although at theend of 2003 the name men.com was sold for $1.3 million by a person who paid $15,000 for itin 1997. see anick jesdanun, òdomain names once again fetch top dollar,ó associatedpress, december 25, 2003.13jon postel held this responsibility for many years. for further information, see <http://www.isoc.org/postel>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.28signposts in cyberspace1.3internet navigationwith the growth of the size, complexity, and variety of applicationsusing the internet, and especially the rapid growth of the world wideweb, a range of aids to the navigation process (especially on the web)have appeared.14 the dns is a single technical system providing a singleservice, which is operated and controlled in a complex institutional framework. in contrast, among aids to navigation on the web there are numerous specialized navigation services, each operated by different providersthat compete openly without any comprehensive institutional frameworkfor their operation and control. principal among these navigation servicesare search engines, which at the possible cost of a few more keystrokesopen up a far wider range of possibilities on the web than simple domainname guessing; and directories, which provide a yellow pages or whitepages guide to locations, principally on the web. as search engines haveimproved in userperceived quality and ease of use, they have become aprincipal means of navigation to new destinations for many users.15 inplace of guessing, intrepid web travelers enter a descriptive word orphrase in the search engine and use the resultant list to direct their journeys. in june 2004, nearly 4 billion searches were conducted each monthby almost 110 million people in the united states, an average of 33searches per person per month.16 it appears that a consequence of thegrowing use of search engines for navigation across the web may be areduction, though by no means elimination, of the direct use of the dnsto support navigation by guessing domain names.because locations that offer search or directory capabilities are accessed so often, a number have evolved into portals, which are web sitesoffering directed links to popular categories of services, such as my yahoo!. portals such as msn and aol have also evolved from provision of14if the location of a desired web site is known, then navigation can be directñthe dnsdetermines the ip address of the site. if the location is not known, then some navigation aidmust first be used to determine the location. see section 7.1 for a detailed discussion of directand indirect navigation.15according to data from websidestory, both direct navigation using a known domainname and the use of web search engines increased substantially from 2002 to 2003. in march2003, 13.6 percent of web site accesses were generated by search engine listings, while 66percent were the result of the use of bookmarks or direct entry of a known address. see<http://www.websidestory.com>, press release, march 12, 2003.16deborah fallows, lee rainie, and graham mudd, òthe popularity and importance ofsearch engines,ó data memo, pew internet & american life project, august 2004, availableat <http://www.pewinternet.org/pdfs/pipdatamemosearchengines.pdf>. the resultscame both from a telephone survey of 1399 internet users and from tracking of internet useby comscore media metrix.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.navigating the internet: concepts and context29internet service. some users find the portals more desirable than searchengines alone and begin their navigation from them. in doing so, they arerelying on the editorial judgment and commercial or other arrangementsof the portal to get started. however, once a world wide web site isreachedñno matter howñsubsequent navigation often flows along thenetwork of links from one site to others. and it is likely that most experienced users deploy a combination of navigation services and other aids:employing search engines, portals, and direct entry of destinations intobrowsers at various times.17 other navigation aids are also in use. in someweb portals run by isps (such as aol) or through extensions to browsers, a specified vocabulary of key words can be used to reach specificdestinations.the cumulative effect of these services and other aids to navigationhas, thus far, been positive. they enable users to find sources of products,services, information, and contacts that they would not have been able toidentify previously. complementarily, they enable providers to reach audiences that might not otherwise have known of their existence. unlikethe development of the top levels of the dns, which has been under thetechnical control of the internet engineering community and the governance of icann, national governments, and the operational organizations, these navigation services have for the most part been provided byprivate organizations. despite their benefits, however, navigation servicesand other aids are also beginning to raise policy concerns. most searchengines and directories now accept payment from advertisers for placement of an ad on the pages of responses to queries with specific searchterms. if not clearly identified such ads might give searchers a false senseof an advertiserõs importance or relevance and reduce the chances that anonadvertiser will be located. concerns about the practices of the providers of navigation services are likely to grow as internet users rely increasingly on these services as a principal means of navigation.1.4the dynamics of changesince the early 1980s, when the dns was developed, five forces haveinexorably driven the transformation of the internet from its origins as asmall, primarily north american research network, which was run by atightknit group of specialists for use within their research and industrialcommunities, into its current state as a diffusely managed and increasingly critical part of the global information and communication infrastruc17these destinations might be derived from guesses about domain names as discussedabove or references provided by others (e.g., in an email) that are copied and pasted intobrowsers, as well as by the use of bookmarks for destinations that are accessed frequently.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.30signposts in cyberspaceture. these driving forces are increasing scale, technological progress, increasing economic value, increasing social value, and internationalization.in addition to having a profound impact on the internet (and the worldwide web) as a whole, these forces have simultaneously transformed thedns and internet navigation to subjects of substantial commercial, legal,political, and social importance. the likelihood of the continued influenceof these forces raises important questions about the future viability, operability, and governability of the dns and internet navigationñthe subjects of this study.1.4.1increasing scalewhen the dns was developed, the internet comprised on the order of1000 sites and perhaps 10,000 users. in two decades it has grown to morethan 30 million sites and over 600 million users.18 though its designersdid not fully anticipate the rapid growth in users and uses stimulated bythe world wide web, the dns has technically scaled quite well to thecurrent size. in addition, new navigation tools have been deployed to assist users in searching the vastly larger internet. the internet continues togrow in number of users, number of addresses, and number and diversityof attached devices. by 2010, at current growth rates, the internet couldhave more than 60 million sites and well over a billion users worldwide.191.4.2technological progresswhen the dns was developed, most of the hosts were workstations,minicomputers, or mainframe computers. personal computers had justbegun their penetration of the business and home markets in northamerica, europe, and japan. internetworking communication took placeover backbones that had 56 kbps (kilobits per second) speedsñabout1/180,000th the speeds of backbones in 2005, which run at 10 gbps (gigabits per second). as the capacities of computers and communications networks have soared, the dns and navigation systems have taken advantage of the increased computational capability and bandwidth to meet the18these numbers reflect estimates made in may 2003 by cyberatlas; see <http://cyberatlas.internet.com>.19to serve them, the basic ip addressñcurrently 32 bitsñis being enlarged to 128 bits,enabling addressing of a wide range of devices from computers and cell phones to homedigital media centers and home appliances. the current ip address space is called the ipv4address space; the new version is called the ipv6 address space. ipv6 is slowly being adopted,working in parallel with ipv4.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.navigating the internet: concepts and context31challenges of scaling. continuing technological advances in computingand communications offer the possibility of strengthening the dns andincreasing the capacities of navigation services, while at the same timefurther empowering those who would attack the services or attempt tomisdirect them for their own benefit.1.4.3increasing economic valuewhen the dns was developed, there was probably little or no economic value associated with possession of a particular domain name,which could be obtained at no cost, although having a hierarchical naming system was judged to be valuable. a distinctive internet culture haddeveloped well before this time, led by the relatively small and homogeneous community of engineers and scientists who were its primary users.it placed high value on voluntary service, free access within the community, and consensus decision making. however, the growth of applications on the internet for commerce, information, art, and entertainmentattracted commercial, legal, governmental, and other communities whosevalues and processes differ from those of the early internet culture. theirarrival led to the development of a vigorous market for domain namesand of a variety of mechanisms to deal with fair allocation of the noweconomically valuable domain names. not surprisingly, throughout thesedevelopments there has been a continuing tension between the technicalcommunity and the public interest community about the proper goals andmechanisms for the allocation of domain names and the management ofthe dns.as domain names have gained economic value, so, too, has the desiregrown for opportunities to publicize those names (as part of web site andemail addresses) to potential users of the corresponding internet locations. consequently, many search engines and other navigational services,which originally provided a single listing of search results in the order ofestimated relevance to the userõs query, now also give prominent placement to those willing to pay for it. as noted above, the search engineindustry faces a continuing challenge in finding the proper balance between the interests of the users of search engines and the advertisers onthem, against the backdrop of the ever present possibility of governmentintervention.1.4.4increasing social valuewhen the dns was developed, there was a modest level of social,political, or cultural value associated with specific domain names. as theinternet grew in size and evolved in use, it became a primary medium forsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.32signposts in cyberspacecommunication, commerce, information, art, and entertainment; accordingly, domain names assumed greater social, political, and cultural significance as the memorable designators of the internet locations of political groups, cultural resources, and social activities. but as a result, thedns became entangled in issues of privacy versus accountability, freedom of expression versus national legal restrictions, and the rights of producers of intellectual property versus those of its users. in the future, the internet can be expected to be even more widelyused for interpersonal communication, for the public expression of ideas,for access to information, for the development of virtual communitiesaround common interests, and for the production and distribution of artand entertainment. it will be a major portion of the global social fabric,facilitating and controlling the flow of information, expression, art, andentertainment. until or unless the dns is replaced, the signs designatingthe location of information, art, entertainment, viewpoints, and serviceswill continue to depend on domain names. for that reason, it will be essential to sustain the dns as the reliable signposting infrastructure of theinternet, facilitating the internetõs use as a medium of free expressionopenly communicated to all corners of the globe, while balancing thatfreedom of expression against privacy rights, property rights, culturalmores, and national laws.as a result of the internetõs increased social value, the desire to navigate freely across it can also be expected to encounter legal, commercial,cultural, and political challenges.1.4.5internationalizationwhen the dns was developed, the internetõs geographic scope waslimited primarily to north america, parts of western europe, and a fewcountries on the pacific rim. and it was operated by a loose confederation of bodies and individuals, primarily in the united states, most ofwhom had received substantial support from the u.s. government. asuse of the internet has spread beyond its initial sites to encompass everycontinent and region and almost all nations, the network has respondedsuccessfully. but internationalization has posed two specific challengesfor the dns.first, until recently domain names have been limited to strings of roman letters, arabic numbers, and the hyphen, a subset of the ascii2020the american standard code for information interchange (ascii) was originally developed for use with teletype. it was extended by ibm to represent 256 characters and hasbecome a de facto standard.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.navigating the internet: concepts and context33character set. however, the native languages of an increasing number ofinternet users employ different character sets. recently, following yearsof work, a means of enabling presentation of internationalized domainnames (domain names encoding other character sets into ascii characters) has been adopted. it should become an important facilitator ofinternet access and use for those communities.21and, second, although icann has international participation, its authority rests on a contract from the u.s. department of commerce, whichis perceived by some as undercutting its legitimacy as a representative ofthe international community. that concern may increase as the economicand social value of the dns as the critical signposting infrastructure ofthe internet continues to grow.22although the dns is only now moving toward presentation of nonascii scripts in domain names, internet content in most important applications, including email and the web, has been internationalized for wellover a decade. most internet navigation services have incorporated thecapability to search in multiple languages. for example, in november 2004the google search engine supported searches in over 100 languages anddialects and provided a customized version of the search interface for 103different nations.23 at the same time, the yahoo! directory and searchservice offered portals customized for 32 national or language groups.24since the navigation services are provided by a variety of organizations inan open forum, they are less subject to concerns about the internationalization of their governance. however, as their importance as the principalmeans of access to the internet grows, they may well come under pressurefrom those who believe that in one aspect of their service or another, theydo not adequately take into account the concerns or interests of certainnations, ethnic groups, or linguistic communities.1.5internet naming and navigationowing to the five forces outlined above, internet naming and navigation have become matters of broad concern throughout the world. those21internationalized domain names (idns) have recently been approved by icann for useby registries with which it has agreements. see òstandards for icann authorization ofinternationalized domain name registrations in registries with agreements,ó posted march13, 2003, on the icann web site, <http://www.icann.org>. see section 4.3 for a more complete discussion of this subject and more extensive references.22changes in icannõs organizational structure and decision processes responded to thisconcern, although debate continued into 2004 about the effectiveness of those changes. seesections 5.1 and 5.2 for an extended discussion of this issue.23for a listing see <http://www.google.com/languagetools?hl=en>.24for a listing see <http://world.yahoo.com/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.34signposts in cyberspaceconcerns are given voice by the large number of competing interest groupsthat now take a vigorous interest in the dns and, to a somewhat lesserdegree, internet navigation.product and service providers compete for named locations on theinternet and have a strong interest in the means for setting up new regions and allocating named locations in them. internet users have acomplementary interest in being able to find the information or servicethey want wherever it may be located, even as the internet continues togrow in size and in diversity. all cultures have an interest in being able toname locations and access and navigate the internet in their native languages. trademark holders have an interest in protecting their rights innames from being infringed. nations and their citizens want assurancethat their interests will be treated fairly and their needs supported by theinstitutional frameworks that affect the internetõs naming and navigationinfrastructures. the internet technical community wants to ensure thateverything is done to improve and nothing is done to compromise thereliability, security, and stability of the internet itself. individuals alsowant to be certain that neither their access nor their rights will be undulyaffected by the actions of the other groups. the interaction among thesevarious interests in naming and navigating the internetña global infrastructure that is undergoing rapid growth in scale while absorbing continual technological changeñraises important issues that lie at the intersection of technology, economics, public policy, law, and user behavior.25this report addresses those issues from a specific perspective, that ofthe domain name system. navigation across the vast and multifacetedcomplex of human activity connected through the internet is a subjectthat warrants a major report in its own right. it is too large, in its fullrichness, to fit within a report that was initiated to address significantquestions about the future of the dns. yet, at the same time, navigation isso intertwined with the present and future of the dns that it cannot becompletely absent. consequently, this report concentrates on navigationover the internet primarily in its relationships with the dns. even underthat constraint, however, it is necessary to introduce fundamental issuesof internet navigation to provide a background for the more circumscribedexamination of its interrelationships with the dns.the dns interrelates with navigation across the internet in five ways.¥first, the dns plays a direct navigational role by providing the ipaddress of a world wide web site, an email server, or another networkhost or resource whose domain name is known, or can be guessed.25see cstb, nrc, the internetõs coming of age, 2001.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.navigating the internet: concepts and context35¥second, the dns serves as an enhancer of navigation because manynavigation services return locators incorporating the domain names ofrelevant web sites. these names usually provide more (although not necessarily reliable) information to the user about the provider whose location has been returned than just the ip address or a blank link would.¥third, navigation services complement the dns by, for example,enabling navigation to web sites whose domain names are not known bythe user or by enabling searches within sites that have been reached byuse of their domain names.¥fourth, navigation services relieve some of the pressure on thedomain name system by reducing the need for a site to have a shortmemorable name in order to be found. it appears that efforts and fundsspent in previous years to obtain desirable domain names are now beingdiverted to some degree to efforts and expenditures to ensure a presenceand high ranking in the results of search engines or directories.¥fifth, navigation services could, in the extreme, substitute entirelyfor the domain name system on the web because they could directlyreturn ip addresses. however, as noted above, this approach would deprive the user of any information about the provider contained in the domain name. it would also deprive the provider of the marketing value ofthe domain name. and it would eliminate the use of domain names asstable identifiers of internet resources whose ip addresses change, whichwas one of the original motivations for the creation of the dns.of these five roles, it is the third and fourthñnavigation as a complement to and a relief for the dnsñthat are the focus of this reportõs examination of internet navigation.1.6 objectives of this reportthis report is addressed to those who are or will be concerned withpolicies and practices that affect the operation and evolution of the dnsand internet navigation. that is a large audience. it includes the technologists who research, design, implement, and operate the dns and navigation systems; the governmental policy makers and their staffs who establish, oversee, and operate the framework of institutions and laws thatgovern or regulate those systems; the commercial and noncommercialorganizations that operate, manage, and use those systems; and the usersand providers who depend on those systems for access to and the accessibility of internet locations.during the time that this report has been in preparation, the dnsand internet navigation have seen many technical and institutionalsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.36signposts in cyberspacechanges, some substantial, others modest; some controversial, othersagreeable; some likely to last, others temporary expedients that willeventually be replaced. some of the changes made have addressed theissues that gave rise to the initial request for this report. clearly, thisstudy was not the proper vehicle to address those specific issues. however, it is equally clear that many issues of similar character are or soonwill arrive on the agendas of the policy, technical, provider, and usercommunities. yet those called upon to deal with policy and practicesaffecting the dns and internet navigation often have little or no knowledge of the full complexity of those arenas. those who are engaged withthe technology of these worlds do not always appreciate the nuances ofthe policy, economic, and legal issues, while those experienced with thelegal, economic, and policy aspects often are largely unaware of the intricacies of the technology. this asymmetry of knowledge exacerbatescultural differences between the technology and the policy communities, inhibiting both effective policy making and desirable technologicalchange. both groups would benefit from having a reliable source of information about the technologies and the institutions that control them,upon which they can base reasonable and effective policies. and, whereappropriate, they might also benefit from the conclusions and recommendations of a broadly knowledgeable committee that has spent several years reviewing the two worlds.therefore, this report, which is the result of extensive and collaborative work by a committee whose members are drawn from both the technology and the policy communities, is intended to serve five objectives:1.to provide a thorough and objective description and assessment ofthe domain name systemñboth its technology and the institutional framework within which that technology operates;2.to describe and analyze alternative approaches to the principaltechnology prospects and institutional issues that are likely to affect the future of the dns;3.to provide a thorough and objective description and assessment ofinternet navigation, with sufficient background information to provide context;4.to describe and analyze alternative approaches to some of the technology prospects and institutional issues that are likely to affectthe future of internet navigation; and5.to present conclusions and make recommendations where it waspossible for the committee to reach agreementñin any case, tocharacterize the range of alternative views.this report has been structured to respond to those objectives.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.navigating the internet: concepts and context371.7 roadmap for this reportthis report is divided into three parts. the dns is the subject of thefirst, consisting of chapters 2, 3, 4, and 5. internet navigation in its relationship to the dns is the subject of the second, consisting of chapters 6,7, and 8. chapter 9 summarizes the interaction between the dns andinternet navigation.because the options for moving forward are partially constrained bythe decisions taken along the path to the present, the first part begins witha careful review of the development of the domain name system. chapter 2 examines the evolution of the technical design of the dns and itsassociated operational, administrative, and governance mechanisms. itdescribes the sequence of important technical decisions and innovations,as well as the new governance and administrative mechanisms that havebeen introduced in response to the internetõs rapid growth. several of theearly technical decisions, taken at the time of restricted use ofinternetworks by specialized groups, still constrain the dns. chapter 3 describes the current state of the dns, considering boththe technical system, which performs the linkage of domain names withip addresses and associated data, and the higherlevel institutional framework, which carries out operational, administrative, and policysettingfunctions essential for the dns to function. it explains and evaluates theoperation of the dns technical system and identifies and assesses each ofthe functions carried out by the highest levels of the institutional framework.chapter 4 describes the prospective technologies that can respond tothe challenges the dns faces from malicious attacks, the growing intersection of the telephone system and the internet, the need to internationalize the dns, and the need to regulate the introduction of potentiallydisruptive new services. chapter 5 deals with the key institutional issuesfacing the dns: governance of the dns itself, oversight of root operations, governance of the toplevel domains, improvement of the disputeresolution process, and improvement of the dnsõs information service(called the whois service).the distinctive characteristics and historical development of internetnavigation, as it relates to the dns, are described in chapter 6. the current state of navigation aids and services and the framework of commercial institutions within which they operate are presented in chapter 7.chapter 8 addresses some prospective technologies whose introduction,and a number of the institutional issues whose resolution, can have amajor influence on the future development of internet navigation and itsrelationship to the dns.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.38signposts in cyberspacefinally, chapter 9 sums up the interaction between the dns andinternet navigation.throughout the chapters on the dns and internet navigation, thecommitteeõs conclusions and recommendations are incorporated into thetext where appropriate.the goal of this report is to clarify the sometimes controversial, oftenarcane, and frequently uncertain issues concerning the signposting andnavigational infrastructure of the internet. the committee hopes that byproviding such clarification, this report will itself serve as a navigationalaid to the policy and technology communities as they find their way todecisions that will enable the internet to remain an efficient and reliablechannel of global communication and commerce.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.392the domain name system:emergence and evolutionthe domain name system (dns) was designed and deployed in the1980s to overcome technical and operational constraints of its predecessor, the hosts.txt system. some of the initial design decisions have proven to be extraordinarily flexible in accommodating majorchanges in the scale and scope of the dns. other initial design decisionsconstrain technical and policy choices to the present day. thus, an understanding of the system architecture and the rationale for the design characteristics of the dns provides the base for understanding how the dnshas evolved to the present and for evaluating possibilities for its future.this chapter outlines the origin and development of the dns and describes its key design characteristics, which include both technological andorganizational aspects.12.1origin of the domain name systemfor the first decade or so of the arpanet,2 the host3 table file(hosts.txt) served as its directory. hosts.txt provided the network1a general presentation of the history of the internet is beyond the scope of this report.one source of documentation on the internetõs history is available at <http://www.isoc.org/internet/history/>.2the internet grew out of the arpanet project (funded by the defense advancedresearch projects agency (darpa), which was known as arpa for a period of itshistory); for many years the arpanet served as the core of the internet.3a host is the primary or controlling computer in a network.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.40signposts in cyberspaceaddress for each host on the arpanet,4 which could be looked up byusing the hostõs oneword english language name, acronym, or abbreviation. the network information center (nic) at the stanford research institute5 managed the registration of hosts and the distribution of the information needed to keep the hosts.txt file current. the list of hostnames and their mapping to and from network addresses was maintainedin the frequently updated hosts.txt file, which was copied to andstored in each computer connected to the arpanet. thus, hosts.txt6was introduced to:¥simplify the identification of computers on the arpanet.simple andfamiliar names are much easier for humans to remember than lengthy(12digit) numeric strings; and¥provide stability when addresses changed.since addresses in thearpanet were a function of network topology and routing,7 they oftenhad to be changed when topology or routing changed. names in the hosttable could remain unchanged even as addresses changed.the hosts.txt file had a very simple format. each line inhosts.txt included information about a single host, such as the network address, and when provided, system manufacturer and model number, operating system, and a listing of the protocols that were supported.because a copy of the host table was stored in every computer on thearpanet, each time a new computer was added to the network, or an4these network addresses could be represented using the internet protocol (ip) format or in the equivalent (now unused) arpanet network control protocol (ncp)format. the most widely used version (v4) of ip represents addresses using 32 bits,usually expressed as four integers in the range from 0 to 255, separated by dots. anexample of an ip address is 144.171.1.26.5stanford research institute became known as sri international in 1977.6for further discussion, see l. peter deutsch, òhost names online,ó request forcomments (rfc) 606, december 1973; ken harrenstien, vic white, and elizabeth feinler,òhostnames server,ó rfc 811, march 1982; and ken harrenstien, m. stahl, and elizabeth feinler, òdod internet host table specification,ó rfc 952, october 1985, allavailable at <http://www.rfceditor.org>. rfcs are created to document technical andorganizational aspects of the internet. the internet engineering task force (ietf)manages the process for discussing, evaluating, and approving rfcs. see box 3.3. fora discussion of the role of the dns more generally, see john c. klensin, òrole of thedomain name system,ó rfc 3467, february 2003.7routing refers to the way data flowed on the arpanet. data transmitted frompoint a to point b might have traversed many different paths, or routes, on the arpanet.note that the arpanet, as the original network to employ the internet protocol (ip),was often referred to as òthe internet,ó although the term later formally encompassedthe aggregate of interconnected ipbased networks.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution41other update was made, the entire table had to be sent to every computeron the network for the change to be recognized.8 as increasing numbersof computers joined the arpanet, the updating task became more andmore burdensome and subject to error and failure, and, as a consequence,several major problems developed from the use of the hosts.txt file:¥failure to scale.as the arpanet started to grow rapidly, it became clear that the centralized hosts.txt file failed to scale in two ways.first, the volume of updates threatened to overwhelm the nic staff maintaining hosts.txt. second, because every system needed to have an uptodate copy of hosts.txt, announcement of a new copy of hosts.txtmeant that the nic server where the current version of hosts.txt wasstored was inundated with attempts to download the file. moreover, thedownload problem was aggravated because hosts.txt kept getting bigger. in short, more hosts on the network meant more updates, more hoststrying to download, and more data to download.¥inadequate timeliness.it often took several days to get a new hostlisted in hosts.txt while the nic staff processed the request to add thehost entry. until it was listed and communicated, the host was effectivelyinvisible to the rest of the arpanet. in a community already becomingaccustomed to getting data instantly over the network, this delay was asource of frustration. similarly, correcting an error often took a few days,because fixes to any errors were not generally available until the nexthosts.txt file was releasedñwhich caused further frustration. themaintainers of some hosts also did not update their copies of the table atvery frequent intervals, resulting in those hosts having obsolete or incomplete information even when the master copy of the table was uptodate.¥susceptibility to failure.the system had multiple ways to fail. probably the most famous outage occurred when the nic released a version ofhosts.txt that omitted the entry for the system where the hosts.txtfile was stored. when the subsequent hosts.txt file was released, mostsystems could not download it, because they could not look up the relevant host name! there were also cases where partial tables were inadvertently released. furthermore, seemingly innocuous additions tohosts.txt could cause the programs that converted hosts.txt intolocal formats to fail.¥name conflicts.the hosts.txt name space was flat, which meantthat host names had to be unique. popular host names such as frodo wereselected first, and so some people had to invent alternate names for theirsystems.8it was the obligation of individual network and host operators to download thelatest hosts.txt file to their machines.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.42signposts in cyberspacethe emergence of these problems caused technologists to develop anew, distributed, method for managing the mapping of names and addresses.2.2designing the domain name systemin the early 1980s, research on naming systemsñsystems for associating names with addressesñwas underway and a few prototype namingsystems had just been developed, most notably the grapevine and clearinghouse systems at the xerox palo alto research center (parc).9 alsoin progress at this time was preliminary work on other computer networkaddressing standards such as x.400.10 because of the uncertainty as towhether these research and development efforts would yield in the nearterm an operational system with the required functionality and neededscale, internet researchers elected to develop their own protocols.in august 1982, zawsing su and jon postel authored òthe domainnaming convention for internet user applications,ó request for comments (rfc) 819, which described how internet naming should bechanged to facilitate a distributed name system. as envisioned in thisdocument, internet names would be organized into logical hierarchies,represented by text components separated by a period (ò.ó) (thus the existing host òisifóñhost computer òfó at the information sciences institute (isi)ñwould become f.isi), and the various parts of the name as assigned (i.e., the parts delimited with periods) would be managed bydifferent network servers. rfc 819 specified only how names would berepresentedñthe details of how the management of various parts of assigned names would take place operationally by the different networkservers remained to be determined.in november 1983, paul mockapetris authored òdomain namesñconcepts and facilitiesó (rfc 882) and òdomain namesñimplementation and specificationó (rfc 883), which specified a set of protocols, calledthe domain name system, that implemented the hierarchical name spaceproposed by su and postel. reflecting the discussions of the previous several months on the electronic mail list namedroppers, the proposed dns9see andrew d. birrell, roy levin, roger m. needham, and michael d. schroeder,ògrapevine: an exercise in distributed computing,ó communications of the acm 25(4):260274, 1982.10the international organization for standardization and the international telecommunication union endorsed x.400 as a standard that describes a messaging service (e.g.,electronic mail). the first version of x.400 was published in 1984 by the comit” consultatifinternational t”l”phonique et t”l”graphique (ccitt), which is now the internationaltelecommunication unionðtelecommunication standardization sector (itut).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution43supported more sophisticated services and features than simply converting host names to addresses (e.g., the proposed system would provide away to map a name to different addresses, depending on the purpose forwhich an inquiry was being made). with some modest changes, the proposed protocols are exactly those in use two decades later.conceptually, the dns is implemented through a distributed and hierarchical series of tables, linked like the branches of an inverted treespringing from a single, common root. when an address is sought, thesearch proceeds successively from the table at the root (or top) of the treeto successive branches and leaves, or lower tables, until the table thatholds the desired address is found. for a particular query, only the lasttable in the search serves as a white pages directory. all of the other tablesserve as directories of directories, each one pointing to lowerlevel directories on a path to the one holding the desired address. thus, the entriesin a table at any given level of the tree can include pointers to lowerleveltables as well as final network addresses. see figure 2.1.when a change is made in the network, only the table directly affected by that change must be updated and only the local organization(e.g., the system administration function in a university or corporation)responsible for that table needs to make the update. as a result, the workof registering changes is distributed among many organizations, thus reducing the burden each must carry.the dns naming syntax corresponds to the levels in the hierarchicaltree. each node in the tree has a name that identifies it relative to the nodeò.óroot.edumit.educstb.orgibm.comcsail.mit.eduòó.com.org.icann.orgfrodo.csail.mit.edufigure 2.1the hierarchical domain name system inverted tree structure.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.44signposts in cyberspaceabove it. the highest level, the òroot node,ó has the null name. in text it iswritten as a single dot (ò.ó) or simply implied (and thus not shown at all).each node below the root is the root of another subtree, a domain, that canin turn be further divided into additional subtrees, called subdomains.each subdomain is written in text to include its name and the subdomainsabove it in the applicable hierarchy. in figure 2.1, .com, .org, and .edu aretoplevel domains (tlds) and cstb.org, mit.edu, and ibm.com aresubdomains of the tlds, often called secondlevel domains. the thirdlevel domain, csail.mit.edu, is a subdomain within the mit.edu secondlevel domain.the dns name of a computer is the name of its node or end point inthe domain name system. thus, frodo.csail.mit.edu would be the computer (or device) named òfrodoó that is located within the csail.mit.edusubdomain of the mit.edu secondlevel domain within the .edu tld. onthe other hand, myownpersonalcomputer.com (without any furthersubdomains) could point directly to a particular computer.applications, such as web browsers and email software, use domainnames as part of the uniform resource identifiers (uris; see box 6.2) orother references that incorporate information about the protocols requiredfor communication with the desired information source. examples of urisare http://www.nationalacademies.org and mailto:someperson@example.com. in the first example, òhttpó refers to the hypertext transfer protocol(http) used for communication with sites on the world wide web. inthe second example, a particular user at the host identified byòexample.comó is identified as the addressee for electronic mail.in terms of information technology, the domain name system is implemented through a series of name servers that are located at each of thenodes in the hierarchy. each name server contains a table that indicates thelocations of the name servers immediately below it in the hierarchy and theportion of the hierarchy for which it contains the final (authoritative) network addresses. thus, the root name servers (at the top of the hierarchy)contain the locations of each of the name servers for the toplevel domains.11at any given node, such as .com or ibm.com, there are expected to be multiple (physical) name servers at different internet protocol (ip) addresses,each with identical information; the purpose of this redundancy is to sharethe workload to ensure adequate system performance.when a user wants to reach www.nationalacademies.org, his or hercomputer usually sends a message to a nearby name server (usually localor operated by the userõs internet service provider), where software (called11each of these root name servers contains identical information; the purpose of having multiple root name servers is to distribute the query workload and ensure reliableoperation. specifics concerning the root name servers are discussed in chapter 3.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution45a resolver), in conjunction with other name servers and resolvers, performs a series of queries to find the name server that is authoritative forwww.nationalacademies.org. that server is then queried for the corresponding ip address(es) and returns the resulting address(es) to the userõscomputer.122.2.1simple, mnemonic, and deeply hierarchical namesas indicated above, domain names were intended to enable a moreconvenient and efficient way of referring to ip addresses and other information, using a simple taxonomy. the early dns included eight generictoplevel domains (gtlds): .edu (institutions of higher educationñmostof which were based in the united states), .gov (u.s. government), .mil(u.s. military), .com (commerce), .net (network resources), .org (other organizations and persons13), .int (international treaty organizations), and.arpa (network infrastructure).14 in addition, countrycode toplevel domains (cctlds) were created based on the twoletter code set (e.g., .gh forghana or .au for australia) in the iso 31661 standard.15despite the ability of the protocols and data structures themselves toaccommodate any binary representation, dns names were historicallyrestricted to a subset of the ascii character set.16 selection of that subsetwas driven in part by human factors considerations, including a desire toeliminate possible ambiguities in an international context. hence, character codes that had international variations in interpretation were excluded;the underscore character (too much like a hyphen) and case distinctions(upper versus lower) were eliminated as being confusing when written orread by people; and so on. these considerations appear to be very similarto those that resulted in similarly restricted character sets being used asprotocol elements in many international telecommunication union (itu)and international organization for standardization (iso) protocols.12the summary provided in this paragraph is quite simplified; there are many discrete technical processes that are not articulated here. see chapter 3 for a more detailed explanation.13initially, the .org tld was intended as the category for organizations and individuals that did not fall into any of the other categories. through time, many individuals increasingly viewed .org as representing the domain name space for nonprofit organizations.14these definitions of the gtlds were generally followed, although a number ofexceptions existed.15thus, the determination of what constitutes a country did not need to be addressedby those who administer the dns. see <http://www.iso.org/iso/en/prodsservices/iso3166ma/index.html>.16this subset, which derives primarily from the original hosts.txt naming rules,includes the 10 arabic digits, the 26 letters of the english alphabet, and the hyphen.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.46signposts in cyberspaceanother initial assumption behind the design of the dns was thatthere would be relatively many physical hosts for each secondlevel domain name and, more generally, that the system would be deeply hierarchical, with most systems (and names) at the third level or below. somedomainsñthose of most universities and some large corporations and thecountry code for the united states (.us)ñfollow this model, at least in itsoriginal design, but most do not17 (see chapter 3 for discussion). however, experience through midyear 2005 has shown that the dns is robustenoughñgiven contemporary machines as servers and current bandwidthnormsñto operate reasonably well even though the design assumption ofa deep hierarchy is not satisfied. nonetheless, it is still useful to rememberthat the system could have been designed to work with a flat structure(e.g., the huge, flat structure under .com comprising tens of millions ofnames) rather than a deeply hierarchical one. for example, based on anassumption of a flat structure at the tld level, one would probably notwish to assign specific operational responsibility by tld (as is the casecurrently). instead, it might have made more sense to design the systemas one database that is replicated on a limited number of servers (to sharethe workload and coordinate updates in a manageable way).2.2.2experimental featuresthe dns specification included a number of experimental features,intended to enhance the services that the dns could provide beyondsimple nametoaddress lookup. several of these features were intendedto facilitate improved support of electronic mail. several resourcerecords18 were intended to improve email routing, helping to ensure thatemail sent to a particular host took a reliable route to that host. the dnsalso included features intended to support email lists and aliases. theidea was to make it easier to maintain mailing lists and to forward mailwhen someoneõs email address changed. in addition, the dns containeda feature to track òwellknown services.ó the purpose of this feature wasto provide a list of services (email, file transfer protocol, web) that are17the .us country code tld was designed originally to use geographical and political jurisdictions as subdomains. as one moves to the left, each subdomain represents asubset of the area represented by the immediately preceding name. for example, inthe name òwww.cnri.reston.va.us,ó òvaó represents the state of virginia within theunited states, òrestonó represents a city within virginia, and òcnrió represents anorganization in the city of reston.18each table within the domain name tree hierarchy contains resource records, whichare composed of fields such as the type (i.e., does this record correspond to a hostaddress, an authoritative name server, or something else) and time to live (i.e., forwhat period of time may this record be cached before the source of the informationshould be consulted again?). see box 3.2 for a detailed discussion of resource records.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution47available from a host. most of the experimental features have not beenadopted for general use. indeed, the original set of emailrelated recordtypes were deprecated in favor of a newer model (see section 2.3.3) andthe òwellknown servicesó record was determined to be unworkable.2.3deploying the domain name systemwhereas the design of the dns looked reasonable on paper, severallimitations of the new system, as with any new system, did not becomeapparent until initial deployment began. addressing these limitationscaused a delay in the full implementation of the dns. the plan called fora switchover to the dns in september 1984, but full conversion did nottake place until 1987. some of the delay was attributable to reconcilingnaming conflicts.19 a large part of the delay derived from a far longerthan expected period to implement and debug the dns, of which a significant portion derived from simple procrastinationñjust not gettingaround to installing and implementing the dns. another delay includedthe difficulty of retrofitting the dns into old operating systems that wereno longer actively maintained.2.3.1cachingthe design of the dns allows for the existence of caches. these arelocal data storage or memory that can significantly reduce the amount ofnetwork traffic associated with repeated successful queries for the samedata by providing access to the data in servers closer to the end user thanthe authoritative name server.20 the data in these caches need to be refreshed at regular intervals21 to ensure that the cached data are valid. inthe initial version of the dns specification, several timing parameters hadtimetolive limits of approximately 18 hours. it quickly became apparent,however, that in many cases data changed slowly, and so updating cachesevery 18 hours or so was unnecessary. as a consequence, the protocolspecification was changed to increase the allowed range of these timingparameters; several other protocol parameters were also given expandedranges, based on the theory that one incompatible protocol change earlyon would be better than a series of such changes. this happened early19most or all of these conflicts were internal onesñfor example, subunits of a university trying to obtain the same domain name as the university.20an additional potential benefit from the use of caches is an improvement in userresponse time.21as defined in the timetolive field in the resource records. see chapter 3.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.48signposts in cyberspaceenough that there was no serious difficulty in deploying upgraded software.in its original design, the dns did not have a corresponding mechanism for reducing the network traffic associated with repeated unsuccessful queries (i.e., queries for which no entry in the relevant authoritativetable is found). within a few years of the initial implementation of thedns, it became apparent that such a mechanism would be beneficial,given the number of identical queries that are unsuccessful. a proposedmechanism for negative response caching was developed, and the datanecessary to support it were added to the protocol in a way that did notaffect software based on earlier versions of the protocol, but the full deployment of the new mechanism was slow. the name server side of thenew mechanism was very simple and was deployed fairly quickly, butinitial support for the client (user) side of the negative caching mechanismwas limited to a few implementations and was not adopted more generally until much later. the lack of widespread and correct clientside support for negative caching is a problem that still persists.222.3.2lookup timeoutsthe biggest single difficulty in the transition from hosts.txt to thedns, however, was not due to any specific shortcoming of the dns.rather, it was attributable to the fundamental change in the nature of thelookup mechanism. in the hosts.txt world, any particular host lookupoperation would either succeed or fail immediatelyñthe hosts.txt fileis located on the userõs system; it is not dependent on internet connectivity at the moment of lookup. the dns added a third possible outcome toany lookup operation: a timeout attributable to any of a number of possible temporary failure conditions (e.g., the required name server is down,so one does not know whether the particular name is indeed in the tableor not). the occurrence of a timeout indicates neither success nor failure;it is the equivalent of asking a yes or no question and being told òaskagain later.ó many of the network programs that predated the dns simply could not handle this third possibility and had to be rewritten. while22users derive benefits from the implementation of negative caching, namely fasterresponse times. the larger system also derives benefits through the reduced load ofinvalid queries. however, there are costs associated with the implementation and maintenance of negative caching. for a given user, if the estimated benefit deriving fromfaster response times is deemed to be worth less than the costs associated with negative caching, then the user is not likely to implement negative caching, even thoughthe total benefits (which include the reduced load of invalid queries on the largersystem) may exceed these costs. this phenomenon is explained under the rubric ofwhat economists refer to as externalities.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution49this was something of a problem for programs intended to be run directlyby a user (e.g., one thenpopular email client checked the host name ofevery recipient during composition), it was a far more serious problemfor programs that ran unattended, such as mail transfer agents. these programs had to be rewritten to handle dns timeout errors in the same wayas they would handle any other form of connection failure. conceptually,this was simple enough, but it took several years to actually track downand fix all the places in all the programs that made implicit assumptionsabout the host lookup mechanism. toward the end of this period, theinternet had entered an era of periodic òcongestion collapsesó that eventually led to a fundamental improvement in certain algorithms used inthe internet infrastructure. during each of these congestion collapses, dnslookups (along with all other forms of internet traffic) frequently timedout, which made it much more obvious which applications still needed tobe converted to handle timeouts properly. to this day, however, correcthandling of the possibility of timeouts during a dns lookup representsan issue in application design.2.3.3convergence in electronic mail systemsin the mid1980s, the internet was one of the major data networks.23although data could not move from one network to the next, email wasable to flowñthrough carefully designed email gatewaysñbetween thenetworks. some of the busiest computers on each network were the machines whose job it was to relay email from one network to the next.24unfortunately, the system of gateways required users to route their email by explicitly using the email address. for instance, to send emailover the internet to a colleague at hewlett packard laboratories on thecomputer science network (csnet), one had to address the email tocolleague%hplabs.csnet@relay.cs.net. this complex syntax says that theinternet should deliver the email to relay.cs.net and then send the message on to the appropriate address on cs.net.25 thus, some people had23these major data networks included bitnet, internet, csnet, uucp, and fidonet.see john s. quarterman, the matrix: computer networks and conferencing systems worldwide,digital press, bedford, mass., 1990; and donnalyn frey, buck adams, and rick adams,!%@: a directory of electronic mail addressing and networks, oõreilly and associates,sebastopol, calif., 1991.24for instance, relay.cs.net and seismo.css.gov, the email gateways between the internetand the computer science network, and an important one of those between the internetand the unixtounix network, respectively, were typically the top two hosts (in termsof traffic sent or received) on the arpanet in the mid1980s.25in some instances, the messages were even messier; someone on the unixtounixnetwork (uucp) might have to write an address such as <ihnp4!seismo!colleague%hplabs.csnet@relay.cs.net> to send an email.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.50signposts in cyberspaceone email box yet had business cards listing three or four different waysto send email to them. there were ample opportunities for confusion andmisrouted email.26the original dns specification tried to address this problem by making it possible to send email to names that were not connected to theinternet. for instance, if the example company was on the uucp network, but wanted to exchange email over the internet, it could registerexample.com and place an entry in the dns directing that all email tonames ending example.com should be forwarded to the uucp emailgateway, which would know to forward the email to the examplecompanyõs email hub.unfortunately, the original dns scheme for email routing was notup to the task. it did not handle certain types of email routing well, and,worse, it could cause email errors that resulted in lost email.the result was a new scheme using mail exchangers (mxs) so that,for any domain name, the dns would store a preferentially ordered list ofhosts that would handle email for that name. the rule is to start with themost preferred host in the list and work down the list until a host is foundthat will accept the email.27 this simple rule could be combined with thedns facility for wildcarding (following rules that state that all names ending in a particular domain, or that a particular subset of names ending ina name, should all get the same response)28 to create email routing foralmost any desirable situation. in particular, it was possible to address e26for instance, at princeton university there was a weekly tape swap between theoperators of princeton.bitnet and princeton.csnetñtwo machines on different networksthat routinely got email accidentally intended for the other.27see craig partridge, òmail routing and the domain name system,ó rfc 974, january 1986, available at <http://www.rfceditor.org>.28for example, in the early days of email connectivity to much of africa, emailhubs were set up inside the countries, serving all users there. these hubs did not havedirect internet connectivity to the rest of the world but were typically served throughoccasional dialup connections that, in turn, usually used nontcp/ip connections. tofacilitate this arrangement, the dns was set up so that all traffic for, say, south africa(the .za cctld), regardless of the full domain name, would be routed to a mailreceiving system in the united states. that system would then open an international dialupconnection at regular intervals and transfer the accumulated email over it. the emailhub in south africa would then distribute the email to other hubs within the country,often using the originally specified domain as an indication of the appropriate domestic server. this model had the added advantage that, when permanent connectivitybecame available, user and institutional email addresses and domain names did nothave to changeñusers just saw a dramatic improvement in service and turnaroundtime. more information on the history of this strategy may be found at <http://www.nsrc.org/> and in john c. klensin and randy bush, òexpanding international email connectivity: another look,ó connexionsñthe interoperability report 7(8):2529,1993, available at <http://www.nsrc.org/articles/930600.connexions>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution51mail to domains that were off the internet, or domains that were partly onand partly off the internet.the development of a dependable and highly flexible mechanism forrouting internet email had two almost immediate consequences. first, allthe other major email networks converted to using domain names ornames that looked like domain names.29 these other networks all hadnonhierarchical (i.e., flat) name spaces, with many of the same scalingproblems that were experienced with hosts.txt, and were looking for aworkable hierarchical name space. once it was shown that the dns wouldwork for email, it was simpler for companies to adopt domain namesand, in some cases, adapt the dns to run on their networks rather than todevise their own naming scheme. thus, within a matter of 18 months to2 years, the babel of email addresses was simplified almost everywherein the world to user@domainname. a second effect was that companiescould now change networks without changing their host names and email addresses, providing incentives for some companies to make theswitch to the internet. indeed, by 1990, almost all the networks that hadoffered services comparable to the internet were either gone or going outof business.30 around the same time, companies began to encourage theiremployees to put email addresses on business cards (it had often beendiscouraged because, as previously noted, email addresses were so complicated). domain names thereafter became a (small) part of everydaybusiness.there were also some longerterm effects. first, it was very clear thatthe dns could provide names for things that were not hosts. for instance,almost every organization soon made it possible to send email tosomeperson@example.com, even though there was no actual machinenamed example.com, but rather a collection of servers (e.g.,mailserver1.example.com, mailserver2.example.com, and so on) thathandled email for the example.com domain. the dns began to beviewed as a general naming system. second, because almost all naming29for convenience and as a transition strategy, many sites chose to treat, for example,òbitnetó and òuucpó as if they were toplevel domain names, mapping those namesthrough the dns or other facilities into gateway paths. so a generation of users believed that, for example, smith@mitvmb.bitnet was an internet domain name when, infact, it was mapped to smith%mitvmb.bitnet@mitvma.mit.edu, where the latter was agateway between the internet and bitnet. the full use of mx records, so that thesame user could be addressed as smith@mitvmb.mit.edu, came along only somewhatlater.30in economics, network effects (or, alternatively, positive network externalities) explain the rationale for the convergence to internetbased email: the value of a network to a user increases as more users join the same network, or other networks thatare compatible with it. see, for example, jean tirole, the theory of industrial organization, mit press, cambridge, mass., and london, 1988, pp. 404409.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.52signposts in cyberspacesystems had been designed primarily to support email, and domainnames had won the battle for how email was done, the other namingsystems diminished in importance and use, leaving the dns as the onlywidely available naming system. the result was that the dns was viewedas a general service, albeit an imperfect one: but even if imperfect, it wasthe only naming system that was widely available, and thus it became theone of choice.2.3.4the whois databasethe whois database was developed in the 1970s to track authorizedarpanet users and, in particular, those users that could request addresses on the network. for each host or domain name, the information inthe whois database was supposed to include the contact information (suchas the contact personõs name, organization, street address, electronic mailaddress, and phone number) of those with responsibility for the host ordomain name; additional information could also be stored and accessed.from a technical design and operational viewpoint, the whois database isindependent of either the hosts.txt file or the dns.31 for a while, thewhois database, maintained by the network information center (nic),served as a de facto white pages directory of arpanet users. beyondthe online database, the nic printed a phone book of everyone listed inthe whois database about once a year until 1982.around the time of the last nic phone book, the whois database wasrapidly losing its value as a white pages directory because many newinternet users were not being included in the database. however, at thesame time, the whois database was becoming increasingly important fornetwork operations because the nic (which at the time also managed theallocation of ip addresses) would not give out an ip address, a host name,or a domain name to anyone who did not have a whois entry. furthermore, the nic put all address and name registrations into the whois database. so, given a host name or address, any user on the network couldquery the database to learn who had control of that host name or address.thus, if a network operator noticed (or had a user complain) that a domain name suddenly could not be looked up, or that a particular networkappeared to be unreachable, the operator could query the whois databaseand find out whom to call about the issue.31òwhoisó represents the name of the implemented system/database as well as thename of the underlying protocol. this caused, and continues to cause, some confusion,since several universities and enterprises maintained local òwhite pagesó and similarservices, which had nothing to do with the central databases, that were accessed usingthe whois protocol.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution53by the late 1980s, problems began to develop with the whois database. the first problem, which proved easy to solve, was that in manycases the formal institutional contact for the name or address was a corporate or university officer or administrator and was not the network operations person who actually managed the network or domain name server.the nic resolved this problem by updating the database to keep track ofboth the administrative and operational contact for each address and domain. the second problem, which was not so easy to solve, was trying tokeep the whois data currentña problem that existed even before the explosive growth of the internet and demands on the dns in the 1990s.322.3.5the dns as a production systemby 1990, the dns was a production system and deeply ingrained inthe internet and its culture.33 the use of hosts.txt was declining rapidly. but the move to a production system was not easy: deploying thedns in the 1980s required several years of debugging and resolving various issues. timeouts and negative caching remain, to some extent, openissues in 2005.several lessons are apparent from the process of developing and deploying the dns. a good new design that solves important problems cancatch on, but it will take time for solid implementations to be developed.and even if a new design offers significant advantages, adoption will taketime. even when the internet was comparatively small, switches fromhosts.txt to dns or from email babel to uniform naming took a significant amount of time. given the decentralized nature of the internet,network service providers, hardware and software vendors, end users, orothers can inhibit worthwhile technical advances from being implementedthrough mere procrastination or a deliberate decision that the implementation of a particular software upgrade is simply not sufficiently beneficial to them. given the much larger scale and scope of the dns and theembedded base of software two decades later, successful implementationof any proposed new system or major changes to the existing dns mayprove difficult.3432the history of the whois database through the 1990s can be found in section 2.5.3.33by the late 1980s, the internet was in fact an operational network and not only asubject of research and, as such, increasingly fell outside darpaõs research mission.at this time, darpa was working with other federal agencies, notably the nationalscience foundation, to hand off the infrastructure it had created.34see tirole, the theory of industrial organization, 1988, pp. 406409, for a brief discussion of the kinds of coordination and strategic issues that can arise in a network likethe dns.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.54signposts in cyberspace2.4continuing growth and evolution of theinternet as a technical infrastructurethe increasing popularity of personal computers changed the basicmodel of computing in most organizations from a model based on centralcomputing using mainframes or minicomputers with terminals to onebased on personal computers connected in local area networks, which inturn were connected to central resources (i.e., the client/server model ofcomputing). the adoption of the personal computer by consumers (whichis correlated with the improving price/performance of computers and, inparticular, increasing modem speeds at affordable prices) provided thehousehold infrastructure for supporting widespread dialin access to theinternet by the mid1990s in the united states.35to function on the internet, a computer needs to have some basic information, such as its ip address, the ip address of at least one router,36and the ip addresses of a few critical services.37 in the world of a relatively small number of large mainframes or minicomputers, such information was entered manually on each new computer when installed and,once configured, rarely changed. in such a world, ip addresses functionedas de facto stable identifiers, with the dns (or its hosts.txt predecessor) representing a convenience, not a necessity.38however, as the number of computers increased sharply, such a custom approach became increasingly impractical. thus, a mechanism to35according to the current population survey (conducted by the u.s. census bureau), personal computer adoption in the united states continued to increase throughout the 1990s and demonstrated a 5fold increase from 1984, the first year data wascollected on computer ownership to the year 2000. by the year 2000, 51 percent, or 54million households, had access to at least one computer at home, up from 36.6 percentin 1997. the percentage of households with internet access more than doubled between these years, from 18 percent in 1997 to 41.5 percent, or 42 million households,by the year 2000. computer access and internet access were becoming synonymous:more than four in five households with computer access also had internet access. forthe full report, see eric c. newburger, òhome computers and internet use in theunited states: august 2000,ó current population reports, u.s. department of commerce,u.s. census bureau, washington, d.c., september 2001, available at <http://www.census.gov/prod/2001pubs/p23207.pdf>.36a router is a device that determines the next internet protocol (ip) network point towhich a data packet should be forwarded toward its destination. the router is connected to at least two networks and determines which way to send each packet basedon its current understanding of the state of the networks to which it is connected.routers create or maintain a table of the available routes and use this information todetermine the best route for a given data packet.37examples include the address of an email server (because most computers do notoperate their own mail server) and the address of a dns resolver (explained in chapter 3).38indeed, the ip addresses of certain important servers were well known to systemadministrators.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution55automate this startup process was developed. one approach is containedwithin the bootstrap protocol (bootp), a very simple protocol that enabled a computer to ask a local central server for and receive a number ofcritical parameters. bootp and other protocols of a similar type sharedone important characteristic: each protocol had a mechanism to allocateip addresses to computers, but did not have any mechanism to reclaim ipaddresses when they were no longer needed. in the 1980s, this was not aproblem because ip addresses were plentiful. however, by the early 1990sip addresses, which had once seemed to be a nearly inexhaustible resource, were starting to look like a scarce resource that required conservation, a consequence of the tremendous growth of the internet. protocols tosupport the òleasingó or temporary assignment of ip addresses were developed,39 such as the dynamic host configuration protocol (dhcp)ñadirect successor of bootpñor the pointtopoint protocol (ppp).40 animportant reason for the development of these protocols was to supportsystem and local area network (lan) management and autoconfiguration, but the timing was fortuitous inasmuch as these protocols could alsohelp with the conservation of ip addresses.the spread of network address translators (nats)ñin part, a response to the increased difficulty of obtaining large blocks of ip addressesin the latter half of the 1990sñfurther degraded the usability of ip addresses as stable identifiers. the basic function of a nat is to rewrite ipaddresses in the data that it forwards. nats map the set of ip addressesfor external traffic (i.e., the ip addresses that are visible to the world) to aset of ip addresses for internal traffic (e.g., an organizationõs lan); thus,an organization can have many more internal ip addresses than externalones. the use of nats distorts the onetoone mapping between internethosts and ip addresses that many applications assumed in their designñthus, any application that depends on ip addresses is at risk when itstraffic goes through a nat.41as a result of these changes, ip addresses have become much lessuseful as stable identifiers than they once were. in the case of most appli39after the lease expires, ownership of the address reverts back to the server thatissued the address. the protocol includes mechanisms for lease renewal, and leasetimes can be quite long at the discretion of the dhcp server administrator. theseòleasesó did not include a financial componentñòtemporary assignmentó is perhaps amore accurate characterization.40ppp supports address assignment for dialup networking by assigning ip addressesto ports on access servers. users connect to the access server and are allocated to aport, which has an ip address assigned to it. thus, users òleaseó the assigned ipaddress for the duration of their session.41in particular, peertopeer applications and security protocols that require differentpublic addresses for each host become much more difficult to deploy.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.56signposts in cyberspacecation protocols, the òobviousó answer has been to replace the use of ipaddresses with dns names wherever possible. thus, over the last decade,applications have come to rely on dns names very heavily as stable identifiers in place of ip addresses.another departure from transparent architecture42 came with the introduction of packetfiltering routers, one of the simplest kinds offirewalls.43 a number of organizations introduced such firewalls beginning in the late 1980s with the intent to defend their sites against variousreal and perceived threats. the muchpublicized morris worm44 furtherraised the profile of network security and provided network administrators with an additional motivation to install firewalls (thereby further inhibiting transparency in the network architecture).45as network security attracted increasing attention, some focus wasdirected to the dns itself. dns security emerged as an issue in the formof a proposed addition of a cryptographic signature mechanism to thedns data.46 such a mechanism would help ensure the integrity of thedns data communicated to the end user. the original dns design didnot include a mechanism to ensure that a name lookup was an accuraterepresentation of the information provided by the entity responsible forthe information. dns information was assumed to be accurate as the result of general notions of network cooperation and interoperation (i.e.,based on the presumption that nobody would deliberately attempt to42in this context, a transparent network is one that does not interfere with arbitrarycommunication between end points.43packetfiltering routers attempt to block certain types of data from entering orleaving a network.44in 1988, a student at cornell university, robert t. morris, wrote a program thatwould connect to another computer, find and use one of several vulnerabilities to copyitself to that second computer, and begin to run the copy of itself at the new location.both the original code and the copy would then repeat these actions in a theoreticallyinfinite loop to other computers on the arpanet. the worm used so many systemresources that the attacked computers could no longer function, and, as a result, 10percent of the u.s. computers connected to the arpanet effectively stopped at aboutthe same time. from òsecurity of the internet,ó available at <http://www.cert.org/encycarticle/tocencyc.html>. also published in the froehlich/kent encyclopedia of telecommunications, vol. 15, marcel dekker, new york, 1997, pp. 231255.45the relative value of firewalls in advancing network security can be debated, andsuch discussions can be found elsewhere; see, for example, fred b. schneider, editor,computer science and telecommunications board, national research council, trustin cyberspace, national academy press, washington, d.c., 1999.46digital signatures do not provide foolproof security, but they can demonstrate thatthe holder of the corresponding private cryptographic key (i.e., a secret password)produced the data of interest. this is more or less like trusting a document that bears aparticular sealñone must independently make a determination that an authorizedperson had possession of the seal when it was used and that the seal is legitimate but,if both of those conditions are met, it provides some assurance of the authenticity ofthe document.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution57tamper with dns information). work on dns security extensions(dnssec) started in the early 1990s and continues more than a decadelater.47 see chapter 4 for further discussion of dnssec and dns securityin general.2.5economic and social value of domain namesthe nature of the growth in the internet during the 1990s was qualitatively different from the growth in the 1980s. most of the new internetusers in the 1990s were nontechnical people who were not associatedwith academic institutions or the computer and communications industry. instead, these new users represented a cross section of society thattypically accessed the internet from their places of employment, throughdialup connections from their homes, and by gaining access through libraries, schools, and community organizations.these new users and the organizations that supported them (such asinternet service providers, electronic commerce companies, nonprofit information services, and so on.) were primarily interested in how theinternet in general, and internet navigation and the domain name system in particular (especially using the world wide web and email), couldadvance and support personal and business goalsñthat is, they were notvery interested in the technology per se. consequently, increasing effortwas directed to support these nontechnical goals, and thus, it is not surprising that economic value, social value, and globalization emerged asmajor forces influencing the dns and internet navigation in the 1990s.2.5.1demand for domain names and emergence of a market48the rapid growth of the world wide web stimulated interest in andthe demand for domain names because web addresses (uniform resourcelocators; urls [see box 6.2])49 incorporate domain names at the top oftheir naming hierarchy. one of the early major uses of the web that appealed to a wide range of the new usersñand helped to continue attracting additional new users to the webñwas electronic commerce. the .comgeneric toplevel domain (gtld) became a kind of directory service forcompanies and their products and services. if a consumer wanted to find47for further information on the historical progression of dnssec, see miek gieben,òa short history of dnssec,ó april 19, 2004, available at <http://www.nlnetlabs.nl/dnssec/history.html>.48a significant portion of this subsection was derived from milton l. mueller, rulingthe root: internet governance and the taming of cyberspace, mit press, cambridge, mass.,and london, 2002.49examples of urls include <http://www.whitehouse.gov> or <http://www.un.org>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.58signposts in cyberspacethe web site for a company, the consumer would often be able to guessthe url by entering part or all of the companyõs name followed by .comin the browser command line; often, the desired site would be located.this practice was further encouraged by the use of secondlevel domainnames in advertisements and by the naming of companies by their secondlevel domain name (e.g., priceline.com). even if the userõs initialguess(es) did not work, users would often then try the companyõs namefollowed by .net or .org, or variations of the companyõs name in combination with one of these gtlds, such as ibmcomputers.net.50it did not take users long to discover that shorter, shallower, urlswere easier to guess, use, remember, and advertise than longer ones. theshortest url of all was based solely on a domain name. thus, if onewanted to post a distinct set of resources on the web, or create an identityfor an organization, product, or idea, it often made sense to register aseparate domain name for it rather than create a new directory under asingle domain name. hypothesizing that customers would look for products and services by guessing at a similar domain name, companies likethe procter & gamble company, for example, registered pampers.comand used that as a url (namely, <http://www.pampers.com>), which alsohad the advantage of being much easier to communicate to users, and for usersto remember, than, say, <http://www.pampers.procterandgamble.com>.these different domain names would be used even if all the informationresided on a single computer. in short, domain names began to refer toproducts or services rather than just network resources (e.g., host names).51before the rise of the web, the largest concentration of domain nameregistrations was under the .edu tld (as of march 1993). the internetõsrapid growth after 1993, however, radically altered the distribution of domain names across tlds; until at least 1997, .com attracted the large majority of new domain name registrations.52 most of the users rushing to take50sometime in 1996 or 1997, browser manufacturers made .com the default value forany names typed directly into the browser command line. that is, whenever a usertyped <name> without a toplevel domain into the command line, the browser automatically directed the user to www.<name>.com. making .com the default value forall browser entries reinforced the value of .com registrations relative to other tlds. ineffect, a .com domain name functioned as a global keyword, and the possession of acommon, simple word in the .com space was sure to generate significant traffic fromweb browsers. this explains, to some degree, why some domain names sold for hundreds of thousands or even millions of dollars. as noted in section 1.2, footnote 9,browsers no longer operate in this way.51generic words were also registered (e.g., cough.com was registered by vicks).52see <http://web.archive.org/web/20020816085435/www.wia.org/pub/timeline.txt>.initiatives to use the internet for commercial purposes (including r&d within companies)before the rise of the webled to anincrease in .com registrations.and with wide use of thewebcame registrations of multiple domain names to single companies, a practice that hadbeen discouraged in the past.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution59advantage of the web were businesses, and .com was the only explicitlycommercial toplevel domain. furthermore, the u.s.based internic operated the only unrestricted, largescale registry (supporting .com and othergtlds). most countrycode registries at this time were slow, or expensive,or followed restrictive policies and considered a domain name a privilegerather than a commercial service.53 indeed, in some of the countries withrestrictive countrycode registries, such as japan and france, more businesses registered in .com than under their own cctld. the available statistics provide the basis for estimating that roughly 75 percent of the worldõsdomain name registrations resided in .com at the end of 1996.54 thus, the.com tld became the dominant place for domain name registration worldwide in the mid1990s, which by the late 1990s became reflected in popularculture through phrases such as a òdotcom companyó (or simply a òdotcomó) or òdotcom economy.óinterest in domain names extended beyond the forprofit sector. thevisibility of governmental entities and nonprofit organizations also became increasingly tied to domain names as the web became a key mechanism for providing information and services to the public and their constituencies. moreover, individuals also wanted their own domain nameas the identifier for their personal information posted on the web or for amyriad of other purposes (e.g., establishing fan sites55). opportunisticcompanies capitalized on (and perhaps helped to create) this demand bydeveloping services so that users could register a domain name and obtain support for establishing and maintaining a web page as an integratedservice for a monthly or annual fee.domain names also became involved in electoral politics and socialcommentary. political campaigns established web sites with descriptivedomain names in the urls such as <http://www.algore2000.com> or<http://www.georgewbush.com>56 to provide access to information53in february 1996, when the internic had about a quarter of a million secondlevelregistrations, germany (.de) had only 9000 total registrations, and great britain (.uk)had only 4000. japan, canada, australia, and other major leading participants in theinternet had numbers comparable to the united kingdomõs. however, some countries(e.g., the united kingdom) have restrictive policies with respect to registering in thesecondlevel domain so that most entities actually have to register in the thirdleveldomain (e.g., sothebys.co.uk) that would instead be a secondlevel domain registration in other tlds (e.g., sothebys.com).54internic gtld registrations accounted for an estimated 85 percent of all domainname registrations worldwide, and .com accounted for 88.6 percent of all internicgtld registrations. (about 62 percent of all registered domains worldwide resided in.com in 2002.)55see, for example, <http://www.juliaroberts.de>, a fan site and tribute to the actress julia roberts that is based in germany; accessed on april 16, 2005.56note that campaign information was not available at the al gore site as of april 16,2005.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.60signposts in cyberspaceabout their respective candidates, to organize volunteers, and to solicitcontributions. web sites were also created to critique or parody virtuallyanything, from the practices of certain companies or their products or services to various social and political causes. a common practice was toregister a domain name that included the name of interest followed byòsucks,ó or something similar, and to associate that domain name with aweb site that criticized the entity in question. in addition to motivatinglegal actions to try to prevent the use of domain names in this fashion, thispractice caused many companies to preemptively register these types ofdomain names for themselves.57therefore, for various reasons, the demand for domain names increased tremendously during the 1990s.58 further fueling the demand wasaggressive marketing by companies that register domain names and provide related services, efforts by it companies more generally that playedup domain names (especially .com names) in their larger marketing campaigns, and the popular and technical press, which devoted a lot of attention to anything related to domain names.the increasing demand for domain names was attributed to interest infacilitating internet navigation as well as to the value of domain names irrespective of their functional utility on the internet (e.g., placing a domain nameon posters in a subway station as a part of a marketing campaign). thus, thereal value of certain domain names in the rapidly growing and commercializing web and internet was far greater than the price of setting up a domainname (which was on the order of $50 at the retail level).59 the predictableconsequence was the development of an aftermarket for certain domainnames. in 1996, tv.com sold for $15,000 and in 1997, business.com changedhands for $150,000.60 not surprisingly, speculation in the registration of domain names took place: an individual or firm would register domain names(often very many) with the intent of reselling them to others for a premium.such speculators would not only register generic or descriptive names (e.g.,òbusiness,ó òfever,ó and so on) with the hope of appealing to multiple pro57however, this was a difficult proposition, considering the nearly limitless variations oflessflattering names that can be devised. see further discussion in the next section.58the growth in the registration of domain names was phenomenal. for example, in september 1995, there were approximately 120,000 registered domain names. by may 1998, 2million domain names were registered. see òfact sheet: nsf and domain names,ó nationalscience foundation, arlington, va.59domain names are registered through and maintained by registrars; see chapter 3 for anextended discussion.60business.com was resold for $7.5 million in 1999. with some irony, the committeeobserves that www.business.com links to òthe business search engineó (as of march27, 2004), a òcomprehensive business directory.ósignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution61spective purchasers, but would also register domain names incorporating thetrademarks of third parties with the hope that the corresponding trademarkowner would purchase the domain name from the speculator as well. seebox 2.1 for further discussion on the value of domain names.an industry emerged to provide services related to the transfer andassignment of domain names and related services.61 the pressure for newtlds led to the conversion of some country codes to quasigeneric tlds.for example, the marketing of .cc (a countrycode tld created to representthe cocos islands but later marketed as a de facto gtld) further increasedthe variety and value of certain domain names. however, true additionalgtlds did not materialize in the 1990s (despite the intense arguments andefforts made by some individuals and organizations), which helped to solidify the dominance of the thenextant tlds, especially of .com.622.5.2the rise of conflicts over domain namesas the number of domain name registrations exploded, conflicts developed over the right to register particular names at the second level ofmany of the tlds.63 the basis for most of these conflicts derived from theunique naming associated with the dns. the dns does not have the capability to incorporate context into domain names, so each domain name must beunique worldwide and then in turn, a web site at that domain name can thenbe accessed throughout the world.64 the consequence is that it is significantlyharder to pick a domain name that is both unused and memorable.claims to rights to domain names can be based on a number of different legal, political, economic, ethical, or cultural criteria. a common prob61registrars, and the industry surrounding registrars and allied services, are discussed indetail in chapters 3 and 4.62discussion of the gtlds added in the early 2000s (e.g., .info) and general discussion ofthe issues involved with adding new gtlds can be found in chapters 3 and 4.63òrights to namesó refers to claims to exclusive or privileged use of an identifier based onthe meaning or economic value of the name.64the mythical (or perhaps real) joeõs pizza illustrates the point. the dns can support only one www.joespizza.com worldwide, but in the physical world, people canusually distinguish among the (presumably) multiple joeõs pizza restaurants aroundthe world. if a person is located in the center of a city and asks a taxi driver to take herto joeõs pizza, it is presumed that she wishes to travel to a restaurant within a fewmiles, not a joeõs pizza located in a city 2000 miles away. although the requestor doesnot state this context explicitly, it is assumed in the conversation. as of february 4,2005, joespizza.com was registered by buydomains.com and offered for resale at aminimum price of $1488.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.62signposts in cyberspacebox 2.1the value of domain namessemantic valueeconomic value often arises when names have some semantic distinctionña meaningñand are visible in a public arena. the value of meaningful names will differ from nil to very high depending on the meaning andthe potential application. examples include sex.com and gardentips.com.mnemonic valuein many contexts, it can be important for a name or identifier to beeasily remembered. if users cannot remember the name, or it is too long orcomplicated to reproduce, the object will not be found. memorability, andin some cases guessability, facilitates more incoming traffic and more business and, therefore, gives rise to economic value. one example is gm.com(i.e., a secondlevel domain name for the general motors corporation).personal valueeven when there is no apparent commercial consequence, the humandesire to make a statement and assert an identity can give economic valueto identifiers in a public name. someone with a high regard for himselfmight want the domain name iamthebest.com.1stability valueusers can accumulate equity in a particular identifier, which becomesclosely associated with them and expensive to change. changing a telephone number or email address that has been used for many years can beburdensome because of the large number of personal contacts and recordsthat contain the number. thus, equity in an identifier raises switching costsfor consumers, making them more likely to stay with the provider of thatidentifier.pure scarcity valuemeaningless identifiers, such as bank account numbers, function economically as an undifferentiated resource pool. they may possess economicvalue by virtue of their scarcity, but no one cares which particular identifierhe or she gets. in the dns, there are plenty of possible names (accepting thatrandom strings of letters and digits can produce domain names (e.g.,akwoeics8320dsdfa0867sdfad02c.org); there is scarcity of some desirednames, with desirability defined by one of the reasons above (e.g., only asmall subset of all possible domain names have semantic value).1as of march 27, 2004, this domain name was not registered.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution63lem raised by all such claims is that any reasonable attempt at resolutionmust balance the value of avoiding confusion or preventing illegal or otherwise undesired appropriation of identity against the value of free expression, open communication, and fair use. whenever semantics and economics enter the picture, however, society and all of its conflicts comealong with them. the resultant conflicts over who has rights to use particular domain names has enmeshed and continues to enmesh apparentlytechnical naming processes in economic, public policy, and legal issues.65trademark conflicts in the commercial world, trademark law provides one of the oldest,most widely recognized and welldeveloped regimes for recognizing andprotecting exclusivities in the use of source identifiers of goods or serviceswithin specific fields and territories. trademark laws developed, in part,to protect consumers against various forms of fraud, deception, or confusion that might result from the ways in which products and services areidentified. by giving producers an exclusive right in an identifier, trademarks reduce consumer search costs and channel the benefits of developing a good reputation to the producer responsible for the reputation.trademark protection is not, however, intended to give firms ownershipof common words alone, to prevent noncommercial or fair use, or to inhibit public discussion of companies, products, and services involvingdirect references to the mark.the great emphasis placed on secondlevel domain names created aproblem for some trademark holders, especially for those that held trademarks that were well known in the united states or worldwide. trademark rights (which are traditionally accorded on a country by countrybasis) generally arise through use of a trademarkable name, logo, color,sound, or other feature, in association with the marketing and sale of particular types or classes of goods and services in commerce. some coun65in his paper òexternal issues in dns scalability,ó paul vixie argues for eliminating thedisputes associated with domain names by eliminating all meaningful toplevel domainsand replacing them with meaningless alphanumeric identifiers. see conference paper, november 11, 1995, available at <http://www.ksg.harvard.edu/iip/giiconf/vixie.html>.whereas the number of conflicts would surely decline, so, too, would the benefits to thosewho prefer specific domain names that have meaning or some other characteristic. as withphone numbers, however, competition for certain numbers will ensue unless they are assigned randomly and a secondary market (in either names or entities that control names) isprohibited.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.64signposts in cyberspace66this also means that the failure to use a registered mark can result in the loss of rights.67see j. thomas mccarthy, mccarthy on trademarks and unfair competition, 4th ed.,¤ 24:88 (2003), clark boardman callaghan/west, deerfield, ill., 1992.68see mccarthy, mccarthy on trademarks and unfair competition, ¤ 24:88 (2003). anexample would be if mack trucks, inc., began using the mark òbig macó in association with a new model of truck. it is unlikely that the mcdonaldõs corporation wouldargue that there was a likelihood of consumer confusion between mackõs truck andmcdonaldõs large sandwich of the same name. however, it is possible that the mcdonaldõscorporation would argue that the truck model was diluting the value of its famousmark, big mac.69these factors include òthe degree of inherent or acquired distinctiveness of themark,ó òthe duration and extent of use of the mark in connection with the goods orservices with which the mark is used,ó and òthe duration and extent of advertisingand publicity of the mark.ó see 15 u.s.c. ¤ 1125(c)(1).tries will allow someone to reserve or even register a trademark withoutusing it, but most countries (including the united states) require use toclaim protection under trademark law.66 similar to trademarks, domainnames can act as sourceidentifiers suggesting the identity, quality, orsource of a good or service. accordingly, domain names may conflict withtrademarks because of their similarity in function.if a trademark holder allows someone else to use the trademark ormark either in the same class of goods/services or in some other way thatcould create confusion in the marketplace, the other party may begin toacquire rights as a result of that use, and those rights reduce the value ofthe mark to its original owner. within the united states, the problem isfurther complicated by the existence of federal and state antidilution lawsthat permit owners of famous marks to enjoin others from commercialuses of such marks, even where such commercial uses are in classes ofgoods or services different from that of the famous mark.67 designed toprevent the whittling away of the identification value of the plaintiffõsmark, antidilution laws differ from more traditional trademark laws,which are designed to prevent consumer confusion within the same classof goods or services.68 in order to determine whether a mark is subject tofederal antidilution protection (i.e., whether it is considered to be a famous mark), the law provides several nonexclusive factors that may beconsidered.69 some states within the united states have more generousdefinitions of òfamous marks,ó while other countries have similar or different definitions or do not recognize the concept at all. another one ofthe factors to be used in this determination under u.s. law is òthe natureand extent of use of the same or similar marks by third parties.ó thisfactor demonstrates that a potentially famous mark ownerõs antidilutionrights, like rights against infringement, can be lessened or lost by its failure to police its mark.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution65thus, trademark holders became quite concerned about the activitiesof parties that had registered domain names that either were confusinglysimilar to their trademarks or diluted their famous marks. generally, tocause a likelihood of confusion under trademark law,70 a domain namemust be used in connection with an offering of goods and services or itmust be used commercially for antidilution laws to apply, butcybersquatters raised a slightly different problem. cybersquatters are generally defined as domain name speculators who register a domain namethat incorporates a trademark owned by another party, not in order to usethe domain name, but with the intent of reselling the registered domainname to that party for an amount that far exceeded the cybersquatterõsregistration cost. the most contentious examples of cybersquatting werethose in which domain names incorporating trademarks (or phonetic ortypographical variants of them) were associated with web sites that included pornographic content or other information that would confuse oroffend users who reached that web site by mistake or assumed that thetrademark holder had registered the domain name and that the web siteassociated with it belonged to the trademark holder. the cybersquatterwould then offer to sell the domain name to the trademark owner for asubstantial sum, which some companies agreed to pay, if for no otherreason than to stop the offending use. such actions, of course, only fueledmore cybersquatting activities. cybersquatters also figured out that userswere trying alternative domain names (e.g., ibmcomputers.com insteadof ibm.com) and began to register many different combinations, such asibmcomputers.com and ibmcomputer.com. partially in response to theseactions, many companies began to register various combinations themselvesñsocalled preemptive registrations71ñand to seek remediesthrough the courts, various dispute resolution processes, and legislativeaction.72at least one court has held that a cybersquatterõs registration of a domain name that incorporated a plaintiffõs famous mark, without the saleof any goods or services via the web site associated with that domainname, was a violation of the federal antidilution statute because the defendant made òcommercial useó of the trademark when he attempted to70see mccarthy, mccarthy on trademarks and unfair competition, ¤ 25:76.71such preemptive registrations were encouraged by the marketing strategy of many registrars.72in fact, the congressional mandate (p.l. 105305) for this study came largely as a result ofactions by representatives of the trademark community. this community was very activeand visible in the domain names arena in the late 1990s.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.66signposts in cyberspacesell the domain name back to the owner of the famous mark.73 anothercourt has found the attempted sale or licensing of domain names containing trademarks to be trademark infringement, similarly concluding thatthe sale of these domain names was a commercial use of the marks.74additionally, the anticybersquatting consumer protection act (acpa),enacted in 1999,75 provides additional rights to trademark owners againstthose who register, traffic in, or use, with the badfaith intent to profit, adomain name that is identical or confusingly similar to a registered orunregistered mark that was distinctive or dilutive of a famous mark whenthe domain name was registered. despite the creation of acpa and otherdomain name dispute resolution mechanisms,76 the costs involved withpreemptive registrations and the enforcement of trademarks ultimatelyled many representatives of trademark holder interests to resist efforts tocreate new tlds, fearing that these costs would continue to increase substantially if new additional tlds were created.in contrast, the protective efforts by trademark holders in some instances have also raised conflicts with other legally equivalent rights heldby the individuals using the domain names. for example, suppose a groupcritical of a corporation wants to create a public space for discussion andregister a domain name associated with that corporation (e.g.,companyname.org). does such a registration constitute an infringementof the corporationõs trademark because it creates consumer confusion oris it dilutive because it tarnishes the reputation of the corporation, orrather is it an exercise of a protected right, such as freedom of speechunder the first amendment of the u.s. constitution? discussions relatedto domain names, trademark concerns, and public policy issues will continue into the 21st century.77other conflicts involving trademarks arose for reasons that had nothing to do with the abovedescribed conflicts between trademark holdersand their cybersquatting antagonists. for example, chris van allen, then12 years old, registered the secondlevel domain name pokey.org becausepokey was his nickname, and was subsequently ensnarled in a trademarkdispute with prema toy company, owner of the trademarks on theclaymation character gumby and his horse pokey, which wanted control73see intermatic, inc. v. toeppen, 947 f. supp. 1227 (n.d. ill. 1996).74see toys òró us, inc. v. abir, 45 u.s.p.q.2d 1944 (s.d.n.y. 1997).75see 15 u.s.c. ¤ 1125(d).76see section 3.5 for an extended treatment.77the state of understanding continues to evolve. see, for example, the taubmancompany v. webfeats, et al., nos. 012648/2725 (6th circuit, february 7, 2003).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution67over the domain name.78 ultimately, prema toy company withdrew itscomplaint.79 in other cases, disputes arose between different entities withequally valid rights to the same secondlevel domain name, such asòbob.com,ó which might have been coveted by many men named robert,and òavon.com,ó which might have been coveted by a variety of differentcompanies around the world that have legitimate rights to the trademarkavon for different products or services in different countries.this latter example presents a particularly difficult point that cannotbe easily resolved by simply granting the secondlevel domain name tothe entity with the legal right to use it as a trademark, since multiple entities can have such legitimate rights. under most countriesõ trademarklaws, multiple entities can use the same trademark in the same country,provided each entity uses the trademark for different categories (calledclasses) of goods or services, as long as there is no possibility of confusingconsumers as a result, and each trademark has to be registered withineach country in which it is used in order to be fully protected. hence it isentirely possible to have one company legitimately use the trademarkòavonó for automotive tires in the united states, and a second companyto use the same trademark for cosmetics. unfortunately, however, therecan be only one avon.com, and so the first entity to register that domainname has often been able to use it to the exclusion of all other legitimateusers worldwide.80beyond trademark conflictstrademark issues dominated domain name conflicts in the late 1990sand into the beginning of the 21st century, but other conflicts also demanded attention. for example, some governments asserted rights to control the assignment of countrycode tlds and country names and theregistration of those names, even beyond the second level.81 some governments assert that this is an extension of national sovereignty. similarclaims may be asserted by ethnic groups and indigenous tribes that have78see courtney macavinta, òshort take: pokey causes net trademark uproar,ó news.com,march 23, 1998, available at <http://news.com.com/21101023209417.html?legacy=cnet>.the dispute also involved pokeyõs network consulting, which registered pokey.com.79see heather mccabe, òpokey wins his domain name,ó wired news, april 22,1998, available at <http://www.wired.com/news/business/0,1367,11846,00.html>.80see chapters 3 and 5 for a discussion of how trademark conflicts over domainnames can be (and should be) managed.81see the principles for delegation and administration of cctlds presented by theicann government advisory committee, february 23, 2000, available at <http://www.icann.org/committees/gac/gaccctldprinciples23feb00.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.68signposts in cyberspacenot achieved the political status of sovereigns, but that nevertheless wishto protect or control the use of their collective name. in some jurisdictions,the subunits of national governments, such as city administrations or portauthorities, have claimed exclusive rights to the use of their name in thedns.82 in a similar vein, some international organizations have asserteda right to prevent others from registering domain names identical to theiracronyms or names.83 these claims have more to do with the imputedlegitimacy of the association than with commercial confusion. here, too,issues arise regarding the balance struck between the use of the name asan identifier and its legitimate use as a reference to the identified entity.these claims also raise questions about who in the affected society has theright to control the name. also, some legal regimes, which are analogousto trademark law because they are related to reputation in commerce, attempt to vest regions or localities, rather than specific firms or products,with exclusive rights to a name for a certain use. these regimes of òcontrolled appellations of originó might be applied, for example, to wines orother agricultural products.84in addition to nations, regions, and international organizations, manypeople feel that they have some ownership right over their personal nameand other aspects of their persona. national systems of law often recognize òrights of personalityó when defined as the ability of a person òtocontrol the commercial use of his or her identity.ó85 in the united states,there currently is no federal right of publicity or privacy; rather, the promulgation of such laws has been left to the states. about half of the stateshave recognized the right of publicity, either through common law or statute.86 other states provide similar protections as a part of the right of82see, for example, excelentisimo ayuntamiento de barcelona v. barcelona.com inc., wipocase no. d20000505, available at <http://arbiter.wipo.int/domains/decisions/html/2000/d20000505.html>; and salinas, california, national arbitration forum, city of salinas v. brian baughn, wipo case no. fa0104000097076, available at <http://www.arbitrationforum.com/domains/decisions/97076.htm>.83for example, international organizations such as the international monetary fund(imf) or the world health organization (who). see the recognition of rights and theuse of names in the internet domain name system, report of the second wipo internetdomain name process, september 3, 2001, available at <http://wipo2.wipo.int/process2/report/pdf/report.pdf>.84for further discussion see, ògeographic identifiers,ó in the recognition of rights andthe use of names in the internet domain name system, 2001.85see mccarthy, mccarthy on trademarks and unfair competition, 4th ed., 1992.86see, for example, carson v. natõl bank of commerce, 501 f.2d 1082, 1084 (8th cir.1974) (recognizing a commonlaw right of publicity in nebraska); and fla. stat. ann.¤540.08 (west 2002) (providing for a statutory right of publicity in florida).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution69privacy.87 under the restatement (second) of torts ¤¤ 652a  652c (1979),invading an individualõs right of publicity is similar to invading her privacy through unauthorized appropriation of her name or likeness.88one of the primary motives behind passage of the anticybersquattingconsumer protection act in the united states, for example, was the widespread registration of the names of u.s. politicians as domain names andtheir linkage to web sites that were satirical or critical.89communications technology can create new arenas for disputes overrights to names. in particular, the process of entering an identifier into anetwork creates numerous opportunities for conflicts over the boundaryof a name right. of course, many of the underlying issuesñconfusion,fraud, competition, fair use, freedom of expressionñare familiar fromother contexts.a good part of the advertising economy of the internet is based onpaying for òhitsó (i.e., the exposure of the content of a web site to a distinct user).90 thus, the practice of òtyposquattingó developed, whereinentrepreneurs registered domain names that were only a keystroke or two87see, for example, allison v. vintage sports plaques, 136 f.3d 1443 (11th cir. 1998)(describing the appropriation of plaintiffõs personality for a commercial use as aninvasion of privacy tort in alabama).88in 1953 in the case of haelan labs. v. topps chewing gum, the right of publicity wasfirst explicitly recognized as a right independent of the right of privacy and as anindividualõs right to the publicity value of his photograph. the court distinguished theright of publicity from the right of privacy because òmany prominent persons . . . farfrom having their feelings bruised through public exposure of their likeness, wouldfeel sorely deprived if they no longer received money for authorizing advertisements[or] popularizing their countenances.ó see haelan labs. v. topps chewing gum, 202 f.2d866, 868 (2d cir. 1953). thus, the right of publicity has developed into a body of lawdistinct from, but related to, copyright law, privacy rights, and the law of unfaircompetition. while certain states encode publicity rights within their right of privacystatutes, prominent case law and jurisprudence acknowledge the development of theright of publicity as an independent body of law. see, for example, carson v. hereõsjohnny portable toilets, 698 f.2d 831, 834 (6th cir. 1983) (stating, ò[t]he right of privacyand the right of publicity protect fundamentally different interests and must be analyzed separately.ó). when commercial exploitation of names is involved, personalityrights often overlap with, or are informed by a logic that parallels, trademark rights.indeed, a personõs name is often registered as a trademark or used to brand productsor services (e.g., michael jordan). but rights of personality are often asserted evenwhen commerce is not directly involved.89u.s. patent and trademark office, òreport to congress: the anticybersquattingconsumer protection act of 1999,ó january 2000. a law passed by the state of california makes it illegal to register someone elseõs name as a domain name òwithout regardto the goods and services of the parties.ó see section 17525 of the california businessand professions code, at <http://www.leginfo.ca.gov/cgibin/displaycode?section=bpc&group=1700118000&file=1752517528.5>.90see section 7.2.2 for an extended discussion.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.70signposts in cyberspaceapart from popular domains. these òtypoó domains would then be linkedto advertisements in order to collect payperhit revenue from people whomistyped the locator into the browser. the cybersquatter john zuccarinirefined the practice of òtyposquattingó to an art, registering hundreds ofclose misspellings of popular domain names and trapping users into aparade of cascading web pages, some of them pornographic.91there are even fuzzier boundaries to consider. there are businessesthat register large collections of expired domain names in order to collectadvertising hits from people who are looking for the old web site.92 isthis an abusive practice or one as innocent as putting up a billboard on achoice spot on a busy highway?beyond secondlevel domain namesthus far, the discussion has focused on secondlevel domain names.although less common, there are disputes involving third, fourth andhigherlevel domain names, as well as involving directory and file descriptors. for example, in bally total fitness holding corp. v. faber, 29 f.supp. 2d 1161 (c.d. cal. 1998), an infringement suit was brought againsta defendant who used the url <http://www.compupix.com/ballysucks> to post critical comments regarding the plaintiff. the courtheld that òno reasonable consumeró was likely to confuse the defendantõsdomain name with the plaintiffõs marks bally, bally total fitness,and ballyõs total fitness, because, among other things, the defen91see, for example, joanna glasner, òtypoloving squatter squashed,ó wired, october 31, 2000, available at <http://www.wired.com/news/business/0,1367,39888,00.html>.in 2004, zuccarini was sentenced to 30 months in prison for using misleading domainnames to trick children into visiting pornographic web sites in violation of the federaltruth in domain names act. see òu.s. man jailed for luring children to porn sites,óreuters, february 26, 2004.92other cases include attempts to protect the ònonproprietaryó status of a name byexcluding it from a name space. the world health organization and the world intellectual property organization (wipo) proposed to do this with respect to international nonproprietary names (inns), a list of over 3000 names of pharmaceuticalsubstances. see òinternational nonproprietary names (inns) for pharmaceutical substances,ó in the recognition of rights and the use of names in the internet domain namesystem, report of the second wipo internet domain name process, september 3, 2001,available at <http://wipo2.wipo.int/process2/report/pdf/report.pdf>. this proposalis particularly problematic because the list of inns not only is long, but also expandsover time.religion is another potential source of rights claims. certain religions recognizewords as sacred and attempt to protect or restrict their use.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution71dant did not use the plaintiffõs mark in his domain name.93 based on thefacts of the case, the court stated that the result would have been the sameeven if the defendantõs domain name was ballysucks.com.94 the courtalso contrasted the defendantõs domain name and the hypothetical secondlevel ballysucks.com domain name with other cases where likelihood of confusion was found when the plaintiffõs mark was the only mark(e.g., panaflex.com) used in the defendantõs secondlevel domain.95in another example, the usenet newsgroup name space contains numerous descriptors that use a variety of names to describe the space, including, for instance, the name disney (e.g., alt.disney.disneyland orrec.arts.disney.parks). these newsgroups (which are visible to mostinternet users) are not run by the disney corporation, and the contentand administration of the group may or may not have the corporationõsapproval. in the even more freewheeling world of aol screen names, anyuser can appropriate the name of his or her favorite disney character (evenin less than flattering variations) and use it as his or her screen name andemail address. while it is clear that no exemption exists for usenet groupsand aol screenname aliases, it does appear that trademark holders havechosen not to pursue many of these uses in these naming spaces.96yet current law and policy regarding domain names erect major distinctions between the various parts of the domain name used in a url.within the generic and most countrycode toplevel domains, all (or atleast most) of the political and legal conflict over rights to names takesplace over the secondlevel domain name. the thirdlevel domain and allidentifiers to the right of the domain name are generally outside the scopeof challenge through dispute resolution processes.97 current law andpolicy therefore regard the toplevel domain as a fixed set of generic cat93see the recognition of rights and the use of names in the internet domain name system, 2001, pp. 11631165.94see the recognition of rights and the use of names in the internet domain name system, 2001, p. 1165.95see the recognition of rights and the use of names in the internet domain name system, 2001, p. 1165.96many trademark holders have not done anything regarding many newsgroup names,in part because it is difficult to police such activities as well as prove that trademarkinfringement or dilution has occurred. indeed, as soon as a name was removed orchanged in this space, another of the millions of users could create a new one.97there are some important exceptions, such as the case of .uk, for which most entities register at the third level (e.g., disney.co.uk) rather than at the second level. forthese exceptions, it is the fourth level and beyond that are outside the purview ofdispute resolution processes. dispute resolution processes are further described inchapters 3 and 5.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.72signposts in cyberspaceegories or country codes, the secondlevel domain as the identifier of anorganization, product, or web site, and the thirdlevel domain as part of aòprivateó naming system, wherein assignments can generally be left tothe discretion of whoever holds the secondlevel name.to further illustrate this point, yahoo! inc. has been an active defenderof its brand name in cyberspace. it has challenged the registration of hundreds of secondlevel domains, including some rather remote misspellings, such as òjahuó or òyhuu,ó whenever they appear in the second levelof a domain name. but under current legal precedent, it would likely takeno action against a name such as yahoo.blatant.cybersquatter.com. inall likelihood, however, yahooõs decision not to pursue claims for trademark infringement or dilution for alternative uses of its brand name andmark is less influenced by current precedent than it is by yahooõs likelihood of success on the merits, especially in view of decisions such as thatin the above noted bally total fitness holding corp. v. faber case.by contrast, secondlevel domain names are ripe for generating conflicts over rights to names. they are meaningful, they are perceived asbeing economically valuable, and they are part of a global, public namingsystem administered via collective action. and perhaps most importantly,they are susceptible to centralized control because of the existence of asingle, central point of coordination, the relevant registry. see box 2.2.2.5.3whoisin concert with the rise in the interest in and demand for domainnames was a corresponding increase in the value of contact informationassociated with domain names. hence, interest in the whois database continued to rise in the 1990s.some of the targeted uses of the whois data were for oldfashionedmarketing purposesñfor example, to send sales brochures and to maketelephone solicitations to network operators and domain name registrants.as domain names became economically valuable after 1995, accessingwhois data also became a popular way to find out which domain nameswere taken, who had registered them, and the creation and expirationdate of the registration. the whois database also became an investigationand monitoring tool for intellectual property rights holders. when a trademark holder discovered a potentially infringing domain name, the trademark holder could use the whois database to identify, investigate, andcontact the registrant of the domain name. at that time, the whois database could also be used to determine if the same registrant had registeredany similar domain names that the trademark holder did not know aboutor to search for further evidence of cybersquatting by the registrant. trademark holders also discovered that they could use the database proactivelysignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution73to perform searches for character strings that matched trademarks, andretrieve many of the domain name registrations in the generic topleveldomains that matched or contained a trademark. this automated searching function proved to be so valuable that trademark interests began todemand that the whois functions be institutionalized, expanded, and subsidized, including the right to purchase the complete list and contact datafor all of a registrarõs customers. the first world intellectual property organization (wipo) domain name process, initiated in 1998 in response toa u.s. government request, as detailed by a u.s. commerce departmentwhite paper,98 recommended that the contact details in a whois record becontractually required to be complete, accurate, and up to date, on penalty of forfeiture of the domain name.992.6globalizationworldwide interest in the dns developed during the 1990s along withincreasing concern about u.s. dominance of a critical element of globalcommunication and a commercial resource on which other nations fore98for the text of the white paper, see <http://www.ntia.doc.gov/ntiahome/domainname/6598dns.htm>.99see paragraph 73 of the management of internet names and addresses: intellectualproperty issues. final report of the wipo internet domain process, april 30, 1999, available at <http://wipo2.wipo.int/process1/report/finalreport.html#49>.box 2.2the institutionalization of .comfor the most part, the initial dominance of .com among the tlds was ahistorical accident, a product of the chance conjunction of the commercialization of the internet, the rise of the web, the openness of the internicregistry relative to the cctld registries, and the lack of any other commercially oriented tld in the original set of gtlds. once .com became established as the most desired tld for many registrants, other forces contributed to the solidification of .comõs increasing dominance. as discussedelsewhere in this section, òbeyond secondlevel domain names,ó the risein value of .com names (whether for navigation or marketing functions) ledto the registration of some domain names for speculative, abusive, or preemptive purposes. based on a desire to avoid further registration of domainnames for these same purposes in new tlds, some resistance developed tothe creation of new tlds, thereby reinforcing the focus on extant tlds(with disproportionate advantage to .com , given its dominant market position). whether the historical dominance of .com from the mid1990s willcontinue in the future of the dns is discussed in section 5.4.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.74signposts in cyberspacesaw their economies and societies becoming ever more dependent. withincreasing recognition of this value came a growing desire to participatein the management and policy decision making with respect to domainnames.an issue of particular interest in many countries is access to theinternet and the dns using homecountry languages other than english.as the number of users whose first language is not based on roman characters grew dramatically during the 1990s, interest developed in domainnames based on nonroman scripts (e.g., chinese, hebrew, arabic, andso on). several major efforts have been undertaken to accommodate internationalized domain names (idns) within the internet infrastructure.100the design of the dns, however, presents formidable technical challenges for the accommodation of languages that use nonroman characters. as a lookup system, the dns must be able to determine unambiguously whether or not there is a match with a query. comparing strings ismuch more difficult than most people realize, because the definition ofwhat is òequaló is often not deterministic. for the french language incanada and in france, for example, there are different rules as to whetheran accent stays over a character when it is converted from lower to uppercase. and some languages (e.g., chinese) cannot be reduced to a relativelysmall number of standardized characters (e.g., the character set for english). see section 4.3 for further discussion of the idn issue and the increasing interest and involvement by parties outside the united states inmatters related to the dns.2.7administration of domain namesin the 1980s, the network information center managed the registration of domain names, operating under the auspices of sri internationaland funded by the department of defense (dod), by darpa and thedefense information systems agency (disa).101 jon postel and other researchers at the information sciences institute at the university of southern california had been given the authority to establish procedures forassigning and keeping track of protocol and network numbers and controlled the definition of tlds.102 overall, the administration and policyoversight for domain names was relatively straightforward.100see discussion in section 4.3.101formally, the nic was the defense data networknetwork information center(ddnnic).102jon postel had a central role in the dns from the beginning as coauthor of òthedomain naming convention for internet user applications,ó rfc 819. postel òheldleadership positions in several internet infrastructure activities. he was founder andhead of the internet assigned numbers authority, rfc editor, and chief administratorsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution75in the mid1980s, the national science foundation (nsf) creatednsfnet to provide data communication services to researchers and educators. it selected the transmission control protocol/internet protocol(tcp/ip) as its transport protocol and worked closely with the department of energy, the national aeronautics and space administration, anddarpa to share facilities to extend this infrastructure in the united statesand worldwide. nsf encouraged campus network investment by focusing its efforts on highspeed and highcapacity longhaul òbackboneó103and regional networks to connect the campuses. thus, the responsibilityfor the civilian network gradually shifted from the dod to nsf. (seebox 2.3 for a timeline of the shifting administration of domain names.) inthe early 1990s, nsf made another important decisionñto withdraw asthe primary financial benefactor for the backbone of the internet and toencourage a commercial market for support of transport facilities.continuing on this path, in 1993 nsf replaced dod as the fundingagency for domain name management. as the workload increased, nsfcontracted with network solutions, inc. (nsi) to manage the registrationfor most of the gtlds (.com, .net, .org, .edu, and .gov), through internic.at this time, nsf, preserving the practice that the registration of domainnames would be free to registrants, subsidized the costs associated withdomain name registration. see box 2.3.increasing scale was not the only impetus for administrative evolution. the increasing economic and social value of domain names causednew players to become interested in the realm of domain names. as discussed earlier, holders of highly visible and valuable trademarks developed an active interest in domain names. many other entities, from national governments and public interest groups to the firms in the emergingdomain name industry, also developed a keen interest in all things relatedto domain names. thus, the 1990s saw the domain name community expand radically, both in scale and, especially important to understand, inthe scope of the interests and backgrounds of participants.104of the .us domain. he was expected to play a crucial role in the future of internetadministration, which [was] in the process of being transferred to the private sector[the internet corporation for assigned names and numbers (icann)].ó see òin memoriam, dr. jonathan b. postel, august 3, 1943 ð october 16, 1998,ó the domain namehandbook, available at <http://www.domainhandbook.com/postel.html>, accessed march31, 2004.103a backbone is a network that interconnects other networks. backbone networksoften operate over relatively longer distances than do typical networks.104this diversity in the range of participants creates challenges in achieving consensus in the decisions needed to make progress on various problems. among otherthings, conflicting goals and varying communication styles and vocabulary contributeto these challenges. even agreeing on something as basic as defining òdnsó can leadto disputes.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.76signposts in cyberspacebox 2.3administration of the domain name systemin the 1990s: the road to icann1991responsibility for much of the network information center (nic) wastransferred from sri international (operating on the behalf of the department of defense; dod) to government systems, inc., which then subcontracted the entire operation to network solutions, inc. (nsi). nsi startedoperating the nic in 1992.1993the national science foundation (nsf) replaced dod as the fundingsource for the nic. nsf completed a service contract with internic, theumbrella organization for the participating contractors at&t (directory anddatabase services), nsi (registration services), and general atomics/cerfnet (information services). thus, nsf engaged nsi to take over domain name registration services for most of the generic toplevel domains(gtlds) through a 5year cooperative agreement.1994òdomain name system structure and delegationó (rfc 1591), writtenby jon postel, was published and gained general acceptance.11995nsf and nsi amended their cooperative agreement, imposing a $100fee for 2 years of domain name registration.1997the international ad hoc committee (iahc), a coalition of individualsrepresenting various constituencies established in 1996, released a proposal for the administration and management of gtlds that included aframework for a governance structure, captured in a document knownas the generic top level domain memorandum of understanding(gtldmou).2the u.s. government created an interagency group to address the domainname issue and assigned lead responsibility to the national telecommunications and information administration (ntia), department ofcommerce. this interagency group reviewed the iahc proposal andsolicited public comment.as a part of the clinton administrationõs òframework for global electroniccommerce,ó3 the department of commerce was directed to privatize thesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: emergence and evolution77domain name system in a manner that would increase competition andfacilitate international participation in its management. the departmentissued a call for public input relating to the overall framework of the dns.1998the ntia released òa proposal to improve technical management ofinternet names and addresses,ó also known as the green paper. thisproposal called for a private, nonprofit corporation, headquartered inthe united states, to manage domain names and ip addresses, and foròthe addition of up to five new registries.ó4a final statement of policy, the òmanagement of internet names and addresses,ó also known as the white paper, was issued by ntia. the whitepaper reaffirmed the goals of the green paper, while having the u.s.government take a more handsoff approach, and urged the creation ofa new notforprofit corporation to oversee the management and assignment of domain names and ip addresses. goals for the new corporationincluded ensuring stability, competition, private and bottomup coordination, and fair representation of the internet community.5nsf transferred authority to the u.s. department of commerce to administer the cooperative agreement under which domain name registrationservices are provided.6internet constituencies (e.g., those that attended the workshops held underthe auspices of the international forum on the white paper) discussedhow the new entity (the new corporation, or ònewcoó) might be constituted and structured. a group led by jon postel (and under his name)proposed a set of bylaws and articles for the incorporation of newco.the final version of newcoõs (then named as the internet corporationfor assigned names and numbers; icann) bylaws and articles of incorporation were submitted to ntia in october. on november 25,ntia and icann signed an official memorandum of understanding(mou), with an initial termination date of september 30, 2000.in october, ntia and nsi extended their cooperative agreement throughseptember 2000. nsi committed to a timetable for the development ofa shared registration system (srs) that permitted multiple registrars toprovide registration services within the .com, .net, and .org gtlds. also,nsi agreed to separate its registrar and registry operations into separatedivisions, to recognize newco, and to make no changes to the rootwithout written approval from the u.s. government.1available at <http://www.rfceditor.org>.2for further information, see <http://www.gtldmou.org/draftiahcrecommend00.html>.3see <http://www.ta.doc.gov/digeconomy/framewrk.htm>.4see <http://www.ntia.doc.gov/ntiahome/domainname/dnsdrft.htm>.5for the text of the white paper, see <http://www.ntia.doc.gov/ntiahome/domainname/6598dns.htm>.6see <http://www.nsf.gov/od/lpa/news/media/ma9822.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.78signposts in cyberspaceby 1996, the belief by some (e.g., jon postel) that additional tlds wereneeded led to the establishment of the international ad hoc committee(iahc) to develop a framework for the administration of domain names,which became known as the generic top level domain memorandum ofunderstanding (gtldmou). the iahcõs proposal for an institutionalframework prompted a strong reaction from a few key constituencies andòsent ripples through the international system,ó as characterized by miltonmueller.105 although the gtldmou was not implemented, its creationdid motivate the discussions leading to the development of the green andwhite papers (see box 2.3) and the eventual creation of the internet corporation for assigned names and numbers (icann) in late 1998.nsi exclusively operated the .com, .net, and .org tlds through 1998.the registry operations (associated with the management of the tld databases themselves) and registrar operations (associated with the retailfunctions of dealing with customers) were integrated. ntiaõs agreementwith nsi in late 1998 required nsi to separate its registry and registrarfunctions so that other registrars could enter the market. to facilitate theentry of other firms, nsi also agreed to establish a shared registrationsystem to enable all registrars (including nsiõs registrar unit) to interactwith the registry database. the vibrant market for domain name registration services in the .com tld that developed in the late 1990s also spurredinterest in the creation of new tlds.thus, the dns has experienced an extraordinary evolution since itsbirth in the early 1980s. initially intended to address specific technical andoperational problems of concern to a small, relatively homogeneous groupof computer scientists and engineers, the dns came to involve individuals from many different sectors such as law, business, government, andthe public interest. the issues surrounding the dns became increasinglynontechnical in nature and increasingly complex and controversial, andso the founding of icann did not end the conflict among constituents,but rather provided the forum for their often intense discussion. chapters3 and 5 further explore these conflicts and the alternatives for their possible resolution.105from milton mueller, òinternet domain names: property rights and institutional innovation,ó in gary libecap, editor, entrepreneurship and growth in the american economy12:93131, elsevier, amsterdam, 2000, p. 111.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.793the domain name system:current statethe domain name system (dns) in 2005 serves a global internet farlarger and more diverse, in users and in uses, than the relativelysmall homogeneous network for which it was first deployed in theearly 1980s. to meet the needs of this expanded and enhanced internet,the dns has developed into a complex sociotechnicaleconomic systemcomprising distributed name servers embedded in a multilayered institutional framework. this chapter describes the dns as it exists in 2005 toestablish a base for consideration of the future of the dns and of navigation on the internet.the chapter begins with an explanation of how the dns responds toqueries, illustrating the process with a query about the internet protocol(ip) address that corresponds to a particular domain name. it then describes the basic architecture of the dns: its domain name space, its hierarchical structure, its basic programs, and its key standards and protocols. the core of the chapter is a description of the implementation of thisarchitecture at three levels of the dns hierarchy: the root, the topleveldomains, and the second and thirdlevel domains. the distinctive characteristics of each level are examined first, followed by descriptions of thetechnical system and its institutional framework. the committeeõs conclusions about the current performance of the dns architecture and theimplementation of each level are presented at the end of each section.open issues affecting the future of the dns are collected and analyzed inchapters 4 and 5.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.80signposts in cyberspacemany of the contentious issues that arise in the context of the dnsconcern domain names themselvesñin particular, the definition of permissible names and the rights to their use. some of those issues are introduced and discussed in chapter 2.3.1operation of the domain name system1many things happen when a query to the dns is initiated. if the dnswere a centralized database, such as hosts.txt,2 every query would godirectly to a central file where the answer would be found (or its absencenoted). however, because the dns is a hierarchical, distributed database,a search in response to a query generally requires several steps. if necessary, it can begin at the root and traverse a course through the tree of filesto the one in which the soughtfor answer resides. however, frequentlythe search can begin further down the tree because previous answers arestored and reused by the querying client. the design of the dns ensuresthat the path down the tree will be followed without detours or false starts,leading directly to the desired file because the structure of the domainname spells out the route. this process may best be understood throughan example, shown in figure 3.1, which illustrates the use of the dns tofind the ip address corresponding to the hypothetical domain nameindns.cstb.nas.edu.3this is what would happen if, for example, the user wanted to accessa web site at that name, in which case the requesting application wouldbe a browser. however, the same process would be followed for, say, anemail application or any other application supported by a host4 on theinternet.two versions of the process are described below: first, the versionshown in figure 3.1, which would be followed if this were a new queryfrom a computer that was not on the same dns subtree as the cstb.nas.eduserver; and then a version shortened by taking advantage of additionalinformation from shared servers or previous queries.1this section elaborates on the highlevel explanation in chapter 2. it draws extensively on material in paul albitz and cricket liu, dns and bind, oõreilly & associates, sebastopol, calif., 2001.2hosts.txt is the predecessor of the dns and is described in section 2.1.3the process shown in figure 3.1 assumes that the querying client has stored norelevant previous answers.4a òhostó is a network computer on which applications run providing services, suchas computation or database access, to end users on the network.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state81netmit.educstb.nas.edurootname server.eduname servernas.eduname servercstb.nas.eduname servercomindns.cstb.nas.edu?indns.cstb.nas.edu?ip address ofindns.cstb.nas.eduedurootip addressnas.edufigure 3.1operation of the domain name system without a local name server.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.82signposts in cyberspace3.1.1a new, remote querywhen a domain name is used in a web browser, email program, orotherwise, the applications program forms a requestña query. the example query, òwhat is the ip address corresponding to the domain nameindns.cstb.nas.edu?,ó goes first to a piece of software called a resolver.resolver software is ordinarily incorporated as part of other software resident on the userõs computer5 or in a host to which it is linked. there aretwo kinds of resolvers: stub resolvers and iterative resolvers. both typesof resolver send queries to name servers (see below), but they differ inhow the resolver selects the name servers to which it sends the query andhow much of the work of answering the query is performed by the resolver. a name server is a computer running one of a small number ofnameserving programs, the most common of which is the berkeleyinternet name domain (bind) software.6 a stub resolver simply forwards the query to a local name server and awaits a reply. it places on thename server the burden of searching the dns for the answer. an iterativeresolver, in contrast, retains control of the search by using the answerfrom each successive name server to guide its search. this example assumes that the query comes from a stub resolver.name servers are located throughout the internet: at the root and thetoplevel domain registries, in organizationsõ intranet infrastructures, andat internet service providers (isps). name servers can perform two important functions:¥first, they are designed to reply directly to queries concerning theportion of the domain name space for which they have complete information, which is called their zone and for which they are said to be authoritative (see section 3.1.2).¥second, they can, by incorporating an iterative resolver, reply toqueries concerning zones for which they are not authoritative, obtaininginformation from other name servers in the dns (described in this section). the incorporated iterative resolver will in almost all cases also contain a file or cache of answers obtained as a result of processing previousqueries (see section 3.1.3). in this case, the combination of name serverand iterative resolver is said to be a caching or recursive name server.5for example, this is part of the transmission control protocol/internet protocol(tcp/ip) stack in microsoft windows software, but some applications incorporatetheir own resolvers. consequently, a computer may contain more than one resolver.6this name server program was originally written in 19831984 by a group of graduate students at the university of california, berkeley, with funding from the defenseadvanced research projects agency. name servers are discussed further in section3.2.3.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state83in practice, name servers with a heavy query demand or at the toplevels of the dns hierarchy are often configured to be authoritative onlyand not to offer caching/recursive services, except through a separateserver. the name servers at isps, however, will offer caching/recursiveservices to their customersõ stub resolvers, but may not be authoritativefor any domain.in figure 3.1, the query is shown as going first to a name server offering recursive services located at the userõs isp.7 since in this example theiterative resolver incorporated into the ispõs name server has not recentlyseen this query or any portion of it and the name server is not authoritative for any portion of the query, it sends the query on to the dns root. itis able to find the root because the ip addresses of the name servers for theroot, called the root hints data, were manually entered into a file on thecomputer, the hints file. some systems automatically detect changes tothe list of root name servers and make use of them, but the software neverchanges the file because to do so might eliminate the fallback in case of anattack that maliciously delivered an incorrect list.there are 13 root name servers (and many satellite copies of them)8distributed around the world, and the querying name server will go toone chosen by an algorithm that, although differing among name serverimplementations, usually takes the shortest response time into account.the multiple computer copies of some of the 13 name servers employ atechnology called òanycastó addressing (see box 3.1). although geographically distributed, each satellite is capable of responding to queriesto the same ip address.if, for some reason, one root name server (or its closest satellite) doesnot respond, the iterative resolver will continue to try other servers according to its selection algorithm, and so on, until it receives a response.similar behavior is common to all iterative resolvers at whatever level inthe dns hierarchy they are searching.the response of a root name server, which is configured to be authoritative only, takes the form: òthe address of indns.cstb.nas.edu is not inmy zoneõs name file, but here are the names or addresses of name serversthat are authoritative for .edu.ó the ispõs iterative resolver then sends thesame query to one of the .edu name servers, which responds: òthe address of indns.cstb.nas.edu is not in my zoneõs name file, but here are thenames or addresses of the name servers that are authoritative for nas.edu.ó7where a query goes first is a consequence of an explicit configuration choice madeby the user, an isp, an enterprise it department, or by a dynamic configuration protocol whose values are supplied by one of those sources.8see table 3.1 for a listing of the 13 root name servers and their base and satellitelocations. see box 3.1 for a description of satellite servers.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.84signposts in cyberspacethe ispõs resolver then queries one of the nas.edu name servers, whichrefers it to a cstb.nas.edu name server, which is authoritative for the requested domain name and replies with the corresponding ip address.3.1.2local querya name server can answer many queries quickly when these queriesrequest the address of a domain name for which the name server is authoritative. this is often the case, for example, for name servers on organizational intranets, where most of the requests are for ip addresses of othercomputers on the intranet. in such a case, the name server can respond tothe query without going to the larger dns, simply by looking up the anbox 3.1anycast addressinganycast addresses, a special type of internet protocol (ip) address, wereinvented in the early 1990s to simplify the process of finding replicatedservices (i.e., services that are provided by multiple and identical servers).1some of the operators of root name servers have implemented anycastaddressing as a way to facilitate load sharing, to improve service, and toreduce vulnerability to attacks.the use of anycast addresses allows a root name server operator toinstall copies of the root zone file at different servers (in this report, thoseservers that replicate the root zone file are called satellites). properly configured and located, each of the satellites will get a share of the traffic forthe root name server. although the shares will, in most cases, not be equal,the load of queries will be distributed and thus relieve the load burden onthe root name server. satellites that are located at the same physical site areusing local anycast addressing, also known as load balancing, which iswidely deployed among the root name server operators.from the userõs perspective, the great advantage derived from the adoption of anycast addressing is improved service. the satellites are typicallyplaced at topologically diverse locations in the internet. queries can therefore be answered more swiftly. an additional benefit is that the dns queries use, in the aggregate, fewer network resources, because servers willtend to be òcloseró on the network to the sources of the queries.the use of anycast addressing can sharply reduce the impact of an attack on a root name server: in the short run, physically disabling a rootname server does not affect the operation of its satellites, and physicallydisabling a satellite disables only that satellite. in the long run, there is thequestion of how satellites would obtain updated root zone information. it isalso much harder to mount an effective electronic attackñbecause queriesare routed to the closest satellite (or the root name server itself, if it is theclosest). an attacker would need to place (or acquire) machines close tosignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state85swer in its local database. for example, if the local name server in theprevious example was authoritative for cstb.nas.edu, it could providethe response directly.3.1.3repeat querya caching name server can answer many other queries quickly whenit has responded previously to queries that were identical or matched at ahigher level of the tree. (for example, in 2005 virtually every cachingname server is highly likely to have cached the ip address forwww.google.com.) it maintains those answers in a cache of informationcontaining the addresses of name servers (and other data) it has previeach of the satellites and the root name server if the attacker wished todisable all access to the service.2 a single attacking machine might disablethe closest serverñwhether a satellite or the root name server itself. theother servers would be affected only in a minimal way, through a slightlyincreased load if one server were rendered inoperative.therefore, the adoption of anycast addressing by the root name serveroperators is a positive development. however, more general use of anycastaddressing is problematic because current methods for deploying theseaddresses waste a number of ip addresses.3 given the importance of arobust dns, this wastage is acceptable for the operation of the root nameservers, but not necessarily for other domain name servers.monitoring the performance of satellites presents root name server operators with a difficult problem. such monitoring involves the placement ofmonitoring devices within the part of the internet that each satellite servesand can represent a significant logistical challenge because the satellitesmay be widely dispersed.1the initial motivation for the creation of anycast addressing was to reduce the needmanually to configure information about basic services such as dns resolvers. the basicidea is that a òhost transmits a datagram [a data packet carrying its own address information so it can be independently routed from its source to the destination computer] to ananycast address and the internetwork [internet] is responsible for providing best effortdelivery of the datagram to at least one, and preferably only one, of the servers thataccept datagrams for the anycast address.ó see craig partridge, trevor mendez, andwalter milliken, òhost anycasting service,ó request for comments (rfc) 1546, november 1993, available at <http://www.rfceditor.org>. see box 3.3 for an explanation ofrfcs. all rfcs are available at <http://www.rfceditor.org>.2and even then other root name servers and their satellites would be accessible.3as of april 2004, anycast addresses were not fully supported in the current version ofip (version 4). in particular, the border gateway protocol (bgp; the crossprovider routingprotocol) was not designed to accommodate anycast addresses and, therefore, a workaroundis used that wastes about 256 ip addresses for each root name server that employs anycastaddressing.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.86signposts in cyberspaceously obtained. before going to the root, it searches its cache to find theknown name servers closest (in the dns hierarchy) to the domain beingsought.for example, if the ispõs caching name server in the previous examplewere to receive a query for the address of tdd.cstb.nas.edu, it would checkto see if it already knew the address of the name server authoritative forcstb.nas.edu. if it did, its iterative resolver would send the query directlyto that server, shortening the path that must be taken to obtain an authoritative response. if it did not, it would then check to see if it had the address of the name server authoritative for nas.edu, and finally .edu. onlyif it had none of those addresses would it go to the root.this property of cachingñthat it limits the number of queries that aresent to the root name serverñhas been crucial to the manageability of thegrowth in the query load on the root system. if all dns queries were tostart at a root name server, the capacity of the root system (as a whole)would have to be of an entirely different magnitude, posing more formidable technical and economic challenges as a consequence.the internet and the many services on it are subject to constant, sometimes rapid change. as a result, cached information can become outdated.to reduce that problem, the administrator of each zone assigns a time tolive (ttl) to each datum that it sends out in reply to a query. after thecorresponding amount of time has passed, the name server is expected toeliminate the datum from its cache.often a name server will receive information that a domain name being sought does not exist. that can happen because the query is ill formed,contains a typographical error, is based on a userõs incorrect guess about adesired domain name, refers to a name that does not exist or no longerexists, or refers to a domain name on a private network that is not on thepublic dns.9 since such inquiries do not correspond to a cached address,even the caching name server system will not normally relieve the load onthe root name servers related to such requests. to minimize the load onthe network and improve response time, however, it is desirable that nameservers store information about such nonexistent domains. that practiceis referred to as negative caching (as introduced in section 2.3.1). the needto assign a ttl also applies to negative caching, since a previously nonexistent domain may come into existence and would be missed if the negative cache did not eliminate responses regularly.9a significant portion of queries to the root name servers are ill formed or in erroraccording to studies by researchers. see, for example, duane wessels and marinafomenkov, òwow, thatõs a lot of packets,ó proceedings of passive and active measurement workshop, 2003, available at <http://www.caida.org/outreach/papers/2003/dnspackets/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state873.2architecture of the domain name systemthe architecture of the dnsñits conceptual designñcomprises itsname space, its hierarchical structure, and the software that specifies operations within that name space and structure.10 the software comprisestwo components: programs, which implement the resolver and nameserver functions on various computers; and technical standards, whichdefine the formats of the communication between the programs, as wellas the logical structure11 of the files in a name server.3.2.1name spacethe name space for domain names is the set of all symbol strings thatadhere to the rules for forming domain names specified in the design of thedns. those rules define a standard format that imposes a tree structure onthe name space. each node on the tree has a label, which consists of 1 to 63characters drawn from a restricted subset of ascii12 comprising the 26 letters of the roman alphabet, the 10 numerals from 0 to 9, and the hyphen.labels may not begin or end with a hyphen.13 the fully qualified domainname of a node is the list of the labels on the path from the node to the rootof the tree written with the deepest node on the left and with those to theright getting successively closer to the root. in external presentation form,the labels are separated by dots (.). by convention, the root label has nulllength and is written as a dot (.), but its presence is optional. thus,òwww.nas.edu.ó (with a trailing dot) and òwww.nas.eduó (without a trailing a dot) are equivalent domain names. the total length of a domain namemust be less than 256 characters. each node on the tree (including the leaves)corresponds to a collection of data, which may be empty at the internalnodes, unless they constitute a delegation point. the data are representedby resource records, which are described in box 3.2 in section 3.2.4.3.2.2hierarchical structurethe hierarchical, tree structure of the dns facilitates both an efficientresponse to queries and the effective decentralization of responsibility for10the evolution of the dns is described in chapter 2.11they will be stored in whatever data structures the local database software requires.12american national standards institute, òusa code for information interchange,ó x3.4,1968.13the limitation to the 37 ascii characters is not a strict requirement of domainnames but results from the constraints placed on domain names by other protocols.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.88signposts in cyberspaceits maintenance and operation. that is accomplished through the divisionof a domain into subdomains, which taken together need not directly include all of the hosts in the domain. the responsibilities for maintaining thename files for some or all of the subdomains can then be delegated to different organizations. they, in turn, can further divide and delegate, a processthat can be repeated as often as necessary. the parent domain need onlyretain pointers to the subdomains so that it can refer queries appropriately.the hierarchical delegation of responsibility is one of the great strengthsof the dns architecture. it is up to the organization responsible for a zone tomaintain the corresponding zone file (thus, the organization has considerable motivation to provide satisfactory maintenance)ñthe data file in thezoneõs name servers that contains pointers to hosts in the zone and to thename servers for delegated zones (see òdns zone data fileó in section3.2.4). the work of keeping the dns current is, thereby, distributed to organizations throughout the entire dns tree, down to the lowest leaves. instead of a central organization being responsible for keeping the dns datacurrent and accurate, which would have been an impossible task, there aremillions of organizations and individuals across the globe doing the work.figure 3.2 illustrates the delegation of responsibility from the root tothe .edu domain, whose name servers are said to be authoritative for the.edu zone. the .edu domain in turn delegates responsibility, in this limited illustration, for the subdomains to three universitiesñthe universityof california at los angeles (ucla), southern methodist university(smu), and the massachusetts institute of technology (mit), whose nameservers are authoritative for their corresponding zonesñucla.edu,smu.edu, and mit.edu. in figure 3.2 the mit subdomain is further delegated to two departments for illustrative purposesñsloan school andelectrical engineering and computer science, whose name servers areauthoritative for their zonesñsloancf.mit.edu and eecs.mit.edu. notethat in the example, the mit.edu zone includes a pointer directly to ahostñweb.mit.eduñin addition to pointers to the delegated zones.this distribution of responsibility, combined with the distributed handlingof tasks by the technology, is why the dns scales, or handles growth so well.3.2.3programs: bind and othersthe dns requires only two types of programs to operate within thecontext of the existing internet.first, there must be resolver software. the resolver, recall from section 3.1, is a client that accepts a query, passes the query to a name server,interprets the response, and returns the response to the source of thequery. generally, resolvers are just a set of library routines within a nameserver, a browser, or an operating system.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state89figure 3.2the .edu domain divided into zones. source: based on figures 28and 29 of paul albitz and cricket liu, dns and bind, 4th edition, oõreilly media, sebastopol, calif., 2001.domainsmu.eduzoneucla.eduzonemit.eduzoneeduzonesmu.eduzoneucla.eduzonemit.eduzoneeduzonezonezonezonesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.90signposts in cyberspacesecond, there must be name server software that performs the functions described in section 3.1. as noted above, the most common nameserver software is bind,14 which is used on the majority of name serverson the internet.15 there have been many versions of bind produced sinceit was originally written in the early 1980s. the most recent releases (as ofmarch 2005) are bind 8.4.6, which extends and enhances prior versions,and bind 9.3.1 and 9.2.5, which are the latest releases of a major rewriteof the underlying architecture undertaken in response to anticipated demands resulting from the rapid growth of the internet. although originally written for unix operating systems, bind has been programmed forother operating systems, including windows nt and windows 2000.16 ithas also been used as the basis for many vendor name servers.17the rest of this section uses bind as an example because it is widelydeployed. however, other name server software may behave differentlyin some respects and still conform to the domain name server standards. a name server running bind, or a comparable program, has completeinformation and authority over the zones for which it is authoritative. itcontains all domain names from the top of its zone down to its leaves, except for those that are delegated to zones within it. see figure 3.2.each zone must have a primary master (or primary) server that receives the contents of the zone data file from some manually preparedlocal file. the primary server is the ultimate source of information aboutthe corresponding domain. generally, there is at least 1 and possibly asmany as 12 secondary servers, which obtain copies of the zone data filefrom the primary or another secondary.bind has not traditionally made severe computational or storage demands on the computers that run it. it has often been implemented on oldmachines that have been taken out of frontline service. however, bind 9incorporates security and other features that impose more severe computational loads. in general, the computational requirements on a nameserver depend on the number of queries per second and the relative distribution of the types of queries (because some types of queries imposegreater computational demands than others), as well as the extent ofchange of the zone files. the memory requirements are determined by the14bind also contains a resolver library.15according to a survey by internet systems consortium, inc., in january 2004 it wasused by almost 75,000 servers; the second most popular name server software wasprovided by microsoft for almost 15,000 servers. for more information about thesurvey and bind, see òisc internet domain survey,ó march 10, 2004, available at<http://www.isc.org>.16see òdns server softwareó at <http://www.dns.net/dnsrd/servers/> for a survey of dns servers available on various operating systems.17a current list is posted at <http://www.isc.org/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state91size of its cache and zone files. in the latest versions of bind, the cachesize can be controlled. in general, the cache size for a new name server isdetermined by observation of the name serverõs operation over a fewweeks to determine how much memory is required to respond to thequery demand at its installation.3.2.4standardsthe queries and responses that flow between name servers must be in aprotocol that is readily interpretable by any name server, no matter whichsoftware and hardware it uses. to that end, the data in the queries andresponses are, like the zone data, represented as resource records (box 3.2).box 3.2resource recordsresource records are used in every dns zone data file and every dnsmessage.1 resource records begin with a domain name (name), which isfollowed by the type (type) and class (class) fields. those fields are followed by the time to live (ttl) and a data field (rdata), appropriate to thetype and class. domain names and ip addresses make up a large portion ofthe data in a typical zone data file.name: the domain to which the record refers.type: the type of data in the resource record. the list of possible typesis openended; each is associated with a type code. there were more than50 in june 2005, of which no more than 20 are used to any extent.examples: a = host ip address; ns = an authoritative name server; mx =mail exchange.2class: only one class, in for internet, is widely used. four classes havebeen defined to date, one of which is obsolete.ttl: specifies the time interval (in seconds) that the resource recordmay be cached before the source of the information should again be consulted.example: 86400 (equivalent to one day).rdata: describes the resource in question.example: if the class = in and the type = a, this field is an ip address.3if the class = in and the type = ns, this field is a domain name.1see p.v. mockapetris, òdomain namesñimplementation and specification,ó rfc1035, november 1987, available at <http://www.rfceditor.org>.2for an explanation of òmail exchange,ó see section 2.3.3.3since each typea resource record in class in can include only one ip address, adomain name that maps to multiple ip addresses will have multiple resource recordsñone for each ip address.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.92signposts in cyberspacedns zone data fileeach dns zone has a zone data file (also called the master file) thatcontains both resource records describing the zone and actual data recordsfor the zone. the former group specifies:¥the domain name of the primary name server and the email address of the responsible person, as well as times associated withupdating the secondary name servers;¥all the name servers that are authoritative for the zone; and¥the ip addresses of the name servers (nametoaddress mappings)that are in the zone.there can also be data files that contain reverse mappings (i.e., tablesfor conversion from ip addresses back to computer names). the domainnames in these files look like ip addresses turned back to front, and theyall end in inaddr.arpa.18the zone data file may contain some additional types of resourcerecords. the specification of resource records allows additional types ofdata to be added in the future, as required.dns message formatthe dns message format comprises five sections, some of which maybe empty:¥header,¥question: the question for the name server (includes domainname),¥answer: resource records answering the question,¥authority: resource records pointing toward an authority, and¥additional: resource records holding additional information.the lengths of the four sections that follow it are specified in theheader section.the practical limitation on the number of root name servers to 13 is aconsequence of the dns message format and the design decision to usedatagrams employing a minimal protocolñthe user datagram protocol(udp)19ñto send dns queries and responses so as to achieve high per18addresses are converted to names in the .arpa domain for dns lookup.the inaddr.arpa zone contains the hosts associated with all registered ipv4 addresses.19for more information on the user datagram protocol, see jon postel, òuser datagramprotocol,ó rfc 768, august 28, 1980, available at <http://www.rfceditor.org>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state93formance. because in current practice there must be room within thedatagram answer section for a list of all root serversñin order to updatethe list of root servers20 in every iterative resolverñthe number of rootservers is constrained by the maximum length of that section.21 to maximize the number of root servers, their names were shortened and standardized for more efficient compression, increasing to 13 the maximumnumber that could fit in the space available.3.2.5functions and institutionsthere are two critical functions that the dns institutional frameworkperforms in support of the standards and the programs that define thedns. the first is maintenance of the dns standards, and the second isensuring the availability of dns name server software. dns client software, primarily stub resolvers, is widely available in standard softwareñoperating systems, web browsersñand the specifics of their provisionare not further considered here.maintenance of the dns standardsñthe internetengineering task forcethe definition and maintenance of the basic standards for the dnsare the responsibility of one informal organizationñthe internet engineering task force (ietf) (see box 3.3). the ietf has attracted experiencedand knowledgeable technical talent, who volunteer considerable time toits activities. the requests for comments (rfcs) process has provided ameans for this diffuse technical community to build a freely available,peerreviewed store of knowledge and the successful standards and protocols that enable the internet and the dns to function reliably and toadapt smoothly to the additional requirements imposed by increasedscale, new applications, and new classes of users. although the ietfõsstandards and protocols underpin the worldwide internet and the dns, itdoes not have the authority, the political or economic power, or the interest to force their adoption or validate their implementation. rather, theiruniversal use has been the result of the practical benefit of having freely20as noted above, every iterative resolver needs to know where the name servers forthe root zone are in order to have a starting point for a nonlocal, nonrepeat query.21in theory, the response could be a list of name servers that contain the names andlocations of root name servers. also, the hints file, which is local, could contain information about more than 13 name servers. however, the limitation to 13 has not yetbeen judged to be a large enough issue to change current practice in either respect.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.94signposts in cyberspacebox 3.3the internet engineering task force andrequests for commentsthe internet engineering task force (ietf)1 is a voluntary, noncommercial organization comprising individuals concerned with the evolutionof the architecture and operation of the internet. it is open to anyone whowishes to participate and draws from a large international community.however, almost all its participants are technologists from universities,network infrastructure operators, and firms in related industries. althoughthe ietf holds three meetings each year at locations around the world,much of its work is conducted through the circulation of email to electronic mailing lists. the ietf divides its activities among working groups,organized into areas that are managed by area directors (ads). the ads, inturn, are members of the internet engineering steering group (iesg). theinternet architecture board (iab) provides general oversight on internetarchitecture issues and adjudicates appeals that are unresolved by the iesg,but it is not actively involved in standards development or implementation.the internet society (isoc) charters the iab and iesg.2requests for comments (rfcs) were established in 1969 to documenttechnical and organizational aspects of the internet (originally the arpanet).rfc memos discuss protocols, procedures, programs, concepts, and variousother aspects of the internet. the ietf defines the official specification documents of the internet protocol suite that are published as òstandardstrackórfcs. rfcs must first be published as internetdraftsña mechanism to provide authors with the ability to distribute and solicit comments on documents that may ultimately become rfcs. an internetdraft, which can bepublished by anyone, has a maximum life of 6 months, unless updated andassigned a new version number. the internetdrafts that are intended forprogression onto the standards track, and some other documents at iesgdiscretion, are òlast called,ó which involves an announcement being sent outto the internet community that the iesg wants input on the document. thelast call is usually of a few weeksõ duration. using input from it, the iesgmakes a decision on further processing of the internetdraft. such decisionsmight include rejection of the draft, publishing it as a standardstrack document, or handling it in some other way. documents that are consideredvaluable and permanent, including all standardstrack documents, are thensubmitted to the rfc editor for publication as rfcs.31for a full description, see susan harris, òthe tao of ietfña noviceõs guide to theinternet engineering task force,ó rfc 2160, august 2001, available at <http://www.rfceditor.org>.2for more information on the evolving relationship between isoc and iesg, see<http://www.isoc.org/isoc/related/ietf/>.3for details on this process, see scott o. bradner, òthe internet standards process,revision 3,ó rfc 2026, october 1996, available at <http://www.rfceditor.org>. for background on rfcs and a searchable repository of rfcs, see <http://www.rfceditor.org>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state95available highquality standards that all can share, and that give no organization proprietary advantage. as a volunteer collaborating body, theietf periodically restructures its processes. in 2003, the ietf identified anumber of problems, both routine and structural, in its operations andinitiated a process of problem resolution.22 as is typical, it did so publiclyvia the rfc process.providing root name server softwareñinternet softwareconsortium, inc., and other software providersinternet systems consortium, inc. (isc), a notforprofit organization formerly called the internet software consortium, has assumedresponsibility for continuing maintenance and development ofbind.23 although iscõs scope is considerably more focused than theietfõs, it, too, has played a key role in the smooth development andoperation of the internet and the dns. by continuing to evolve bindand making it readily available worldwide, free of charge, isc has provided a widely adopted implementation of the dns standards promulgated by the ietf.implementations of bind and other dns server software are alsoavailable from microsoft and other software companies as well as fromvarious providers in the form of freeware and shareware.3.2.6assessmentconclusion: the architecture of the domain name system has demonstrated the ability to scale to support the internetõs rapid growth, neverholding up its development because of an inability to meet the challengesof vast increases in the number of domain names, users, and queries. furthermore, it has demonstrated robustness, operating reliably despite malicious attacks and a very high volume of erroneous requests. what failures there have been have occurred in subzones of the system and havebeen insulated from the rest of the dns by its hierarchical, distributedstructure.the hierarchical architecture and caching have been critical to the ability of the dns to scale smoothly. first, they ensure that many queries are22the problem statement and the history of the response are described in e. davies,ed., òietf problem statement,ó rfc 3774, may 2004, available at <http://www.rfceditor.org>; and e. davies and j. hoffman, eds., òietf problem resolution process,órfc 3844, august 2004, available at <http://www.rfceditor.org>.23information about isc is available at <http://www.isc.org>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.96signposts in cyberspaceresolved locally, never reaching the higher levels of the dns. second, evenqueries that do reach higher levels of the dns do so only the first timethey are made by a specific name server in a given period (the ttl), withall subsequent queries from the same name server during that period being answered locally.these benefits are amplified by the ability of large isps, such as mciand verio, to maintain very large caches and, thereby, to handle a substantial portion of the queries originating from their customers withoutever passing them along to the dns.conclusion: through its rfc process, the ietf has created a store ofknowledge and a body of standards and protocols that have, thus far,enabled the internet and the dns to function reliably and to adaptsmoothly to the additional requirements imposed by increased scale, newapplications, and new classes of users. though iscõs scope is much morefocused than the ietfõs and its participation and decisionmaking processes are far less open and public, by continuing the evolution of bindand making it readily available isc has brought most of the ietf dnsstandards24 into practical effect.however, the continued growth of the internet is posing new challengesand placing new demands on the dns architecture. the issues of future security and robustness, internationalized domain names, and the intersectionof the dns with the telephone system are addressed in chapter 4.3.3implementationñthe domain namesystem root zonethe top of the dns inverted tree is its root, or more properly, the rootzone (see section 3.1.1). the root zone name file (or, simply, root zone file)is stored in 13 root name servers, which use it to respond to queries to theroot. as shown in section 3.1, while queries can enter lower on the tree iftheir resolvers have current cached information, or if the query lies withinthe zone of the local name server, the root serves as the assured point ofentry to the dns for any other query.24this issue is complex since not all of ietfõs standards are mandatory or evenrecommended, and some are experimental or turn out to be bad ideas. the situationalso differs between bind 8, which is on endoflife maintenance, and bind 9, whichis an entirely new code base. bind 9 is believed to adhere to all the mandatory specifications, while isc has eliminated noncompliant code from bind 8 whenever it hasbeen identified.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state973.3.1characteristics of the root zonedefining characteristicsthe root zone file defines the dns. for all practical purposes, a toplevel domain (and, therefore, all of its lowerlevel domains) is in thedns if and only if it is listed in the root zone file. therefore, presence inthe root determines which dns domains are available on the internet.25as internet use has grown, especially with the explosive growth of theweb and its reliance on domain names as key parts of web site addresses, entry of a toplevel domain into the root zone file has become asubject of substantial economic and social importance. consequently,who controls entry into the root, and by what means, have become controversial subjects. the current process for resolving these issues is described in section 3.3.3.critical characteristicsthe root zone and the root name servers are critical to the operationof the dns. the effective and reliable operation of the dns, and of theinternet, is entirely dependent on the accuracy and integrity of the rootzone file (and its copies) and the security, reliability, and efficiency of theroot name servers. fortunately, the root zone has proven highly resilientand resistant to errors or disruptions.one possible source of error is an incorrect entryña mistyped domain name or an erroneous ip addressñin the root zone file. a consequence could be misdirection of queries seeking a particular topleveldomain (tld) name server, say .net. that could prevent users searchingfor the address of any domain name within that name serverõs tld, sayany address in .net, from reaching it through the specific root name servercontaining the incorrect entry. if the error were updated in all copies ofthe root zone file, access would effectively be denied to all domain namesin that tld, except from name servers that had previously cached thecorrect address.26 however, relatively simple error detection and correction procedures can quickly prevent such errors. (for example, most largetoplevel domains are programmed to regularly query the root to ensurethat it is properly routing queries seeking that tld.)25the ip addresses for the servers of wellknown tlds are widely available, and soto them presence in the root may be less important. for less well known and newtlds, however, presence in the root is the critical question.26this exception would hold true only until the ttls of the cached addresses expired.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.98signposts in cyberspacea possibly disruptive event would involve one or more of the rootname servers being nonoperational for hours or more. this might happen because of the unexpected failure of a computer or communicationlink (accidental or purposeful) or because of regular maintenance. however, since the capacity of each name server is many times greater than itsaverage load, and iterative resolvers can use any of the root name servers,other name servers can take up the load without degradation in thesystemõs performance that is perceptible to users. moreover, in recentyears such outages have been very rare.27although, as noted, there have been instances in the past of errors inthe root zone file that have had significant effects on the reliable operationof the dns, there have been none in recent times. at least for the currentrates of queries and of changes in the root zone file, the systems of errorchecking and correction and of capacity sharing appear to be workingsuccessfully.unique characteristicsthe design of the dns is predicated on the existence of a single authoritative root that ensures that there is one and only one set of topleveldomains. however, some of those who object to the pace at which newgeneric tlds have been added to the root, or to the process by which theyhave been selected, have sought a solution through the addition of one ormore roots. they have been joined by some who believe in the principlethat having competition in the delivery of root services would benefitinternet users.on the other side are those who argue that additional roots wouldcompromise the reliable operation of the internet by, among other things,opening the possibility of multiple addresses, associated with differententities, being assigned the same domain name.28 most experienced technologists view the idea of introducing multiple roots for the dns as threatening the stable operation of the dns.27for example, in 2000, 4 of the 13 root servers failed for a brief period because of atechnical mistake. in 1997, a more serious problem involving the transfer of an incorrect directory list to seven root servers caused much of the traffic on the internet tocome to a stop. as reported in òisc sets up crisis centre to protect domain namesystem,ó sydney morning herald, october 21, 2003, available at <http://www.smh.com.au/articles/2003/10/21/1066631394527.html>.28see, for example, m. stuart lynn, òicp3, a unique, authoritative root for thedns,ó icann, july 2001, available at <http://www.icann.org/icp/icp3.htm>; also,internet architecture board, òiab technical comment on the unique dns root,ó rfc2826, may 2000, available at <http://www.rfceditor.org>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state99moreover, since which domains are accessible to a user would depend on which of the multiple roots were used, these technologists see amultipleroot dns as balkanizing the internet. although there may besome benefits from having competing roots, the presence of network externalities29 encourages isps and name servers to converge on a singleroot that provides global compatibility. consequently, many technologistsand economists believe it is unlikely that an alternative root would achievewidespread success.30 in their view, while competition may serve a valuable purpose in the short term, the task of maintaining the root zone filewill equilibrate on a single, dominant root zone file, albeit an equilibriumin which operational control is shared among a number of (noncompeting) entities.31there have been several attempts to create alternate roots thathave data about the tlds that are recognized by the current rootservers plus some additional tlds that the operator of the alternateroot is trying to promote. however, these attempts have generallybeen unsuccessful, in large measure because of the lack of global compatibility among the domain names recognized only by alternativeroots, which has made users unwilling to use them. however, onecompanyñnew.netñclaims to have reached financial profitability,to have registered over 100,000 domain names, and to be potentiallyaccessible to 175 million internet users through allied isps andbrowser plugin software. it offers 12 additional tlds in english aswell as in each of spanish, french, portuguese, italian, and german.32although the continued existence of new.net can be seen as a challenge to the dns and icannõs management of the root zone file, ithas not thus far appeared to have had any significant effect on either.furthermore, in september 2004, new.net was acquired by thevendare group, an online media and marketing company, as the basis for a division offering search services, while continuing to offerdomain name registration.3329network externalities are the increased benefits received by one user of a system as thenumber of users of the system increases.30milton l. mueller, òcompeting dns roots: creative destruction or just plain destruction?ó journal of network industries 3(3):313334, 2002.31if an alternate root attracts a sufficient number of registrations, it raises the possibility that tlds in the alternate root and registrations within these tlds could becreated for speculative purposes. if icann creates a tld that already exists in analternate root, the organization that controls the corresponding tld in the alternateroot could be willing to transfer the registered names to the icann tldñfor a price.32this information was obtained from <http://www.new.net/> in february 2004.33the vendare group, òthe vendare group, online media and marketing company,acquires searchservices provider new.net,ó press release, september 17, 2004, available at<http://www.new.net/id9172004.tp>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.100signposts in cyberspace3.3.2technical system of the root zonethe root zone filethe root zone file contains resource records for all the tlds as well asfor the root. in february 2005, there were 258 sets of entries. of those, 243were country code tlds (cctlds) and 15 were generic tlds (gtlds).(one of the gtlds was the domain .arpa that is used for infrastructuralpurposes, which is sometimes considered a separate category.) becausethere are multiple records in the root zone file for each of the subdomains,there were a total of 2143 records in the root zone, which translates toabout 78 kilobytes of storage. moreover, although, as noted earlier, all theroot name servers together execute, in total, 8 billion searches a day onthis file,34 this is well within their computational capability because of thesubstantial overprovisioning of the system.the root name serverslike other zone files, the root zone initially had a primary or masterserver accessible from the dns and severalñin this case, 12ñsecondaryor slave servers. that primary zone file was the most current of the files,and all updates and changes were made to it; it served as the referencesource for the root zone. the secondary files were updated from it on aregular basis, at least twice daily. starting in 1996 and achieving adoptionby all secondaries by the end of 2001, the role of the primary was transferred to a òhidden primary,ó which is a server that is used to update thesecondaries but is not itself accessible from the dns. verisign operatesthis hidden primary. all 13 of the public root name servers are now secondaries, including the former primary. digital signatures, error checking, and correction processes are in place to minimize the chance of introducing errors or being successfully attacked during updates.the december 2004 status of the group of 13 named root nameservers is shown in table 3.1.35 they are designated by the letters athrough m. the aroot server, a.rootserver.net, was until recently theprimary but, as noted above, has been replaced by a hidden primary.see box 3.4.34the froot server (which includes its satellites), one of 13 root servers, answered morethan 272 million queries per day according to the internet systems consortium in january2004. see <http://www.isc.org>.35for the current version of this table, see <http://www.rootservers.org>. that web sitealso contains links to the root name server operators and to other relevant information..signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state101although the home locations of some of the root servers are the resultof historical accident, they were originally determined by analysis of network traffic flows and loads, seeking to have at least one server òcloseó interms of message communication time to every location on the network.it is important to have root servers distributed so that they provide a uniform level of service across the network.36 having a root server in a wellconnected area is fairly unimportant to that area, since users there arelikely to be able to reach several servers. by contrast, if an area is fairlyisolated from most of the network, it is important that the isps that serveit acquire sufficient connectivity to enable the areaõs users to access one ormore root servers at all times.considerations of this type are both complex and important but werenot sufficient to determine a unique set of locations for the home sites ofthe 13 root servers. however, as the internet has evolved, these originallocations became less satisfactory, which has been one of the reasons forthe proliferation by some operatorsñnotably c, f, i, j, k, and m in table3.1ñof satellite sites at different locations. these satellite sites use anycastaddressing (see box 3.1), which enables servers with the same ip addressto be located at different points on the internet. copies of the froot server,for example, can be placed at multiple locations around the world. thewidespread distribution of anycast satellites of the 13 root servers hasimproved the level of service provided to many previously less wellserved locations.some have believed that 13 root name servers are too few to meetrequirements for reliability and robustness, which requires sufficient capacity distributed widely enough to protect against system or networkfailures and attacks. others have believed that more root servers areneeded to satisfy institutional requirements. their concern arose from thebelief that to be a full participant in the internet, a nation or region musthave its own root name server. while technical reasons37 make it difficultto increase the number of root name server ip addresses beyond 13, therapidly increasing use of anycast addressing has enabled the root nameserver system to respond to both the technical and institutional requirements through the addition of multiple geographically distributed anycastroot server satellites. even so, since it addresses the distribution only of36see tony lee, brad huffaker, marina fomenkov, and kc klaffy, òon the problem ofoptimization of dns root servers placement,ó passive measurement and analysis workshop, 2003, available at <http://www.caida.org/outreach/papers/2003/dnsplacement/>.37see òdns message formató in section 3.2.4 for an explanation of the technical limitations.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.102signposts in cyberspacetable 3.1 the 13 root name servers and their anycast satellites as ofdecember 2004nameoperatoraverisign naming and directory servicesbinformation sciences institute, university ofsouthern californiaccogent communicationsduniversity of marylandenasa, ames research centerfinternet systems consortium, inc.gu.s. dod network information centerhu.s. army research laboratoryiautonomica/nordunetjverisign naming and directory serviceskr”seaux ip europ”ensñnetwork coordination centrelicannmwide projectsource: this table derives directly from information provided at<http://www.rootservers.org> as accessed on february 13, 2005.servers and not of the operating institutions, the location issue is likely tocontinue to add some political acrimony to any selection process thatmight follow from the withdrawal of one of the current operators. (seesection 5.3.)there is no standard hardware and software implementation of theroot name servers. each of the responsible organizations uses its preferredequipment and operating and file systems, although most of them runsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state103some version of the bind name server software.38 although there mightbe some operational advantages to having standard implementations,locationscountrydulles, vausamarina del rey, causaherndon, va; new york city; chicago; los angelesusacollege park, mdusamountain view, causapalo alto, ca; san jose, ca; new york city; san francisco; ottawa;usamadrid; hong kong; los angeles; rome; auckland; s‰o paulo;beijing; seoul; moscow; taipei; dubai; paris; singapore; brisbane;toronto; monterrey; lisbon; johannesburg; tel aviv; jakarta;munich; osaka; praguevienna, vausaaberdeen, mdusastockholm; helsinki; milan; london; geneva; amsterdam;swedenoslo; bangkok; hong kong; brussels; frankfurt; ankara; bucharest;chicago; washington, dc; tokyo; kuala lumpurdulles, va (2 locations); mountain view, ca; sterling, va (2 locations);usaseattle, wa; amsterdam; atlanta, ga; los angeles; miami;stockholm; london; tokyo; seoul; singaporelondon, amsterdam, frankfurt, athens, doha, milan,nlreykjavik, helsinki, geneva, poznan, budapestlos angelesusatokyo, seoul, parisjapan38since bind 8 and bind 9 have different code bases, this is less of a problem than itwould be if they were identical. the k root and some instances of other servers runnsd name server software from nlnet labs of amsterdam. verisign runs its ownname server software.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.104signposts in cyberspacemost internet technologists believe that variation in the underlying hardware and software of the root name server system is highly desirable,since it ensures that an error in a particular piece of hardware or softwarewill not lead to the simultaneous failure of all of the root servers.as the number and rate of queries to the root name servers have increased, hardware and software upgrades have enabled the servers to keepup.39 however, the pace of inquiries is likely to continue to grow and it isconceivable that it could, in principle, exceed the capacity of a system comprising even the most powerful single computers. because of anycastingand multiprocessing, through which a root server can comprise multipleprocessors, the number of computers at each rootserver address is effectively unrestricted. moreover, it is plausible to expect continued improvements in computing and communications performance. consequently, it isbox 3.4verisignverisign, inc., founded in 1995, describes itself as providing òintelligentinfrastructure services that support the digital economy.ó its acquisition in2000 of network solutions, inc. made it the registry for three gtlds: .com,.net, and .org and the operator of the aroot and the jroot name servers.it currently operates the aroot and jroot name servers, the hidden rootprimary, and the name servers for the .com, and .net tlds. at the end of2004, its naming and directory services unit managed a database of over38 million names in the .com and .net gtlds; owned and maintained 13gtld name server sites around the globe that handled the more than 14billion transactions per day for those two gtlds; and provided access tothe .com and .net gtld registries for more than 150 icannaccreditedregistrars that submit over 100 million domain name transactions daily toits shared registration system.as a registrarñthrough a subsidiary renamed network solutions, inc. in2003ñit registered more than 500,000 new domain names during the second quarter of 2002, and an additional 700,000 names were renewed orextended. more than 8.7 million active domain names in .com and .netwere under management by verisignõs registrar. however, in october2003, it sold network solutions to a private equity firm for $100 million.11this information was obtained from <http://www.verisign.com> on february 13, 2005.39this is only a portion of the total potential query load to the root zone file because ofcaching of queries by many name servers, and especially those of large isps, as noted above.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state105unlikely that the query load will ever be able to outrun the computing capacity of the 13 named root name servers and their satellites.3.3.3 institutional framework of the root zonebecause the root is central and critical to the operation of the dns,decisions about the root zone and the root name servers are of substantialimportance, and the institutions that bear responsibility for them take onan important role as stewards of the dns.those institutions carry out four critical functions:1.deciding what new or revised entries will be permitted in the rootzone file;2.creating the root zone file, keeping it current, and distributing it toall the root name servers;3.selecting the locations and the operators of the root name servers;and4.establishing and continually and reliably operating the root nameservers.the diverse collection of institutions that performs these functionsincludes a notforprofit corporationñicann; a u.s. governmentagencyñthe department of commerce; a corporationñverisign; and aninformal group consisting of the commercial, noncommercial, and governmental root name server operators.approving the root zone fileñu.s. departmentof commerce and icannthe fundamental importance of the root zone file to the operation ofthe dns and, therefore, of the internet means that special attention is paidto the process by which new or revised entries to the file are authorized.some process must be in place to decide whether a change is legitimate;otherwise, persons or organizations with malicious motives or inadequatecapabilities could make or revise entries. currently the authority to makechanges lies with the u.s. department of commerce (doc).40 however,the daytoday operational responsibility is at verisign. as part of thedocõs delegation of responsibility to icann (see box 3.5), the process ofauthorization for new or modified entries in the root zone was changed.40see section 2.7 for a history of that authority.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.106signposts in cyberspaceall such requests go first to the internet assigned numbers authority(iana) (now a function of icann) and then to the doc for final approval. once the addition or change is approved, the doc notifies ianaand verisign. verisign naming and directory services then makes thechange in the hidden primary, which distributes the changed root zonefile to the other root name servers (see òoperating the root name serversó in section 3.3.3).there are three kinds of changes to the root zone file. the first kind ofchange is a modification of the data associated with an existing resourcerecord. this might entail a change in the ip address of one or more of thebox 3.5the internet corporation forassigned names and numbersas described in chapter 2, the internet corporation for assigned namesand numbers (icann) is a notforprofit corporation founded in october1998 in california by a group of individuals interested in the internet. itwas sponsored by the u.s. department of commerce (doc) to serve as atechnical coordination body for the internet. consequently, icann hasassumed responsibility (under a memorandum of understandingñand itssix amendmentsñwith the doc) for a set of technical functions previouslyperformed under u.s. government contract by the internet assigned numbers authority (iana) and other groups. however, in practice, many of itsmost important and controversial activities have been as a policysetting,rather than as a technical coordination, body.iana continues as a function of icann with overall administrative responsibility for the assignment of ip addresses, autonomous system numbers, toplevel domains, and other unique parameters of the internet. inaddition, icann is charged with coordinating the stable operation of theinternetõs root server system.icannõs primary governing body is its board of directors, which nowcomprises 15 voting members and the president, ex officio. dissatisfactionwith the composition of the board and with the nature of the selectionprocess inspired a reform effort that resulted in new bylaws that guided theselection of a new board in 2003. (see section 5.2.4, alternative f, for adescription of this reform.)icann has three supporting organizations: the address supporting organization (aso), which deals with the system of ip addresses; the countrycode names supporting organization (ccnso), which focuses on issues related to the countrycode toplevel domains; and the generic namessupporting organization (gnso), which handles issues related to the generic toplevel domains. in addition, it has four advisory committees: theatlarge advisory committee (alac) for the internet community atlarge;the dns root server system advisory committee (rssac) for root serversignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state107name servers resulting, for example, from a change in the network serviceprovider. the data entry process is straightforward, and so such changesshould be routine and rapid. however, they do require a stage of verification to ensure that the request is legitimate and not, for example, an effortby a third party to capture a toplevel domain. nevertheless, such requestsshould be processed in a few hours or days.the second kind of change is a shift in the responsibility for a tld,typically a cctld. in such redelegation cases, the questions that must beresolved may be more difficult and timeconsuming. (see òselecting theorganizations responsibile for the tldsó in section 3.4.3 for a discussionoperators; the governmental advisory committee (gac) for governments;and the security and stability advisory committee (ssac) for security.there is also the technical liaison group (tlg) for standardssetting organizations and an internet engineering task force liaison who provides technical advice to icann. the supporting organizations and advisory committees together represent a broad cross section of the internetõscommercial, technical, academic, noncommercial, and user communitiesand advise the board on matters lying within their areas of expertise andinterest.as part of the reform effort, icann adopted a new mission statement:the mission of icann is to coordinate the stable operation of theinternetõs unique identifier systems. in particular, icann:1.coordinates the allocation and assignment of three sets of uniqueidentifiers of the internetñdomain names, ip addresses and autonomous system (as) numbers, and protocol ports and parameter numbers.2.coordinates the operation and evolution of the dnsõs root nameserver system.3.coordinates policydevelopment as reasonably and appropriatelyrelated to the performance of these functions.icann is open to the participation of any interested internet user, business, or organization. it holds several meetings a year at locations aroundthe world.1 icann has been the subject of many controversies regardingits governance, its processes, and its decisions since its founding. the primary issues are discussed in section 5.2. a good sense of the full range ofcontroversies that have surrounded icann can be obtained from <http://www.icannwatch.org>, circleid (<http://circleid.com>), and icannfocus(<http://www.icannfocus.org>), through the resources that can be linked tofrom these sites, and from innumerable articles written about icann.1information about icann was derived from <http://www.icann.org> on february 13,2005.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.108signposts in cyberspaceof the issues.) in particular, they may entail judging which organization hasthe òrightó to operate the registry for a cctld, which can become embroiledin national politics. these changes will generally take longer but shouldproceed according to a formal and transparent process.the third kind of change is the addition of data about a new tld to theroot zone file (see òselecting the organizations responsible for the tldsóin section 3.4.3). this is a single process for new gtlds. an icann selection process recommends both the domain name that shall be added andwho shall operate it. it is a twostep process for new cctlds. who will beresponsible for operations is a separate recommendation from the decisionto add a cctld name to the list of cctlds. such changes should take placewithin a few days after the appropriate decisions have been made.maintaining the root zone fileñverisignverisign, as the operator of the hidden primary root zone server, isresponsible for maintaining the root zone file and for distributing it to thesecondary servers. it performs this function under the terms of a memorandum of understanding (mou) with the doc.since any errors in the root zone file can affect large numbers of sitesand users, accurate and errorfree preparation and distribution of the fileare essential. in the first instance, this is a human function. someone mustenter additions and updates into the database, create a new zone file, andcheck it for errors. individuals at the secondary sites must check to ensurethat the file has not been corrupted during its distribution. however, computer techniques and aids can be used to support this process and reducethe demands on humans. furthermore, regular queries of the root by eachof the tld operators can be used to test the entries corresponding to theirtlds and provide further assurance that no undetected errors are presentin the file.selecting the root name server operatorsñselfselectionthe current root name server operators were not selected through aformal evaluation and qualification process, although they play a fundamental role in ensuring the availability and reliability of the root. rather,the group is the cumulative result of a sequence of separate decisionstaken over the years since the establishment of the dns. it is a looselyorganized collection of autonomous institutions whose names are givenin table 3.1. ten of them are based in the united states. of those, three areassociated with the u.s. government (national aeronautics and spaceadministration (nasa), department of defense (dod), and the u.s.army), two are universities (university of maryland and university ofsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state109southern california), two are corporations (verisign and cogent communications), and two are notforprofits (isc, inc. and icann). threeare based outside the united states: one in sweden, one in the netherlands, and one in japan.one of the responsibilities that icann assumed under its agreementwith the doc is coordinating the stable operation of the root server system. to do so, it established the dns root server system advisory committee, whose responsibilities were spelled out in icannõs bylaws (article vii, section 3(b)).the responsibility of the root server system advisory committeeshall be to advise the board (of icann) about the operation of the rootname servers of the domain name system. the root server system advisory committee should consider and provide advice on the operationalrequirements of root name servers, including host hardware capacities,operating systems and name server software versions, network connectivity and physical environment . . . should examine and advise on thesecurity aspects of the root name server system . . . [and] should reviewthe number, location, and distribution of root name servers consideringthe total system performance, robustness, and reliability.the parties will collaborate on a study and process for making the management of the internet (dns) root server system more robust and secure.icannõs intent is to enter into an mou41 with each server operatorthat will spell out the root name server performance requirements, suchas service levels, reliability, and security. however, as of february 2005,no mous had yet been signed.in the absence of an agreed oversight role for icann, there is, atpresent, no formal process for selecting a new root name server operatorif one of the incumbents should withdraw, although it is clear that the setof remaining operators could, and probably would, work together to makethe selection. (see section 5.3 for a discussion of this issue.) operating the root name serversñthe root name server operatorsthe role of the operators of the 13 root name servers is to maintainreliable, secure, and accurate operation of the servers containing the current root zone on a 24houraday, 365 daysperyearbasis. each server isexpected to have the capacity to respond to many times the rate of queriesit receives and must increase its capacity at least as fast as the query rate41the dns root server system advisory committee has drafted a model memorandum of understanding, available at <http://www.icann.org/committees/dnsroot/modelrootservermou21jan02.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.110signposts in cyberspaceincreases. an attempt to define the responsibilities of the root name serveroperators was made in rfc 2870, issued in june 2000,42 but the ideal thatit describes has not been achieved.historically, the operators of the root servers have not charged feesfor resolving internet address queries, instead obtaining support in otherways for the substantial costs they incur in providing the service. theseoperators choose to do so either because (1) they believe that operating aroot server is a public service (and sufficiently inexpensive that they canafford the cost) or (2) they believe that operating a root server conveys abusiness, or other, advantage to them. nevertheless, it is a valuable service, whose provision is a littleknown and littleappreciated gift in kindto all users of the internet.3.3.4assessmentconclusion: the system of dns root name servers currently respondsto more than 8 billion queries per day43 and does so reliably and accuratelyas shown by its virtually uninterrupted availability and the very low occurrence of rootcaused misdirections. because the majority of queries areserved from cached answers lower in the hierarchy, the entire dns responds to many times that number each day with correspondingly goodresults. however, the robust operation of the root name servers is potentially vulnerable to an excessive query load, either inadvertent or malicious,that might slow down their responses or cause them to fail to respond.data collected about root name server operation has revealed that asubstantial fractionñbetween 75 percent and 97 percentñof the load onthose servers may be the result of erroneous queries.44 these errors fallinto three categories: stupidñfor example, asking for the ip address of anip address; invalidñfor example, asking for the ip address of a nonexistent domain; and repetitiveñfor example, continuing to send an incorrectquery even after receiving a negative response. analysis has revealed thatthe sources of many of these errors lie in faulty resolver or name serversoftware and faulty system management that misconfigures name servers42see randy bush, daniel karrenberg, mark kosters, and raymond plzak, òrootname server operational requirements,ó rfc 2870, june 2000, available at <http://www.rfceditor.org>.43the monthly average load on all root name servers in december 2004 was around90,000 queries per second according to the internet societyõs member briefing no. 20,òdns root name serversñfrequently asked questions,ó january 2005, available at<http://www.isoc.org/briefings/020/>.44the 97 percent figure is from wessels and fomenkov, òwow, thatõs a lot of packets,ó 2003. however, according to an anonymous reviewer, verisignõs experience onits two servers is closer to 75 percent.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state111or resolvers and does not monitor performance closely enough to catcherrors. the latter is not purely a technical issue but poses an institutionalissue.45 software developers, system administrators, and users generallyhave few incentives to make an effort to prevent the occurrence of thisextra load.in addition, the system of root name servers may be vulnerable tomalicious attempts to overload it. in october 2002, the root name serversystem was subjected to such a denialofservice attack that sought toswamp the system with queries.46 eight of the 13 servers were inaccessible from some places on the internet for an hour or more, but the remaining 5 served the internet without observable degradation. althoughthe system successfully resisted this attack, which lasted only an hour anda half, it should serve as a warning about the potential for longer andmore sophisticated attacks in the future.conclusion: the root name servers receive far too many incorrect orrepetitive queries, increasing the load that they must serve. this unnecessary load arrives at the root name servers because many sites on theinternet employ faulty software, misconfigure their resolvers or nameservers, or do not manage their systems adequately. the root name serveroperators, however, lack the means to discipline the sites at fault.conclusion: the root name servers are subject to malicious attack,but through overprovisioning and the addition of anycast satellites havesubstantially reduced their vulnerability to denialofservice attacks. furthermore, the widespread caching of the root zone file and its long time tolive mean that the dns could continue to operate even during a relativelylong outage of most or all of the root name servers and their satellites.recommendation: to be able to continue to meet the increasing queryload, both benign and malign, the root name server operators should continue to implement both local and global load balancing through the deployment of anycast satellites.45these analyses have been sponsored by the cooperative association for internetdata analysis (caida) and have been reported in many publications. in addition tothe wessels and fomenkov study, see, for example, nevil brownlee, kc claffy, and evinemeth, òdns measurements at a root server,ó proceedings of ieee globecom, caida,san antonio, tex., november 2001, pp. 16721676. also see <http://caida.org/outreach/papers/2001/dnsmeasroot/>.46see, for example, david mcguire and brian krebs, òattack on internet calledlargest ever,ó washington post, october 22, 2002. three root server operators coauthored an authoritative report about the attack. it can be found at <http://d.rootservers.org/october21.txt>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.112signposts in cyberspaceconclusion: notwithstanding the deployment of anycast serversand installation of backup servers at remote locations, the concentration of root name server facilities and personnel in the washington,d.c., area and, to a lesser extent, in the los angeles area is a potentialvulnerability.recommendation: the need for further diversification of the locationof root name server facilities and personnel should be carefully analyzedin the light of possible dangers, both natural and human in origin.conclusion: the system of root name servers lacks formal management oversight, although the operators do communicate and cooperate.not everyone would agree that formal oversight is desirable. should oneor more of the current root name server operators withdraw from thatresponsibility, or fail to exercise it reliably, effectively, or securely, therewould be no responsible organization or formal process for removing thefailed operator or for recruiting and selecting a replacement. in their absence, the informal, collegial processes that led to the current group ofoperators would likely continue to be used.conclusion: the root name server operators have provided effectiveand reliable service to the community of internet users without any formof direct compensation for that service from the users. with the growth inthe scale and economic importance of the internet, and with the expenseof ensuring secure operation, the root name server operators face increasing costs and potential liabilities that some, at least, may find too great tomeet without compensation.47 indeed, the current system for maintaining root servers may well face additional economic pressures, as well astechnical ones, as the volume of internet traffic increases, especially if thenumber of tlds were to be expanded.the root zone must be kept secure and robust in the face of possible future threats. moreover, the continued stable management andfinancing of root zone operations must be ensured for the dns tofunction. these challenges and approaches to meeting them are discussed in section 5.3.47as noted in presidentõs report: icannñthe case for reform, february 24, 2002, ò. . .some organizations that sponsor a root name server operator have little motivation tosign formal agreements [with icann], even in the form of the mou that is nowcontemplated. what do they gain in return, except perhaps unwanted visibility andthe attendant possibility of nuisance litigation? they receive no funding for their efforts, so why should they take on any contractual commitments, however loose?ó thesame logic raises questions about their incentives to continue to operate the root nameservers. see <http://www.icann.org/general/lynnreformproposal24feb02.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state1133.4implementationñthe toplevel domainsthe portion of the dns hierarchy that has captured the most publicattention and attracted the greatest controversy is the level just below theroot, the toplevel domains. as noted above, in february 2005 there were258 such domains in the two major categories defined in the early days ofthe dns (see section 2.2.1): 243 country code toplevel domains (cctlds)and 15 generic toplevel domains (gtlds). these tlds are, in turn, thetop of a hierarchy of secondlevel domain names. typically, the commercial gtlds have very flat structures with many secondlevel names, butthe others vary widely, some having very deep structures. the cctldsalso have a wide range of structures, some having several levels of hierarchy, which may be structured geographically or generically.3.4.1characteristics of the tldscctldsthe 243 cctlds are each associated with a nation or region or external territory and designated by the twoletter abbreviation for that entityassigned by the international organization for standardization in iso31661.48 examples of cctlds are .ke for kenya, .jp for japan, and .de forgermany.49 the expectation was that a cctld would signify a locationand would be supervised and administered by an organization in the corresponding location, and be limited to registrants with a presence there;however, these criteria are not effectively enforced. moreover, a numberof small nations and territories have licensed administration of their domainsñfor example, .tv for tuvalu and .cc for the cocos islandsñto commercial bodies that register anyone who wishes to use that cctldõs twoletter domain. such cctlds are for all practical purposes equivalent tocommercial gtlds. this equivalence is further explored inòrecharacterizing tldsó in section 3.4.1.the largest cctlds are listed in table 3.2, as are most of thosecctlds, shown in boldface, that have contracted for commercial use oftheir domains. the .us domain, which had been limited to third andfourthlevel registrations in a localitybased hierarchy, is shown in italics. in april 2002, registration at the second level in .us was opened with48see <http://www.iso.org/iso/en/prodsservices/iso3166ma/index.html> for a listof the abbreviations.49there are a few exceptions to the use of iso 31661 twoletter abbreviations. forexample, the united kingdom is assigned .uk rather than .gb (for great britain). icannhas also assigned cctld twoletter codes to each of the channel islands and to ascension island, which are not in iso 31661, because it was anticipated that they would beadded to the list.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.114signposts in cyberspacethe intent that any u.s. citizen or resident and any business or organization with a bona fide presence in the united states could register a domain name in .us.50table 3.2 shows the number of domains registered at the first available level under each toplevel domain in february 2003. the total at thattime was just over 19 million. by december 2003, almost 24 million domains had been registered in cctlds, and by november 2004 it hadreached 25.6 million. as noted above, some country code tlds have further generic or geographic substructures. in those cases, the count of domains is the sum of those registered under each second or thirdleveldomain, depending on the highest level at which registration by the general public is permitted.gtldsthere are 15 gtlds, 8 that date from the early years of the dnsñ.net,.com, .org, .edu, .gov, .mil, .int, and .arpañand 7 that were authorized byicann in november 2000. as their designations suggest, the expectationwas that registration in the original gtlds would be by types of organizations. commercial organizations were expected to register in .com, accredited educational organizations in .edu, network infrastructure organizations in .net, u.s. government organizations in .gov and .mil, andinternational treaty organizations in .int. the .org tld was created fororganizations that did not fit into one of the other gtlds. the designation.arpa was assigned for network infrastructural use.in announcing the authorization of the seven new gtldsñ.biz, .info,.name, .aero, .museum, .coop, and .pro, icann distinguished betweensponsored and unsponsored tlds. those that are sponsored have a notforprofit organization representing the community of potential registrants.the charters of the sponsored tlds specify that registrants are restricted tothose satisfying criteria appropriate to that community. thus, .aero is restricted to people, entities, and government agencies that (1) provide forand support the efficient, safe, and secure transport of people and cargo byair and (2) facilitate or perform the necessary transactions to transportpeople and cargo by air. registrations in .museum are restricted to entitiesthat are recognized by the international council of museums as museums,professional associations of museums, or individuals who are professionalmuseum workers. and registrations in .coop are restricted to members ofthe international cooperative movement, which is further defined by mem50the localitybased use of .us seems to be declining, which raises questions aboutthe relative merits of registrations at the second level and their associated revenuemotivations versus the benefits of the localitybased structure of .us.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state115bership in one or more of eight specific classes. icann allows unsponsoredtlds to be either restricted or unrestricted. thus, .info is unrestrictedñanyone can register a name in .info, whereas .name is restricted to individuals and .biz is restricted to bona fide business or commercial uses. determination of who is eligible to register is up to the domain operatoroperating under the terms of its agreement with icann.table 3.2 some large countrycode toplevel domainscctldcountry or territoryregistered domain namesa.degermany 6,117,000.ukunited kingdom 4,168,000.nlnetherlands 827,000.ititaly 767,000.arargentina 627,000.jpjapan 568,000.usunited states 529,000.krrepublic of korea 507,000.cccocos (keeling) islands 500,000.chswitzerland 500,000.dkdenmark 428,000.brbrazil 427,000.auaustralia 343,000.cacanada 310,000.ataustria 272,000.tvtuvalu 262,000.bebelgium 238,000.wswestern samoa 183,000.cnchina 179,000.plpoland 175,000.frfrance 163,000.rurussian federation 156,000.zasouth africa 134,000.twtaiwan 123,000.nuniue 112,000.totonga 97,000total (including cctlds not listed above) 25,637,000note: individual domain data is for february 2003; the total is for november 2004.asource: icannõs budget for fiscal year 20032004. see <http://www.icann.org/financials/revisedproposedbudget24jun03.htm>. domain name counts where not available are estimated from the average of all other cctlds for which data is available (fromweb sites or other direct information). these estimated counts represent about 16 percent ofall cctld domain names. the total (for november 2004) was provided by matthew zook,department of geography, university of kentucky.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.116signposts in cyberspacethe 15 generic tlds are shown in table 3.3 together with, for each, itstype and purpose, the organization responsible for its operation, and thenumber of secondlevel domains that are registered in it. note, however,that in many domains there are far more registrants at the third and lowerlevels.recharacterizing tldsalthough a distinction between generic tlds and national or countrycode tlds is widely accepted and used in policy discussions, the realityof practice is that the distinctions have been significantly eroded.table 3.3generic toplevel domains in 2004gtldtypecurrent purpose.comunsponsoredunrestricted.netunsponsoredunrestricted.orgunsponsoredunrestricted.edusponsoredu.s. accredited highereducational institutions.milsponsoredu.s. military.govsponsoredu.s. governments.arpasponsoredinternet infrastructure.intunsponsoredinternational treatyorganizations.infounsponsoredunrestricted.bizunsponsoredbusinesses.nameunsponsoredindividuals.prounsponsoredprofessionals.museumsponsoredmuseums.aerosponsoredairtransport industry.coopsponsoredcooperativesasource: icannõs budget for fiscal year 20032004. see <http://www.icann.org/financials/revisedproposedbudget24jun03.htm>. domain count data provided courtesyof matthew zook, department of geography, university of kentucky. ongoing data seriesare available at his web site <http://www.zooknic.com/>.bneulevel is a joint venture of neustar, inc., and australiabased melbourne it, ltd.c.pro started accepting registrations in the united states on june 1, 2004, from licensedmds, lawyers, and cpas; added canadian and u.k. professionals in september 2004; andadded engineers in february 2005.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state117organizationdomainsaverisign grs33,352,000cverisign grs 5,324,000cpublic interest registry (pir) 3,307,000cas of january 1, 2003educause 7,400cu.s. dod network information center?cu.s. general services administration (gsa) 1,100cinternet architecture board/internet assigned?c numbers authority (iana)iana 88caflilias, llc 3,334,000cneulevelb 1,088,000cglobal name registry 87,000cregistry.proñcmusedoma 658dsita 4,000+edotcooperation, llc 7,992ftotal46,412,000gddata provided by cary karp, president and ceo, musedoma, personal communication,february 20, 2004.eas listed on the .aero web site in february 2005. see <http://www.information.aero/users.php>.fas of february 2004. carolyn cooper, dot coop operations center, personal communication, march 17, 2004.gtotal reported on the zooknic web site at <http://www.zooknic.com>, february 2005.among the generic gtlds, threeñ.edu,51 .mil, and .govñare currentlyrestricted to new registrations by u.s. organizations and, in principle, couldhave been established as secondlevel domains under the .us cctld.as noted above, among the cctlds, a numberñincluding .cc, .tv, .bz,.ws, .nu, and .toñactively seek global registrants and function as thoughthey were gtlds.51some nonu.s. educational institutions, such as the university of toronto and theunited nations university, retain their registrations from an earlier, less restrictivetime. also, registrations from foreign but u.s.accredited educational institutions arecurrently being accepted.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.118signposts in cyberspacemoreover, the registrants in some gtlds have not been limited tothose originally expected. in practice, .com, .net, or .org have all beenoperating as unrestricted tldsñany person or organization can registerin them.since many policy issues concern the desirable number and type oftlds, it is useful to introduce a characterization of tlds that better captures the reality of their current state.in table 3.4, the tlds are recharacterized into eight types, designatedby the numbers 1 to 8, which are given in the first column. the secondcolumn, òtld,ó indicates whether the domain is currently considered agtld or a cctld.the òscopeó column shows whether the tld is open to registrantsfrom anywhere on the globeñglobalñor is primarily for those who arelocated within the national boundaries of the countryñnational. (manycctlds that are primarily national will accept some nonnational registrants, but usually they must have an association with the country.) inaddition, the .arpa tld is open only to register elements of the infrastructure of the internet, so its scope is designated as infrastructural.the òrestrictionó column in table 3.4 indicates whether the generictld or, within national boundaries, the cctld has second or thirdleveldomains that are intended to be restricted to members of specific communities (however, the enforcement of these restrictions varies widely). mostcctlds have no restrictions on registrations at the second level, but some,such as .ar (argentina) and .au (australia), and the .us (united states)until recently, register only at the third level under a limited number ofrestricted secondlevel domains, such as com.ar and com.au for commercial organizations. however, great britain, .uk, has some secondleveldomains that are restricted, such as ltd.uk and plc.uk, and others, such asco.uk, that are not. as with other aspects of the dns, restriction withincctlds is not really òyesó or òno,ó but more accurately òyes,ó òno,ó oròsome.ó that situation is reflected in table 3.4 by treating secondleveldomains of such cctlds as though they were òseparateó tldsñsee theexamples in 7 and 8.the òsponsoró column indicates whether an organization representative of a community has responsibility for managing a gtld and for enforcing registration restrictions, if any. the concept of sponsor for a cctldis less clear. to some degree, for example, the governments of the unitedstates and of france, for example, can be viewed as the sponsors of theircctlds. the corresponding entries are left blank.thus, among the 15 current gtlds, 4 are of type 1ñ.com, .net, .org,and .info. type 2 includes three tlds—.museum, .aero, and .coop. thereare four in type 3: .name, .biz, .pro, and .int. that leaves three in typesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state1194ñ.edu, .mil, and .gov, which are discussed below as cctldsñand onein type 8, .arpa.it has not been possible to assign a type to each of the 243 cctlds, butexamples of each of the four types have been identified in table 3.4.type 5 comprises many cctlds that function as generic tlds. asnoted above, they are generally small countries that have recognized, orbeen shown, that their twoletter designation can be marketed globally tocompanies and individuals who would find it commercially or personallyvaluable. thus, the lease of the domain name of tuvalu (population:11,000) could provide that pacific island nation with $50 million in royalties over the next dozen years. the .tv corporation, a subsidiary ofverisign, in june 2005 listed on its site such òpremium registrationsó asbusiness.tv, which is available for $1 million, and weather.tv, which wouldcost the registrant $250,000. the administrator of this tld is the ministryof finance and tourism of tuvalu, although in fact, the ministry appearsto have delegated all of its decisionmaking authority to the .tv corporation as a part of the lease. other nations are managing their globally available domains themselves. western samoa (population: 178,000), anotherpacific island nation, markets .ws directly and handles the registrationlocally. western samoa had two isps and 3000 internet users in 2002.52table 3.4types of toplevel domainstypetldscopeintended restrictionsponsorexamples1gtldglobalnono.com, .net,.info, .org2gtldglobalyesyes.aero, .museum,.coop3gtldglobalyesno.biz, .name,.pro, .int4gtldnationalyesyes.mil, .gov, .edu5cctldglobalnoð.cc, .tv, .bz6cctldnationalnoð.jp, .fr, .us,.co.uk7cctldnationalyesðcom.au, id.au,.ltd.uk8gtldinfrastructuralyesyes.arpa52see cia, the world factbook, 2004, available at <http://www.odci.gov/cia/publications/factbook/fields/2028.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.120signposts in cyberspacewhile some cctlds function as gtlds, type 4 comprises the threegtlds that function like cctldsñ.edu, .gov, .mil. all three are limited toregistrants in the united states that are, in turn, restricted to specific communitiesñprimarily accredited higher educational institutions,53 civiliangovernment54 agencies, and federal military agencies.the remaining two types distinguish between restricted and nonrestricted cctlds. almost all cctlds are unrestricted at the second andthird levels and fall into type 6, but some, such as australia, argentina,and austria, have introduced categories resembling the gtld categoriesas their second levels. they belong to type 7. thus, australians cannotregister directly in the .au domain but must instead use the category appropriate to their status: com.au for commercial organizations, asn.au forassociations, id.au for individuals, and so on.thus, the apparently simple distinction between gtlds and cctldsis really more complex. the differences among tlds lie in the differencesin the policies that they operate under, not in whether they were originally associated with a country code or a generic category.3.4.2technical system of the tldsevery tld has an associated zone file, which is stored in name servers whose addresses are recorded in the root zone file. icann requiresthat there be at least two name servers for each cctld and at least five foreach gtld with which it has agreements. some tlds have as many as 13name servers, depending on the query load, the need for security againstattack, and their desire to improve access by their users. each name serveris implemented on one or more computers, most of which run a version ofbind.55the zone files on all tlds are larger, generally very much larger, thanthe root zone file. at the extreme, .com contains more than 33 millionsecondlevel domains, but even greenland has more than 1200 domainsregistered. moreover, because of the hierarchical nature of dns search,53as noted previously, some nonu.s. academic institutions have been ògrandfatheredinó or will be registered if they are accredited in the united states. also, there aresome other exceptions such as the thomas jefferson high school for science and technology, whose domain name is tjhsst.edu.54originally it was limited to federal agencies. it is now open to registration by stateand local governments and native sovereign nations.55however, the name server for .org (and for some other tlds) is operated byultradns, which uses its own proprietary name server software; and verisign, whichruns .com, .net, .bz, and .tv, also uses its own proprietary name server software,atlas.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state121the ease of caching the labels and associated resource record sets in thesmall root zone file, and the long ttls within that file, the tld nameservers receive a greater number of queries than the root name servers.for example, according to verisign .com and .net alone receive over 14billion queries per day, while the root receives about 8 billion queries perday.tld name servers face specific unique technical issues distinct fromthose that involve the roots. one issue is increased traffic resulting fromlow ttls on secondlevel zone records. a popular secondlevel zone canincrease traffic to its parent tld name servers by lowering its ttl, effectively defeating the dnsõs caching mechanism. (the root name servers donot suffer from this potential problem to the same extent, since tld nameservers give out mostly referrals. as a result, name server caches throughout the internet retain the copy of the tld records from the root zonewith their 48hour ttls.56)tlds probably receive some bogus queries, but perhaps not as manyas the root, since at least a portion of the query must be correctñthetld name. their name servers face the same vulnerabilities that arefaced by the root name servers. however, although the effect would besignificant if the operations of large tlds such as .com or .uk were to beinterrupted, the consequence of a short interruption of most tlds, individually, would not be significant for the overall internet. an attack thatcould take out a substantial number of tld servers would be significantbut difficult to sustain because of the number of distinct targets thatwould be involved.3.4.3 institutional framework of the tldsthe effective operation of the toplevel domains requires that an institutional framework perform four functions:1.deciding which new tlds will enter the root zone file,2.determining the organization to be responsible for a tld,3.determining the organization to operate a tldõs name server, and4.operating the tld registry.many different organizations, international and national, governmental and private, forprofit and notforprofit, including icann, verisign,and the doc, are engaged in these activities. their processes and interactions are complex and, often, controversial.56information provided by an anonymous reviewer.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.122signposts in cyberspaceselecting new tldsthe original dns design assumed a single, unified, name space (inwhich the set of names that one user is able to look up is the same set ofnames that any other user is able to look up).57 unless uncoordinatedentry into the root zone file is permitted, which would require that theoperators of the root servers recognize any tld that chooses to operate,some entity must decide how many and which tlds there will be andwho will operate them. òselecting new tldsó means deciding whichnew tlds will enter the root zone file. as described above, that decisionis made by the u.s. department of commerce upon the recommendation of icann. therefore, it is in the first instance a decision for icann.the decision process that is employed differs between cctlds andgtlds.cctldsthere is generally no need for a complex decision process for entry of cctlds since, as noted earlier, they are available to countriesand external territories represented by country codes in iso 31661.this list has been used as the authoritative source for country codesbecause, as was stated in rfc 1591, òthe iana is not in the businessof deciding what is and what is not a country.ó58 when new entitiesare assigned a twoletter identifier by the iso, that entity is automatically entitled to have a cctld. however, two situations have arisenthat cannot be resolved solely by this rule. the first occurs when acountry is removed from the iso list. the twoletter code for the soviet union, su, was removed from the list in september 1992 andplaced in òtransitional reserved status,ó which means that its useshould be stopped as soon as possible. but, although this issue is onicannõs agenda, it has not yet addressed the complicated issues thatarise when a country is removed from the iso 31661 list. indeed, it isstill possible to register in the .su domain, and this domain remainsin the root.the second situation occurs when an international entity requests acctld that is not on the iso 31661 list. in july 2000, the european commission wrote to icann requesting the inclusion of the .eu domain in57it is this assumption that alternative or multiple roots violate. this discussionassumes a single root.58jon postel, òdomain name system structure and delegation,ó rfc 1591, march1994, p. 6, available at <http://www.rfceditor.org>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state123the dns root.59 its request noted that the iso had agreed to use of thetwoletter code eu as a tld. (the code, although not in iso 31661, hadòexceptional reserved statusó enabling its use for specific isoapprovedpurposes.) at its september 25, 2000, meeting, the icann board passeda resolution that approved for delegation as cctlds those codes fromthe isoõs exceptional reserved list for which the reservation permits anyapplication requiring a coded representation of the entity.60 in march2005, icann authorized the creation of the .eu tld, which is expectedto begin operation in early 2006.61 it will be open to any person living inthe eu, as well as businesses with their headquarters, central administration, or main base in the eu.62 the exceptional reserved list is nolonger published, and a policy has been implemented to prohibit thecreation or reservation of an unrestricted name that is not on the iso31661 list. the process of deciding who will be delegated responsibility for operating a cctld upon its first entry into the root, or for redelegating responsibility subsequently, can become very complex. this process is discussed in the next section and in section 5.5.gtldsthe gtlds are a different matter. they fall into two groups: the firsteight, which were selected at the time of initiation of the dnsñthe legacygtlds; and the seven that were selected by icann in 2000 for additionto the rootñthe new gtlds. (an additional 4 to 10 are being added during 2005 as the result of an icann selection process initiated in 2004. seealternative a under òwhat selection process should be usedó in section5.4.2.)the legacy gtlds were selected by the developers of the dns and agroup of network and information center operators. jon postel, writing59letter from erkki liikanen, member of the european commission, to mike roberts, (then) ceo and president of icann, dated july 6, 2000, available at <http://europa.eu.int/ispo/eif/internetpoliciessite/doteu/letterliikanenroberts.html>.60icann, òpreliminary report. special meeting of the board,ó september 25, 2000,available at <http://www.icann.org/minutes/prelimreport25sep00.htm#00.74>.61see ellen dumout, òicann approves .eu net domain,ó c/net news.com, march 24,2005, available at <http://news.com.com/2100103835634121.html>.62see the october 2004 eu fact sheet, òopen for business in 2005: yourname.eu.,óavailable at <http://europa.eu.int/informationsociety/doc/factsheets/017doteunovember04.pdf>. there is a more complex story behind the .eu tld, but it is beyondthe scope of this chapter.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.124signposts in cyberspacealmost 10 years later, still maintained a policy that he expressed as: òit isextremely unlikely that any other tlds will be created.ó63 however, bythe following year, postel had changed his mind and recommended thecreation of new tlds to compete with nsi, which had a monopoly incommercial gtld registrations, and in 1996 he recommended the creationof 150 or 300 new tlds. at the same time, the rapid growth in size andscope of the internet, driven by the introduction of the world wide web,created a heavy demand for secondlevel domain names in the gtlds,especially in .com. (see section 2.5.1.) that, in turn, led to a public demand for additional gtlds. in response to that demand (some wouldargue it was a belated response), icann created a process, which it usedduring the year 2000 to select the new gtlds. icann treated the addition of gtlds as an experiment in order to seek compromises that wouldsatisfy the contending interest groups, although that did not prevent theadditions from becoming controversial. since that process also entailedselecting the organizations responsible for the tlds and the tld nameserver operators, its description is deferred to òselecting the tld registryoperatorsó below.to at least some degree, tlds compete with one another for the patronage of those entities that wish to register domain names, although themaximum prices that icann has negotiated with the gtlds limit theextent of this competition. this competition might be more intenseñbothwith respect to the prices charged and the services offeredñthe larger thenumber of competitors, although beyond some point the effect of additional entry is likely to be small and the costs of switching from one domain to another are likely to give incumbents a strong advantage. in anyevent, even when firms wish to operate tlds, either because they observeincumbents earning large profits or because they believe they can offerbetter or cheaper services, entry is constrained by their need to obtainapproval from icann for inclusion in the root file.64over the past few years, the demand for registrations in the tlds hasgone through several changes. while the cctld registrations have growncontinually throughout the period, those in the previously rapidly growing gtlds declined in the aftermath of the dotcom bust and only beganto grow again in mid2002. according to icann writing in mid2003:òthe domain name counts for cctlds have jumped 22% over the numbers used last year [in the budget]. the count for gtlds, however, has63postel, rfc 1591, 1994, p. 1.64some limitations on entry may have a legitimate practical basis. nor is it clearwhether a small number of large tlds are to be preferred to a large number of smallerones. in any event, incumbents can be expected to wish to limit the competition thatthey face, whether or not there is a legitimate basis for such limits.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state125declined 5%, largely due to a dropoff in .com whose statistics dominatethe overall gtld count because of its comparative size.ó65 in fact, thename counts in all three of the largest gtldsñ.com, .net, and .orgñdeclined from 2002 to 2003. both .net and .org declined by 14 percent. however, by august 2003, another source reported that the total number of.com, .net, and .org domain names had returned to the high mark of 30.7million reached in october 2001.66 sustained growth had returned in july2002, and over the next 13 months the total registrations in those threedomains grew an average of 250,000 per month. as further confirmationof the renewed demand for those gtlds, verisign reported67 that an average of 1.2 million new registrations for domain names ending in .comand .net were added each month in the third quarter of 2004ña 33 percent increase over the third quarter of 2003.ó68selecting the organizations responsible for the tldsicann has been delegated authority by the doc (and subject to thedocõs approval) over entries in the root zone and, consequently, it candetermine which organization is delegated responsibility for each cctldand gtld. the delegated responsibility entails arranging for the establishment and operation of (1) name servers for the tld satisfying internettechnical requirements and (2) a domain name registration process thatmeets the needs of the local or international internet communities.in the case of cctlds, the organizations with delegated responsibilityare designated managers or sponsors, and they are designated the sponsors for sponsored gtlds. sponsors are primarily either government ornotforprofit organizations that provide their own funding, althoughprofitmaking organizations run the commercial gtlds and some cctlds.in both groups of tlds, the responsible organization need not operate therequired name server and domain registration functions itself and generally contracts with a specialist organization, which may be a commercialservice, to carry out those functions. in the case of the seven unsponsored65see icannõs budget for fiscal year 20032004, available at <http:// www.icann.org/financials/revisedproposedbudget24jun03.htm>.66zooknic internet intelligence, ògtld domains returning to 2001 levels,ó pressrelease. august 25, 2003, available at <http://www.zooknic.com/pr20030825.html>.67verisign, òverisign issues quarterly domain name industry brief; overall domain name registration tops past record of 66.3 million,ó december 1, 2004, available at <http://www.verisign.com/verisigninc/newsandevents/newsarchive/usnews2004/page019484.html>.68see also linda rosencrance, òdomain name registrations hit alltime high,ócomputerworld, june 8, 2004, available at <www.computerworld.com/developmenttopics/websitemgmt/story/0,10801,93716,00.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.126signposts in cyberspacegtlds (other than .int), the responsible organization and the operatingorganization are the same and had until recently all been commercial services. however, icann designated public interest registry (pir), a notforprofit, to manage .org beginning in 2003. pir has contracted with adublinbased company, aflilias, to provide the registration services andafilias has contracted, in turn, with a commercial provider of dns services, ultradns, to run the name servers.for the cctlds and the legacy gtlds, icann must have a processfor recognizing the organizations that will be responsible for the tldwhen a new cctld is added or when a change of responsibility is desiredfor whatever reason. the processes used for the cctlds and the legacygtlds are different. they are described below. for the new gtlds, theprocesses of selecting a manager and selecting an operator were combinedsince the prospective managerõs choice of operator was one factor in themanager selection decision. that combined process is described below inòselecting the tld registry operators.ócctldsiana began delegating responsibility for cctlds shortly after the deployment of the dns and most delegations predate the formation oficann. icannõs policy has been not to challenge these except in caseswhere a government seeks redelegation.69 in the early days of the dns,responsibility for cctld management was usually assigned to the internetpioneers who volunteered for the task. generally, there was only one interested organization since, at the time, the commercial prospects were thoughtto be minimal. even so, there was considerable due diligence on many applications to determine that other possible applicants had been identifiedand, if there were any, that they supported the active application. therewere, however, some cases of multiple applications and postdelegationchallenges by those who sought various other benefits such as prestige orthe ability to leverage the role into sale of internet services. the managersagreed to abide by a set of policies for the administration and delegation ofcctlds that covered technical requirements and the circumstances underwhich iana would make or change a delegation of responsibility.70 oftenthe corresponding governments did not know or did not care about theinternet or the applicable cctld.69this section draws extensively on material in icann, òupdate on cctld agreements.ó september 20, 2001, available at <http://www.icann.org/montevideo/cctldupdatetopic.htm>. see also jon postel, rfc 1591, 1994.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state127with the growth in the size and importance of the internet and theformation of icann, that situation has changed. governments increasingly want to participate in the selection and oversight of the manager oftheir cctlds.71 furthermore, icann felt the need for more precisely described agreements spelling out the mutual obligations and responsibilities among governments, icann, and the delegated managers of cctlds.consequently, the board of icann authorized the development of suchagreements with the cctlds.according to icann, it was soon realized that no single agreementor, even, structure of agreement would fit every cctld. however, afterconsideration of the wide variety of specific circumstances in the 243cctlds, icann found that most would fit into one of two general situations that differ principally in the involvement of the local government orpublic authority. in the first, legacy situation, the government is not involved. in the second, triangular situation, it is, thus yielding three participants: a cctld, icann, and a local government. icann proposedtwo types of agreements, corresponding to these two situations.according to the proposed agreement for the legacy situation, thecctld manager would operate under the oversight of icann only, subject of course to the laws of the country. icann would have the soleresponsibility to ensure that the cctld manager operates as a trustee forboth the local and the international internet communities.according to the proposed agreement for the triangular situation,icann would retain the responsibility to see that the cctld managermeets its responsibilities to the international internet community and toany nonnational registrants, while the local government would assumeresponsibility for ensuring that the interests of the local internet community are served.according to icann, the decision as to which arrangement to pursue would be reached by the government and the cctld manager (orcandidate manager) in consultation with the local internet community,with icann adopting òa neutral stance.óin the legacy situation, icann would have the full authority to selectand, when necessary, change the cctld manager. (although they are notsignatories to the agreements, governments are notified if one is in preparation in case they want to be involved.) in the triangular situation, the70the general responsibilities of the cctld managers are documented in rfc 1591and in the icann publications icp1, internet domain name system structure and delegation (cctld administration and delegation), may 1999, and cctld constituency bestpractice guidelines for cctld managers, 4th draft, march 10, 2001. however, neither ofthe icann documents appears to have achieved consensus among all the cctld managers.71see discussion in section 5.5.2.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.128signposts in cyberspacerelevant government or public authority would communicate its designation of a cctld manager to icann, which would then decide whether ornot to accept the designee and, assuming a positive decision, seek to negotiate an appropriate agreement with the manager.the proposed agreements with the cctlds are intended to cover thefollowing areas: (1) the delegation of responsibility to the cctld and description of the circumstances that would lead to its termination, (2) specification of the local and global policy responsibilities of the cctld, (3)characterization of the relationship with icann and their respective responsibilities, and (4) funding for icann.despite icannõs efforts to get cctlds to enter into agreements withit, by june 2005 it had completed only 12 of them. a number of cctldsobject to accepting icannõs formal authority over their operations. thisissue is discussed in detail in section 5.5.gtldsicann has acted to change the organization responsible for severalof the eight legacy gtlds. the most significant instance was its negotiation with verisign global registry services, the legacy manager of .com,.net, and .org. because those three gtlds contain the registrations of thevast majority of the internetõs gtld secondlevel domains and, in particular, almost all of those on its unsponsored and unrestricted domains,verisignõs position as the profitmaking sole supplier of those three wasfelt by many in the internet community to be detrimental to the longtermhealth of the internet. in may 2001, verisign, inc., icann, and the docsigned a revised agreement in which verisign agreed to give up its operation of .org at the end of 2002 while extending the term of its operation of.net to the beginning of 2006 and of .com to november 2007. both of thelatter agreements are renewable, although under different terms: underexisting agreements, .net had to be put out for bid by icann by the endof 2005, while verisign has presumptive renewal rights for .com, unless itmaterially breaches the agreement. icann initiated an open bidding process for .net in march 2004 and in june 2005 selected verisign, inc., tocontinue as the operator.72to select a new manager for .org, icann issued a request for proposals (rfp) in may 2002. in response, it received 11 proposals from a varietyof organizations, both commercial and notforprofit. according toicann, those proposals were reviewed by three independent evaluation72see icann, ò.net request for proposals,ó december 10, 2004, available at <http://www.icann.org/tlds/dotnetreassignment/netrfpfinal10dec04.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state129teams that were charged with looking at technical issues and at the abilityof the proposals to meet the specific needs of .org. comments were alsoreceived from the public and the applicants, which, according to icann,were used by the icann staff to prepare an evaluation report and recommendation. the icann board accepted the staff recommendation andicann contracted with the pir, a whollyowned subsidiary of theinternet society, to become the manager of .org, effective january 1, 2003.a similar process was followed for .net.selecting the tld registry operatorsan organization that is responsible for reliably performing the functions of (1) operating the tld name servers and (2) registering secondlevel domains in the tld is called a registry.73 it may or may not be thesame as the delegated manager for the tld.for example, verisign is the manager and operates the registry for.com and .net. pir is the manager of .org, but, as noted above, it hassubcontracted with afilias to operate the tld registry, which has contracted the name server function to ultradns. afilias also operates theregistry for .info, for which it also serves as the manager, and for .vc, thecctld for residents of st.vincent and the grenadines, which is managedby the ministry of communications and works of st.vincent and thegrenadines.there is always one, and only one, registry for a given tld, but, asnoted above, an organization can be the registry operator for more thanone tld. while the majority of tld managers are noncommercial organizations, some registry operators are commercial organizations that operate for profit; they register the vast majority of domain names.cctldsthe manager of a cctld may also be the registry operator, or it maysubcontract the registry services in whole or in part to other organizations. the process for selecting the registry services operator is entirely upto the cctld manager, subject only to whatever restrictions the national73registries can exist at any level, except the root, in the dns (although in somerespects icann could be viewed as the registry for the root). in this section, only tldregistries are considered. the term òregistryó is unfortunately used ambiguously inthis context. the database maintained by a registry is also called a registry, as are theorganizations that some registries subcontract with for database maintenance and operation, which are here called registry operators.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.130signposts in cyberspacegovernment may impose. the situations differ widely among the 243cctlds.since the growth of the world wide web has vastly extended thescope, scale, and importance of the internet, two phenomena have workedto shape the operational arrangements of cctlds in a country. first, therehas been a movement from the early informal arrangements, which ofteninvolved voluntary efforts by the computer science department of a university in the country, to more formal arrangements that provide legalprotection and engage a wider national community in policysetting roles.second, there has been a tendency to contract the actual operations tocommercial organizations more willing and able to undertake the responsibilities than academic institutions.for example, in austria, the current manager and registry is nic.at,which is a limitedliability company that since 2000 has been whollyowned by a charitable foundation, the internet private foundation austria. nic.at was established in 1998 by the austrian isp association totake over responsibility for the cctld from the university of vienna,which had managed it from its inception but was faced with an increasingnumber of registrations, legal questions, and name conflicts beyond itscompetence. while nic.at handles the name registration, it contracts withthe university of vienna computer center to run the .at name servers.in contrast, the new registry and registry operator for the .us tld is acommercial company, neustar, which also is the registry and registry operator for the new gtld .biz. in the .us case, the manager, the doc, decided to change the operational model from a deeply hierarchical, mostlygeographic, extensively delegated structure to one that would be exploitedcommercially at the second level. unlike the austrian case, there was nopressure for the change in strategy from the previous manager or operator, and no significant pressure from users/registrants in the domainñindeed, many of them argued against it. and the doc rfp essentiallyrequired a commercial operator with commercial intentions.legacy gtldsthe registries for the legacy gtlds are the consequence of history. nsihad been operating the registries for .com, .org, and .net by agreement withthe u.s. government when verisign purchased it and assumed the responsibility. as noted above, pir, upon becoming manager of .org, contracted withafilias to run the registry. the organizations shown in table 3.3 for each ofthe other legacy gtlds are the associated registries (and also sponsors).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state131new gtldsin july 2000, the icann board adopted a policy for the introduction ofnew gtlds that called for the solicitation and submission of proposals tosponsor or operate them. in august 2000, the rfp was published. it specified the contents of the detailed multipart proposal, which was to be accompanied by extensive supporting documentation and a nonrefundable$50,000 application fee. the deadline for applications was october 2000.as explained by icann, two types of gtlds were specified: sponsored and unsponsored. in the latter case, the application was to be submitted directly by the organization proposing to serve as the registry. inthe former case, the application was to be submitted by the sponsoringorganization but would include the proposal of an organization that hadagreed to perform the registry functions for the sponsoring organization.thus, the registries for the new tlds were selected through the icannprocess whether icann made the decision directly or accepted the sponsoring organizationsõ selections.icann announced that the selection criteria would be the following:¥the need to maintain the internetõs stability;¥the extent to which selection of the proposal would lead to an effective proof of concept concerning the introduction of topleveldomains in the future;¥the enhancement of competition for registration services;¥the enhancement of the utility of the dns;¥the extent to which the proposal would meet previously unmettypes of needs;¥the extent to which the proposal would enhance the diversity ofthe dns and of registration services generally;¥the evaluation of delegation of policyformulation functions forspecialpurpose tlds to appropriate organizations;¥appropriate protections of rights of others in connection with theoperation of the tld; and¥the completeness of the proposals submitted and the extent towhich they demonstrate realistic business, financial, technical, andoperational plans and sound analysis of market needs.icann received 47 applications, of which 2 were returned for nonpayment of the fee and 1 was withdrawn, leaving 44 to be evaluated. theicann staff carried out evaluation with the assistance of outside technical, financial/business, and legal advisors. icannõs goal was to select aòrelatively small group of applicationsó that (1) were functionally diverseand (2) satisfied the selection criteria.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.132signposts in cyberspaceat its november 2000 meeting, the icann board acted on the staffevaluation and selected the seven new gtldsñ.biz, .info, .name, .pro,.museum, .aero, and .coop. four were unsponsoredñ.biz, .info, .pro, and.nameñand, therefore, amounted to the direct selection of a registry aswell as the tld. the other three were sponsored, and each included adesignated registry chosen by the sponsor to operate its tld.the registries for .com, .net, .org and for the seven new gtlds haveagreed to pay certain fees and adhere to certain requirements as spelledout in icannõs sponsored and unsponsored tld agreements. (the registries for .edu, .gov, and .mil operate under separate agreements withagencies of the u.s. government. icann is the registry for .int, and theinternet architecture board (iab) manages .arpa. therefore, they do nothave agreements with icann.)icannõs tld agreement obligates the sponsor and the registry to(1) satisfy functional and performance specifications set by icann; (2)enter into agreements with any icannaccredited registrar (see òselecting the organizations to register domainsó in section 3.5.2) desiringsuch an agreement and accord the registrar fair treatment; (3) providequery and bulk access to registrant datañwhois information (see box3.6); (4) periodically deposit its registrant data into escrow with an apbox 3.6whois servicewhois services provide contact information about the registries, registrars, or registrants in the dns. (see sections 2.3.4 and 2.5.3 for information on the development of the whois service and background on the issues surrounding it.)icannaccredited registrars are contractually obligated to collect andprovide access to information about the name being registered, the namesand ip addresses of its name servers, the name of the registrar, the dates ofinitiation and expiration of the registration, the name and postal address ofthe registrant, and the name and postal, telephone, and email addresses ofthe technical and administrative contacts for the registered name. thesemust be made available either directly by the registrar or, in some cases, bythe registry.there are many separate whois services on the internet run by registrars, registries, and other organizations (often, as with universities, of theirown second or thirdlevel domains). in addition, there are numerous websites that provide links to many of the whois sites, such as allwhois.comand betterwhois.com.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state133proved escrow operator; and (5) comply with consensus policies established by icann.the icann process for adding gtlds that was implemented in 2000was quite controversial. many participants and observers complainedabout the design and implementation of the process. the issue of whetherand how to add new gtlds is examined in detail in section 5.4.operating the tld registriesevery tld registry operator must perform two basic functions: register domain names requested by registrants and operate the name serversthat will link those domain names with their ip addresses and other critical information. even these basic responsibilities may be divided betweenorganizations, some commercial and some noncommercial, as notedabove in the cases of austria and of .org. in contrast, a single commercialorganization, verisign, is the manager, runs the registry, and runs thename servers for .com and .net.the registration operation produces the entries to the zone file forthat domain, the content of the whois file, and records of billing and payment, where appropriate. when the tld has restrictions on who mayregister either in the domain (such as restricting registrations to nationalsor residents of a country or to professionals or museums) or in its genericsubdomains (such as australian businesses in com.au or british limitedliability corporations in ltd.uk), each application for a domain name mustbe examined to ensure that those restrictions are satisfied.the icann agreements with 12 gtlds include functional and operational specifications that the registry operators are responsible for meeting, while the few agreements with cctlds specify only general requirements for internet connectivity, operational capability, and adherence tokey rfcs, as well as agreements to make financial contributions toicann. ideally, all operators of tld name servers should satisfy certainminimal technical conditions to ensure their compatibility with theinternet and that they are configured so as not to pose a danger to thestability of the internet, although there is no mechanism for enforcing thisfor the tlds not covered by icann agreements.3.4.4assessmentconclusion: the level of technical capability and competence varieswidely across the 258 tld registries. the gtlds and the large cctldsgenerally operate at a high level of availability and responsiveness. although there are no readily available measures of the performance of themajority of cctlds, they appear to provide adequate service.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.134signposts in cyberspacerecommendation: regular and systematic testing of the availabilityand operation of secondary servers should be adopted by toplevel domain registry operators. policies and procedures should be developed toclarify what to do when problems are identified and what measures canbe taken when problems are not resolved within a reasonable period oftime.conclusion: no single organization has the authority and the abilityto oversee the operation of all the tlds. icannõs formal authority extends only as far as the provisions of its agreements with 10 gtlds and 12or so cctlds and the authority it has to recommend changes in the rootzone to accommodate new or reassigned tlds.even where there is a contract, icannõs authority has been tested.verisignõs introduction in october 2003 of its site finder service raisedfundamental issues of both a technical and an institutional nature and hasbeen challenged in the courts.743.5implementationñthe second andthirdlevel domainsthe domain names in the dns hierarchy that internet users interactwith most directly are those at the second level (or in those cctlds withfixed secondlevel domains, such as ltd.uk, those at the third level). theyare generally the key identifiers in email addresses (such asrecipient@mailserver1.nas.edu) or a web address (such as http://www.nas.edu). they are the names that businesses, individuals, government agencies, nonprofit organizations, and various other groups acquireto identify themselves on the internetñthe names on their signposts incyberspace. more than 70 million secondlevel (and, in some instances,thirdlevel) domain names were registered during early 2005, with abouttwothirds in the gtlds (more than half in the two largest gtldsñ.comand .net) and about onethird in the cctlds.753.5.1technical system of the second and thirdlevel domainssecond and thirdlevel domains may have their own name servers torespond to queries to their zone files, as most large organizations do, butoften the services are provided by isps or other web site hosting organi74see chapter 4 for a discussion of the site finder case.75see tables 3.2 and 3.3.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state135zations that store the zone file on their name servers. this is the coursetaken by most small organizations and individuals, although there aremany exceptions.the zone file of a second or thirdlevel domain may be very small if itbelongs, for example, to an individual, or it may be quite large, if it isowned by a commercial or governmental organization. in the latter case, agreat many of the entries may be associated with the email addresses ofthe thousands of employees of the institution, while several, tens, or hundreds may be associated with the name servers of lowerlevel zones. often, institutions will register multiple domain names (e.g., nas.edu andnationalacademies.org) that point to the ip address of the same server,enabling access to it under different domain names.3.5.2institutional framework of the second andthirdlevel domainsthe effective operation of the second and thirdlevel domains requires that three functions be performed:1.selecting the organizations to register secondlevel domains,2.registering secondlevel domains, and3.resolving secondlevel domain name conflicts.the principal organizations participating in this institutional framework are icann, the tld registries, the registrars, and the organizationsthat provide dispute resolution services. although many of the organizations at this level are commercial, numerous notforprofit and governmental organizations play an active role as well.selecting the organizations to register domainsin many cases, especially in the cctlds and some of the gtlds, onlythe registry carries out the registration of second or thirdlevel domains.however, in a 1998 white paper76 the doc, responding to a policy goal ofprivatizing and increasing competition in the market for domain nameregistration, recommended opening the business of registering lowerlevelnames in gtlds to competition. it subsequently amended its agreementwith nsi, then the operator of the .com, .org, and .net registries, to require it to develop a system of multiple registrars and put it into opera76department of commerce, òmanagement of internet names and addresses,ó federal register 63(111):31741, 1998.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.136signposts in cyberspacetion in 1999. the doc designated icann as the organization that wouldoversee the establishment of the shared registration system (srs) andwould be responsible for establishing and implementing a system for registrar accreditation. the srs and registrar accreditation began operationin 1999. before the multiple registrar system, nsi charged $35 per year forregistrations in its domains. at the beginning of 2005, registrations in thosedomains in the united states could be obtained for less than $10 peryear.77under the terms of their agreements with icann, gtld registriesare required to permit registrars to provide internet domain name registration services within their toplevel domains. in addition, these agreements regulate the price that registries can charge registrarsñthe òwholesale price,ó with the current regulated price being a maximum of $6 peryear per registrant. one can think of the regulation of the wholesale priceas intended to constrain the exercise of market power by registries andthe requirement for competing registrars as intended to constrain the retail òmargin.óto the extent that regulation of the wholesale price is intended to limitthe exercise of market power in the wholesale market, however, it is notentirely obvious why the wholesale price that can be charged by newgtlds, especially new gtlds that are intended to serve diverse users,must be regulated.78 indeed, increased future competition, especially asthe number of gtlds is expanded, might reduce or eliminate the need toregulate the wholesale price that verisign or other registries can charge.but if regulation of the wholesale price is intended to prevent registriesfrom exploiting existing customers that may be locked in, there may be acontinuing need to regulate wholesale rates even if the registry marketwere to become more competitive. the significance of lockin will dependon the importance of switching costs, the flow of new registrants relativeto the existing stock, and on whether registries can discriminate betweennew and existing registrants. there were in february 2005 more than 460 registrars from more than20 countries accredited to register domain names in 1 or more of the 10eligible gtld domains.79 many of them have decided to operate, at leastin part, as wholesalers and suppliers of registrar services; those operations have enabled many agents to sell domain names without any rela77for example, in february 2005, godaddy.com was offering .com registrations for$8.95.78some specialized tlds might continue to have market power even if the totalnumber of tlds were very large.79for the current list, see the icann site at <http://www.icann.org/registrars/accreditedlist.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state137tionship with, or accreditation by, icann. although most cctlds useauthorized agents, many cctlds have adopted the notion of multiple registrars, and many icannaccredited registrars also register cctld secondlevel domain names.icann accredits registrars through an open application process. anyorganization wishing to become an icannaccredited registrar mustcomplete a detailed application concerning its technical and businessqualifications and pay a $2500 application fee. if approved by icann,the applicant must execute the standard registrar accreditation agreement80 and pay a yearly accreditation fee that is $4000 for the first tldand $500 for each additional tld for which the registrar is accredited. inaddition, the registrar must pay a quarterly accreditation fee to cover aportion of icannõs operating expenses. the fee is based, in part, on theregistrarõs share of registrations in the tlds for which it is accredited.registrars that are accredited by icann must also enter into accreditation agreements with the registries in the tlds in which they want toregister domains. those agreements specify, among other things, the feesto be paid to the registries for each registration. as noted above, a ceilingis imposed on that fee structure by icann for the gtlds that have signedagreements with icann.the icann registrar accreditation agreement imposes certain requirements on registrars. the registrar is obligated to (1) submit specifiedinformation81 for each registrant to the registry; (2) enable public internetaccess to a file of information about registrantsñthe whois fileñboth inquery and bulk access form; (3) maintain a file of all registrant information submitted to the registry; (4) regularly submit a copy of the file toicann or to an escrow agent; (5) comply with consensus policies established by icann; and (6) have for the resolution of name disputes a policyand procedures that comply with icannõs uniform dispute resolutionpolicy. (see òresolving domain name conflictsó below.) however, someof the newer gtld agreements anticipate the possibility of òthickó registries, for example, ones in which whois and similar data are maintainedby the registry, not the registrars. this changes requirement (2) and hassome impact on the others.registering domain namesregistration of secondlevel (or thirdlevel) domain names occurs according to different processes in the different types of tlds. for the 1080a copy of the agreement can be found at <http://www.icann.org/registrars/raagreement17may01.htm>.81see box 3.6.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.138signposts in cyberspacegtlds that use accredited registrars and for a number of cctldsñforexample, great britain, australia, canada, and denmarkñregistrars compete to sell secondlevel domain names in the tlds they represent. theyare free to set whatever fees they like, subject only to competitive marketforces and their obligations to pay registration fees to the registries. forthe .edu, .gov, .mil, .int, and .arpa gtlds, as well as for most cctlds,registration by members of the restricted group occurs directly at the registries.the registrar stage of the dns process appears to be quite competitive, with entry being relatively easy82 and competition taking placealong a number of dimensions. registrars for the same registry competewith one another for the patronage of registrants83ñwhat is sometimescalled intrabrand competitionñwith competition being based on boththe prices and the services offered. these services include the efficiencywith which registrations take place as well as valueadded services thatmay be bundled with registration.84 switching registrars within a givenregistry is not particularly difficult, but there have been complaints thatregistrars have not always responded promptly to requests for switching and that some registrars have aggressively and misleadingly solicited other registrarsõ customers. in addition, domain name theft has beenone of the problems associated with inadequate procedures and securitymeasures put in place by the registrars of domain names. in such cases,a third party fraudulently claims to be the registrant in order to have thedomain name transferred to its ownership.85 there have also been instances of fraud charges against domain name registries and registrarsof domain names.the snapnames state of the domain report listed 148 registrars in thecno domains (.com, .net, and .org) in the first quarter of 2003.86 how82this competition is facilitated by the shared registration system protocol, whichallows registrars to enter names directly in registries.83this is not to say that registrars for different tlds do not also compete with oneanother, a form of interbrand competition. in addition to registering new domainnames, registrars also participate in the secondary market for domain names, acting asbrokers, as well as in assisting registrants in applying for expired names.84snapnames reported that godaddy, a registrar, gained 70,000 registrants in a monthwhen it launched its free online tax preparation software, presumably available onlyto its registrants. see the next section for a discussion of valueadded services, some ofwhich are provided by firms that are not registrars.85in april 2004, the original operator of sex.com received a $15 million settlementfrom verisign because its registrar service had incorrectly transferred ownership ofthe name to a fraudulent claimant.86snapnames.com, inc., state of the domain, first quarter 2003, may 13, 2003, available at <http://www.sotd.info/sotd/content/documents/sotdq103.pdf>. thesnapnames report showed over 150 icannaccredited registrars operational at thattime (pp. 3134).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state139ever, òmarket sharesó in these domains were skewed, with the verisignregistrar (now network solutions)87 having more than 25 percent of allregistrations in .comñwhich was, however, a significant decline from its40 percent share only 15 months earlier;88 tucows having about 10 percent; register.com having approximately 9 percent; and godaddy havingsomewhat over 6 percent. thus, the share of the òmarketó controlled bythe top four firms in .comñthe fourfirm concentration ratioñwas about52 percent.89 seven other registrars each had more than 1 percent of all.com registrations. (more recent data were not available at the time of thiswriting.)the situation was somewhat different in the then newly opened .bizdomain according to the snapnames state of the domain, first quarter 2003report. although the verisign registrar (network solutions) was the market leader, its share was only about 19 percent, 6 percent less than itsshare in the .com domain. other registrars with shares in excess of 6 percent were register.com (10 percent), tucows (9 percent), and melbourneit (6 percent),90 so that the fourfirm concentration ratio here was onlyabout 44 percent. snapnames reports that there were 127 registrars of .biznames. as a result of the wide disparity in the sizes of the various domains, network solutionõs approximately 25 percent share of .com wasabout 5.8 million names, while its approximately 19 percent share of .bizwas only about 170,000 names.91finally, although registrars charge the same prices to all registrants,some registrars offer a backorder service under which, for a fee, they willtrack the expiration of a desired domain name and attempt to register itimmediately if the registration lapses. however, multiple registrars maybe trying electronically to register the same name at the instant it becomes87verisign sold its registrar, network solutions, to a private investment company for about$100 million in october 2003.88snapnames.com, inc., state of the domain, january 2002, february 26, 2002.89the quotation marks around òmarketó and òmarket sharesó are intended to indicate that no claim is being made that registrar services in the .com domain constitute arelevant antitrust market. snapnames reported that the top 10 registrars had about75 percent of the market in the first quarter of 2003, down from about 91 percent at theend of 2001.90recall that melbourne it is part of a joint venture with neustar, the operator of the.biz registry.91for further discussion of market issues and presentation of market data, seeògeneric top level domain names: market development and allocation issues,óorganisation for economic cooperation and development, directorate for science,technology and industry, committee for information, computer and communications policy, working party on telecommunication and information service policies,july 13, 2004, available at <http://www.oecd.org/dataoecd/56/34/32996948.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.140signposts in cyberspaceavailable. the one that tries at just the right instant wins the prize. because of this chance element, consumers often enter back orders withmultiple registrars. in march 2002, icann asked verisign to conduct a12month trial of a single waitlisting service, which would take just oneorderñat a $24 fee directly from the consumerñfor an expiring name ona firstcome, firstserved basis. thus, from the consumerõs side, the needto use multiple registrars would be eliminated, but from the registrarõsside, the opportunity to derive additional revenue would be lost. on july15, 2003, a coalition of name registrars filed a lawsuit against icann seeking to block the launch of verisignõs global waiting list for domainnames.92 at its march 2004 meeting, icannõs board voted to seek thedocõs agreement to its approval of verisignõs 1year trial of the waitlisting service.resolving domain name conflictsone of the most difficult institutional roles that the operation of thedns requires is the resolution of conflicts among competing claimantsfor domain names. these conflicts arise for a number of reasons that arediscussed in detail in section 2.5. the one that has attracted the mostattention is the use of trademarked words in domain names, which iscovered in òtrademark conflictsó in section 2.5.2. although domainnames can be used for a number of legitimate purposes other than as anaddress for a world wide web site, such as identifying a host, an emailserver, an ftp site, and so on, the vast majority of the disputes involvingdomain names are associated with their very visible use in associationwith world wide web sites. conflicts can also arise over names in whichindividuals, organizations, or governments claim a proprietary interestother than a trademark.whatever the source, the practical use of the dns, which assumesthat every domain name will be registered to one and only one entity,cannot proceed without some means for resolving conflicting claims forthe same name. in the early days of the internet, before strong financialand political interests were involved, such conflicts were handled informally, usually on a firstcome, firstserved basis, and they still are in manycctlds.93 however, as domain names appeared on the signposts on theworld wide web and in email addresses, and some gained visibility andpotentially great value, the need to use more formal processes became92see susan kuchinskas, embittered registrars sue embattled icann, july 15, 2003,available at <http://siliconvalley.internet.com/news/print.php/2235661>.93see, for example, the terms and conditions for the .uk registry available at <http://www.nic.uk>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state141evident. this was especially true for .com at first, and then for .net and.org as they were more widely marketed to general users. for the reasonsdescribed in section 2.5.1, they were the most visible names on signpostson the web.possible remedies to conflicts over namesthere are basically two approaches to resolving conflicts over rightsto names: one approach incorporates policies and regulations into the actual administration of the naming system and its assignment rules. theother approach relies on dispute resolution mechanisms that are externalto naming system administration.internal remedies.in a completely internalized naming system administration, a single manager owns the naming system and decides who is entitledto which name. hence there are no rights conflicts. public or quasipublicnaming systems, such as the dns, can also attempt to link the assignment ofnames to strict policies and regulations. the available techniques includeimposing policies on the assignment of names at the point of registration,name reservations94 or exclusion, and socalled sunrise proposals.policies imposed at the point of registration.such policies must relyon rules or procedures to determine eligibility for a name. it is difficult tomechanize such rules. thus, prior review of registration is likely to beexpensive and slow if it is administered manually and prone to be crudeand unfair if it is not.name exclusions.name exclusions withdraw specific names or entire classes of names from the available database. for a time, networksolutions did not allow registration of six of the federal communicationcommissionõs òseven dirty wordsó in the domain name space.95 theworld intellectual property organization (wipo) recommended eliminating a list of òfamousó trademarks from the dns database and reserving their use to the trademark holder.96 icann has provided all of its94the deployment of internationalized domain names involves new processes andchallenges with respect to the reservation of names to prevent some conflicts overdomain names. see section 5.6.3 for discussion.95for example, see òseven dirty words,ó wikipedia online encyclopedia, availableat <http://en.wikipedia.org/wiki/sevendirtywords>.96see òthe problem of notoriety: famous and wellknown marks,ó in the mangementof internet names and addresses: intellectual property issues, first report of wipo internetdomain name process, april 30, 1999, available at <http://wipo2.wipo.int/process1/rfc/3/interim2ch4.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.142signposts in cyberspacenewly authorized registries with a list of reserved names that consisted ofnames and acronyms of organizations related to the ietf and icann.97name exclusion is an effective method of protecting the reservednames from abuse, but it is also a crude instrument, and in a global, publicname space its crudeness raises significant public policy concerns. withdrawing words from circulation is in effect a form of automated censorship. exclusions do not make any distinction between legitimate and illegitimate users; they simply make it impossible to use the names. a rigidexclusion deprives these organizations of the right to register domainnames corresponding to their acronyms or trademarks. exclusions andother regulations are less significant when they are part of the practice ofa private naming system, where the owner can be assumed to have property rights over the naming system as a whole. such exclusions also ignore the fact that certain words have a particular meaning only in a particular language. a òdirtyó word in english may have no such meaning inanother language.sunrise proposals.sunrise proposals, in general, establish a periodat the startup of a new name space within the dns during which certainentities may register names in which they have established rights (e.g.,famous trademarks) before the space is opened for public registration.external remedies.external methods of resolving rights conflicts include litigation through the courts or alternative dispute resolution procedures, such as the icann uniform domain name dispute resolutionpolicy (udrp), which is discussed below. the advantage of these methods is that they are based on casespecific analysis. thus, they are sensitive to the specific facts of the conflict and can employ òsoftó interpretiveprinciples to adjudicate a dispute. their disadvantage, of course, is thatthey are more timeconsuming and expensive, and litigation is subject tojurisdictional limitations that may not match the scope of the affectednaming system. litigation is particularly expensive and cumbersome, although it offers a reliably neutral tribunal in many countries. alternativedispute resolution techniques such as the udrp greatly reduce the costof external dispute resolution but sacrifice thoroughness in compilingand verifying facts, and their rapid procedures can put respondents at adisadvantage.97for the list of reserved names, see icann, òappendix k, schedule of reserved names,óavailable at <http://www.icann.org/tlds/agreements/unsponsored/registryagmtappk26apr01.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state143remedies to conflicts over names in the dnssince the remedies to domain name conflicts differ somewhat betweenthe gtlds and the cctlds, each is described separately below.gtlds.although there are other uses of trademarks with internationalspillover effects, secondlevel domains in gtlds are unusual in the extentto which they are visible in almost every jurisdiction in the world, withthe resulting difficulty in making either geographic or sectoral distinctions. ordinarily, the same trademarks can be used in a single geographicregion so long as they are in different economic sectors where confusion isunlikely. on the internet such distinctions cannot be made. as a result,the question arises as to the means to be used to make decisions aboutdomain name conflicts and disputes that cross national and business sector boundaries and, since such decisions inevitably involve matters ofcommercial or political or social importance, to ensure that those decisions are regarded as legitimate and enforced. normally, trademark andrelated disputes are resolved by the courts of the nation in which theyarise, and those in many nations have shown themselves capable of handling domain name disputes. in addition, the united states has passedspecific legislation at both the federal and the state levels addressing therights of trademark owners to domain names. (these are discussed further below.) as noted above, however, legal proceedings can become expensive and timeconsuming. therefore, many in the internet communityfelt the need for a less expensive and quicker means of resolving domainname disputes.uniform domain name dispute resolution policy.an answer,implemented by icann in december 1999, based on a recommendationfrom wipo, was the uniform domain name dispute resolution policy.the udrp has been adopted, as icann requires, by all registrars in the.aero, .biz, .com, .coop, .info, .museum, .name, .net, and .org topleveldomains, as well as voluntarily by managers of several global cctlds,such as .tv, .cc, and .ws. in addition, managers of other cctlds, such as.ca, have adopted their own policies based on modified versions of theudrp.the policy takes effect through agreements between registrars (orother registration authorities) and their registrants. each registrant agreesto be bound by the provisions of the policy when it registers its domainname.98 in agreeing to the registration agreement, the registrant also must98the policy conditions, examples of badfaith actions, and other provisions listedbelow are paraphrased from the udrp text available at <http://www.icann.org/dndr/udrp/policy.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.144signposts in cyberspacerepresent that to its knowledge its registration of the domain name doesnot infringe any third partyõs rights, nor is it for an unlawful purpose, norwill it be used in violation of any applicable laws or regulations.by registering the domain name, the registrant is then bound by thepolicy to submit to a mandatory administrative proceeding if a complainant asserts that:1.registrantõs domain name is identical or confusingly similar to atrademark or service mark in which the complainant has rights;and2.registrant has no rights or legitimate interests in respect of the domain name; and3.registrantõs domain name has been registered and is being used inbad faith.the complainant must demonstrate all three of these conditions for thecomplainant to prevail.the policy asserts examples of actions that would demonstrate badfaith that include registering and using the domain name:1.for the purpose of transferring the registration to the complainant,or to one of its competitors, for more than the documented outofpocket costs of the domain name; or2.to prevent the owner of the trademark or service mark from usingthe mark in a domain name (provided that registrant engaged in apattern of such conduct); or3.primarily for the purpose of disrupting the business of a competitor; or4.intentionally to attract, for commercial gain, internet users toregistrantõs web site or other online location, by creating a likelihood of confusion with the complainantõs mark on registrantõs website or location.it also describes circumstances that would enable the registrant todemonstrate its rights and legitimate interests in the domain name. theseare as follows:1.before any notice to registrant of the dispute, its use of, or demonstrable preparations to use, the domain name or a name corresponding to the domain name in connection with a bona fide offering of goods or services; or2.registrant has been commonly known by the domain name, evenif it has acquired no trademark or service mark rights; orsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state1453.registrant is making a legitimate noncommercial or fair use of thedomain name, without intent for commercial gain, to misleadinglydivert consumers, or to tarnish the trademark or service mark.the mandatory proceedingñwhich is electronically basedñmust beheld before an accredited and administrativedisputeresolution providerthat has been approved by icann.99 the complainant selects the provider and is required to pay the fees, except in the case when the registrant elects to expand the panel from one to three panelists, in which casethe fee is split. the registrar, the registry, and icann are not parties to audrp proceeding. however, during a udrp proceeding, the registrardoes confirm that the domain name has been registered by the respondent named in the proceeding and is required to execute the outcome of adecision. the only remedy available to the complainant through the proceeding is cancellation or transfer of the domain name.as of may 10, 2004, 9377 proceedings involving 15,710 domain nameshad been brought under the udrp.100 twothirds (6262) of these proceedings had resulted in a transfer of the disputed domain name to thecomplainant or in a cancellation of the domain name. approximately onefifth (1892) had resulted in a decision for the respondent, and approximately onetenth (971) of the proceedings had been disposed without decision or terminated. there were 931 proceedings pending. the 15,710domain names that had been disputed in 4 years represent 0.03 percent ofthe more than 46 million domain names registered in the gtlds subject tothe udrp.approximately 60 percent of these proceedings have been filed withwipo, approximately 33 percent have been filed with the national arbitration forum (naf), approximately 6 percent were filed witheresolution,101 and approximately 0.7 percent have been filed with thecenter for public resources institute for dispute resolution (cpr). theasian domain name dispute resolution centre (adndrc) began operation in february 2002.99the approved providers are listed at <http://www.icann.org/dndr/udrp/approvedproviders.htm>. there were four approved providers in february 2005.100icann, òstatistical summary of proceedings under uniform domain name dispute resolution policy,ó january 30, 2004; latest version available at <http://www.icann.org/udrp/proceedingsstat.htm>.101eresolution ceased operating as a disputeresolution provider for icann in latenovember 2001.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.146signposts in cyberspaceover time, there has been a decline in the number of udrp proceedings filed. as shown in figure 3.3, the number of udrp proceedings filedeach month has been steadily decreasing since august 2000.wipo explained this decline as suggesting that òan expedited online dispute resolution service has been effective in dissuading internetpirates from hijacking names.ó102 it may also be partly the conse050100150200250300350number of filingsdec99mar00jun00sep00dec00mar01jun01sep01dec01mar02jun02sep02dec02mar03jun03sep03dec03mar04figure 3.3 udrp filings as of april 30, 2004. note: with respect to gtld udrpfilings commencing during the period from december 1999 through october 2003,data were obtained from the icann web site at <http://www.icann.org/udrp/proceedingslist.htm>. with respect to such filings commencing during the period from november 2003 through april 2004, data were obtained directly fromthe asian domain name dispute resolution centre web sites at <http://www.adndrc.org/adndrc/bjhome.html> and <http://www.adndrc.org/adndrc/hkhome.html>, the center for public resources institute for disputeresolution web site at <http://www.cpradr.org/icanncases.htm>, the national arbitration forum web site at <http://www.arbforum.com/domains/decisions.asp>, and the world intellectual property organization arbitration andmediation center web site at <http://arbiter.wipo.int/domains/statistics/index.html>. specialized domain name dispute resolution proceedings (e.g., startup trademark opposition policy (stop) and the ustld domain name disputeresolution policy (usdrp)) have been excluded from these statistics.102wipo, òwipo continues efforts to curb cybersquatting,ó press release pr/2002/303,february 26, 2002, available at <http://www.wipo.org/pressroom/en/releases/2002/p303.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state147quence of working through the backlog of cases that udrp faced uponstartup and entering a more normal steadystate condition. to someextent, as well, it may reflect a change in the attitudes of trademarkowners, some of whom may have come to feel that their interests arenot jeopardized by every similar domain name, which are not worththe cost and effort to maintain. the decline in cases might also be attributed, in part, to learning by cybersquatters about avoiding a finding of bad faith against them.as a first step in a policy development process, in 2003, icann prepared a report that lists many of the procedural and substantive issuesthat have been raised about the udrp.103startup registrations.the udrp was designed to handle an ongoing rate of domain name conflicts arising in already established gtlds.however, several of the seven new gtlds have faced unique issues whenthey entered the startup phase. specifically, under the terms of their contracts with icann, they needed a process by which intellectual propertyrights holders could challenge badfaith claimants in advance of open registration in order to avoid a rush of cybersquatters followed by a heavydemand on the udrp process as intellectual property holders assertedtheir rights. the four most significantñ.biz, .info, .name, and .proñeachadopted somewhat different policies, but all are adopting or have a udrplike dispute resolution policy.cctlds.most cctld registries, and their agents and registrars whenthey exist, publish policies about who is eligible to register in the secondlevel domain, or in its thirdlevel domains when they are open for directregistration. these policies generally also cover the resolution of conflicts over domain names. where the tld limits itself to individuals andorganizations that have an association with the country, many potentialconflicts are readily addressed through national administrative, regulatory, and judicial institutions. for example, matters of trademark priorityare handled through the national regulatory and legal systems, and corporations may have defensible rights only in the names that are legallyregistered.103see icann, òstaff managerõs issues report on udrp review,ó august 1, 2003,available at <http://www.icann.org/gnso/issuereports/udrpreviewreport01aug03.htm>.icann also set up a committee to consider wipoõs proposed amendments to theudrp. icann has not made the committeeõs report public.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.148signposts in cyberspaceu.s. legislation.the united states has passed legislation at both thefederal and the state levels addressing the rights of trademark owners todomain names.federalñthe acpa:on november 29, 1999, president clintonsigned into law the anticybersquatting consumer protection act(acpa), which provided trademark owners with a further cause of actionthat was specifically directed to domain names.104 under the acpa, atrademark owner can bring a civil action against a person if that personhas a badfaith intent to profit from a mark and registers, traffics in, oruses a domain name that, in the case of a mark that is distinctive, is identical or confusingly similar to that mark; or in the case of a famous mark,is identical or confusingly similar to or dilutive of that mark; or is a trademark, word, or name protected by law.105 mere registration of such adomain in bad faith may be sufficient to violate the trademark ownerõsrights under the acpa; there is no further requirement for any use of thedomain name in association with any goods or services.under the acpa, factors affecting the judgment of bad faith include,but are not limited to, whether (1) the registrant holds any intellectualproperty rights in the name; (2) the domain name consists of theregistrantõs name; (3) the domain name was used in connection with thebona fide offering of any goods or services; (4) the domain name was usedin a way that could be viewed as a bona fide noncommercial or fair use;(5) the domain name was intended to divert consumers from the markownerõs online location; (6) the registrant offered to sell the domain nameto the mark owner without having used it in a bona fide manner; (7) theregistrant provided false contact information in the registration form; (8)the registrant acquired multiple domain names that are identical or similar to the trademarks of others; and (9) the domain name incorporates amark that is not distinctive and famous.the acpa also created a cause of action for individuals with respectto domain names. specifically, a domain name registrant can be held liable if the domain name consists of, or is substantially and confusinglysimilar to, the name of another living person and the domain name hasbeen registered without that personõs consent with the specific intent toprofit from the name by selling it for financial gain. this particular causeof action, however, is not available for domain name registrations thatoccurred prior to the acpaõs enactment date.with respect to remedies, the acpa provided that a court may awardinjunctive relief, including forfeiture, cancellation, or transfer of the do10415 u.s.c. ¤ 1125(d).10518 u.s.c. ¤ 706 (òred crossó) or 36 u.s.c. ¤ 220506 (òolympicó).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state149main name. in addition, if the registration, trafficking, or use of the domain name occurred after the acpaõs enactment date, a plaintiff can electto recover, instead of actual damages and profits, an award of statutorydamages in the amount of $1,000 to $100,000 per domain name (as thecourt considers just).furthermore, if personal jurisdiction over the domain name registrantcannot be obtained, the trademark owner could file an in rem civil action106 against the domain name itself in the judicial district of the domain name registrar, domain name registry, or other domain name authority that registered or assigned the domain name. however, the acpalimits the remedies in an in rem action to forfeiture, cancellation, or transfer of the domain name.states:california, hawaii, and louisiana also passed laws that address the registration, sale, and use of domain names within that state andprovide for civil remedies in state courts for violations of these laws.foreign legislation. relatively few countries have chosen to addressthe rights of trademark holders in domain names in the same legislativemanner as the united states. the european union (eu) has relied largelyon new telecommunications laws coordinated at the eu level to provide forthe regulation of domain names at the national level. for example, in spain,the general telecommunications act (1998) was modified in july 2001 toimpose a number of conditions on the registration of domain names underthe cctld .es, including a requirement that a domain name to be registeredbe somehow related to the trademark or name of the company undertakingthe registration. in other countries, the judicial process, rather than the legislative process, has been relied on to address conflicts between domainnames and trademarks. since at least 1997, courts within the united kingdom have been prohibiting the registration of domain names that conflictwith trademarks. in 1998, the delhi high court in india likewise extendedits form of common law trademark protection to domain names, as did thetribunal de grande instance of draguignan in france. many cctlds, 42 inall, including a number from the eu, have opted to rely on a form of alternative dispute resolution policy.107 likewise, the new .eu cctld will applythe following rules regarding registrations:¥governments may reserve geographical and geopolitical names.¥in a 4month sunrise phase, òprior rightsó holders and public bodies can register .eu domain names before the general public can do so.106 an in rem action is taken against property directly, in contrast to an action againstpeople (e.g., the owners of a given piece of property).107see <http://arbiter.wipo.int/domains/cctld/index.html> for an example.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.150signposts in cyberspace¥two months before the sunrise phase starts, technical and administrative measures will be published in detail.¥in the first 2 months of the sunrise phase, registered national andeuropean community trademarks and geographical indications as wellas names and acronyms of public bodies can be registered as .eu domainnames by the holder/public body.¥two months later, other òprior rightsó holders can also register .eudomain names, but only as far as they are protected under national law inthe member state where they are held. this provision concerns unregistered trademarks, trade names, business identifiers, company names, family names, and distinctive titles of protected literary and artistic works.¥there will be an alternative dispute resolution procedure in place(similar to icannõs òuniform domain name dispute resolution policyóudrp).¥after the sunrise phase, the domain names will be registered according to the firstcome, first servedprinciple.3.5.3assessmentconclusion: the tens of millions of registered second and thirdleveldomains are operated by individuals with a broad spectrum of capabilities. it is notable that the dns has been able to function effectively andreliably despite this range of operator capabilities.conclusion: the udrp is a unique crossborder, electronically basedprocess that has resolved thousands of disputes over domain names without the expense and potential delay of court proceedings.the issues of dispute resolution and appropriate whois balance areexamined in chapter 5, where the alternative approaches are describedand the committeeõs recommendations presented.3.6summaryconclusion: the domain name technical system reliably and effectively handles the billions of queries it receives every day. the institutionsthat manage it perform the required functions adequately, in many caseswithout direct compensation.conclusion: the dns technical system can continue to meet the needsof an expanding internet. early in the committeeõs assessment it becameapparent that it would not be fruitful to consider alternate naming systems. as noted, the dns operates quite well for its intended purpose andsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: current state151has demonstrated its ability to scale with the growth of the internet and tooperate robustly in an open environment. moreover, significantly increased functionality can be achieved though applicationsñsuch as navigation systemsñbuilt on the dns, or offered independently, rather thanthrough changing the dns directly. hence, the need did not seem to be toreplace the dns but rather to maintain and incrementally improve it. furthermore, given the rapidly increasing installed base and the corresponding heavy investments in the technical system and the institutional framework, the financial cost and operational disruption of changing to areplacement for the dns would be extremely high, if even possible at all.yet, despite this better than passing grade, the committeeõs assessments have identified a number of significant technical and institutionalissues whose effective resolution is critical to the dnsõs successful adaptation to the demands on it. chapters 4 and 5 address those issues.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.1524the domain name system:technology prospectsthe domain name system, as described in chapter 3, has met mostof the infrastructural naming needs of the internet and the applications that rely on it, even as their uses and usage have expanded rapidly. however, the broadening and deepening penetration of the internetand its applications into global communications, commerce, and cultureposes new challenges to the basic technology of the dns. in anticipation ofand in response to those challenges, the technology community has been developing modifications of and extensions to the current technology.this chapter is a review of the challenges and the prospective or actualtechnology responses to them. each challenge and responsive technology isdescribed and evaluated and the implications for the internet and its applications are explained. where the committee is in agreement, its conclusionsand recommendations are presented. in all cases, the goal is to provide aclear description of the challenges, the technologies, and their prospects inorder to inform forthcoming policy deliberations affecting or affected them.the following challenges and responsive technologies are addressedin this chapter:1.improving the security of the dns,2.linking the telephone and internet naming systems,3.internationalizing domain names, and4.responding to domain name errors.some of these technologies are in or ready for the first stages of implementation, whereas others may never enter into widescale usage. neversignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects153theless, a basic understanding of each of them will enable wiser decisionsabout them and other innovations in the future.4.1improving the security of the domain name systembecause of its central role in the operation of the internet, the dns is anatural target for mischievous and malicious attacks. these can take awide variety of forms depending on the ingenuity of the attacker and onwhich of the potential vulnerabilities is attacked.1 the most severe recentattack was the denialofservice attack launched in october 2002. itswamped 8 of the 13 root name servers for up to an hour and a half. however, the remaining 5 servers handled the regular requests to the root without difficulty. since that attack, the root name server operators have takena number of steps, including the widespread distribution of òanycastósatellites and diversification of network connectivity (see box 3.1), to reduce their vulnerability to such attacks and to mitigate their effects.furthermore, although some steps have been taken,2 more could be doneto continuously monitor the performance and traffic flows of the dns infrastructure so as to enable rapid detection and response to attacks or outages.however, another serious vulnerability remains. as described in section 2.4, òthe original dns design did not include a mechanism to ensurethat a name lookup was an accurate representation of the informationprovided by the entity responsible for the information. dns informationwas assumed to be accurate as the result of general notions of networkcooperation and interoperation (i.e., based on the presumption that nobody would deliberately attempt to tamper with dns information).ó inmore technical terms, the initial design of the dns did not incorporatedata origin authentication and data integrity protection. however, because of increased fear of additional attacks on the dns, these kinds ofsecurity features have now become a major concern.data origin authentication is needed to help ensure that the results ofdns lookups come from authoritative sources. a widely publicized casethat involved the diversion of internet users to an undesired web sitedrew attention to the lack of such authentication in the dns.31see derek atkins and rob austein, òthreat analysis of the domain name system,ó rfc3833, august 2004, available at <http://www.rfceditor.org>.2notably the establishment of the operations analysis and research center by the internetsystems consortium (see https://oarc.isc.org/) and the online performance monitoring bythe kroot (see <http://k.rootservers.org/#stats>).3in 1997, eugene kashpureff diverted internet users who were seeking the networksolutions web site to his own site, although this was intended as a publicity stunt ratherthan as a malicious attack. see rik farrow, òlocking up dns troubles,ó network magazine,august 5, 2000, available at <http://www.networkmagazine.com/showarticle.jhtml?articleid=8702868>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.154signposts in cyberspacedata integrity protection is needed because dns data flows could becompromised at any point between the various name servers, resolvers,or other intermediaries, and the corrupted data can remain in caches forextended periods of time.to respond to these potential vulnerabilities, the technical community has over a number of years developed dns security extensions(dnssec).4 dnssec adds data origin authentication and data integrityprotection to the dns. it aims to ensure that the recipient can validate thatthe data was sent from an authoritative source and that it arrived at itsdestination unchanged.4.1.1mechanics of dnssecdnssec provides endtoend protection through the use of cryptographic digital signatures that are created by responding zone administrators and verified by a recipientõs resolver software. in particular,dnssec avoids the need to trust intermediate name servers and resolvers that cache or route the dns records originating from the respondingzone administrator before they reach the source of the query. dnssecalso preserves the capacity for localized variations and independencewithin the dns hierarchy.5in dnssec, resource record sets (rrsets) 6 within a zone are signedbased on the model of publickey cryptography.7 to support each signing operation, two keys are generated: a private key (to sign data) and thecorresponding public key that is used to verify that the data were signedby the private key. the process of signing takes data to be signed and aprivate key as inputs to produce digitally signed data as the output.8however, dnssec involves signing the hash value of an rrset, rather4defined in roy arends, rob austein, matt larson, dan massey, and scott rose, òdnssecurity introduction and requirement,ó rfc 4033, march 2005, available at <http://www.rfceditor.org>.5for example, the control of the private and public keys remains within each respectivezone.6resource records that have the same label, class, and type are categorized as belonging tothe same rrset. see box 3.2 for a detailed explanation of resource records.7for a review of public key cryptography and digital signatures, see paul albitz andcricket liu, dns and bind, 4th edition, chapter 11, oõreilly media, sebastopol, calif., 2001;and fred b. schneider, editor, computer science and telecommunications board, nationalresearch council, trust in cyberspace, chapter 4, national academy press, washington, d.c.,1999.8the crucial property of the digital signature is that it could have been produced only bysomeone with access to the private key.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects155than signing the full rrset itself.9 (see figure 4.1 for an illustration of thednssec signing and verification process.)two copies of the rrset are sent over the internet to the recipient.one copy is not signed; the other is hashed and then signed as describedabove. to verify the origin and integrity of the unsigned rrset, it ishashed using the same algorithm used by the sender. it is then comparedwith the verified, but still hashed, copy of the rrset created by the zoneauthentic rrsethashsignsigned hash of rrsetverify signature of rrsethashreceivedrrset=?hashhashedrrsetprivate keypublic keyreceivedrrsetverifiedreceived hash of rrsetrecipientsenderinternetinternetif hashed rrsetsare =, the received rrsetis authentic; if not, it is not.1.2.authentic rrsethashsignsigned hash of rrsetverify signature of rrsethash=?hashhashedrrsetprivate keypublic keyhashedrecipientsenderinternetinternetif hashed rrsetsare equal, the received rrsetis authentic; if not, it is not.1.2.figure 4.1use of dnssec to authenticate a resource record set (rrset).9a hash algorithm is a mathematical process that converts a message to a probabilisticallyunique fixedlength string of digits that represents the original message. a hash algorithm isessentially unidirectional: given a hash value, it is nearly impossible to reverse the process toderive the original message in order to construct a second message whose hash valuematches that of the original message. since a hash value is typically much less data thancontained in an rrset, it is generally more efficient to sign hash values rather than rrsets.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.156signposts in cyberspaceadministrator. matching hash values provide a high level of assurancethat the nonsigned rrset is authoritative and that it has not been alteredin transit.dnssec can, when everything works correctly, give the data consumer (validating resolver) some confidence that the received data is whatthe data producer (signing zone administrator) has sent. it provides a basis for trusting that the data has been received without tampering. it doesnot, however, assure that the data that the data producer sent is errorfreeor appropriate for the data consumerõs application.the dnssec extensions are based on four new resource record types:the public key (dnskey), the resource record digital signature (rrsig),the delegation signer (ds), and the authenticated denial of existence(nsec).10 the public key used to verify the digital signature of an rrsetis stored in the dnskey resource record.11 the digital signature is storedin the rrsig resource record, and several rrsig resource records may beassociated with an rrset, if more than one cryptographic algorithm isused for signing the rrset.dnssec depends on establishing the authenticity of the dns hierarchy leading to the domain name in question, and thus its operation depends on beginning the use of cryptographic digital signatures in the rootzone. the ds resource record facilitates key signing and authenticationbetween dns zones to create an authentication chain, or trusted sequenceof signed data, from the root of the dns tree down to a specific domainname. to secure all dns lookups, including those for nonexistent domain names and record types, dnssec uses the nsec resource record toauthenticate negative responses to queries. nsec is used to identify therange of dns names or resource record types that do not exist among thesequence of domain names in a zone.124.1.2deployment of dnssecdnssec implementation on a global level faces a number of technical and nontechnical challenges. the process of cryptographically sign10for detailed information about these resource records, see roy arends, rob austein,matt larson, dan massey, and scott rose, òresource records for the dns security extensions,ó rfc 4034, march 2005, available at <http://www.rfceditor.org>.11the private key must be closely protected from public access, of course, and so it is notstored in a resource record.12the implementation of dnssec also necessitates other changes that are too detailed todiscuss here. for the specifics on the two ònew message header bitsó (cd and ad) indnssec, see roy arends, rob austein, matt larson, dan massey, and scott rose, òprotocolrequirements for the dns security extensions,ó rfc 4035, march 2005, available at <http://www.rfceditor.org>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects157ing hash values derived from resource records, along with the increase inthe dns packet size to accommodate large key sizes, adds significant operational costs for organizations that manage dns servers because of theincrease in dns data and the associated increases in server computationsand communications traffic.13 the implementation of dnssec also increases the volume of internet traffic and that, in turn, could increase thevulnerability of the internet to denialofservice (dos) attacksña threatdnssec does not protect against, although dnssec may offer more confidence in the responses of anycast satellites, which do provide a measureof defense against dos attacks. dnssec could also cause more timeoutsthat would degrade the quality of service for end users.14 dnssec alsointroduces more complexity to the dns and adds to the administrativerequirements for managing the security mechanism.15 for instance, theadministrator of a large zone would probably experience great difficultyin resigning his or her entire zone daily. this would require dividing thetask among many smaller parallel operations that could be managed withsoftwareña solution that is feasible given the dnssec design (that makessignatures within a zone remain largely independent), but would not bewithout additional costs.because public keys for the root zone will need to be replaced withnew ones on a regular basis, key management for the digital signaturespresents another problem for dnssec. in particular, the interaction ofkey revocation with global caching and the distribution of copies of a newpublic root key remain unresolved,16 and this adds even more importance to the management of root zone keys. the consequence of a corrupted root zone key is that it would break the chain of trust for sourceauthentication and data integrity that serves as the basis of dnssec. arelated and more fundamental and thorny problem that technical solutions could only partially resolve is reaching agreement over which organization should have control of the root zone key. obvious candidates for13estimates for the increased computations and communications traffic associated withthe introduction of dnssec vary, but range from a 5 to 10fold increase. see albitz and liu,dns and bind, 2001; beth cohen, òdnssec: security for essential network services,ó may12, 2003, available at <http://www.rfceditor.org>; and diane davidowicz and paul vixie,òsecuring the domain name system,ó network magazine, january 1, 2000.14see david berlind, òdns inventor says cure to net identity problems is right underour nose,ó august 7, 2003, available at <http://techupdate.zdnet.com/techupdate/stories/main/0,14179,2914447,00.html>.15see cohen, òdnssec: security for essential network services,ó 2003.16distributing new public root keys is difficult as they must be preconfigured in dns rootname servers, but they cannot be delivered via dnssec, since they cannot vouch for themselves, and thus they may require an offline distribution mechanism. one proposed solutioninvolves the publication of a public root key in national and international newspapers, whichillustrates the magnitude of the problem.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.158signposts in cyberspacethe controlling organization include verisign, icann, and the department of commerce; other entities could also be considered. however,until a controlling organization is identified, the deployment of dnssecis likely to be delayed.17while the introduction of dnssec imposes significant costs and doesnot eliminate all internet security concerns nor address all internetthreats,18 its implementation would represent considerable progress inimproving the security of the dns. for example, it would raise the levelof protection against the falsification of dns data to help in deterringidentityrelated theft and spam problems.19 furthermore, dnsec provides a basis to build trust on the internet to support higherlevel protocols facilitating internet protocol (ip) telephony and other web services.20conclusion: the security of the dns would be significantly improvedif dnssec were widely deployed among name servers for the root zoneand toplevel domains (tlds) in particular, and throughout the dns ingeneral.conclusion: urgent attention is needed to identify the organizationthat would maintain control of the root zone key. the deployment ofdnssec is likely to be delayed until this organization is identified.recommendation: dnssec should be deployed throughout the dnsas practical, with highest priority given to deployment in the root zoneand the tlds.4.2linking the telephone andinternet naming systemsthe internet and the traditional telephone network operate differently. when a traditional telephone call is made, switches create a circuitbetween the caller and the person who is called. that circuit remains inplace for the duration of the call. the process is called circuit switching.17several facilities in the netherlands and sweden are examining how dnssec couldoperate when it is generally deployed by examining procedures, such as key rollover, determining parameters for dnssec mechanisms, such as key length and signature lifetimes,and other issues beyond the scope of this discussion. for more information about currentefforts of dnssec testing, see <http://www.dnssec.net>.18see atkins and austein, òthreat analysis of the domain name system,ó rfc 3833, 2004.19see berlind, òdns inventor says cure to net identity problems is right under ournose,ó 2003.20see john leyden, òdns inventor calls for security overhaul,ó the register, april 11,2003, available at <http://www.theregister.co.uk/content/7/30224.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects159however, when a message is sent from one computer connected to theinternet to another computer, no such circuit is established. rather, themessage is broken into packets and each is routed through the networkindependently, possibly even following different paths, and reassembledat their destination in the proper order. that process is called packetswitching. for the most part, the circuitswitched world of telephony andthe packetswitched world of the internet have remained distinct. however, in recent years, a convergence between the two has begun to occur,with increasing use of the internet to transmit telephone calls through aprocess called voice over internet protocol, or voip.21the recognition of the potential convergence of telephony and theinternet was one of the motivations for consideration by the technical community of ways to bring telephone numbers into the domain name system. doing so, it was thought, would facilitate communications betweenthe internet and the worldõs telephone networks. the method that wasdeveloped is called the telephone number mapping protocol, more commonly known as the enum protocol.22 under the enum scheme, telephone numbers, called e.164 numbers,23 are mapped (via the enum protocol) to domain names. these are then mapped (in the dns) to variousresources by dns lookups that lead to uniform resource identifiers(uris).24 the main premise underlying development of the enum protocol is that standard telephone numbersñfamiliar, globally unique identifiers easily usable on numeric keyboardsñare likely to persist. consequently, making it easy to link the internet and telephone naming systemsmay support the development of new and improved services that use atelephonylike model.applications that can build on the enum protocol include voice communications, fax, email, and messaging. for example, a telephone call21see, for example, the explanation of voip on the federal communications commissionweb site, <http://www.fcc.gov/voip/>.22see patrik f−ltstrım and michael mealling, òthe e.164 to uniform resource identifiers(uri) dynamic delegation discovery system (ddds) application (enum),ó rfc 3761,april 2004, available at <http://www.rfceditor.org>. the mechanism used by enum formapping telephone numbers into the dns was first specified in late 1992 as part of aninternet òremote printingó model that could substitute for fax and other telephoneenabledtransmission mechanisms. that application and the mapping mechanism are described incarl malamud and marshall rose, òprinciples of operation for the tpc.int subdomain:remote printingðtechnical procedures,ó rfc 1528, october 1993, available at <http://www.rfceditor.org>.23e.164 is the designation for the international telecommunication union recommendation that established the global numbering plan. rfc 3761 stipulates that the domain namesgenerated through the enum protocol must adhere to the existing e.164 country (or region)delegations.24see box 6.2 for a definition of uris.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.160signposts in cyberspacemight originate from a standard desktop telephone set and terminate at atelephone connected to the internet (after passing through a gateway).the implementation of the enum protocol may facilitate the completionof such voip telephone calls, although such calls do not require the use ofenum as an addressing mechanism. the enum protocol enables the useof a single e.164 number to access applications based on the telephonenetwork, the internet network, or both networks. thus, it may enable increased functionality and/or lower costs for communications in such interconnected networks.254.2.1mechanics and operations of enumthe enum protocol specifies how telephone numbers are convertedinto domain names. the conversion is best explained through an example.begin with a telephone number such as +4681234567. then remove allcharacters except the digits, put dots between the digits, and reverse theorder, which yields, in the example above, 7.6.5.4.3.2.1.8.6.4. then a secondlevel domain name is appended, which for the implementation of theenum protocol is e164.arpa.26 the resulting enum domain name is then7.6.5.4.3.2.1.8.6.4.e164.arpa.the deployment of enum is typically envisioned in tiers. the highest level within the enum hierarchyñtier 0ñcorresponds with the selected secondlevel domain e164.arpa.27 the name server resourcerecords in this secondlevel domain would point to ònationaló tier 1 registries, such as 2.6.e164.arpa (for indonesiañtelephone country code 62) or2.3.e164.arpa (for belgiumñtelephone country code 32).28 the delega25the resources used to develop this subsection include presentations and discussions atthe public forum of the meetings of the internet corporation for assigned names and numbers, rio de janeiro, brazil, march 25, 2003, available at <http://www.icann.org/riodejaneiro/captioningboardmeeting27mar03.htm>; materials from the internationaltelecommunication workshop on enum, geneva, switzerland, february 8, 2002, availableat <http://www.itu.int>; the enum web site of the international telecommunicationunion, at <http://www.itu.int/osg/spu/enum/>; òfrequently asked questions,ó available at <http://www.enum.org>; john c. klensin, editor, òthe history and context of telephone number mapping (enum) operational decisions: informational documents contributed to itut study group 2 (sg2),ó rfc 3245, march 2002, available at <http://www.rfceditor.org>; and òonline registries: the dns and beyondé,ó release 1.0, september 16, 2003, edventure holdings, inc., new york.26e164.arpa is the secondlevel domain name specified by the internet architecture boardfor enum use in rfc 3761. the .arpa tld is intended to support internet infrastructureinitiatives such as the implementation of the enum protocol.27the r”seaux ip europ”ens (ripe) network coordination centre (ncc) is the administrator of the e164.arpa domain as determined by the internet architecture board.28twentysix codes have been delegated (28 have been approved) as of march 4, 2005, asreported by ripe ncc at <http://www.ripe.net/enum/requestarchives>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects161tion beyond tier 1 registries (and the definition of a òtieró itself) may differamong countries. various trials are underway in a number of countries toidentify the most effective models for those countries.29a tier 1 registry could delegate directly to name servers that containenum information. however, in some models for the implementation ofthe enum protocol, a tier 1 registry would delegate to multiple tier 2operators (e.g., divided in a way that is based on how telephone numbersare partitioned within a country). tier 2 operators would then operatename servers that contain enum information that takes the form of naming authority pointer (naptr) resource records.30 these records includenaptr records for servicespecific addresses (e.g., an email address, cellphone number, fax number, and so on31), which would all be returned inthe response to any dns query about a particular enum domain name.an important feature of naptr records is that they can convey priorityordering (e.g., try this address firstñif there is no response, then try thisone). the situation described above is referred to by some as the callingparty control model because the dns query for the naptr records retrieves all possible contact modesñthat is, access to this information isdetermined by the requestor.tier 3 services could also be offered. services at this level could support operations after the completion of a lookup of enum information(i.e., some of these operations might not depend on the dns in any way).for example, a lookup from a tier 2 name server could point to a proxyserver that contains tailored user information, rather than to servicespecific addresses directly. this tailored user information could, in turn, provide office addresses to all queries and, in addition, home addresses onlyto those requests with particular characteristics. alternatively, all queriesto the naptr records could be directed to this tailored user information,thereby providing the called party with control over what contact information is made available (i.e., the calledparty control model).3229for example, see <http://www.itu.int/itut/inr/enum/trials.html>.30naptr records are described in michael mealling, òdynamic delegation discoverysystem (ddds) part three: the domain name system (dns) database,ó rfc 3403, october2002, available at <http://www.rfceditor.org>.31these addresses may be specified using a variety of protocols that include the sessioninitiation protocol (sip), which supports the negotiation of the parameters between endpoints for a realtime session. see mark handley, henning schulzrinne, eve schooler, andjonathan rosenberg, òsip: session initiation protocol,ó rfc 2543, march 1999, available at<http://www.rfceditor.org>.32this discussion was derived, in part, from òenum: mapping telephone numbers on to theinternet: potential benefits with public policy risks,ó april 2003, center for democracy andtechnology, washington, d.c., available at <http://www.cdt.org/standards/enum/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.162signposts in cyberspace4.2.2technical and public policy issuesthe deployment of the enum protocol raises anew most of the challenges associated with the dns as well as a few new ones. thus, the technical and policy context for enum implementation includes a wide variety of issues that should be resolved prior to the widespread deploymentof the enum protocol and serves as an illustrative case study for otherapplications that might be developed on top of the dns. (it also illustratesanother one of the core internet navigation issues: while enum providesmechanisms for mapping from telephone numbers to the dns and from adomain name to relevant resources, it does not address the problem ofdetermining a telephone number given some (possibly inexact) form ofthe name of a person or organization (and perhaps some additional qualifying attributes). on a global basis, that navigation problem is far moredifficult than the challenges associated with enum.)¥registrars and consumers.an important implementation issue iswho has control over the information in the name servers. conflicts overthe inclusion or content of naptr records need to be resolved in someway. the design of the mechanisms for managing these conflicts can drawfrom past experience with the dns and telephone networks, which hasincluded dealing with slamming (the unauthorized change in service providers), number portability, and recourse in the event of fraud.¥privacy.since the records in the dns are publicly accessible, there issome concern about the privacy of the personal information stored there.of specific concern are uris in the naptr records that refer to personalinformation that an individual would not wish to have linked to a telephone number in a freely accessible way.33 alternatives such as the calledparty control model described above accord individuals the ability tospecify what kind of information will be publicly available, and an optinstrategy provides individuals with the ability to decide whether his or hertelephone number will be included in the dns as an enum domain name.¥authentication and security.under a system in which an individualmust make a deliberate optin decision, authentication of his or her identity is critical in substantiating that the person who wants a number isreally that person and that he or she has the rights to use that number(and to make subsequent modifications to enum information). in addition, ensuring that the results from lookups to enum information areauthentic suggests that the implementation of dnssec is as critical forenum deployment as it is for other dns applications, as discussed insection 4.2.33however, note that the storage of e.164 numbers themselves in name servers is not aprivacy issue. the issue arises when e.164 numbers are linked to personal information.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects163¥institutions.because enum is also dependent on telephone numbers and the various policies that pertain to telephone numbers, the institutional framework includes the international telecommunication union(itu). also, as enum is based on telephone number country codes, national policies must be considered. a clash of institutional approaches mayresult, given the strong regulatory tradition associated with telephonenumbering that contrasts with the traditionally less regulated management of internet naming and addressing.an important design characteristic of the dns is the existence of aroot zone that provides the operational basis for global uniqueness andcoherence. by contrast, telephone service providers determine the country codes that they use for routing telephone calls. each provider mightnot use the same set of codes. for example, the country code +866 is usedfrom many, but not all, locations in the world to complete telephone callsto taiwan. the +866 country code is not officially allocated to taiwan, butit is being reserved by the itu, which manages the country codes in theworld. because the enum model as currently implemented requires ituand national approval for each enum delegation, the use of standardenum for communication in and with taiwan has been prevented by thepeopleõs republic of china.¥other.the deployment of the enum protocol raises other issuesthat are too detailed to be discussed here, such as the disposition of anenum domain name when an individual terminates the service for thecorresponding telephone number. the references provided in this sectionprovide pointers to documents that explore these issues.4.2.3alternate modelsin principle, enumlike domain names could be based on a uniqueidentifier other than a telephone number. for example, consider the useof any random identifier that is globally unique, such as a product barcode. or one might tie enum more closely to the existing countrycodetld model, using iso 3166 numeric codes rather than e.164 country codesto identify the countryspecific part of the number. another alternativecould call for the use (at least in part) of a domain other than e164.arpa.also, the hierarchy of names need not be based on countries at all. however, it is unclear whether the adoption of an alternate model instead ofthe enum protocol would provide the basis for a superior deployment.the deployment of the enum protocol could support important newapplications. however, it is also the case that its deployment would reinforce the utility of telephone numbers. assuming that it is increasinglydesirable to identify an individual or activity rather than a telephone number, the deployment of the enum protocol might not be optimal in thesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.164signposts in cyberspacelong run because its use could forestall efforts to develop systems withgreater capabilities.conclusion: overall, the plan to deploy the enum protocol couldlead to applications that use the dns without necessitating any changesto dns protocols or software. however, a number of important technicaland public policy issues would need to be resolved in each country thathas an interest in deploying enum. these issues include establishing therights and requirements of registrars and consumers, developing practices for the protection of personal privacy, implementing procedures forauthentication and security, and developing an effective and efficient institutional framework for operation of enum.4.3internationalizing domain namesone of the issues of particular interest in many countries is access tothe internet and the dns using homecountry languages and scripts. asthe number of users in countries with first languages that are not based onthe roman characters used in the dns increased dramatically throughthe 1990s, interest developed in domain names based on nonromanscripts (e.g., chinese, hebrew, arabic, and so on). several major effortswere undertaken in the effort to accommodate internationalized domainnames (idns) within the internet infrastructure.unfortunately, the design of the dns presents formidable technicalchallenges for the accommodation of languages that use nonroman characters. as a lookup system, the dns must be able to determine unambiguously whether there is a match with a query or not. comparing stringsis much more difficult than most people realize, because the definition ofwhat is òequaló is often not deterministic. for example, consider the caseof the french language in canada and france, for which there are different rules as to whether an accent stays over the character when it is converted from lower to upper case.34 and some languages (e.g., chinese)cannot even be reduced to a relatively small number of standardized characters (e.g., the character set for english). as these challenges were articulated and analyzed by the interested communities, it became clear that thewidespread deployment of idns would necessitate a number of compro34another example is the òaó with diaeresis ò¬ó (ò−ó) which in german should be sortedand looked at exactly as an òaó with diacritical character, but in swedish has nothing to dowith the character òaó except the look. in the same way, † as the abbreviation for the physical unit of length òangstromó is one character, but the initial character of the word †ngstrımis another (which in turn is different from an òaó). the other problem with the german òaówith diaresis (umlaut) is that it may be considered to match the string òaeó, while not allnames containing òaeó match ò−ó.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects165mises. some of these compromises stemmed from intense arguments overthe preservation of cultural identities, the use of names that are semantically correct, and other linguistic issues.other compromises have their roots in technical issues. some of thosewho were very concerned about the integrity of the dns argued that internationalized domain names should be implemented in applications(e.g., by reworking url and similar formats to accommodate idns directly). some other technical experts argued that the deployment of idnsshould be executed through a major overhaul of the internetõs infrastructure, rather than as an addon. however, considerable pressure developed within the interested communities to implement idns in the nearterm and, therefore, solutions that would require extensive changes inarchitectures or standards did not attract very much support. this pressure provided the impetus for an effort led by the internet engineeringtask force (ietf) that culminated in a standard solution, the internationalizing domain names in applications (idna) mechanism.354.3.1internationalizing domain names in applicationsthe central goal of the idna scheme is to enable enduser viewing ofidns (e.g., .cn) without altering the dns protocols themselves.hence, even though an end user may see an idn, the dns itself sees onlythe usual ldhstyle domain names.36 idna is entirely a clientside set ofprocedures.there are a number of encoding systems for representing various language scripts. in the discussions leading to the adoption of idna as astandard, it became clear that a constraint would be needed on the number of encoding systems so that the introduction of idns would be tractable. unicode was agreed to be the clientside encoding system for language scripts.37 thus, any user application based on other encodingsystems would first have to translate its internationalized domain names35idna is described in patrik f−ltstrım, paul hoffman, and adam m. costello, òinternationalizing domain names in applications (idna),ó rfc 3490, march 2003, available at<http://www.rfceditor.org>.36these are domain names comprising letters, digits, and the hyphenña subset of asciiñas described in chapter 2.37òunicode is a coded character set containing tens of thousands of characters. a singleunicode code point is denoted by òu+ó followed by four to six hexadecimal digits, while arange of unicode code points is denoted by two hexadecimal numbers separated by ò..ówith no prefixes,ó as described in rfc 3490. additional information about unicode may befound at <http://www.unicode.org>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.166signposts in cyberspaceto a unicode representation prior to processing by idnacompliant procedures.38the algorithms that make up idna work on the individual parts of adomain name separated by dots, which are called labels.39 translationcan occur in two directions: from unicode to ldh format (ascii) or thereverse.the input to the òtoasciió algorithm is a single label comprisingunicode code points. however, before labels are processed, they must benormalized because different unicode strings can represent the same domain name.40 thus, a profile (ònameprepó) is appliedña string preparation and normalization procedure for unicode that is partially derivedfrom unicode technical consortium (utc)specified normalization procedures.41 an encoding system (òpunycodeó) is then used for mappingònamepreppedó labels into conventional ldhstyle labels.42 these labelsare then concatenated (with dots in between the labels) to generate theresulting domain name. in the process of assembling the resulting domain name, òxnñó is added as a prefix to denote that the domain name isan idn;43 an example of such a domain name is xn—fiq43lrrlfy5a.tw. atthis point, the dns is used as described in chapter 3.the process for going from ascii to unicode involves the use of thedecoding algorithm in punycode. the details of this process are describedin òinternationalizing domain names in applications (idna),ó rfc 3490.38the mappings to and from unicode may not be obvious (and may become controversial), as the local encodings sometimes make distinctions that unicode does not, or viceversa.39for instance, in www.example.com, there are three labels: www, example, and com.40for example, upper case characters would be converted to lower case characters. however, this case mapping may be problematic, as in the case for handling diacritical markswhere characters are mapped to upper case in modern french as compared to older forms(still used in qu”b”c and elsewhere). also, consider the unicode stringwww.exa$(not$)mple.com that would be normalized to www.example.com. adapted fromeric a. hall, òthe idnatoascii conversion process,ó network magazine, june 1, 2004, p.60.41see paul hoffman and marc blanchet, ònameprep: a stringprep profile for internationalized domain names,ó rfc 3491, march 2003; and paul hoffman and marc blanchet,òpreparation of internationalized strings (stingprep),ó rfc 3454, december 2002, available at <http://www.rfceditor.org/>. for unicode normalization, see mark davis andat <http://www.unicode.org/reports/tr15/tr1523.html>.42see adam m. costello, òpunycode: a bootstring encoding of unicode for internationalized domain names in applications (idna),ó rfc 3492, march 2003, available at <http://www.rfceditor.org>.43the description given here is a simplified one. the many details concerning the variousalgorithms may be found in the rfcs referenced above.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects167clientside supportthere is a gap between òdeploying idnaó (i.e., adding idnaformat(punycode) domain names in dns zones) and the actual ability of usersto see, or provide as input, domain names expressed in characters that areònativeó to their preferred languages. the actual appearance of a domainname in native characters on a screen or printout, or the ability to transcribe such characters from a sign on the side of a bus into a url to locatea web page, requires that the relevant applications be upgraded to recognize the idna format and to translate to and from local scripts.supporting web accesssome web browsers have been upgraded to support idna namesdirectly, whereas others, including the most common browser, internetexplorer, support idna through browser plugins.44 these extensions tobrowser operations and syntax are not standardized and not consistent,leading to different users getting different results depending on whichtools they choose to use (or, more commonly, have chosen for them).45 inthe worst case, the consequence is a breakdown of the principle of referential integrityña putative domain name or uri, when passed from oneuser to another, acquires a different meaning (or target) depending on theenvironments of the two users. even when support for web browsers isachieved on a consistent and widespread basis, it will take a considerableperiod of time to replace the millions of copies of web browsers. forresterresearch predicts that it will take at least 2 to 3 years before idns canreally be used for web browsing and up to 5 years until 90 percent ofapplications are idn compatible.46supporting email and other accessfor applications other than the web, the situation is yet more problematic. there is, in general, no òpatchó option equivalent to the browserplugins. while there are only a few heavily used browsers, there are very44for an example of a plugin, see <http://www.idnnow.com>. internet explorer doesnot provide direct support for idna as of july 2004.45improper resolution and browser plugins that were not stable enough, complicated,and slow to download were among the reasons why network solutions, inc., pulled out ofthe idn business in early 2004. see ònsi pulls out of idn registration, citing technicalproblems,ó washington internet daily, january 15, 2004.46see thomas mendel, òinternationalized domain names: good idea; shame about theexecution,ó forrester research, march 10, 2004, available at <http://www.forrester.com/research/document/excerpt/0,7211,34018,00.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.168signposts in cyberspacelarge numbers of client / user interface programs for email, the filetransfer protocol (ftp), and other protocols. some of these programs areembedded in firmware on portable devices, which generally cannot beupgraded in a practical way.electronic mail poses additional problems. for most users, the web islargely passive: people find and view web pages, but relatively few userscreate their own web content or need to establish addressing or locationinformation for it. email, by contrast, is not passive. most email usersare actively engaged in the creation and receipt of email. addresses readover the phone or copied from business cards or notes may well be morecommon for email than for the web. moreover, internet email operatesin a storeandforward mode: unlike, for example, the web, there is normally no reliable mechanism for a sender to determine, or negotiate, thecapabilities of the receiver such as whether a receiver can handle internationalized addresses. and, finally, users typically expect the left side orlocal part (before the ò@ó) of an email address to reflect their names andrelated conventions (or other personal identifiers such as nicknames) andto do so accurately.47 people are often extremely sensitive about the spelling of their names (or other personal identifiers), and efforts to replace email addresses based on names with ones that involve semirandomstrings have rarely been met with enthusiasm. even if the domain namepart of the address internationalization problem were solved with appropriate user agent software, it may well lead to more demand for properlyspelled and formatted local parts in local scripts. nonenglishspeakingusers who have been using addresses containing romanized transliterations of their names are not likely to consider a transition to encoded asciistrings that have no mnemonic value and that generally cannot bepronounced to be a step forward, especially with their expectations fornativescript presentation.design and standardization efforts for email local parts are in theirinfancy in 2005. there are two major proposals. one tries to minimize thenumber of infrastructure changes that are required (just as idna avoidedrequiring, or even permitting, any dns protocol changes). the other proposal assumes that true internationalization is going to require rethinkingemail in an internationalized context (and hence requiring those whowish to take advantage of internationalized addresses to implement someupgrades).47although the òlocal partó of an email address is not within the scope of idna standards, it is an important issue concerning the internationalization of the internet morebroadly.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects1694.3.2registries and registrarswhen it approved the initial versions of the idna standards, theinternet engineering steering group (iesg) issued a statement that discussed the scope of those documents and areas in which other work wasneeded by other organizations.48 specifically, it pointed out that idnaaddresses characters only and that any relevant language or script issues,including nearequivalencies, must be dealt with on a perregistry basis.it also identified the special problems faced by generic toplevel domains(gtlds), the importance of conservatism in characters that are permitted,and concerns about display issues with converted idna strings.after some discussion, and essentially as part of the process of gettingseveral new countrycode tlds to sign up to a formal icann relationship, icann issued a set of guidelines for the deployment of idns intlds.49 these guidelines build on the iesg statement and the work of thejoint engineering team (jet; discussed below) and provide that topleveldomain registries must use the idna standards and must adopt conservative, languagespecific approaches to idn registration.to protect their populations from confusion and fraud, and, in at leastsome cases, to comply with icann guidelines, registries have begun toestablish languagebased policies for registrations. the key to these involves specifying which particular characters can be registered out of theunicode set or, when language rules are interpreted strictly, which characters are permitted in combination. of course, there is no standard list ofcharacters for any given language, and the unicode technical consortium has declined to make lists of characters that belong to named (bylanguage or otherwise) scripts, so a òlanguageó for dns purposes is ultimately a list of characters chosen by registries, with each registry free tomake a different choice. for the convenience of registries that are disinclined to reinvent the wheel, the internet assigned numbers authority(iana) set up a registry/catalog of these language/script/registrytables.50 the criterion for registration is that a tld registry thinks thetable is worthwhile; icann is not going into the òwhat is really a languageó business.this leaves the more complex question of what scripts and languagesa particular registry should permit. the smaller the number of scripts permitted, the lower the odds of fraud or other undesirable behavior. prohibition of mixing of scripts (or languages) within a given label is almostimplicit in a languagebased system and will prevent at least some prob48see <http://www.ietf.org/iesg/statements/idnstatement.txt>.49see <http://www.icann.org/general/idnguidelines20jun03.htm>.50see òidn language table registry,ó at <http://www.iana.org/assignments/idn/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.170signposts in cyberspacelems,51 but it may restrict some registrations that might be consideredreasonable.all of these issues are much more complex for gtlds, or other tlds,that are seen as serving the entire world. within a country, a decision as towhich languages or scripts are more important than others is at least tractable. while it may be very difficult, especially in countries that have morethan one official language, and where there are constitutional provisionsprohibiting treating some of those as more important than others, theseare the types of decisions that governments are typically constituted tomake. for generic toplevel domains, on the other hand, there is an, atleast, implied requirement to treat all registration applicants equally,which implies that policies such as òthis script is preferred over that oneóor òthis language is assumed when the choice of language cannot be determinedó are much more difficult, if not impossible, to implement.4.3.3chinese, japanese, and korean scriptsthe scripts of chinese, japanese, and korean (cjk) present specialchallenges. these languages are based on han ideographs, which are derived from pictographs and are constantly evolving. the òsimplificationóof chinese writing in the peopleõs republic of china (prc) in the early1950s created a sharp divide in methods of writing chinese, with the simplified characters being used in the prc, but not in taiwan, hong kong,macao, and other chinesespeaking communities elsewhere in the world.however, the mapping between simplified and traditional chinese formsis not always onetoone, but sometimes requires knowledge of meaningor context.52 in addition, chinesebased characters are used in writtenjapanese (as kanji) and in korean (as hanji). an algorithm for handlingmappings between traditional and simplified chinese characters that wasnot sensitive to the particular language in use would map, for example,51at the time idna was adopted, the utc representatives who were participating in theworking group were convinced that a òone label, one scriptó rule would prevent many,perhaps most, potentially fraudulent cases resulting from confusing one character with another. more examples have been turned up since then, and few, if any, people actively engaged in idn issues now believe that such a restriction would eliminate even a large fraction of the potential problems.52increasing communications and commerce among chinesespeaking groups make itimportant that simplified and traditional characters be treated as equivalent. the committeethat did the writing simplification work, however, followed the historical pattern of language reforms over the centuries: they did more than simply replace one written characteror one spelling with another and, instead, made some changes to disambiguate homographsand consolidated other words.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects171kanji into simplified chinese, resulting in the characters becoming notonly incorrect, but also unreadable to a significant fraction of the japanesepopulation.to address the cjk script issues, a joint committee known as the jointengineering team (jet) was created among the network information centers and registries for japan, china, and korea. that committee created acollection of guidelines for registration of the cjk languages and characters.53 those guidelines, in turn, introduced two new concepts into dnsmanagement: òvariant charactersó and òreserved labelsó that could be registered into the dns only by the registrant of some other, primary, label.in the jet model, the script associated with a particular language isdefined by the entries of a table, with the primary (valid) characters beinglisted, one per row, in that table. if a label were proposed to be registeredthat contained any characters that did not appear among these entries, theregistration attempt would be rejected as not conforming to the script.each one of these characters may be associated with zero or more preferred variantsñcharacters that, if they appear, are considered to be fullyequivalent to the òvalidó character; and character variantsñcharactersthat might be confused or substituted for the valid one (see figure 4.2).that is, many han ideographs look exactly the same or have a similarappearance but are assigned different code points in unicode. the variants for the individual characters are then used to generate alternate (variant) versions of the labels. for example, if a label proposed for registration were abc, and òbó had variants òxó and òy,ó a label set (idnpackage) would be formed consisting of òabc,ó òaxc,ó and òayc.ó allof these labels would be reserved; that is, it would not be possible foranyone but the registrant of òabcó to actually register them in the dns.54the labels generated from the preferred variants (as well as, of course, theoriginal òabcó) would be automatically registered; those from the character variants would be reserved and could be registered at the option ofthe package registrant. of course, if more than one of the characters in alabel had a nonzero number of variants, the number of variant labelsgenerated by the combinations, and hence the size of the idn package,could become quite largeñexamples have been shown of some chineselabels that could generate hundreds of variants.5553see kazunori konishi, kenny huang, hualin qian, and yanwoo ko, òjoint engineeringteam (jet) guidelines for internationalized domain names (idn) registration and administration for chinese, japanese, and korean,ó rfc 3743, april 2004, available at <http://www.rfceditor.org>. also see james seng, òjet guidelines for internationalized domainnames,ó circleid, may 8, 2004.54the jet guideline document uses the term òactivate.ó55the jet guidelines view idn packages as atomicñthere should not be a mechanism formoving names in or out of a package once it is created.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.172signposts in cyberspaceintroduction of the òpackageó concept raises varying economic questions that do not arise with ldhstyle domain names. how should thepricing of idns reflect the reality that each registration may cause other(sometimes many other) domain names to be reserved? also, given thatthere is only one possible authorized registrant for a reserved domainname, what options exist for pricing? many new possibilities arise in therealm of domain name pricing structures for idns.the challenges posed by cjk scripts also exist, though perhaps lessseverely, in alphabetic languages. thus, work to generalize the jet guidelines to alphabetic languages is underway. two attempts have been madeso far to make that generalization work, or at least to construct recommendations for considerations as to how to do it for particular alphabeticscripts and languages.56figure 4.2example of multiple forms of an internationalized domain name.aof course, it is the case that a domain name of the form xn—k0tp21.com, forinstance, could have been registered directly, irrespective of any idn issues (under idna processing, it would represent .com). however, as discussed inchapter 2, there are strong reasons against the registration of domain names thatdo not have some kind of semantic or mnemonic significance to someone, andthese specially coded labels do not have that property. indeed, an extensive searchwas done, and none of these xnðstrings actually appeared, at least in the accessible top few levels of the dns.source: vincent w.s. chen, òidn whois challengesñtwnicõs case study,ópresentation at the icann meeting, october 29, 2003, carthage, tunisia,available at <http://www.icann.org/presentations/chenwhoiscarthage29oct03.ppt>.56see john c. klensin, òsuggested practices for registration of internationalized domainnames,ó draft, may 17, 2005, available at <http://www.ietf.org/internetdrafts/draftklensinregguidelines08.txt>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects1734.3.4conclusionsit was recognized on its adoptionñand it has become much moreobvious sinceñthat idna solved only part of the internationalizationproblem. remaining to be addressed are the questions of consumer confusionñespecially those questions that did not involve intellectual property issues; conflict avoidance or resolution for similarappearing names;differences in interpretations for different languages; restrictions on registrations on a perdomain basis; implications for the uniform domainname dispute resolution process (udrp) and the whois database; security issues raised by idn;57 the implications of (and alternatives to) òmultilingualó top level domains.58recommendation: continuing and increased attention to internationalized domain names is necessary. efforts to coordinate work across different countries, regions, and language groups should be undertaken toprevent the balkanization of the internet.conclusion: the relative merit of an approach for implementing internationalized domain names based on incremental fixes as comparedwith one that involves an infrastructure overhaul remains uncertain.conclusion: although the ongoing work on internationalized domainnames is important, it addresses only a small fraction of the issues associated with internationalization of the internet in general.4.4responding to domain name errorsa challenge that has faced the dns since its inception is that userssometimes make errors when entering domain names as part of web uris,email addresses, or other applications on the internet. the errors maysimply be misspellings or they may be the entry of nonexistent or inactive domains; often they are the result of a user guessing an address orremembering one incorrectly. when an erroneous domain name arrivesat some level in the dns, the standard response is for a òno such domainómessage to be returned to the user. if the application is email, then the57the unicode consortium has published a draft technical report that addresses unicodesecurity issues, including idn issues. see mark davis, òsecurity considerations for theimplementation of unicode and related technologies,ó proposed draft unicode technicalreport #36, unicode consortium, february 2005, available at <http://www.unicode.org/reports/tr36/>.58the implications of idn introduction for dispute resolution are discussed in section5.6.3 and for whois data and the whois protocol in sections 5.7.2 and 5.7.3.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.174signposts in cyberspaceresponse may be from a mailer daemon reporting that the mail couldnot be delivered to the nonexistent address. if the application is the web,then either the internet service provider (e.g., aol or yahoo!) or thebrowser (e.g., internet explorer) may send the erroneous address to asearch engine59 to initiate a search. in any event, the user receives information that the address entered is erroneous.however, in addition to the return of error information to the originator as specified by the dns technical standards and conventions, two controversial kinds of response to user errors have appeared recently. bothderive from the fundamental law of internet commerce: traffic = > income.that is, traffic to an internet location (generally a web site) can produceincome for the owner of the site (through advertising sales); the greaterthe traffic, the greater the income potential. consequently, the commercial imperative is to acquire as much traffic as possible. controversy ariseswhen that imperative leads to actions that confound user expectations or,more fundamentally, challenge the underlying technology standards andconventions on which smooth operation of the internet has been based.4.4.1traffic aggregationthe first controversial response is called traffic aggregation. 60 theaggregator sets up a web site on which multiple advertisers place advertising text that includes links to their marketing sites. the site may or maynot have a specific theme, such as travel or electronic products. the advertisers contract to pay for òclickthroughsó to their sites, that is, for visits that originate from the links on the aggregatorõs site. to attract traffic,the aggregator invests in domain names that would result from likely usererrors, for example, misspellings or wrong guesses of the domain namesof highly trafficked web sites. it may also buy names that have not beenrenewed by the original registrant and solicit people who invest in domain names for future resale (often called cybersquatters) to link theirwarehoused domain names to the aggregatorõs web site in exchange for ashare of the resultant proceeds. the aggregator then awaits the traffic resulting from users who misspell or incorrectly guess a domain name orattempt to visit a domain name that is no longer operative or that has notyet been made operative and collects fees from the advertisers, if any, towhich they òclick through.ó59for an extended discussion of search engines and various forms of paid advertising onsearch engines, see chapter 7.60two traffic aggregators, for example, are trafficz.com and namerenters.com. theirweb sites are, respectively, <http://www.trafficz.com> and <http://www.namerenters.com>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects175although users finding themselves at entirely different sites fromthose intended may be annoyed, the operation of a traffic aggregation siteis in itself neither illegal nor in contravention of the explicit dns technicalstandards. however, by responding to an erroneous query with a webpage that the user was not specifically seeking, it does arguably contravene dns conventions and reasonable user expectations of the dns service. depending on the domain name used to attract the traffic, and thecontent on the page, it might also result in trademark infringement, unfaircompetition, or cybersquatting prosecution under the anticybersquattingconsumer protection act or violate a host of consumer and child protection laws. nevertheless, apparently a sufficient number of users find theadvertised sites of enough interest to follow their links and, thereby, provide income to the aggregators. moreover, there does not seem to be apractical technical or regulatory way to control this practice outside thelisted legal realms. therefore, it not further considered here.4.4.2site finder by verisignfar more controversial and subject to control was the offering of thesite finder service by verisign, which was launched without notice in midseptember 2003.61 that service, which was aimed at users of the worldwide web, rerouted any request concerning an unregistered domain namewithin the .com and .net zones to a verisignoperated web site featuringpaid advertising links and a search engine, rather than returning the usualòno such domainó error message. verisign described it as a valueaddedservice for users that could, at the same time, generate significant revenuefor verisign from the frequent errors in secondlevel domain names in the.com and .net tlds.62 however, the elimination of the òno such domainóerror across the .com and .net domains, which numerous applications depend on for their current operation, had a direct and an indirect impact onthe performance of applications other than the web, on the dns, and onthe internet in general. many in the internet technical and operator communities believed that, even though site finder was implemented in strict conformance with dns standards, it was in conflict with their spirit. as a resultof their strong complaints and icannõs written demand that it desist,6361see verisignõs site finder faq at <http://www.verisign.com/productsservices/naminganddirectoryservices/namingservices/sitefinderservices/page002698.html>.62verisign estimated the number of misspellings to be 20 million per day; see circleid,òfacts and figures,ó available at <http://www.circleid.com/sitefinder>.63see òletter from paul twomey to russell lewis 3 october 2003,ó available at <http://www.icann.org/correspondence/twomeytolewis03oct03.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.176signposts in cyberspaceverisign suspended the service (under protest) in early october 2003 andpursued the matter in the courts, as is described below.the intense reactions from the internet technical and operator communities64 that prompted icann to demand the suspension of the service65 until further review raised issues of two types: technical and institutional. the technical issues were, themselves, of two types: first, whethersite finder would have negative effects on the stability and security of thedomain name system,66 and second, whether verisign had followed anappropriate process for introducing operational changes that have potential effects on other internet processes and applications. the unilateralintroduction of the site finder service by verisign also raised fundamental institutional issues about the relationship between icann andverisign and, by extension, the other gtld registries.technical issuesthe site finder service introduced changes to the operation of the.com and .net toplevel domains, through the use of the wildcard address(a) record. wildcards, which can be set up by an authoritative nameserver to stand in for name and class records (see box 3.2), are used tosynthesize records if no exact match exists in the zone. in the site findercase, the wild card entries in .com and .net synthesized a response thatsent requests for nonexistent secondlevel domains to the verisign service web site. the use of wildcards is specified within internet engineering task force (ietf) standards for the dns protocol,67 but their use generally has been localized or confined to an organization.68 in contrast, the64comments expressing concern about the site finder service are available at <http://www.icann.org/general/wildcardhistory.htm>.65icann, òadvisory concerning demand to remove verisignõs wildcard,ó october 3,2003, available at <http://www.icann.org/announcements/advisory03oct03.htm>. for adescription of icannõs ability to force verisign to suspend the site finder service, seejonathan weinberg, òsite finder and internet governance,ó december 28, 2003, available at<http://www.law.wayne.edu/weinberg/sitefinder.new.pdf>.66for a discussion of the broader social, political, and privacy issues raised, see <http://www.circleid.com/article/312010c/>. see also <http://cyber.law.harvard.edu/tlds/sitefinder/concerns.html>.67see paul mockapetris, òdomain namesñconcepts and facilities,ó rfc 1034, november1987, available at <http://www.rfceditor.org> and paul mockapetris, òdomain names ñimplementation and specification,ó rfc 1035, november 1987, available at <http://www.rfceditor.org>.68an example of a common use of wildcards is for mail resource records, or mx records, asthey allow email server operators to synthesize all records locally that enable immediatenotification that a domain name is valid before a message is sent.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects177introduction of wildcards in the a records of the .com and .net tlds hadan impact across a major portion of the dns. they produced affirmativeresponses, instead of the expected òno such domainó response, to everyattempt by the numerous applications that use the dns to find a nonexistent domain name within the two tlds, as noted in the next section.security and stability issuestechnical community views.according to an assessment made by theinternet architecture board (iab) shortly after the introduction of the sitefinder service, verisignõs unilateral change had direct effects on the manyapplications that use the internet.69 for example, sitefinder altered thenormal operation of email servers, which would be to return to the senderany email addressed to nonexistent domains. the result of the consistent affirmative responses for the verisignoperated toplevel domainswas to send email addressed to the nonexistent domains to the registryoperated server instead. this change affected users, as the immediate notification of a nonexistent domain could be delayed by several days ormore. it also affected network administrators that incurred costs toreconfigure servers, if they chose to bypass verisignõs server.70according to the iab, these changes also affected the utility of spamfilters that rely on identification of invalid domain names to block messages, and limited the operation of sequential lookups that require noticeof unsuccessful dns queries to seek information from other sources.other direct effects of these changes, according to the iab, included theinconvenience to users who were rerouted to an englishlanguage web site,rather than receiving an error message in their native language; the potential loss of privacy as a result of email and other internet traffic being rerouted to an unintended destination; and the danger to internet securityand reliability caused by routing all the erroneous traffic to one location,creating a single point of failure and a target for deliberate attacks.71an indirect effect of this change was the development of various technical countermeasures to circumvent the verisign site finder service. theinternet systems consortium (isc) issued a patch for bind,72 the soft69see internet architecture board (iab), òcommentary: architectural concerns on the useof dns wildcards,ó september 19, 2003, available at <http://www.iab.org/documents/docs/20030920dnswildcards.html>.70iab, òcommentary,ó september 19, 2003.71as noted in iab, òcommentary,ó september 19, 2003. for an additional list of technicalproblems, see <http://www.packetpushers.net/tldwildcards/>.72for more information on bind, see section 3.2.3.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.178signposts in cyberspaceware used on many domain name servers, that disabled the redirect tothe verisign web site and responded with an error message instead.73while patches released by isc and others74 provided an immediate solution to the redirect, the ad hoc decision by network administrators orinternet service providers (isps) to use a patch or to create anotherworkaround introduced inconsistent changes throughout the internet,75that had the secondorder consequence of limiting options for other services that operated within the boundaries of either the protocols or reasonable user expectations.verisignõs view. verisign responded to the iab criticism with a pointbypoint rebuttal,76 which asserted that (1) site finder did not violate thedns standards; (2) verisign was working to provide otherlanguage responses in the near future; (3) site finder, by adding a wildcard rrset tothe .com and .net zones and updating its server, can relieve the majorityof email problems; (4) applications that rely on error messages canachieve the same effect by querying the dns for the presence of a wildcarda record in the zone; (5) the detection of erroneous domains is not a widelyimplemented mechanism for spam identification and discovery and, inany event, is easily circumvented; (6) verisign has published mitigationstrategies for dealing with other protocols; (7) verisignõs experience insecurely and stably operating redundant .com and .net servers enables itto protect the site finder service; (8) verisign does not collect or retainpersonal information through site finder; and (9) verisign is willing towork with icann and the technical community to deal with internationalized domain names and domains not in the .com or .net domains. italso said that it shared the iabõs concerns with workarounds to bypasssite finder and has written a guide for application developers to helpthem write software consistent with the dns standards for wildcards.73for a description of the patch, bind 9.2.3rc2, see <http://www.isc.org/index.pl?/sw/bind/delegationonly.php>.74such as imperial violet; see òverisign countermeasuresó at <http://www.imperialviolet.org/dnsfix.html>.75iab, òcommentary,ó september 19, 2003. see also benjamin edelman, òthe aftermath:how isps responded to site finder around the world,ó circleid, october 6, 2003, availableat <http://www.circleid.com/article/303010c/>.76see verisign, òverisignõs response to iab on site finder service,ó october 3, 2003, available at <http://www.verisign.com/productsservices/naminganddirectoryservices/namingservices/sitefinderservices/page002695.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects179process issuestechnical community views. while the technical communities recognizethat the use of the wildcard record does not violate dns protocol specifications,77 its implementation in the two largest tlds did not follow principles that have guided the process for making internet architecture decisions from the initial development of the internet to the present, whichhave sought to minimize the impact of changes on the network.78 thetraditional process of working out proposed changes with the technicalcommunities aims to maintain flexibility for all applications that use thedns and balance the impact of changes on network operators, users, andthe overall stability of the dns and the internet in general. furthermore,as a matter of principle, the technical communities insist that innovationshould take place not within the dns, a core infrastructure of the internet,but rather on top of the dns, at the edgesñthe applications that use theinternet and the dns.examples of innovation at the edges consist of services similar to sitefinder, but which reroute misspelled or nonexistent domain names atthe web browser, such as internet explorer, or the isp, such as americaonline. because the service is limited to the web browser or isp, otherprotocols, such as email and ftp, are not affected by the redirect and willstill receive a òno such domainó response.changes at the core tend to make service offerings at the edges moredifficult, as the redirect offered at the dns level overrides the changesmade at the web browser or isp level, requiring these services to workaround the highlevel implementation. while services offered at the edgescause the least harm to the network overall, they are also the most beneficial to users, as they tend to offer more options to elect the service the userwants to receive, to disable it, or to switch to another web browser or isp.shortly after site finder was introduced, icann requested that itssecurity and stability advisory committee (ssac) undertake a study ofsite finderõs implications for the security and stability of the internet. after public hearings and comments, the ssac issued its report in july2004.79 its primary focus was not on site finder, per se, but rather on the77iab, òcommentary,ó september 19, 2003.78the two principles include the robustness principle, òbe conservative in what you do,be liberal in what you accept from othersó (jon postel, òtransmission control protocol,órfc 793, september 1, 1981), and the principle of least astonishment, òa program shouldalways respond in the way that is least likely to astonish the useró (source unknown; iab,òcommentary,ó september 19, 2003).79security and stability advisory committee (ssac), òredirection in the com and netdomains,ó report submitted to the icann board, july 9, 2004, available at <http://www.icann.org/committees/security/ssacreport09jul04.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.180signposts in cyberspacefacts that òcore registry operations were modified, thereby changing existing services, and the change was introduced abruptly without broadnotice, testing, refinement or community agreement.ó80 it found that sitefinder (1) òdisturbed a set of existing services that had been functioningsatisfactorilyó; (2) òviolated fundamental internet architectural principlesby blurring the welldefined boundary between architectural layersó andmoving more control toward the center and away from the periphery;and (3) proposed mechanisms òto ameliorate the undesirable effects oftheir diversionó that òput verisign in the implementation path of everyexisting and future protocol that uses dns.óin addition, the ssac found that òthe abruptness of the change violated accepted codes of conduct that called for public review, commentand testing of changes to core systems.ó that process is intended òto ensure that changes are introduced with minimal disruption to existing services and hence with minimal disruption to the security and stability ofthe internet.ó moreover, it òprecluded the possibility that administrators,it departments, isps and other intermediaries on whom end users relymight be adequately prepared to deal with the consequences.ó the ssacalso found that òin response, workarounds and patches were introducedquickly, cumulatively reducing the overall coherence of the system andagain violating the established practices of public evaluation, testing, discussion and review before core services are implemented and deployed.these workarounds further blurred the functional layers intrinsic to theinternetõs robust architecture and in some instances created additionalñand unintendedñharmful effects.óthe ssac made recommendations to eliminate òsynthesized responsesó from tlds that serve the public and that satisfy several technicalconditions and to eliminate shortcomings from the specification of dnswildcards and their use. most significantly, it recommended that òchangesin registry services should take place only after a substantial period of notice, comment and consensus involving both the technical community andthe larger user community.ó it asserted that the process must ò(i) considerissues of security and stability, (ii) afford ample time for testing and refinement and (iii) allow for adequate notice and coordination with affected andpotentially affected systems managers and end users.óverisignõs view.as its use of a wildcard a record in the tlds did notdeviate from the ietf standards that describe the dns protocol specifica80all quoted material in this paragraph and the next two is from the executive summaryof the ssac report òredirection in the com and net domains,ó 2004.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects181tions,81 verisign maintains that this implementation is a legitimate use ofthe wildcard and a valid service innovation that adds value for usersearches that are not well served by the òpage not foundó error message.82additionally, verisign selected its own technical advisory group to testthe site finder service before it was deployed, arguing that a comparableprocess within the broader technical community would have taken muchlonger to complete and was incompatible with the pace and time horizonof business decisions.83in august 2004, verisign published a response to the ssacõs report.84in verisignõs view, ssacõs òpurported ôfindingsõ and ôrecommendationsõare inappropriate, unsubstantiated, and themselves contrary tolongstanding written standards and specifications for the operation of thedns and the internet.ó85 according to verisign, since the ssac did notfind that òsite finder, or wildcards generally, pose a threat to the securityand stability of the internetõs naming and address allocation system,ó itsòfindingsó and òrecommendationsó exceeded the scope of ssacõs charter. verisign argued that the ssac started its analysis with a predetermined conclusion and its report was written by persons who are opponents of site finder or competitors of verisign. of greater generalsignificance was its assertion that the reportõs findings and recommendations òwould in effect restrain technical innovation and commercial practices on the internet on the basis of vague and unwritten ôcodes of conductõ and selfstyled ôestablished practicesõ that, contrary to the report,do not represent consistent internet practices and conduct.óverisign asserted that the òwelldefined boundary between architectural layersó claimed by the ssac is violated by òmultiple technologieswidely used on the internet, such as network translators and firewalls.ófurthermore, verisign stated that site finder did not change the positioning of the dns in the layering of network services, while the ssacen81verisign, òarchitectural concerns on the use of dns wildcardsó (response to iabòcommentaryó of september 19, 2003), september 23, 2003, available at <http://www.verisign.com/nds/naming/sitefinder/iabresponse.html>.82verisignõs site finder implementation; see <http://www.verisign.com/resources/gd/sitefinder/implementation.pdf>.83see charles cooper, òthe cultural divide and the internetõs future,ó cnet news.com,october 16, 2003, available at <http://news.com.com/2008734735092590.html>.84verisign, òverisign, inc.õs response to report from the icann security and stabilitycommittee re ôredirection in the com and net domainsõ,ó august 5, 2004, available at<http://www.verisign.com/static/012393.pdf>.85all quoted material in this paragraph and the next two is from verisign, òverisign, inc.õsresponse,ó august 5, 2004.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.182signposts in cyberspacedorsed processing of idns at the dns level would, by its own analysis,òbluró the boundaries between architectural layers.in sum, verisign charged ssac with using òa fa“ade of technical orthodoxy to mask rigid adherence to the status quo of the dns, which isantithetical to the very nature of the internet and inconsistent with therfcs, which themselves recognize the importance of innovation to theinternet.ó verisign went on to argue that òcontrary to icannõs clear directive, ssac has failed to quantify or independently verify any of thepurported problems described in the report, raising serious doubts thatthey were real, serious, or widespread.óinstitutional issueswhile the site finder service raised contentious issues of adherence totechnical standards and processes, it also brought to the fore a critical andequally contentious issue of authority over and responsibility for the service offerings of tld registries, especially gtld registries that havesigned agreements with icann. (in section 3.4.3 it is noted that, as ofjune 2005, icann had such agreements with 10 of the 15 establishedgtlds.) the issue is of particular significance to the relationship betweenicann and verisign, the registry for the two largest tld domains, whichcontain over 38 million secondlevel registrations between them.specifically, the issue is this: to what extent and by what processescan icann control the offering of new services or the modification ofexisting services by tld registries with which it has contracts? (it has noclear authority over most other tld registries, although it couldñintheoryñuse the threat of exclusion from the root to control the behaviorof other registries. in practice, that threat is unlikely to be used or to beeffective under current circumstances.)in his letter to verisign86 demanding the suspension of site finderservices on .com and .net, the president of icann asserted that òourreview of the .com and .net registry agreements between icann andverisign leads us to the conclusion that verisignõs unilateral and unannounced changes to the .com and .net top level domains are not consistent with material provisions of both agreements.ó he went on to list sixspecific provisions of the agreements that verisign was, in icannõs view,violating.86see òletter from paul twomey to russell lewis 3 october 2003,ó available at <http://www.icann.org/correspondence/twomeytolewis03oct03.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects183more generally, there is the question of whether the introduction ofsite finder abused the public trust that accompanies the monopoly position granted to verisign as the sole operator of the .com and .net tlds. 87did it take advantage of that monopoly position to extract profits fromunregistered domain names in unfair competition with isps, browsers,and search engines? for example, the secondlevel domain names directedto the traffic aggregation sites described in section 4.4.1 must all be specifically registered and a fee must be paid to the registrar, which in turnpays verisign for each name. in contrast, site finder effectively redirectedevery unregistered secondlevel domain in .com and .net to verisignõsservice, generating trafficbased advertising revenue for verisign. becauseof verisignõs position as the sole registry for those two tlds, it did nothave to specifically register those names in order to control the responseto a request for them.from verisignõs perspective, icann overstepped its authority as atechnicalcoordination organization and prevented it from continuing tooffer services that benefited internet users.88 in pursuit of that argument,in february 2004 it filed a federal lawsuit in the u.s. district court, central district of california, charging that icann òoverstepped its contractual authority and improperly attempted to regulate verisignõs businessin violation of its charter and its agreements with verisign.ó89 verisignasserted that icann òstifled the introduction of new services that benefitinternet users and promote the growth of the internet.ó it asked the courtto assess damages against icann and for icann to treat verisign in aòfair, reasonable, and equitableó fashion in the future.90verisignõs antitrust claims against icann were dismissed in may2004, but the court initially allowed verisign to file an amended com87for more information, see òthe cooperative agreement between the departmentof commerce and verisign,ó available at <http://www.ntia.doc.gov/ntiahome/domainname/nsi.htm>, which contains the text of the agreement and the amendments to itfrom 1998 to the present.88verisign reported receiving 5 million unique visitors per day while the service was operating; see john leyden, òusers ôvote with their mousesõ for site finder,ó the register, october 9, 2003, available at <http://www.theregister.co.uk/content/6/32973.html>.89verisign, òverisign files lawsuit against site finder,ó press release, february 26, 2004,available at <http://www.verisign.com/verisigninc/newsandevents/newsarchive/usnews2004/page005186.html>.90declan mccullagh, òverisign sues icann to restore site finder,ó cnet. news.com,february 24, 2004, available at <http://news.com.com/verisign+sues+icann+to+restore+site+finder/2100103835165982.html?tag=mainstry>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.184signposts in cyberspaceplaint to try to strengthen its legal arguments. however, on august 27,2004, the court dismissed the claims with prejudice; specifically, the courtheld that verisignõs claims about competitors controlling icannõs boardcould not be supported.verisignõs remaining causes of action based upon contractual mattersresulting from the registry agreements had to be refiled in california statecourts. in august 2004 it made such a filing in the california superiorcourt in los angeles county. verisign claims that: òwere verisign to defer offering such services to the public during the effective period of the2001 .com registry agreement, or to modify such services due toicannõs conduct and threats, verisign will suffer irreparable losses ofrevenue from third parties, profits, market share, competitive position,reputation and good will. furthermore, millions of internet users will bedeprived of the improved functionality and quality of verisignõs services.ó91 as of october 2004, the suit remained open.4.4.3conclusionsthe internet and the domain name system have operated successfully over two decades, despite manyfold increases in connectivity andconnected devices and a great expansion of users and uses. as describedin chapter 3, their successful adaptation to rapid change has been basedon a shared commitment among the operators of the internet and dns toadhere voluntarily to a set of open standards strictly vetted by the technical community and to a collaborative process of cautious and controlledchange. this commitment has held even though the operators are vastlydifferent in nationality and in typeñacademic, commercial, governmental, notforprofitñand are not subject to the authority of any overall controlling body. the commitment is threatened, however, by two externalforces. one is the desire by some governments and international agenciesto introduce stronger international regulation of internet operations. thisforce is discussed in chapter 5. the other is the commercial imperativedescribed earlier.the commercial organizations that operate key elements of the dnsare appropriately driven by the goal of increasing revenue and profit. asobserved earlier, in the internet that goal is best served by attracting andcapturing the attention of user traffic, which can be translated into advertising dollars. consequently, there is a natural pressure on commercialoperators to find ways to do so in competition with other operators. thisis what happened in the site finder case. verisign saw an opportunity to91paul festa, òverisign sues icann in state court,ó cnet news.com, august 31, 2004,available at <http://news.com.com/2102103035331779.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: technology prospects185capture substantial traffic from unregistered domain names and, drivenby its commercial imperative, took it. in doing so, it made an unanticipated use of a dns standard for wildcards. moreover, it launched its newservice as a surprise, without vetting it with the technical community orinforming other operators. verisign has defended its actions as beingwithin its rights to provide innovative new services that offer benefits tousers. however, the technical and operator communities have complainedvigorously about verisignõs breaking of the shared commitment to standards and process.although site finder may adhere strictly to published standards andits introduction might even, in some views, be strictly consonant withverisignõs rights to innovate, verisignõs action poses two highorder challenges to the successful operation of the dns and the internet.first, verisign is not like any other tld registry. it contains roughlyhalf of all secondlevel domain name registrations and almost all the commercial and network infrastructure domains. it was granted the right tooperate the registry as a commercial monopoly by the department ofcommerce and icann. therefore, it is effectively an international publicutility whose actions have profound and widespread effects across theentire internet. when it is seen in that light, it becomes clear that it wouldbe reasonable for it to be required to, at the very least, obtain formal approval from its contractual regulator before introducing any new servicewith wideranging consequences.second, and more significant, verisignõs action could set in motion acommercial rush among other operators of the dns. suppose verisignõsactions were copied by other commercial registries. the consequence forthe stability and predictability of operations of the dns could be profound. by ignoring the shared commitment among operators to acceptthe authority of the technical community on standards and new servicesand to adhere to a collaborative and cautious process of change, verisigntore a hole in the invisible web of implicit understandings that has beencritical to the success of the dns and the internet. in remains to be seenwhether the outcome of its court cases will determine whether that webcan be mended.recommendation: icann should strengthen its contracts with tldoperators (especially the largest ones) to ensure that it has the authority toreview proposed changes in their services that could have a detrimentaleffect on the dns or on other services that depend on the dns. it shouldestablish an open, transparent, and speedy process of review for suchchanges that solicits contributions from the technical community, otherdns operators, other affected internet operations, and end users.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.186signposts in cyberspacerecommendation: tlds and other dns operators that do not haveagreements with icann should voluntarily agree to adhere to publishedtechnical standards and to consult the technical community and conductpublic review processes before introducing new services that could havea detrimental effect on the dns or on other services that depend on thedns.the issues raised by verisignõs introduction of site finder are bothtechnical and institutional. as such they serve as an appropriate bridge tothe next chapter, which addresses the issues facing the institutional framework of the domain name system.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.1875the domain name system:institutional issuesthe institutional framework of the domain name system (dns), asdescribed in chapter 3, comprises a diverse group of organizationscarrying out their various responsibilities with a high degree ofautonomy. no single institutionñnot even the internet corporation forassigned names and numbers (icann) or the u.s. department of commerceñhas effective authority over all of the participating organizations.nevertheless, this group of organizations has successfully managed thedns through two decades of rapid growth of the internet, and of themost significant applications on the internet such as the web and email,which rely on it. however, as the internet and its applications have grownin importance, so have the attention and the controversy that the dnsand its institutional framework have attracted. that critical scrutiny hasraised a number of issues concerning the structure, governance, management, and operations of the organizations that manage the dns.most of those issues are being actively addressed, but the organizations involved face the reality of multiple, often conflicting interestsñboth public and privateñbecoming more actively engaged in their activities. that makes achieving consensus decisionsñin the tradition of theearly internet communityñincreasingly difficult and leaves a residue ofdissatisfaction with any decision that is taken. since attention to the institutional framework of the dns can be expected to continue to increasewith the internetõs growing significance as a critical global communications infrastructure, so too can the critical institutional issues be expectedto receive increasing scrutiny and to give rise to increasing controversy.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.188signposts in cyberspacethis chapter is a guide to the principal institutional issues that havealready or can soon be expected to come to the fore. for each institutionalissue, the principal alternatives that have been publicly identified are summarized, and the alternatives are compared. where the committee is inagreement, its conclusions and recommendations are presented. in allcases, the intent is to provide a clear description of the alternatives andthe arguments for and against them as background for current and futurepolicy deliberations.some of the issues, such as icannõs management structure, may appear to be resolved for the time being. in the committeeõs view, understanding the conflicting proposals that preceded the present resolutionilluminates the pressures that remain in the background and that may, inthe future, force the issue once again onto the policy agenda.the following issues are addressed in this chapter:1.governance of the dns.how should the dns be governed? whatshould be the role of the u.s. government, international organizations, and icann?2.management of the dns.what changes in icann, if any, are appropriate?3.oversight and operation of root name servers.is there a need forgreater oversight of the root name server operators? if so, howmight it best be conducted?4.regulation of generic toplevel domains (gtlds): number andprocess.can and should new gtlds be added? if so, how manynew gtlds should be added, and how fast? what types shouldthey be, and how should they and their operators be selected?5.oversight of country code toplevel domains (cctlds).should anything be done to increase icannõs oversight of and authority overthe cctlds? if so, what form should its increased authority take,and how can it be implemented?6.resolution of conflicts over domain names.does the uniform domainname dispute resolution process (udrp) need to be improved? ifso, how should it be improved?7.provision and protection of whois data.what is the appropriate balance among the various interests in whois data?in contrast to most of the other chapters in this report, this one dealswith issues for which opinion and values play a significant role. consequently, many of the citations and references are to advocacy documents,not to peerreviewed scientific or technical papers. these references serveas pointers to places where the proposals being summarized were presented. when there were multiple similar proposals, one or two have beensignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues189selected as references, either because they appeared to be the most representative or because they were the most readily accessible. thecommitteeõs use of these references should in no way be considered anendorsement of the point of view expressed.5.1governance of the domain name systemissues: how should the dns be governed? what should be the role of theu.s. government, international organizations, and icann?as explained in chapter 3, the u.s. government currently possessesthe final authority to make key decisions affecting the dns. specifically, itmust approve all changes in the root zone file and, thereby, controls thedesignation of toplevel domains (tlds) and the assignment of responsibility for their operation. in this way, it functions as the steward of thedns, exercising its authority and making decisions for the larger internetcommunity.through a memorandum of understanding (mou) signed in november 1998, the u.s. government delegated daytoday operational authority to icann, which makes recommendations to the u.s. departmentof commerce (doc) for its decisions affecting the dns. in this capacity,icann recommends the addition of new tlds and redelegations ofexisting tlds. (as noted in chapter 3, icann has additional responsibilities for internet protocol (ip) addresses and protocols.) icann mightbe thought of as the registry for the root, sponsored by the u.s. government. icann nominally has the same responsibilities as other registries: it registers entries into the zone file and sees to the distribution ofthat zone file to the name server operators. however, as noted in chapter 3, unlike the tld registries, icann does not directly contract foroperation of the root name servers, nor does it have contracts with allthe tlds. in fact, in june 2005 it had agreements with only 10 of the 15gtlds and 12 of the 243 cctlds. however, because it recommends anynew and revised entries into the root zone, because its agreements withthe largest gtlds set the rules for their operations and those of theiraccredited registrars, and because those rules strongly influence the operations of the other tlds, icann is generally perceived to be the manager of the dns.against this background, the issue of the proper form of dns governance can be divided into two separate but closely interrelated issues: (1)where should the stewardshipñthe final authority for key decisionsñofthe dns reside? and (2) how should management authorityñthe registry function for the rootñfor the dns be exercised? although these rolesare distinct at present, one possible answer is that they be combined.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.190signposts in cyberspace5.1.1relationship to governance of the internetbefore addressing the questions of stewardship and management authority for the dns, it is important to emphasize the distinction betweengovernance of the dns and governance of the internet. clarifying this distinction is necessary because the docõs and icannõs visible responsibilityfor a key part of the internetõs infrastructure and the fact that decisions affecting the dns have economic, social, and political consequences have tendedto focus discussions of internet governance on the doc/icann and thedns. however, there are many aspects of the internet that are or might besubject to governance but that lie outside the dns and the areas of responsibility of its managers.1 these include, for example, controlling spam; dealingwith use of the internet for illegal purposes; resolving the òdigital divideóbetween developed and developing countries; protecting intellectual property other than domain names; protecting privacy and freedom of expression; and facilitating and regulating ecommerce.2 furthermore, there are increasingly important aspects of the internet that are currently subject to littlepublic governance, such as search engines and directories. thus, dns governance is a part of, but does not include many aspects of, internet governance.since at the time of this writing in december 2004 there have been no practical proposals for broad governance of the internet, this chapter focuses solelyon governance of the dns. (the institutional issues associated with internetnavigation are discussed separately in chapter 8.)conclusion: governance of the dns is part, but not all, of internetgovernance. icann and the dns are not the proper vehicles to addressmost internet policy issues.5.1.2where should stewardship of the dns reside?the u.s. government acquired responsibility for and authority overthe dns root by virtue of its historical initiative and financial investment1the issue of internet governance, in general, has become the subject of intense scrutiny inpreparation for the second phase of the world summit on the information society (wsis) innovember 2005. the itu held a workshop on internet governance in february 2004 at whichmany views on the subject were presented. for an extensive discussion of internet governance and the place of dns governance within it, see, for example, don mclean, òherdingschrıdingerõs cats: some conceptual tools for thinking about internet governance,ó ituworkshop on internet governance, february, 2004, available at <http://www.itu.int/osg/spu/forum/intgov04/contributions.html>. in preparation for the wsis meeting in 2005, theworking group on internet governance (wgig) was appointed in november 2004.2the itu invited selected experts to present papers on internet governance at a workshop.these papers, which present a variety of personal views on this broad range of issues, areavailable at <http://www.itu.int/osg/spu/forum/intgov04/contributions.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues191in supporting creation of the internet and the dns, as described in chapter 2. however, as the internet has become international in extent, support, and operation, the formal legitimacy of the u.s. governmentõs continued authority over the root has come under challenge, such as in thecontext of the world summit on the information society (wsis).3critics, including representatives of the governments of brazil, southafrica, russia, and china,4 have argued that the dns is so central to thereliable and effective operation of the now fully global internet that itscontrol by a single nation is no longer justifiable. some would prefer thatthe ultimate stewardship reside in an intergovernmental body, such as au.n.affiliated agencyñfor example, the international telecommunication unionñor a new organization specifically negotiated by treaty, suchas a òworld internet organizationó; others prefer an international bodythat includes governments, the private sector, and civil society. many ofthe critics are national governments that have felt left out of the icannprocess, in which their representation is through the governmental advisory committee (gac),5 which until 2003 had advisory status only.6,7indeed, brazil has asserted that òit is a myth that governments have a sayin icannõs activities via the gac . . . the influence of governments iscomparable to the influence of nonshareholders in a private company.ó83for information about the world summit on the information society, see <http://www.itu.int/wsis/>.4see òglobal fight looms for net management,ó reuters, september 16, 2003, available at<http://news.com.com/2102102835077101.html>.5as of march 2005, the governmental advisory committee comprised the representativesof 94 nations, as well as several international and regional organizations with observer statusñthe african telecommunications union (atu), agence intergouvernmentale de lafrancophonie, asia pacific telecommunity (apt), commonwealth telecommunicationsorganization, economic commission for africa, international telecommunication union(itu), organization for economic cooperation and development (oecd), pacific islandsforum, and the world intellectual property organization (wipo).6for a history and analysis of the role of the gac in icann, see wolfgang kleinwachter,òfrom selfgovernance to publicprivate partnership: the changing role of governmentsin the management of the internetõs core resources,ó loyola of los angeles law review36(spring): 11031126, 2003.7in september 2004, norway argued, in a submission to a preparatory meeting for thewsis, that the gac needs stronger funding and òcannot continue to have a mere counselingrole to the icann.ó norway called for a stronger and betterfunded secretariat that wouldenable the gac to focus on more strategic and political issues. see world summit on theinformation society, working group on internet governance, written contribution from norway,which is available at <http://www.itu.int/wsis/preparatory2/wgig/norway.pdf>.8as reported by icannwatch: òwgig will reassessñor reassert?ñgovernmentsõ rolein internet,ó which is available at <http://www.icannwatch.com/article.pl?sid=04/09/21/1812238&mode=thread>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.192signposts in cyberspacehowever reasonable the move toward international stewardshipmight appear in theory, in practice any change can be made only with theacquiescence and active participation of the u.s. government. not onlywould the u.s. government have to be an important party to any transfer,but it also holds an effective veto because all of the root name server operators would have to agree to accept the root zone file from a new source,yet 3 of the 12 operators are u.s. government agencies and 6 others areu.s.based organizations that may well be reluctant to take actions contrary to the wishes of the u.s. government.5.1.3alternativesin this light, an examination of three alternatives to u.s. governmentstewardship is instructive: an existing intergovernmental organization, anew international organization formed by treaty, or an international (butnongovernmental) organization, such as icann or a successor. (anotherpossibility would be to divide dns governance responsibilities amongseveral organizations, each of which would have its own steward. although that may be an outcome of dns governance decisions, this sectionaddresses the stewardship of the manager or managers of the dns, whatever form it or they should take.)alternative a: existing intergovernmental organizationñinternational telecommunication uniondescriptionof all the existing intergovernmental organizations, the one thatclaims the most relevant experience and that has expressed the greatestinterest in dns governance is the genevabased international telecommunication union (itu), a treaty organization affiliated with the unitednations.9 its membership comprises about 190 nations as well as morethan 650 firms and international organizations in the telecommunicationsand information technology industries. its standardization sector (itut)has long experience with the adoption and implementation of international telecommunications standards, primarily for telephony but also forsome computer networking technologies that are now considered histori9other u.n. agencies have expressed interest in the broader question of internet governance, among them the united nations educational, scientific, and cultural organization,which prepared a position statement for the u.n. i.c.t. task force global forum on internetgovernance held in march 2004 in new york. see <http://www.itu.int/wsis/preparatory2/wgig/unesco.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues193cal in much of the world.10 a separate organization within the itu, theradiocommunication sector (itur), has responsibility for radio frequencies and some regulatory authority under the applicable treaties. its processes and procedures are mature and, according to the itu, òthere aresufficient checks and balances in place to ensure that vested interests cannot misuse itu processes for their particular interests.ó11 all membergovernments and any interested private company (including registries,registrars, internet service providers (isps), and equipment suppliers) canparticipate in itutõs work, but unless there is general agreement, onlygovernments can vote and only governments can be represented in ituõscouncil, which has overall policy and strategy responsibility between ituplenipotentiary conferences.because the itu is an intergovernmental organization, it has sovereign immunity, which obviates the need for liability insurance or worryabout liability affecting its decisions. since concerns about the legal liability it might be assuming appear to have affected icannõs willingness to,for example, enter into agreements with some cctlds that wanted to holdit to predefined performance standards, and could affect its ability to takeon other roles, this advantage of an intergovernmental organization hassome weight. conversely, however, it may make the itu a less attractivealternative to those cctlds and others that want to be able to hold a governing organization liable if it fails to perform its functions satisfactorily.the itu members voted at its 2002 plenipotentiary conference inmorocco that it should play an active role in òdiscussions and initiativesórelated to the dns and ip address system with the goal of becoming theforum in which public policy issues of internet naming and numberingare resolved. in its resolution from the meeting, the itu identified òstability, security, freedom of use, protection of individual rights, sovereignty,competition rules, and equal access for alló as important public policyissues.12 since that meeting, the itu has campaigned for a more activerole in governance of the internet generally and the dns specifically. its10òthe itut performs worldwide administration, and acts as the forum for policy management, of a number of naming and address allocation systems that are essential for thegood functioning of critical infrastructures, including the physicallayer infrastructure of theinternet itself . . . [and] such wellknown examples as the e.164 numbering resource and thee.212 mobile numbering resource.ó see houlin zhao, itut and icann reform, telecommunication standards bureau, itu, april 17, 2002, pp. 34, available at <http://www.itu.int/itut/tsbdirector/ituticann/icannreform.html>.11zhao, itut and icann reform, 2002.12itu resolution 102, management of internet domain names and addresses, marrakesh,morocco, 2002, available at <http://www.itu.int/osg/spu/resolutions/2002/res102.html>.also see kevin delaney, òglobal organization seeks voice in internet addressing system,ówall street journal, october 21, 2002, p. b4.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.194signposts in cyberspacesponsorship of the workshop on internet governance in february 2004and its consultation on forming the working group on internet governance in september 2004 are indicative of its continuing active interest.13evaluationthe principal arguments in favor of moving stewardship of the dnsto the itu are the broad international participation in the itu, both bygovernments and industry; its established processes for policy making; itssecure funding and sovereign immunity; and its long experience withmanagement of international telecommunications resources. its international treaty status would, perhaps, also give it greater influence over thecctlds and the root name server operators. at the same time, itut cannot make decisions affecting competing parties or take actions withoutagreement by its membership. if there is a disagreement between governments, aside from attempting to mediate, itut can do nothing until aplenipotentiary conference acts to resolve the matter, since only it has theauthority to make recommendations to governments (which, however,can still ignore them). furthermore, the ituõs charter does not allow intervention in disputes within countries, such as might occur over the delegation or redelegation of a cctld registry.there are, moreover, objections to the ituõs assumption of the dnsstewardship role from the internet technical and user communities and,significantly, from the u.s. government.the technical and user communities have a distrust of the itu for itslong record of opposing the transmission control protocol/internet protocol (tcp/ip) and for its unwillingness to make its standards publiclyavailable for use on the internet. additionally, they fear that the ituõsbureaucracy and its structure and processes, which require that governments sign off on decisions, will lead to extremely slow decision makingunable to keep pace with the requirements of managing the dns. manyalso fear that the large telecommunications companies, which have a longstanding interest in and presence at the itu, will dominate the processes.it has generally been difficult for individuals and public interest groups toparticipate in the ituõs processes, although the itu has expressed a commitment to change. although it engaged individuals and groups in themeeting on internet governance that it sponsored in association with thewsis,14 it excluded nongovernmental organizations from the decisionmaking sessions and it has not moved to change the ituõs charter or itutõs internal rules to permit their active participation.13see materials at <http://www.itu.int/osg/spu/intgov/index.phtml/>.14see a list of participants at <http://www.itu.int/osg/spu/forum/intgov04/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues195the user communities are also concerned that the itu would becomea vehicle for governments to exercise control over the registration of domain names and would use that control to enforce other policies such asthe local taxation of internet commerce, intellectual property protection,and the restriction of free speech and rights to privacy.from what is known of current u.s. government attitudes, both in theexecutive and legislative branches, transfer of dns stewardship to an intergovernmental organization is not likely to be supported now or in thenear future, although such attitudes can change.conclusion: despite the interest of the itu and some of its nationalmembers in its assuming stewardship of the dns root, that does not appear to be a realistic alternative for the near future.alternative b: international treaty organizationdescription and evaluationthe negotiation of an international treaty to establish a special agencyof the united nations for internet governance is also not likely to be supported by the u.s. government. the example of other such negotiationshas shown that they take many years to complete, especially if governance or binding regulation are contemplated among its authority, ratherthan just coordination or standardization, and are unlikely to succeed inthe absence of strong and sustained efforts by many nations, which despite the currently expressed concerns does not seem likely. so this alternative does not appear to be realistic in the near term either.conclusion: although it is possible that the u.n.sponsored 2005world summit on the information society will lead to proposals for someform of internationally negotiated, quasigovernmental or multistakeholder organization with oversight or other influence over dns governance, specific proposals are not yet (in december 2004) on the table andcannot be evaluated for either their practicality or their feasibility.this leaves the third alternative, which follows.alternative c: private organization with international participationdescriptionthe only institution to which the u.s. government has expressed itswillingness to transfer its stewardship of the dns is icann, or a similarsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.196signposts in cyberspaceprivate, nonprofit successor. furthermore, this transfer of stewardshipcould occur only after icann (or a successor) had established its ability tooperate effectively, reliably, and with wide international and constituencysupport for a number of years. indeed, in its statement regarding the 1yearextension of its mou with icann in september 2002, the doc said:the department of commerce (department) continues to support thegoal of a private sector management of the internet domain name system(dns). innovation, expanded services, broader participation, and lowerprices will arise most easily in a marketdriven arena, not in an environment that operates under substantial regulation. to this end, the department has long maintained that a private sector organization is best ableto respond nimbly to dns issues in the rapidly evolving internet space.further, in order to garner international respect and function stably andsoundly in the longterm, such an organization must be globally andfunctionally representative, operate on the basis of open and transparentprocesses, and possess robust, professional management.15in september 2003, the doc granted icann a 3year extension of itsmou and indicated that if the agreementõs milestones are met, it is prepared to complete the transition of dns management to the private sectorat the end of that period.16 more recently, in conjunction with icannõsjuly 2004 meeting, the assistant secretary of commerce for communications and information issued a statement expressing pleasure thatòicann has timely met the mou milestones to date. clearly more workremains to be done for icann to achieve functional, sustainable independence. we look forward to continuing to work collaboratively withicann . . . as we complete the transition to independent, private sectormanagement of the internet domain name system.ó17evaluationalthough these statements indicate the u.s. governmentõs willingnessto give up the ultimate stewardship of the root, they also demonstrate its15department of commerce (doc), òdepartment of commerce statement regarding extension of memorandum of understanding with icann,ó september 19, 2002, available at<http://www.ntia.doc.gov/ntiahome/domainname/agreements/docstatement09192002.htm>.16see amendment 6 to icann/doc memorandum of understanding, september 16, 2003,available at <http://www.icann.org/general/amend6jpamou17sep03.htm>; and doc,òdepartment of commerce statement regarding extension of memorandum of understanding with icann,ó september 16, 2003, available at <http://www.ntia.gov/ntiahome/domainname/agreements/sepstatement09162003.htm>.17department of commerce, national telecommunications and information administration, òstatement by assistant secretary michael d. gallagher on icannõs july meeting inkuala lumpur,ó press release, july 19, 2004, doc, washington, d.c.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues197unwillingness to do so until it is assured that icann can manage thedns òin a manner that promotes stability and security, competition, coordination, and representation.ó18the stewardship role of the doc, while a matter of political concernto some nations, has not impeded icannõs governance role, with theimportant exception of sometimes substantial delays in approvals for routine changes in the root zone file, a situation that improved during 2004.19(see òapproving the root zone fileó in section 3.3.3). for example, thedoc has not overridden any icann recommendations for reasons ofu.s. national interest. the issues that have arisen about the governance ofthe root have, rather, concerned the way in which icann operates inpreparing its recommendations to the doc and not in the way that thedoc operates once it receives those recommendations. in that respect,the decision to establish an organization to take on the daytoday administration of the root has successfully reduced those pressures on the u.s.government while, at the same time, preserving its ultimate stewardship.the internet in general and the dns in particular have been developed and governed with the goal of technically enabling equitable accessto all locations on the internet to users anywhere on the globe. to bestserve the worldwide internet and the dns, the u.s. governmentõs influence needs to continue to be exercised carefully and, in particular, thisinfluence should not be used as an instrument of u.s. domestic or foreignpolicy in areas far removed from the internet.conclusion: governance of the dns is not an appropriate venue forthe playing out of national political interests.the technical legacy of the dnsõs development and initial implementation in the united states, such as the use of the ascii character set fordomain names and the concentration of root servers in the united states,has been a source of concern to some countries. such concerns have been18doc, òdepartment of commerce statement regarding extension of memorandum ofunderstanding with icann,ó september 16, 2003, p. 2.19there has been dissatisfaction among the cctld managers over the length of time required by icann and the doc to approve routine changes to the root zone file. in response, icann prepared a revised process designed to cut the time substantially and tokeep requesters informed of progress in the approval process. see internet assigned numbers authority (iana), òprocedures for handling requests by cctld managers to changenameservers,ó may 13, 2003, available at <http://www.iana.org/cctld/nameserverchangeprocedures13may03.htm>. these revised procedures and other changes have significantlyreduced the time taken to make changes in the root zone file as reported by the generalmanager of icann/iana at the kuala lumpur meeting of icann. his full report, including specific data, is available at <http://www.icann.org/presentations/bartonforumkl22jul04.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.198signposts in cyberspaceor are in the process of being addressed and they should, consequently,be substantially reduced or eliminated.although there may be continued objection by some nations to theright of the u.s. government to exercise its role,20 the united states hascommitted itself to a contractual 3year transition to icann under theconditions laid out in the amended mou. the real question is whethericann will be able to gain full legitimacy in the perception of other national governments and constituencies during this period.conclusion: the continued evolution of icann to attain legitimacyamong its critical constituencies and, consequently, to receive stewardship responsibility from the u.s. government appears to be the most feasible path to governance of the dns that is broadly accepted as international.the prospects of icannõs assuming stewardship of the dns are addressed in the discussion of icannõs role that follows.5.2management of the domain name systemissue: what changes, if any, are required in icannõs organization and management for it to achieve greater legitimacy?when the doc delegated responsibility for daytoday management ofthe root to icann in 1998, it was with the expectation that icann wouldsoon be perceived as a legitimate steward of the root as well. yet, althoughicann is not a part of the u.s. government and its board has had an international membership, its legitimacy was not immediately accepted.21 thecriticsõ concerns have been with (1) icannõs scope, (2) its organizationalstructure, (3) or its management processes, or with all three. the concernabout scope has been the extent to which icann has exceeded its specifictechnicaladministrative responsibilities to, for example, regulate tld registry operations. the concerns about structure have included a perceivedimbalance in the historical composition of icannõs board, failings in theprocesses by which the board was selected, and the inadequate representation of certain constituency groups. the concerns about management processes have included the lack of transparency, effectiveness, accountability,and recourse in icannõs electoral and decision processes.20in the recent u.n.sponsored forums on internet governance, a few nations have expressed a concern that their cctlds could be removed from the root by the u.s. governmentfor political reasons.21see, for example, jonathan weinberg, òicann and the problem of legitimacy,ó dukelaw journal 50:187257, 2000.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues1995.2.1scope of icannõs authoritythe first controversy affecting icannõs perceived legitimacy is itsappropriate scopeñthe extent of its responsibilities and authority. on theone hand, there are those who believe that icann should stick as closelyas possible to its technicaladministrative charter, eschewing responsibility for seemingly related matters that require it to make valueladen judgments that have political, commercial, or social effects.22 such mattersinclude the administrative approval of new gtlds, regulation of the business practices of gtld registries, and the delegation or redelegation ofcctld registries. on the other hand, icann currently engages in each ofthose activities as a result of decisions taken by its staff and board duringits early years. icann may have assumed those decision responsibilitiesbecause there was no other organization able to take them on, becausethey believed that there was no nonjudgmental way of resolving issuesthat icann confronted in connection with its technicaladministrativeresponsibilities, or because of the views and aspirations of the board andstaff.there should be a connection among the breadth of icannõs activities, the pressure on it to broaden membership on its board and engagemore constituencies in its decisions, and the acceptance of its legitimacyby various constituency groups. were icann able, for example, to narrow its scope primarily to the iana administrative functions, to use economic processes such as auctions or lotteries to allocate tlds, and to delegate to third parties the politically sensitive decisions such asredelegation of cctlds, then the pressures might ease, and acceptance oficannõs legitimacy as an essentially administrative body might becomeeasier. however, in actual implementation, even economic processes require some potentially sensitive decisions to be taken (see section 5.4.2);delegation entails the question of delegation to whom; and apparentlyroutine administrative processes, such as contracting with a gtld registry, entail judgments about what provisionsñif anyñare necessary toprotect the technical integrity of the dns, safeguard the interests of registrants, and meet the needs of intellectual property owners while preserving freedom of expression.conclusion: icann is more likely to achieve perceived legitimacywith a narrower scope rather than with a broader one.22see, for example, center for democracy and technology, icann and internet governance:getting back to basics, july 2004, available at <http://www.cdt.org/dns/icann/20040713cdt.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.200signposts in cyberspacehowever, it may not be possible or desirable to narrow icannõsscope to a purely technicaladministrative one because of the difficulty ofperforming such functions without making some politically, socially, oreconomically sensitive judgments. moreover, icann might very well attract controversy simply because it would be the most visible organization with some, however limited, authority over the dns.5.2.2composition of the icann boardthe second controversy concerns icannõs organizational structure.if it is to be widely perceived as legitimate, what should the compositionof the icann board be and how should its members be selected? thosequestions have been the subject of dispute since icann was formed. to alarge extent, the dispute stems from different views of icannõs properscope.those who believe that icann is principally a technicaladministrative body may favor selection of the board by members of the technicaladministrative community from among the members of that communityon the basis of expertise and experienceña traditional process in that community. in contrast, those who see icann as a major element of internetgovernance may favor a board comprising representatives of the broadinternet user community chosen, so as to achieve legitimacy, through anopen electoral processñinternet democracy. those who see icannõsscope as lying between these two views might favor a board representative of various constituencies selected through some combination of constituency elections and peer selections. finally, some governments feelthat because the internet (and the dns) has become a central element ofthe global communications infrastructure, it requires governmental oversight and regulation and, therefore, icannõs board should consist onlyor principally of governmental representatives.23much of the debate about icannõs board stems from the differencesamong these perspectives.in its first days, the 18member icann board was selected withoutparticipation by many internet constituencies, despite a docimposedrequirement in its bylaws that half the board be elected by a membership.the boardõs composition quickly became a source of controversy asicann addressed issues of broad significance and socialeconomicpolitical consequence, such as the addition of new gtlds and the23since those countries have principally been calling for the itu or another u.n. agency toassume doc/icann functions, they have not at the time of this writing made this suggestion. however, should they determine that those options are not feasible, they might turn tothis view.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues201development of the udrp. this put icann under pressure to implement the requirement for democratically chosen representation of thebroad internet community on the board. that pressure led it to experiment with a process of open internet voting for five (the docrequiredonehalf would have been nine) regionally representative members of theboard. that experiment, in turn, raised questions among some icannparticipants about the legitimacy of an open internet vote, which theycharged was vulnerable to capture by intensely interested, but not necessarily representative, groups and open to possible fraud. others felt that itbrought onto the board new members whose views were more representative of those of the broader internet community than were the views ofthe previously appointed members.24 recently, icann has moved awayfrom that model of a partially elected board to one that more closely follows the inbetween case described above. the 15member board in 2004comprises six representatives selected by the three major constituencygroups (the generic names supporting organizationñgnso; the country code names supporting organizationñccnso; and the address supporting organizationñaso); eight others chosen by a boardselectednominating committee, which includes representatives of icann stakeholders, from nominations made by constituency groups and the public;and the icann president, serving ex officio.the legitimacy of the icann board has also been undercut by theperception by some that the selection of its initial members was severelyflawed. critics charge that it was done topdown by icannõs managersand did not represent a diversity of views. in their judgment, board members lacked political experience and ties to constituencies and were, therefore, illprepared to supervise the managers who selected them. most ofthe members of that initial board remained in place longer than anticipated, during which time many of the key policies and processes oficann were put in place. these critics see the selection, composition,and actions of the initial board as having weakened icannõs claims tolegitimacy.since disagreements about icannõs board composition and selection appear to arise in some measure from different views of icannõsscope, they are likely to be difficult to resolve unless and until there isbroader agreement on that scope. in the more likely situation, where thereis not agreement among all parties on its scope, icann will probably24a recent academic study of icannõs experiment in òrunning a representative and opencorporate decisionmaking processó judged it to have òlargely failed.ó see john g. palfrey,jr., òthe end of the experiment: how icannõs foray into global internet democracyfailed,ó research publication no.20042, beckman center for internet & society, harvarduniversity, 2004, available at <http://cyber.law.harvard.edu/publications>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.202signposts in cyberspacecontinue to be subject to some criticisms of its legitimacy. as in all political processes, icannõs goal will be to ensure that the most importantconstituencies are not among the critics. in particular, it will have to convince the department of commerce that it has achieved legitimacy amongthe most important constituencies in order to fulfill the terms of its mostrecent mou with the doc.it should also be noted that even if there were agreement on icannõsproper scope, icann would still face numerous practical problems ofrepresentation. what would it take, for example, for it to be seen as trulyinternational? does it suffice, for example, simply to have one board member from each region? or should the distribution of board membershipbetter reflect internet usage in each country or region? or should it, perhaps, reflect the geographic distribution of registered domain names? thisappears to be an inherently difficult problem to which any proposed solution may incur objections from some of those nations that are not directlyrepresented. (even direct representation may not suffice. two of the countries that have been most critical of icann in international forums arebrazil and china, both of which have nationals on the icann board.)in a similar way, the broadest view of icannõs appropriate scopeimplies that the board reflects the many internet constituencies having aninterest in its decisions. but there is no agreed list of those constituencies,nor would the list be likely to remain unchanged. even assuming that alist could be agreed upon, should one board member be selected fromeach constituency despite the fact that constituencies are of different sizeand degrees of importance? and how should each constituency make itsselection? in the event that elections are used: who is the electorate? howare they to be reached? how can the validity of their votes be assured?these difficulties are not matters of icannõs making. they arise fromthe unique situation in which it finds itself and would confront any othernongovernmental organization attempting to manage an economically,socially, and politically significant component of the global infrastructure.conclusion: no composition of the icann board, no matter howarrived at, is likely by itself to confer the perception of legitimacy onicann among all its possible constituency groups.5.2.3nature of icannõs management processesthe third controversy concerns icannõs management processes. perhaps the goal of perceived legitimacy could be achieved through refiningthe processes by which icann carries out its work and makes its decisions. from its inception, icann has indicated that it would use bottomup, consensusbased, and transparent decision processes. the aspirationsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues203for such processes largely reflected the culture of the early internet community, especially the internet engineering task force (ietf). it fit wellwith that small, relatively homogeneous group in which technical expertise and experimental results drove most decisions. however, it has notturned out to be as effective a tool for making the valueladen decisionsthat have faced icann in an environment with a very large number ofusers, many of whom are not technical experts, holding highly diverseand often fundamentally different goals and values that are often not susceptible to resolution through consensus.although icann put in place a formal structure of constituencygroups with apparent input into the boardõs decision processes, prior tothe recent reform, at least, it had not succeeded in employing them insuch a way that they were perceived to identify consensus views, or evento ensure that all constituency opinions were heard during the process. inpart, this was the result of failure of the constituency groups to participate, but there were also questions about the weight given to some constituency groups and the absence of others.thus, although icann has made efforts to fulfill its promises usingthe current processes, it appears doubtful thatñas long as icann is morethan a purely technicaladministrative bodyñany set of processes thatwas both efficient and effective could be restricted to bottomup, consensus decision making among imperfectly defined constituency groups.icannõs existing processes have also been heavily criticized for theirlack of transparency, for the failure to document the logic of decisions, forthe absence of a process of appeal, and for the heavy reliance on nonaccountable staff and consultants. many icann observers view accountability as an òessential component of legitimacy for icann.ó25conclusion: improvement of icannõs processes appears to be a necessary step toward strengthening its perceived legitimacy.for the reasons noted above, it would be difficult to strengthenicannõs perceived legitimacy if the focus on bottomup, consensus decision making were retained. it would be more practical to concentrate on25center for democracy and technology, òcomments of the center for democracy andtechnology to the committee on icann evolution and reform,ó may 3, 2002, available at<http://www.cdt.org/dns/icann/020503ceir.shtml>. see also tamar frankel, òaccountability and oversight of the internet corporation for assigned names and numbers(icann),ó report to the markle foundation, july 12, 2002, available at <http://www.markle.org/news/icannfin19.pdf>; and center for global studies, òenhancinglegitimacy in the internet corporation for assigned names and numbers: accountable andtransparent governance structures,ó final report to the markle foundation, september 18,2002, available at <http://www.markle.org/news/icannfinalsept18.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.204signposts in cyberspacemaking conventional majorityvote decisions through processes that areaccepted by its constituencies as being open to input from all those havinga legitimate interest, transparent and observable in all their stages, andfair to all participants.5.2.4alternativesin response to the criticisms of its structure and management practices, icann began implementing a significant reform in early 2003. during 2002, while it was examining what specific steps to take, a number ofexternal groups put forward specific proposals of their own. those proposals demonstrate the diversity of the interests that attempt to influenceicann and that remain active or potential critics of its efforts. furthermore, should the current icann reform not prove successful, those proposals are likely to reappear in their original or a modified form. thus,both to show the forces that icann faces and to characterize the alternatives to its current reform, this section summarizes and evaluates some ofthe major alternative paths that have been proposed for icann to achievelegitimacy in the eyes of its critical constituencies.two distinctly different groups of approaches to icannõs structurewere proposed: broadening and narrowing. the broadening approacheswould keep or extend icannõs scope and keep or broaden the number ofgroups that participate in its processes on the board and through othermeans. in contrast, the narrowing approaches would narrow bothicannõs scope and the diversity of stakeholders directly involved. eachapproach would also have consequences for the nature of the processesicann employed.the alternatives described and evaluated below include two broadening proposalsñone by the markle foundation and the other by thenongovernmental organization and academic icann study groupñand two narrowing proposals, one that icann serve solely as the registry for the root and another that it be a private trade association. thediscussion concludes with two proposals that combine a narrowing ofscope with a broadening of participationña proposal by the center fordemocracy and technology, and the actual reform that icann adoptedin 2003.alternative a: markle foundation proposal (2002)descriptionthe president of the markle foundation, zo‚ baird, presented recommendations for improving icannõs credibility and legitimacy in a 2002signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues205foreign affairs article.26 these recommendations entailed changes tobroaden participation in the board and to improve its processes.with respect to the board, baird said:icannõs credibility as a global manager of critical parts of the internetõsinfrastructure depends on the boardõs ability to ensure that all the variousprivate and public interests are represented [emphasis added]. governmentinvolvement is one step toward providing publicinterest representationbut is insufficient on its own. only with truly broad representation on itsboardñincluding nonprofit organizationsñcan icann adequately address the crisis of legitimacy that plagues it [emphasis added].27baird also recommended changes in icannõs processes:icann must take steps to bolster transparency and accountability. thesesteps should include some kind of public oversight by politically accountable officials; development of dueprocess principles and clear, publiclyavailable procedures for the resolution of complaints; public disclosureof its funding sources and budgets; staff and board members who areheld accountable to a clear set of professional norms and standards; openmeetings; and documentation of the rationale for icannõs policy decisions and actions.28evaluationalthough pointing in attractive directions, the markle proposalõs recommendations about icann board composition are, unfortunately, toogeneral to confront and resolve the practical difficulties of their implementation. for example: what are the groups that constitute òalló publicand private interests that should be represented on the board? how manydifferent governments need to be on the board to represent all public interests? how many nonprofits need to be represented to cover all otherpublic interests? in sum, how many board members would be required toprovide representation of all public and private interests? how can thenumber be kept from becoming unwieldy?the markle proposalõs recommendation on process, although stillgeneral, appear to lead more directly to practical implementation. in thespecific case of òpublic oversight by politically accountable officialsó itshould be observed that, in fact, that is the role that the doc currentlyplays and effects through its mou with icann. for reasons adducedbefore, it is not clear that the u.s. government would be agreeable to shar26see zo‚ baird, ògoverning the internet: engaging government, business, andnonprofits,ó foreign affairs, november/december 2002, pp. 1520.27baird, ògoverning the internet,ó 2002.28baird, ògoverning the internet,ó 2002.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.206signposts in cyberspaceing that oversight with officials of other governments. even if it were,there is the question, once again, of which governments and which publicofficials should play that role.alternative b: nongovernmental organization andacademic icann study proposal (2001)descriptionthe nongovernmental organization and academic icann study(nais) group described itself as òa collaboration of experts from aroundthe world, formed to explore public participation in icann and the selection of atlarge directors on icannõs governing board.ó29 the naisgroup was selfselected and directed but was funded by a grant from themarkle foundation, whose president is zo‚ baird, author of the foreignaffairs article in which alternative a appeared. in its report, published inaugust 2001, the nais group summarized its arguments for broad publicparticipation in icannõs board:¥òthe mission, character, and history of icann requires [sic] global public participation and representation for its longterm legitimacy and stability.ó¥òto the extent possible, the entire affected internet communityñfrom companies in the business of providing dns services, to domain name holders impacted by icannõs rules, to individualinternet users and consumers whose activities online could beshaped by icannõs rulesñshould be considered stakeholders inicannõs activities.ó¥òicannõs existing supporting organization structures [in 2001], orrepresentation by governments, do not alone provide appropriatepublic participation.ó¥òôatlargeõ participatory structures and representation on theboard are therefore essential channels for broader stakeholder involvement and icannõs legitimacy.óon the basis of these arguments, the nais groupõs report assertedtwo òoverarching principles: the public membership [of icann] shouldbe given structure and the public membership should be given representation.ó to fulfill those principles, it made six recommendations:29nongovernmental organization and academic icann study group, òicann, legitimacy, and the public voice: making global participation and representation work,óaugust, 2001, available at <http://www.naisproject.org>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues207¥òicann should constitute a broad membership open to all whocomplete a relatively simple registration process.ó¥ò. . . the atlarge membership should have internal structures thatpromote policy deliberation, coalition building and informationsharing among members.ó¥òthe public voice in icann should be represented at the boardlevel through a number of atlarge directors equal to the numberof directors chosen by the supporting organizations.ó¥òatlarge directors should be chosen through direct election bythe atlarge membership. direct elections, while imperfect, aremore likely to provide icann with global legitimacy than otherproposed options.ó¥specific processes should be followed to authenticate voters, toachieve both geographic and global representation, and to refineelection policies.¥to ensure the publicõs voice in icann, it should develop structural constraints on board authority, create additional accountability mechanisms, and should pursue supporting organization reformñstructure, processes, and board representation.òthus,ó the nais groupõs report concluded, òit is essential for icannto establish an inclusive, open atlarge membership, with a clear meansto participate in the decisionmaking process and substantial direct representation on the board.óevaluationthis is a clear and full expression of the view that icannõs influenceon the internet is so broad and important that the internetõs end usersmust have a strong role (equal to that of the supporting organizations) inits governance. it avoids the question of determining which constituencies should be represented by merging them all into a common òpublicóconstituency comprising all who sign up and are authenticated throughthe best available method. representation would be by region, with someglobal representatives as well. voting would be done online, which hasthe advantages of speed, global availability, and economy but has beencriticized because of the potential for fraud, for capture or disruption by adetermined group, and for possibly wide national differences in participation. in addition, the populations and internet participation rates differgreatly among regions, suggesting that equal representation may not bethe best approach.while opening participation to such a broad potential membershipwould undoubtedly increase the perception of icannõs legitimacysignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.208signposts in cyberspaceamong a number of its constituencies, open participation might have theopposite effect on those constituencies that take a narrower view oficannõs role and stakeholders. this illustrates the point made in section5.2.2 that differing, perhaps irreconcilable, views of icannõs role lead todifferent views about the proper composition and selection of its board.(the icann reform (alternative f) that is being implemented did createthe atlarge advisory committee (alac) with a nonvoting liaisonmember on the board.)alternative c: icann as registry for the root (2004)30descriptionthe opposite approach (to alternative b) to enhancing icannõs perceived legitimacy would be to focus icann on its primary role as registry for the root,31 with responsibility for reliability, security, accuracy,and availability, and to design its governance and operations accordingly.under this approach, icannõs governance would be simplified bynarrowing its controlling constituencies to four groups of primary stakeholders:¥the gtld and cctld registries that depend on the root to directpotential users to them,¥the root name server operators that provide access to the root zonefile,¥the internet service providers (isps) and intranets that rely on theroot to enable them to do lookups on the tlds, and¥the technical community that defines protocols and standards affecting the root and its operation.only these groups would participate directly in icannõs governance.since all of them are directly affected by or directly affect the operation ofthe root, they would, in effect, constitute a selfgoverning body. following the tradition established by icann, these stakeholder groups could30this proposal has been constructed for discussion purposes only. it is not a recommendation by the committee. it was created to illustrate how a narrowly focused icann mightoperate and be governed. it bears some resemblance to, but differs in important ways from,the perspective presented in elliot noss, timothy m. denton, and ross wm. rader, òa newapproach to icann reform: the heathrow declaration,ó march 25, 2002, available at<http://www.byte.org/heathrow/heathrowdeclarationv0r0d5032502.html>.31icannõs other roles concerning the ip address space and protocols could be retained orturned over to a strictly technical body.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues209organize themselves into supporting organizations or forums to considerissues of special interest to their respective groups and to forward proposals to the icann board.(the group of domain name registrants and the registrars that servethem are not directly included in this alternative, although they have amore direct interest in the operation of the dns than, say, the much largergroup of all internet users. a variant of this alternative could includethem, but it would make voting and funding much more complex anddifficult to balance. this alternative assumes that their views will be heardeither through the registries and isps or through direct presentation tothe board.)all other interested partiesñinternational agencies, governments,32private commercial and noncommercial users and suppliers, registrars,domain name registrants, individual internet users, and public interestgroupsñwould be considered secondary stakeholders that could influence icann through one of the primary stakeholders, by testifying athearings and board meetings, and by lobbying individually or throughprivate and public interest organizations.although icann would remain a notforprofit organization, thetlds, isps, and intranets would be required to pay a fee for listing in theroot (if a tld) or for access to the root zone file (if an isp, intranet, orother large user33). a portion of the funds collected would compensatethe root name service providers34 for their service and would subsidizethe technical community to conduct testing and validation activities. thefunds would also cover the costs of the iana function of icann and itsother registry activities.the boardõs members would be elected for fixed terms by the fouror five stakeholder groups. the number of votes cast by each tld orisp would be proportional to its annual fee to icann, which wouldbe in some relationship to its demand for root service, for example, asmeasured by the number of registrations for tlds and the number ofip addresses for isps. the number of votes cast by each of the rootservice providers and by each technical organization would be proportional to the annual payments it received, which would be based on its32national governmentsõ interests in their cctlds would not be subject to this body, except when a conflict over the operator of the cctld registry occurred.33small, noncommercial users would be exempt unless they wanted to participate inicann governance.34full implementation of this alternative would probably require replacement of the u.s.governmentoperated root name servers so that they could receive payments.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.210signposts in cyberspacerequirements. (note that the sum of the paymentbased votes wouldequal the sum of the feebased votes less a number of votes proportional to the operating expenses of icann itself. these could form athird category of votes that would be cast by the icann president.)tying board voting power to payments would provide an incentiveboth for payment and for participation, particularly by the cctlds androot name server operators.the board would operate like the board of a public agency, takingdecisions based on its collective judgment as informed by public hearings. on special issues, stakeholders could petition for a stakeholder vote,similar to a shareholder vote in a commercial corporation.evaluationthe approach described in alternative c for narrowing icannõsscope is in strong contrast to the proposals for a broadly representative board that relies on bottomup consensusbased processes. it substitutes a board that is intended to reflect the interests and experience of the immediate providers and users of root name service only.in doing so, it reconceives icann as a narrower, more technicallyfocused body whose decisions would be limited to those that affectthe ability of the root to meet the needs of those who have directrecourse to it. it would have the means to exercise authority over theroot service providers through its payments to them, while theywould gain influence on its decisions through their consequent voting power. each tld would pay a fee to be listed in the root, but theamount would depend on the number of its direct registrants (notincluding registrants in the subdomains of its registrants) and wouldbe proportional to its voting power. very large tlds, such as .com,would have a substantial number of votes, but not enough to overcome the sum of the votes of other tlds, the root name service providers, and the technical community. the most difficult issue wouldbe imposing a fee on the isps for access to the root zone file sincethere is no practical way to prevent access to those that have not paid.the threat of exclusion from icann activities and decisions wouldbe the primary incentive for payment.because it runs counter to the design intent of icann, to the cultural traditions of the internet, and to icannõs own recent reforms, theapproach of focusing icann on its role as registry for the root is unlikely to be adopted in the near future. however, it illustrates one possible model of a narrowly focused icann and stands, therefore, as aclear contrast to the more expansive models described in alternatives a,b, e, and f.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues211alternative d: new.net proposalñicann as aprivate trade association (2002)descriptionanother narrowly focused model for icann was proposed in 2002by new.net. 35 under this proposal, icann would gain legitimacy byreconstituting itself as an international consensusbased trade associationfor òparties interested in issues related to domain names, ip addressesand internet protocols.ó36 the association would be the vehicle for developing and promulgating industrywide practices and policies. becausepolicies would be developed through industry consensus, its proponentsbelieve that these policies and practices would be more likely to beadopted voluntarily by the association members. they point to the consensus process, for example, that led to film producersõ widespread adoption of the motion picture association of americaõs film rating practices.icann as a trade association would also be characterized by a relianceon market forces as the òdominant factor in regulating conduct of personsbuying, selling and using internetrelated products and services.ó37 theforces of the market would be expected to induce entrepreneurs and companies to introduce a wide range of innovative services that would succeed orfail based on usersõ experience with them, crucially including theirinteroperability with other services. in other words, the proponents of thisalternative expect that many of the concerns that have driven icann to aregulatory model and, in particular, the protection of a single authoritativeroot and the controlled pace of new gtld entries would be better handled byletting the market decide. these proponents believe that the market wouldreject any innovation that harms the functioning of the dns and the internet.where regulation would be required to supplement industry agreements and market forces, this alternative would rely on existing practices,using national, regional, and local governments or formal intergovernmental treaties. in the proponentsõ view: òit is hubris to assume that thereis something so special about internet naming issues that the domainname industry requires a unique form of government that is different fromall other industries.ó38one consequence of adopting this alternative would be the possibleproliferation of dns root zones, which might be created by countries un35new.net (see section 3.3.1) is a commercial organization that offers an alternative rootand related search service. it has an obvious selfinterest in a proposal that calls for establishment of alternative roots.36new.net, òa proposal for more realistic domain name governance,ó march 2002, p. 13,available at <http://www.new.net/whitepaperv2.pdf>.37new.net, òa proposal for more realistic domain name governance,ó 2002, p. 15.38new.net, òa proposal for more realistic domain name governance,ó 2002, p. 16.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.212signposts in cyberspacehappy with u.s. control of the òlegacy rootó or desirous of one in theirnational language, or by corporations, like new.net, that see business opportunities in offering roots containing additional tlds and operating under different policies. to alleviate the concerns of key players, the proposalsuggests that the united states retain policy control of the legacy root; thatother nations form a cctld association that would agree on the contents ofthe cctld component of the root; and that the united states contract withthat association to ensure inclusion of those entries in the legacy root. otherroot zone providers would decide whether to include the legacy root or thecctld entries in their root. finally, the workings of the market would determine whether any root zone, other than the legacy root, would survive.evaluationas with alternative c, the approach of icann as trade association movesaway from the notion of a broadly representative board for icann and replaces it with a smaller set of stakeholders that have a direct interest in operating the root. however, it retains the basic consensus decisionmaking process and, while not specifically limiting the range of icannõs action, doesindicate a strong preference for leaving decisions to the operation of marketforces. because of that preference, it loosens restrictions on the technical system of the dns (such as maintenance of a unique root, regulation of tldregistry services, and a relatively slow, controlled addition of new tlds) thatmany in the technical community have said are required to retain theinternetõs stability, openness, and uniform accessibility.while obviously serving the interests of its principal proponent in allowing alternative roots and, thereby, opening the market for gtlds, alternative d does suggest how a marketbased, freeentry management of theroot might be designed. like the preceding alternative, new.netõs proposalchallenges existing views, in this case those of the internet technical community, about what constraints are required to protect the dns technicalsystem. although it is unlikely to be put into practice in the near future, it isanother model available for consideration should other reform efforts fail.alternative e: center for democracy and technology proposalñnarrowed scope with broad participation (2004)descriptionin july 2004, the center for democracy and technology published areport39 that called for both narrowing the scope of icannõs mission and39see center for democracy and technology, icann and internet governance, 2004. allquoted material in this section, òdescription,ó is from that report.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues213broadening participation in its activities. at the same time, it supportedthe consensusbased approach to decision making.with regard to mission, it urged icann to:¥òreaffirm the extremely limited mission that [it] was created toaccomplish . . . the technical function of coordinating the assigningof names and numbers . . . and a few inextricably related policyquestionsó;¥òrefrain from using [its] coordination role as leverage to engage inpolicymaking in broader areasó;¥òreassess and ensure its contracts with registries provide both thereality and appearance of a limited approach to coordination ofregistry activitiesó; and¥òadopt an approach to coordination that seeks to minimize policyimpacts.ówith respect to participation in decision making, it urged icann to:¥òstrengthen activities to engage diverse constituencies around theworld in [its] decisionmaking.ówith reference to decision processes, it urged icann to:¥òsupport the consensusbased approach to decisionmaking thatwas core to the original concept under which [it] was createdó;¥make its decision making òtransparent, predictable and open tobroad global participation by stakeholders, including usersó; and¥make its òfuture policies binding only if they are supported by ademonstrable bottomup consensus among affected parties.óit also asserted that icannõs òonly real and legitimate power comesfrom voluntary [emphasis in the original] contracts and certain other mutually acceptable relationships and agreements.óevaluationalternative e was published as a proposal in the context of the worldsummit on the information society to refute the arguments and correctthe misperceptions of those who see icann as a òprecedent or justificationó for international centralization of internet governance. it does so byemphasizing the limited scope of icannõs original mission and its charter obligation to apply only policies arrived at by òbottomup consensusamong affected parties.ósignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.214signposts in cyberspacebecause it focuses on narrowing icannõs scope and at the same timeencourages icann to broaden participation by diverse constituenciesaround the world and rely on consensus decisionmaking policies, alternative e appears somewhat inconsistent. for it would seem that restraining icannõs role to the technicaladministrative function (and a fewtightly linked policy matters) would, at the same time, reduce the numberof interested constituencies and the range of policy issues requiring consensus decision making, though it would make the latter more feasible. itis primarily a call for icann to òget back to basicsó and reverse the stepstaken to set and apply nonconsensus policies beyond icannõs originalnarrow scope.alternative f: reformed icannñnarrowed scope with broadparticipation (2003)descriptionthe issues facing icann in 2002 of board composition, constituencyparticipation, funding, and decision processes were brought into the openand given formal recognition when the thenpresident, m. stuart lynn,published a critique of icannõs operations.40 this led to the creation of acommittee to study and make recommendations on icannõs governance.the committeeõs report was published in october 200241 and its recommendations, after board consideration in november 2002,42 have beenimplemented.the new icann bylaws, which took effect in 2003, have remade thegoverning structure of icann, especially the board and the supportingorganizations that represent its constituencies. they are derived from amission statement revised and sharpened in response to the widely heldperception that icann had suffered from a vague and undefined concept of its mission. the new mission statement is as follows:the internet corporation for assigned names and numbers (icann) isthe privatesector body responsible for coordinating the global internetõssystems of unique identifiers.the mission of icann is to coordinate the stable operation of theinternetõs unique identifier systems. in particular, icann:40m. stuart lynn, òpresidentõs report: icannñthe case for reform,ó february 24, 2002,available at <http://www.icann.org/general/lynnreformproposal24feb02.htm>.41committee on icann evolution and reform, òfinal implementation report and recommendations,ó october 2, 2002, available at <http://www.icann.org/committees/evolreform/finalimplementationreport02oct02.htm>.42icann board of directors meeting in shanghai, òpreliminary report,ó november 1,2002, available at <http://www.icann.org/minutes/prelimreport31oct02.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues2151.coordinates the allocation and assignment of three sets of uniqueidentifiers of the internetñdomain names, ip addresses and autonomous system (as) numbers, and protocol ports and parameter numbers.2.coordinates the operation and evolution of the dnsõs root nameserver system.3.coordinates policydevelopment as reasonably and appropriatelyrelated to the performance of these functions.43in conjunction with the mission statement, icann adopted 11 corevalues that icann will adhere to, including preservation of internet stability, reliability, security, and interoperability; limiting activities to thosebenefiting from global scope; delegation where feasible; broad, informedparticipation; dependence on market mechanisms where feasible; promotion of domain name registry competition; open and transparent policydevelopment; application of documented policies; speedy action; accountability; and sensitivity to the public interest and related governmental concerns.under the new bylaws, the governing structure consists of a board ofdirectors with 15 voting members: 8 selected by a nominating committee;6 selected by three supporting organizations44 (2 from each); and thepresident of icann, ex officio. in addition, there are 6 nonvoting liaisons to the board: 1 each from five advisory organizations,45 and 1 fromthe internet architecture board (iab)/ietf. the nominating committeeis charged to select directors to ensure that in aggregate the board hasfunctional, geographic, and cultural diversity; the capacity to understandthe global effects of icannõs mission and decisions; and credibility.each of the supporting organizations has its own internal structure,allowing for the representation of multiple constituencies. each is responsible for the development of policy recommendations to the icann board43icann evolution and reform committee (erc), òicann: a blueprint for reform,ójune 20, 2002, available at <http://www.icann.org/committees/evolreform/blueprint20jun02.htm>, with revisions from icann erc, òfinal implementation report and recommendations,ó october 2, 2002, available at <http://www.icann.org/committees/evolreform/finalimplementationreport02oct02.htm>.44the three supporting organizations are the address supporting organization (aso),which deals with the system of ip addresses; the countrycode names supporting organization (ccnso), which focuses on issues related to the letter countrycode toplevel domains;and the generic names supporting organization (gnso), which handles issues related tothe dns and the generic toplevel domains.45the four advisory committees are the atlarge advisory committee (alac) for theinternet community atlarge; the dns root server system advisory committee (rssac)for root server operators; the governmental advisory committee (gac) for governments;and the security and stability advisory committee (ssac) for security. the fifth organization is the technical liaison group (tlg) for standards groups.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.216signposts in cyberspaceand developing internal consensus. the nominating committee comprises 11 members appointed by constituencies, 3 appointed by advisorycommittees, and 5 unaffiliated public interest persons appointed by theatlarge advisory committee. in addition, there are 2 nonvoting liaisons from the other advisory committees and the technical liaison group.the board appoints its chair.in a move away from the consensusbased, bottomup process thatguided icann initially, the policy responsibility of the icann boardhas been strengthened:the icann board of directors is icannõs ultimate decisionmakingbody. . . . it is ultimately responsible for the management of the policydevelopment process. therefore, while it is highly desirable to seek andwherever possible find consensus, it does not follow that even proposalsthat enjoy consensus support should receive uncritical board approval.the board has a fiduciary responsibility to make decisions on the basis ofgood faith judgment in furthering the public interest.46in response to concerns about transparency and accountability, thenew bylaws call for the creation of an office of ombudsman, a manager ofpublic participation to encourage full public participation in icann, anda strengthening of the reconsideration process applicable to both the staffand board and requiring prompt consideration. it also establishes an independent review process to review whether the board has acted consistently with the bylaws.to strengthen government participation without directly includinggovernment representatives on the board, the bylaws call for the governmental advisory committee to appoint a nonvoting liaison to the board,a delegate to the nominating committee, and nonvoting liaisons to eachof the supporting organizations and to the other advisory committees.in place of having five atlarge board members elected by internetusers, that community is expected to be represented through the atlargeadvisory committee, which will seek to engage individual internet usersthrough regional atlarge organizations in five geographic regions.evaluationthe restated icann mission is to focus on its original missionñcoordinating the stable operation of the internetõs unique identifier systems. ifthe board adheres to that mission statement, the effect could be to narrowicannõs scope from that which has evolved since 1998. the reform, at46icann erc, òicann: a blueprint for reform,ó 2002, and òfinal implementation report and recommendations,ó 2002.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues217the same time, takes a broad view of icannõs constituencies. the newbylaws define selection and representation mechanisms that could widenthe range and raise the quality of members on the board and, thereby,strengthen icannõs perceived legitimacy. however, some critics arguethat the board member selection mechanisms are vulnerable to capture bythe board itself, leading to a narrowing of representation. the structureattempts to respond to concerns about icannõs processes by definingsteps to increase the specificity, transparency, and accountability oficannõs processes.whether this new structure and these new processes will enableicann to achieve the perceived legitimacy that it has so far failed toattain can be determined only through the practical experience of the coming years.summary of the alternativesthe six alternative approaches to achieving an icann that is perceived as the legitimate steward of the root are summarized in table 5.1.they are characterized along two dimensions. the first is the breadth oficannõs roleñbroad or focused. the second is the breadth of its community of stakeholdersñbroad or narrow.5.2.5conclusions and recommendationthe discussion of alternatives in sections 5.1 and 5.2 leads to fourobservations. first, the department of commerce has expressed the u.s.governmentõs intention to complete privatization of dns governance bytransferring its stewardship role to icann by 2006, conditional uponicannõs satisfying certain preconditions. second, the 2005 wsis meeting might produce a proposal for a private, nongovernmental organizatable 5.1alternatives for organization of icann to achievelegitimacyicannõs roleconstituencybroadfocusedbroada. markle (2002)e. cdt (2004)b. nais (2001)f. icann reform (2003)prereform icannnarrowc. registry for the root (2004)d. private trade association (2002)signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.218signposts in cyberspacetion designed to assume certain internet governance responsibilities.however, as of march 2005, whether such a proposal would in fact bepresented and what form it would take were not known. third, evaluation of any organization proposed by wsis in late 2005 as a dns stewardwould face practical difficulties: it could be done only on the basis of theproposed organizationõs design, whereas icann will be evaluated onthe basis of its record. and it might not be possible to complete an evaluation before the intended transfer of stewardship to icann in 2006.fourth, the outcome of implementing icannõs 2003 reform and othericann changes may or may not result in the fulfillment of the docõsrequirements.these observations suggest three conclusions.conclusion: if icann satisfies the department of commerceõs requirements and is generally perceived to be a legitimate manager of thedns in the view of a substantial majority of its constituencies, and if nopreferable alternative results from the 2005 wsis meeting, the u.s. government is highly likely to transfer its role as steward of the dns toicann during 2006.conclusion: any private, nongovernmental organization proposedas a result of the 2005 wsis meeting is likely to be considered by the department of commerce for dns stewardship only if icann fails to satisfy the docõs requirements.conclusion: if icannõs reforms are not successful and if the 2005wsis meeting does not propose an organization to assume dns stewardship that is acceptable to the u.s. government, the likely outcomes will bea continuation of the department of commerceõs stewardship role and abasic reconsideration of how dns governance should be organized.a transfer of stewardship from the doc will leave icann (and another organization if stewardship is kept separate) without the benefitsand controls that the doc has provided. it independently reviewedicannõs recommended decisions, regularly oversaw icannõs performance subject to the sanction of nonrenewal of its mou, and implicitlyprotected it from attempts by other governments and organizations togain control of or strongly influence icannõs decisions. if the doc doestransfer its stewardship either to icann or to another private body, howwill these benefits and controls be provided?conclusion: without additional protection, legitimacy based on theòconsent of the governedó would be the only basis for icannõs continsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues219ued authority and its ability to resist inappropriate pressure from governments and other powerful interests. without additional oversight, finalresponsibility for satisfying the needs of its constituencies in an equitable,open, and efficient manner would lie solely with its board.recommendation: before completing the transfer of its stewardshipto icann (or any other organization), the department of commerceshould seek ways to protect that organization from undue commercial orgovernmental pressures and to provide some form of oversight of performance.5.3oversight and operation of root name serversissues: is there a need for greater oversight of the root name server operators?if so, how might it best be conducted? should there be a formal process for replacing root name server operators? should the root name server operators be compensated for their service, and if so, how?the root has functioned well as the shared responsibility of a group of12 diverse, autonomous, informally coordinated, and independentlyfunded operators (see table 3.1). many observers believe that the diversity and autonomy have been strengths, reducing vulnerability to singlepoint failures. yet, other observers feel that the dns and the internet havebecome too important to the global society and economy to permit such acrucial system to continue to operate without the oversight of an organization responsible for its continued healthñtechnical, operational, andfinancial.the tension between these two viewsñdiverse autonomy versus central oversightñleads to several different potential approaches to the issues identified above. in this section, the current situation is first reviewedand evaluated and then four alternatives are similarly described and reviewed. the committeeõs conclusions and recommendations follow a comparison of the four alternatives.5.3.1current situation: diverse autonomydescriptionthe effective daily operation of the root name servers, described inòthe root name serversó in section 3.3.2, lies squarely in the hands of theroot name server operators. the operating organizations have taken onthe responsibility voluntarily, are not compensated by users for their baseoperations (although all are subsidized by their home institutions or outsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.220signposts in cyberspaceside contributors, and some receive payments from operators of theiranycast satellites47), and are selfregulating through extensive and continuous intragroup coordination.although icannõs mou with the doc48 assigns it the responsibilityto manage the root name server system, its authority, as noted in òselecting the root name server operatorsó in section 3.3.3, has not been sufficient to enable it to manage or even regulate the root name server operators directly. the recent extension of the mou places emphasis on icanncollaborating with the doc on òoperational procedures for the root nameserver system, including formalization of relationships under which rootname servers throughout the world are operated and continuing to promote best practices used by the root system operators.ó 49 to increase itsauthority, icann has established the dns root server system advisorycommittee,50 has sought to enter into formal agreements with each of the11 other root name server operators,51 and has prepared a draft òmemorandum of understanding concerning root nameserver operation.ó52however, it has thus far been unable to complete an agreement with anyof the operators. this is not surprising since it is likely that the operatorsdo not expect to receive benefits that would compensate for the additionalobligations they would be expected to assume to icann or, through it, tothe doc. in addition, many operators are subsidiary organizations withinlarger u.s. and foreign academic, commercial, or governmental entities,which themselves may not wish to incur the obligations and assume theliabilities that would come with such an agreement.53 indeed, it is diffi47see box 3.1 for a discussion of anycast satellites of root name servers.48òmemorandum of understanding (mou) between icann and u.s. department ofcommerce,ó november 12, 1998, available at <http://www.icann.org/general/icannmou25nov98.htm>.49òamendment 6 to mou between icann and u.s. department of commerce,ó september 16, 2003, available at <http://www.icann.org/general/amend6jpamou17sep03.htm>.see also doc, òdepartment of commerce statement regarding extension of memorandumof understanding with icann,ó september 16, 2003, available at <http://www.ntia.doc.gov/ntiahome/domainname/agreements/sepstatement09162003.htm>.50for a description of its responsibilities and activities, see <http://www.icann.org/committees/dnsroot/>.51icann operates the l root name server itself.52the draft memorandum of understanding is available at <http://www.icann.org/committees/dnsroot/modelrootservermou21jan02.htm>.53as the thenpresident of icann, stuart lynn, noted ò. . . some organizations that sponsora root name server operator have little motivation to sign formal agreements [with icann],even in the form of the mou that is now contemplated. what do they gain in return, exceptperhaps unwanted visibility and the attendant possibility of nuisance litigation? they receiveno funding for their efforts, so why should they take on any contractual commitments, however loose?ó òpresidentõs report: icannñthe case for reform,ó february 24, 2002, availableat <http://www.icann.org/general/lynnreformproposal24feb02.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues221cult to see how icann could induce the operators to sign the òmemorandum of understanding concerning root nameserver operationó in theabsence of a very attractive quid pro quo. thus, although icann hasbeen assigned the responsibility for òformalization of relationshipsóamong the autonomous root name server operators, it currently has littleability to convince the operators to agree to a stronger icann role.evaluationfortunately, the current operators have operated the system successfully and without major incident up to now, despite the enormous andsomewhat unanticipated rate of growth in demand for root name servicesince the mid1990s when usage of the web took off, and despite at leastone malicious attack54 on the system. recently, through the voluntaryadoption of anycast technology (see box 3.1), the operators have effectively multiplied the number of root name servers severalfold, reducingthe vulnerability of the system to denialofservice attacks, improving theglobal accessibility of the root, and moderating the political pressure forrelocation of the core 13 root name servers.the root name server operators assumed their responsibilities and,with a modest number of changes, have successfully operated within thecontext of internet culture that favors informal, voluntary, and nonbureaucratic institutions run by technical specialists with primarily altruistic motives. in addition, advances in computer technology and the readyavailability of free name server software have kept the cost of operatingroot name servers relatively low,55 especially when run as an adjunct toother, larger computer operations, as most of them are.nor would it be easy to change this situation without the agreementof the operators. their incumbency and financial independence protecttheir responsibility and authority, and their informal, collegial relationships serve to strengthen their power as a group. furthermore, althoughthey do not receive direct financial compensation for their service, they allreceive intangible benefits that, together with their fear of potentially destabilizing change in a system that is working well, are evidently suffi54on october 21, 2002, a distributed denialofservice attack was launched against the 13dns root name servers. for more information on the impact of the attack, see <http://www.caida.org/projects/dnsanalysis/oct02dos.xml>.55according to discussions in june 2004 with kurt erik lindqvist, managing director ofautonomica ab, which operates i.rootservers.net, the average annual cost of operating anindependent root server, including the costs of multiple anycast satellite servers, is about$1 million. however, other root servers are operated as adjuncts to already wellprovisionedsecure internet sites, requiring a minimal incremental expenditure on the order of tens ofthousands of dollars annually.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.222signposts in cyberspacecient to support their continued activity. in the absence of strong justification, it appears that they are not inclined to favor a change in the currentstate.but despite that fact that the current arrangement is functioning well,it might run into difficulties if for some reason the root name serversõperformance deteriorated or some of the operators resigned. moreover,icann is obliged under the mou to try to take a more formal role in rootname server operations. consequently, it is useful to consider the range ofalternatives there might be for operating the root name server system andto see if they might offer advantages over the current arrangement, aswell as in meeting icannõs mou obligation.5.3.2alternativestwo alternative models for structuring management of the operationsof the root are (1) funding and regulation and (2) a competitive market.they are described and evaluated below. a third, hypothetical possibilityñdistributing the root zone fileñis here raised by the committee as ameans of opening a different kind of approach for consideration. a fourthalternative would be for the doc to release icann from its mou requirement that it formalize relationships with the root name server operators.alternative a: funding and regulationdescriptionunder alternative a, icann (or a successor organization) would acquire the means to assume responsibilities for the root name server system. as noted above, the most likely source of authority for icannñas anongovernmental bodyñwould be financial. if funds were available tocover all or a significant portion of the operating costs of the root nameserver operators, icann might be in a position to use its financial authority to do some or all of the following regulatory tasks:¥establish minimal performance standards for the root name serveroperators.¥support the implementation of a realtime performance monitoring system for each operator and the system as a whole, perhapsbased on the system under development by the res”aux ipeurop”ens network coordination centre (ripe ncc).56¥monitor the performance of the root name server system.56see <http://dnsmon.ripe.net/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues223¥enforce performance standards by adjusting compensation to theoperators according to the level at which they performed.¥require performance improvement of operators that do not achieveminimum levels of root name server performance that would beenforced through cut off or reduction of compensation.¥remove operators whose performance does not meet minimumrequired levels despite requests and reduced or eliminated payments.¥identify and qualify new operators to replace removed or resignedoperators.¥use the contingent provision of additional funding to provide incentives for the operators to achieve higher performance levels andintroduce new services.evaluationif it performed most or all of those tasks, icann would be the centraloverseer of the root name server system with full responsibility and authority for its reliable and effective operation. it could establish a performancemonitoring system and use financial rewards and punishments tomaintain and improve performance. should change in an operator or inoperations be required, icann would be in a position to bring it about.icann would, in fact, be carrying out natural responsibilities of the registry for the root (see alternative c in section 5.2.4).icannõs capabilities as a monitor and decision maker would stronglyinfluence the performance of the root name server system. if it had capable staff, excellent system understanding, and a knowledgeable board,it could make timely and effective decisions. however, should any ofthose conditions not apply, its influence could in fact be detrimental to theperformance of the root name server system.moreover, this alternative depends on the operators responding tofinancial incentives. many might, but it is clear that not all of them would.there is some possibility of a significant number of them dropping out ifthe alternative were additional controls from icann (or anyone else),and a change in a number of root server operators at the same time mightbe destabilizing. in addition, the dropouts could form an alternative root,which could be further destabilizing. the three u.s. government agencies that run root name servers, forexample, would probably not legally be able to give up their autonomy inexchange for a financial inducement, especially from a private organization. they would have to be replaced by nongovernmental organizations,and that would probably require the agreement of the u.s. government.the relevant elements of the u.s. government might, in turn, be reluctantto agree for fear of thereby reducing overall stability.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.224signposts in cyberspacenor are the funds necessary for this approach available withinicannõs current budget. they would have to be incorporated into a future budget and could require a corresponding increase in icannõs funding from registries and registrars. (this would be available under òalternative c, icann as registry for the root,ó in section 5.2.4.) anotheroption would be to allocate to this purpose a portion of any funds received from the procedure for selecting new tlds through auction orother processes, as described in òwhat selection process should be used?óin section 5.4.2. below.an alternative proposal would be to charge isps and other users anannual fee for access to the root, which is similar to what is done today bythe root server operators when the cost of an anycast satellite is shared bythe isps and users that will benefit from it. (however, there is no practicalway that such a fee could be enforced, except through the voluntary agreement of the isps and other users.)alternative b: competitive marketthe second alternative would be to create a competitive market forroot service. to the committeeõs knowledge, competitive service of thesame root has not been formally proposed elsewhere. however, since increasing competition in the provision of dns services is one of the statedgoals of the doc, the committee has created an example of what astraightforward approach to such competition might mean for root nameservices.57 a less straightforward example, which is actually being implemented, is also described.b1: competing root name server systemsin the most straightforward form of market for root name service,competition would entail having two or more distinct groups offering access to the authoritative root zone file. to avoid the confusion that couldarise with multiple root zones, each of the operator groups would have toagree to offer access to the same root zone file, which would be providedto each of them at the same time by the authoritative source, say, verisignfor icann.58 every isp, intranet, or other organization running a full57the recent sixth amendment to the memorandum of understanding includes the statement, òthe department reaffirms its policy goal of privatizing the technical management ofthe dns in a manner that promotes stability and security, competition [emphasis added],coordination, and representation.ó see òamendment 6 to mou between icann and u.s.department of commerce,ó september 16, 2003, p. 2.58the authoritative root zone file is currently distributed by verisign, which operates thehidden primary. however, at some future time, icann may take over this function itself.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues225service resolver on the internet would have to contract with one (or more)of the competing root server operators, which would charge them amonthly or yearly subscription fee that could be based on volume of queries or, more practically, on how many ip addresses the organization hadassigned to it. a technical means of ensuring that only subscribers couldgain access to an operatorõs root name servers would be required.evaluation. the committee was unable to conceive a version of this fullcompetitive market for root name service that would be both technicallyand operationally feasible and beneficial enough to displace the currentsystem.there are two major technical difficulties. first, the communicationand computation overhead of ensuring that only subscribers could gainaccess to the operatorsõ servers could be a substantial and undesirableload on the root name server system, with the servers spending significantly more effort checking permissions rather than answering queries.second, there is the difficulty that arises because the content of the rootzone file includes the ip addresses of the root name servers. if there is oneauthoritative root zone file, then there is only one set of ip addresses thatit can contain and, therefore, only one set of root name servers. even ifthese technical problems could be overcome, two major operational problems would remain.the first operational problem is that every system that contains a fullservice resolver would need access to the root zone. thus, every laptopand home system so equipped (and there are many) would require a contract with one of the competing root name server systems or would haveto change to a stub resolver and contract with an isp for that service. this,in turn, would cause problems for traveling users who typically encounter and would have to contract for root service from multiple differentisps in the course of their travels.the second operational problem is that the switchover to operation ofa competitive system would have to take place in a short time, unless thecurrent set of operators were the default choice, to which competitorswould likely object. that means that every isp, organizational intranet,and owner of a fullservice resolver would have to sign up for servicewith one of the competitors. technically, the root name server hints filein every resolver/name server on the internet would have to be changedover in a short time to list the ip addresses of the root name servers of oneof the providers.even if these technical and operational difficulties could be overcome,there are two pragmatic difficulties that the changeover to a full competitive market for root name service would have to overcome.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.226signposts in cyberspacefirst, a fee would be introduced for what is currently a free good.that is only likely to be accepted if it is accompanied by significantly improved performance on dimensions that its customers care about and ifthe root zone file can be kept secure from all but subscribers. but there hasbeen no suggestion that dissatisfaction with current service is such thatany level of òimproved performanceó would be willingly paid for.second, the incumbent operators would have a great advantage, sincethey have the facilities, the skilled staff, and the operational experiencethat newcomers would have to develop. however, that might not be aproblem for companies that already run large dns name servers, such asneulevel or ultradns, or for national governments that wanted to establish their own system of local name servers.these potential difficulties, which mean that the probable costs wouldsignificantly outweigh the prospective benefits, effectively eliminate theapproach of a full competitive market for root name service. however,there is another approach that is already developing.b2: competing providers of anycast serversthe current market for anycast satellite servers is a less direct form ofcompetition for root name service. the competitive providers are a number of the root name server operators who compete on price, service level,and other features to attract customers, which are isps or others that wantto have an anycast satellite server nearby. the result of the developmentof this market has been a rapid multiplication and broadened distributionof the number of servers of the root zone file.evaluation. model b2 has shown itself to be a demonstrably feasible pathto reducing the geographically uneven distribution of response times andto increasing the reliability of the root name server system without incurring the technical, operational, or practical problems of the model firstdescribed. thus, it provides most of the benefits of model b1, òcompetingroot name server systems,ó without its difficulties.alternative c: distributed root zone filedescriptiona third alternative, which might avoid the difficulties of regulation orcompeting root name servers, would be for isps and organizationalintranets to obtain copies of the root zone file from icann (throughverisignõs distribution server) and make local name servers authoritativesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues227for the root zone. something like this is, in fact, done today through thecaching of queries by isps and through the possibility of an isp obtainingan anycast satellite of one of the root name servers.59 however, in thisalternative, the intention would be to formalize this practice and haveicann require every isp or intranet to subscribe to the authoritative rootzone file. the current public root name servers could be retained for useby small and less technically skilled isps and intranets, but would bescaled down to serve the smaller load.evaluationthe wide distribution of the root zone file and root name serverswould significantly enhance the security of the root and the reliability ofits operation, in much the same way that anycast satellite sites alreadyhave done, but to an even greater extent. furthermore, the effects of erroneous or malicious queries would be limited to the isp or intranet fromwhich they originated, and the isp would have a strong incentive to findand eliminate their sources. some fear that widespread distribution of the root zone file and theprobable large numbers of poor local configurations and irregular updating of the local name servers would cause havoc at worst, and poor localservice at best. the concern is that widespread availability of the root zonefile would encourage the offering of alternative roots, from which sometlds had been removed or to which additional tlds had been added.the latter problem can, however, be partially addressed through dnssecurity extensions (dnssec; see section 4.2), which would detect, although not prevent, unauthorized changes to the root zone file. what actions would be taken if a change is detected would have to be agreed inadvance and enforced through an agreement with the isps. the irregularupdating problem might be resolved through the use of a distributordriven process like that currently used to update the secondary root nameservers.if it could not be ensured that organizations (especially isps, which inturn have customers) would keep their copies of the root zone file uptodate and uniform, the approach of having a distributed root zone filecould cause a decrease in the integrity of the dns, which relies on the rootzone file being consistent across the internet.59in fact, the root zone file is available for download at <ftp://ftp.internic.net/domain/root.zone.gz>, but there is no encouragement to use it.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.228signposts in cyberspacealternative d: doc relaxes mou requirementdescriptionthe doc could relax its requirements for icann if it accepted thesuccess of the current diverse, autonomous, selfregulating root nameserver system instead of viewing it as unsatisfactory because it is subjectto neither formal regulation nor the discipline of the market. in place of itscooperation with the doc on òoperational procedures for the root nameserver system, including formalization of relationships under which rootname servers throughout the world are operated,ó icann could betasked simply to serve as a facilitator, if asked, of the voluntary cooperation among the root name server operators. evaluationthe docõs relaxation of its requirements for icann would, in effect, legitimate the current de facto relationship between icann andthe operators and relieve the pressure on icann to take on authorityand responsibility that the operators have not yet shown themselveswilling to cede.summary of the alternativesthe current state and the four alternatives for oversight of the rootname servers are summarized in table 5.2. it compares them on two dimensions: first, whether the root name server operators are under formalor informal oversight by icann, and second, whether there is one set ofroot name server operators or multiple sets.table 5.2alternatives for root name server oversight and operationoversightroot name serversformalinformalone set of operatorsa. funding and(current situationñdiverse autonomy) regulationb2.competing providers of anycastserversd.doc relaxes mou requirementmultiple operatorsc. distributed rootb1.competing root name servers zone filesystemssignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues2295.3.3conclusions and recommendationsconclusion: the effective daily operation of the root, and therefore of the dns and the internet, lies squarely in the hands of theroot name server operators. although icann has been assigned responsibility for the stability and security of the root name server system by the department of commerce, its authority has not been sufficient for it to manage or even regulate the root name server operatorsdirectly.conclusion: the committee commends the operators of the 13 rootname servers for their reliable and efficient provision of critical root nameservice as the internet has undergone rapid growth in the numbers of itsusers and providers.conclusion: the committee believes that greater oversight of the operators will not be necessary so long as they operate effectively and reliably and continue to improve the root name systemõs reliability and capability.conclusion: the committee believes that in the longer term it is desirable for there to be more formal coordination of the operators and thaticann would be the most appropriate organization to assume the coordination role.recommendation: icann should work with the root name serveroperators to establish a formal process for replacing operators that directly engages the remaining root name server operators.for example, should one of the current operators withdraw, icanncould convene the remaining root name server operators as a selectioncommittee to recommend a replacement operator to icannõs board. theboard could after appropriate consideration (and after approval by thedoc or a future stewardship organization, if any) then direct iana toenter the address of the new operator in the root zone file.conclusion: any central source of funds to compensate all the rootname server operators for their services is likely to carry an unacceptableregulatory or control role for the funding organization and reduce the diversity of support that is one of the strengths of the current arrangement.recommendation: the present independent funding arrangementsfor the root name servers are advantageous and should continue, becausethe multiplicity of sources contributes to the resilience, autonomy, anddiversity of the root name server system.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.230signposts in cyberspace5.4regulation of generic toplevel domainsissues: can and should new gtlds be added? if so, how many new gtldsshould be added, and how fast? what types should they be, and how should theyand their operators be selected?icann has faced a demand for the addition of gtlds since its establishment (see section 2.7). at that time, the demand for .com addresseswas growing very rapidly. some applicants that were unable to obtaintheir preferred domain names within .com or .net called for the creationof new tlds in which they might register. potential registry operators,seeing an opportunity for profit in the rapidly growing market for domain names, added their strong voices to the cry for more tlds.although the demand for domain names is not growing as rapidly asit did in those very early days, there remains a strong interest in addinggtlds to the root as well as a strong counterbalancing interest in moderating such additions.in response to the pressure to add new gtlds and to a requirement inits 2003 mou with the doc, icann agreed60 to deliver by september2004 a comprehensive evaluation of:¥òthe potential impact of new gtlds on the internet root serversystem and internet stabilityó and¥òpotential consumer benefits/costs associated with establishing acompetitive environment for tld registries.óit also committed to:¥òcreation and implementation of selection criteria for new and existing tld registries, including public explanation of the process,selection criteria, and the rationale for selection decisions,ó and¥òrecommendations from expert advisory panels, bodies, agenciesor organizations regarding economic, competition, trademark, andintellectual property issues.óto fulfill this commitment, icann at its october 2003 meetinglaunched a strategic initiative to allow new generic toplevel domains.61the initiative comprises two stages intended òto move to the full global60reported in icann board resolutions at the icann meeting in carthage, tunisia, october 31, 2003, available at <http://www.icann.org/announcements/advisory31oct03.htm>.61icann, òicann launches broad strategic initiative for new generic topleveldomains,ó announcement, october 31, 2003, available at <http://www.icann.org/announcements/announcement31oct03.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues231ization of the market for toplevel domains.ó one stage is a comprehensive evaluation that includes:¥an assessment of technical standards to support multilingualtlds,¥an assessment of the introduction of competition into the tldmarket and of possible business models for the tld managerðicann relationship,¥a study of intellectual property issues involved in the introductionof new tlds,¥reports on technical stability issues related to the introduction ofnew tlds, and¥a review of consumer protection issues.these studies were carried out by independent outside organizations62as well as by icannõs security and stability advisory committee.the second stage was an expedited process that was intended to adda new group of gtlds before the end of 2004. in this process, each of thesegtlds would be sponsored by a nonprofit organization representing aspecific community, whose members would be the only ones eligible toregister domain names in it.thus, the question of adding gtlds is timely and open to careful examination. although icann has accepted the view that new gtldsshould be added and is employing one specific means for doing so, it isuseful for a full understanding of the issues involved to take one stepback and consider first the fundamental questions: should new gtlds beadded to the root zone and, if so, how many and how fast? if new gtldsare to be added, what types should they be, and how should they andtheir operators be selected?5.4.1should new gtlds be added? if so,how many new gtlds, and how fast?an increase in the number of gtlds would have technical, operational, economic, and service consequences that would affect domainname registrants, registries, registrars, and internet users generally. thus,responsible decisions about gtld additions should take into account thedifferent potential effects on the several constituencies. in contrast, thepublic discourse and controversy have often been framed narrowlyñ62on august 31, 2004, icann published a report, prepared for it by summit strategiesinternational, entitled òevaluation of the new gtlds: policy and legal issues.ó the reporttouches on the second and third topics in the list of studies for a comprehensive evaluation.it is available at <http://www.icann.org/tlds/newgtldeval31aug04.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.232signposts in cyberspacesometimes considering only one type of effect on one constituency. furthermore, the arguments are often based on assumptions, rather than evidence, and the assertions of one side are often vigorously disputed by theother side.the issue is addressed here broadly in terms of effects as well as constituencies affected, but for simplicity, the multidimensional argumentsfor and against new gtlds are clustered into two groups: (1) technicaland operational performance issues and (2) user needs and economic issues. where relevant evidence is available to support or contradict an argument, it is reported.(note: the amount of space devoted to each argument does not reflect the committeeõs judgment either of its importance or of its credibility. rather, it is a consequence of the material available and the spacerequired to explain it.)technical and operational performance issuesarguments in favoras noted in chapter 3, the root zone file is very small, comprisingdata for 258 tlds and the 13 root name serversñjust over 78 kilobytes intotal. it is searched on the root name servers about 8 billion times per day.the committee did not find any purely technical reasons that the rootname servers could not provide the same level of response with a muchlarger root zone file. indeed, the ability of the .com name servers to respond to billions of queries a day against the .com zone file, with morethan 30 million entries, is a demonstration of the technical capacity thatcould be applied to the root zone, if necessary.nor are there any fixed limits in the design of the dns on the size or therate of addition of domains at any level in the dns hierarchy. any suchlimits would arise from practical matters of implementation and operation.moreover, additions have already been made to the root zoneñboth theseven gtlds added in 2000 and the numerous cctlds added during themid1990s, with no noticeable degradation of root name server performance.arguments againsthowever, there are operational and administrative issues that suggest practical constraints on, at least, the rate of addition of new tlds tothe root zone file, and potentially as well, on its total size. of concern tosome members of the technical community are the number and the rate ofchanges to the root zone fileñboth at the time of creation of a tld (as anew entry into the root zone file) and in support of subsequent changessignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues233(as a modification of an existing entry to accommodate a changed ip address, for example). errors or corrupted entries in the root zone file pose agreater risk of harmful consequences for the dns and internet than doanalogous mistakes made elsewhere in the dns hierarchy. an increase inthe number of root zone file updates increases the probability of inadvertent errors and makes it more difficult to detect them in a timely manner.yet, as discussed in chapter 3, the design of the dns makes heavyuse of address caching. this means that errors at the root will not affect asignificant number of users immediately, but rather will gradually be disseminated as the caches time out. errors at the root zone, while certainlyundesirable, should not have catastrophic consequences and should beable to be caught before they do much significant damage.the administrative procedures for approving additions of new gtlds(see òselecting new tldsó in section 3.4.3) have been much more intensive and extended than those, for example, for adding a new secondleveldomain to one of the gtlds. this has been for technical reasonsñto ensure that the gtldõs name server operations will meet internet standards;for consumer protection reasonsñto ensure that registrants in the newgtld will have reasonable assurance of a competent, reliable, and continuing service; and because of the need to deal with a variety of contending legal and commercial interests. should a high level of scrutiny be required for approving additions of all new gtlds and the ongoingworkload increase as a consequence of the additional gtlds, then the rateof buildup of an adequate administrative staff would also set a bound onthe rate of addition of new gtlds.committee viewin light of these considerations, several members of the committeehold the view that an extremely cautious approach should be taken toward additions to the root zone file. their preference would be for noadditions at all. and they would certainly limit new gtlds to those thatcan be shown to meet an important, unsatisfied need. furthermore, theythink that a process for monitoring root zone operations capable of detecting signs of degradation or instability and of acting to correct their causesmust accompany any process for regular addition of new gtlds.taking into account those views, the committee agreed that if additions are to be made to the root zone, it would be prudent to limit theirrate. after balancing the various considerations and the differing views ofits members, the committee concluded that the addition of tens of newgtlds per year for several years would be unlikely to jeopardize the technical or operational stability of the dns. the committee accepted thatadditions at a faster rate would unacceptably increase the risk at present.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.234signposts in cyberspacehowever, further refinement of the practices for making and distributingroot zone file changes (as discussed in òmaintaining the root zone fileñverisignó in section 3.3.3), the addition of administrative capacity toicann, and further closely monitored experience with gtld additionscould provide the basis for largerscale annual increases in the future,should the demand be shown to exist.conclusion: considering technical and operational performancealone, the addition of tens of gtlds per year for several years would poseminimal risk to the stability of the root.user needs and economic issuesarguments in favora principal argument for adding new gtlds is that only by openingthe market for gtld registry services would a true identification of domain name registrant (user) needs be possible, because only then wouldentrepreneurs and other innovators have the opportunity to offer a rangeof gtlds to potential registrants. two indicators of the potential demandfor new gtlds are the more than 3 million registrants in .info, the millionor so registrants in .biz, and the more than 100,000 registrants in alternatetlds offered by new.net, which are readily accessible from only 25 percent of the internet (see òunique characteristicsó in section 3.3.1).while the advocates of adding gtlds do not claim to know when orif the user demand for new domains would be completely filled, theyaccept the inevitability of some new gtlds failing. in their view, suchfailures would be a reasonable price to pay for clarifying and meetinguser needs, many of which may be latentñunrecognized even by the potential beneficiaries. advocates of this position, however, generally acknowledge that to protect domain name registrants in new gtlds, registry contracts should require zone file escrow and agreements with otherregistries to assume responsibility in case a gtld were to fail.one question that arises in this context is whether new gtlds will provide new users opportunities to register their desired (secondlevel) domainnames or whether gtld proliferation will simply result in existing users registering similar domain names in all gtlds for which they are eligible. in thelatter case, for example, .biz would simply replicate .com, duplicating registration and administrative costs without any associated benefits.6363indeed, there may be significant costs in addition to those associated with registering inmultiple domains as cybersquatters expend resources in order to acquire names that theymay later sell for prices that substantially exceed the costs of registration.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues235at least as judged by the experience of the operation of the .biz domain,there is only a small amount of duplication. to begin with, no more than avery small fraction of .com registrants have chosen to register the same domain name in .biz, since in february 2005 there were more than 33 millionnames registered in .com but just over 1 million names registered in .biz.64moreover, even when the same name has been registered, the identity of the.biz and .com registrants is the same in only 25 percent of those cases, according to an earlier study.65 thus, the .biz gtld has, in fact, offered a substantialnumber of new registrants opportunities to register their desired domainnames, with proportionately little duplication of .com domain names.a demand for additional gtlds could arise from the implementationof internationalized domain names that use nonroman scripts (see section4.3). although much of the early activity has been in registering secondlevel domain names in nonroman scripts in existing tlds, that usagecould develop into a demand for gtlds in nonroman scripts. this demand could be quite large, given that the number of nonenglishspeakingusers of the internet is already very large and is growing rapidly.a new gtld (e.g., .health) might induce additional valueaddedservices at the second level (e.g., example.health) that would be more accessible than the currently possible thirdlevel services (e.g., example.health.com ) or secondlevel services (e.g., examplehealth.com).another reason for favoring the addition of gtlds is economic. first,it would open the opportunity for new participants to enter the registryservices market, promoting both price and nonprice competition (whichincludes diversity in naming methods) among registries. the august 2004icann report on the policy and legal issues of new gtlds noted thatòthe icann community now has several registry operators, as opposedto just one provider, which is [sic] able to operate a global registry ofsignificant scale. . . . today the three companies [verisign, afilias, andneulevel] compete for the ability to provide registry services to new andexisting tlds, both in the gtld and cctld markets.ó66 second, it wouldencourage innovation. according to the report, òthe new gtlds have hadan impact beyond their size or market share . . . in terms of innovation.ó67furthermore, a steady and foreseeable supply of new gtlds couldreduce the incentive to cybersquat by lowering the scarcity value of spe64see <http://www.zooknic.com/domains/counts.html>, accessed on june 18, 2005.65see jonathan zittrain and benjamin edelman, òsurvey of usage of the .biz tld,ó available at <http://cyber.law.harvard.edu/tlds/001/>, accessed july 22, 2002. this estimate isbased on a random sample of 823 .biz domain names, where the identities of registrantswere matched using zip codes, name server secondlevel domains, email addresses, or somecombination thereof.66summit strategies international, òevaluation of new gtlds,ó 2004, p. 111.67summit strategies international, òevaluation of new gtlds,ó 2004, p. 111.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.236signposts in cyberspacecific names and making it more costly to hoard names. thus, the potentialvictims of cybersquatters may save money should new gtlds be added.new gtlds would also enable the establishment of additional restricted name spaces, whose registrants would be authenticated by theregistry to be members of a specific class and who might also have toaccept specified rules of conduct. these would be like the existing sites.edu (primarily for accredited institutions of higher education), .pro (forprofessionals), and .museum (for the museum community). possibilitiesinclude .kids (for kidsafe sites) and .health (for qualified health care providers). in addition, many organizations, especially medium and largeones, may want their own gtlds, enabling their computer services toassume responsibility directly for functions they currently must acquireand pay for from tld registries. for example, ibm might prefer to ownand operate the .ibm tld, rather than rely on the .com registry for servicefor ibm.com.arguments againstthere are strongly held opinions against opening the market in gtldsas well.68on the question of user needs, opponents of gtld addition contendthat the existing selection of gtlds (and cctlds that act like themñseeòrecharacterizing tldsó in section 3.4.1) have met registrant needs quitewell and are capable of continuing to do so. they perceive few signs thatmany prospective domain name registrants have an unmet need for newgtlds that could not be satisfied in one of the available secondlevel domains. whatever truly unmet needs there might be are not sufficient, intheir view, to justify even a small threat to the reliable operation of thedns. the august 2004 icann report on the policy and legal issues ofnew gtlds notes that, despite the entry of the new gtlds, .com, .net,and .org still have more than 93 percent of the registrations in all gtlds.69it concludes that ò.com remains the tld of first choice for a majority ofgtld registrants, including new registrantsó70 and that a òchoice of tldshas thus far been unable to overcome the advantages the .com tld enjoys.ó71 nonetheless, the report concludes that òthe new gtlds presented68see, for example, tim bernerslee, ònew top level domains considered harmful,óapril 30, 2004, world wide web consortium, design issues, available at: <http://www.w3.org/designissues/tld>.69summit strategies international, òevaluation of new gtlds,ó 2004, p. 96.70summit strategies international, òevaluation of new gtlds,ó 2004, p. 109.71summit strategies international, òevaluation of new gtlds,ó 2004, p. 110. nonetheless, thereport notes the views of some members of the ònoncommercial communityó who believe that,although overcoming the advantages of .com would be difficult, it would not be impossible.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues237registrants with significantly greater choice, at least in terms of initial registration.ó72 further, the report concludes that òthere are indications thata respectable number of the new gtld registrations have attracted newusers to the dns, and that these new registrations are being activelyused.ó73from the perspective of the user seeking a site through guessing orrelying on a possibly faulty memory, the addition of gtlds increases thenumber of possible domain names to try. for example, is itòexample.comó or òexample.bizó or òexample.infoó? this is already aproblem, but it could be exacerbated by the addition of new gtlds.there are economic counterarguments as well. trademark holders,for example, fear that they would face the possible need to defensivelyregister (to preclude cybersquatting) in all unrestricted gtlds, incurringan expense that could be substantial, particularly for small organizationsand individuals. however, the august 2004 icann report concludes thatòthe startup mechanisms proved generally effective in protecting legitimate trademark owners against cybersquatting.ó74 at the same time, thereport notes òa contradiction between . . . trying to attract new users anduses to the dns, and allowing trademark holders to claim priority registration of the same names in new tlds.ó75 and it observes that the number of sunrise registrations76 in the new gtlds that used such a processòhas turned out to be much smaller than anticipated.ó77more generally, holders of existing domain names that have built areputation could find the value of that reputation reduced as similar sitesproliferate. for example, the owner of a discount ticket web site mightfear that some of his customers would become confused and unable toremember whether it is òcheaptickets.comó or òcheaptickets.bizó oròcheaptickets.traveló that is known for offering the cheapest tickets.furthermore, current registry services stand to lose some of their economic (scarcity) value as a result of the entry of new tld registry serviceproviders. so trademark holders, the owners of existing sites, and currentregistry services all fear possible additional costs or losses of value if newgtlds are added.opponents are also concerned that each increment of new gtldscould be followed by a period of administrative instability, set off by a72summit strategies international, òevaluation of new gtlds,ó 2004, p. 97.73summit strategies international, òevaluation of new gtlds,ó 2004, p. 99.74summit strategies international, òevaluation of new gtlds,ó 2004, p. 79.75summit strategies international, òevaluation of new gtlds,ó 2004, p. 80.76see òpossible remedies to conflicts over namesó in section 3.5.2.77summit strategies international, òevaluation of new gtlds,ó 2004, p. 81.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.238signposts in cyberspacerace to register potentially valuable domain names and the flurry of administrative and dispute resolution activity that it induces.in the extreme, if unlimited additions were permitted (say, for example, .ibm, .ge, .sony, .siemens, and so on), the root zone could becomecomparable to the .com gtld, which would seem to have uncertain benefits, while threatening considerable upheaval in the technical operationsof the dns and administrative processes of icann. however, the imposition of a restriction on the allowable number and rate of additions, assuggested by technical and operational considerations, would alleviatethis risk.committee viewafter taking into account the user needs and economic benefits arguments for and against potential gtld additions, the committee remaineddivided on the addition of new gtlds. some members felt strongly that onbalance those needs and benefits were not great enough to risk the technicaland operational stability and reliability of the dns. other members believed that within the limits of tens of new gtlds per year it was worthwhile to enable some form of market process to be used (with proper safeguards, discussed below) to determine how extensive the need might be.conclusion: neither the user needs and economic benefits argumentsin favor of nor those against additional gtlds are conclusive.in addition to the question of whether and how many gtlds shouldbe added is the question of how often. thus far, additions have occurredat an irregular and unpredictable pace: the initial group of 8, 7 more in2000, and up to 10 more in 20042005. that uncertainty makes it difficultfor current and potential gtld registries to develop and operate according to reasonable business plans and has the effect of overvaluing newgtlds (because of the uncertainty of whether and when there will be anyfurther additions). a regular schedule would enable those who lose outone year to anticipate additional chances in the next year, reducing theprice they would be willing to pay (in a gtld auction, for example) werethere no certainty about the addition of gtlds in the near future.recommendationsrecommendation: if new gtlds are added, they should be added ona regular schedule that establishes the maximum number of gtlds (onthe order of tens per year) that could be added each time and the intervalbetween additions.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues239recommendation: since the effect of continuing increments of newgtlds on the performance and stability of the root zone is not known,and the consequences of reduced performance and instability can be great,it would be prudent to accompany any process of addition with a processfor monitoring and identifying any technical or operational problems thenew gtlds may cause.recommendation: a mechanism to suspend the addition of gtlds inthe event that severe technical or operational problems arise should accompany a schedule of additions. it should explicitly specify who has theauthority to suspend additions and under what conditions.recommendation: a neutral, disinterested party should conduct anevaluation of new gtlds approximately 1 or 2 years after each set of newgtlds is operational to make recommendations for improving the process for selecting and adding gtlds.as noted in the introduction to section 5.4, icann has included aspart of its strategic initiative the need for an evaluation of the additionsmade in 2000. the committee believes that icann should contract withneutral, disinterested parties to conduct such evaluations for every subsequent addition of gtlds.5.4.2if new gtlds are to be added, what types should they be,and how should they and their operators be selected?if new gtlds are to be added to the root zone, there remain the questions of deciding which types of gtlds should be added and which entities should be selected to operate the associated registries.in some selection processes used in comparable circumstances, whatshould be added and who should be their operators are considered completely separately.78 in other cases, what should be allocated and to whomit should be assigned have been determined in the same proceeding. inthe case of the dns, both types of approach have been used. when sevennew gtlds were authorized in 2000, icannõs selection process combinedthe choices of the types and the identities of the registries, so that a particular entity was selected as a registry because icann favored the type78in radio frequency management, this is referred to as the distinction between òallocation,ó which denotes setting aside blocks of frequencies in specific geographic areas for aparticular use, and òassignment,ó which denotes the award of these frequencies to particular users. of course, it may be possible to dispense with the determination of the type ofnew entrant and to limit the process to determining which entrants to allow.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.240signposts in cyberspaceof service it promised to provide. in contrast, the decision as to whichorganization would operate .org upon its transfer from verisign was independent of the legacy decision to have such a gtld.whatever process is used to make such decisions, it should at a minimum satisfy four fundamental criteria:1.fairness.the process should not favor an applicant or class of applicants over others.2.transparency.the reasons for the outcomes should be clear to allinvolved.3.efficiency.the process should not place a heavy burden on the applicants or the selection group.4.economy.the process should not impose undue costs on the applicants or the administrator of the selection process.the discussion that follows provides a context against which to evaluateicannõs current round of selections and the process that it is following.which types of gtlds should be added?there are three approaches to determining the types of gtlds. theyderive from different views about the desirable structure of the gtldname space.taxonomic/restrictedthe first approach holds that the gtlds should adhere, as much aspossible, to a taxonomic structure. its adherents believe that such a structure can assist internet navigation by serving as a highorder directoryand that it can channel and bound the addition of gtlds. in an idealtaxonomic structure, each gtld would be restricted to members of a specific class, there would be a gtld for each appropriate class of members,and each possible member would fit into one and only one class.the current structure of gtlds is already far from an ideal taxonomy.although the names of the three largest gtlds, .com, .net, and .org, imply a restriction to commercial, networking, and noncommercial registrants, respectively, in practice the registries have not enforced such restrictions. moreover, there is nothing to exclude a web site having, say,both .org and .edu domain names, even if both were strictly restricted toappropriate registrants. so the best that an adherent to this view couldhope for would be that each new gtld would be restricted to a specificclass whose membership could be inferred from the domain name (e.g.,names such as .travel, .xxx, .library, and .health).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues241the òtaxonomistsó favor an extension of the gtlds only in the restricted form.79 in this case, each new gtld would need a registry willingand able to enforce the specific restrictions, which can be arduous andseverely limit the rate of registration. for example, the .pro registry, whichwas formed in 2000, began registration only in the spring of 2004. it islimiting its rollout to the rate at which it can gain access to records ofregistered professionals so that it can identify those that it will permit tohave a .pro domain.although it is no longer feasible to impose a full taxonomy on thedns, this approach can strengthen its implicit directory function by ensuring that all new gtld names clearly identify a restricted class of secondlevel domains. this is the approach taken by icann in adding newgtlds in 20042005 as described below.if there are benefits to using a tightly controlled taxonomy, there isnothing to stop this from occurring at the second level. for example, therecould be a gtld called .industry, with secondlevel domains describingvarious instances of industries: travel.industry, health.industry,automobile.industry, and so on.marketdeterminedthe second approach favors allowing the processes of supply anddemand to determine how many and which domains are offered, first bythe willingness of an operator to offer it (supply) and second by the willingness of those desiring domain names to register in it (demand). underthis approach, it would be up to the gtld registry to decide whether ornot it would restrict registrations to members of a certain group.to the advocates of this approach, opening a new gtld and thenclosing it down because of an insufficient number of registrations wouldbe an acceptable outcome, assuming (as noted above) that zone file escrow and alternate registry provisions could be made to protect domainname holders for some period of time after the closure.in contrast to the taxonomic/restricted view, the marketdeterminedapproach holds that attempting to structure or control the gtld namespace provides little navigational value in a world of search engines andother navigational aids. many also doubt the taxonomic/restrictedapproachõs practicality. they believe that a marketdriven name space ismore flexible and reflective of usersõ desires than is adherence to a limiting structure imposed by some authority.79see, for example, business constituency, òa differentiated expansion of the namesspace,ó icann position paper, december 2002, available at <http://www.bizconst.org/positions/bcpositionpapernewgtldsv2.doc>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.242signposts in cyberspaceregulatedthe third approach takes a position intermediate between the firsttwo. it would add new gtlds, both restricted and not, based on thequalifications and justifications presented by those who propose to runthem, on a casebycase basis. an administrative body, presumablyicann, would exercise judgment to select which new gtlds wereadded and who would operate them. this is effectively the approachtaken by icann in 2000 when it added seven new gtlds, selectedfrom the more than 40 applicants because icann favored the tldname and the type of service proposed, as described in ònew gtldsóin section 3.4.3.how should the operators of gtlds be selected?the necessity for selection arises when the number of candidates for aresource exceeds the quantity of the resource that is available, when candidatesõ qualifications to receive the resource must be validated, or both.three common forms for the selection process in situations comparable toselection of new gtlds and their operators are comparative hearings,auctions, and lotteries.comparative hearinga comparative hearing is an administrative process in whichwouldbe entrants attempt to convince the decision body that they,and their proposed service, are qualified for selection in competitionwith other candidates. it is the form that has been and is being used byicann. comparative hearings typically feature discretionary entry,merit assignment, and heavy regulation. such hearings can take intoaccount a large number of factors, draw on a wide range of expertise,offer opportunities to learn from experience, and enable judgment tobe employed. through use of a nonrefundable application fee, such asicann has required, they can reduce speculative applications and beselffunding.there are downsides to comparative hearings, however, as they canbe subject to capture by interest groups. furthermore, the real decisionprocess may not be transparent, and thus may be perceived as arbitraryand unfair, especially by the losers. also, decision quality is highly dependent on staff and decision maker competence, while the negotiationand oversight of contracts can be timeconsuming and expensive. in addition, depending on the nature of the process and the stakes involved, application costs can be very high.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues243auctionin the basic auction model, the highest bidder wins, although participation in the auction might be limited to those meeting a minimum set ofqualifications. the advantages of auctions are that they are fair and transparent processes that reflect the economic value perceived by applicants,they may be designed to selffund the process, and they discourage anexcessive number of speculative applications. however, the tradeoffs withthe auction model are that it tends to favor wellfunded applicants (whichcould be corporations or nonprofits) and thus does not necessarily reflectsocietal value, only economic value.in principle, auctions could be designed to choose winners on the basis of who can best minimize prices (say, for example, the price of a domain name registration). however, in such cases, it may be impossible toprevent the winning bidder from later claiming (successfully) that changing conditions justify a higher price.to the extent that in a specific situation social welfare extends beyondeconomic considerations, auctions, at least in their pure form, become lessappealing.lotterywinners in the lottery selection model are determined through arandom choice from all entrants, each of which may be required tomeet some minimum qualifications in order to participate and would(in contrast to a fundraising lottery) be restricted to one entry per entity. the biggest advantage of lotteries is their transparency: they arefair and transparent, giving all entrants an equal chance regardless ofmeans. lotteries can also be selffunding if a charge is made for eachòticket.ó although the cost to a given entrant may be quite small, lotteries can be expensive to society in the aggregate because they canattract a very large number of participants.because it can be difficult to determine whether an entry to thelottery is from a distinct qualified entity, a lottery can be gamed by oneparticipant obtaining multiple entries under different òlegitimateóguises. moreover, unless the qualification criteria are very restrictiveand carefully vetted, participants may not even have the financial ortechnical capacity to operate a service if they win, and the winnersmay simply sell the service to another entity for a significantly greaterprice. in the latter case, the lottery is turned into an auction, with theproceeds going to the lottery winner rather than the organization holding the lottery.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.244signposts in cyberspacecombination methodsit is also possible to integrate two or three of the basic methods into avariety of combination methods, some of which are described below.what selection process should be used?there is a widely held view that the process employed by icann in2000 to add new gtlds was faulty. there is much less agreement abouthow to improve it, although the elements from which an alternative canbe developed are described above. in july 2004, the organization for economic cooperation and development (oecd) issued a report that describes and compares two of those elements, comparative selection (hearing) and auctions, as means for allocation of gtlds.80 what follows is adescription of several of the alternatives that have been specifically suggested, beginning with the process used in 20042005 by icann for thenext round of additions.alternative a: sponsored gtlds selected bymodified comparative hearing (20042005)description.icann is using a modified comparative hearing approachto select new sponsored gtlds. each new gtld will be restricted to registrants from a welldefined and limited community and managed by asponsoring organization with ongoing policyformulation responsibilityfor the gtld. the sponsoring organization will select the registry operator and, to some degree, establish the roles played by the registrars andtheir relationships to the registry operator.81the request for proposal, evaluation, and selection processes aremodifications of those used in 2000 to select seven new gtlds. nonrefundable application fees of $45,000 have been charged to cover the costsof the selection process.the eventual registry agreement will be similar to those entered intoby the .museum, .coop, and .aero registries. however, the august 2004report published by icann that evaluated the policy and legal issues of80working party on telecommunication and information services policies, ògeneric toplevel domain names: market development and allocation issuesó july 13, 2004, oecddirectorate for science, technology and industry, available at <http://www.oecd.org/dataoecd/56/34/996948.pdf>.81for full details, see icann, ònew stld application. part a. explanatory notes,ódecember 15, 2003, available at <http://www.icann.org/tlds/newstldrfp/newstldapplicationparta15dec03.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues245new gtlds concluded that òwhile it is understandable for icann to havewished to err on the side of caution as it undertook gtld expansion . . .the resulting legal framework is cumbersome.ó82 it concludes that òthenumber and length of appendices [in agreements between gtlds andicann] could be reduced in a future round. a streamlined base agreement with perhaps a few appendices could provide a more workable format that also preserves the critical elements of registry performance andmandates compliance with icann policies.ó83selection is to be determined by the degree to which independentevaluators judge the applicant to have met icannõs requirements in fourmajor categories, which are divided into 15 subsidiary categories:1.sponsorshipa.definition of sponsored tld communityb.evidence of support from the sponsoring organizationc.appropriateness of the sponsoring organization and thepolicy formulation environmentd.level of support from the community2.business plan informationa.business planb.financial model3.technical standardsa.evidence of ability to ensure stable registry operationb.evidence of ability to ensure that the registry conforms withbestpractices technical standards for registry operationsc.evidence of a full range of registry servicesd.assurance of continuity of registry operation in the event ofbusiness failure of the proposed registry4.community valuea.addition of new value to the internet name spaceb.protection of the rights of othersc.assurance of chartercompliant registrations and avoidance ofabusive registration practicesd.assurance of adequate disputeresolution mechanismse.provision of icannpolicycompliant whois servicein light of the prior discussions of the types of gtlds to be added andtheir potential value, it is useful to examine the specifics under topic 4a,addition of new value to the internet name space. the subtopics are:82summit strategies international, òevaluation of new gtlds,ó 2004, pp. 130131.83summit strategies international, òevaluation of new gtlds,ó 2004, p. 131.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.246signposts in cyberspace1.name value. the proposed name must be of broad significance andestablish clear and lasting value. it should categorize a broad and lastingfield of human, institutional, or social endeavor or activity. it should represent an endeavor or activity that has importance across multiple geographic regions.2.enhanced diversity of the internet name space. the tld must create anew and clearly differentiated space and satisfy needs that cannot bereadily met through existing tlds. the proposed tld should enhancecompetition in registry services and should attract new suppliers and usercommunities to the internet.3.enrichment of broad global communities. the tld should have broadgeographic and demographic impact. òsignificant considerationó will begiven to those gtlds that serve larger user communities and attractgreater numbers of registrants. òconsiderationó will be given to thosegtlds whose charters have relatively broader functional scope.these specifics, together with the sponsorship requirement, indicatethat icann is adhering to a taxonomic/restricted approach in this selection, not allowing the tld applicant to simply let the market decide whichtld names will succeed, but requiring that a gtld name should categorize a òbroad and lasting field of human, institutional, or social endeavoror activity . . . that has importance across multiple geographic regions.óten proposals84 were submitted by the march 2004 deadline. evaluation of the proposals was carried out by teams external to icann and,therefore, not involved in icann activities or subject to icann politicalpressures. each evaluation team comprised three members: a technical, afinancial, and a sponsorshipandotherissues evaluator. the evaluators,whose identities were kept secret during the process, were selected andmanaged by an outside firm.85 the evaluation teams made recommendations about the preferred applications from among those that were successful in meeting the selection criteria. some proposed domains met allof the criteria and entered a contract negotiation with icann staff. otherproposals did not meet all the criteria, were sent back to the sponsors withsuggestions for improvement, and were resubmitted. the result is thatnew gtlds will be announced one at a time and not all at once as in 2000.in october 2004, icann announced that it was negotiating with two prospective new gtlds: .post and .travel; in december 2004, it began negotiations with .mobi and .jobs. in march 2005, icann announced the84the list is available at <http://www.icann.org/tlds/stldapps19mar04/stldpubliccomments.htm>.85summit strategies international in washington, d.c. see sarah lai stirland, òdomainname registry expansion process underway,ó national journal tech daily, may 26, 2004.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues247completion of negotiations with .jobs and .travel, and in april 2005 theboard announced their designation.evaluation. although icann adhered to the comparative hearing approach in this selection process, it significantly reduced the use of staffand board judgment and relied instead on the judgment of independentoutside evaluators using an explicitly defined set of criteria. by doing soand by giving applicants the opportunity to revise and resubmit their applications, icann increased the apparent transparency (although keeping evaluators anonymous) and apparent objectivity of the process (although using criteria subject to a wide range of discretion), and reducedthe potential for disappointed applicants to challenge the scores awardedby the evaluators.alternative b: unlimited gtlds awarded firstcome,firstserved to qualified sponsors (2003)description.almost at the opposite extreme from the preceding approachlies a proposal by ross wm. rader in which an undetermined number ofnew gtlds would be awarded on a firstcome, firstserved basis to approved òdelegantsó that would in turn contract with icannaccreditedòoperatorsó for the daytoday operation of the gtld.86the delegant would be the òpolicy coordinator for the gtld that ensures that the registry operates in a manner that benefits its target community.ó a delegant would be approved by icann on the basis of fourcriteria: (1) the requested gtld name is not confusingly similar to an existing gtld name; (2) the delegant has a satisfactory plan specifying allsignificant operational policies; (3) an accredited operator is willing tomanage the gtld; and (4) the delegant yields rights in the gtld name sothat it can be transferred by icann to a new sponsor if required.the operator would perform the registry functions. to be accreditedby icann, the operator would have to satisfy the minimum standardsfor technically operating a registry. there would be no limitation on thenumber of gtld registries an accredited operator could contract to run.evaluation.alternative b lies squarely in the market determinationcamp, both with respect to determining how many gtlds there should beand who should operate them and with respect to the organization of86ross wm. rader, òa sustainable framework for the deployment of new gtlds part i,ócircleid, february 26, 2003, available at <http://www.circleid.com/article/100010c/>;and part ii, march 26, available at <http://www.circleid.com/article/108010c/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.248signposts in cyberspacegtld names. in fact, it essentially allows there to be an unlimited numberof gtlds, simply determined by the number of delegants who qualify. itdoes not even specify a limit to the rate of addition of new gtlds. this process could be combined withñfor exampleña policy of adding x new gtlds per year by proceeding down the list of firstcome, firstserved requests and filling them as slots become available. but that raisesthe question of how to actually implement a firstcome, firstserved process. how would all the essentially simultaneous electronic entries submitted at the opening instant be prioritized? if a random selection were tobe used, for example, then this process would becomeñat least initiallyña lottery.nor does the proposal specify a process for resolving conflicts thatmight arise with trademark holders if, for example, someone other thansony wished to register .sony as a gtld. presumably, however, somevariant of the sunrise procedures used to protect trademark holders whenthe .biz and .info domains were introduced could be used in this instance.alternative c: fixed number of gtlds annuallyawarded by auction and lottery (2003)description. mueller and mcknight87 have proposed an auction/lotteryprocess to award a limited number of new gtlds each year.88 no structure would be imposed on the specific gtlds awarded, resulting in asupplyanddemanddriven approach to the types of gtld names accepted.forty new gtlds would be made available for award each year. thatnumber was chosen based on advice from members of the technical community with the goals of retaining the hierarchical structure of the dnsand avoiding the introduction of errors into the root zone through toomany changes, made too fast. although 40 was the number chosen for theproposal, any number up to about 80 would be compatible with the authorsõ understanding of the advice they received.the 40 new gtlds would be divided into two tranches: 30 would betargeted for commercial applicants (but open to noncommercial as well),which could apply for any number of tld names but be awarded no87milton l. mueller and lee w. mcknight, òthe post.com internet: toward regular andobjective procedures for internet governance,ó syracuse university, syracuse, new york,august 2003, available at <http://dcc.syr.edu/miscarticles/newtlds2mmlm.pdf>.88a similar auction model has been proposed in karl manheim and lawrence solum,òthe case for gtld auctions: a framework for evaluating domain name policy,ó research paper no. 200311, loyola law school, los angeles, calif., march 2003, available at<http://papers.ssrn.com/sol3/papers.cfm?abstractid=388780>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues249more than 2; 10 would be reserved for noncommercial and lesser developed country (ldc) applicants, which could apply for and be awardedonly 1 name. each applicant would pay a modest application fee, estimatedby mueller and mcknight at $1000, to cover icannõs costs of the selectionprocess. the authors leave open the question of whether applications shouldinclude a fitness disclosure and statement of financial capability to operatea registry or association with an already accredited registry.the 10 noncommercial gtlds would be allocated first, if necessary,by a random selection process, such as a lottery. to avoid possible abuse,the resultant tld allocations could not be sold or transferred to commercial entities.the selection of commercial gtlds would follow. if there were morethan 30 commercial (and other) applicants, the selection would be madeby a simultaneous multipleround webbased auction, with each bidderknowing whether it is in the top 30 or not at every time, just as with ebay.when the auction period ended, the winning bidders would pay theamount of the lowest successful bid in order to keep auction prices at areasonable level. however, should there be multiple bidders for the samegtld, such as .sex, the high bidder would receive the gtld and pay theamount bid by the secondhighest bidder. having a predictable annualincrement in gtlds would also be expected to relieve some of the pressure on the auction prices.if there were 30 or fewer eligible commercial applicants, each wouldpay icannõs reserve price, which would be fixed to cover the costs of theauction and of adding new names to the root. (note that if, as some claim,there is only a limited demand for new gtlds, this would be the outcomein the first, and possibly only, auction.)mueller and mcknight suggest that the proceeds of the auction (orthe reserve price) go to maintaining and managing the root, with a portion reserved for the root name server operators. (see section 5.3.2.)after the award of the gtlds, there would be a period during whichthe gtld names could be challenged on intellectual property grounds orbecause of possible confusion with another gtld. the udrplike processwould be used to resolve such challenges.the winning gtld applicants would enter into standardized anduniform registry agreements with icann that would require adherenceto a minimal set of icanndefined technical specifications and conformity to existing icann policies. they would be required to meet standards for transferring a zone file that would allow the domain to be maintained if the registry failed.evaluation.the result of the mueller and mcknight proposal would be amarketdetermined structure of the dns name space, presumably resignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.250signposts in cyberspacespondingñat least for commercial tldsñdirectly to the supplierperceived demand for new tlds. and except for the limitation on the rate ofadditions and the division between commercial and noncommercial/ldc awards, this is also a clear expression of the marketbased approachto gtld operator selection.those who favor a purer marketbased approach could argue againstthe commercial/noncommercial/ldc division on the grounds that ldcsalready have countrycode tlds and that just as with the allocation ofother goods (e.g., office space, equipment, personnel) there is no need tofavor noncommercial organizations, which should be capable of raisingfunds to acquire a gtld if they need one.consistent with its òlet the market decideó approach, this proposaldoes not specify any restrictions on the registration practices of theawarded tlds except that noncommercial/ldc tlds cannot becomecommercial.alternative d: differentiated expansion of gtlds with selection bycomparative hearing (2002)description.in 2002, the business constituency (bc) of icann proposedthat all future expansion of gtlds should occur within the framework ofa previously agreed set of principles.89 in its view:given that there is pressure on icann to introduce additional names,the bc supports the development of a logical expansion, which will result in a name space with added value, rather than the cloning of theexisting space. such a valueadded space will create differentiation andreduce the need for entities to defensively register.usersñregardless whether they are businesses, nonprofit organizationsor individualsñwant certainty. spending time searching is not costeffective. the user community needs a certain process for identifying prospective names and a certain process for selecting sponsors/registries tooperate those names.90under this approach all new domain names would have to satisfy sixprinciples:1.differentiation: be clearly differentiated from other gtlds,2.certainty: give the user confidence that the name stands for what itpurports to stand for,89business constituency, òa differentiated expansion of the name space,ó 2002, p. 1.90business constituency, òa differentiated expansion of the name space,ó 2002, p. 1.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues2513.honesty: avoid increasing opportunities for bad faith entities thatwish to defraud users,4.competition: create valueadded competition,5.diversity: serve commercial or noncommercial users, and6.meaning: have meaning to its relevant population of users.91in the view of the bc, òthe principles . . . determine a taxonomized ordirectorystyle domain name structure. . . . the structure does not imply arapid expansion. the choice of one name will preclude future nondifferentiated choices.ó92 the bc also argues that all new gtlds should beboth sponsored and restricted. only bona fide members of the targetgroup would be able to register in a gtld. the sponsor would be responsible for ensuring that the registered names are appropriate for the registrants and do not infringe on othersõ intellectual property. the bc believes that this approach òsimultaneously solves three intellectualproperty issues. cyberpirates will not be able to obtain the names of others. there will therefore typically be no need for costly defensive registration. new whois databases will be verified and therefore accurate.ó93the bc proposal recommends separation of the functions of sponsorand registry, similar to but less specific than the rader proposal (alternative b) described above. the goal is to create a set of qualified registriesthat can operate any number of gtlds under contract with the gtldsponsor. should a registry fail, it could readily be replaced by anotherqualified registry.evaluation.one goal of the bc proposal is to enhance the role of thedns as a directory service for the internet. (see chapters 6 and 7 for adiscussion of the role of the dns as an internet navigation aid.) its principle of differentiation is intended to avoid the internet usersõ navigationconfusion that might result from overlap among gtlds. but it would haveprecluded the creation of .biz as a way of giving internet providers another chance at a preferred secondlevel domain name that had been registered by someone else in .com. moreover, by emphasizing differentiation, it would limit price competition in favor of nonprice competitionbetween gtlds.the bc proposal is not specific on the rate of addition of new names,other than that it is not necessarily a rapid expansion. nor is it specific onthe process by which sponsors and registries for the new names would be91business constituency, òa differentiated expansion of the name space,ó 2002, p. 1.92business constituency, òa differentiated expansion of the name space,ó 2002, p. 2.93business constituency, òa differentiated expansion of the name space,ó 2002, p. 2.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.252signposts in cyberspaceselected. it is silent on the fact that, as noted above, many of the existingnames would not belong in a strictly taxonomic structure.by requiring that all tlds be sponsored and restricted, this alternative places on the sponsors and registries the responsibility of enforcingintellectual property rights and qualifying an organizationõs orindividualõs right to use a specific domain name. by doing so, it movesfrom ex post to ex ante enforcement of those rights and from consideration of name assignments when an issue arises to examination of everyassignment in advance. this approach can be expected to raise the costs ofrunning a registry and, consequently, to increase the likely registrationfees.comparison of the four alternativesthe four alternatives presented above for adding new gtlds are compared in table 5.3 on two dimensions: desirable structure of the namespace and the means of selecting gtld operators. both the bc and theicann alternatives anticipate only sponsored and restricted gtlds,whereas the mueller and mcknight and the rader proposals allow, butdo not require, them.5.4.3recommendationsicannõs 2004 modification of its comparative hearing process so asto eliminate (or at least significantly reduce) subjective judgments by itsstaff and board and increase the processõs transparency and objectivityhas reduced the potential sources of dissatisfaction with the resultant selections. however, the question still remains open as to whether it is really necessary for icann to qualify new gtlds on such matters as spontable 5.3alternatives for adding generic toplevel domainsmeans of selecting gtld operatorsdesirable structurefirstcome,auctionof name spacefirstservedcomparative hearing(and lottery)taxonomic/restrictedd. business constituencya. icann 2004 additionregulatedicann 2000 additionmarketdeterminedb. raderc. mueller and mcknightsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues253sorship by a community, business and financial plans, and addition ofnew value to the name space.an alternative approach would be qualification of applicants only ontechnical capability, basic financial viability, and adherence to registrantprotection standards and icann policies. then a marketbased selectionprocessñessentially an auctionñcould be used to select among qualifiedapplicants when their number exceeds the number of available slots.recommendation: if new gtlds are to be created, the currently employed comparative hearing or expert evaluation processes should not beassumed to be the only processes for selecting their operators. icannshould consider alternate processes that are less reliant on expert, staff, orboard judgments.recommendation: any gtld auction selection process should bedesigned with reference to the substantial literature on auction design.94the following principal matters will have to be decided:¥what is being auctioned.is it a òslotó that the winner can use for atld with its choice of name and operating policy, or the òright to operateó one of a prespecified list of tld names and policies, each of which issubject to a separate auction? is it an outright sale or the license to operatefor a fixed, potentially renewable term?¥how the winner is chosen.does the high bid win, or the low bid? inthe latter case the bid would be the maximum amount the winner wouldcharge for a basic registration in the tld. (this latter case raises the issueof tightly specifying levels of service so that the bids can be comparable.)¥what is done with the proceeds of a òhigh bid winsó auction.would theproceeds go to cover icann operating costs or be allocated to other organizations, such as the root name server operators or the iab/ietf in support of technical activities related to icann responsibilities?¥how commercial and noncommercial bidders are treated.would theyparticipate equally in the same auctions, or would there be separate selection processes for each?¥what the auction mechanism is.would it be open or closed; single ormultiple iterations; with a reserve price or not; english or dutch;95 and soon?94see, for example, paul klemperer, auctions: theory and practice, princeton universitypress, princeton, n.j., 2004.95in an english auction, participants bid openly against one another, with each bid higherthan the previous one. by contrast, in a dutch auction, the auctioneer begins with a highasking price that is lowered until someone accepts the auctioneerõs price.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.254signposts in cyberspace¥how the bidders are qualified.would it be òno restrictionsó orthrough some combination of technical capability, financial strength, continuity provisions, and so on?¥how many òslotsó or òrightsó a bidder could win.would it be just oneor two or as many as desired?¥how postauction actions by winners are restricted.would it be at all;no resale for x years; no change in policies; and so on?¥how various failure modes are dealt with.what happens if the winnerdoesnõt pay, or doesnõt proceed in a timely manner to set up the domain?what if the winner operates the domain poorly from a technical or ethicalpoint of view?because of the many choices for each of these matters and their manypossible combinations, there can be many different kinds of tld auctionswith different goals and quite different processes. furthermore, as thepreviously cited oecd report96 suggests, there can be various combinations of comparative hearings (say, for qualification of prospective registries) and auctions (where demand for gtlds exceeds the number madeavailable). the exploration of one or more such designs should be included in icannõs evaluation of alternative gtld selection processes.5.5oversight of countrycode toplevel domainsissues: does icannõs responsibility for the root require that it work to increase its oversight of and authority over the cctlds? if so, what form should itsincreased authority take, and how can it be implemented? and to what degreeshould the cctlds accept icannõs authority and participate in its activities?although it does not have much visibility in the united states, theissue of who controls the delegation and redelegation of cctlds is highlysensitive in many parts of the world. on the one hand, some nations97have expressed concern that the u.s. government, acting through icann,could unilaterally remove their cctlds from the root zone file and, therefore, cut them off from the internet. on the other hand, some nongovernmental cctld registries fear that their governments could take over control of the cctlds through the use of icannõs redelegation responsibility.in some sense, these fears are anomalous since although icann has been96working party on telecommunication and information services policies, ògeneric toplevel domain names,ó 2004, p. 5197for example, a brazilian government representative at the february 2004 u.n. meetingon internet governance expressed this concern.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues255given responsibility for management of the root, the vast majority of thetlds in the rootñthe cctldsñhave, for the most part, eluded its directauthority. fewer than half of them (though they include some of the largerones) contribute to icannõs budget. although many participate in theicann meetings (and the special cctld meetings that have occurred atthe same time), they have not fully participated in icannõs decisions.and few have signed agreements with icann. yet, through its control ofthe root zone file, icann does have the sole responsibility for recommending delegations and redelegations of cctlds to the doc. so thepolicy issues that face icann are whether its responsibility for the rootrequires that it work to increase its oversight and authority over thecctlds and, if so, what form such oversight should take and how it canbe implemented. and the complementary issue for the cctlds is the degree to which they should accept icannõs authority and participate in itsactivities. this latter issue is, of course, complicated by the fact that the243 cctlds do not act in concert98 and, as described in òcctldsó in section 3.4.1, represent a very wide range of relationships between government and registry and a very wide range of registry policies.5.5.1current situationas the internet has grown and matured, the role and importance ofcctlds has grown and changed as well, as have their relationships withtheir governments, with their local communities, and with icann.a study in 2002 of the cctlds of 45 countries revealed a wide diversity of relationships between cctlds and the countriesõ governments.99the cctlds of 10 of the 45 countries surveyed were operated by government agencies or departments, 9 by private commercial enterprises, 20 bynonprofit organizations, 5 by academic institutions, and 1 by an individual. of the 35 nongovernmental sponsoring organizations, only 9 hada formal contractual relationship with their governments and 13 had informal relationships, of which 3 were awaiting formalization. three of thecctlds operators were battling government attempts to take over management of the cctld. altogether, only half of the studied cctlds hadformal or soontobe formal relationships with their governments. their98there are, however, a number of regional cctld associations such as centr, the council of european national toplevel domain registries, which has 39 member registries, notall of which are european. see <www.centr.org>. centr has expressed strong positions onicann matters, especially its relationships with the cctlds.99michael a. geist, cctld governance project, 2003, available at <http://www.cctldinfo.com/home.php>. data for this project was obtained from cctld web sites,cctld contacts, and gac representatives between june and september 2002. it was notclaimed to be a representative sample.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.256signposts in cyberspaceformal relationships with icann were also weak. by early 2005, only 12of the 243 cctlds had entered into formal agreements with icann.the consequence of this evolution is that the cctlds operate in a spacethat is only in part under the oversight of any higher authority. a fewcctlds are overseen by their national governments; some have established representative nongovernmental bodies to represent the localinternet community and exercise varying degrees of oversight; some arecompletely autonomous nonprofit bodies that operate voluntarily to meetlocal internet community interests; and some are commercial bodies withsome linkage to the national government.the only body that currently has an opportunity to exercise oversightover all the cctlds is icann. according to icann, it does so on thebasis of rfc 1591 in conjunction with òicp1: internet domain name system structure and delegation (cctld administration and delegation)ó100and the òprinciples and guidelines for the delegation and administration of country code top level domains,ó a revision of principles firstpublished in 2000, which was presented by the governmental advisorycommittee at the icann meeting in april 2005.101the delegations in the early days of the dns placed highest priorityon the responsibility of the manager and less on notions of ownership.however, with the current economic, political, and social importance ofthe internet to all nations, matters of accountability to the local government, local internet community, and the global internet community haveassumed much greater significance. thus, matters of delegation for newcctlds and redelegations of responsibility for existing cctlds have become much more important and, when combined with the many differentcctldgovernment relationships, have also become much more complex.the relationship between cctlds and icann has been difficult fromthe beginning of icann. first, a large number of the cctlds felt no needto contribute to icannõs budget, since they did not think they receivedany corresponding benefits. whether or not true,102 many cctlds believed that 90 percent of icannõs resources were devoted to gtld issues, while they were asked to provide 35 percent of its budget.103 sec100available at <www.icann.org/icp/icp1.htm>.101see <http://gac.icann.org/web/docs/cctld/cctldprinciplesmdp final.rtf>. thisnew, revised statement of principles was published in april 2005.102however, according to a reviewer with knowledge of icannõs activities: òclose to 50percent of icann time/resources has been devoted to cctld and international issues. . . .much of that time is spent on small cctlds (with) complex redelegation issues. a considerable amount of time is also spent liaising with regional organizations and governments . . .participating in international fora.ó103peter de blanc, òcctld briefing document,ó february 19, 2001, available at <http://www.wwtld.org/meetings/cctld/cctldbriefingdocument.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues257ond, many of them resented icannõs major role in deciding on delegations and redelegationsñessentially a policy roleñthat they felt would bebetter performed locally. they also believed that their position as one constituency within icannõs names supporting organization, whose otherconstituencies primarily addressed gtld issues, did not adequately reflect their importance as 243 of the 258 tlds.under its 2003 reorganization (see section 5.2.4, alternative f), icannhas responded to that concern by replacing the names supporting organization with two supporting organizations, the generic names supporting organization (gnso) and the countrycode names supporting organization (ccnso), which formally came into being in march 2004.icann hopes, thereby, to draw the cctlds more actively into its operations and build a stronger basis for their support. furthermore, the revised óprinciples for the delegation and administration of country codetop level domainsó issued in april 2005 by the governmental advisorycommittee addresses many of the concerns of the cctlds and governments.104although icannõs actions may have the desired effect, it is useful tolay out the alternative approaches to providing reasonable oversight ofthe cctlds that have been suggested.5.5.2alternativesicann appears to have four goals for the cctlds. first, that theyoperate according to standards, protocols, and practices that are consistent with the reliable and stable operation of the dns and that allow openconnectivity to and from their registrants and the rest of the internet. second, that they contribute proportionately105 to the overall costs of maintaining the dns root zone file and cctld database in which they arelisted. third, that they accept icannõs authority to decide on delegationsand redelegations when controversies arise. and fourth, that they formalize these expectations by means of an agreement with icann. however,not all of the cctlds accept these as appropriate goals for icannõs relationship with them. what is the current situation?the absence of significant and sustained operational problems sug104see <http://gac.icann.org/web/docs/cctld/cctldprinciplesmdp final.rtf>. thisnew, revised statement of principles was published in april 2005.105in 1999, the task force on funding recommended that the cctlds contribute a 35percent share of icannõs continuing revenue requirements. see <http://www.icann.org/committees/tff/finalreportdraft30oct99.htm#4>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.258signposts in cyberspacegests that the cctlds generally meet the first of icannõs goals, supporting reliable, stable, and open operation of the dns and internet.106however, there is only a modest contribution, at present, from a minority of the cctlds to icannõs budget. (in 20042005, the 243 cctldsõfixed contributions are budgeted at $1.02 million, whereas 10 gtlds areexpected to provide $1.45 million. an additional $14 million is expectedfrom the accredited registrars and gtld registries in proportion to actualregistrations.) so they do not appear to satisfy its second goal.the cctlds represented by the european association of cctld registries, the council of european national toplevel domain registries(centr), favor a much more limited role for icann. in their view,icann should restrict its operational responsibilities to maintaining thecctld database (containing whois information about the cctlds) andthe corresponding root zone file entries and ensuring that the cctldssatisfy minimal technical requirements to function within the globaldns. in their view, delegations and redelegations should be made onlyby icann upon verified instruction from the current manager of thecctld. where there is controversy, it should be referred to a third partyfor resolution. (this approach would be consistent with the proposalsnoted earlier to increase icannõs legitimacy by narrowing its range ofauthority and by delegating sensitive decisions to appropriate third parties wherever possible.)an even stronger view, held by a number of cctld managers, is thatthe maintenance of the cctld database should be the responsibility of acctldsponsored organization independent of icann. this organizationwould receive entries from the cctlds and have full responsibility forupdating the database to reflect the latest information. through a contractwith icann, it would provide the relevant cctld entries for inclusion inthe root zone file, but icann would play no part in deciding what theentries would be. participation in the independent database would bevoluntary for each cctld. if a cctld desired, it could continue to submitinformation directly to icann. as a result, each cctld would have aòvoteó on whose management of the cctld database it favored.thus, although icannõs delegation and redelegation authority is accepted de factoñbecause it currently has sole authority to recommendchanges in the root zone file to the docñthere are many cctlds thatdispute either the way that authority is exercised or that it should be anicann function at all. consequently, its third goal has not been satisfied.106on rare occasions, a cctld may temporarily disappear from the internet as the libyancctld did in april 2004. this is often the result of political or institutional disputes within anation over responsibility for the cctld, with which icann has to deal. see òwho runs thedot ly?,ó libyan jamahiriya broadcasting corporation, 2004, available at <http://en.ljbc.net/online/subjectdetails.php?subid=26&catid=1>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues259finally, as noted above, only 12 agreements have been signed betweenicann and cctlds. so icannõs fourth goal has not been satisfied.it should be observed that a comparable list of the goals of the 243cctlds cannot be provided, since they are consistent neither with eachother nor, necessarily, with icann. as efforts are made to increase thecctldsõ role in icann and icannõs influence over them, many independent cctlds will straddle the fence, playing the various forces offagainst each other until the ambiguities and uncertain power relationships among the u.s. government, their own national governments,icann, and the international community are worked out. because of thediversity of cctld models, histories, and relationships to national governments, it is unlikely that any proposal will satisfy everyone; but someaggressive or lopsided proposals are likely to antagonize all of them.how then can icann best interact with the cctlds? the differinggoals of icann and of some of the cctlds have led to four proposedmodels for icannõs òoversightó of the cctlds.alternative a: òthickó icanndescriptionthe model initially implemented by icann has had icann attempting to achieve its goals by playing a strong role in the oversight of thecctlds: maintaining the cctld database and cctld entries in the rootzone file, making recommendations to the doc concerning delegationsand redelegations, establishing standards for cctld performance, andinducing compliance through mous with the cctld managers or the relevant governments. currently, it is seeking through the newly establishedccnso to engage the more active participation of the cctlds in icannactivities.evaluationby elevating the cctlds to the status of a supporting organization,similar to the gnso, icann has both raised their profile in the organization and given them influence over board membership and icann policy.by engaging them more directly in its governance, it evidently hopes togain their support for its role in cctld oversight. at the same time, therevised icann bylaws107 give the ccnso the principal role in establish107the changes in icann bylaws that establish the ccnso and define its roles are inicann, òappendix a to minutes of regular meeting of icann board,ó june 26, 2003,available at <http://www.icann.org/minutes/minutesappa26jun03.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.260signposts in cyberspaceing policy for entry of data concerning cctlds into the root zone file.over time, this may lead to a ccnsoled redefinition of the delegation/redelegation policies and practices of icann.however, some of the most important cctlds were not participantsin the ccnso upon its formation. most notably, only four of the europeancctlds (from the netherlands, the czech republic, gibraltar, and thecayman islands) were among the 38 founding members. in april 2004,the european community (ec) member responsible for the internet saidthat the ec will stand by icann as long as it continues to make changesand that unless the ec cctlds come to agreement with icann, the ecwill lose patience and the governments will step in, possibly turningicannõs cctld role over to the itu.108 but the distance that remainsbetween icann and the european cctlds was clearly shown by the response of centr to icannõs proposed 20042005 budget. in a may 2004letter to icann, centr accused icann of a òlack of financial prudenceóand refused to support it òfinancially or otherwiseó in its òunrealistic political and operational targets.ó109 specifically, it said: òicann/ianashould focus on doing a few administrative tasks well and not seek tomake decisionsñdecisions are best handled elsewhere.óalternative b: òthinó icanndescriptionmany cctlds would favor a much more limited role for icann, essentially reducing it to performance of a technical coordination functionand eliminating all policy functions. under this approach, icann wouldcontinue to run the iana function, maintaining the database of cctldsand the cctld entries in the root zone file. however, decisions about thedelegation of responsibility for a cctld when it is a subject of disputewould not be made by icann. rather, they would be made, in the firstinstance, by the local internet community relying on national laws andprocesses as necessary, and if that failed, by a process established by thecctld community. in this model, the cctlds would agree to pay the costincurred by icann in maintaining the database of cctlds and cctldentries in the root zone file through a fee based on the size of each cctldõsmembership.108speech by ec commissioner erkki liikanen quoted by kieren mccarthy, òec tellseurope and icann to make peace,ó the register, april 28, 2004, available at <http://www.theregister.co.uk/2004/04/28/ecicannwarningshot/>.109paul m. kane, letter to paul twomey, may 26, 2004, available at <http://www.centr.org/docs/statements/centrresponse2004budget.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues261evaluationalternative b would reduce icann to performance of a technical/administrative root registry function, eliminating its role in determiningwho among alternative claimants should have the right to be the registryfor a specific cctld. in that sense, it is compatible with the approaches togtld selection that favor the use of auctions to determine which gtldsshould enter the root zone file. a combination of the two approacheswould virtually eliminate icannõs role as a gatekeeper to the root andleave it primarily as the record keeper and, presumably neutral, validatorof the technical qualifications of registries.alternative c: international oversightdescriptionin the third model, a major part of the iana function would be removed from icann and turned over to a thirdparty organization established by the cctlds. that organization would be responsible for maintaining an uptodate cctld database and sending the appropriateinformation to icann for entry into the root zone file. presumably, therewould be a corresponding agreement with the doc (as long as it retainedits stewardship role) to accept the information from the thirdparty organization as authoritative. if that organization had broad international participation in its governance and activities, this might alleviate some of thediscontent with the u.s. governmentõs current central role as steward ofthe dns. one possibility would be, for example, to turn the cctld database and delegation responsibilities over to the itu. however, the itu isan intergovernmental organization, responsible primarily to the telecommunication ministries of governments. yet, as noted earlier, many cctldsare either simply independent from their governments or operating indelicate balance with them. they would probably not like a process whoseonly recourse is to the governments.evaluationthis alternative takes alternative b a step further by eliminating eventhe recordkeeping function of icann with respect to the cctlds. its rolewould simply be to pass the appropriate entries to the organization responsible for distributing the root zone file (currently verisign). in fact,this amounts to establishing an òicannó for the cctlds, leaving thepresent icann with responsibility only for the gtlds. although alternative c would certainly eliminate any cctld discontent with icann, itmight simply shift the focus of concern to the new organization, dependsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.262signposts in cyberspaceing on how the issue of delegation/redelegation decision making wasdecided. this possibility suggests that finding a solution to the delegation/redelegation decision process within the existing icann that is satisfactory to the cctlds and their governments would preclude cctldsupport for alternative c.alternative d: selfgoverning root management organizationdescriptionan additional possibility would be an icann focused solely on rootmanagement responsibilities whose members are limited to those groups,including the cctlds, having a direct interest in the root. (see òalternative c:icann as registry for the rootó in section 5.2.4.) this model assumes thatthe cctlds would take an active role in icannõs governance and would,therefore, be more willing to see icann play an active, òthickó role in cctldoversight. by creating a ccnso and giving it greater influence on board composition and enabling it to submit recommendations to the board for its unmodified approval or rejection, icann has taken a step in this direction.evaluationalternative d, discussed in greater detail as one of the icann alternatives, could achieve the goal of bringing the cctlds fully into the management of an organization whose authority would be strictly limited tomanagement of the root. once again, however, the issue would devolveto the sensitive one of how delegation/redelegation decisions are made.this alternative might be more attractive to the cctlds because it wouldpresumably increase the strength of their influence over icannõs operations and decisionmaking processes. however, the issue still remains thedegree to which they, a highly diverse group, would all be comfortablewith the policies and practices that would determine which registry isdelegated or redelegated responsibility for a cctld.comparison of the four alternativesthe four alternative models described above for oversight of cctldsare compared in table 5.4 on two dimensions: who maintains the cctlddatabase and who recommends redelegations (to doc). three modelsassume that icann will continue to manage the cctld database. onlyone posits an independent manager of the database. two models foreseethe decision/policy responsibility for delegations and redelegations being removed from icann.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues2635.5.3conclusionsconclusion: resolution of icannõs role vis‹vis the cctlds is oneof the critical steps on the path to establishing an icann that is viewed asa legitimate and appropriate steward for the dns.the creation of the ccnso represents progress in that direction whosesuccess will depend on the ccnsoõs ability to attract an increasing number of members, both from the large cctlds that are needed for financialand other support of icann and the smaller cctlds that can benefit fromthe support that icann could offer them. even more critical is the refinement of the principles and processes for delegation and redelegation ofcctld registries and their acceptance by most of the cctlds.conclusion: if the creation of the ccnso does not result in increasedparticipation by the cctlds in icann policy making, then icann mayfind itself subject to increasing pressures to constrain its role to that ofgtld management and root zone file record keeping.5.6resolution of conflicts over domain namesissue: does the udrp need to be improved? if so, how should it be improved?administrative processes, such as the uniform domain name disputeresolution policy (udrp), are playing an important role in helping to resolve certain privateparty disputes related to the use of domain names,without requiring isps, registries, registrars, registrants, or other parties toappear in court to provide evidence or to protect their interests. such processes contribute to the smooth operation of the economic and legal framework associated with the dns. at the same time, while the highly simplitable 5.4alternatives for oversight of the country code topleveldomainsmaintainer of cctld databaserecommender of redelegationsicannthird partyicanna. thick icannd. selfgoverning root management organizationthird partyb. thin icannc. international oversightsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.264signposts in cyberspacefied rules created by the udrp and similar dispute resolution procedures(e.g., those adopted by some cctlds) and dispute avoidance efforts (e.g.,sunrise provisions) make it possible for some actual or potential disputes tobe resolved quickly at relatively low cost and without requiring the partiesto be represented by legal counsel, they can also undermine the potentialfor fair outcomes. the udrp is the primary subject of this section, sincemost attention has been paid to issues concerning it.during 2003, the icann staff carried out a review of the udrp. itproduced an issues report in august 2003.110 the report cataloged andidentified the pros and cons of proposed solutions to both procedural andsubstantive issues and concluded that òwhile there are some areas whereimprovements may be possible, there does not appear to be an urgentneed for revision.ó furthermore, it noted that òrevision of the udrp islikely to be contentious; there are not many (if any) areas that are obviously amenable to achieving consensus.ó (since the udrp is a consensuspolicy, according to provisions of the icann registry and registrar agreements it must be revised by consensus.)to provide an understanding of the issues that have given rise to thoseproposals, this section begins with an assessment of the udrp and thenexamines the major proposals for improvement. it incorporates thecommitteeõs conclusions and recommendations. the section concludeswith a discussion of the potential consequences of deployed internationalized domain names (idns) for dispute resolution.5.6.1assessment of the udrpmany observers believe that the udrp has functioned well to resolvedisputes over domain names.111 however, there are others who believethat the current system is biased toward the interests of trademark holders and away from the interests of individuals.112 notwithstanding itsperceived disadvantages, numerous decisions have been rendered under110icann, òstaff managerõs issues report on udrp review,ó august 2003, available at<http://www.icann.org/gnso/issuereports/udrpissuesreport01aug03.htm>.111one such favorable assessment appears in colm brannigan, òthe udrp: how do youspell success?,ó digital technology law journal 5(1, july), 2004, available at <http://wwwlaw.murdoch.edu.au/dtlj/2004/vol51/brannigan.pdf>. a careful assessment of thepros and cons of the udrp can be found in laurence helfer and graeme dinwoodie. 2001.òdesigning nonnational systems: the case of the uniform domain name dispute resolution policy,ó william and mary law review 43(1, october):141273, 2001, available at <http://www.kentlaw.edu/depts/ipp/intlcourts/docs/dh.pdf>.112see, for example, a. michael froomkin, òicannõs ôuniform dispute resolutionpolicyõñcauses and (partial) cures,ó brooklyn law review 67(3):608718, 2002, available atsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues265the udrp, and other domain name dispute policies have been modeledafter the udrp as described in òresolving domain name conflictsó insection 3.5.2. thus, the udrp has both positive and negative aspects,which differ, however, depending on whether they are being consideredfrom the perspective of the complainants or of the respondents.¥general benefits.the udrp crosses national boundaries and relieson communication technology to bring the parties together it is more informal than litigation in national courts and relies on panelists who areexperts in the areas of trademark law and domain name issues. the proceedings are quasiinrem, meaning that even though both parties are included, the action is focused on resolving which party has rights to thedomain name, rather than assessing fault or monetary damages againsteither party. although it is international in scope, it raises no jurisdictional issues, which may be present in court litigation in some countries,by requiring all domain name registrants to agree to submit to a mandatory administrative proceeding as part of the registration agreement. theudrp requires that the proceeding be conducted in the language of theregistration agreement, which eliminates language as a potential barrierto participation by domain name registrants.¥complainantõs benefits.from the complainantõs (generally, trademark holderõs) point of view, the udrpõs positive features include that itprovides a quick and relatively inexpensive method of resolving a domain name dispute and obtaining the transfer of a domain name to thetrademark owner. domain name disputes brought under the udrp aregenerally resolved within 45 to 60 days of the domain name disputeproviderõs receipt of the complaint. in addition, the udrp is not limitedto registered trademarks identical to the domain name, and it allows trademark owners to file a complaint against a registrant of a domain namethat is òconfusingly similaró to the ownerõs mark. further, owners withcommonlaw rights in trademarks may also take advantage of the udrpas there are no trademark registration prerequisites to commencing audrp action.the udrp is a costeffective dispute resolution mechanism overallbecause it (1) is based primarily on the pleadings of the parties, (2) only<http://personal.law.miami.edu/~froomkin/articles/udrp.pdf>. in addition, see michaelgeist, òfair.com? an examination of the allegations of systemic unfairness in the icannudrp,ó university of ottawa, faculty of law, august 2001, available at <http://aix1.uottawa.ca/~geist/guistudrp.pdf>. see also a followup piece by the same author inmarch 2002, òfundamentally fair.com? an update on bias allegations and the icannudrp,ó available at <http://aix1.uottawa.ca/~geist/fairupdate.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.266signposts in cyberspaceallows inperson hearings under exceptional circumstances, and (3) onlyallows additional evidence at the discretion of the panel.113 furthermore,the parties are generally not required to travel in order to participate inthe proceeding, which is usually conducted by postal mail, email, or facsimile. this last point can be seen as a greater advantage for the complainants, since ordinary court proceedings would occur in the respondentsõlocales, thus, requiring the complainants to travel.¥respondentõs benefits.from the respondentõs perspective, the panelcan grant the complainant the requested remedy (i.e., transfer or cancellation of the domain name registration) only if the complainant succeeds inshowing all three of the udrp elements (see òremedies to conflicts overnames in the dnsó in section 3.5.2), even if the respondent did not submit a response. respondents see other advantages to the udrp as well,since it requires trademark owners to comply with a standard stricter thanthat of the courtsñdemonstrating that the respondent had both registeredand used the domain name in bad faith (although it has been argued thatnot all panelists have adhered to this requirement). in addition, the udrpallows a party against which an adverse decision is rendered to take thedecision to the courts.moreover, the udrp provides limited remedies to trademark owners, namely simply transfer or cancellation of the domain name. to receive monetary damages or an injunction, a trademark owner would haveto proceed to litigation.¥complainantõs disadvantages.from the complainantõs perspective,the preparation of a proper complaint and necessary appendices can betimeconsuming and costly, and although much less costly than preparing for litigation, it is still viewed by many complainants as excessive.in addition, the only avenue, at present, for correcting what the complainant views as an improper decision by the panel is to litigate the samematter before a court having in personam jurisdiction over the respondent,or in some cases in in rem jurisdiction over the domain name in dispute.this is not perceived as an advantage by all complainants, especially ifthe respondent is not located in the same location as the complainant andthe domain name was not registered in the united states, where in remjurisdiction is possible in some cases.moreover, complainants see disadvantages in the limitations on remedies (no potential damage recovery no matter how egregious the respondent) and in panelsõ inconsistent definitions of critical terms, such as òconfusing similarity,ó òuse,ó and òbad faith.ó113icann, òrules for uniform domain name dispute resolution policy,ó october 24,1999, paragraph 12.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues267¥respondentõs disadvantages.there are also, however, disadvantagesthat fall primarily on the respondents. although the udrp allows administrative proceedings to be conducted in languages other than english, theudrp itself is written in english. many nonnativeenglish speakers whoregister domain names with registrars that do not provide translated versions of their registration agreements or the udrp may not be aware thatthey are subject to the provisions of the udrp or that they should avoidselecting a domain name that violates the trademark rights of other parties.114 additionally, since the complainant selects the dispute resolutionservice provider, it is possible for complainants to òforum shopó (i.e., toselect a provider more likely to favor the complainant, or which has beenmore sympathetic to similar complaints in the past).115some critics have also alleged that providers, seeking to increase theirchances of being selected by future complainants, purposely choose arbitrators who are more likely to favor complainants, but little concrete evidence supporting this allegation has been provided. nevertheless, arbitrator selection bias would be a serious issue were it to occur, and serviceproviders should be reviewed on a periodic basis to make sure such biasdoes not exist.once a decision is rendered, the respondentõs only recourse for dealing with a decision transferring or canceling the domain name is to proceed to court.¥general deficiencies.critics of the current udrp116 have pointed toa number of perceived deficiencies. among them are that some panelistsdo not apply the precedents of previous arbitrations appropriately, or insome cases consistently; some panelists (and many respondents) are notwellenough educated in either the operations of the dns or the policiesand rules applicable to domain name disputes; the charges for a udrpproceeding and the ways in which panelist are compensated can lead to114as noted by one reviewer: ò. . . many countries have consumer protection laws thatrequire all consumer contracts concluded within the jurisdiction to be in the local languagein order to be valid and enforceable. this condition is not satisfied by the udrpõs requirement that the proceedings be conducted in the language of the registration agreement.ó seeholger p. hestermeyer, òthe invalidity of icannõs udrp under national law,ó minnesotaintellectual property review 3(1):157, 2002115an early analysis of the udrp that asserted that òforum shoppingó was a source of biasfavoring the complainant was in milton mueller, òrough justice: an analysis of icannõsuniform dispute resolution policy,ó convergence center, syracuse university school ofinformation studies, 2000, available at <http://dcc.syr.edu/miscarticles/roughjustice.pdf>.the inta study, òudrpa success storyó (2002), is a rebuttal to the mueller article. michaelgeistõs reports, òfair.com?ó (2001) and òfundamentally fair.com?ó (2002), both provide further data on the asserted complainantbeneficial effects of forum shopping.116see, for example, the froomkin, mueller, and geist articles cited above.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.268signposts in cyberspaceundesired consequences; and there is no appeals process with the udrpitselfñthe only appeal is a de novo action before a court.each of these perceived deficiencies is described and proposals forremedying them are addressed in the next section.conclusion: the udrp has generally satisfied the need for an effective and costefficient means of resolving disputes concerning domainnames; however, it has weaknesses for which remedies have been proposed.5.6.2proposed improvements to the udrpin response to the perceived deficiencies of the current udrp, a number of improvements have been proposed: a better, more consistent application of arbitral precedents; an appeals process; required use of threemember panels; improved training and selfhelp tools; and revisedfunding and compensation structures.¥better application of precedents.some believe that more consistentapplication of arbitral precedents in udrp proceedings is needed, so thatsimilar issues can be addressed in a more predictable manner that alsosupports casebycase knowledge building. in addition, greater consideration of international legal issues is needed, given that laws vary fromcountry to country. because the panelists in udrp proceedings tend to bemost knowledgeable about their home countryõs laws, new issues in disputes tend to be examined through the legal lens of a particular panelistõscountry. when these decisions are relied on in later cases, panelists unfamiliar with the legal context of the original decision will often assessthemñinviting misinterpretation, however wellintentioned a panelistmay be. one way to encourage better and more consistent use of arbitralprecedents is to have an internal appeals process, whose panelists wouldbe in a better position to require and make use of precedents.¥appeals process.an appeals process could serve the purpose of reversing decisions that were clearly faulty or that covered a situation orissue for which competing bodies of precedent exist.117 to remain consis117for a specific proposal, see patrick kelley, òemerging patterns in arbitration under theuniform domainname disputeresolution policy,ó law and technology writing workshop, annual review of exemplar papers, school of law (boalt hall), university of california, berkeley, 20012002, available at <http://www.law.berkeley.edu/institutes/bclt/pubs/annrev/exmplrs/final/pkfin.pdf>. another proposal for an appeals process appears in m.scott donahey, òdivergence in the udrp and the need for appellate review,ó 2002, available at <http://www.tzmm.com/content/articles/mil2910.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues269tent with the original purpose of the udrp, the intent of such a processwould be to reexamine only a small percentage of decisions, so as to provide an inexpensive mechanism (as compared to a court case) for resolving relatively straightforward cases. as noted above, an appeals processwould have the likely effect of encouraging better and more consistentuse of arbitral precedents. but support for an appeals process has beenlimited, with the emphasis being placed on resolving such issues througha national court proceedingñrather than creating another layer to a relatively quick and inexpensive dispute resolution process. those who holdthat view emphasize that the udrp, with or without an appeals process,is not intended to serve as a full substitute for national and internationallaw or courts, but simply to provide a quicker and less costly process forthe majority of disputes, whose resolution is often obvious. with carefuldesign and restriction to very specific situations, the proposal for a limited appeals process could be consistent with that intent.¥threemember panels.analyses conducted during 2001 and early2002 of udrp proceedings indicated a significant difference in their outcomes, depending on whether they were heard by onemember or threemember panels.118 (the choice is made by the complainant in the firstinstance, but the respondent can request a threemember panel.) threemember panels found for the complainant in a smaller percentage of thecases. critics have taken this as an indicator of greater bias toward complainants by the onemember panels and have recommended, therefore,that all panels have three members.119 (in threemember panels, the complainant, the respondent, and the provider each provide lists from whichone of the panelists is chosen.) others have argued that the impression ofbias is due to other factors.120 both sides agree that threemember panelsare more expensive and, therefore, that they erode the benefits of theudrp as a relatively inexpensive means of resolving domain name disputes. those who favor them argue that the increase in fairness is worththe cost. in addition, they have suggested the payment of a bond by thecomplainant that would be used to cover the respondentõs costs of theproceeding if the complainant lost and would be refunded if the complainant won.121118michael geist, òfair.com? an examination of the allegations of systemic unfairness inthe icann udrp,ó 2001; and michael geist, òfundamentally fair.com? an update on biasallegations and the icann udrp,ó 2002.119michael geist, òfair.com?,ó 2001.120inta, òthe udrp by all accounts works effectively,ó 2002.121milton mueller, òsuccess by default: a new profile of domain name trademark disputes under icannõs udrp,ó convergence center, syracuse university school of information studies, june 24, 2002.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.270signposts in cyberspace¥improved training and selfhelp tools.in many udrp proceedings thefocus is on the use of domain names in web addresses (uris). the role ofdomain names in email addresses and in other applications is often ignored by the panelists, even though the effects can be different from thosein web addresses. one possible reason for this oversight is that some panelists may lack a technical understanding of how the dns and the internetoperate. thus, some believe, udrp proceedings could be improved byenhancing the training requirements for panelists in the technology underlying the dns, the manner in which domain names can be used, andthe application of the policies and rules applicable to domain name disputes. improvements in the process might be developed to help panelistsverify the manner in which domain names are used, either through selfhelp mechanisms or by changing the rules to request this information fromthe respondents. dispute resolution providers could provide training forpanelists on a regular basis, with such training being a requirement tomaintain panelist status with that provider.thorough and detailed selfhelp tools might also be developed to enable respondents to better understand the udrp process itself, thetimeline involved, and the substance and format of an effective responseto better comprehend and respond to a udrp action.122¥revised funding and compensation structures.under the currentfunding structure, the revenue for panelists depends on the volume ofcases, thereby either creating a disincentive to spend a sufficient amountof time reviewing the facts in a case and writing a wellthoughtout opinion, or creating an incentive for marketing strategy and tactics to attractcases by defining lucrative niches, which may or may not correspond tojustice in dispute resolution proceedings. observers assert that suchniches exist and that complainants often forum shopñselecting disputeresolution service providers based on their past record of favorable (tothe complainantõs position) rulings.since some parties believe that the $1150 to $1500 fee for filing a complaint regarding a single domain name is already expensive, there is someresistance to any proposed increase. in addition, increasing the fees paidto resolve or avoid a dispute raises the likelihood that, on the one hand,individual domain name holders would be discouraged from employingdispute resolution processes, while, on the other hand, wellfinanced domain name holders might be discouraged from filing large numbers ofnot completely justified complaints.122early in 2005 the world intellectual property organization posted on its web site anòinformal overview of panel positions on key procedural and substantive issues,ó includingreferences to decisions supporting each line of opinion. the òwipo overview of wipo panelviews on selected udrp questions,ó which is not binding on the panelists, is available at<http://arbiter.wipo.int/domains/search/overview/index.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues271on the compensation side, the fee paid to panelists, typically $1000 to$1750, is below the level that highly qualified attorneys and consultantssay is needed to attract them to serve or continue to serve as panelists.while it may never be possible to set the level high enough to attract andretain highly paid specialists on the basis of compensation alone, it maybe worth examining the fee schedule to see whether a higher level couldbe established while retaining the low cost of the udrp.recommendation: arbitral domain name dispute resolution processes, rather than national courts, should continue to be encouraged asthe initial and primary vehicle for resolving most disputes associated withthe rights to domain names.recommendation: the feasibility and desirability of five specificudrp improvements should be further considered by icann: improving consistent use of arbitral precedents, establishing an internal appealsprocess, using threemember panels, improving panelist knowledge aboutthe technology underlying the dns, and improving the nature and structure of incentives in the process.5.6.3disputes concerning internationalized domain namesthe widespread deployment of internationalized domain names(idns)123 may well compound the difficulty of resolving disputes overdomain names by increasing the possibility that domain names will becreated that appear to be the same, but are not.the introduction of nonascii characters introduces a number of opportunities for conflicts, not about domain names themselves, but aboutcharacters that look alike. as the most trivial of examples, the uppercasegreek alpha and its cyrillic equivalent are indistinguishable on theprinted page from roman upper case òa,ó but the three have differentunicode code points and strings containing them will compare differently.there are several similar combinations involving roman, greek, andcyrillic scripts, but other examples appear in almost all pairings of alphabetic scripts. another problem occurs because of the overlap between, forexample, simplified and traditional chinese, where the characters lookdifferent but have the same meanings.these concerns about similarappearing, or similarly interpreted, domain names are compounded by the observation that, in some circum123see section 4.3 for discussion of internationalized domain names.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.272signposts in cyberspacestances, a single registered domain name might have dozens, or even hundreds, of such variations. a cybersquatter could turn such conflicts into apotentially lucrative business by offering to sell such variant names to theòlegitimateó owner at a fee just below the cost of a udrp proceeding.some of the registries and communities that would be most affected haveconcluded that it is preferable to shift the problem, to the degree possible,from conflict resolution to conflict avoidance by imposing restrictions onthe registration of domain names that would conflict or otherwise causeconfusion. icann has reinforced this approach by creating a guidelinethat requires that an idn must be registered only with regard to a specified language, which eliminates some of the difficulties encountered withmixed scripts.124 this approach is discussed in more detail in section 4.3.one view is that the potential for confusion in these cases is not reallydifferent from that of existing similarappearing domain names, for whichit has been suggested that udrpbased name conflict resolution is adequate and appropriate. but variations among similarlooking domainnames are such as to generate, potentially, hundreds of possible conflictswith a given character string.the joint engineering team (jet) guideline model (see section 4.3.3)addresses this problem by preventing some large fraction of the potentialconflicts, rather than devising remedies for them after they occur. the jetguidelines take the position that idn packages are atomic, and that thereshould be no mechanism for moving domain names in or out of one onceit is created (see section 4.3 for discussion of idns). under that model, if adomain name conflict arises in the creation of such a package, the conflicting (alreadyregistered or reserved) domain name is simply not placed inthe new package. but if the conflicting domain name is later deleted, itdoes not become part of the later idn package unless the domain namesassociated with that package are explicitly deleted and reregistered.thatmay or may not be the best possible model, but the alternatives, such ashaving domain names appear as reserved in two or more packages, witha priority order, lead to administrative, policy, or database managementnightmares.but there are constituencies that oppose such systems, some of themon the grounds that dispute resolution is adequate and others, perhaps,on the more cynical grounds that letting things go to dispute resolutionpermits them to collect registrar and registry fees on the names whetherthey are valid or not and encourages even more business in defensiveregistrations.124guidelines are available at <http://www.icann.org/general/idnguidelines20jun03.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues273conclusion: the deployment of internationalized domain names introduces new sources of potential conflict over domain name rights. reduction of such conflicts through guidelines and registration policiesshould be encouraged.5.7 provision and protection of whois dataissue: what is the appropriate balance among the various interests in whoisdata?as noted in chapter 2, the whois service began as a vehicle for network operators to find and contact those responsible for the operation ofan internet host when, for example, an operational problem arose. however, with the commercialization of the internet, the whois service hasbecome an important and valuable tool for intellectual property ownersand is often used by trademark owners to determine the identity of suspected infringers and cybersquatters. in addition, it is used by law enforcement agencies, such as the federal trade commission in the unitedstates, to track down the sources of fraudulent or other illegal uses of theinternet. at the same time, there has been concern about its real and potential exploitation by marketers and others who find the informationabout domain name registrants valuable. these uses have, in turn, givenrise to significant and strongly held privacy concerns. thus, while theability to search the whois database has always been limited, because ofprivacy concerns access and searching of whois information have becomemore and more restricted over time.5.7.1assessment of whois data issuesin the early days of the dns, there were few, if any, concerns aboutthe misuse of whois data, just as ensuring the integrity of dns data wasdeemed to be unnecessary. however, the population of users of whoisdata has increased markedly in scale and scope, and assumptions aboutthe good intent of all users have become unfounded. furthermore, underthe udrp, giving false whois information and not responding to requestsfor information have led to a presumption of bad faith by the respondent.for example, when whois was used as a unix command, trademarkowners were able to retrieve a wide range of information, including contactinformation of the domain name registrant and a list of all domain namesregistered by one particular registrant. later, and until 2001, network solutions, inc. (nsi) allowed internet users to retrieve a list of up to 50 domainnames registered by a particular registrant, but then changed the maximumnumber to 10 registrations. currently, none of the registrars allow internetsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.274signposts in cyberspaceusers freely to query their whois databases to determine which domainnames a particular registrant has registered. many registrars charge a feefor each request for a list of domain names registered by one of their registrants. in addition, some of the registrars do not provide a domain nameregistrantõs email address in the contact information, but instead assigneach registrant a generic email address125 that is linked to the email address the registrant provided in registering its domain name.data accuracywhois information can be inaccurate, out of date, or false. indeed,registrants may provide fictitious names and addresses and fail to updateany of their contact information promptly, if ever. icannõs registraraccreditation agreement contractually binds each of its accredited registrars to investigate and correct any reported inaccuracies in contact information for the domain names they maintain.icann established in september 2002 the whois data problem reports system (wdprs) to receive public reports of inaccurate or absentwhois data. the sixth amendment to its mou with the doc requires thaticann publish an annual report containing an analysis of the receivedreports. according to its march 2004 report,126 over the 18month periodfrom september 2002 through february 2004, the system received about24,000 confirmed whois inaccuracy reports, concerning about 16,000 different domain names. of these, 82 percent concerned .com; 13 percent,.net; and 5 percent, .org. (an enhanced version of the system that willcover the new gtlds as well as the legacy ones was launched in 2004.)the complaints received by each registrar were generally proportional tothe number of names it registered. on average, each registrar received 4.8complaints per year per 10,000 names managed. somewhat more than athird of these complaints resulted in the correction of data or the removalof a domain name.as a further step to improve whois data accuracy, icann adoptedthe whois data reminder policy (wdrp) on march 27, 2003.127 sincenovember 2003, all icannaccredited registrars must comply with the125this could cause problems in a udrp proceeding since the generic email address couldbe interpreted as false and, consequently, a contributor to the presumption of bad faith onthe part of the respondent.126icann, òcommunity experiences with the internic whois data problem reportssystem,ó march 13, 2004, available at <http://www.icann.org/whois/wdprsreportfinal31mar04.htm>.127icann, òwhois data reminder policy,ó june 16, 2003, available at <http://www.icann.org/registrars/wdrphtm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues275wdrp with respect to registrations they sponsor in all toplevel domainsfor which they are accredited. at least annually, a registrar must presentthe current whois information to registrants and remind them that provision of false whois information can be grounds for cancellation of theirdomain name registration. registrants must review their whois data andmake any corrections. data privacyicann posted a staff managerõs issues report on privacy issues related to whois on may 13, 2003,128 that spelled out a catalog of the issues,the stakeholders, and their apparent positions on the issues. the issuesconcerned the data collected, including its quality, handling, disclosure,and use; the classification of registrants (i.e., political, commercial, individual); and commercial confidentiality and rights in data.the various stakeholders were viewed as placing emphasis on different issues. noncommercial users were viewed as focusing on privacy,whereas commercial users were seen as concerned with accessibility toenforce accountability of uses. the intellectual property interests wereunderstood to stress the importance of ready access to support investigations of intellectual property abuse, while isps support it to facilitate resolution of network problems and identification of the sources of spam. registrars and registries view registrant data as an important business assetthat should not be made available to competitors, while at the same timeregistrars need to access registrant data of competitors to confirm authorization of transfers. registrars and registries both bear the expense of providing the services and, therefore, have strong incentives to reduce thecost of doing so.as a consequence of these differences in emphasis among stakeholders, the policy issues surrounding whois services (as opposed to thewhois protocol) are often framed in adversarial terms. on the one hand,trademark holders and their representatives want comprehensive and freeaccess to all whois data and would like improvements in whois services,such as higher quality in the whois data and the ability to consolidatedata across whois services more easily. they see whois data as an essential resource in the pursuit of those who compromise their trademarks in128icann, òstaff managerõs issues report on privacy issues related to whois,ó may 13,2003, available at <http://www.icann.org/gnso/issuereports/whoisprivacyreport13may03.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.276signposts in cyberspacedomain names.129 on the other hand, those who are concerned about individual privacy highlight the problems that could be associated withunconstrained access to whois datañfrom junk mailers and marketers tothose who may use such data to facilitate more serious, illegal activitiessuch as identity theft.in recognition of the complexity of the issues and interests involved,the icann staff managerõs issues report recommended as the next stepthe formation of a whois/privacy steering group in the generic namessupporting organization (gnso) to conduct a factfinding and issuesdefinition process. following on the work of that steering group, thenames council of the gnso in october 2003 launched three simultaneoustask forces on various aspects of whois privacy. the council intended toalign their recommendations for submission to the icann board.task force 1 (tf1) was charged with examining what contractualchanges (if any) would be required to allow registrars and registries toprotect domain name holder data from data mining130 for marketing purposes. task force 2 (tf2) was asked to address issues concerning the datato be collected from registrants, their options to restrict access to the dataand be informed of its use, and their ability to remove certain data elements from public access and receive notice if it is accessed. task force 3(tf3) was tasked with looking at verification of the data collected, considering both errors and deliberate falsification. the three task forces presented their preliminary reports at the end of may 2004. they have beenposted on the icann web site for comment.131 among the significantissues and positions identified were the following.¥local law.132in some cases, national privacy laws conflict with theprovisions of icannõs agreement requiring the registrars to collect and129in a udrp proceeding, for example, trademark owners are often required to show aòpattern of conductó by the respondent of registering domain names incorporating the trademarks of other parties. unless a trademark owner can guess the domain names registeredby the respondent, it can incur considerable costs in obtaining this information, since therespondent may have used several different registrars in registering its domain names orprovided slightly different contact details for each registration.130òdata miningó as used here means the use of computerized techniques to extract dataabout registrants from registrar whois files in large quantities. often these techniques aredesigned to overcome specific limitations imposed by registrars on the number of namesthat may be requested. the lists are then used for unsolicited mailings (spam) and otherpossibly illicit (identity theft) purposes.131links to the preliminary reports are available at <http://gnso.icann.org/issues/whoisprivacy/index.shtml>.132for this and the next two items, see the report of tf2 available at <http://gnso.icann.org/issues/whoisprivacy/index.shtml>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues277make accessible certain data elements about registrants. the icann registry/registrar agreement should be modified to exempt registrars whoobey local law from the conflicting provisions of the agreement.¥data elements.all of the data elements currently collected are considered by at least some constituencies to be required, although some constituencies dispute the needs for some of them. no consensus exists onwhether new elements are needed and whether some existing elementsshould be made voluntary. the issue is less what should be collected byregistries/registrars and more what data should be made available forpublic access.¥publication of data.whois data has a wide range of uses (as discussed above.) it is also subject to abusesñtelemarketing, identity theft,spamming, stalking, and abuse and harassment have been reported,though not quantified. there is a need to achieve a balance between accessibility and privacy. possible approaches include tiered access, in whichdifferent types of users would have access to different subsets of the data;proxy registration services that would substitute thirdparty for registrantdata and control access to the latter; and the ability of registrants to optout of publication of certain data on a casebycase basis. the latter approach has been adopted by some cctlds.¥data mining and marketing.133if only nonsensitive data (generally,technical information) were to be available via whois, it would have littlevalue, be unlikely to be data mined, and have little impact on privacy. however, to the extent that sensitive data (generally, personal contact information) is publicly available through registry/registrar whois services, tf1members agreed that at a minimum the requestor of whois informationshould be required to identify (and authenticate) itself to the whois provider together with its reasons for seeking the data. they left open the issue,however, of whether notice to the registrant of such a request should berequired. they also left open the question of whether and under what conditions automated access to whois data could be allowed and to whom.among the possibilities would be enabling a restricted license that wouldprovide data to approved requestors for recognized purposes in humanreadable format only. requestors could be approved generally and centrally (a white list) or locally and specifically (an individual use list).133see the report of tf1 available at <http://gnso.icann.org/issues/whoisprivacy/index.shtml>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.278signposts in cyberspace5.7.2whois and internationalized domain names134just as it does for the udrp, the introduction of internationalizeddomain names (idns) raises technical and institutional issues for thewhois service. for the most part, these are issues about the languages inwhich whois queries will be posed and responded to.at the basic query level, the current whois service expects to receiveascii characters only; it cannot receive queries in unicode (which is usedto encode the many different character sets of contemporary human languages), and its responses are similarly in ascii. but in an internationalized environment, domain names will not all be written in ascii (although, as explained in section 4.3, they will all be mapped into asciistrings). this raises the first question: what character sets should be acceptable in a query? the choices include not only unicode, but also idnapuny code (see section 4.3) and local character sets, or some combinationof them.similarly, responses to whois queries are currently provided in ascii.this raises the second question: what language should be acceptable in aresponse, and how should it be encoded? the choices of language includethe language of the nation in which the registrar or the registrant is located or english. or one might permit some òinternational languages,ósuch as english, chinese, french, spanish, russian, arabic, and so on. ifthe response is to be useful to most questioners on the internationalinternet, then would it be reasonable to expect them to have to hire translators? or should the whois registrant be required to list its informationin some commonly accepted language? if the language is other than english, then issues about coding arise that are similar to the question regarding queries. for example, should unicode be required and, if so,which encoding form of unicode? or should local character encodings,which might be in much more general use with the particular relevantlanguage or script, but less easily accessible internationally, be permitted?a third question arises since idn practices for complex languagesactually create packages of reserved names (see section 4.3). in such cases,how much information should whois provide about other names in thepackage in response to a query about one of them?none of these issues had been resolved by september 2004. however,as idns are more widely adopted, the lack of their early resolution willincrease the likelihood of problems arising and the difficulty of introducing the necessary changes.134this section draws on material in john c. klensin, òôwhoisõ internationalization issues,ópresentation at the icann meeting in carthage, tunisia, october 2003, available at <http://www.icann.org/presentations/klensinwhoiscarthage29oct03.ppt>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system: institutional issues279on the other hand, the work on a new protocol to replace whois (seesection 5.7.3) has explicitly addressed some internationalization issues.although that work does not address all of the issues raised above, it atleast makes it possible to transmit and receive unicode characters without somehow encoding them into ascii form and, if it is desired to support local character encodings, to construct a framework for identifyingand using them.recommendation: the ietf and icann should address whois datainternationalization issues with high priority in order to enable their resolution and implementation of the results together with the widespreadintroduction of idns. 5.7.3conclusion and recommendationthe issues concerning the accuracy of and access to whois data engage the interests of many stakeholders with legitimate but sometimesconflicting interests. they entail actual and potential conflicts with differing national privacy laws. furthermore, the icann agreements with registrars and registries obligate them to accept only consensus policies. consequently, the best way to achieve improvements in the whois policiesand practices appears to be through the consensus policy developmentprocess in which icann is engaged. attempts by individual governments to impose specific requirements on whois, such as recent legislative initiatives in the u.s. congress,135 can interfere with these efforts andhave counterproductive consequences by inducing registrants to findways to hide their identities.conclusion: legislative or technical initiatives that construe whoisnarrowly will not be productive in the long run and serve only to energizethose constituencies that perceive their interests as being compromised.the committee agrees that access to whois data should be viewed as atiered decision, and not as a binary decision. gradations should exist, asthey do in local telephone directories where entries are included by default, but where unlisted numbers can be obtained. moreover, under certain conditions, law enforcement officials can obtain an individualõs information, even if the individual has opted not to be included in the publicdirectory. alternatively, individuals can sometimes embellish their ge135h.r. 3754, 108th congress, fraudulent online identities sanctions act (foisa).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.280signposts in cyberspace136the ietf had, by october 2004, approved as òstandardstrackó documents (see box 3.3)several elements of a proposed replacement protocol, which is called iris and defined bythe crisp working group, that will implement this capability. the protocol also addressesmost or all of the other perceived deficiencies of the whois protocol, including its inability todeal with nonascii characters. more detail on those deficiencies is available in the statement of requirements for the new protocol in a. newton, òcross registry internet serviceprotocol (crisp) requirements,ó rfc 3707, february 2004, available at <http://www.rfceditor.org>. however, in may 2005 it was still unclear how long it would take for all theelements to be approved, published, and implemented.neric entry (for a fee). thus, changes to the whois process need to be conceived in a systematic way that accounts for the varying legitimate perspectives. the example of local telephone directories is offered for illustrative purposes only. the committee is not recommending this specificmodel per se, although the analogy can also be helpful since personal data(name, address, and phone number) are made publicly available throughprinted (and now online) directories, just as they are through whois services.recommendation: future systems that support whois data management and access should be designed to allow for gradations in accesswhile maintaining some degree of free access to whois information. thewhois protocol will have to be replaced to accommodate the desired gradations in access.136signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.2816internet navigation:emergence and evolutionas the previous chapters show, the domain name system has beena foundation for the rapid development of the internet. domainnames appear on the signposts designating origins and destinations linked by the internet and in the addresses used by the principal applications traversing the internetñemail and the world wide web. andthey have been useful for navigating across the internet: given a domainname, many web browsers will automatically expand it into the uniformresource locator (url) of a web site; from a domain name, many emailusers can guess the email address of an addressee. for these reasons,memorable domain names may often acquire high value. their registrantsbelieve that searchers can more readily find and navigate to their offerings.however, as the internet developed in size, scope, and complexity, thedomain name system (dns) was unable to satisfy many internet usersõneeds for navigational assistance. how, for example, can a single web pagebe found from among billions when only its subject and not the domainname in its url is known? to meet such needs, a number of new types ofaids and services for internet navigation were developed.1 while, in theend, these generally rely on the domain name system to find specificinternet protocol (ip) addresses, they greatly expand the range of ways inwhich searchers can identify the internet location of the resource they seek.1the difference between a navigation aid and a navigation service is one of degree. anavigation service, such as the offerings of a search engine service provider, are more elaborate and extensive than those offered by a navigation aid, such as the bookmark feature of aweb browser.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.282signposts in cyberspacethese navigational aids and services have, in return, relieved some ofthe pressure on the domain name system to serve as a de facto directoryof the internet and have somewhat reduced the importance of the registration of memorable domain names. because of these tight linkages between the dns and internet navigation, this chapter and the next onesaddressñat a high levelñthe development of the major types of internetnavigational aids and services. this chapter is concerned with their pastdevelopment. the next chapter deals with their current state. and thefinal chapter on internet navigation, chapter 8, considers the technological prospects and the institutional issues facing them.after describing the distinctive nature of internet navigation, this chapter traces the evolution of a variety of aids and services for internet navigation. while its primary focus is on navigating the world wide web, it doesnot cover techniques for navigation within web sites, which is the subject ofspecialized attention by web site designers, operators, and researchers.26.1the nature of internet navigationnavigation across the internet is sometimes compared to the wellstudied problem of readers navigating through collections of printed materialand other physical artifacts in search of specific documents or specific artifacts. (see the addendum to this chapter: òsearching the web versussearching libraries.ó) that comparison illustrates the differences in thetechnical and institutional contexts for internet navigation. internet navigation for some purposes is similar to searches in library environmentsand relies on the same tools, whereas navigation for other purposes maybe performed quite differently via the internet. the multiple purposes anddiverse characteristics listed below combine to make navigating to a resource across the internet a much more varied and complex activity thanthose previously encountered. the library examples provide a point of reference and a point of departure for discussion in subsequent chapters.6.1.1vast and varied resources for multiple purposesfirst, the internet connects its users to a vast collection of heterogeneousresources that are used for many purposes, including the dissemination of information; the marketing of products and services; communication with others; and the delivery of art, entertainment, and a wide range of commercial andpublic services. the kinds of resources connected to the internet include:2see, for example, merlyn holmes, web usability & navigation: a beginnerõs guide, mcgrawhill/osborne, berkeley, calif., 2002; and louis rosenfeld and peter morville, informationarchitecture for the world wide web: designing large scale sites, 2nd edition, oõreilly & associates, sebastopol, calif., 2002.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution283¥documents that differ in language (human and programming),vocabulary (including words, product numbers, zip codes, latitudes andlongitudes, links, symbols, and images), formats (such as the hypertextmarkup language (html), portable document format (pdf), or jointphotographic experts group (jpeg) format), character sets, and source(human or machine generated).¥nontextual information, such as audio and video files, and interactive games. the volume of online content (in terms of the number ofbytes) in image, sound, and video formats is much greater than that ofmost library collections and is expanding rapidly.¥transaction services, such as sales of products or services, auctions,tax return preparation, matchmaking, and travel reservations.¥dynamic information, such as weather forecasts, stock market information, and news, which can be constantly changing to incorporatethe latest developments.¥scientific data generated by instruments such as sensor networksand satellites are contributing to a òdata deluge.ó3 many of these data arestored in repositories on the internet and are available for research andeducational purposes.¥custom information constructed from data in a database (such asproduct descriptions and pricing) in response to a specific query (e.g., pricecomparisons of a product listed for sale on multiple web sites).consequently, aids or services that support internet navigation facethe daunting problem of finding and assigning descriptive terms to eachof these types of resource so that it can be reliably located. searchers facethe complementary problem of selecting the aids or services that will bestenable them to locate the information, entertainment, communication link,or service that they are seeking.6.1.2twosided processsecond, internet navigation is twosided: it must serve the needs bothof the searchers who want to reach resources and of the providers thatwant their resources to be found by potential users.from the searcherõs perspective, navigating the internet resembles tosome extent the use of the information retrieval systems that were developed3see tony hey and anne trefethen, òthe data deluge: an escience perspective,ó gridcomputing: making the global infrastructure a reality, fran berman, geoffrey fox, and anthony j.g. hey, editors, wiley, 2003.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.284signposts in cyberspaceover the last several decades within the library and information science4 andcomputer science communities.5 however, libraryoriented retrieval systems,reflecting the welldeveloped norms of librarians, were designed to describeand organize information so that users could readily find exactly what theywere looking for. in many cases, the same people and organizations wereresponsible both for the design of the retrieval systems and for the processesof indexing, abstracting, and cataloging the information to be retrieved. inthis information services world, the providerõs goal was to make descriptionand search as neutral as possible, so that every document relevant to a topicwould have an equal chance of being retrieved.6 while this goal of retrievalneutrality has carried over to some internet navigation services and resourceproviders, it is by no means universal. indeed, from the perspective of manyresource providers, particularly commercial providers, attracting users viathe internet requires the application to internet navigation of nonneutralmarketing approaches deriving from advertising and public relations as developed for newspapers, magazines, radio, television, and yellowpages directories.7 research on neutral, communitybased technology for describinginternet resources is an active area in information and computer science andis a key element of the semantic web (see box 7.1).84for an overview, see elaine svenonius, the intellectual foundation of information organization, mit press, cambridge, mass., 2000; and christine l. borgman, from gutenberg to theglobal information infrastructure: access to information in the networked world, mit press, cambridge, mass., 2000.5for an overview, see ricardo baezayates and berthier ribieroneto, modern informationretrieval, addisonwesley, boston, 1999; and karen sparck jones and peter willett, editors,readings in information retrieval, morgan kaufmann, san francisco, 1997. for typical examples of early work on information retrieval systems, see, for example, george schecter,editor, information retrievalña critical view, thompson book company, washington, d.c.,1967. for work on retrieval from large databases, see the proceedings of the annual textretrieval conference (trec), currently sponsored by the national institute of standards andtechnology and the advanced research and development activity, available at <http://trec.nist.gov>.6see svenonius, the intellectual foundation of information organization, 2000.7see, for example, john caples and fred e. hahn, tested advertising methods, 5th edition,prenticehall, new york, 1998.8e. bradley, n. collins, and w.p. kegelmeyer, òfeature characterization in scientificdatasets,ó pp. 112 in proceedings of the 4th international conference on advances in intelligentdata analysis (lecture notes in computer science, vol. 2189), springerverlag, 2001; v.brilhante, òusing formal metadata descriptions for automated ecological modeling,ó pp.9095 in environmental decision support systems and artificial intelligence, aaai press, menlopark, calif., 1999; e. hovy, òusing an ontology to simplify data access,ó communications ofthe acm 46(1):4749, 2003; owl web ontology language guide, òw3c recommendation(10 february 2004),ó november 24, 2004, available at <http://www.w3.org/tr/owlguide>;and p. wariyapola, s.l. abrams, a.r. robinson, k. streitlien, n.m. patrikalakis, p. elisseeff,and h. schmidt, òontology and metadata creation for the poseidon distributed coastalzone management system,ó proceedings of the ieee forum on research and technology advances in digital libraries, ieee computer society, los alamitos, calif., 1999, pp. 180189.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution285for commercial providers, therefore, the challenge is how to identifyand reachñin the complex, diverse, and global audience accessible viathe internetñpotential users who are likely to be interested (or can bemade interested) in the providerõs materials. that is done in traditionalmarketing and public relations through the identification of media andplaces (television or radio programs, magazines, newspapers in specificlocations) that an audience with the desired common characteristics (forexample, 18 to 24yearold males) frequents. similar approaches can beapplied on the internet (see section 7.2.2), but unlike the traditional media, the internet also offers providers the distinctive and extremely valuable opportunity to capture their specific audience during the navigationprocess itself, just when they are searching for what the provider offersñfor example, by paying to be listed or featured in a navigation serviceõsresponse to specific words or phrases. (see òmonetized searchó in section7.1.7.) marketers have found ways to use the specific characteristics of theinternet,9 just as they have developed methods appropriate for each newmedium.10 this has led, for example, to the establishment of companiesthat are devoted to finding ways to manipulate internet navigation services to increase the ranking of a clientõs web site and, in response, to thedevelopment of countermeasures by the services. (see òsearch enginemarketing and optimizationó in section 7.1.7.)for noncommercial resources, the situation is somewhat different,since the providers generally have fewer resources and may have lessincentive to actively seek users, at least to the extent of paying for webadvertising or search engine marketing. at the same time, the existence ofa specific noncommercial resource may be well known to the communityof its potential users. for example, the members of a scholarly communityor a nonprofit organization are likely to be aware of the internet resourcesrelevant to their concerns. those new to a community or outside it aredependent on internet navigation tools to locate these resources.internet navigation is a complex interplay of the interests of both thesearchers for and the providers of resources. on the internet, the9see, for example, joe cappo, the future of advertising: new media, new clients, newconsumers in the posttelevision age, mcgrawhill, new york, 2003; and barbara cox andwilliam koelzer, internet marketing, prenticehall, new york, 2004.10it should be noted that the internet, by making the marginal cost of an email messageextremely low, has also enabled providers to conduct a nondiscriminating search for potential users by broadcasting spam email. although this might be considered a variant ofinternet navigation, where the provider actively advertises its location to a vast audiencewhose members may or may not be interested, its onesided benefits and frequent use fordishonest or illegal purposes disqualify it for inclusion in this report, which focuses onsearcherbeneficial navigation aids and services.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.286signposts in cyberspacelibrarianõs ideal of neutral information retrieval often confronts the realityof selfinterested marketing.6.1.3complexity and diversity of uses, users, and providersthird, the complexity and diversity of uses of resources on theinternet, of their users, and of their providers significantly complicateinternet navigation. it becomes a multidimensional activity that incorporates behaviors ranging from random browsing to highly organizedsearching and from discovering a new resource to accessing a previouslylocated resource.11studies in information science show that navigation in an informationsystem is simplest and most effective when the content is homogeneous,the purposes of searching are consistent and clearly defined, and thesearchers have common purposes and similar levels of skills.12 yet,internet resources per se often represent the opposite case in all of theserespects. their content is often highly heterogeneous; their diverse usersõpurposes are often greatly varied; the resources the users are seeking areoften poorly described; and the users often have widely varying degreesof skills and knowledge. thus, as the resources accessible via the internetexpand in quantity and diversity of content, number and diversity of users, and variety of applications, the challenges facing internet navigationbecome even more complex.indeed, prior to the use of the internet as a means to access information, many collections of information resources, whether in a library or anonline information system, were accessed by a more homogenous collection of users. it was generally known when compiling the collectionwhether the content should be organized for specialists or lay people, andwhether skill in the use of the resource could be assumed. thus, navigation aids, such as indexes or catalogs, were readily optimized for theirspecific content and for the goals of the people searching them. healthinformation in a database intended for searching by physicians could beindexed or cataloged using specific and highly detailed terminology thatassumed expert knowledge. similarly, databases of case law and statutelaw assumed a significant amount of knowledge of the law. in fields suchas medicine and law, learning the navigation tools and the vocabulariesof the field is an essential part of professional education. many such databases are now accessible by specialists via the internet and continue toassume a skillful and knowledgeable set of users, even though in some11see shanju chang and ronald e. rice, òbrowsing: a multidimensional framework,óannual review of information science and technology 28:231276, 1993.12see borgman, from gutenberg to the global information infrastructure, 2000.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution287cases they are also accessible by the general public. with the growth ininternet use, however, many more nonspecialist users have ready accessto the web and are using it to seek medical, legal, or other specializedinformation. the user community for such resources is no longer welldefined. few assumptions of purpose, skill level, or prior knowledge canbe made about the users of a web information resource. consequently, itis generalpurpose navigation aids and services and less specialized (andpossibly lowerquality) information resources that must serve their needs.6.1.4lack of human intermediariesfourth, the human intermediaries who traditionally linked searcherswith specific bodies of knowledge or servicesñsuch as librarians, travelagents, and real estate agentsñare often not available to users as theyseek information on the internet. instead, users generally navigate to theplaces they seek and assess what they find on their own, relying on theaid of digital intermediariesñthe internetõs general navigation aids andservices, as well as the specialized sites for shopping, travel, job hunting,and so on. human intermediariesõ insights and assistance are generallyabsent during the navigation process.human search intermediaries help by selecting, collecting, organizing, conserving, and prioritizing information resources so that they areavailable for access.13 they combine their knowledge of a subject areaand of informationseeking behavior with their skills in searching databases to assist people in articulating their needs. for example, travelershave relied on travel agents to find them the best prices, best routes, andbest hotels, and to provide services such as negotiating with hotels, airlines, and tour companies when things go wrong. intermediaries oftenask their clients about the purposes for which they want information (e.g.,what kind of trip the seekers desire and how they expect to spend theirtime; what they value in a home or neighborhood; or what research questions their term paper is trying to address), and elicit additional detailsconcerning the problem. these intermediaries also may help in evaluating content retrieved from databases and other sources by offering counsel on what to trust, what is current, and what is important to consider inthe content retrieved.with the growth of the internet and the world wide web, a profoundchange in the nature of professional control over information is takingplace. travel agents and real estate agents previously maintained tightcontrol over access to fares and schedules and to listings of homes for13see chapter 7, òwhither, or wither, libraries?,ó in borgman, from gutenberg to the globalinformation infrastructure, 2000.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.288signposts in cyberspacesale. until recently, many of these resources were considered proprietary,especially in travel and real estate, and consumers were denied direct access to their content. information seekers had little choice but to delegatetheir searches to an expertña medical professional, librarian, paralegal,records analyst, travel agent, real estate agent, and so on. today, travelreservation and real estate information services are posting their information on the internet and actively seeking users. specialized travel sites,such as expedia.com and travelocity.com, help the user to searchthrough and evaluate travel options. similar sites serve the real estatemarket. travel agents that remain in business must get their revenue fromother valueadded services, such as planning customized itineraries andtours and negotiating with brokers. although house hunters now can domost of their shopping online, in most jurisdictions they still need realestate agents with access to house keys to show them properties and toguide them in executing the legal transactions. libraries have respondedto the web by providing òvirtual reference servicesó in addition to traditional onsite reference services.14 other entities, including the u.s. department of education, have supported the creation of nonlibrarybasedreference services that use the internet to connect users with òpeople whocan answer questions and support the development of skillsó withoutgoing through a library intermediary.156.1.5democratization of information access and provisionfifth, the internet has hugely democratized and extended both theoffering of and access to information and services. barriers to entry,whether cost or credentials, have been substantially reduced. anyone withmodest skill and not much money can provide almost anything online,and anyone can access it from almost anywhere. rarely are credentialsrequired for gaining access to content or services that are connected to thepublic internet, although paid or free registration may be necessary togain access to some potentially relevant material. not only commercialand technical information are openly accessible, but also the full range ofpolitical speech, of artistic expression, and of personal opinion are readilyavailable on the public internetñeven though efforts are continually be14see, for example, the more than 600 references about such services in bernie sloan, òdigital reference services bibliography,ó graduate school of library and information science,university of illinois at urbanachampaign, november 18, 2003, available at <http://www.lis.uiuc.edu/~bsloan/digiref.html>.15for example, the virtual reference desk is òa project dedicated to the advancement ofdigital reference.ó see <http://www.vrd.org/about.shtml>. this service is sponsored bythe u.s. department of education.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution289ing made to impose restrictions on access to some materials by variouspopulations in a number of countries.16in a great many countries, anyone can set up a web siteñand manypeople do. the freedom of the press does not belong just to those whoown one; now nearly anyone can have the opportunity to publish via avirtual pressñthe world wide web.17 whether or not what they publishwill be read is another matter. that depends on whether they will befound, and, once found, whether they can provide content worthy of perusalñat least by someone.for the most part, in many places, provision of or access to content orservices is uncensored and uncontrolled. on the positive side, the internetenables access to a global information resource of unprecedented scopeand reach. its potential impact on all aspects of human activity is profound.18 but the institutions that select, edit, and endorse traditionallypublished information have no role in determining much of what is published via the internet. the large majority of material reachable via theinternet has never gone through the customary editing or selection processes of professional journals or of newspapers, magazines, and books.19so in this respect as well, there has been significant disintermediation,leaving internet users with relatively few solid reference points as theynavigate through a vast collection of information of varying accuracy andquality. in response to this widely acknowledged problem, some groupshave offered evaluations of materials on the world wide web.20 one16these range from the efforts of parents to prevent their children from accessing ageinappropriate sites to those made by governments to prevent their citizens from accessingpolitically sensitive sites. the current regulations placed on libraries in the united states tofilter content are available at <http://hraunfoss.fcc.gov/edocspublic/attachmatch/fcc03188a1.pdf>. see also, information on the increasing sophistication of filtering efforts inchina in david lee, òwhen the net goes dark and silent,ó south china morning post, october 2, 2002, available at <http://cyber.law.harvard.edu/people/edelman/pubs/scmp1001022.pdf>. for additional information, see jonathan zittrain and benjamin edelman,empirical analysis of internet filtering in china, beckman center for internet & society,harvard university, 2002, available at <http://cyber.law.harvard.edu/filtering/china/>.17the rapid growth in the number of blogs (short for web logs) illustrates this. accordingto òhow much information?,ó there were 2.9 million active web logs in 2003. see peterlyman and hal r. varian, òhow much information?,ó 2003, retrieved from <http://www.sims.berkeley.edu/research/projects/howmuchinfo2003> on april 27, 2005.18see borgman, from gutenberg to the global information infrastructure, 2000; and thomasfriedman, òis google god?ó, new york times, june 29, 2003.19however, it must be acknowledged that many òtraditionaló dissemination outlets (e.g.,wellknown media companies) operate web sites that provide material with editorialreview.20see, for example, the information quality www virtual library at <http://www.ciolek.com/wwwvlinfoquality.html> and evaluating web sites: criteria and tools at<http://www.library.cornell.edu/okuref/research/webeval.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.290signposts in cyberspaceexample is the librariansõ index to the internet,21 whose motto is òinformation you can trust.ó6.1.6lack of context or lack of skillsixth, most generalpurpose internet navigation services can assumenothing about the context of a search beyond what is in the query itself.the circumstances of the person searching the internetñwho could beanyone, searching for almost any purpose, from almost any placeñaregenerally not known or, if known, not used.22 while an unskilled userplanning a european trip who types òparisó into a navigation service mayexpect to receive back only information on the city of paris, france, or ifstudying the iliad may expect to find out about the greek hero, the navigation service has no knowledge of that context. if it relies on the textalone, it may return information about both, as well as information aboutsources for plaster of paris, the small town in texas, movies set in paris,and people with the first or family name of paris.while any generalpurpose navigation service would be unable to ascertain which of those specific answers was desired, the person initiatingan internet request always knows its context, and if experienced ortrained, should be able to incorporate some of that information in thequery. an experienced searcher could incorporate context by expandingthe query to òparis france,ó òparis and iliad,ó òparis texas,ó or òplaster ofparis.ó so the lack of context in many navigation requests is closely related to the userõs level of training or experience in the use of navigationservices.2321òlibrariansõ index to the internet (lii) is a searchable, annotated subject directory ofmore than 12,000 internet resources selected and evaluated by librarians for their usefulnessto users of public libraries. lii is used by both librarians and the general public as a reliableand efficient guide to internet resources.ó quoted from <http://lii.org/search/file/about>,accessed on may 2, 2004.22an online advertising company, doubleclick, launched a service in 2000 to track peopleõsinternet usage in order to serve ads based on personal taste. after considerable controversy,especially from federal regulators and privacy advocates, and an inability to develop anadequate market, the profiling service was terminated at the end of 2001. see stefanie olsen,òdoubleclick turns away from ad profiles,ó c/net news.com, january 8, 2002, available at<http://news.com.com/21001023803593.html>. however, yahoo! indicates in its privacypolicy that it does use information provided by those who register at its site òto customizethe advertising and content you see, fulfill your requests for products and services . . . .ó23see, for example, steven johnson, òdigging for googleholes,ó slate.com, july 16, 2003,available at <http://slate.msn.com/id/2085668/>; donald o. case, looking for information:a survey of research on information seeking, needs, and behavior, academic press, san diego,calif., 2002; and paul solomon, òdiscovering information in context,ó annual review of information science and technology, blaise cronin, editor, information today, inc., medford,n.j., 2002, pp. 229264.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution291the incorporation of context is also related to the degree to which thenavigation service is itself specialized. when people searched in traditional information sources, the selection of the source usually carried information about the context for a search (e.g., seeking a telephone numberin the white pages for manhattan in particular, or looking for a home inthe multiple listing service for boston specifically). furthermore, therewere often intermediaries who could obtain contextual information fromthe information seeker and use that to choose the right source and refinethe information request. although the former approach is also availableon the internet through internet white pages and internet real estatesearch sites, the latter is just developing through the virtual reference services mentioned earlier.generalpurpose navigation services are exploring a variety of mechanisms for incorporating context into search. for example, both yahoo! andgoogle now allow local searches, specified by adding a location to thesearch terms. the siteflavored google search customizes searches originating at a web site to return search results based on a profile of thesiteõs content. other recent search engines such as vivisimo(www.vivisimo.com) return search results in clusters that correspond todifferent contextsñfor example, a search on the keyword ònetworkó returns one cluster of results describing cable networks, another on network games, and so on.24still, issues of context complicate internet navigation because the mostwidely used navigation services are general purposeñsearching the vastarray of objects on the internet with equal attentionñand because manyusers are not experienced or trained and have no access to intermediariesto assist them.6.1.7lack of persistenceseventh, there is no guarantee of persistence for material at a particular location on the internet. while there is no reason to believe that everything made accessible through the internet should persist indefinitely,there are a great many materials whose value is such that many userswould want to access them at the same internet address at indefinite timesin the future. for example, throughout this report there are two kinds ofreferences: those to printed materialsñbooks, journals, newspapersñandthose to digital resources that are located via web pages. there is a veryhigh probability that whenever this report is read, even years after itspublication, that every one of the referenced printed materials will be ac24see chris gaither, ògoogle offers sites its services,ó los angeles times, june 19, 2004, p. c2.also see <http://www.google.com/services/siteflavored.html>, accessed on june 18, 2004.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.292signposts in cyberspacecessible in unchanged form through (though not necessarily in) any goodlibrary (at least in the united states). there is an equal certainty that whenever this report is read, even in the year of its publication, some of thereferenced web pages either will no longer be accessible or will no longercontain the precise material that was referenced. the proportion of missing or changed references will increase over time. to the extent that itwould be valuable to locate the referenced web material, there is a problem of persistence (see box 6.1) of resources on the internet.25the problem of persistence arises because material connected to theinternet is not generally governed by the conventions, standards, andpractices of preservation that evolved with regard to printed material.the material may change in many ways and for many reasons. it mayremain the same, but the location may change because of a change of computers, or a redesign of a web site, or a reorganization of files to savespace, or a change in internet service providers (isps).26 or it may bereplaced at the same location by an improved version or by somethingentirely different but with the same title. it may disappear completelybecause the provider stops operating or decides not to provide it any moreor it may be replaced by an adequate substitute, but at a different location.thus, navigation to an item is often a onetime event. incorporating a reference or a link to that item in another document is no guarantee that afuture seeker will find the same item at the same location. nor is there anyguarantee that something once navigated to will be there when the recorded path is followed once more or that it will be the same as it waswhen first found.the problem is exacerbated for material on the world wide web byits structureña hyperlinked web of pages. even if a specific web pagepersists indefinitely, it is unlikely that the many pages to which it linkswill also persist for the same period of time, and so on along the path oflinked pages. so to the extent that the persistent page relies on those towhich it links, its persistence is tenuous.25one example of the lack of persistence of important information is u.s. governmentdocuments published only on the web. the u.s. government printing office has begun aneffort to find and archive such electronic documents. see florence olsen, òa crisis for webpreservation,ó federal computer week, june 21, 2004, available at <http://www.fcw.com/fcw/articles/2004/0621/polcrisis062104.asp>.26thomas phelps and robert wilensky of the university of california at berkeley have suggested a way to overcome the difficulties caused by shifting locations. they add a small numberof words carefully selected from the page to its url. if the url is no longer valid, the words canbe used in a search engine to find the pageõs new location. see thomas phelps and robertwilensky, òrobust hyperlinks: cheap, everywhere, now,ó proceedings of the 8th international conference on digital documents and electronic publishing (lecture notes in computerscience, vol. 2023), springerverlag, 2004.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution293box 6.1discovery, retrieval, and persistencenavigation is a twostep process: discovery and then retrieval. the discovery process involves identifying the location of the desired material ona web site. the retrieval process involves obtaining the located material atthe identified url. (see box 6.2.) discovery may find dynamically generated pages for which only a transient url exists, such as driving directionsbetween two locations or an online order, or a constant url that has everchanging information, such as a weather service. it may not be possible oreven feasible (last yearõs weather forecast) to retrieve the same pages again.thus, not even a hyperlink to that material can be embedded in otherpages, nor can the page be bookmarked for future reference.even if the resource is itself static, such as the text of a research report,it may be moved, invalidating the url. more problematically, it may benecessary to decide whether what is retrieved a second time (even if it is inthe same place) is the same as what was retrieved previously. unless theoriginal object and the (possibly) new one are identical bitbybit, the question of whether the two are òthe same,ó or identical, raises longstandingquestions that are typically very subjective and/or contextual: is a translation into another language the same as the original? if a document is reformatted, but all of the words are the same, is it identical to the original? if adocument is compressed, or transposed into a different character code, oradapted to a different version of a viewer program, is it still the same document? is a second edition an acceptable match to a request for the firstedition? and so on. for each of these questions, the correct answer is probably òsometimes,ó but òsometimesó is rarely a satisfactory answer, especially if it is to be evaluated by a computer system.if things are abstracted further so that, instead of discovering a urldirectly, the user utilizes an updatable bookmark that incorporates a reference to the discovery processes, the meaning of persistence becomes evenmore ambiguous. such a bookmark, intended to reference a list of restaurants in a particular city, might upon being used not only discover a newerversion of the same list, but also find a newer, more comprehensive, listfrom a different source and at an entirely different location on the network.so what is persistent in this case is not the answer, but the question.these are arguably not new conundrumsñanalogies occur with editions of books and bibliographies, but the opportunities on the internet forfaster turnover and for changes of finer granularity, as well as the ability toupdate search indexes at very high frequency, make the meaning andachievement of internet persistence more complex and ambiguous anddifficult to understand for the casual user.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.294signposts in cyberspace6.1.8scaleeighth, the internetñin particular, the world wide webñvastly exceeds even the largest traditional libraries in the amount of material that itmakes accessible.27 in 2003, the world wide web was estimated to contain 170 terabytes of content in its surface, readily accessibleñpublicñsites. this compares with an estimated 10 terabytes of printed documentsin the library of congress (which also contains many terabytes of material in other media). in addition, the òdarkó web is estimated to contain400 to 450 times as much content in its databases and in other forms inaccessible to search engines,28 a ratio that may be increasing. (see in section7.1.7 the discussion titled òthe deep, dark, and invisible web.ó)6.1.9the sum of the differencesfor all the reasons described above, navigation on the internet is different from navigating through traditional collections of documents; finding information or services through the use of knowledgeable intermediaries; locating the television audience for a commercial or politicalmessage; or reaching the readers for an essay. navigating the internet iseven more than the sum of all those differences over a much larger extentand variety of resources and a much greater number and diversity of users and providers.conclusion: finding and accessing a desired resource via the internetposes challenges that are substantially different from the challenges facedin navigating to resources in nondigital, nonnetworked environmentsbecause of differences in content, purpose, description, user community,institutional framework, context, skill, persistence, and scale.fortunately, the internet has also served as the infrastructure for thedevelopment of new means for responding to these challenges. as thefollowing section and the next chapter show, a wide range of navigationaids and services now permit large segments of the internet to be traversed rapidly and efficiently in ways previously unimaginable, providing ready access to a vast world of human knowledge and experience tousers across the globe and opening an international audience to purveyors of content and services no matter where they may be located.27because the web contains a large amount of òformat overheadó and nonreliable information, this comparison was disputed for the web of 2000 (2550 terabytes estimated) byresearchers from oclc. see edward t. oõneill et al., òtrends in the evolution of the publicweb 19982002,ó dlib magazine 9(4), 2003, at <http://www.dlib.org/dlib/april03/lavoie/04lavoie.html>.28these data are taken from lyman and varian, òhow much information?,ó 2003.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution2956.2internet navigation aids and servicesñhistoryaids and services to assist internet navigation have had to evolvesteadily to keep pace with the growth in the scale, scope, and complexityof material on the internet.29in the first years of the internet,30 the 1970s and 1980s, informationwas accessed through a twostep process: first, the host on which a desired resource resided was found,31 and then the desired file was found.32a good example of this hostoriented navigation is the file transfer protocol (ftp). retrieving a file using ftp required that the user (using ftpclient software) already know the name of the host (which would be using ftp server software) on which the file was stored,33 have a login nameand password for that host (unless anonymous login was permitted),know a file name, and sometimes have other information such as an account name for computer time billing.34 the file transfer protocol madeit possible to retrieve data from any ftp server to which one was connected by a network. file names and server locations could be obtained invarious waysñfrom friends, from newsgroups and mailing lists, fromfiles that identified particular resources, or from a few archive serversthat contained very large collections of files with locally created indexing.however, such ad hoc and laborintensive processes do not scale well.more automated processes were needed as the number of internet usersand topics of interest increased substantially.29the early period of rapid development of internet navigation aids was not well documented, nor are there many good references. many of the critical developments are includedin this brief history, but it is not intended to be comprehensive.30in this section, the òinternetó also includes the arpanet. see chapter 2.31while a few protocols did not explicitly name a host, in most cases that meant that thehost name was implicit in the service being requested (e.g., running a program that querieda central database that resides only on the network information center (nic) computerimplies the host name of interest).32at a technical level, this still occurs, but is less visible to the user. for example, a urlcontains a domain (host) name, and the client (browser in the case of the web) uses someprotocol (usually the hypertext transfer protocol (http) in the case of the web) to open aconnection to a specified host. the rest of the url is then transmitted to that host, whichreturns data or takes other action.33once the desired ftp server was located, ftp eventually included capabilities to traveldown directory hierarchies to find the desired files. (at the time ftp was designed, theprotocol did not contain any provision for dealing with hierarchical filesñthat was addedsomewhat later.) user names and the account command were, on many systems, the primary mechanism for providing context for the file names. that is, òuseró and òacctó werenavigational commands as much as they were authentication and authorization commands.34frequently, some documentation about the content of directories was provided in fileswith the file name of òreadme.txtó or some variation thereof, such as aaread.me, to takeadvantage of alphabetic sorting when the directory was retrieved.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.296signposts in cyberspace6.2.1aiding navigation via the internetthe first response to the need for automated processes was archie,35a selective index of those files thought to be òinterestingó by those whosubmitted them to the index and of the ftp servers on which they werelocated. when archie was first released in 1989, many people were skeptical of the idea of having an index of such large size on one computer, butarchie was a success. it consisted of three components: the data gatherer,the index merger, and the query protocol. the gathering of data was notdone by brute force. the company that took over operation of the archieservice (bunyip information systems) relied on licensed archie serveroperators all over the world (who knew which ftp archives were reliable) to run a data gatherer that indexed local files by searching each localsite.36 each local gatherer passed the partial index upstream, and eventually the partial indexes were merged into a full index having fairly simplefunctionality, primarily limited to singlelevel alphabetic sorting. this process of collaborative gathering saved time and minimized the bandwidthrequired. a special protocol allowed clients to query the full index, whichwas replicated on servers around the world, to identify the ftp serverthat contained the requested file. archie still required users to employ ftp to download the files ofinterest for viewing on their local computers. the next aid, gopher, wasdeveloped as a protocol for viewing remote files, which were in a specified format, on a userõs local computer. it became the first navigation aidon the internet that was easily accessible by noncomputerscience specialists.37 the gopher òbrowseró provided users with the capability tolook at the content of a file on the computer that stored it, and if the fileincluded a reference to another file, to òclickó directly on the link to seethe contents of the second file. gopher included some metadata38 so that,for example, when a user clicked on a link, the userõs client software would35òarchieó is not an acronym but is a shortening of the word òarchiveó to satisfy softwareconstraints. peter deutsch, alan emtage, bill heelan, and mike parker at mcgill universityin montr”al created archie.36the burden this imposed on the ftp servers led the operators of many of them to createand keep up to date an archieusable listing of the server in its root directory and to keepthose listings up to date, obviating the need for archie to search the server.37gopher, created in 1991 by marc mccahill and his technical team at the university ofminnesota, is not an acronym but is named after the mascot at the university of minnesota.see chris sherman, òsearchday,ó number 198, february 6, 2002, available at <http://searchenginewatch.com/searchday/02/sd0206gopher.html>.38metadata are data that describe the characteristics or organization of other data. seemurtha baca, introduction to metadata: pathways to digital information, getty information institute, los angeles, 1998.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution297automatically check the metadata, choose the desired document format,and start the appropriate program to deal with the data format.to overcome gopherõs limitation to files on a single computer, a central search aid for gopher filesñveronicañwas created in 1992.39 it didfor gopher what archie did for ftp. veronica was the first service thatused bruteforce software robots (software that automatically searchedthe internet) to collect and index information and, therefore, could be seenas the forerunner of web search engines. in 1993, jughead added keywords and boolean search capabilities to veronica.40the next step in the evolution of internet navigation aids was the widearea information server (wais) that enabled search using word indices ofspecified files available on the internet.41 the wais search engine received a query, sought documents relevant to the question in its databaseby searching the word indices, and returned a list of documents orderedby estimated relevance to the user. each document was scored from 1 to1000 based on criteria such as its match to the userõs question as determined by how many of the query words it contained and their importance in the document. wais did not index the entire internet, but ratheronly specific files and servers on it. at its peak, wais linked up to 600databases, worldwide.42 it was used, for example, by dow jones to createa fully indexed online file of its publications. wais was an important stepbeyond ftp, gopher, and archie (and friends) because it built on knowninformationretrieval methods43 and standards, including the z39.50òsearch and retrieveó standard as its key data representation model.4439veronica (very easy, rodentoriented, netwide index to computerized archives) wascreated in november 1992 by fred barrie and stephen foster of the university of nevadasystem computing services group.40jughead (jonzyõs universal gopher hierarchy excavation and display) was created byrhett òjonzyó jones at the university of utah computer center. the names of these twoprotocols were derived from characters in archie comics. see <http://www.archiecomics.com/>.41wais was developed between 1989 and 1992 at thinking machines corporation underthe leadership of brewster kahle. unlike archie (and friends), gopher, and the web, waiswas firmly rooted in information sciences approaches and technology.42richard t. griffiths, òchapter four: search engines,ó history of the internet, leiden university, the netherlands, 2002, available at <http://web.let.leidenuniv.nl/history/ivh/chap4.htm>.43many of the navigation aids and services described in this history drew inspiration andmethodology from the long line of research in information science, as well as computerscience. it has not been possible to give full credit to those antecedents in this brief history.44for information about the z39.50 protocol, see national information standards organization, z39.50 resource page, available at <http://www.niso.org/z39.50/z3950.html#other>;and mark needleman, òz39.50ða review, analysis and some thoughts on the future,ólibrary hitech 18(2):15865, 2000, available at <http://www.bibliotech.com/html/z39.50.html>, accessed on june 23, 2004.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.298signposts in cyberspaceftp with archie, gopher with veronica and jughead, and wais demonstrated three ways to index and find information on the internet.45 theylaid the foundation for the subsequent development of aids for navigating the world wide web.6.2.2aiding navigation through the world wide webwhile those early navigation aids were being developed, a new wayof structuring information on the internet46ñthe world wide webñwasunder development at the european organization for nuclear research(cern) in geneva.47 many of the concepts underlying the web existed ingopher, but the web incorporated more advanced interface features, wasdesigned explicitly for linking information across sites, and employed acommon language, called hypertext markup language (html), to describe web content. with the deployment of the mosaic browser48 and itswidely adopted commercial successorsñnetscapeõs navigator andmicrosoftõs internet explorerñit became easy to view html formatteddocuments and images located on the web, making it much more appealing to most users than gopherõs textoriented system.indeed, the use of browsers on the web eventually replaced the use ofwais, ftp/archie and gopher/veronica. at the same time, the webunintentionally made domain names valuable as identifiers, thereby raising their profile and importance. while ftp and gopher sites used do45see michael f. schwartz, alan emtage, brewster kahle, and b. clifford neuman, òacomparison of internet discovery approaches,ó computing systems 5(4):461493, 1992.46the webõs structure is hypertext, which was anticipated in the form of òassociative indexingó by vannevar bush in a famous article, òas we may think,ó published in the atlantic monthly in july 1945. the term òhypertextó was coined by theodor (ted) nelson in theearly 1960s. nelson spent many years publicizing the concept and attempting early implementations. douglas c. engelbartõs nls/augment project at the stanford research institute (which in 1977 became known as sri international) first demonstrated a hypertext system in 1968. apple computer introduced hypercard, a commercial implementation ofhypertext for the macintosh, in 1987. the practical implementation of a hypertext data structure on the internet at a time when computer capacity and network speed were finally sufficient to make it practical was cernõs contribution.47tim bernerslee and his team developed the web in 1990. it was first released to thephysics community in 1991 and spread quickly to universities and research organizationsthereafter. see <http://public.web.cern.ch/public/about/achievements/www/history/history.html>.48mosaic, which was released in 1993 by the national center for supercomputing applications (ncsa) at the university of illinois, urbanachampaign, was the first web browserwith a graphical user interface for the pc and apple environments. it had an immediateeffect on the widespread adoption of the web by nonresearch users. marc andreessen, oneof the developers of mosaic, became a cofounder of netscape. see <http://www.ncsa.uiuc.edu/divisions/communications/mosaichistory/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution299main names, these names attracted little attention per se. however, thedevelopment of the web and its meteoric growth linked domain namesand the web very closely through their prominent inclusion in browseraddresses as a key part of uniform resource locators (urls). (see box6.2.) as noted in chapter 2, it was commonplace to navigate across theworld wide web just by typing domain names into the address bar, sincebrowsers automatically expanded them into urls. often, at that time, thedomain names were simply guessed on the assumption that trying a brandname followed by .com had a high probability of success.the web, whose underlying structure is hypertextñresources connected by linksñalso introduced a new and convenient means of navigation: òclickingó on hyperlinks on a page displayed in a browser. hyperlinksgenerally have text, called anchor text, which many browsers display byunderlining and color change. when the user moves the pointer to the anchor text of a hyperlink and clicks the mouse button, the browser finds theassociated url in the code for that page and accesses the correspondingpage.49 thus, navigation across the web from an initial site can consist ofnothing more than a series of clicks on the anchor text of hyperlinks.the world wide web has experienced rapid and continual growth50since the introduction of browsers. in 1993, when the national center forsupercomputing applicationsõ (ncsa) mosaic browser was made publicly available, there were just 200 sites on the web. the growth rate ofweb traffic in 1993 in transmitted bytes was 340,000 percent, as comparedwith 997 percent for gopher traffic.51 by march 1994, web traffic exceededgopher traffic in absolute terms.52 based on one estimate of the numberof internet hosts,53 the exponential growth of web sites continued from49since there is no required association between the hyperlink and its anchor text, there isan opportunity for malicious or criminal misdirection to deliberately bogus sites, which hasbeen exploited recently as a vehicle for identity theft and is referred to as òphishingó oròbrand spoofing.ó50there is difficulty in measuring the rate of growth of and the volume of information onthe web because of the lack of consistent and comprehensive data sources. the lack of consistent measurements over time is also attributable to the very factors that continue to enablethe webõs growthñas the technology and architecture supporting the web have evolved, sohave the methods of characterizing its growth.51see robert h. zakon, òhobbesõ internet timeline,ó rfc 2235, november 1997, availableat <http://www.rfceditor.org>.52see susan calcari, òa snapshot of the internet,ó internet world 5(1, september):5458,1994. also, merit network, inc., internet statistics, 1995, available at <ftp://nic.merit.edu/nsfnet/statistics>. graphics and tables of nsfnet backbone statistics are available at <http://www.cc.gatech.edu/gvu/stats/nsf/merit.html>.53internet systems consortium provides host data, which are available at <http://www.isc.org/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.300signposts in cyberspacebox 6.2uniform resource identifiers (uris)the uniform resource identifier (uri)1 is a general name for resourceidentifiers on the internet. several distinct types of uris have been defined:uniform resource locators (urls), uniform resource names (urns), anduniform resource characteristics (urcs), each of which identifies a resource differently. urls are, by far, the most commonly used of the three.urls are uris that identify resources by their location. although urlscan be used to locate many different types of resources on the internet, themost common urls are those used to identify locations on the world wideweb.2 web urls, such as <http://www.nas.edu>, include òhttpó to designate the hypertext transfer protocol (http) and òwww.nas.eduó to designate the web location of interest. the example below shows the url for thecommitteeõs charter document in html format located in the directory3/cstb/committees/indns, located on the www.nas.edu http server.a url cannot separate the location from the name of a resource. therefore, a url is outdated when a resource is moved to a new location, yet itremains unchanged even when the resource at that location is changed.the urn type of uri was defined to meet the need for a more persistentidentifier. a urn identifies a resource by assigning it a permanent andglobally unique name drawn from a specified name space that is not tied toa location.4 however, there needs to be a continually updated table linking each urn to the current location of the resource it names.a third class of uri, the urc, was proposed to incorporate metadataabout resources and their corresponding urns. urcs have not achievedwidespread acceptance or use.1993 to 1998, with the number of hosts approximately doubling each year.after 1998, the rate of growth in hosts slowed to a doubling every 2 years.web server data54 provides the number of active web sites located via thedns as a measure of the growth in the volume of information on the web.although data are discontinuous, from june 1993 to december 1995, thenumber of web sites doubled every 3 months; from december 1997 todecember 2000, the number doubled approximately every 10 months.54matthew gray of the massachusetts institute of technology compiled data on the growthof web sites from june 1993 to june 1995, which is available at <http://www.mit.edu/people/mkgray/net/webgrowthsummary.html>; the netcraft web server survey beganin august 1995 and is available at <http://www.netcraft.com/survey/reports/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution301an approach different from uris for naming resources on the internetmotivates the handle system.5 a handle consists of two parts separated bya forward slash. the first part is a naming authorityña unique, arbitrarynumber assigned within the handle system, which identifies the administrative unit that is the creator of the handle, but not necessarily the continuing administrator of the associated handles. the part after the slash is alocal name that identifies the specific object. it must be unique to the givennaming authority. the handle system allows a handle to map to more thanone version or attribute of a resource and resolve more than one piece ofdata. the multiple resolution capabilities of handles support extended services such as reverse lookup, multiversioning, and digital rights management.1for a formal definition, see t. bernerslee, r. fielding, and l. masinter, òuniformresource identifiers (uri): generic syntax,ó rfc 2396, august 1998, available at <http://www.rfceditor.org>. for further information, see m. mealling and r. denenberg, editors,òreport from the joint w3c/ietf uri planning interest group: uniform resource identifiers (uris), urls, and uniform resource names (urns): clarifications and recommendations,ó rfc 3305, august 2002, available at <http://www.rfceditor.org>.2the internet assigned numbers authority maintains a register the types of resourcesand access methods supported by uris. see <http://www.iana.org/assignments/urischemes>.3more generally, this string is passed to a server and then interpreted. frequently, thisstring is interpreted as a (partial) directory path and file name.4iana maintains a register of name spaces at <http://www.iana.org/assignments/urnnamespaces>.5the handle system was developed in 1994 by robert e. kahn, founder and presidentof the corporation for national research initiatives (cnri). for the foundational paperdescribing the components of this system, see robert e. kahn and robert wilensky, òaframework for distributed digital object services,ó may 13, 1995, corporation for national research initiatives, reston, va., available at <http://www.cnri.reston.va.us/kw.html>.current status and available software can be found at <http://www.handle.net/>.as the volume of material on the web grew exponentially, simpleguessing and hypertext linking no longer served to find the sites userswanted. nor was the almost daily unindexed list of new sites that ncsapublished (as òncsa whatõs newó) from june 1993 to june 199655 sufficient. new methods for navigating to web resources were badly neededand the need unleashed a flurry of innovation, much of it based in universities and often the product of graduate students and faculty, who recognized the opportunity and had the freedom to pursue it. the new naviga55an archive of those listings is available at <http://archive.ncsa.uiuc.edu/sdg/software/mosaic/docs/whatsnew.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.302signposts in cyberspacetion services took two primary forms: directories and search engines. directories organized web resources by popular categories. search enginesindexed web resources by the words found within them.the sequence of key developments from 1993 through 2004 in bothforms of web navigation system is shown in detail in box 6.3. a broadoverview of the development follows.web navigation service development began in 1993, the year the mosaic browser became available, first to universities and research laboratories, and then more generally on the internet. the first directory and thefirst search engines were created in that year. but it was 1994 when thefirst of the widely used directoriesñyahoo!ñand the first fulltext searchengineñwebcrawlerñwere launched. over the next few years, technological innovation occurred at a rapid pace, with search engines addingnew features and increasing their speed of operation and their coverageof the web as computing and communication technology and system design advanced. lycos, launched in 1994, was the first web search engineto achieve widespread adoption as it indexed millions of web pages. itwas followed in 1995 by excite and alta vista. alta vista in particularoffered speed improvements and innovative search features. with thelaunch of google in beta in 1998 and as a full commercial offering in 1999,the general nature of the technology of search engines appeared to reach aplateau, although there is continual innovation in search algorithms andapproaches to facilitate ease of use. the commercial evolution of searchservices continued rapidly both through additional entries into the market and an increasingly rapid pace of consolidation of existing entries.the evolution of directory technology has been less visible and probablyless rapid. the focus of that evolution appears, rather, to have been on themeans of creating and maintaining directories and on the addition of offerings, including search engines, to the basic directory structure.by the first years of this century, the two worlds of search engines anddirectories had merged, at least commercially. in 2004, google offeredgoogle directory (supplied by open directory) and yahoo! offered yahoosearch (provided by its acquisitionñinktomi) with paid ads (provided byits acquisitionñoverture). by 2004 most commercial navigation servicesoffered advertisements associated with specific responses. these paid adsare the principal source of funding and profit for commercial navigationservices. (commercial internet navigation is discussed in further detail insection 7.2.) associated with this latter development has been the rapidrise of the business of search engine marketing, which helps commercialweb sites to decide in which search engines and directories they shouldpay for ads; and search engine optimization, which helps to design websites so search engines will easily find and index them. (organizationssignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution303that provide these services generally also provide assistance with biddingstrategies and assistance in advertising design.) finally, by 2004, manysearch services had established themselves as portalsñsites whose frontpages offer access to search; news, weather, stock prices, entertainmentlistings, and other information; and links to travel, job search, and otherservices.the development of internet navigation aids and services, especiallythose focused primarily on the web, stands in interesting contrast to thedevelopment of the domain name system as described in chapter 2.conclusion: a wide range of reasonably effective, usable, and readilyavailable internet navigation aids and services have been developed andhave evolved rapidly in the years since the world wide web came intowidespread use in 1993.large investments in research and development are currently beingmade in commercial search and directory services. still, many of the unexpected innovations in internet navigation occurred in academic institutions. these are places with strong traditions of information sharing andopen inquiry. research and education are òproblemrichó arenas in whichstudents and faculty nurture innovation.conclusion: computer science and information science graduate students and faculty played a prominent role in the initial development of agreat many innovative internet navigation aids and services, most ofwhich are now run as commercial enterprises. two of those services havebecome the industry leaders and have achieved great commercial successñyahoo! and google.conclusion: because of the vast scale, broad scope, and ready accessibility of resources on the internet, the development of navigation aids andservices opens access to a much wider array of resources than has heretofore been available to nonspecialist searchers. at the same time, the development of successful internet navigation aids and services opens access to a much broader potential audience than has heretofore beenavailable to most resource providers.one cannot know if the past is prelude, but it is clear that the numberand the variety of resources available on the internet continue to grow,that uses for it continue to evolve, and that many challenges of internetnavigation remain. some of the likely directions of technological development are described in section 8.1signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.304signposts in cyberspacebox 6.3key events in the development of navigation aids andservices for the world wide web1989work started on the inquery engine at the university of massachusetts thateventually led to the infoseek engine.1993first web robot or spider.1 the world wide web wanderer was createdby mit student matthew gray. it was used to count web servers andcreate a databaseñwandexñof their urls.work on the architext search engine using statistical clustering was startedby six stanford university undergraduates, which was the basis for excite search engine launched in 1995.first directory. www virtual library was created by tim bernerslee.aliweb, an archielike index of the web based on automatic gathering ofinformation provided by webmasters, was created by martijn kosters atnexor co., united kingdom.first robotbased search engines launched. the world wide web worm,jumpstation, and repositorybased software engineering (rbse) werelaunched. none indexed the full text of web pages.1994the world wide web worm indexed 110,000 web pages and webaccessible documents; it received an average of 1500 queries a day (inmarch and april).first searchable directory of the web. galaxy, created at the mcc research consortium, provided a directory service to support electroniccommerce.first widely used web directory. yahoo! was created by two stanfordgraduate students, david filo and jerry yang, as a directory of theirfavorite web sites. usage expanded with the growth in entries and addition of categories. yahoo! became a public company in 1995.first robotbased search engine to index full text of web pages. webcrawler was created by brian pinkerton, a student at the university ofwashington.lycos was created by michael mauldin, a research scientist at carnegiemellon university. it quickly became the largest robotbased searchengine. by january 1995 it had indexed 1.5 million documents and bynovember 1996, over 60 millionñmore than any other search engineat the time.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution305harvest was created by the internet research task force research groupon resource discovery at the university of colorado. it featured a scalable, highly customizable architecture and tools for gathering, indexing, caching, replicating, and accessing internet information.infoseek guide, launched by infoseek corporation as a web directory, wasinitially fee based, and then free.the opentext 4 search engine was launched by open text corporationbased on work on fulltext indexing and string search for the oxfordenglish dictionary. (in 1996 it launched òpreferred listings,ó enablingsites to pay for listing in top10 search results. resultant controversymay have hastened its demise in 1997.)1995the infoseek search engine was launched in february and in decemberbecame netscapeõs default search service, displacing yahoo!first metasearch service. searchsavvy, created by daniel dreilinger, agraduate student at colorado state university, queried multiple searchengines and combined their results.first commercial metasearch service. metacrawler, developed by graduate student erik selberg and faculty member oren etzioni at the university of washington, was licensed to go2net.the excite commercial search engine, based on the stanford architext engine, was launched.the magellan directory was launched by the mckinley group. it wascomplemented by a book, the mckinley internet yellow pages, thatcategorized, indexed, and described 15,000 internet resources and thataccepted advertising.search engine achieved record speed: 3 million pages indexed per day.altavista, launched by digital equipment corporation, combined computing power with innovative search featuresñincluding boolean operators, newsgroup search, and usersõ addition and removal of their ownurlsñto become the most popular search engine.1996first search engine to employ parallel computing for indexing: 10 millionpages indexed per day. inktomi corporation launched the hotbot searchengine based on work of faculty member eric brewer and graduate student paul gauthier of the university of california, berkeley. hotbot usedclusters of inexpensive workstations to achieve supercomputer speeds. itadopted the oem search modelñproviding search services through othersñand was licensed to wired magazineõs web site, hotwired.continuedsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.306signposts in cyberspacebox 6.3continuedfirst paid listings in an online directory. looksmart was launched as adirectory of web site listings. containing both paid commercial listingsand noncommercial listings submitted by volunteer editors, it alsoadopted the oem model.first internet archive. archive.org was launched by brewster kahle as aninternet repository with the goal of archiving snapshots of the webõscontent on a regular basis.consolidation begins: excite acquired webcrawler and magellan.1997first search engine to incorporate automatic classification and creation oftaxonomies of responses and to use multidimensional relevance ranking. the northern light search engine also indexed proprietary document collections.aol launched aol netfind, its own branded version of excite. the mining company directory service, started by scott kurnitt and others, useda network of òguidesó to prepare directory articles.first òquestionansweró style search engine. ask jeeves was launched. thecompany was founded in 1996 by a software engineer, david warthen,and a venture capitalist, garrett gruener. the service emphasized easeof use, relevance, precision, and ability to learn.alexa.com was launched by brewster kahle. it assisted search users byproviding additional informationñsite ownership, related links, and alink to encyclopedia britannicañand also provided a copy of all indexed pages to archive.org.alta vista, the largest search engine, indexed 100 million pages total andreceived 20 million queries per day.open text corporation ceased operation.1998first search engine with paid placement (òpayperclickó) in responses.idealab! launched the goto search engine. web sites were listed in anorder determined by what they paid to be included in responses to aquery term.first open source web directory. open directory project was launched (initially with the name gnuhoo and then newhoo) with the goal of becoming the webõs most comprehensive directory through the use of theopen source modelñcontributions by thousands of volunteer editors.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution307first search engine to use òpage rank,ó based on number of links to apage, in prioritizing results of web keyword searches. stanford graduate students larry page and sergey brin announced google, which wasdesigned to support research on web search technology. google became available as a òbeta versionó on the web.microsoft launched msn search using the inktomi search engine.the direct hit search engine was introduced. it ranked responses by thepopularity of sites among previous searchers using similar keywords.yahoo! web search was powered by inktomi.consolidation heats up: goto acquired www worm; lycos acquiredwired/hotbot; netscape acquired the open directory; disney acquireda large stake in infoseek.1999google, inc. (formed in 1998) opened a fully operational search service.aol/netscape adopted it for search on its portal sites.the norwegian company fast search & transfer (fast) launched thealltheweb search engine.the mining company was renamed about.com.northern light became the first engine to index 200 million pages.the findwhat payforplacement search engine was launched to providepaid listings to other search engines.consolidation continued: cmgi acquired altavista; at home acquiredexcite.2000yahoo! adopted google as the default search results provider on its portalsite.google launched an advertising program to complement its search services, added netscape open directory to augment its search results,and began 10 nonenglishlanguage search services.consolidation continued: ask jeeves acquired direct hit; terra networkss.a. acquired lycos.by yearõs end, google had become the largest search engine on the webwith an index of over 1.3 billion pages, answering 60 million searchesper day.2001google acquired the deja.com usenet archive dating back to 1995.continuedsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.308signposts in cyberspacebox 6.3continuedoverture, the new name for goto, became the leading payforplacementsearch engine.the teoma search engine, launched in april, was bought by ask jeeves inseptember.the wisenut search engine was launched.magellan ceased operation.by the end of the year, google had indexed over 3 billion web documents(including a usenet archive dating back to 1981).2002consolidation continued: looksmart acquired wisenut.the gigablast search engine was launched.2003consolidation heated up:yahoo acquired inktomi and overture, which had acquired altavista andalltheweb.findwhat acquired espotting.google acquired applied semantics and sprinks.google indexed over 3 billion web documents and answered over 200million searches daily.2004competition became more intense:yahoo! switched its search from google to its own inktomi and overtureservices.6.3addendumñsearching the web versussearching librariessearching on the public web has no direct analog with searching libraries, which is both an advantage and a disadvantage. library modelsprovide a familiar and useful comparison for explaining the options anddifficulties of categorizing web resources.first, locating an item by its url has no direct equivalent in librarymodels. the url usually combines the name of a resource with its precise machine location. the url approach assumes a unique resource at aunique location. library models assume that documents exist in multiplesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution309amazon.com entered the market with a9.com, which added search insidethe bookª and other user features to the results of a google search.google included (in february) 6 billion items: 4.28 billion web pages, 880million images, 845 million usenet messages, and a test collection ofbookrelated information pages.google went public in an initial public offering in august. ask jeeves acquired interactive search holdings, inc., which owned excite and iwon.in november, google reported that its index included over 8 billion webpages.2in december, google, four university libraries, and the new york publiclibrary announced an agreement to scan books from the library collections and make them available for online search.3sources: search engine optimization consultants, òhistory of search engines and directories,ó june 2003, available at <http://www/seoconsultants.com/searchengines/history.asp>;iprospect, òa brief history of search engine marketing and search engines,ó 2003, available at<http://www.iprospect.com/searchengineplacement/seohistory.htm>; danny sullivan,òsearch engine timeline,ó searchenginewatch.com, available at <http://www.searchenginewatch.com/subscribers/factfiles/article.php/2152951>; and wes sonnenreich, òahistory of search engines,ó wiley.com, available at <http://www.wiley.com/legacy/compbooks/sonnenreich/history.html>.1a spider is a program that collects web pages by traversing the web, following linksfrom site to site in a systematic way. see box 7.2.2see david a. vise, òsearch swagger,ó washington post, november 11, 2004, p. e1.3john markoff and edward wyatt. 2004. ògoogle is adding major libraries to itsdatabase,ó new york times, december 14, 2004, available at <http://www.nytimes.com/2004/12/14/technology/14google.html>.locations, and separate the name of the document (its bibliographic description, usually a catalog record or index entry) from its physical location within a given library. classification systems (e.g., dewey decimal orlibrary of congress) are used for shelf location only in openstack libraries, which are prevalent in the united states. even then, further coding isneeded to achieve unique numbering within individual libraries.56 in56the shelf location za3225.b67 2000 for borgman, from gutenberg to the global informationinfrastructure, 2000, at the university of california at berkeley library consists of the libraryof congress call number (za3225) plus a local number to order the author name (b67 forborgman) and the date (2000) to create a unique shelf placement in this library.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.310signposts in cyberspaceclosedstack libraries where users cannot browse the shelves, such as thelibrary of congress, books usually are stored by size and date of acquisition. the uniqueness of name and location of resources that is assumed ina url leads to multiple problems of description and persistence, as explained in this chapter.second, resources on the web may be located by terms in their pagesbecause search engines attempt to index documents in all the sites theyselect for indexing, regardless of type of content (e.g., text, images, sound;personal, popular, scholarly, technical), type of hosting organization (e.g.,commercial, personal, community, academic, political), country, or language. by comparison, no single index of the contents of the worldõs libraries exists. describing such a vast array of content in a consistent manner isan impossible task, and libraries do not attempt to do so. the resource thatcomes closest to being a common index is worldcat,57 which òis a worldwide union catalog created and maintained collectively by more than 9,000member institutionsó of the online computer library center (oclc) andin 2004 contained about 54 million items.58 the contents of worldcat consist of bibliographic descriptions (cataloging records) of books, journals,movies, and other types of documents; the full content of these documentsis not indexed. despite the scope of this database, it represents only a fraction of the worldõs libraries (albeit most of the largest and most prestigiousones), and only a fraction of the collections within these libraries (individualarticles in journals are not indexed, nor are most maps, archival materials,and other types of documents). the total number of documents in worldcat(54 million) is small compared with those indexed by google, infoseek,altavista, or other internet search engines.rather than create a common index to all the worldõs libraries, consistent and effective access to documents is achieved by dividing them intomanageable collections according to their subject content or audience. library catalogs generally represent the collections of only one library, or atmost a group of libraries participating in a consortium (e.g., the campusesof the university of california59). these catalogs describe books, journals(but not individual journal articles), and other types of documents. manymaterials are described only as collections. for example, just one catalogrecord describes all the maps of los angeles made by the u.s. geologicalsurvey from 1924 to 1963. it has been estimated that individual records inthe library catalog represent only about 2 percent of the separate items ina typical academic library collection.60 thus, library catalogs are far less57see <http://www.oclc.org/worldcat/default.htm>.58accessed may 7, 2004.59see <http://melvyl.cdlib.org/>.60see david a. tyckoson, òthe 98% solution: the failure of the catalog and the role ofelectronic databases,ó technicalities 9(2):812, 1989.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: emergence and evolution311comprehensive than most library users realize. however, online librarycatalogs are moving away from the narrower model of card catalogs.many online catalogs are merging their catalog files with records fromjournal article databases. mixing resources from different sources createsa more comprehensive database but introduces the web searching problem of inconsistent description.nor do libraries attempt the international, multilingual indexing thatsearch engines do. the catalogs of libraries may be organized consistentlyon a countrybycountry basis, at best. the descriptive aspects of cataloging (e.g., author, title, date, publisher) are fairly consistent internationally, as most countries use some variation of the machine readable cataloging (marc) metadata structure. (metadata are data about data or,more generally, about resources.) however, many variations of themarc format exist, each tied to a national or multinational set of cataloging rules. the united states and united kingdom share the angloamerican cataloging rules but store their data in usmarc andukmarc formats, respectively. these formats are finally being merged,after nearly 40 years of use. in 2004, the national libraries of the unitedstates and the united kingdom implemented a common format, marc21, and other countries are following suit.61 other marc formats include unimarc, humarc (hungary), and finnmarc (finland). theoclc worldcat database merges these into an oclc marc format.each catalog describes its holdings in its local language and may alsoinclude descriptions in the language of the document content. for example, oclc worldcat contains records describing resources in about400 languages; each record has some descriptive entries in english. thus,libraries achieve interoperability through highly decentralized cataloging activities. the cataloging enterprise is economically feasible in theunited states because most published resources are described by thepublishers and the library of congress and contributed to oclcworldcat and other shared databases. despite the relative national andinternational success in establishing cataloging rules and formats amonglibraries, incompatibilities continue to exist within these communities,and the archives and museum communities employ yet other metadataformats. given the difficulty of achieving agreement on basic descriptivemodels among these established institutions run by information management professionals, the likelihood of getting universal agreement on61see british library, marc 21 and ukmarc, british library, london, november24, 2004, available at <http://www.bl.uk/services/bibliographic/nbsils.html>; andmarc 21 concise format for bibliographic data, concise edition, library of congress, washington, d.c., november 24, 2003, available at <http://www.loc.gov/marc/bibliographic/ecbdhome.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.312signposts in cyberspacedescriptive standards for web documents is low. decentralized modelsfor data creation, combined with mapping between similar formats, arethe most feasible way to achieve interoperability.third, while a rich subject index to the web would certainly be extremely useful, universal subject access is almost impossible to achieve.american libraries attempt general subject access via the library of congress subject headings (lcsh), but these apply only two or three headings per book. few other countries appear to use the lcsh, as many ofthe concepts are specific to u.s. culture. unified access via classificationsystems such as the dewey decimal classification (ddc) and library ofcongress classification (lcc) are more common. these are also countryand culturespecific. ddc and lcc are little used outside the unitedstates; the universal decimal classification (udc) system has broaderinternational adoption. many other countryspecific classifications exist.consistent subject access in any depth is feasible only within topicalareas due to a number of wellunderstood linguistic problems.62 theseinclude synonymy (multiple terms or phrases may have the same meaning), polysemy (the same terms and phrases may have multiple meanings), morphological relationships (structure of words, such as variantendingsñe.g., acid and acidic; dog and dogs; mouse and mice, and semantic relationships (conceptual relationships (e.g., two words may havethe same meaning in one context and different meanings in other contexts). both automatic and manual methods to provide consistent retrievalby controlling the meaning of words work best when the subject area isconstrained. controlled sets of terms (e.g., thesauri, ontologies) can beconstrained to their meaning within one field, such as computer science,economics, arts, or psychology. libraries construct or purchase indexesspecific to each field within the scope of their collections.fourth, web directories are more analogous to topicspecific libraryindexes than to library catalogs. however, web directories cover only asmall portion of the content of the web, and their descriptions of eachitem are often less complete and can be less reliable than those created byprofessional librarians. consequently, structured and formal characterizations of material can be accomplished most effectively in a library catalog or bookstore database, rather than in a general web directory.selecting the proper resource to search remains an important startingpoint in seeking information, whether online or offline.62see richard k. belew, finding out about: a cognitive perspective on search engine technology and the www, cambridge university press, cambridge, u.k., 2000; peter brusilovskyand carlo tasso, òpreface to special issue on user modeling for web information retrieval,óuser modeling and useradapted interaction: the journal of personalization research 14(23):147157, 2004; and william a. woods, òsearching vs. finding,ó acm queue 2(4), 2004, availableat <http://www.acmqueue.com/modules.php?name=content&pa=showpage&pid=137>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.3137internet navigation:current stateat this point in the development of internet navigation, there are atleast seven basic ways for a user to navigate to a desired webresource, which is generally located on a page within a web site.five of them are directñusersõ actions take them immediately to the desired resource. two are indirectñusers must first employ a navigationservice, either a directory or a search engine, to find the address of a desired resource and then, using that information, go to the desired resource.these basic ways can be and often are used in combination with one another. table 7.1 summarizes and characterizes the various internet navigation aids and services.this discussion is concerned with navigation across the internet andnot specifically with navigation within sites, although the tools deployedin both cases are usually similar. most web sitesñexcept those with onlya few pagesñnow incorporate one or more means of navigation withinthe site itself. these include hyperlinks, directories (menus), site maps,and search engines. because they are usually limited to the contents of thesite, the problems of generalpurpose web navigation aids are diminished.for example, the context is delimited, the users are relatively homogeneous, the scale is relatively small, and material that is difficult to automatically index (such as multimedia and images) can usually be manuallyindexed.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.314signposts in cyberspace7.1navigation aids and services7.1.1direct access via a uniform resource locator or domain name one of the major factors in the success of the web was the development of uniform resource locators (urls) for web sites. because thoseidentifiers offered a standardized way to identify resources on the web,resource providers and resource seekers had a common way to refer totheir locations. but the urls were intended as codes hidden behind meaningful objectsñthe anchor textñin a document, not directly typed by theuser. the designers of the web may have been surprised when urls began appearing on the sides of buses and on billboards.urls are typically not managed to be permanent and can be difficultto remember, especially when they require many elements to describe aresource deep within a web site. (examples of such urls abound in thefootnoted references throughout this report.) despite their flaws, however, they have thrived as a robust means of navigation.in some browsers, users can also navigate through the web by typingonly a domain name because the browsers will automatically expand itinto a url that may identify a web site. this use of domain names fornavigation is effective to the degree that the searcher knows or is able toguess the domain name exactly and is satisfied with being taken to thehome page of a web site. if the name entered is incorrect, then the browser,email server, or other internet service consumes resources (in the localcomputer and in the internet) trying to find a dns match. mistakentable 7.1principal internet navigation aids and servicesmethodstepsindexing processfile structurematch1. domain nameñ1 or 2humanhierarchicalexact known or guessed2. hyperlink1humannetworkexact3. bookmark1humanflat or hierarchicalexact4. keyworda1humanflat or hierarchicalexact5. metadata1humanflat or hierarchicalexact6. directory2human/computerhierarchical orfuzzymultihierarchical7. search engine2computerinvertedrankedaòkeywordó is capitalized to distinguish it from the use of keywords in traditionalinformation retrieval or in internet search engines (see sections 7.1.4 and 7.1.7). in this use,each keyword is part of a controlled vocabulary for which the match to a specific internetresource is one to one.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state315guesses can create extra traffic and burden the dns, as discussed in chapter 3. however, most browsers now treat invalid domain names as searchterms and return a list of possible matches.1furthermore, as web sites have grown more complex, discovering thesite has often had to be followed by a second navigation process to findrelevant information or pages within the site. but some users would preferto go directly to the page that contains the specific information being sought.remembering or guessing does not suffice for such navigation because theurls of inner pages comprise more than the domain name.in addition, as network services proliferate and as additional toplevel domains are added, users will have many more sites of interest towhich to navigate, but at the probable cost of domain names that aremore difficult to remember or guess. furthermore, not only information, entertainment, and service resources, but also many personal electronic devices and home appliances may well be connected to theinternet. for convenience, users will probably want to assign easytoremember domain names to such devices. but because of competitionfor the easiest and shortest names, they may have to settle for lessreadilyremembered ones. in either event, they can use bookmarks (see section7.1.3) to simplify access.for these reasons, remembering or guessing correct domain names islikely to become less dependable and, therefore, a less important aid tonavigation as the number of locations on the internet continues to expand.7.1.2direct access via hyperlinksbecause the web is a network of sites through which users can navigate by following links between documents on the sites, once the first sitehas been found, one can move across subnetworks of related and relevant information and services. the address of the linkedto informationmay be visible or, more typically, hidden behind anchor text. a humanbeing defines the linkages within and from a site during site design.there is no publicly available internetwide file of links; they aremaintained locally. however, linkage information is collected and usedby all major search engines as an important part of the ranking of responses. for example, google maintains an extensive file of linkages, andit is possible to use google to find all the pages that link to a given page(within the scope of what is indexed by google; see òthe deep, dark, orinvisible webó in section 7.1.7).1as discussed in chapter 4, verisign tried to offer a service to users who enter an incorrect.com or .net domain name that directed them to possible matches, raising technical andpolicy issues.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.316signposts in cyberspacenavigation by following hyperlinks is an effective tool for movingbetween related sites once the first relevant site has been found. however,since web site operators establish the linkages, they may or may not leadto the specific sites of interest to the user. thus, navigation by hyperlinksis both a valuable and a limited aid. it generally must be supplemented byother means of finding starting sites and of identifying sites of interestthat may not be on the radiating set of paths from the initial point.7.1.3direct access via bookmarksthe urls for sites of continuing interest that have been found after asearch and those of frequently accessed sites can be stored locallyñòbookmarkedó or placed on a òfavoritesó listñand managed in most browsers. by doing so, the user can return directly to a location, perhaps deepwithin a site, with a single click. however, these local files can become difficult to manage over time, due both to scaling problems (as the list of bookmarks grows, it may require its own database) and to the likelihood of broken links or changed content as urls age. for these reasons, bookmarksmay become less useful with the scaling and maturing of the internet, leading users to rely on search engines to find even familiar sites and web pages.the bookmark/favorite mechanism as implemented in current browsersand described above is fairly weak, providing a simple association between aname (provided by either the user or the web page) and a url. richer methods are possible. for example, prior experience in both information retrievaland software engineering suggests that it would be useful to store, in someform, both the query that produced the reference and information about howlong the reference was likely to remain current. with this information available, it would become easier to repeat the discovery process when a link wentbad, perhaps even automatically. some work is now underway to recastbookmarks as a type of local cache with this information included and somereference updating and recovery capabilities. that work also expects to unifythe results of multiple types of navigation, from search engine output, touniform resource identifiers (uris) obtained from colleagues, to links obtained from pages being traversed, into a single framework. (in informationretrieval and library practice since the early 1960s, queries have been storedand then periodically executed to support current awareness or selectivedissemination of information services.2 however, unlike the bookmark case,the queries are run by a service on a regular schedule and not by users onlywhen they need to update their bookmarks.)2see robert r. korfhage, information storage and retrieval, wiley, new york, 1997; and c.b.hensley, r.r. savage, a.j. sowarby, and a. resnick, òselective dissemination of informationña new approach to effective communication,ó ire transactions of the professionalgroup on engineering management em9:2, 1962.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state3177.1.4direct access via keywordsthe term òkeywordó is used in several contexts, with slightly different meanings, in internet navigation.its most common current use is to denote the terms entered into thesearch window of a search engine for matching against the search engineõsindex of words appearing on web pages.3 in this meaning, a òkeywordócan be any phrase and can be treated in a variety of ways by individualsearch mechanisms. it is also used in this sense in search engine marketing to refer to the search terms for which a particular marketer is willingto pay.4however, òkeywordó has also been used to denote terms in a controlledvocabulary linked to specific internet locations by a specific internet (generally, web) service. to distinguish this meaning, it is written here in capitals.typically, keywords are associated with a particular organization or service and that organization or service has paid to have them linked uniquelyto its location. usually, just a single keyword (or phrase) is entered andonly one site appears in the response. they apply, however, only within aspecific web service and are not generally interpretable in the same way byothers. one of the bestknown uses of keywords is that of americaonline (aol) in which keywords can be typed into the aol addressbar.5 aol keywords link uniquely to a network resourceñònytimesólinks to www.nytimes.com, or to an aol feature or serviceñòstockmarketó links to the aol market news center. (the latest versions ofaol now offer a choice between: ògo to aol keyword: ôny timesõó oròsearch the web for ôny timesõó.) typing the aol keywords into msnor into internet explorer will not necessarily lead to the same location. indeed, both ònytimesó and òstock marketó when typed into internetexplorer and netscape navigator6 are treated as search terms (keywordsin the more general sense), and the response is a ranked list of possiblymatching sites.3this is similar to the sense in which òkeywordó has conventionally been used in information retrieval, where a òkeywordó is òone of a set of individual words chosen to representthe content of a document.ó see korfhage, information storage and retrieval, 1997, p. 325.4the marketerõs site or advertisement will appear as one of the responses to any query thatincludes those keywords. in this context, there generally are several keywords entered in thequery and many responses in the list produced by the search engine. this use of òkeywordóis treated in detail in section 7.2.2.5see danny sullivan, òaol search big improvement for members,ó searchenginewatch.com,1999, available at <http://searchenginewatch.com/sereport/article.php/2167581>. see alsodominic gates, òweb navigation for sale,ó the industry standard, may 15, 2000, available at<http://www.thestandard.com/article/0,1902,14735,00.html?bodypage=1>.6test carried out in march 2005.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.318signposts in cyberspaceseveral years ago, there were a number of attempts to offer morewidely applicable keywords on the public internet. a service offeredby realnames, inc. was available for several years. it was adopted, forexample, by msn, which, however, terminated its use in june 2002.7realnames closed shortly thereafter. keywords have been replaced inmost casesñexcept for services catering to nonenglish language users8and aolñby search engines, which provide a widerranging response tokeyword terms, and by the sale of search engine keywords to multiplebidders.keywords have many of the same strengths and weaknesses asdomain names for navigation. if known, they lead exactly to the locationto which the purchaser of the keyword wishes to lead the searcher(which may not be the same as the searcherõs intent). if guessed, theyeither succeed, lead to the wrong site, or fail. however, since many browsers and services now treat nonurl entries in their address lines as searchterms, òfailureó now generally produces a ranked list of possible matches.thus, keyword systemsñincluding aolõsñnow default to search systems, just as domain name guesses generally do.9unlike the dns, a variety of keyword systems applicable to specific topic areas and with or without hierarchical structure are conceptually possible. implementation of a keyword system on the web requiresan application or a service, such as a browser or netpia, that recognizesthe keyword terms when entered into its address line or when theyreach the serviceõs name server. and, whereas in the early days of theweb such an innovation might have been relatively easy, the generalimplementation of standardized browser software in various versionsmakes the widespread introduction of a new feature much more difficult7see danny sullivan, òrealnames to close after losing microsoft,ó searchenginewatch.com,june 3, 2002, available at <http://www.searchenginewatch.com/sereport/article.php/2164841>. the committee heard testimony from keith teare, then chief executive officer ofrealnames, at its july 2001 meeting.8two prominent native language keyword systems are the following: (1) netpia, a korean internet service, offers native language internet address (nlia) for 95 countries (as ofmay 2, 2005). nlia enables substitution of a native language word or phrase (a keyword)for a unique url. see <http://e.netpia.com>. (2) beijing 3721 technology co., ltd., hasoffered chinese language keywords since 1999. see <http://www.3721.com/english/about.htm>.9in july 2004, google added a òbrowse by nameó feature to its search, enabling a user toenter a single name in the tool bar and returning a single site if the term is specific or wellknown; if not, it defaults to a traditional search. it is not clear how the single response namesare selected and whether or not they are paid for. see scarlett pruitt, ògoogle goes browsingby name,ó pc world, july 15, 2004, available at <http://www.pcworld.com/news/article/0,aid,116910,00.asp>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state319(although specific services, such as aol or netpia, can still implementthem for their users).moreover, within any specific database, digital library, or communityrepository (such as the large databases of primary scientific data beingassembled around the world), terms can take on local meanings. generally speaking, meanings are constrained by the use of a controlled vocabulary, which defines each term as applied in this system. wellknownexamples of controlled vocabularies include the library of congress subject headings, the medical subject headings (mesh), subject headingsfor engineering (she), and the association for computing machinery(acm) classification system.keyword systems also face the problems that arise from scale. thelarger the number of locations to which they seek to assign simple andunique names, the greater the pressure to become complex and structured.the system must either remain manageably small or develop an institutional framework that allows decentralization, while centrally determining who can use which names to designate which locations. aol andnetpia both centrally determine the assignment of names. however,netpia implements keywords through decentralized name servers located at collaborating isps, while aol implements its smaller list of keywords through its own service system.7.1.5direct access via metadatasince the early days of the web, there has been a desireñespecially,but not only, by those in the library and information science communityñto establish a more consistent and more controlled way to categorize anddescribe web resources based on the use of òdata about data,ó ormetadata.10however, differences between the web11 and conventional librariesand data collections complicate fulfillment of that desire. first, the number, scope of content, and diversity of form of resources on the publicweb exceed that in any library. second, the quality of the, often selfprovided, metadata is highly variable. and third, there is no organization orgroup of organizations that is able and willing to assume responsibility10for an overview, see tony gill, introduction to metadata: metadata and the world wide web,getty research institute, july 2000, available at <http://www.getty.edu/research/conductingresearch/standards/intrometadata/2articles/gill/index.html>.11hypertext markup language (html)ñthe programming language of web site constructionñspecifies the expression of metadata in the form of òmetatagsó that are visible tosearch engines (as they collect data from the webñsee box 7.2) but are not typically displayed to humans by browsers. to see metatags, if they are present on a web page, go toview/source in internet explorer or view/page source in netscape navigator.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.320signposts in cyberspacefor assigning metadata tags to a significant portion of the resources accessible on the web, as the library of congress does for books.efforts to adapt metadata for the description and categorization ofsufficiently valuable web resources began in the mid1990s, when standard ways to express metadatañmetadata schemesñwere proposed asthe answer to interoperability and scaling of the expanding web.12 but areexamination in 2002 of the mid1990sõ recommendations forced theirproponents to consider why metadata had not been successfully used.13the error was in their assumptions: they had expected to find highqualityñclean and honestñinformation, not the large amount of misrepresented and deliberately incorrect metadata that was provided for resources on the web.it seems that any feasible attempt to develop metadata schemes andapply them broadly to the web would have to be decentralized and basedon the efforts of a large number of autonomous organizations with specific knowledge of the content and quality of the resources they describe.yet decentralization raises the question of coordination among the manypotentially inconsistent and noninteroperable metadata schemes that theautonomous organizations might otherwise develop. through coordination, their separate efforts could cover a significant portion of the weband open access to their resources to a wider audience beyond the organizations themselves. two approaches have been taken to the coordinationof metadata schemes produced by autonomous organizations.the first approach to coordination is for organizations to collaboratein defining common metadata elements that will be used by all of them asa core for their metadata schemes. the best known and best developed ofthese is the dublin metadata core element set, known as the dublincore,14 so named because it originated at a meeting in dublin, ohio, thatwas sponsored by the online computer library center (oclc). it comprises fifteen metadata elements, which were thought to be the minimumnumber required to enable discovery of documentlike resources on theinternet. thus, dublin core can be used to discover an item, to determine12see clifford a. lynch and hector garciamolina, interoperability, scaling, and the digitallibraries research agenda, 1995, available at <http://wwwdiglib.stanford.edu/diglib/pub/reports/iitadlw/main.html>, accessed july 9, 2004.13christine l. borgman, òchallenges in building digital libraries for the 21st century,óproceedings of the 5th international conference on asian digital libraries (icadl 2002),eepeng lim, schubert foo, christopher s.g. khoo, h. chen, e. fox, u. shalini, and c.thanos, editors (lecture notes in computer science, vol. 2555), springerverlag, 2002, available at <http://www.springer.de/comp/lncs/index.html>.14the dublin core web site is at <http://www.purl.org/dc/>. official reference definitions of the metadata elements can be found there.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state321where fuller descriptions can be found, and to identify its detailed format(e.g., marc for books or the environmental markup language forbiocomplexity data). dublin core works best when a professional cataloger creates descriptions. to achieve wide adoption, some believe that itneeds to be made more suitable to machinegenerated descriptions.15the second approach to coordination is to provide a higherlevel structure that can incorporate multiple metadata schemes, enabling them to bedeployed in combination to describe a resource with the assurance that theresultant description will be correctly interpreted by any computer programthat is compatible with the higherlevel structure. the best known and bestdeveloped of these higherlevel structures is the resource description framework (rdf) developed by the world wide web consortium (w3c).16 it extends another w3c standard, extensible markup language (xml),17 whichis used to describe data where interchange and interoperability are important, to describe resources. any web resourceñthat is, any object with auriñcan be described in a machineunderstandable way in the rdf, although for some objects the description might contain little information. theresourceñweb objectñis described by a collection of propertiesñits rdfdescription. these properties can come from any metadata scheme since therdf description incorporates reference information about the metadatascheme and the definition for each property. the advantage of the rdf is thatit provides a widely applicable framework within which specialized metadatasets can be combined. for example, to describe geographic resources on theweb, an rdf description might incorporate the dublin core to describe thebibliographic provenance and a geographic metadata scheme to describe thegeographic coverage of each resource. the developers of the rdf believe thatits existence will encourage the development of a large number of metadataschemes for different resource domains and that where there is overlap intheir coverage, they will, in effect, compete for adoption by those who describe resources. see box 7.1.while the rdf may provide a useful framework within which variousmetadata schemes may be developed and combined, it does not resolve themore difficult problem of actually using these metadata schemes to describeresources on the web. that problem has three components: determining15see carl lagoze, òkeeping dublin core simple: crossdomain discovery or resourcedescription,ó dlib magazine 7(1), 2001, available at <http://www.dlib.org/dlib/january01/lagoze/01lagoze.html>. lagoze provides a useful discussion of the tradeoffs insimple and complex metadata descriptions and the relationship between dublin core, rdf,and other schema.16see resource description framework (rdf)/w3c semantic web activity, available at <http://www.w3c.org/rdf>, and rdf primer primer [correct as written], available at <http://notabug.com/2002/rdfprimer/>.17see extensible markup language (xml), available at <http://www.w3c.org/xml>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.322signposts in cyberspacewho will assign the metadata to each resource; finding incentives formetadata use; and determining how the metadata will be used.the resolution of that threecomponent problem is easiest within communities, whether organized by topic, geographic region, or some othershared subject area.18 individual communities in several academic disciplines are creating their own repositories with their own metadata frameworks. among the repositories that have been established are iris forbox 7.1the semantic webdespite the problems of characterizing most resources on the public webwith rdf metadata, there are islands of application and, over the long term,they may extend to cover ever more terrain. with that prospect in mind, timbernerslee and his colleagues at the w3c have proposed a way of linkingthese islands into a formalized network of knowledge that they call the òsemantic web.ó1 they do so by introducing òontologiesó that consist of relational statements (propositions) and inference rules for specific domains ofknowledge and are used to define terms used on the web. in their vision, thesemantic web would enable web agents to draw upon that network ofmachineaccessible knowledge to carry out complex functions with less explicit direction than is currently required. while its area of application is farbroader than navigation, its developers foresee, for example, that softwareagents will òuse this information to search, filter, and prepare information innew and exciting ways to assist the web user.ó2 like metadata and rdf, theapplicability and feasibility of the semantic web remains the subject of dispute between its advocates and the skeptics.3the practical implementation and use of the semantic web is highlydependent on the broad adoption of rdf and the ontologies it requires.that work has proceeded slowly thus far.1see tim bernerslee, james hendler, and ora lassila, òthe semantic web,ó scientificamerican, may 2001, available at <http://www.sciam.com/article.cfm?articleid=0004814410d21c7084a9809ec588ef21&catid=2>.2see james hendler, tim bernerslee, and eric miller, òintegrating applications on the semantic web,ó journal of the institute of electrical engineers of japan 122(10):676680, 2002,available at <http://www.w3c.org/2002/07/swint>. for an imaginative exploration of the possibilities, see paul ford, òaugust 2009: how google beat amazon and ebay to the semanticweb,ó july 26, 2002, available at <http://www.ftrain.com/googletakesall.html>.3see, for example, clay shirky, òthe semantic web, syllogism, and worldview,ó november7, 2003, available at <http://www.shirky.com/writings/semanticsyllogism.html>. also see paulford, òa response to clay shirkyõs ôthe semantic web, syllogism, and worldviewõ,ó november13, 2003, available at <http://www.ftrain.com/contrashirky.html>.18see chris sherman, òsearch dayñmetadata or metagarbage,ó searchenginewatch.com,march 4, 2002, available at <http://www.searchenginewatch.com/searchday/article.php/2159381>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state323seismology, knb for biocomplexity, and ncarñamong othersñfor environmental data.19 other communities have established portals to gatherresources and links to other resources on their topic of interest. communities build these metadatabased repositories and portals out of selfinterestñwith accurate metadata they can provide better access to community resources. as both the creators and the users of the metadata, theselfinterest of cohesive communities leads them to want trustworthymetadata and to provide the resources needed to create and keep themcurrent and accurate.20solving that threecomponent problem is more difficult for the general web user òcommunity.ó metadata would either have to be suppliedby independent editors (as it is now for use in directory services) or applied by the resource providers and collected automatically by search engines. although search engines look at the metatagsña type of information about a web page that can be placed in the code describing the pagebut not made visible to usersñon web sites, it is not always clear whetherand how they make use of the metadata they find there. and the fundamental difficulty of unreliable selfassigned metadata is difficult to overcome through automatic means.however, one important current use of metadata is to characterizeimages and audio and video files on the general web so that they can beindexed and found by search engines. the metadata tags are generallyeither extracted from text accompanying the images or supplied manually by editors or the resource provider and appear, generally, to be reliable. (see section 8.1.3.)thus, it is highly unlikely that general metadata schemes, even if theywere designed, could be reasonably implemented for the web generally.however, metadata schemes may be practical and useful for specific setsof resources with interested user communities, such as professional organizations, museums, archives, libraries, businesses, and government agencies and for nontextual resources, such as images, audio, and video files.moreover, even in specialized resources, establishing the framework andassigning the metadata terms to a large number of items are very differentmatters, since the latter is far more labor intensive. thus, the widespreaduse of metadata would become easier with the improvement of automatic19iris (incorporated research institutions for seismology) is at <http://www.iris.edu/>;knb (the knowledge network for biocomplexity) is at <http://knb.ecoinformatics.org/home.html>; and ncar (national center for atmospheric research) is at <http://www.ncar.ucar.edu/ncar/>.20see, for example, work done by the education network australia, including ednaonline, the edna metadata standard, 2003, available at <http://www.edna.edu.au/edna/go/pid/385>, and the listing of activities at <http://www.ukoln.ac.uk/metadata>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.324signposts in cyberspaceindexing (automatic metadata tagging), a topic that has long been pursued in information retrieval.217.1.6navigation via directory systemsin general, the term òdirectoryó refers to a structured collection ofobjects organized by subject, much like a library card catalog or yellowpages telephone listing. structuring a directoryñusually using a taxonomy of some formñand placing objects under specific subject headings are done by humans. they may assign the same subject heading tomore than one object and the same object may be assigned to more thanone subjectñthat is, it may appear under more than one heading. in thecase of internet directories, the objects are internet locationsñweb sitesor web pages, typically.only the web sites that have been submitted to or found by aninternet directory service and whose content has been classified and described, either by the editors of the directory or by the creators of the website, will be available in the directory. as a result of the heavy requirements for skilled labor, internet directories can include only a small selection of all the sites connected by the web. however, in contrast to searchengines, they have the advantage of being able to incorporate listings ofmany web sites in the òdarkó web (see òthe deep, dark, or invisiblewebó in section 7.1.7) because the sites themselves solicit a listing or because they become known to the directory editors through other means.the listings, categorized under subject hierarchies, can be browsed bynarrowing down subject categories or can be searched by matching searchterms against summary descriptions of the web site content.22 for example, the yahoo! directory of the internet classifies web sites by 14 topics. under the òcomputers and internetó topic, there are two commercial(sponsored) categories and 48 additional categories. the latter groupingincludes topics such as òcommunications and networkingó with 1108 entries grouped into 40 subtopics; òsupercomputing and parallel computingó with 9 subtopics and 11 sites; and òsoftwareó with 50 subtopics.23users search a typical, hierarchically organized directory by startingat the top of the tree and moving deeper along branches labeled (by thedirectory editors) with terms that seem to match their interests.24 thus, a21see, for example, gerard salton, editor, the smart retrieval system: experiments in automatic document processing, prentice hall, englewood cliffs, n.j., 1971.22three of the largest directories include the open directory, yahoo!, and looksmart.23directory accessed on march 5, 2005.24many directories have added the ability for users to jump directly to a subtopic within adirectory.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state325user interested in administration tools for the dns could trace the following path in yahoo!:directorycomputers and internetcommunications andnetworkingprotocolsdnsadministration tools25the success of the userõs navigation depends on the userõs skill inidentifying appropriate paths (but backing up and trying another path isrelatively easy), on the editorsõ skill in describing and placing the site inthe directory, and on the siteõs accuracy in describing itself to the editors(unless they visit and characterize each site themselves).directories present the user with a taxonomic view of some of theweb sites on the internet, which can enable users to reach their goalsthrough successive refinement. however, if the taxonomy is poorly implemented or does not roughly match the view of the user, it can be verydifficult to use. there are hundreds of directories, general and specific,available on the web and listed in various directories of directories.26work is now underway by several groups (a majority with at leastloose links to each other)27 to reexamine analogies to the timetested òyellow pagesó model for the internet. whereas search engines are modeledon a òsearch through the visible web and see where appropriate materialcan be foundó model (augmented, as discussed below, by paid placements), a yellow pages system is one in which all of the entries are therebecause their owners want them there, there is considerable contentowner control over presentation, and although a classification system isused to organize the information, the categories in which a listing is placedare generally chosen by the listing (content) owner, not the site operatoror an automated process. in its paper form, that type of system has beenthoroughly demonstrated over the years and is useful precisely becausethe information content is high and the amount of extraneous materiallow. since the combination of several of the factors discussed in this section has resulted in most searches for products leading to merchants thatsell those products, and to a good deal of extraneous information as well,a directory that is organized the way the merchants want (and pay for)may be more efficient technically and economically. of course, these models can apply to many types of listings, goals, and content other than commercial ones.25directory accessed on march 5, 2005.26see, for example, the directory of directories at galileo (georgiaõs virtual library) <http://www.usg.edu/galileo/internet/netinfo/director.html>.27for example, the work by beijing 3721 technology co., ltd. (also known as ò3721ó),which was recently acquired by yahoo!signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.326signposts in cyberspaceone of the major differences between a traditional yellow pages andsome of these systems is that the yellow pages (and even their online versions that support broader geographical scope28) are organized around asingle hierarchical category system. that is necessitated by the organizationof the material for publication on paper. but a computerbased system cantake advantage of a multihierarchical environment in which, for example,the location of an entity (at various degrees of precision) is specified in ahierarchy different from that for content descriptors (such as category ofstore), rather than having to be a superior category in the hierarchy.because directories are typically built and maintained by humans, theycan cover only a small portion of the web, have difficulty keeping up withchanges in locations, and are labor intensive. (however, as noted above, specialized directories that are supported by those who want to be found, suchas commercial yellow pages listings, can overcome the latter two problems.)one way to address all of these problems is to decentralize responsibility formaintaining the directory, just as the dns name files are decentralized. forexample, 475 òguidesó who are selected and trained to cover a specific subject area maintain the about.com directory.29 its 475 òguidesó are responsible for òmore than 50,000 topics with over 1 million pieces of original content, which are grouped into 23 channels.ó30 another way, which is becomingcommon, is to combine directories with search engines, which index a muchlarger portion of the web using automated processes. netscape began anambitious directory project using volunteers and called open directory,which continues to this day and is incorporated into google.7.1.7navigation via search enginessearch engines rely on indices generated from web pages collectedby software robots, called crawlers or spiders.31 these programs traversethe web in a systematic way, depositing all collected information in acentral repository where it is automatically indexed.32 the selection andranking of web pages to include in the response to a query are done byprograms that search through the indices, return results, and sort themaccording to a generally proprietary ranking algorithm. consequently,basic search by search engines is often referred to as algorithmic search.(see box 7.2 for an expanded description of how search engines work.)28see <http://www.superpages.com>.29see <http://www.about.com>.30about.com web site, march 5, 2005. for more information see <http://ourstory.about.com/>.31see <http://www.searchenginewatch.com> for a wealth of information about searchengines and directories.32many search algorithms do not depend on the script or language used, so almost all theinternetõs visible web pages can be includedñregardless of their language.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state327when web site operators pay to have their sites listed in response to queries, the search is referred to as monetized search. the desire of web sitesto obtain advantageous positions in the listing of responses to queriesrelevant to their offerings has led to the development of specialized strategies and tactics that are called search engine marketing and optimization. despite their best efforts, search engines cannot, for a variety of reasons, reach all sites on the world wide web. the untouched part of theweb is called, variously, the òdeep,ó the òdark,ó or the òinvisibleó web.finally, the searcher can obtain more comprehensive results to a query bylooking at the results of searches conducted by several search enginescombined by a òmetasearchó engine. the following sections examine thesesearch engine topics in more detail.algorithmic searchbecause they are automated, search engines are the only currently available navigation aids capable of finding and identifying even a moderate fraction of the billions of web pages on the public internet. to index and retrievethat much information from the web, search engine developers must overcome unique challenges in each of the three main parts that make up a searchengine: the crawler, the indexer, and the query engine. (see box 7.2.)the principal challenges facing the crawler (robot or spider) are determining which web sites to visit and how frequently to do so. searchengines vary substantially in the number of web sites visited, the depth oftheir search, and the intervals at which they return. in general, increasingthe size of the computing facility can increase the number, the depth, andthe frequency of visits and, consequently, it is a business judgment by thesearch engine operators that determines these parameters.the principal challenge facing the indexer is in determining whentwo terms are equivalent, bearing in mind singular versus plural versions,misspellings, differing translations or transliterations, synonyms, and soon. moreover, these challenges are languagespecific. these problems canbe addressed to some extent during the creation of an index, but are oftenleft to the search engine. a search engine typically allows for partialmatching to the query and returns many results. searching for òcook rutabagaó may return pointers to results with those words, but also to resultscontaining òcooked rutabagaó or òcooking rutabaga.óthe major challenges facing the query engine are matching the querywords appropriately and calculating the relevance33 of each response.33research on relevance in traditional information retrieval has identified dozens of factors, such as degree of topical match, authority of the source, how current the material is,familiarity of the terminology, ease and cost of acquiring the content, and so on. see, forexample, linda schamber, òrelevance and information behavior,ó chapter 1 in martha e.williams, editor, annual review of information science and technology, vol. 29, pp. 348, 1994.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.328signposts in cyberspacedetermining the relevance of a response to a query is a complex problem,since relevance depends on the userõs specific needs, which may not beclear from the words chosen for the query. (see the example of a searchfor òparisó in section 6.1.6.) different search engines use different criteriato calculate relevance, with examples being the location and frequency ofwords matching the query terms on a web page and the patterns andquality of links among web pages.relevant results, once retrieved, can be sequenced by other factorsthat the system or the user considers appropriate. few people will viewdozens, much less thousands, of matches to a query; typically, only thefirst one or a few pages of results are viewed. among the 1400 or so rebox 7.2how search engines worksearch engines are technical systems comprising computer programs thatperform three interrelated functions: searching the web to collect web pages,indexing the web pages found, and using the index to respond to queries.the web search programs, called crawlers or spiders, collect web pagesby traversing the web, following links from site to site in a systematic way.by beginning with web sites that are densely populated with links, acrawler is able to spread across the most frequently accessed parts of theweb, and then increase speed as it travels to other less frequently visitedsites. search engines use different algorithms to determine the coverageand depth of the pages that are visited. some may focus more on breadth,covering only pages linked from the home page of a web site, rather thandepth, visiting pages deeper within the web siteõs hierarchical structure.because of the constant changes of web site content and the addition ofnew web sites, web crawling by search engines is never completed. thefrequency with which web pages are recrawled directly affects the freshness of the results returned from a search engine query.once the web pages are retrieved, indexing programs create a word index of the web by extracting the words encountered on each web page andrecording the uniform resource locator (url) and possibly additional information for each one. indexes are then created that list the urls of all pageson the web for a given word. they may also record additional informationabout the word such as whether it appeared in a title, anchor text, heading,or plain text; the relative size of its type; and its distance from other words.in response to queries, query engines will search the index for the querywords to find the pages where they appear. for example, if the query is foròcstb committees,ó the search engine will retrieve a list of all the pages onwhich both the strings òcstbó and òcommitteesó appear. a search mayreturn tens or thousands or even millions of responses, which users willtypically not examine in full. therefore, the critical question is the order inwhich the retrieved list of pages is returned. the goal is to return the pagessignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state329spondents to a survey of search engine users in the spring of 2002, only 23percent went beyond the second page and only about 9 percent read morethan three pages.34 thus, the matching and ranking criteria of search engines strongly influence the material that people actually view and use.no single set of matching and ranking criteria is likely to suit all usersõ purposes. consequently, it is in general usersõ interest that multiplein decreasing order of relevance. the determination of relevance is bothcritical to the quality of response and very difficult to assess, because of thelarge number of indexed pages and the short queries that search enginestypically receive. each distinct search engine has developed its own proprietary algorithms for determining relevance.google, currently the generalpurpose search engine with the largestdatabase, is noted for its algorithm, pagerankª, which uses the link structure of the web as a key part of the relevance calculation. it assumes thata link from page a to page b is a vote by page a for the quality of contenton page b. aõs vote is given higher weight if the web site of page a is alsohighly linked. the relevance ranking assigned to a page by pagerankª isbased on the intrinsic value of the page plus the endorsements from theother pages linked to it. the qualitative performance of the pagerankªalgorithm is better than keyword algorithms alone, since it makes use ofmore information than just the content on the pages.1the retrieved web pages used to create the index may also be stored, orcached, beyond the time needed to create the index. caching of resultsenables them to be returned more quickly in response to a request but alsoadds to the enormous storage capacity needed to create indexes requiredfor largescale search engines. estimates of the computing resources usedby one search engine to index the web and handle 200 million queries perdayñapproximately onethird of the total daily web searchesñis 54,000servers, over 100,000 processors, and 261,000 disks.2currently operating search engines include alltheweb, alta vista,google, inktomi, msn search, and teoma.1see arvind arasu, junghoo cho, hector garciamolina, andreas paepcke, and sriramraghavan, òsearching the web,ó acm transactions on internet technology 1(1, august): 243,2001.2see john markoff and g. pascal zachary, òin search of the web, google finds riches,ónew york times, sec. 3, p. 1, april 13, 2003; and john markoff, òthe coming search wars,ónew york times, february 1, 2004.34see òiprospect search engine branding survey,ó reported in òiprospect survey confirms internet users ignore web sites without top search engine rankings,ó iprospectpress release, november 14, 2002, available at <http://www.iprospect.com/media/press20021114.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.330signposts in cyberspacesearch engines employing different relevance criteria be available. themore options, the more likely it is that users will find a search engine thatconsistently ranks highly the content or services they seek. very skilledand experienced users might even want to know the criteria by which asearch engine ranks its results, enabling them to choose the search enginewhose criteria best meets their needs. however, commercial search services treat the details of their ranking algorithms as proprietary since theyare a primary means of the services differentiating themselves from theircompetitors and of minimizing the capacity of web site operators toògameó the system to achieve higher ranks.search engines are able to return a high proportion of all the relevantweb pages that are available for indexingñthough often in such a largenumber that they exceed the searcherõs ability to review most of themñand to give a reasonable probability of retrieving lesswellknown webpages related to particular topics, though not necessarily in the first fewpages of results. furthermore, since information on the web is dynamically changing, heterogeneous, and redundant, no manual system can listand remain current with more than a small fraction of all sites. only searchengines have the capacity to keep their indices relatively current by continually revisiting accessible sites, although (as noted above) the frequencywith which sites are visited varies among search engines and, probablyalso, depends on specific site characteristics. as the web expands, so maythe number of responses that search engines return for a query, althoughthe relationship is not generally proportional. because it is likely that theywill receive large numbers of responses to a query, searchers naturallyfavor search engines whose ranking of responses reliably provides closeto the top of the listing the pages that best meet their needs.monetized searchthe growing use of search engines offers the opportunity for information and service providers to affect the presentation of search results tousers through a variety of direct and indirect means. when viewed fromthe traditional information retrieval perspective, this appears to contradict a userõs òrightó or expectation of neutrality in his or her informationsources (except when seeking information from sources with an obviousviewpoint, such as political or commercial sources.) however, when seenfrom the marketing perspective, it is an especially efficient way for providers to reach prospective users just at the time when the users haveexpressed interest in what they have to offer.the search engine companies have responded to the providersõ interest through a variety of advertising, òpay for placementó and òpay forinclusionó opportunities. these practices as a group are often called monsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state331etized search. payment can result in having an advertisement placedahead or alongside of the search results for specified search terms, havinga site visited more frequently or more deeply by the crawler, having apage assured a place in the results, or having a link placed at the top of thelist of results. (however, concerns about the latter two practicesñpaidinclusion and paid rankingñhave led some search engines that offer themeither to phase them out or to consider doing so.35)the consequence of these opportunities is that the first page of resultsof a search engine query for, say, òflorida holidaysó generally now includes not only the neutral results ranked according to the relevance algorithm used by the engine, but also sponsored listings along the top or thesides from advertisers that paid to have their listings presented wheneverthe keywords òfloridaó or òholidayó or òflorida holidaysó appeared inthe query.providersõ payments have become the major source of revenue formost search engines, which searchers use for free. (see section 7.2.2 for afurther discussion of advertising and the search engine market.)search engine marketing and optimizationthe opportunity to pay for listings in response to certain key wordson specified search engines has led to the development of search enginemarketing. its practitioners help operators of web sites to decide whichkey words to pay for on which search engines to attract the greatest number of prospective customers to their sites. this is very similar to the rolethat advertising agencies play in helping advertisers to decide what adsto run in which media. however, advertising on search engines has thedistinct advantage that the message is presented only to prospective customers who have expressed an interest in a topic that may be related tothe advertisersõ wares at the time of their interest. in many cases, the advertiser pays only if prospective customers actually click on the link thattakes them to the advertiserõs site.web site operators have also responded to their perceived businessneed to be ranked higher in the nonpaid results of searches (e.g., floristsin the search for òflowersó) by adopting means to improve theirrankings.36 this has led to the development of search engine optimization in which the site design is optimized to include simple, common35see stefanie olsen, òsearch engines rethink paid inclusion,ó c/net news.com, june 23,2004, available at <http://news.com.com/210010245245825.html>.36see mylene mangalindan, òplaying the searchengine game,ó wall street journal, june16, 2003, p. r1.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.332signposts in cyberspaceterms likely to turn up in searches and to include metatags (metadata)that are invisible to users but are picked up by some search engines. specialized firms have grown up to help companies both in marketing andoptimizing their web sites.other approaches are less savory. for example, òpagejackersó falsifyinformation in the meta tags on their site to emulate the appearance ofanother web site that would rank higher; òspamdexersó seek placementunder search terms that are unrelated to the content of their pages byplacing many repetitions of the unrelated terms on their site in invisibleform (e.g., white text on white background, which can nevertheless beread by the search engine). in response to providersõ tactics, search engines eliminate from their databases those companies that they believeare using unscrupulous methods to improve rankings.37 not surprisingly,this has led to a continuing battle between web site operators trying newways to improve their ranking and search engines introducing countermeasures as each new tactic is discovered.the deep, dark, or invisible webalthough they are far more comprehensive than directories, generalsearch engines still index and retrieve only a portion of the content available on the internet. first, they do not reach every page that is visible tothem because of limits on how often they will crawl the web, on the capabilities of their crawlers, and on how much of each visited site they willcrawl. second, a large majority of the information potentially reachableon the web is not visible to them. the parts that they cannot see are calledthe òdeep,ó the òdark,ó or the òinvisibleó web.38 various estimates placethe size of the invisible web at hundreds of times larger than the visible orpublic world wide web.39 web pages can be invisible to search enginesfor a variety of reasons.40a primary reason is the increasing use of databases to deliver content37see, for example, googleõs guidelines at <www.google.com/webmasters/guidelines.html>.38see chris sherman and gary price, the invisible web, information today, inc., medford,n.j., 2001.39see michael k. bergman, òthe deep web: surfacing hidden value,óaugust, journal ofelectronic publishing 7(1, august), 2001, available at <http://www.press.umich.edu/jep/o701/bergman.html>.40see genie tyburski and gayle oõconnor, òthe invisible web; hidden online searchtool,ó presentation to aba techshow, april 3, 2003, chicago, available at <http://www.virtualchase.com/iweb>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state333dynamically. if material is available only in response to queries and actually does not exist until a question is asked, there is no practical way for ageneral search engineõs crawler to òseeó it since those systems cannot synthesize the queries that will generate the relevant material. thus, engines41cannot crawl inside searchable databases such as library catalogs, the thomas register of manufacturing information, or indexes of journal literature. a search engine query on òshakespeareó may retrieve sites that specialize in shakespearean memorabilia (as described in their web pages),sites of theaters that are currently performing shakespearean plays, andshakespeare fan clubs, but usually will not retrieve catalog records forbooks in libraries or for records in archives. there are web sites that serveas directories to many òinvisibleó resources, such as library catalogs anddatabases, on the internet.42 moreover, specialized search engines, suchas those used by shopping comparison43 or travel reservation sites,44 aredesigned to synthesize the appropriate queries and submit them to multiple databases in order to obtain the comparison information requestedby the user. furthermore, as noted earlier, directories can be useful in thissituation since they can manually identify or seek submission of databasesites, enabling the searcher to find a relevant database and then submit aspecific query to it.content virtualization45 produces a considerable amount of dynamicinformation that is unavailable to web crawlers. google has made an attempt to overcome some of the challenges of rapidly changing contentand the increasing use of òvirtualó content, particularly among large newsweb sites, by creating special arrangements with news organizations tocontinually update, retrieve, and index content from a preselected list ofnews web sites.4641see clifford a. lynch, òmetadata harvesting and the open archives initiative,ó arlbimonthly report 217:19, 2001.42one such directory is òthose dark hiding places: the invisible web revealed,ó whichcan be found at <http://library.rider.edu/scholarly/rlackie/invisible/invweb.html>.43such as, for example, epinions (www.epinions.com) and bizrate (www.bizrate.com).44for example, travelocity (www.travelocity.com) and expedia (www.expedia.com), ormetasites, such as sidestep (www.sidestep.com) and mobissimo (www.mobissimo.com).45òcontent virtualizationñor content integration as some know itñleaves data in its originating system and pulls it together in real time when requested by the user.ó quoted fromlowell rapaport, òmanage content virtually,ó transform magazine, april 2003, available at<http://transformmag.com/shared/cp/printarticleflat.jhtml?article=/dbarea/archs/2003/04/tfm0304tp1.shtml>.46for more information about news aggregation services by google, see <http://news.google.com/>. for other approaches to news aggregation services, see blogdex at<http://blogdex.net/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.334signposts in cyberspacethe dark web also encompasses the vast intranets of many corporations, governments, and other organizations. resources are not indexed ifthey are behind firewalls, require payment, or are otherwise coded òofflimitsó to search engines.progress on the dark web problem is being made via efforts such asthe open archives initiative (oai), which enables information providersto offer their metadata for harvesting.47 additionally, new kinds of webpages for which indexing is probably infeasible are emerging. personalized content such as the òmy yahoo personal news pageó is an example ofthis type of content, since it is created only when the user requests it andis not available to others on the web. however, it comprises a selection ofmaterials from public web pages, so indexing it would add little otherthan information about an individualõs selectionsñand that would probably be constrained by considerations of privacy. some ephemeral content, such as òinstant messagingó and òchat,ó is not indexed because it isdynamic and not readily accessible to search engines unless it is archived.google indexes the complete usenet archives and the archives of manyimportant internet mailing lists.another source of new and rapidly changing information on the webis the profusion of journals in the form of web logs, called blogs. softwarethat has made it very easy for individuals to construct and modify websites and the availability of services to house them have made web publishing common. the ease of creating and changing blogs has lowered thebarriers to entry for publishing to large audiences. this has led to theirincreasing number, types, and ranges of quality. they often incorporate alarge number of links to other blogs and web sites, making them a distinctive medium that contains not only the authorsõ contributions, but alsothe authorsõ identification of òcommunities of interestó whose ideas aregermane to theirs.these new forms of content pose further requirements for search engines to retrieve information more frequently and also to return the widevariety of information posted to web logs in a useful way. some of thesechallenges are being met by specialty search engines, which go beyondthe features presented by google. one of these is daypop,48 which usesits own kind of link analysis to identify web logs that are pointed to otherweb log sites from their front pages, rather than from archived or back47scholarly publishing and academic resources coalition, òthe case for institutionalrepositories: a sparc position paper,ó available at <http://www.arl.org/sparc/ir/ir.html>.48see greg notess, òthe blog realm: news source, searching with daypop, and contentmanagement,ó online 26(5), 2002. for more information about daypop, see <http://www.daypop.com/>; see also technorati for another search engine approach to weblogging, at<http://www.technorati.com/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state335pages, and allows popular commentary, or responses to original posts ona web log, to be comparatively searched across a number of web logs.finally, multimedia materials are increasingly populating the internet.they range from still photographs to fulllength videos and films. these canreadily be indexed by their descriptions, but unless a human indexer provides descriptive termsñmetadataña photo or song cannot yet be automatically searched and indexed by its content at a commercially viable scale.the inability to search everything accessible via the internet is notnecessarily a problem, since much of it may not be useful and there isnecessarily a cost associated with sorting through ever larger amounts ofmaterial. however, while some of the unsearchable material may be oflittle value, it is likely that some of it (say, major library catalogs or government databases) would be of great value, if it could be readily searched.metasearch enginesòmetasearchó engines take the keywords entered by the user and submit them to a number of independent search engines. they present thecombined results to the user. this would appear to offer the advantage oftime saving and the possibility of getting the best results from the sum ofthe engines searched. however, whether those advantages are realizeddepends on how the metasearch engine combines and orders the resultsfrom several search engines, each using different relevance and rankingcriteria. among the metasearch engines available in 200449 were dogpile,vivisimo, kartoo, and mamma.7.1.8use of navigation aidshow much use is made of these aids to navigation? complete dataare unavailable, but use of search engines (and their associated directoryservices) is being measured. according to the pew internet & americanlife project:50¥in total, americans conducted 3.9 billion searches in june 2004.¥the average search engine user conducted 33 searches in june 2004.49for a listing of metasearch engines, see chris sherman, òmetacrawlers andmetasearch engines,ó searchenginewatch.com, march 15, 2004, available at <http://searchenginewatch.com/links/article.php/2156241>.50see deborah fallows, lee rainie, and graham mudd, òthe popularity and importanceof search engines,ó data memo, pew internet & american life project, august 2004, available at <http://www.pewinternet.org/pdfs/pipdatamemosearchengines.pdf>. the results came both from a telephone survey of 1399 internet users and from tracking of internetuse by comscore media metrix.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.336signposts in cyberspace¥eightyfour percent of americans who use the internet have usedsearch enginesñmore than 107 million people.¥on an average day, about 38 million of the 64 million americanswho are online use a search engine. twothirds of americans who areonline say they use search engines at least twice a week.¥using search engines is second only to using email as the mostpopular internet activity, except when major news stories are breaking,when getting the news online surpasses using search engines.¥òthere is a substantial payoff as search engines improve and peoplebecome more adept at using them. some 87% of search engine users saythey find the information they want most of the time when they use searchengines.ó¥òmore than twothirds of search engine users say they considersearch engines a fair and unbiased source of information.ó¥ò. . . 92% of searchers express confidence in their skills as searchersñover half of them say they are ôvery confidentõ they can accomplishwhat they want when they perform an online search.ó¥ò. . . 44% of searchers say that all or most of the searches they conduct are for information they absolutely need to find.ó¥òa third of searchers say they couldnõt live without internet searchengines.ó however, about a half say that, while they like using searchengines, they could go back to other ways of finding information.how do internet users deploy the available aids to navigation? dothey generally go to the web sites they seek by entry of a domain name orkeyword or through bookmarks? do they follow hyperlinks from webpage to web page? or do they commonly make use of search engines anddirectories? there is little publicly available research that addresses thesespecific questions. one analysis, based on survey data from march 2003and 1 year earlier, provides some insights.51 according to that analysis,search engines produced 13.4 percent of site referrals on the day measured, which was an increase from 7.1 percent 1 year earlier. navigationthrough entry of a known or guessed url or use of a bookmark alsoincreased from 50.1 percent to 65.5 percent over the year. the decline occurred in the flow along hyperlinks, which decreased from 42.6 percent to21 percent. this survey indicates that internet users tend to use certainsites and services consistently, visiting them repeatedly, using their book51the data were collected on march 6, 2003, by websidestoryõs statmarket from about 12million visitors to 125,000 sites using its proprietary analytical platform and were comparedwith figures from the previous year. reported in brian morrissey, òsearch guiding moreweb activity,ó cyberatlas, march 13, 2003, available at <http://cyberatlas.internet.com/bigpicture/trafficpatterns/article/0,1323,59312109221,00.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state337marks or remembered urls. this suggests that much of their web use isroutine: checking email, visiting a few standard sites, and exchanginginstant messages with some internet buddies. the need for search enginesor directories arises primarily when a user needs a specific piece of information or wants a new or a replacement source of information, entertainment, or other material.when a search is required, a survey of 1403 internet users in spring200252 showed a strong user allegiance to one or a small number of navigation services. more than half (52 percent) generally relied on the samesearch engine or directory and close to 35 percent used several interchangeably. only 13 percent used different services for different kinds ofsearches. with respect to the usefulness of search engines, at that timealmost half (45.9 percent) believed their searches were successful almostalways. when they were not successful, 27 percent of the users switchedto another search engine, rather than refining the search with moretermsñonly 7.5 percent did that. one third of the users felt that theirsearches were successful threequarters of the time and 13 percent reported successful searches only half the time. (though presented differently, these figures are not inconsistent with the results of the pew studyreported above.)users of diverse skills and interests, located across the world, have arange of information and services literally òat their fingertips,ó whether atwork, at home, or on the road, that far exceeds that available even to information specialists before 1993. this is true especially for those seekingcommercial products and services. comparable navigation tools for scholarly and public interest materials are generally less well developed.conclusion: the further development of internet navigation services,such as subjectspecific directories, that enable discovery of specialized databases and similar resources not readily indexed by search engines, is desirable. they can be of particular value to noncommercial groups, whoseinformation resources may not be able to support active marketing.conclusion: as the material accessible through the internet continuesits rapid increase in volume and variety and as its societal importancegrows, internet navigation aids and services are likely to be challenged todeliver more precise responses, in more convenient forms, to more diverse questions, from more users with widely varying skills.52see òiprospect search engine branding survey,ó reported in òiprospect survey confirms internet users ignore web sites without top search engine rankings,ó iprospectpress release, november 14 2002, available at <http://www.iprospect.com/media/press20021114.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.338signposts in cyberspaceprospective improvements in internet navigation technology and processes are discussed in section 8.1.7.2internet navigationñinstitutional frameworkin contrast to the provision of domain name services, internet navigation is not the function of a single integrated technical system. while thereis just one domain name system, there are many ways of navigating theinternet, only three of which currently involve distinct technical systemsdedicated to navigationñkeywords,53 search engines, and directories.moreover, the institutional framework of the technical systems supporting internet navigation is an open market, with many independent andcompeting providers offering their services. while some providers arenonprofit or governmental institutions, such as national libraries or professional societies, the most frequently used navigation systems are provided by commercial organizations. this section concentrates on the commercial market for directory and search engine services.7.2.1the commercial providers of navigation servicesas noted in section 6.2.2, the early distinctions between providers ofdirectories and providers of search enginesñwhen each web search sitefeatured either algorithmic search engine results or humanpowered directory listings54ñhave increasingly become blurred. technology has helpedto automate some of the classification processes for the yahoo! directory,55and most generalpurpose web search sites now feature search results fromboth humanbased directories and crawlerbased search engines, with onetype providing the majority of search results. see table 7.2 for a listing ofnavigation services and the sources of the results they provide.the navigation services market is dynamic. the relationships shownin table 7.2, which applied in july 2004, are continually changing. for53in june 2004, the commercial market for keywords comprised primarily aol, netpia,and beijing 3721. yahoo! purchased beijing 3721 in 2004.54see danny sullivan, how search engines work, october 14, 2002, available at <http://searchenginewatch.com/webmasters/article.php/2168031>.55in òa history of search engines,ó wes sonnenreich explains that òas the number of linksgrew and their pages began to receive thousands of hits a day, the team created ways tobetter organize the data. in order to aid in data retrieval, yahoo! became a searchable directory. the search feature was a simple database search engine. because yahoo! entries wereentered and categorized manually, yahoo! was not really classified as a search engine. instead, it was generally considered to be a searchable directory. yahoo! has since automatedsome aspects of the gathering and classification process, blurring the distinction betweenengine and directory.ó see òa history of search engines,ó available at <http://www.wiley.com/legacy/compbooks/sonnenreich/history.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.339table 7.2navigation services and the providers of their resultsprocess used toprovider ofnavigationobtainprovider ofprovider ofdirectory and/orservicemain resultsmain resultspaid resultsbackup resultsalltheweb (overtureowned; searchalltheweboverturen/ayahoo!acquired)alta vista (overtureowned;searchalta vistaoverturelooksmartyahoo!acquired)aol searchsearchgooglegoogleopen directoryask jeevessearchteomagoogleopen directorygooglesearchgooglegoogleopen directoryhotbotsearchchoice of: inktomioverturen/a(yahoo!owned)google, ask jeeveslooksmartdirectorylooksmartlooksmartzeallycossearchallthewebovertureopen directorymsn searchsearchmsn/searchoverturen/anetscapesearchgooglegoogleopen directoryoverture (yahoo!owned)paidovertureoverturebackup from inktomiopen directorydirectoryopen directoryn/an/ateoma (ask jeevesowned)searchteomagooglen/ayahoo!search/directoryinktomi (yahoo!owned)overtureyahoo!source: based on searchenginewatch.com, 2003, available at <http://www.searchenginewatch.com/webmasters/article.php/2167981#chart>and updated in march 2005.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.340signposts in cyberspaceinstance, the early search engine lycos, which began in 1994, ceased providing its own search listings in april 1999 and has since used allthewebto power its web search site. google, which generates it own web searchresults, also provides algorithmic search services to others such as aoland, until march 2004, yahoo!, which paid google $7.2 million in 2002 forthe search queries it handled.56over the past 4 years from 2000 to 2004 in the united states, googlerose from eleventh position among navigation sites with a 5.8 percentmarket share in december 2000, as measured by òaudience reach,ó57 tofirst position with an estimated share of 34.7 percent in february 2004,as measured by òshare of search.ó58 (see figure 7.1.) the previous leading web navigation site, yahoo!, fell from a 48 percent share to secondposition with 30 percent during that time. two of the other highranking web navigation sites were msn with 15.4 percent and aol with 15percent of searches in february 2004. however, note that during thatperiod inktomi provided search services for msn, while google provided search services for aol. for international internet users (englishlanguage using populations), google had an even larger lead in february 2004, capturing more than 43 percent of searches to yahoo!õs 31percent, msnõs 14 percent, and aolõs 7 pecent. (since google still provided search results to both yahoo! and aol in february 2004, its actualshare of searches was closer to 80 percent, both internationally and inthe united states after march 2004, without yahoo!, its share droppedto 50 percent.)7.2.2the business of internet navigationthe primary source of income for commercial internet navigation services, which provide access to material on the public internet, has become56see yahoo proxy statement filed march 2002, p. 30, available at <http://www.sec.gov/archives/edgar/data/1011006/000091205702010171/a2073396zdef14a.htm>.57nielsen netratings reported in danny sullivan, ònielsen netratings search engineratings,ó february 2003, available at <http://www.searchenginewatch.com/reports/print.php/347012156451>. òaudience reachó is the percentage of u.s. home and workinternet users estimated to have searched on each site at least once during the month througha web browser or some other òonlineó means.58the new metric generated monthly by comscore media metrix, beginning in january2003, provides a better measure of market share by focusing on the number of searches thata search engine handles per month rather than the number of searchers that perform at leastone query on the web search site. the web search site queries are based on a panel of 1.5million web users located within the united states and in nonu.s. locations. the february2004 results are from a comscore media metrix press release on april 29, 2004, available at<http://www.comscore.com/press/default.asp>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state341selling advertising and placement on their sites.59 consequently, as inmany broadcast media, it is the content and service providers that aresubsidizing usersõ access to navigation services in order to present advertisements to them at the time of their expressed interest in a topic. thiscontrasts sharply with traditional commercial information search services,such as lexis, westlaw, and dialog, which have obtained their incomedirectly from their users, who pay to access the servicesõ proprietary (butfree of marketing influence) information. typically, those payforaccesscompanies also provide other services, such as training, documentation,and extensive customer support, to their users.figure 7.1company share of u.s. web searches by home and work users, february 2004. source: comscore media metrix qsearch press release, april 28,2004, available at <http://www.comscore.com/press/default.asp>.59commercial search engine companies are exploring possibilities beyond their own searchsites. for example, publishers such as the washington post have turned to google or overture to sell advertisements associated with the content that a visitor selects. see bob tedeschi,òif you liked the web page, youõll love the ad,ó new york times, august 4, 2003, availableat <http://www.nytimes.com/2003/08/04/technology/04ecom.html>. in addition,google and others license their search engine technology for use by other web sites and bycorporate intranets.yahoo, 30%google, 35%others, 3%ask jeeves, 2%aol, 15%msn, 15%signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.342signposts in cyberspacethe advertising that supports search services can take several forms:banner advertisements, popup advertisements, or searchlinked ads. banners are typically displayed at the top or side of a web page and are generally priced on a perimpression (view) basis, which means that the advertiser pays based on how many people see its advertisement, with pricesquoted in cpms (cost per thousand impressions), as is traditional in theadvertising industry. a typical rate for a generic banner advertisement is2 cents per impression, or $20 cpm. banner sizes are standardized so thatsellers and buyers of advertising space can find it easy to negotiate pricing and other contract terms.60 socalled òskyscrapersó are vertically oriented banner ads. popup advertisements are similar to banners, exceptthat they pop up as separate windows. their shape is also standardized.(the intrusive nature of popup advertisements has led to a variety of software productsñseparate programs or browser featuresñthat automatically prevent them from appearing.61)searchlinked advertisements appear as the result of a search. for example, the searcher mentioned above who enters the keyword search termòflorida vacationó might see advertisements for florida hotels, condorentals, theme parks, towns and cities, and the like. these may be displayed as banners, popups, sidebars, orñas noted earlierñpresented withthe search results themselves. sophisticated algorithms are used by thesearch services to select which advertisements will appear. these algorithms take into account, among other things, the amount the advertiser iswilling to pay if the user clicks on the advertisement, the relevance of theadvertisement, and the historic success of the advertisement in generating clicks. all services place limits on the number of advertisements theywill display.not surprisingly, searchlinked advertisements are much more valuable than generic banners. they are priced both by impression and byclickthrough. practices differ among search services, but google displaysup to two advertisements at the top of the page (which it calls òpremiumsponsorshipsó and up to eight advertisements on the right side of the60further information regarding these standards may be found at <http://www.iab.net/standards/guidelines.asp>.61additionally, software known as òadwareó or òspywareó has been developed that is installed on a userõs computer and covertly gathers information about a user during navigationof the internet and transmits such information to an individual or company. in turn, the individual or company transmits information back to the userõs computer to display specific banner advertisements based on the userõs navigation of the internet. such activity has resulted instate legislatures considering or enacting spyware regulation laws; see, for example, utahspyware control act (h.b. 323 2004), california  law (a.b. 2787 april 13, 2004; s.b. 1436 march23, 2004), and iowa law (s.f. 2200 march 1, 2004), and litigation to undo such laws; see, forexample, whenu.com, inc. v. utah, no. 040907578 (utah dist. ct. 3d dist. april 23, 2004).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state343page (which it calls òadwords selectó). typically, these ads can appearon every page of results.at one time google priced the top ads on a cpm basis and the sideads on a cpc (cost per click) basis. in the latter case, the advertiser paysonly when the user actually clicks on an advertisement. however, googlehas eliminated the cpm pricing, and now all its ads are priced on a cpcbasis. the ads placed at the top of the page are chosen from the side adson the basis of price and performance. prices for a clickthrough are over10 times as much as the price of a generic impression.62 however, somesearch engines will drop a clickthrough advertiser that does not producea sufficient number of hits.the two leading providers of searchlinked advertisements (or monetized search) are overture (now owned by yahoo!) and google, whichalso distribute searchlinked advertisements to other search sites. the paidlistings provided by overture to its affiliated network of web search sites,including yahoo!, msn, infospace, and alta vista, have been estimated tohave handled 46.8 percent of all u.s.based paid searches; and the paidlistings provided by google, appearing on the search results pages ofgoogle, aol, infospace and ask jeeves, accounted for 46.6 percent of allu.s. paid searches in january 2003.63 google provides search services toseveral hundred other partners, in the united states and abroad, althoughaol and ask jeeves are the biggest u.s. customers.searchlinked advertisements have been very successful. accordingto its initial public offering (ipo) prospectus, google had revenues of$961.9 million in 2003 and profits of $105.6 million, but without some unusual provisions, its operating profit margin is 62 percent. before its acquisition by yahoo!, overture reported revenues of $103 million in 2000,$288 million in 2001, and $668 million in 2002. in 2003 it claimed over95,000 advertisers, who received over 646 million clicks in the secondquarter of 2003 for which they paid an average of 40 cents per click.64these figures dramatically illustrate that internet navigation servicesñunlike many other internet services that were tested in the 1990sñhaveapparently found a financial model that is capable of supporting themand enabling their continued development. at the same time, the struggleto capture advertising dollars has been one of the forces driving the continuing consolidation of the industry, as some of the most successfulsearch services have acquired their competitors in order to increase theirshare of the market.62from overture, òannual report,ó january 2003.63see <http://www.imediaconnection.com/content/news/050503c.asp>.64data collected on august 16, 2002, and december 4, 2003, from <http://www.overture.com/d/usm/about/news/glance.jhtml>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.344signposts in cyberspacespending on paid listings (guaranteed separate listings on the searchengine results pages) and paid inclusion (guaranteed inclusion in the regular search engine results, but ranking not assured)65ñtwo of the threeforms of searchrelated marketingñgrew by 40 times in 4 years since2000.66 globally such spending is expected to grow 5fold to $7 billion ayear by 2007, from $1.4 billion in 2002. outside the united states, 10foldgrowth to $2 billion in 2007 from about $200 million in 2003 is expected. 67the revenues from monetized search are often shared between thesite and the search service that provides the advertisements. for example,google currently provides algorithmic search and monetized search foraol and they split the revenues from the monetization. overture provided monetized search for yahoo! on a sharedrevenue basis until itsacquisition, while google provided algorithmic search service to yahoo!until march 2004 for a flat fee. google and overture both use an auctionmodel to price their searchlinked advertisements: users can specify aprice that they are willing to pay for various positions, and the highestbidder gets the highest position in response to a specific query. for example, a rental car agency could bid to be listed first in any search foròrental cars.ó minimum bids vary, but generally the range of biddingstarts at 5 cents a click and goes up to $100 for some mortgagerelateditems, although google caps bids at $50. the model is sufficiently popularthat, as noted earlier, a secondary market of search engine marketers/optimizers has arisen to advise web sites on how to optimize their bidding for queries.68 the details of the auction systems differ, but the advantage of auctions is that hundreds of thousands of prices can be set byactual demand rather than having to be preset and posted.since these auctions are subject to gaming, navigation services activelywatch for potential fraud by advertisers and monitor the content of advertisers with editorial spotchecking. if they suspect cheating, the advertiserwill be removed from bidding. to become qualified bidders, advertisers65ask jeeves announced in june 2004 that it was phasing out its paid inclusion programbecause its algorithmic search had become sophisticated enough to find all necessary websites and refresh them as required, making paying for inclusion unnecessary. see stefanieolsen òsearch engines rethink paid inclusion,ó c/net news.com, june 23, 2004, available at<http://news.com.com/2102102435245825.html>.66see wall street journal online, accessed may 5, 2004. data from interactive advertising bureau, pricewaterhousecoopers llp, emarketer.67according to u.s. bancorpõs piper jaffray as reported by mylene mangalindan, òplayingthe searchengine game,ó wall street journal, june 16, 2003, available at <http://www.morevisibility.com/news/wsjplayingthesearchenginegame.html>.68see sites such as wordtracker, at <http://www.wordtracker.com/>, and <http://www.paidsearchenginetools.com/> for a description of their keyword bid optimizer(kbo); and traffick at <http://www.traffick.com/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state345provide information about themselves, their business, their interests, thekeywords on which they wish to bid, and how much they wish to bid.these advertiserdriven business models for navigation services contrastwith the noncommercial model of neutral information searching and navigation of public and academic libraries, although they more closely resemblethe business models for newspapers and other media where advertising andeditorial matter are expected to be rigorously separated. nevertheless, usersneed to be cautious about how they treat the results of internet searches,especially those about subjects with commercial significance. as noted above,the major search services currently identify the sponsored results (sponsoredlinks or sponsored search listings) and set them off from the direct results ofthe algorithmic search, following the newspaper model. as long as the distinction is clear and users are aware of it, sponsored search should presentfew problems while providing the great benefit of òfreeó search services tothe user. however, the potential for abuse exists. it would be possible, forexample, for a search service to accept payment for assured placement in theòtop 10ó of what would appear to be a neutral listing. (none have been accused of doing so, but some will accept payment to ensure inclusion, but notranking, in the otherwise neutral listing.) or the distinct placement and typography of the sponsored listing could be weakened to the point that acasual user would not be aware of its difference from the algorithmic searchresults. thus far, competition among sites and thirdparty evaluations haveserved as important countervailing forces. should abuses grow, however,search services could find themselves under increased public pressure forgovernment scrutiny or facing more disputes and criticism concerning suchactivities from other commercial entities. (see the discussion in section 8.2.1.)7.2.3the navigation services marketas seen above, a large number of navigation services have enteredthe market, attempting to achieve profitability by selling advertising. although it can be very profitable, this has turned out to be a difficult andexpensive venture. furthermore, competition among search engines hasforced them to invest in improved software and extensive computer andstorage facilities with substantial communications capacity to increase thebreadth, depth, and frequency of their coverage of the web.consolidationover the past 4 years, there has been considerable consolidation inthe search services market.69 several large search engine service provid69see, for example, <http://www.imediaconnection.com/content/news/050503c.asp>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.346signposts in cyberspaceers have left the market, and others have been combined into a singlefirm. at the same time, there has been increased vertical integration asoperators of web sites have acquired operators of search engines. in 2003,overture, with a primary focus on providing paid search listings, acquiredalta vista for $140 million and alltheweb, the fast search and transfer(fast) web search unit, for $70 million. overture aimed to strengthen itscore business of paid search listings by eventually integrating it with itsalgorithmic search and paid inclusion services.70 also in 2003, however,the directorybased yahoo! purchased the search engine inktomi for $235million, and then in july 2003, acquired overture for $1.62 billion.71google, while not an aggressive acquirer, went public with an ipo in 2004that raised $1.67 billion,72 which provided it with a war chest that can beused for acquisitions. the one new player that has entered the search services market is microsoft, which built the staff and technology to launchits own search service, which it is very likely to integrate into its nextgeneration operating system. in february 2005, microsoft unveiled a revised msn search that bore strong visual similarities to googleõs searchinterface.73yahoo! has apparently decided to vertically integrate by buying both apaidlisting provider and a search engine. it is now able to produce by itselfthe paid listings previously supplied by an independent overture and thealgorithmic search services previously provided by google. the net resultof this latest phase of consolidation is that there are only a few major independent navigation services leftñgoogle and yahoo! are the largest.in 2004, google, which then provided search services to both yahoo!and aol, actually had 80 percent share of searches. this dropped whenyahoo! replaced google with its own algorithmic search engine. however, whether the acquisitions result in sustained shifts in search shareswill depend on whether, for example, users of the yahoo! search site continue to search there or instead switch to another site that uses google.these changes in the search services industry are likely to influence other70see brian morrissey, òoverture to buy fast,ó australia internet.com, february 26, 2003,available at <http://www.breakfastforums.com.au/r/article/jsp/sid/12837>.71see òyahoo! to acquire overture,ó press release, july 14, 2003, available at <http://www.corporateir.net/ireye/irsite.zhtml?ticker=over&script=410&layout=0&itemid=430830>; and mylene mangalindan, nick wingfield, and robert guth, òrisingclout of google prompts rush by internet rivals to adapt,ó the wall street journal, july 16,2003.72see dawn kawamoto and stefanie olsen, ògoogle gets to wall streetñand lives,óc/net news.com, august 19, 2004, available at <http://news.com.com/google+gets+to+wall+streetñand+lives/2100103835317091.html>.73see juan carlos perez, òmicrosoft turns spotlight on its search engine,ó computerworld,february 1, 2005, available at <http://www.computerworld.com/softwaretopics/software/story/0,10801,99416,00.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: current state347web search sites, primarily aol, which currently outsource both websearch results and paid listings, to consider creating or acquiring theirown inhouse services. now that microsoft has entered the search enginecompetition, it is possible that aol will feel compelled to do the same.innovationin the past, as described in section 6.2, there has been a cycle of innovation, adoption, and displacement of navigation services. it began whensome new search engine or directory emerged with new technology, or abetter user interface, or both than the incumbentfavored service. the newservice attracted attention and gained market share. then as it and theinternet grew, its searches returned a larger number of irrelevant answers,even though its precision may not have changed. then yet another newservice with better technology or a better interface or both appeared. themarket tipped to the new leader and the cycle repeated. if this innovativecycle were to continue into the future, or if more specialized navigationservices were developed and succeeded, then the current consolidationmight be only temporary, a pause until a significant new and better technology or services arose. rapid changing of the leader is unlikely to happen under currentconditions in the navigation services industry (though the entry ofmicrosoft may represent an exception). the current consolidation reflectsthe increasing importance of economies of scaleñthe fact that the considerable hardware and software costs of developing and operating a searchengine are independent of the number of users, whereas revenues fromadvertising are directly dependent on them. this makes it difficult forinnovative services to start small and build volume over time unless theyhave a very large amount of patient investment capital. so in the future,competition among navigation services is more likely to take the form ofrivalry among a small number of established large players rather thancompetition with a large number of small newcomers.conclusion: the internet navigation services industry has successfully financed the development and evolution of services that meet manyof the needs of a wide range of searchers at little or no cost to them, especially when they are seeking commercial material. at the same time, it hasprovided advertisers with an efficient, costeffective means to gain accessto potential customers at the time that they are most interested in theadvertiserõs product or service.conclusion: the consolidation of the internet navigation services industry could reduce the opportunity for innovative new services to entersignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.348signposts in cyberspacethe market for general internetwide navigation in competition with existing services. however, the new services or their technology could alternatively be acquired by an incumbent, thus making it available to users,or could focus on a niche that is not well served by the more general services.so long as no single service becomes dominant, each competitor willhave continuing pressure to improve its offerings. the net effect of thesefactors on innovation cannot be predicted.conclusion: the importance of the internet as the infrastructure linking a growing worldwide audience with an expanding array of resourcesmeans that improving internet navigation will remain a profitable goalfor commercial developers and a challenging and socially valuable objective for academic researchers.conclusion: since competition in the market for internet navigationservices promotes innovation, supports consumer choice, and preventsundue control over the location of and access to the diverse resourcesavailable via the internet, public policies should support the competitivemarketplace that has emerged and avoid actions that damage it.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.3498internet navigation:selected prospects and issuesin this chapter, the committee explores a number of factors that arelikely to shape the future of internet navigation. the exposition thatfollows should not be construed as a comprehensive or representativetreatment of these issues. internet navigation encompasses a number of theestablished subdisciplines of computer and information science such as information retrieval, database management, humancomputer interface,computer algorithms, information economics, and intellectual property law,to name only some of them. the brief discussion that follows only toucheson a selected number of these subdisciplinesñand only for those issuesthat came to the attention of the committee during its deliberations.8.1technological prospectsdespite the relative success of the current array of internet navigationservices in satisfying their diverse and numerous users and providers, inthe future they will be faced both with pressures to improve further andwith technologydriven opportunities to do so.those pressures and opportunities have motivated a wide range ofresearch and development activity. part of this activity is devoted to advancing key technologies, three of which are navigation service algorithmsand operations, navigation interfaces, and navigation to audio and visualmaterials. another part is dedicated to improving navigation performanceby addressing some of the distinctive features of internet navigation (asnoted in section 6.1)ñmaking use of contextual information, improvingpersistence, and understanding user behavior.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.350signposts in cyberspace8.1.1navigation service algorithms and operationsefforts to improve internet navigation services1 are being undertakenin several areas that include:¥increasing the amount of material indexed and the frequency of indexing.2this is a topic of competitive research and development among commercial search services and is dependent primarily on the available computing and storage capacities. most of the effort goes into increasing the computing capabilities and storage facilities deployed. there is also a tradeoffbetween the size of the computational resources and the depth to whichsites are searched.¥improving algorithms for matching requests with results.3commercialsearch services devote substantial effort to improving these algorithms,and there is a large and vibrant community studying them in academicand other research institutions.4¥delimiting and describing specific regions of search.in many cases, users wish to limit the scope of their search. for example, searches may belimited to a particular site or uniform resource locator (url), to definitions, to telephone numbers, to a range of dates, to specific locations, andto a number of other special regions. many other categories could be usedto limit or filter results (e.g., a person, a book, an article).¥autonomous collection of information by search agents.softwareagents5 to automate access to information have long been predicted. research efforts continue to look for ways to use agents automatically toaggregate news and information based on a personõs interests. some of1for an overview of research on information retrieval that underlies much of internet navigation technology, see ricardo baezayates and berthier ribeironeto, modern informationretrieval, addisonwesley, wokingham, u.k., 1999.2see, for example, baezayates and ribeironeto, chapter 8, òindexing and searching,ówritten with gonzalo navarro, in modern information retrieval, 1999.3see, for example, baezayates and ribeironeto, chapter 5, in modern information retrieval, 1999.4for example, see michael kanellos, ònext generation search tools to refine results,ótechrepublic.com, august 9, 2004, available at <http://techrepublic.com.com/510022115302095.html>. in addition, the considerable worldwide research activity is reported in conferences and publications sponsored by trec (text retrieval conference), which is supported by the national institute of standards and technology and the department ofdefense, and the special interest group on information retrieval (sigir) of the associationfor computing machinery (acm). information on trec can be found at <http://trec.nist.gov>. information on sigir can be found at <http://www.acm.org/sigir>.5according to the dublin core metadata glossary, òa computer program that carries outtasks on behalf of another entity. frequently used to reference a program that searches theinternet for information meeting the specified requirements of an individual user.ó thedublin core web site is at <fttp://www.purl.org/dc/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues351the more interesting recent examples look for òdealsóñon, for example,auction sites and travel sites.6¥search specialized for nonroman scripts and various cultures.therehas been a considerable amount of work on commercial navigation tools,much of it government supported, in asia, especially korea and china.although it is inspired by the need to work with distinctly different asianlanguage/culture/character sets, the techniques developed may prove tobe applicable globally. the work has focused on intentionally populateddirectory systems and especially keyword (see section 7.1.4) systems.7efforts to improve the algorithms and operations of internet navigation services will continue, and are likely to increase, because of competitive pressures, evolving user requirements, and technological advances.unlike the early days, when almost all research and even developmentwas done within academic settings, commercial organizations now devote substantial resources to development and even research. however,research at universities and research organizations continues to be active,often with federal government support, and can be a source of distinctlynew approaches. furthermore, many academics are workingcollaboratively with commercial technologists, facilitating the transfer ofideas between academia and industry.8.1.2navigation interfacesinterfaces play a key role both in the creation of a query and in thedisplay of the results of that query.8 one of googleõs most attractive features, which has been adopted by other search services, for many of itsgeneral users is the simplicity of its singleline basic query interface. forthose so inclined and skilled, queries can be further specified through theadditional capabilities in òadvanced search.ó the clarity of the structureof googleõs display of results, with a clear separation between algorith6for flights, hotels, and rental cars, sidestep (<http://www.sidestep.com>) claims tosearch the web for travel values, presenting them to the user side by side with expedia ortravelocity results, allowing for comparisons. for extensive information on software agents,see the university of maryland, baltimore countyõs agent web, accessible at <http://agents.umbc.edu/about.shtml>.7two examples are (1) netpia, a korean internet service that enables substitution of anative language word or phrase (a keyword) for a unique url (see <http://e.netpia.com>) and (2) beijing 3721 technology co., ltd., which has offered chinese language keywords since 1999 (see <http://www.3721.com/english/about.htm>).8for background on this subject, see, for example, marti hearst, òuser interfaces and visualization,ó chapter 10 in baezayates and ribeironeto, modern information retrieval, 1999.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.352signposts in cyberspacemic search results and those that are sponsored, has also contributed to itssuccess with many users.further improvements in the query interface that would enable relatively unsophisticated users to characterize their queries more preciselywould be desirable, although to succeed they will have to remain veryeasy to use.there is, as well, room for improvement in the display of query results. for example, the relevanceranked listing that most search enginesproduce or the alphabetical listing that many directories provide might beimproved by displaying the relationships among the listed responses in amorereadily grasped visual form.a substantial body of research on the display of information exists. inthe late 1980s and early 1990s, the xerox palo alto research center(parc),9 in particular, developed several novel display representationsincluding cones, fisheye views, and hyperbolic trees.10 researchers atapple, the massachusetts institute of technology, and elsewhere haveexperimented with arranging webs of information (including search results) as threedimensional spaces; see, for example, the (now discontinued) apple hot sauce project.11 others have experimented with mappingresults on to twodimensional spaces. see, for example, kartoo, ametasearch engine that displays the search term (keyword) in a map withlinks to a range of related terms,12 and grokker2 that groups and mapsthe results of a metasearch of the web (and some sites, includingamazon.com) by subtopics.13 the display of query results is a subset ofthe larger field of information visualization, which incorporates the visual display of data of all kinds.14 research in that field may very welllead to new methods for visualizing query results.still other experiments have been directed at simplifying the management of the search. builtin search boxes, addin tool bars, frames (in webpages), sidebars, and tabs are a few of the browser additions that helpusers manage searches (among other things). at times, a number of companies offered browser addons or browser companions to aid web navigation and searching by collecting and displaying commentary on the9xerox parc was founded in 1970. in 2002, it became incorporated as parc, a subsidiaryof the xerox corporation. see <http://www.parc.com/about/factsheet.html>.10see <http://www2.parc.com/istl/projects/uir> for a description of the palo alto research centerõs user interface research projects.11see <http://www.eclecticasystems.co.uk/complex/hotsauce.php>.12see <http://www.kartoo.com/>.13see <http://www.groxis.com/>.14the annual ieee symposium on information visualization is a good source of information on current research on the subject. for information about the 2004 conference, see<http://infovis.org/infovis2004/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues353pages being viewed. most of these applications failed as commercial products, even though their interface ideas appeared to have merit.microsoft is expected to incorporate an internet search interface in itsnextgeneration operating system, codenamed òlonghorn.ó it is anticipated that the search interface will be the same for searching the internet,the local networkõs files, and the local computer files.15 this feature willencourage users to consider search an integral function of the operatingsystem, rather than a separate application available only through abrowser.future interface designers will also continue to be faced with designing interfaces to fit within form factors16 ranging from small (e.g.,cell phones17 and personal digital assistants) to expansive (multiscreenwallsize displays) and with employing one or more of a variety of sensory systems (auditory, visual, tactile) to communicate under diversecircumstances.8.1.3navigation to audio and visual materialsthe increase of multimedia materialsñcontaining digital images, audio, or videoñavailable via the internet has complicated the process ofnavigation by search engines whose crawlers are challenged to extractindex terms from still or moving images or from sounds. tools to indexaudio well enough to support search services exist, but generally only fora particular input domain such as television news broadcasts or applicationspecific telephone conversations. commercial video often has closedcaptioning, obviating the need for recognition. some technologies existfor searching images based on colors and shapes, but they are still in arelatively early stage of development.18 resources that incorporate mul15see michael kanellos, òmicrosoft aims for search on its own terms,ó c/netnews.com,november 24, 2003, available at <http://news.com.com/microsoft+aims+for+search+on+its+own+terms/2100100835110910.html?tag=nl>. òmicrosoft has set a firmer date forthe release of its desktop search software, after google launched a test version of its rivalprogram for scouring a pcõs hard drive,óreported in ina fried, òmicrosoft fixes date fordesktop search tool,ó c/net news.com, october 22, 2004, available at <http://news.zdnet.com/21003513225423080.html>.16the òform factoró of a device is its physical size and shape. the form factors of cellphones, personal digital assistants, and laptop computers differ substantially, resulting indifferent size displays that generally require different interface designs.17in october 2004, both yahoo! and google began offering search services from cell phones.yahoo!õs service is called yahoo! mobile, and googleõs is google sms.18for background on this subject, see, for example, christos faloutsos, òmultimedia ir:indexing and searching,ó chapter 12 in baezayates and ribeironeto, modern informationretrieval, 1999.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.354signposts in cyberspacetiple media, such as electronic literature that contains text, images, animation, and voice, are a particularly challenging search problem.19full accessibility for most multimedia materials, comparable to thatfor textual materials, will require development of technologies for theirautomatic indexing by search engines, which is a very difficult technology problem. for the foreseeable future, most effective multimedia searchwill depend on the use of metadata and associated text (see section 7.1.5).this can be done manually; can be picked up by web crawlers from pagemetatags; or can be extracted from text associated with still image, video,or audio files. a number of navigation services using these techniques areavailable on the web to find multimedia materials.20 among them aregoogle images, yahoo! search images, alta vista photo finder, fastmultimedia search, and lycos pictures and sounds.a navigation challenge common to all forms of multimedia search isstandardization and automatic capture of the metadata to be used for indexing, which would improve the availability and accessibility of suchmaterials.21 considerable research progress is being made in the searching of music by text, sound, and music notation,22 which is an active areaof academic research.23 video metadata is being pushed by industryforces, so it is reasonably far along. the mpeg7 standard24 for describingmultimedia content in a form that can be used by a device or a program ishighly developed, and deployment is likely to begin soon.19for background on this subject, see, for example, elisa bertino, barbara catania, andelena ferrari, òmultimedia ir: models and languages,ó chapter 11 in baezayates andribeironeto, modern information retrieval, 1999. current research activities are reported, forexample, in the conferences on image and video retrieval (civr), a series held since 1998.links to the conferences can be found at <http://www.informatik.unitrier.de/~ley/db/conf/civr/>.20see danny sullivan, òmultimedia search engines,ó searchenginewatch, january 25, 2002,available at <http://www.searchenginewatch.com/links/article.php/2156251>.21see <http://www.chin.gc.ca/english/standards/metadatamultimedia.html> for anoverview of the topic. research on computerassisted extraction of metadata from scholarlymaterial associated with images is underway in the climb project at columbia university.see <http://www.columbia.edu/cu/cria/climb/>.22for example, look at the work presented at the 5th international conference on musicinformation retrieval, available at <http://ismir2004.ismir.net/>.23one example is the work underway at carnegie mellon university in the infomediaproject on òdigital video understanding,ó which aims òto achieve machine understanding ofvideo and film media, including all aspects of search, retrieval, visualization and summarization in both contemporaneous and archival content collections.ó see <http://www.informedia.cs.cmu.edu/>.24see <http://www.chiariglione.org/mpeg/index.htm> and also rob koenen, òfrommpeg1 to mpeg21: creating an interoperable multimedia infrastructure,ó 2001, availableat <http://www.chiariglione.org/mpeg/frommpeg1tompeg21.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues355query by example25 is another promising approach to multimediasearch. given an image, it is possible in experimental systems (and insome commercial imageprocessing software) to find others with similarshapes and colors.26 however, given an image of horses, such techniquescan only find other images with the general shapes, colors, and textures inthe sample image, while missing images that have to do with horses, butdiffer in those respects.conclusion: indexing and retrieving multimedia materials on theinternet is an extremely difficult technical problem in its full generality,when there are few textual clues. however, for specific purposes or contexts, where textual descriptions are associated with the media, or whererelatively low precision can be tolerated, the existing systems can suffice.research prototypes and commercial offerings can be expected to continue to make slow but useful progress by focusing on specific subcases.8.1.4making greater use of contextual informationas noted in section 6.1.6, most current general internet navigationservices do not remember usersõ recent searches. in most cases, each queryis treated the same; the service collects no information about its usersõinterests or search goals. while this protects the searcherõs privacy, it canalso reduce the responsiveness of the search. in contrast, some sitespecific navigation services make considerable use of previous search historyto create user models and provide context for specifying searches.amazon.com, for example, gathers and displays a running history of whathas been seen within the current session and retains considerable information about what has been searched for or purchased previously that ituses to make userspecific recommendations. theoretically, generalinternet search engines could offer similar services to improve the ranking or filtering of results or to suggest additional searches.another approach, which is less likely to raise privacy concerns,would be to have a navigation aid that captures contextual informationon the userõs computer and uses that information to formulate contextaware requests to an internet navigation service.for many searches, knowing the geographical location of the userscan help in providing the desired information. but should navigation services assume that users are seeking local or global information? atpresent, the default assumption of a general internet navigation service is25query by example for textual queries is used in several conventional database systems.the concept was developed by ibm in 1975.26see <http://elib.cs.berkeley.edu/vision.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.356signposts in cyberspacethat users are seeking global information. however, in theory, navigationservices could sort multiple matches by geographic location (for objectswith geographic data, such as stores, restaurants, and libraries), listingthe nearest matches first, as specialized travel reservation services alreadycan do for hotels around a specific place. in response to this perceivedneed, both google and yahoo! now allow searches to be localized throughthe entry of an address, a zip code, or a city name together with the subject keyword (e.g., òsan francisco italian restaurantsó).27 the result is alisting of locally relevant web sites, maps, and listings from businesses inthe area. both services also offer local businesses the opportunity to advertise in response to localized keyword queries. in addition, google canobtain general information about the location of a query from the internetprotocol (ip) address of the user, while yahoo! could make use of its usersõ addresses, which they provide when registering for email, photo exchange, or other yahoo! services.the demand for geographically localized context information is likelyto grow rapidly as information appliances become smaller and more portable. a new yorker searching the web from his or her cell phone whilein chicago is likely to want to find a restaurant in chicago.28 a navigationtool that made that assumption might, in that situation, be appreciated.however, although with todayõs internet there is no fully reliable way todetermine the location of a searcher, technical tools do exist that offergood enough guesses to allow search engines to tune results to specificgeographic areas (through, for example, the ip address). for example, suchtools are currently being used to implement certain nationally requiredcensorship practices on yahoo! and ebay, such as the prohibition of thesale of nazi memorabilia in france or of mein kampf29 in germany. googlewill recognize canada as the source of a search dialed in from there.30 ofcourse, when the user enters geographic information voluntarily, or thedevice enters it automaticallyñas cell phones may soon be able to doñ27see stefanie olsen, ògoogle goes local,ó cnet news.com, march 17, 2004, available at<http://news.com.com/210010385173685.html>; and jefferson graham, òwebsites testlocal search marketing,ó usa today, february 6, 2004, available at <http://www.usatoday.com/tech/news/20040204localsearchx.htm>.28however, it is worth noting that while geographic context can increase the likelihood ofobtaining more relevant information, it is not a perfect process. in the example given, thenew yorker might be searching for the name and phone number of a new york restaurantto provide to a chicagoan in response to a query about recommendations for good restaurants in new york.29there are a number of versions of adolf hitlerõs mein kampf. one version is a translationto english by ralph manheim, houghtonmifflin, boston, 1971.30examples provided by an anonymous reviewer.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues357such geographic searches can be made easily. however, the automaticreporting of a userõs location to a search engine or other internet servicewould raise significant privacy concerns.31conclusion: the collection of some contextual information about users by navigation services can be used to improve internet navigation, butas the data become more detailed, difficult conceptual and implementation issues should be resolved and the associated privacy concerns addressed.the increased use of contextual information is likely to include somecombination of improvements in the collection and use of such information by the navigation services, extension of the option for users to enterspecific contextual information (e.g., location), development of contextsensitive local aids directly under the userõs control, and improvements inthe training and experience of users. the incorporation into queries ofinformation about the location of users, either automatically or voluntarily, and the addition of location filters into navigation servicesõ rankingalgorithms is already underway and is likely to expand rapidly under theimpetus of local advertising revenue.32user modelingñthe collection, retention, and use of informationabout specific users to assist in responding to their queriesñis an activeresearch area.33 creation of user models generates privacy concerns, andthis is another area of active research.34 those user models where theuserõs identity is known to the organization creating the model (such as31such systems are likely to work effectively only if the user wants to be located. the userwill have the option to disguise her location or to disable the system.32in the latter part of 2004, several major internet navigation service providers took steps toincrease the level of personalization in their services. see chris sherman, òyahoo introducespersonal search,ó searchenginewatch, october 5, 2004, available at <http://searchenginewatch.com/searchday/article.php/3417111>; gary price, òask jeeves serves it your way,ósearchenginewatch, september 21, 2004, available at <http://searchenginewatch.com/searchday/article.php/3410441>; and leslie walker and david a. vise, ògoogleõs new toolbrings search home,ó washington post, october 15, 2004, p. e1, available at <http://www.washingtonpost.com/wpdyn/articles/a340992004oct14.html>.33see peter brusilovsky and carlo tasso, òpreface to special issue, user modeling for webinformation retrieval,ó user modeling and useradapted interaction: the journal of personalization research 14(2):147157, 2004.34see alfred kobsa, òpersonalized hypermedia and international privacy,ó communications of the acm 45(5):6467, 2002; alfred kobsa, òtailoring privacy to usersõ needs,ó 8thinternational conference on user modeling, springerverlag, sonthofen, germany, 2001, available at <http://www.ics.uci.edu/~kobsa/papers/2001um01kobsa.pdf>; and alfredkobsa and jırg schreck, òprivacy through pseudonymity in useradaptive systems,ó acmtransactions on internet technology, 2003, available at <http://www.ics.uci.edu/~kobsa/papers/2003toitkobsa.pdf>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.358signposts in cyberspaceamazon.com) raise the greatest privacy concerns, as discussed further insection 8.2.2. user models that are maintained on the clientside andwhere the user can maintain control over what is known about him or herraise relatively fewer privacy concerns.8.1.5improving persistencesection 6.1.7 characterizes the many reasons that resources once discovered at a particular location on the internet may not be there whensubsequently sought. while this transience is not a problem for many resources, it can be a difficulty for many others. for example, the referencesto web resources throughout this report provide examples of materialsthat the reportõs authors and readers would like to see persistñbut cannot control.the notion of òpersistenceó of materials on the internet is related to,but not identical with, the more traditional notion of òpreservation.ó generally speaking, the goal of persistence is to maintain the same material atthe same address for an indefinite period, so that once discovered there itcan always be retrieved from that location in the identical form. preservation, however, has the goal of saving the material for future reference, butnot necessarily at the same address. in other words, to find somethingthat has been preserved will require at least one additional discoverystepñfinding the location (e.g., in an archive) at which it has been preserved.persistence is most likely to be achieved through the adoption of practices by web site managers and designers that leave unchanged the urlsof material judged valuable enough to persist and locate modified versions of those materials at new urls. consequently, unless there were tobe widespread adoption by web site managers and designers of commonpersistence practices, the problem of transient persistence will persist.however, there are services that provide a degree of persistence forsome materials on the world wide web. google offers access to the cachedversion, which is the version of a resource available at the time it wasmost recently added to the index. however, there is no attempt to provideaccess to earlier versions, and so persistence is very short.that leaves preservation as the most viable alternative. web preservation initiatives comprise three approaches: harvesting, selection, anddeposit.3535michael day, òpreserving the fabric of our lives: a survey of web preservation initiatives,ó research and advanced technology for digital libraries, 7th european conference, edcl,trondheim, norway, springer, berlin, germany, 2003.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues359the most farreaching approach to preservation has been taken by theinternet archive,36 a nonprofit corporation founded and run by brewsterkahle, which is supported by contributions from individuals, foundations,and corporations. rather than being concerned with the persistence ofspecific material on the internet, the internet archive is devoted to capturing (and preserving) a sequence of snapshots of what is publicly accessible on the internet. its goal is preserving the history both of the internetand of the vast range of human activities reflected in the constantly evolving materials on it. the internet archive, also called the òwayback machine,ó has taken and stored snapshots of materials on the internet since1996. in december 2003 it comprised over 11 billion web pages and over300 terabytes of data storage, increasing at 12 terabytes per month.37 it isoften the only way to locate digital documents that were moved to othersites or taken offline and, therefore, is of great value to users and scholarsñand to copyright holders, who can track the use of their content.at present, the internet archive is the only active effort in the unitedstates to preserve and provide access to the history of a significant portion of internet materials.38 in other countries, however, the national libraries are undertaking similar efforts.39 the international internet preservation consortium (iipc) was formally chartered at the biblioth‘quenationale de france with 12 participating institutions, all national libraries (including the library of congress) and the internet archive.40 its goalsare as follows:¥to achieve the collection of a rich body of internet content fromaround the world to be preserved in a way that it can be archived,secured and accessed over time.¥to foster the development and use of common tools, techniques andstandards that enable creation of international archives.¥to encourage and support national libraries everywhere to addressinternet archiving and preservation.during the 3 years of iipcõs initial agreement, membership is limited tothe charter institutions. it will open to other national libraries in 2006.36for information on the internet archive, see <http://www.archive.org>.37paul marks, òway back when,ó new scientist (date unknown), available at <http://www.newscientist.com/opinion/opinterview.jsp?id=ns23701>; latest information at<http://www.waybackmachine.org>.38the internet archive is mirrored at the new library of alexandria, egypt, and at thetime of writing it is in the process of establishing a european internet archive in amsterdam,the netherlands.39for example, the australian national libraryõs pandora project, which has beenarchiving australian online publications since 1996, is described at <http://www.nla.gov.au/initiatives/digarch.html>.40see <www.netpreserve.org> for full information on the iipc.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.360signposts in cyberspacehowever, the iipc will not serve as an operational archive. rather, it willprovide a forum for sharing knowledge; develop and recommend standards; develop tools and techniques to acquire, archive, and provide access to web sites; and raise awareness of preservation issues throughmeetings and publications.41in a similar vein, the library of congress has been leading since 2001a cooperative national digitalstrategy effort, called the national digitalinformation infrastructure and preservation program.42 the library,working with government and private partners, is to òdevelop a nationalstrategy to collect, archive and preserve the burgeoning amounts of digital content, especially materials that are created only in digital formats,for current and future generations.ó there is currently no commonly accepted way to decide which material on the internet should be retained orto ensure the availability of the resources or incentives needed to achievethat goal. these are among the issues that the library of congress effort isaddressing.8.1.6understanding user behavioruser behavior in navigating through traditional information resourceshas been a subject of considerable research, but less is known about theinternet case. if such information were available, it is likely that moreeffective internet navigation aids and services could be designed.research on information seeking in print environments dates back toearly in the 20th century, and research on information seeking in electronic environments dates to the 1960s. although a large body of empirical data exists, it is not clear how much of it is relevant to internet navigation. much of the prior research is in library (or comparable) contexts andassumes more homogeneous content, more constrained searching goals,and noncommercial environments. although relatively little is knownabout how people navigate the internet generally, there is a small butgrowing body of empirical research on the use of the world wide web.however, research on the web is severely restricted because search companies have been unwilling to share samples of the enormous amount ofdata they collect every day with researchers in academic environments.conclusion: basic research aimed at a better understanding of userbehavior in a variety of internet navigation tasks using a variety of methods and services is highly desirable.41information obtained from the iipc web site on september 3, 2004.42see the programõs web site at <http://www.digitalpreservation.gov/>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues361however, standard methods to evaluate searching performance onthe internet are lacking. the most advanced evaluation methods are constrained to text searching in bounded databases. a broader set of metrics,measures, and test beds is needed for the internet and digital libraries,and their development would also be desirable.43 an array of new national science foundation initiatives in cyberinfrastructure may contribute to these efforts.448.2institutional issuesmost of the institutional issues affecting internet navigation arise withrespect to the commercially supported navigation services, and especiallywith respect to services whose results are influenced by advertiser payments. the expectation by users that they will be able to understand andtrust the results presented by navigation systems leads to efforts by governments to impose disclosure requirements on navigation system operators, similar to the way other advertising practices are regulated in manycountries. the desire by information providers to protect their ownershipof trademarked and copyrighted material must be balanced with the needsof other providers to incorporate some of that material in descriptions oftheir own material. these issues are examined in this section.8.2.1regulationit is generally assumed by researchers and other observers of the industry that users want access to navigation services that are neutral, or atleast services whose biases match their own.45 in either event, they areassumed to want to know enough about the criteria by which results arereturned so that they can judge if those results are trustworthy. yet these43see christine l. borgman, evaluation of digital libraries: testbeds, measurements, andmetrics, final report to the national science foundation, fourth delos workshop, hungarian academy of sciences, computer and automation research institute (mta sztaki),budapest, hungary, june 67, 2002, available at <http://www.sztaki.hu/conferences/deval/presentations/finalreport.html>.44see daniel atkins, revolutionizing science and engineering through cyberinfrastructure:report of the national science foundation blueribbon panel on cyberinfrastructure, january 2003,available at <http://www.cise.nsf.gov/sci/reports/toc.cfm/>. see also the new nsf division on shared cyberinfrastructure, whose web site is available at <http://www.cise.nsf.gov/div/index.cfm?div=sci>, and similar programs in other directorates.45see deborah fallows, lee rainie, and graham mudd, òthe popularity and importanceof search engines,ó data memo, pew internet & american life project, august 2004, available at <http://www.pewinternet.org/pdfs/pipdatamemosearchengines.pdf>; 68 percent of respondents to the pew/internet survey thought that internet search engines are afair and unbiased source of information, while 19 percent thought they were not.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.362signposts in cyberspaceassumptions are not proven; more complete understanding is needed ofthe value that users place on the explicit disclosure of search and resultsranking criteria and on having a choice among navigation systems employing a range of different criteria. in addition, there is a presumed social benefit in having an information infrastructure that can be trusted. a searcherõs need to understand the criteria for ranking the results ofa search has risen in importance now that advertising has become theprimary source of revenue for search engine companies. that need conflicts with the objectives of some advertisers, who would like their listingsto appear as much as possible like the highranking results of a neutralsearch. consequently, it is not surprising that u.s. federal trade commission (ftc) regulators concluded in june 2002 that some internet searchengines46 were not adequately informing consumers when advertiserspaid for prominent placement in search results. the ftc division of advertising practices sent a letter47 to major search services recommendingthat theyreview their web sites and make any changes necessary to ensure that:¥any paid ranking search results are distinguished from nonpaid results with clear and conspicuous disclosures;¥the use of paid inclusion is clearly and conspicuously explained anddisclosed; and¥no affirmative statement is made that might mislead consumers as tothe basis on which a search result is generated.in addition, òto the extent that search engine companies providesearch results to thirdparty web sites, including other search engines orguides, [the ftc is] encouraging the companies to discuss with the thirdparty web sites whether the above criteria are being met with respect toany supplied search results that involve a payment of any kind for ranking, insertion of paid results into unpaid results, or any payforinclusionprogram.ó furthermore, the ftc staff recognized òthat search enginecompaniesõ business models vary and that there is a need for flexibility inthe manner in which paid placement and paid inclusion are clearly andconspicuously disclosed.óthe ftc letter went on to say that the few studies of consumer viewson paid inclusion and paid placement that have been done indicate thatmany consumers are not aware of the practice. it referred explicitly to twostudies:46other search engines, such as google and altavista, clearly designate or segregate thesponsored listings. see section 5.4.2.47letter from ftc to gary ruskin, executive director of commercial alert, june 27, 2002,available at <http://www3.ftc.gov/os/closings/staff/commercialalertletter.htm>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues363a consumers union national survey found that 60% of u.s. internet users had not heard or read that certain search engines were paid fees to listsome sites more prominently than others in their search results. afterbeing told that some search engines take these fees, 80% said it is important (including 44% who said it is very important) for a search engine todisclose, in its search results or in an easytofind page on its site, that itis being paid to list certain sites more prominently. if clearly told in thesearch results that some sites are displayed prominently because theypaid, 30% said they would be less likely to use that search engine, 10%said more likely, and 4% said donõt know/refused. consumers unionalso reported that ògiven the complicated situation, 56% say it wouldmake no difference to them.ó it stated that the òcombination of usersõlow level of knowledge of search engine practices and their strong demand that search engines should come clean leaves users splinteredabout how to react.ó48 a recent bbccommissioned survey found that71% of u.k. users were unaware that some search engines let advertiserspay to get more prominent positions in search results.49against this background, the ftc also issued, in september 2002, aconsumer alert, òbeing frank about search engine rank,ó which advisesusers to be aware that the results of their searches may be affected byvarious payforplacement programs of internet search engines.50although neither of these actions constitutes an enforcement actionwith the force of law, they do alert the navigation services operators to theinterest of the ftc and the possibility that in the absence of change itmight consider more formal action.in addition, internet advertising, whether search engine linked or not,is subject to the same types of national regulation as other advertisingwith respect to fraudulent or misleading claims and so on. in the unitedstates, the ftc has pursued various cases on those grounds. furthermore,search engines typically have guidelines for the content they will provide.in 2003, yahoo! and google announced that they would restrict advertisements from unlicensed pharmacies in response to consumer concernsabout illegal online drug sales.51the way in which search engines provide rankings has also been thesubject of a u.s. district court case. searchking, an online advertisingnetwork, sued google because it asserted that google reduced the48see òa matter of trust: what users want from web sites,ó april 16, 2002, available at<www.consumerwebwatch.com/news/report1.pdf>.49see, for example, òbbc launches its noncommercial search engine in response toôtaintedõ results,ó may 2, 2002, available at <http://www.venturereporter.net> (subscription required).50available at <http://www3.ftc.gov/bcp/conline/pubs/alerts/searchalrt.htm>.51saul hansell, òsearch engines limit ads for drugs but ease rules on sex,ó new yorktimes, december 3, 2003.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.364signposts in cyberspacepagerankª of its site after searchking created a network of sites that hadthe effect of boosting all the membersõ pageranksª. by reducingsearchkingõs pagerankª, google also had the countervailing effect ofreducing the pagerankª of the network members. searchking assertedthat googleõs action harmed its business. the court, however, found thatgoogle had the right to adjust pagerankª value since it constituted anopinion and was covered by first amendment protections.52these two examples illustrate the nascent engagement of nationalregulatory agencies and legal systems with issues arising in navigationservices. as internet navigation continues its growth as a major source ofcontacts for information and service providers and as a major advertisingmedium, it may be expected that the scrutiny and activity of regulatoryagencies and legal systemsñand legislaturesñwill increase as well.conclusion: the behavior of commercial navigation services can havea substantial influence on the kind, quality, and appropriateness of theinformation that internet users receive. although there is no evidence thatabuse has yet occurred, the potential for abuse is inherent in the navigation servicesõ ability to affect usersõ access to information for commercialor other reasons.recommendation: although competition and the desire to be seen asuseful by searchers are incentives for fair and open behavior, appropriateregulatory agencies of the u.s. federal government and of other governments should pay careful and continuing attention to the result rankingand display practices of internet navigation services and their advertisersto ensure that information can flow freely and that those critical practicesare fully disclosed.recommendation: since competition in the market for internet navigation services promotes innovation, supports consumer choice, and prevents undue control over the location of and access to the diverse resourcesavailable via the internet, public policies should support the competitivemarketplace that has emerged and avoid actions that damage it.8.2.2privacyprivacy issues affect internet navigation, in both overt and subtleways. the crux of the privacy concerns rests on the ability of web sitesand other online resources to track their visitors and to capture data about52see ògoogle wins over searchking in pagerank case,ó pandia search engine news, june2, 2003, available at <http://www.pandia.com/sw2003/21searchking.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues365what is being viewed, read, downloaded, or otherwise used without theconsent of users.53 as noted in the discussion of context (section 6.1.6), themore that a system knows about a personõs goals, intentions, and prioractivities, the greater the context that can be provided and the more tailored the searching can be. the negative sides of tracking are equally significant, however.tracking what people read or view could violate longestablished liberties in the united states and in many other free societies if that information were made available, freely or under subpoena, to government agencies. lack of privacy also has a potential òchilling effect.ó people are lesslikely to act on their freedom of speech if they feel that their queries arebeing recorded and may be disclosed without their permission.yet the internet is the site of illegal activities, such as identity theft,illegal transactions, and nonprotected speech, such as child pornography. law enforcement has always had means to target illegal activitieswithout undermining basic democratic principles and needs them on theinternet as well. the designers of future navigation services and of thelaws that affect them will, of necessity, be trying to find a workable balance among the servicesõ desire to use individual information to improveservice, the individualõs right to privacy, and the governmentõs legitimateneeds to know.54issues of privacy are both important and complex and relate to theinternet and information technology more broadly, not only to navigation. this study could not do them justice, but there are a number of reports and ongoing studies on internet privacy.558.2.3trademarks and copyrightintellectual property rights is an issue whose link to internet navigation may not be obvious. however, a number of court cases have arisen inwhich the use of trademarked material in the navigation process has beenin dispute.56 moreover, the extent to which search engines may make use53see fallows, rainie, and mudd, òthe popularity and importance of search engines,ó2004. according to the pew/internet survey, 85 percent of search engine users rate òknowing that personal information will not be shared without permissionó as an important attribute of search engines, but only 55 percent believe that they deliver.54googleõs privacy policy is available at <http://www.google.com/privacy.html>;yahoo!õs, at <http://privacy.yahoo.com/>.55for example, the computer science and telecommunications board of the national research council has an ongoing study, whose report is forthcoming in 2006, on privacy in theinformation age. for further details, see <http://www.cstbprivacy.org/>.56see cindy sherman, òsearch engines and legal issuesñoctober 23, 2002,ósearchenginewatch, 2002, available at <http://www.searchenginewatch.com/searchday/article.php/2161041>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.366signposts in cyberspaceof copyrighted material has been and is certain to continue to be a significant issue.trademarkas in the dns, the use of trademarked names is a source of contention in internet navigation. whereas for the dns the issue is the use oftrademarks in domain names, in navigation the issue is their use inmetatags and keywords. unlike the dns, for which the nonjudicial uniform domain name dispute resolution process (udrp) has been established, most disputes in internet navigation that are not resolved throughnavigation servicesõ own policies have found their way to the courts.however, thus far, there have been far fewer trademark cases concerningnavigation than concerning domain names.one trademark dispute that reached the courts concerned the right touse such terms in metatags, the invisible markers of a web site selected bythe site creator and sometimes used by search engines as keywords. playboy enterprises sued a former playmate for incorporating some of itstrademarked terms in the metatags at her site. the court, however, decided in her favor on the grounds that she had a legitimate right to usethose terms in describing herself and had not done so with the intent ofattracting users seeking the playboy site.57another trademark dispute concerned allowing nontrademark holders to bid for a trademarked term. mark nutritionals filed suit againstoverture (then goto) and other paid placement providers for auctioningits trademarked phrase òbody solutionsó to their competitors. as a result,those competitors were showing up higher in searches for òbody solutionsó than was mark nutritionals, which claimed that this constitutedtrademark infringement as well as unfair competition.58in a third dispute, j.k. harris & co. sued taxes.com because thetaxes.com site was higher ranked in search engine results than the j.k.harris site for the search term òj.k. harris.ó the suit was for trademarkinfringement, unfair competition, false and misleading advertising, anddefamation. the reason for the higher ranking was that the phrase òj.k.harrisó appeared frequently (75 times) on the web page entitled òcomplaints about j.k. harris,ó which contained emails detailing the siteownerõs conversations with investigators about j.k. harris. the judge57the court decision is available at <http://caselaw.lp.findlaw.com/data2/circs/9th/0055009p.pdf>.58see christopher saunders, òweight loss company sues search engines,óinternetnews.com, february 1, 2002, available at <http://www.internetnews.com/iar/article.php/12966901>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues367ruled that the site had the right to use the òj.k. harrisó term, but did notlike the number of times that it was used. a preliminary injunction againsttaxes.com was issued by the court but was due for reconsideration as aresult of a brief filed by the electronic frontier foundation.59 note thatthis case was against the web site owner, not the search engine company.presumably to avoid becoming the subject of frequent suits, googlehas established a complaint procedure to enable companies to claim òreasonableó rights to their trademarked terms.60 in a prominent use of thatprocedure, ebay asked google in august 2003 to refuse to sell ads that useebayõs trademarked name, either alone or in phrases and variations, òsothat thirdparty advertisers do not abuse the intellectual property of thecompany.ó ebay submitted a 13page list of terms, such as òebay sellingóand òebay power seller,ó that it wanted google to bar. ebay says thatgoogle has complied with its requests.61 ebayõs trademarks can still bereferenced under fairuse provisions, which allow an advertiser to usesome one elseõs trademarked term for description or comparison of itsproductñfor example, to sell the book ebay for dummies.62however, in france, google has been sued by three companies and inthree significant cases has been ordered by regional french courts to stopselling a companyõs trademarked terms as keywords to other companiesand to pay damages. in the first case, a regional court ordered google topay 75,000 euros to two travel companies whose trademarked terms weresold as keywords to rival companies. the court said that google shouldòfind the means to block advertisements by third parties who have noright to [the] trademarks.ó in the second case, a nanterre court told googleto stop selling trademarked terms of the le meridien hotel chain as keywords to its competitors or pay a daily fine of 150 euros.63 in the thirdcase, a paris district court ordered google not to sell keywords incorporating trademarks of the luxury goods firm louis vuitton malletier and topay a fine of 200,000 euros.64in an effort to block a similar case in the united states, google has59see cindy sherman, òsearch engines and legal issuesñoctober 23, 2002,ó 2002, available at <http://searchenginewatch.com/searchday/article.php/2161051>.60see <http://www.google.com/tmcomplaint.html>.61see brian morrisey, òebay invokes trademark on google keywords,ó internetnews, august 11, 2003, available at <http://www.internetnews.com/iar/print.php/2447071>.62marsha collier and roland woerner, ebay for dummies, 2nd edition, hungry mind press,st. paul, minn., 2000.63see stefanie olsen, ògoogle loses trademark dispute in france,ó c/net news.com, january 20, 2005, available at <http://news.com.com/google+loses+trademark+dispute+in+france/2100103035543827.html?tag=nl>.64see stefanie olsen, ògoogle loses trademark case in france,ó c/net news.com, february4, 2005, available at <http://news.com.com/google+loses+trademark+case+in+france/2100103035564118.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.368signposts in cyberspaceasked a u.s. district court judge for a declaratory judgment on trademarkissues raised by american blind, which sells wallpaper and window coverings. the company complained that google was selling adwords infringing its trademarks, listing over 30 terms ranging from the obvious tomore generic terms, such as òamerican wallpaper discount.ó googleagreed to block the trademarks, but not variant terms because they weredescriptive terms that other advertisers had the right to use. in january2004, american blind filed a lawsuit.65 shortly before, google had made arequest for a judgment that adwords do not infringe american blindõstrademarks and demanded a jury trial. the outcome can be quite significant for google, and other advertisingdependent search engines, since itcould affect the degree of scrutiny that they would have to apply to eachkeyword sale, potentially increasing costs and reducing the number ofavailable words.in december 2004, google won a u.s. victory when a judge of the u.s.district court granted googleõs request to dismiss a trademarkinfringement complaint from the insurance company, geico. the judge ruled thatit is not trademark infringement to use trademarks as keywords to triggeradvertising.66copyrightonly a few contentious issues have arisen regarding copyright andnavigation services. one such issue involves the socalled ònotice and takedownó provisions of the digital millennium copyright act (dmca),67which requires any internet service provider (isp) (which would includeany search engine operator) to remove or disable access to any thirdpartycontent that has been identified in a statutorily compliant notice providedto the isp by the owner, or its agent, of the copyright in such content. inorder to be statutorily compliant, a dmca notice must (1) be signed bysomeone authorized to act on behalf of the owner of the exclusive rightthat is allegedly infringed; (2) identify the copyrighted work allegedlyinfringed; (3) identify the allegedly infringing content or activity and provide enough information to enable the isp to find the content; (4) provideinformation that is reasonably sufficient to permit the isp to contact thecomplaining party, such as a mailing address, telephone number, or65see stefanie olsen, ògoogle faces trademark suit over keyword ads,ó c/net news.com,january 28, 2004, available at <http://news.com.com/google+faces+trademark+suit+over+keyword+ads/2100102435149780.html?tag=nl>.66see stefanie olsen, ògoogle wins in trademark suit with geico,ó c/net news.com, december 15, 2004, available at <http://news.com.com/google+wins+in+trademark+suit+with+geico/2100102435491704.html?tag=nl>.67public law 105304.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.internet navigation: selected prospects and issues369email address; and (5) include a statement that the complaining party hasa goodfaith belief that use of the allegedly infringing content is not authorized by the copyright owner, its agent, or the law. back in 1996 and1997, when the dmca was being negotiated, hyperlinks to thirdpartycontent were thought to be outside the scope of the notice and take down(ntd) provisions of the dmca, and in fact a few courts have refused toenforce the dmca when asserted in this context. however, the nature ofproviding links, at least within the context of search engines, has changedover the years, in that many search engines now include excerpts of theinformation as part of the link, and so the applicability of the ntd provisions is less clear. accordingly, some search engine operators have takento complying with dmca notices, even though they may not be technically required to do so. for example, in 2002, google removed some 126pages that the church of scientology claimed infringed its copyright. oneof the pages was the home page of an antiscientology site that had gaineda high ranking in searches on the term òscientologyó through the effortsof antiscientology activists to build links to it. after protest, google restored that page, saying that it was òinadvertently removed.ó68 the caseshows the potential danger from use of the dmca to unfairly shut downaccess to web sites. however, according to google, the case was unusual.it generally gets one or two dmca complaints per week that it describesas òopen and shut.óalthough the dmca requires only that the complaining party attestto its goodfaith belief that the content in question is infringing, the dmcaalso provides a counternotice provision that enables the provider of thequestionable content to challenge the complaining partyõs notice and havethe information restored until the complaining party avails itself of thefederal courts and obtains injunctive relief. one of the primary purposesof the dmca, other than to extend the protections of the copyright lawsto digital works published over the internet, was to remove isps frombeing caught in between thirdparty providers of content and the ownersof copyrights when a fight broke out over who owned the rights to thatcontent. by filing a counternotice, the provider of the content is effectivelyaccepting the jurisdiction of a u.s. court should the original complainantwant to pursue its complaint, and so many content providers may choosenot to avail themselves of this protection. it should also be noted, however, that the dmca does not obligate search engines to inform contentproviders when their content has been removed or blocked. according tothe statement of dmca policy on its web site,69 however, google will68see david f. gallagher, ònew economy; a copyright dispute with the church ofscientology is forcing google to do some creative linking,ó new york times, april 22, 2002,p. c4.69available at <http://www.google.com/dmca.html>.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.370signposts in cyberspacemake a ògoodfaith attempt to contact the owner or administrator of eachaffected site so that they may make a counter notification.óconclusion: as with the domain name system, the most contentiousintellectual property issues affecting navigation services concern trademarks. since there is no arbitral process, such as the udrp, by which suchdisputes could be resolved outside the courts and with worldwide effect,it seems likely that conflicting court decisions in different jurisdictions,worldwide, will establish the potentially conflicting rules by which navigation services will have to abide. potential rulings in some jurisdictionscould substantially reduce the ability of search engines to sell keywordsusing the current automated methods with restriction of specifically trademarked terms only.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.3719the domain name system andinternet navigationas the preceding chapters show, the relationship between internetnavigation and the domain name system is complex and multidimensional.the domain name system (dns) was defined centrally under theleadership of a relatively small group of internet engineers in response toan operational need. although its effective implementation occurred overseveral years, during which relatively small changes were made as required, the basic design of the system has remained the same for twodecades. as described in chapter 3, the internet engineering task force(ietf) and the internet architecture board (iab) provide technical leadership and coordination for developing changes to the protocols and otherstandards affecting the dns. changes in the root zone file are controlledby the internet corporation for assigned names and numbers (icann)and the u.s. department of commerce. but a mix of academic, governmental, commercial, and nonprofit organizations with distributed responsibilities operates and manages the domains. the dns stands, therefore, as an example of a technical system that was designed centrally butis operated by a distributed set of organizations.in contrast, internet navigation aids and services have evolvedthrough a sequence of innovations by separate and independent individuals and organizations, initially primarily by academics, and more recently,by commercial entities. their evolution has been shaped by the responseto the cumulative knowledge obtained through publication, the responsesof the market to successive offerings, and the close study of competitivesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.372signposts in cyberspaceofferings. innovation continues, although perhaps at a slower pace thanin the first few years. no central organization has affected the design orevolution of navigation aids and services, except to the extent that widelyaccepted web protocols specify the structure of web sites to be searchedby search robots. internet navigation aids and services are good examplesof technologies that have developed and operated in a decentralized environment with investors, users, and advertisersñthat is, market forcesñdetermining which designs are successful.despite the differences in the way in which they developed, the relationship between the dns technical system and internet navigation aidsand services is strong and fundamentalñthe dns has served as the stablecore on which the incremental evolution of the different navigation aidsand services has depended. domain names are a key part of the uniformresource locators (urls) that identify the web resources found by allinternet navigation aids and services, and when the user navigates to anidentified resource, it is the dns that retrieves its internet protocol (ip)address. however, since search engines and directories actually identifythe ip address of a server resource directly, they could simply display it asthe link to the resource without displaying its url. that, of course, woulddeprive the user of the additional information that the descriptive elements of the url, specifically the domain name, provide about the resource. but it suggests that, in the absence of a functioning dns, searchengines and directories could still allow users to navigate to many (if notall) desired locations on the public internet.in sum, it is the dns and internet navigation aids and services working together that enables searchers to have successful and convenient access to the vast realm of web resources.the institutional frameworks of the dns and navigation services provide illuminating contrasts. the dns is a single hierarchical technical system whose implementation is decentralized, but which adheres to opentechnical standards promulgated by an international technical community. it is guided by the general oversight of a nonprofit organization andthe stewardship of the u.s. government, and is operated by a diverse,global collection of organizations and individuals. except for the leasingof domain names, its services are made available at no direct charge tousers. in contrast, internet navigation services are provided by a largenumber of autonomous organizations, both commercial and noncommercial, operating proprietary or licensed technical systems, without any general oversight of either their technology or their operations. however,internet navigation services are also offered at no direct charge to the users; advertisers cover much of the costs through the purchase of advertising insertions associated with search terms.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.the domain name system and internet navigation373the rapid development of navigation technology in the past decadeappears to have had a significant effect on the unintended uses of thedns and the commercial pressures on it. in the early days of the web,guessing of domain names played an important role in navigation to websites. as noted in chapter 2, that led to a rapid increase in the economicand social value of ògoodó domain names, especially those in the .comdomain, and to a correspondingly òhotó market in their sale and resale.while such domain names remain valuable for their identifier function (ina url or on the side of a bus), their role in navigation has been replacedto a significant degree by the use of search terms in search engines. correspondingly, much of the commercial concern about registering notabledomain names appears to have been transferred to the commercial business of purchasing effective search terms on the various navigation services. to some extent, this also appears to be shifting some of the concernwith protecting trademark rights on the internet from domain names tosearch terms.conclusion: both the domain name system and internet navigationservices will be significant elements of the internet for the foreseeable future. both will continue to evolve, as will the interrelationships betweenthem.conclusion: the governance and administration of the dns shouldnot become a vehicle for addressing political, legal, or economic issuesbeyond those of the dns itself.conclusion: the development of internet navigation services is likelyto continue to relieve some of the commercial pressures on the dns asusers become increasingly comfortable with using these services as theirprimary means to navigate the internet.conclusion: the preservation of a stable, reliable, and effective domain name system will remain crucial both to effective internet navigation and to the operation of the internet and most of the applications thatit supports.recommendation: the demonstrated success of the dns and navigation aids and services in meeting the basic needs of internet users shouldnot be jeopardized by efforts to constrain or direct their evolution outsideof the open architecture of the internet, or to use them to enable control ofthe free flow of information across the internet.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.appendixessignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.377abiographies of committeemembers and staffroger levien, chair, is the principal and founder of strategy & innovation consulting, a personal consultancy established to provide strategyand innovation consulting services to the senior managers of public andprivate organizations. his career has focused on the integrative use ofinformation from social, environmental, and physical science research andtechnology to analyze and inform the choices faced by public and privateinstitutions. previously, he was corporate vice president for strategy andinnovation at xerox corporation; director of the international institute forapplied systems analysis in austria; and department head and deputyvice president with responsibility for system sciences and nonmilitarypolicy research at the rand corporation in santa monica, california,and washington, d.c. he is the author of three books: the emerging technology (mcgrawhill, 1972), r&d management (lexington, 1975), and taking technology to market (crisp, 1997). he has also written chapters in systems, experts and computers (mit press, 2000) and technology 2001 (mitpress, 1991). he was awarded the ehrenkreuz, first class, in science andarts by the austrian government and is a member of the connecticutacademy of science and engineering, phi beta kappa, sigma xi, and taubeta pi. dr. levien received his ph.d. (1962) and m.s. (1958) degrees inapplied mathematics (computer science) from harvard university. healso received his b.s. degree in engineering (highest honors) fromswarthmore college in 1956.s. robert austein is a software engineer at the internet systems consortium, focused primarily on development and deployment of standardssignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.378signposts in cyberspacebased internet protocols. prior to this, he was vice president of engineering at internetshare, incorporated, architect for the epilogue embeddedproducts group at integrated systems, inc., vice president of engineeringat epilogue technology corporation, and a member of the research staffat mitõs laboratory for computer science. at various times he has servedas a member of the internet architecture board (iab), a member of thegtldmou policy oversight committee, as chair of the internet engineering task forceõs (ietfõs) domain name system, dns operations,ipsec key, and intellectual property rights working groups, and hashelped both to specify extensions to the dns protocol within the ietfand to implement various portions of the dns on everything from mainframes to embedded systems since 1985. he holds a b.a. in mathematicsfrom wesleyan university.stanley m. besen is a vice president at charles river associates,washington, d.c. besen has served as a brookings economic policy fellow, office of telecommunications policy, executive office of the president (19711972); codirector, network inquiry special staff, federal communications commission (19781980); coeditor, rand journal ofeconomics (19851988); senior economist, rand corporation (19801992);and a member of office of technology assessment advisory panels oncommunications systems for an information age (19861988) and intellectual property rights in an age of electronics and information (19841985) and on the national research councilõs committee on licensinggeographic data and services (20022004). he currently serves as a member of the editorial board of economics of innovation and new technology.dr. besen has taught at rice university (19651980) where he was theallyn m. and gladys r. cline professor of economics and finance, columbia university (19881989) where he was the visiting henley professor of law and business, and the georgetown university law center(19901991) where he was a visiting professor of law and economics. heholds a ph.d. in economics from yale university (1964). dr. besen haspublished widely on telecommunications economics and policy, intellectual property, and the economics of standards and has consulted withmany companies in the telecommunications and information industries.he is the author of òthe economics of telecommunications standardsó inr.w. crandall and k. flamm (eds.), changing the rules: technologicalchange, international competition, and regulation in communications (withg. saloner); òchoosing how to compete: strategy and tactics in standardization,ó journal of economic perspectives, 1994 (with j. farrell); òintellectual property,ó in the new palgrave dictionary of economics and the law,macmillan press, 1998; òadvances in routing technologies and internetpeering agreements,ó american economic association papers and proceedsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.appendix a379ings,ó 2001 (with p. milgrom, b. mitchell, and p. srinagesh); and òverticaland horizontal ownership in cable tv: time warnerturner (1996),ó inj.e. kwoka and l.j. white, the antitrust revolution, scott, foresman, 1998(with e.j. murdoch, d.p. oõbrien, s.c. salop, and j.r. woodbury).christine l. borgman holds the presidential chair in informationstudies at the university of california, los angeles (ucla), where shehas been a faculty member since 1983. she spent a sabbatical year (20042005) at the oxford internet institute, university of oxford, u.k. dr.borgmanõs teaching and research interests include digital libraries, information infrastructure, scholarly communication, social studies of science,and information technology policy. dr. borgman has published more than150 articles, conference papers, reports, and books in the fields of information studies, computer science, and communication; she has lecturedor conducted research in more than 20 countries. she is currently a coprincipal investigator for the center for embedded networked systems(cens) and for the alexandria digital earth prototype (adept) project,both funded by the national science foundation. she currently chairs section t (information, computing, and communication) of the americanassociation for the advancement of science (aaas) and is a fellow of theaaas. her professional responsibilities include current membership onthe advisory board to the electronic privacy information center and onthe association for computing machinery public policy committee, andprior membership on the advisory committee to the computer, information sciences, and engineering directorate of the national science foundation (19982001), the board of directors of the council on library andinformation resources (19922000), and the international advisory boardto the soros foundation open society institute regional library program(19941997). she was program chair for the first joint conference on digital libraries (acm and ieee) in 2001 and continues to serve on programcommittees for the international conference on asian digital libraries,the joint conferences on digital libraries, and the european conferenceon digital libraries. other international activities include service as a visiting professor at loughborough university, u.k. (19962002), a scholarinresidence at the rockefeller foundation study and conference centerin bellagio, italy (1994), and as a fulbright visiting professor in budapest,hungary (1993). her most recent book, from gutenberg to the global information infrastructure: access to information in a networked world (mit press,2000), won the best information science book of the year award from theamerican society for information science and technology. she holds theph.d. in communication from stanford university, an m.l.s. from theuniversity of pittsburgh, and a b.a. in mathematics from michigan stateuniversity.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.380signposts in cyberspacetimothy casey is the executive director of the institute for innovation and informatics at the university of nevada, reno as of july 1, 2005.casey was a partner in fried, frank, harris, shriver, and jacobsonõs washington, d.c., and new york offices, where he was chair of the firmõs intellectual property and technology law department. casey has also beenan adjunct professor of law at american university, washington collegeof law, since 2003, where he has taught advanced patent law. caseyjoined fried frank in 2000 after serving as chief technology counsel, senior vice president, and assistant secretary for mci since 1995. in addition to managing the worldwide technology law and intellectual propertyoperations of mciõs predecessors worldcom and mci communicationscorporation, casey played a pivotal role in the development of the u.s.digital millennium copyright act (dmca) and the european unionõs ecommerce directive. casey was also an invited, but unpaid, advisor towipo leading up to the first wipo process and an informal mediatorbetween the parties negotiating the terms of the uniform domain namedispute resolution policy (udrp). he has been a udrp panelist and hasrendered over 28 decisions. casey was director of intellectual propertyfor silicon graphics from 1992 to 1995, divisional patent counsel for applecomputer from 1989 to 1992, and in private practice in california from1986 to 1989. casey received his j.d. from santa clara university schoolof law, where he was editorinchief of the computer & high technologylaw journal and where he was also an adjunct professor of law. he received his b.s. in electrical engineering from the university of nevada,reno. he is admitted to the bar in california and the district of columbiaand is registered to practice before the u.s. patent and trademark office.hugh dubberly is a principal in dubberly design office (ddo), asan franciscobased consultancy that focuses on making software easierto use through interaction design and information design. at apple computer in the late 1980s and early 1990s, dubberly managed crossfunctional design teams and later managed creative services for the entire company. while at apple, he cocreated a technologyforecast film calledòknowledge navigatoró that presaged the appearance of the internet in aportable digital device. intrigued by what the publishing industry wouldlook like on the internet, he next became director of interface design fortimes mirror. this led him to netscape, where he became vice presidentof design and managed groups responsible for the design, engineering,and production of netscapeõs web portal. in 2000, he cofounded ddo.in addition to his practice, dubberly also teaches. while at apple, he alsoserved at art center college of design in pasadena as the first and founding chair of the computer graphics department. he has also taught classesin the graphic design department at san jose state university, at the insignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.appendix a381stitute of design at iit, and in the computer science department atstanford university. he graduated from rhode island school of designwith a b.f.a. in graphic design and earned an m.f.a. in graphic designfrom yale university.patrik f•ltstr–m is a consulting engineer in the corporate development section of cisco systems. at cisco, f−ltstrım is involved withmany things touching applications, especially the domain name system,electronic mail, and internet telephony. previously, f−ltstrım was a technical specialist in the internet strategies and coordination group at tele2,systems manager at the royal institute of technology in stockholm, and aprogrammer in the swedish royal navy as well as at bunyip informationsystems in montr”al, canada. he has been working with unix since 1985and has been involved in internetrelated standardization since 1989, bothin sweden and worldwide. f−ltstrım also works with the internet engineering task force (ietf), was one of two area directors of the applications area between 1998 and 2003, and is the author of several rfcs.among those are rfcs on how to send apple macintosh files with email,on the whois++ directory service, on global indexing of textual data, onenum (the telephone number mapping protocol) on uniform resourcenames, and on internationalized domain names. since 2003 he has beena member of the internet architecture board and from september 2003also an appointed advisor to the it minister of sweden as a member of theswedish government it policy and strategy group. f−ltstrım holds anm.sc. degree in mathematics from the university of stockholm.perkristian (kris) halvorsen is vice president and director ofthe solutions and services research center (ssrc) at hewlettpackard(hp). the center creates and transfers technology for hpõs services andsolutions businesses and it houses hpõs research initiatives for developing markets. there are six research laboratories in the united states, theunited kingdom, and india. ssrcõs research focus is on software andsystems that enable secure, inter and intraenterprise collaboration, witha particular emphasis on trust, security, and content management. this iscomplemented by a new and growing activity aimed at bringing the benefits of information technology to large groups of people and enterprisesin developing countries through the discovery of new functionalities anddesign. prior to joining hp in 2000, halvorsen was the founding directorof the information sciences and technologies laboratory at xerox parc.under his direction, the lab became a leading center for research on thefundamental forces driving the evolution of the web and the internet. dr.halvorsen is an inventor on more than 10 patents, and he has publishedwidely in the areas of linguistics, natural language processing, and knowlsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.382signposts in cyberspaceedge management and information access. he holds a ph.d. in theoreticallinguistics and he received his education at the university of oslo, theuniversity texas at austin, and the massachusetts institute of technology. he has been a professor at the university of texas at austin and theuniversity of oslo, and a consulting professor at stanford university, aswell as a principal at the center for study of language and information atstanford. dr. halvorsen has been a member of the board of directors ofseveral technology companies (symantec, autodesk, finn and finntech),and a member of the national advisory board of the college of computer sciences at the university of arkansas.marylee jenkins is a partner at the law firm of arent fox, pllc andheads the firmõs new york intellectual property group. ms. jenkins specializes in intellectual property matters involving computers and theinternet and counsels an array of international companies on domainname disputes and domain name strategy and enforcement and management issues. she is the american bar association (aba) section of intellectual property lawõs representative to the intellectual property constituency of the internet corporation for assigned names and numbers(icann) and is also the sectionõs division chair on information technology. ms. jenkins has previously been a member of the sectionõs counciland is a former chairperson of the sectionõs special committee on trademarks and the internet. ms. jenkins is a member of the aba standingcommittee on technology and information systems (scotis) and is adomain name panelist to the world intellectual property organizationarbitration and mediation center. she is also a member of columbia university school of engineering and applied scienceõs engineering counciland a member of john marshall law schoolõs intellectual property lawadvisory board. she writes and lectures frequently on computer andinternetrelated intellectual property issues to legal, business, and governmental groups at conferences worldwide. she holds a b.s. in mechanical engineering from columbia university school of engineering andapplied science, a b.s. in physics from centre college of kentucky, and aj.d. from new york law school.john c. klensin is an independent consultant, focusing primarily oninternet standards, application protocols, and their implementations anddeployment. formerly, he was internet architecture vice president atat&t labs. he served as a member of the internet architecture boardfrom 1996 to 2002 and as its chair for the last 2 of those years and, beforethat, as area director for applications of the internet engineering taskforce (ietf), chair of its working group on electronic mail transport extensions, and in several other capacities. since 2004 he has served as liaisignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.appendix a383son from the ietf to the icann board, a position that gives him someinsight into icann internal processes but no obligations to, or benefitsfrom, icann itself. prior to joining at&t, he was distinguished engineering fellow at mci and then mci worldcom. outside his corporatecommitments, he has had significant responsibility for the present generation of internet applications standards, as well as standards work inother areas. he served as a member of ansiõs information systems standards board from 1986 to 2000 and was its vice chair for 2 years. hisinvolvement with what is now the internet began in 1969 and 1970, whenhe participated in the working group that created the file transfer protocol (ftp) and that made the decision to include electronic mail capabilityin the networkõs design. dr. klensin was on the permanent research staffat massachusetts institute of technology (mit) for about 25 years, participating in or directing a wide variety of projects, many of them involvingthe application or development of computer networking or related technologies to applied problems including measurement of mass media useand impact, taxation policy, automatic indexing of politically orientednatural language texts, management of statistical databases, statisticalcomputing, and urban development planning. dr. klensin has also beeninvolved with international development work with a united nationsuniversity project on food composition data, archives of images in islamicarchitecture, and the network startup resource center. dr. klensinserved on the cstb committee that produced the report the internetõscoming of age. he holds a ph.d. from mit in computer applications anduse in the social and policy sciences.milton l. mueller is professor and director of the graduate program in telecommunications and network management, syracuse university school of information studies. since 1982 he has conducted research on the political economy of telecommunications and information,including topics such as monopoly and competition in communicationindustries, internet trademarks and domain names, dns economics, radiofrequency allocation, and telecommunication industry reform in newzealand, china, and hong kong. two recent publications of import include the book ruling the root: internet governance and the taming ofcyberspace (mit press, 2002) and universal service: competition, interconnection, and monopoly in the making of the american telephone system (mitpress, 1997). his current research focuses on internet governance, civilsociety advocacy, and the impact of digital convergence on market structure. dr. mueller founded and directs the convergence center at syracuse university. he is a founder of the internet governance project, amultiuniversity consortium for research and policy analysis. he participates in the wsiscivil societyõs internet governance caucus. he is onsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.384signposts in cyberspacethe editorial boards of the scholarly journals the information society, telecommunications policy, and info: the journal of policy, regulation and strategyfor telecommunications, information and media. dr. mueller received theph.d. from the university of pennsylvania, annenberg school of communication, in 1989. dr. mueller was a founder of, and currently chairs,icannõs noncommercial users constituency, a part of the policymaking structure in icannõs generic names supporting organization. as amember of ncuc, he has shaped policy on the .org reassignment, whoisand privacy, and other issues. he served as a uniform domain namedispute resolution policy panelist for wipo from 2000 to 2003.sharon l. nelson is the senior assistant attorney general serving aschief of the consumer protection division of the washington state attorney generalõs office. from 2000 to 2003 she served as director of theshidler center for law, commerce, and technology at the university ofwashington school of law. previously, ms. nelson served two terms aschair of the washington utilities and transportation commission(wutc), from february 1985 to august 1997. prior to joining the wutc,she taught history and anthropology in secondary schools (19691973),served as staff counsel to the u.s. senate commerce committee (19761978), and served as legislative counsel to consumers union of the unitedstates (19781981). she has also been a lawyer in private practice (19821983) and served as staff coordinator for the washington statelegislatureõs joint select committee on telecommunications (19831985).ms. nelson received her b.a. from carleton college, an m.a.t. from theuniversity of chicago, and a j.d. from the university of washington. sheis the past president of the national association of regulatory utilitycommissioners (19891990). she currently serves as chair of the board ofdirectors for consumers union and sits on the board of trustees for thenorth american electric reliability council (nerc) and the board of directors of the itron corporation, and serves as a commissioner on the national energy policy commission (funded by the william and florahewlett foundation).craig partridge is a chief scientist at bbn technologies (an independent hightech research company), where he has led a variety ofinternetrelated research projects. recent major projects involved building and developing a method for tracing packet attacks across the internetand designing a highperformance encrypter. in the 1980s, dr. partridgedeveloped the rules for how systems use the dns to route email. dr. partridge is the pastchair of the association for computing machineryõs special interest group in data communication (one of the two major professional societies in data communications). he is the former editorinchiefsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.appendix a385of both acm computer communication review and ieee network magazineand a consulting editor for addisonwesleyõs professional computingseries. from 1992 to 2001, he was a consulting professor of computer science at stanford university and in 1991 was a research fellow at the swedish institute of computer science. partridge holds a.b., m.sc., and ph.d.degrees from harvard university. he is a fellow of the ieee and acm.william j. raduchel is the chair and ceo of ruckus network, adigital entertainment network for students at colleges and universitiesover the university network. he is a director of chordiant software andin2books and serves as chair of panellink cinema partners plc and asadviser to its parent company, silicon image. dr. raduchel is also an adviser to myriad international holdings, hyperspace communications,and wild tangent. through 2002 he was executive vice president andchief technology officer of aol time warner, inc., after earlier being senior vice president and chief technology officer of aol, where he alsoserved as a strategic adviser after leaving aol time warner. in 2001 hewas named cto of the year by infoworld. dr. raduchel joined aol inseptember 1999 from sun microsystems, inc., where he was chief strategyofficer and a member of its executive committee. in his 11 years at sun, healso served as chief information officer, chief financial officer, acting vicepresident of human resources, and vice president of corporate planningand development and oversaw relationships with the major japanese partners. he was recognized separately as cio of the year and as best cfo inthe computer industry. in addition, dr. raduchel has held senior executive roles at xerox corporation and mcgrawhill, inc. he is a member ofthe national advisory board for the salvation army (and chair of its committee on business administration), the conference of business economists, and the board on science, technology, and economic policy of thenational research council. he has several issued and pending patents.raduchel received his undergraduate degree in economics from michigan state university and earned his a.m. and ph.d. degrees in economicsat harvard university. in both the fall and spring of 2003 he was the castlelecturer on computer science at the u.s. military academy at west point.hal r. varian is a professor in the school of information management and systems at the university of california, berkeley. he is also aprofessor in the haas school of business and in the department of economics, and he holds the class of 1944 professorship. from 1995 to 2004,dr. varian served as dean of the school of information management andsystems. he has taught at the massachusetts institute of technology(mit), stanford university, oxford university, the university of michigan and other universities around the world. dr. varian is a fellow of thesignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.386signposts in cyberspaceguggenheim foundation, the econometric society, and the americanacademy of arts and sciences. he has served as coeditor of the americaneconomic review and is on the editorial boards of several journals. dr.varian has published numerous papers in economic theory, industrialorganization, financial economics, and econometrics and information economics. he is the author of two major economics textbooks, which havebeen translated into 11 languages. his recent work has been concernedwith the economics of information technology and the informationeconomy. he has been a consultant and advisor to several technologycompanies, including ibm and google. he is the coauthor of a bestselling book on business strategy, information rules: a strategic guide to thenetwork economy, and writes a monthly column on economics for the newyork times. he received his s.b. degree from mit in 1969 and his m.a.(mathematics) and ph.d. (economics) from the university of california,berkeley in 1973.staffalan s. inouye, study director (through december 2004), is the coordinator of the presidentõs information technology advisory committee(pitac), a federal advisory committee that provides advice to the president through the national science and technology council. from 1997through 2004, dr. inouye served as a study director at the national research councilõs computer science and telecommunications board(cstb). his completed cstb studies include beyond productivity: information technology, innovation, and creativity; lc21: a digital strategy for thelibrary of congress; the digital dilemma: intellectual property in the information age; and trust in cyberspace. in addition, dr. inouye served as thestaff liaison on projects in other units of the national academies, resulting in the completion of four reports: national automated highway systemresearch program: a review; advanced engineering environments: achievingthe vision, phase 1; advanced engineering environments: design in the newmillennium; and review of the u.s. department of defense air, space, andsupporting information systems science and technology program. prior to joining cstb, inouye completed a ph.d. from the school of information management and systems at the university of california, berkeley. in a previous life, dr. inouye worked in silicon valley as a programmer (ataricorporation), statistician and programmer/analyst (verbatim corporation), and manager of information systems (amdahl corporation). dr.inouye also completed other degreesñin information systems (m.s.), systems management (m.s.), business administration/finance (m.b.a.), liberal studies (b.s.), and mathematics (b.a.).signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.appendix a387charles n. brownstein is the director of the computer scienceand telecommunications board (cstb) of the national research council.he is also the study director for the project on improving cybersecurityresearch in the united states. he joined cstb in 2004 from the corporation for national research initiatives (cnri), where since 1994 he directedthe cross industry working team and did independent research withsupport from the national science foundation (nsf) and darpa. hisinterests are in innovation, applications, and impacts of information technology, internet performance, and the technologypolicy interface. dr.brownstein joined cnri in 1994 after a 20year career at nsf. there heserved in positions including program director for telecommunicationspolicy and it applications, division director for information science andtechnology, deputy assistant director and assistant director of nsf forcomputer and information science and engineering (cise), and directorof the office of planning and assessment. at nsf, he led in the creation ofcise, nurtured the development of nsfnet, and set strategic directionsfor federal information infrastructure. he was a principal in organizingthe interagency high performance computing and communications initiative, and he was executive director of the national science board special committee on the future of nsf. he presided over information technology and policy working groups at the organization for economiccooperation and development, was founding chair of the federal networking council, and participated on the board of regents of the national library of medicine. he organized and cochaired the white housenational performance review working group for reinventing government through information technology. he was a founding trustee of theinternet society, chaired the association for computing machinery public policy activity, usacm, and is currently a director of fortec, whichprovides the ietf secretariat. from 1971 to 1975, dr. brownstein taughtat lehigh university and was a founder of the institute of social and behavioral research. there he was a principal investigator on nsf and industrysupported research awards on telecommunications policy, information industry innovation, twoway cable field experimentation, andinteractive learning technologies. he also taught research design at theuniversity of michigan interuniversity consortium for social and political research. his ph.d. is in political science, from florida state university, 1971.margaret marsh huynh, senior program assistant, has been withthe computer science and telecommunications board since january 1999supporting several projects. she is currently supporting studies on wireless technology prospects and policy options, and biometrics. she previsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.388signposts in cyberspaceously worked on the studies that produced the reports getting up to speed:the future of supercomputing; beyond productivity: information technology,innovation, and creativity; it roadmap to a geospatial future; building aworkforce for the information economy; and the digital dilemma: intellectualproperty in the information age. ms. huynh also assisted with the projecton exploring information technology issues for the behavioral and socialsciences (digital divide and digital democracy). she assists on otherprojects as needed. prior to coming to cstb, ms. huynh worked as ameeting assistant at management for meetings (april 1998 through august 1998) and as a meeting assistant at the american society for civilengineers (september 1996 through april 1998). ms. huynh has a b.a.(1990) in liberal studies with minors in sociology and psychology fromsalisbury university, salisbury, maryland.kristen batch is a research associate with the computer science andtelecommunications board of the national research council. she is currently involved with projects focusing on wireless communication technologies, biometrics, and privacy in the information age. while pursuingan m.a. in international communications from american university, sheinterned at the national telecommunications and information administration, in the office of international affairs, and at the center for strategic and international studies, in the technology and public policy program. she also earned a b.a. from carnegie mellon university in literaryand cultural studies and spanish, and received two travel grants to conduct independent research in spain.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.389bspeakers at meetings andparticipants at site visitscommittee meetingapril 910, 2001national research councilwashington, d.c.j. beckwith burr, wilmer, cutler and pickeringaubrey bush, national science foundationalan davidson, center for democracy and technologymichael froomkin, university of miamim. stuart lynn, internet corporation for assigned names and numberssteven metalitz, copyright coalition on domain namesamy page, u.s. department of commerce, patent and trademark officedavid post, temple universitymichael roberts, formerly of the internet corporation for assignednames and numberskaren rose, u.s. department of commerce, nationaltelecommunications and information administrationshari steele, electronic frontier foundationrobert stoll, u.s. department of commerce, patent and trademarkofficegeorge strawn, national science foundationemerson tiller, university of texas, austinsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.390signposts in cyberspacecommittee meetingjuly 1113, 2001university of californiaschool of information management and systemsberkeley, californiayves arrouye, realnameskarl auerbach, internet corporation for assigned names and numberseric brewer, university of california, berkeley and inktomikc claffy, cooperative association for internet data analysis, san diegosupercomputer center, university of california, san diegoleslie daigle, verisign, inc. (by telephone)mark handley, at&t center for internet research, internationalcomputer science institute, university of california, berkeleymarti hearst, university of california, berkeleyjoe hellerstein, university of california, berkeleypaul hoffman, internet mail consortiumdavid lawrence, nominumclifford lynch, coalition for networked informationcarl malamud, nettopbox, inc.eric schmidt, novell and google, inc.keith teare, realnamestan tin wee, national university of singaporecommittee meetingnovember 56, 2001national research councilwashington, d.c.ari balogh, verisign global registryelana broitman, register.combrian kahin, university of marylandelliot noss, tucowssite visitnovember 7, 2001verisign and aol time warnerdulles, virginiamichael aisenberg, verisign, inc.ari balogh, verisign, inc.joe barrett, aol time warner, inc.leslie daigle, verisign, inc.signposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.appendix b391matt korn, aol time warner, inc.mark kosters, verisign, inc.geraldine macdonald, aol time warner, inc.michael mealing, verisign, inc.mark rippe, verisign, inc.ken silva, verisign, inc.site visitnovember 1215, 2001icann meetingmarina del rey, californiacarl bildt, ag global solutions and icann atlarge study committeepaul twomey, icann government advisory committeecommittee meetingjanuary 78, 2002beckman centerirvine, californiam. stuart lynn, internet corporation for assigned names and numberscommittee meetingfebruary 27march 2, 2002harvard universityjohn f. kennedy school of governmentcambridge, massachusettstim bernerslee, massachusetts institute of technology and worldwide web consortium (w3c)david d. clark, massachusetts institute of technologyfrancis gurry, world intellectual property organizationrichard hill, international telecommunication unionsignposts in cyberspace: the domain name system and internet navigationcopyright national academy of sciences. all rights reserved.