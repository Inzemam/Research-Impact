detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/1136computer assisted modeling: contributions of computationalapproaches to elucidating macromolecular structure andfunction186 pages | 6 x 9 | paperbackisbn 9780309062282 | doi 10.17226/1136committee on computerassisted modeling, national research councilcomputer assisted modeling: contributions of computational approaches to elucidating macromolecular structure...copyright national academy of sciences. all rights reserved.computerassistedmodelingcontributions of computational approaches toelucidating macromolecular structure and functioncommittee on computerassisted modelingboard on basic biologycommission on life sciencesnational research councilnational academy presswashington, d.c. 1987icomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.notice: the project that is the subject of this report was approved by the governing board of thenational research council, whose members are drawn from the councils of the national academyof sciences, the national academy of engineering, and the institute of medicine. the members ofthe committee responsible for the report were chosen for their special competences and with regardfor appropriate balance.this report has been reviewed by a group other than the authors according to proceduresapproved by a report review committee consisting of members of the national academy of sciences, the national academy of engineering, and the institute of medicine.the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific and engineering research, dedicated to the furtherance ofscience and technology and to their use for the general welfare. upon the authority of the chartergranted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientific and technical matters. dr. frank press is president of the nationalacademy of sciences.the national academy of engineering was established in 1964, under the charter of thenational academy of sciences, as a parallel organization of outstanding engineers. it is autonomousin its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineeringalso sponsors engineering programs aimed at meeting national needs, encourages education andresearch, and recognizes the superior achievements of engineers. dr. robert m. white is presidentof the national academy of engineering.the institute of medicine was established in 1970 by the national academy of sciences tosecure the services of eminent members of appropriate professions in the examination of policy matters pertaining to the health of the public. the institute acts under the responsibility given to thenational academy of sciences by its congressional charter to be an adviser to the federal government and, upon its own initiative, to identify issues of medical care, research, and education. dr.samuel o. thier is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 toassociate the broad community of science and technology with the academy's purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both thenational academy of sciences and the national academy of engineering in providing services tothe government, the public, and the scientific and engineering communities. the council is administered jointly by both academies and the institute of medicine. dr. frank press and dr. robert m.white are chairman and vice chairman, respectively, of the national research council.this study by the board on basic biology was conducted under contract no. defgo186er60457 with the u.s. department of energy.copies of this report can be obtained from the national academy press , 2101 constitution avenue,n.w. ,washington, dc 20418 , for $3.00 per copy prepaid. supplies are limited.printed in the united states of americacover: connollyrichards solventaccessible surfaces of trypsin, thymidylate synthase, and carbonic anhydrase. coordinates from the protein data bank, brookhaven national laboratory, and r.stroud, university of california/san francisco. photographs taken by r. desjarlais and b. shoichet,university of california/san francisco, using the facilities of the computer graphics laboratory.iicomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.committee on computerassisted modelingirwin d. kuntz (chairman), university of california, san franciscodavid r. davies, national institutes of health, bethesda, marylandrichard e. dickerson, university of california, los angelesrussell f. doolittle, university of california, san diegorichard j. feldmann, national institutes of health, bethesda, marylandjan hermans, university of north carolina, chapel hillyvonne c. martin, abbott laboratories, abbott park, illinoisjames h. prestegard, yale university, new haven, connecticutpeter j. rossky, university of texas, austinharold a. scheraga, cornell university, ithaca, new yorkdennis h. smith, molecular design ltd., san leandro, californiacharles c. sweeley, michigan state university, east lansingignacio tinoco, university of california, berkeleywalter g. rosen, senior program officersusan walton, editorlinda miller poore, senior secretaryiiicomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.board on basic biologyfrancisco j. ayala (chairman), university of california, davisnina v. fedoroff, carnegie institution of washington, baltimore, marylandtimothy h. goldsmith, yale university, new haven, connecticutralph w. f. hardy, cornell university, ithaca, new yorkernest g. jaworski, monsanto company, st. louis, missourisimon a. levin, cornell university, ithaca, new yorkharold a. mooney, stanford university, stanford, californiaharold j. morowitz, yale university, new haven, connecticutwilliam e. paul, national institutes of health, bethesda, marylanddavid d. sabatini, new york university, new york citymalcolm s. steinberg, princeton university, princeton, new jerseyjoseph e. varner, washington university, st. louis, missouridavid b. wake, university of california, berkeleyjohn e. dowling (exofficio), harvard university, cambridge,massachusettsjohn e. burris, directorivcomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.commission on life sciencesjohn e. dowling (chairman), harvard university, cambridge,massachusettsperry l. adkisson, the texas a&m university system, college stationfrancisco j. ayala, university of california, davisj. michael bishop, the g.w. hooper research foundation, san francisco,californianina v. fedoroff, carnegie institution of washington, baltimore, marylandtimothy h. goldsmith, yale university, new haven, connecticutrichard w. hanson, case western reserve university school ofmedicine, cleveland, ohioralph w. f. hardy, cornell university, ithaca, new yorkrichard j. havel, university of california, san francisco, school ofmedicinedonald f. hornig, harvard school of public health, boston, massachusettsernest g. jaworski, monsanto company, st. louis, missourisimon a. levin, cornell university, ithaca, new yorkfranklin m. loew, school of veterinary medicine, tufts university,north grafton, massachusettsrobert w. mann, massachusetts institute of technology, cambridge,massachusettsharold a. mooney, stanford university, stanford, californiajoseph e. rall, national institutes of health, bethesda, marylandrichard d. remington, university of iowa, iowa cityrichard b. setlow, brookhaven national laboratory, upton, new yorkjoseph e. varner, washington university, st. louis, missourialvin g. lazen, executive directorvcomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.vicomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.prefacethe committee, asked to provide an assessment of computerassistedmodeling of molecular structure, has highlighted the signal successes and thesignificant limitations for a broad panoply of technologies and has projectedplausible paths of development over the next decade.as with any assessment of such scope, differing opinions about present orfuture prospects were expressed. the conclusions and recommendations,however, represent a consensus of our views of the present status ofcomputational efforts in this field.the committee's task was made easier by colleagues who generouslyprovided us with the benefit of their expertise. we wish particularly to thankpeter goodford, william jorgensen, and andrew mccammon.the committee is indebted to the excellent national research council staffwhose work greatly expedited the production of this report. special thanks aredue to linda poore, susan walton, and, particularly, to walter rosen forunfailing help and guidance.irwin d. kuntzchairmanprefaceviicomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.prefaceviiicomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.contents1. executive summary 12. introduction 183. primary structure of proteins and nucleic acids 23 protein sequences and data bases, 23 pattern based comparisons, 284. secondary structure of proteins and nucleic acids 32 proteins, 32 nucleic acids, 365. tertiary structure of proteins and nucleic acids: experimental 41 xray diffraction of biological macromolecules, 41 computerassisted modeling in dna structure analysis, 44 using nuclear magnetic resonance to determine tertiary structures, 57 areas of potential impact of nmr, 62 demand on computational facilities, 666. tertiary structure of proteins and nucleic acids: theory 69 energy optimization, 69 molecular dynamics, 77 results, 79contentsixcomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved. solvation and electrostatics in computer simulation ofbiopolymers, 88 heuristic methods, 99 hierarchical models of protein folding, 102 pattern recognition and artificial intelligence, 1037. functional aspects of proteins and nucleic acids 106 catalysis, 106 designing new protein structures, 108 predicting function from a predicted threedimensional structure, 1148. structure and function of complex carbohydrates 131 biological function, 131 biosynthesis of nlinked glycoproteins and glycosphingolipids, 133 analysis of primary and tertiary structure, 137 xray analysis of crystal structures of carbohydrates, 138 nmr solution structures of carbohydrates, 140 supramolecular structure, 1429. hardware 144 central versus distributed computing, 149 computer utilization in the next 5 to 10 years, 149 the national supercomputer network, 150 local area networks, 151 data base use, 151 competitiveness, 15210. conclusions and recommendations 154 conclusions, 154 recommendations, 157 references 160contentsxcomputer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.1.executive summaryin much of biology, the search for understanding the relation betweenstructure and function is now taking place at the macromolecular level.proteins, nucleic acids, and polysaccharides are macromoleculesšpolymersformed from families of simpler subunits. because of their size and complexity,the polymers are capable of both inter and intramolecular interactions. theseinteractions confer upon the polymers distinctive threedimensional shapes.these tertiary configurations, in turn, determine the function of themacromolecule.a molecular view of biological function has already led to significantadvances. the conceptual breakthrough that led to our present mastery ofgenetic control of protein synthesis was the discovery that the nucleotidesequence in nucleic acids codes for the amino acid sequence of the proteinbeing synthesized. the rosetta stone of molecular genetics was the elucidationof the actual code, whereby the sequence of trimers (codons) in the nucleic acidcan be translated to the sequence of amino acids in the protein.amino acid sequences in proteins can be determined directly throughchemical analysis or indirectly by determining the base sequence in the parentdna. these two methods have been used to describe the primary structures(amino acid sequences) of substantial numbers of proteins. but to understandthe function of aexecutive summary1computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.protein, we need to know more than its primary structure. except, perhaps, forsome structural elements, proteins are not found in nature as simple chains ofamino acids. in their biologically active form, they are folded upon themselves,forming complex threedimensional structures. their shape determines theirbiological activity.currently, determining the threedimensional structure of macromoleculesdepends on the interplay of various experimental and theoretical approaches,particularly xray diffraction and twodimensional nuclear magnetic resonance(nmr), all of which involve the use of computers. at their most fundamentallevel, computers simply function to solve mathematical equations at very highspeeds. their speed makes it possible to accomplish in fractions of a secondtasks that would take a human orders of magnitude longer, even with theassistance of mechanical calculators. computers are also used to generategraphic representations of the three.dimensional structures of molecules,thereby aiding comprehension and largely eliminating the need to constructphysical modelsšanother laborious and timeconsuming process. thesegraphic representations provide an important stimulus to the development ofnew ideas about the way macromolecules function.computers have become so inextricably involved in empirical studies ofthreedimensional macromolecular structure that mathematical modeling, ortheory, and experimental approaches are interrelated aspects of a singleenterprise. the experimental methods, such as xray crystallography, nmrspectroscopy, and mass spectrometry provide the data with which to construct amathematical model that can account for the electron density distributions, bondangles, bond energies, and other observed structural properties of the molecule.conversely, the mathematical model must generate a structure that agrees withthe experimental data. the interplay between the two is continual; theoreticalmodels are modified repeatedly to improve their fit with experimental data, andtheoretical results help in the interpretation and planning of experiments.the potential practical applications of these techniques are myriad. whencan the payoff be expected? what are the anticipated needs in terms ofhardware, software, and human resources? to what extent should the effort becentralized? is present funding adequate or should it be increased?the task of the committee was to examine these questionsexecutive summary2computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.as they relate to two major realms of theoretical molecular biology. the first isthe prediction of tertiary structure from primary structure and other physical/chemical data. the second is the prediction of biological activity from tertiarystructure and related data and theory.proteinsprimary structuremore than 5,000 protein amino acid sequences have been reported, most ofwhich were inferred from the dna sequences that encode them. although thecollection is redundant (same protein from different species) and definitelybiased (many human and few plant sequences, for example), several patternsstand out. the most prominent is that the number of different types of protein isnot endless. it is clear that most proteins belong to identifiable families, easilyrecognized by their amino acid sequences alone. but surprisingly, the samefamilies of protein primary structures are showing up in proteins in quitedifferent settings.at this point it is not possible to determine, with accuracy, a threedimensional structure of a protein using only the amino acid sequence.however, recognition of patterns in structuresequence correlations holds greatpromise in this area.predicting secondary structure from amino acid sequencesthe methods used to predict secondary structure from amino acidsequences have been (1) calculation of the energies of the major conformers fora given sequence, (2) statistical analysis of known structures, and (3) modeling.although these methods have had some success and should continue to improvewith an increasing data base, they have limited accuracy.it is now computationally feasible to calculate energies for conformationsof short peptides with or without solvent. the nearterm developments in thisarea are most likely to be incremental improvements. computer speed willcontinue to increase substantially. data bases will continue to grow at leastlinearly. experiments on the structural consequences of modifying amino acidsare beginning to be reported in significant numbers. more powerful statisticaland modeling efforts are under development.executive summary3computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the situation is less positive for larger peptides and proteins. after 10years, however, we might well see major improvements in our ability tocorrelate sequences and secondary structure. today's goal of correctlypredicting every major feature in a new sequence is a plausible target for thattime. however, we will need a major conceptual or computational breakthroughbefore it will be possible to specify accurately the secondary structuralconfiguration of each amino acid in a protein.deriving threedimensional structure and function fromhomologymethods for identifying homologies and for determining sequencealignments and homologies are powerful tools to relate the structures and,potentially, the functions of two or more biopolymers. the analyses of patternsin sequences is a problem in symbolic, not numeric, computation. languagesthat support symbol manipulation and pattern matching primitives such as cand lisp are often the languages of choice.many of the techniques used to infer higher order structural information inpatternsšsuch as secondary structural analysisšare empirical. sequencebasedmethods alone do not take full advantage of the information available in theprimary structures of biopolymers. for example, different nucleotide patternsmay code for the same protein sequence; different protein sequences may sharevery similar function.predicting nucleic acid structures from sequencecomputer programs used to predict rna conformation from sequencehave a limited goal and limited success. the goal is to calculate secondarystructure onlyšto specify which bases are paired. the procedure usesexperimental thermodynamic data on doublestrand formation in synthetic rnaoligonucleotides. a dynamic programming algorithm considers all possiblebase pairs in the rna and calculates the free energies of the correspondingstructures. the free energy of a structure is assumed to be the sum of freeenergies of its constituent substructures (singlestranded regions, doublestranded regions, bulges, hairpin loops, and interior loops). the lowest freeenergy structure is the predicted secondary structure.executive summary4computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.computer programs of the future will require much more detailedknowledge of thermodynamics of local regions of an rna molecule. theextensive thermodynamic data needed to predict secondary structure correctlywill most likely come from computer interpolation and extrapolation of limiteddata measured on synthetic oligonucleotides in a few solvents.proposals of methods to fold possible secondary structures into threedimensional structures and calculate their energies are in very early stages.prediction of secondary structures in rna is at about the same stage as it is inproteins. however, prediction of tertiary structure in rna is far behind similarprediction in proteins.rapid and efficient progress in this area will require: effective methods for crystallizing rna oligonucleotides and naturallyoccurring rna molecules other than transfer rna; nmr methods that can provide conformations for rna molecules thatcontain from 10 to 100 nucleotides; computer programs that can reproduce and extrapolate theexperimental results.the higher charge densities in nucleic acids (one per nucleotide) requirespecial care in the correct treatment of solvent and ionic effects in the computerprograms.tertiary structure from xray crystallographytoday, several hundred proteins have been analyzed by xray diffractionand their threedimensional structures catalogued, and their number is growingsubstantially. this knowledge of molecular structure, together with the aminoacid and gene sequence data, enable us to study the mechanisms of action ofthese proteins at the molecular level. twodimensional nmr techniques are avaluable complement to xray diffraction for relatively small molecules(molecular weight less than 10,000), but for the foreseeable future, crystalstructure analysis will be the principal experimental source of structural data forenzymes, nucleic acid binding proteins, antibodies, and other proteins involvedin the immune response or intercellular communication.determining the threedimensional structure of a biologicalexecutive summary5computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.macromolecule involves several clearly defined steps. first, crystals of suitablesize and diffraction properties must be prepared. next, xray diffraction datamust be collected for these crystals and also, typically, for some heavy atomderivatives of the crystals. these data can then be assembled by acomputational process that yields an electron density map. this map must nowbe fitted with a polypeptide chain of the appropriate amino acid sequence.because the map is of lessthanatomic resolution and because it also containserrors in the phase determination, considerable skill is required to obtain thebest fit. the resulting protein model must then be refined to remove as many aspossible of the errors present in the map as well as those introduced by thefitting process. computers play an essential role in most of these steps.the availability of new instrumentation that allows crystallographers toproduce in a few days data that previously took weeks or months of laborintensive work is revolutionizing protein crystallography at an opportune time.in recent years, developments in genetic engineering have made it possible toproduce large quantities of rare proteins and to use sitedirected mutagenesis toanswer structural questions.xray diffraction experiments have provided structures for doublestrandeddna, proteindna complexes, and dnasmall molecule compounds incrystals. computer modeling is needed to extrapolate these results to morebiological environments and to other complexes. an obvious application ofsuch insight is to design more specific and more effective antibiotics. ingeneral, we would like to be able to design molecules that can start or stop theexpression of any gene in any dna. the key to achieving this is computerassisted calculation used in close collaboration with experimental observation.nuclear magnetic resonancenmr is another important source for structural data, and its use isdeveloping very rapidly. nmr results can be compared directly with theoretical(mathematical) modeling and with structures derived from xraycrystallography. nmr has been applied to macromolecules in aqueous mediaand to a limited extent in other environments, such as those that approximatebiological membranes. it is at its best when used to explore changes in preferredstructure in response to environmental or structural perturbations.executive summary6computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.in this sense, nmr can be important in extrapolating to other environmentsstructural data obtained by other techniques. it also is well suited to exploringchanges in structure when comparing homologous series of macromolecules,such as a series produced by sitespecific mutagenesis.more recently, technological advances have extended the applicability ofnmr to solids, oriented phases, and even to total structure determination ofmolecules in solution. the latter use has attracted the most attention andcurrently has the greatest potential to affect computerassisted modeling efforts.the major limitation on the use of nmr methods to determine structure isthe restriction on molecular weight. current applications require proteins ofmw 10,000 and less. a second limitation stems from the restricted range ofmeasurable distances, less than 4å. a third limitation arises because ofunderlying assumptions about the rigidity of macromolecules. all theselimitations are likely to be overcome in time, but doing so will require advancesin nmr methodology and computational capacity.improved computational and molecular modeling facilities could promotethe use of nmr to determine structure in several ways. processing andanalyzing structural data for macromolecules of mw 10,000 is far more timeconsuming than is ac quiring the data. each phase of this operation could beimproved. data are normally collected as a twodimensional time domain set,and processing involves fourier transformation to a frequency do main set.these processes are now handled by array processors associated withinstrument computers, with a moderate investment in time (one hour perprocess). however, alternative methods of processing, including lineardecomposition and maximum entropy methods, may be better in terms of thesignaltonoise ratio and may be more compatible with automating the analysis.such methods take far more computer time and may become practical only onsupercomputers.some efforts are underway to use semiautomated pattern recognition andexpert system strategies to determine threedimensional structure, but these willrequire substantial investments in programming and computer hardware.an investment in programming is obviously warranted. this investmentcould be used best if we acknowledge that, in the future, we may need toaccommodate types of data not used today. some data may come from otherstructural methods applicable toexecutive summary7computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.solids and oriented specimens. other data may come from entirely differentmethods, such as tunneling microscopy. thus, programs need not be directedspecifically for use with nmr data, but should, if possible, accommodatestructural data from a variety of sources.in summary, current nmr methods of determining structure are applicableto a variety of biologically important molecules that are less than mw 10,000.data production in this size range will be greatly enhanced by bettercomputational facilities, high field spectrometers, and modeling programs thataim for compatibility with experimental constraints of the form provided bynmr. nmr data should be meshed with data gathered through other methodsof determining structure. the range of molecules accessible by these methods islikely to increase by a factor of two over the next five years. the rate of dataproduction is likely to increase even more quickly as we improve structuredetermination protocols and as highfield spectrometers become more generallyavailable.tertiary structure from theoryenergy optimizationaccording to the thermodynamic hypothesis, the amino acid sequence of aprotein determines its threedimensional structure in a given medium as thethermodynamically most stable structure.to identify this structure requires some kind of optimization strategy,which, in turn, requires procedures to generate arbitrary threedimensionalconformations of a polypeptide chain, compute the free energy of the system foreach conformation, and then alter the conformation so that it ultimatelycorresponds to the global minimum of the free energy.although algorithms are available for minimizing an energy function ofmany variables, there are no efficient ones to use for passing from one localminimum, over a potential energy barrier, to the next local minimumšandultimately to the global minimum in a manydimensional surface. thus,minimization leads to the nearest local minimum, where the procedure istrapped. this trapping in a local, rather than the global, minimum is referred toas the ﬁmultipleminima problem.ﬂ a variety of procedures areexecutive summary8computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.being developed to overcome this problem, including approximations thatinitially place the system in a broad potential energy well in which the moresharply defined global minimum lies.although supercomputers will more adequately cover conformationalspace, workers in this field will need more time on these machines to achievegreater efficiency. parallel processing offers a breakthrough, but will requirethat more software be developed to take advantage of the new hardware. withnew hardware and software, it should be possible to surmount the major hurdlecreated by the multipleminima problem. however, bottlenecks may develop asattempts are made to apply procedures that work on 20residue segments toproteins containing 100 to 200 residues.homologyproteins can be categorized by families. evidence for this comes fromprotein sequence homology and from the architectural similarity in tertiarystructures of homologous proteins as established by xray and nmr methods. afamily of proteins can be modeled if several conditions are fulfilled. first andmost important, the structure of at least one member of the family must beknown. second, the protein to be modeled must be sufficiently homologous tothe known protein. many proteins have been modeled over the past five years,and the general consensus is that if two proteins share at least 30 percentsimilarity, it is reasonable to use computer graphics and energy modeling topropose the unknown structure from the known.molecular dynamicsmolecular dynamics simulations apply newton's equations of motion tothe atoms of one or several molecules. newton's equations relate threeindependent quantities: time, conformation (threedimensional atomiccoordinates), and potential energy.molecular dynamics simulation allows us to estimate theoretical meanatomic positions and deviations from the mean; rates of motion andconformation change; and ensemble averages, including thermodynamicfunctions such as energy, enthalpy, specific heat, and free energy. althoughsimple in concept, molecular dynamics simulations were not practical until theadvent of highspeed computers. the time is approaching when molecularexecutive summary9computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.dynamics calculations will produce useful predictions of the structure,dynamics, and thermodynamics of proteins, nucleic acids, and complexes ofthese macromolecules with one another and other molecules.the simulation requires two initial pieces of information: a startingconformation and a potential energy function or forcefield. for a protein, thestarting conformation must be firmly based on experimental observation. theforcefield is often identical to that used in molecular mechanics.the forcefield is a very simple empirical approximation of the underlyingphysics, which properly should be expressed in terms of quantum mechanics,but is totally unmanageable in that form. parameters of the forcefields currentlyin use have been proposed on the basis of various experimental data and, tosome extent, on theoretical considerations.recently developed forcefields for waterwater and waterproteininteractions permit the simulation of the dynamics of proteins in solution. thiscapacity is a prerequisite for modeling events at the protein surface, includingmost interactions of proteins with other molecules.the simulations of molecular dynamics of proteins require carefuladjustment of starting configurations and simulation parameters. the limitingfactor is always the available computing power. for example, calculation ofmolecular dynamics simulations of the motion of a protein over a 109secondtime interval takes roughly a month of computer time on a cray. makingadditional computer time available to those working in the field will help in thedevelopment/application of more detailed forcefields, produce longersimulations, encourage the simulation of larger systems that pose new physicaland biological questions, and promote the application of new, more timeconsuming dynamics methods to be used to ask different questions about thesystem.molecular dynamics simulations show considerable promise of being ableto more accurately depict the structures that are proposed on the basis ofincomplete information, particularly from twodimensional nmr. suchreiterations are thought to be the best method of investigating the atomic detailsof macromolecular motion.executive summary10computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.thermodynamicsphysicists have known, in principle, how to calculate equilibriumthermodynamic properties from molecular dynamics calculations forconsiderable time. only very recently have these techniques been applied toproteins, but their use has already shifted the emphasis of the moleculardynamics simulation field to calculations of freeenergy differences. severalfactors explain the great current interest in this application. the most importantare the magnitude and precision of available experimental data for a variety ofequilibriuminvolving biological macromolecules and the unexpectedlyexcellent theoretical estimates that were and still are produced by thesimulations.progress in freeenergy simulations, although potentially very rapid, isseverely limited by available computer time. to realize the possibilities alreadyidentified will require a radical increase of computer access for moleculardynamics studies. an immediate 10fold increase does not seem an extravagantobjective if we duplicate existing hardware that is already programmed andinexpensive.in contrast to the folding problem, the problem of computer modeling ofthe dynamics of protein interactions can be tackled in a series of small,increasingly complex steps, each of which solves a discrete problem ofimmediate biochemical interest, yet also adds to our insight and experience withthe broader picture.beyond the need for adequate computer time, two other needs must bemet. one is the need for better forcefields, particularly for nucleic acids andcarbohydrates; the second is the need for improved molecular dynamictechniques designed to overcome some of the intrinsic imperfections of existingforcefields. one possible impediment to this is the apparent trend toward thedevelopment and commercialization of proprietary forcefields much like thetrend toward proprietary software. this trend seems counter to the best interestsof science because it limits access and precludes rigorous testing of results.solvent effectsbiomolecular systems function in vivo in environments of aqueoussolutions or in a membrane. the aqueous environmentexecutive summary11computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.includes solvent as well as a substantial component that consists of various ions.because of the potentially relatively strong interactions of these componentswith each other and with the macromolecular species, this environment cancontribute substantially to the observed state of a macromolecule in solution.the membrane environment differs in that the charged groups and electricallyneutral regions are spatially separated. a quantitative treatment of biopolymerstructure and function cannot be expected to succeed unless we pay attention tothe molecular role of the environment.the ability to adequately test predictions made from theoreticalcalculations is an element of overriding importance in the future of this aspectof modeling. this can occur at two levels: first and most important incomparing theory and experiment and second in comparing results obtainedthrough convenient but approximate theory with those that follow from accuratetheoretical treatment. the first level is essential for accuracy and the second forthe future development of viable theoretical methods for increasingly complexsystems. therefore, we should continue to encourageboth experiment andtheory forboth macromolecular and smaller model compounds.the evident rapid progress in the ability to describe the environmentalaspects of biopolymer systems justifies our optimism that this element ofbiomolecular modeling will not impede development of useful predictivemethods. for the most challenging aspects, however, we are at least severalyears away from being able to accurately mimic environmental effects ofsolution.analysis and design of drugscentral questions regarding function include (1) which aspects of proteinstructure and dynamics are responsible for the often enormous enhancements ofrates of reaction of enzymes over the rates in water and (2) how the signal of thebinding of a ligand or quantum of light is transduced into a physiologicalresponse such as an increase in blood pressure or a change in mentalfunctioning. the questions are at best incompletely answered.in principle, the information needed to predict the function of a biologicalmacromolecule is encoded in its threedimensional structure. the problem ishow to decode the rules that govern the relationship between structure andfunction. the tools ofexecutive summary12computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.molecular dynamics promise to offer insight into this problem, but resourcesmust be made available.the prospect of computerassisted drug design based on the threedimensional structure of the target biomolecule has recently received muchattention in the scientific literature. many medicinal chemists believe that theirfield is poised to undergo a revolution as dramatic as that of the 1950s and1960s that transformed organic chemistry from a descriptive to a predictivescience.this revolution presupposes that we can (or soon will be able to) predictthe functions of macromolecules from their structure. in particular, this wouldrequire predicting whether a protein can recognize and bind a ligand andpredicting the structure of the optimum ligand. beyond that, however, we wouldneed to be able to predict how a protein recognizes and interacts with othermacromolecules to alter its own and their functions. these insights will be adirect consequence of the theoretical studies discussed in this report.the design of a new drug from theoretical principles must somehowincorporate the possible interaction of the proposed ligand with all othermacromolecules of the body. quantitative structure/activity relations (qsar)is a logical complement to the more structurebased computer methodologies.qsar is based on computing the activity of molecules from the properties andactivities of substituents. this tool can be used to model the potential wholeanimal activity of new ligands and perhaps to search for unanticipatedinteractions with other macromolecules.the recent interest in computerassisted drug design arose because at lastthe scientist has available the elements of each of the important tools needed forsuch an activity. two types of computer hardware are necessary: high speedcolor graphics and affordable but powerful minicomputers dedicated tomodeling. data on the threedimensional structure of proteins are becomingavailable at an increasing rate as we improve our understanding of some of therelationships between structure and function of proteins. finally, software isalso available for displaying the molecules and modeling the energetics andthermodynamics of the binding. equally important, specialized graphics toolsfor molecular design have been developed. some of these arose from the relatedactivity of ﬁdockingﬂ a known ligand into a protein.we must understand the relation between structure and function if we areto design agents that alter function by changingexecutive summary13computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.structure. ultimately, we expect to be able to predict the biotransformations ofsmall molecules from the structures of the enzymes involved, but we cannot doso now.complex carbohydratescomplex carbohydrates occur everywhere in animals, plants, and bacteria.the enzymes involved in glycoconjugate biosynthesis are glycosyltransferasesthat catalyze the transfer of sugar residues from the sugar nucleotides to thenonreducing end of a growing carbohydrate chain. the distinction between thisprocess and protein synthesis is key; the latter occurs on a template ofmessenger rna and is therefore determined by the genetic code for a singlestructural gene. in sharp contrast, glycoconjugate synthesis is accomplished byadding sugar units in a stepwise manner, with a different enzyme used for eachstep. the current state of knowledge does not indicate that a single dnasequence determines the primary structure of the complex carbohydrate.it is not yet possible to predict the primary structures of complexcarbohydrates from dna sequences, and the threedimensional structures ofglycoproteins, glycosphingolipids, and other complex carbohydratecontainingmolecules can never be completely predicted without analyzing the twodimensional structures of the carbohydrates. a complete understanding of theinteractions between carbohydrates and proteins (enzymes, lectins, antibodies,and cell surface receptors) will depend on the generation of accurate threedimensional structures of both kinds of molecules.of the three major classes of complex biological molecules, we have theleast information at the atomic level about the threedimensional structure ofcarbohydrates. because no large carbohydrates have been crystallized, we haveno data on relevant crystal structure, other than data on simple monomers totrimers, upon which to model classical or semiempirical quantum mechanicalcalculations. adequate computer time, including access to appropriate parallelprocessors is an important consideration in support of this research.configurations that consist of more than one macromolecule may interactas a whole in biological phenomena such as catalysis by many enzymes,binding at a cell surface, and signal transduction across cell membranes. hybridsystems involving complex carbohydrates, proteins and nucleic acids areimportant in proteinexecutive summary14computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.and nucleic acid synthesis, repair, and regulation. we believe it will be possiblein the near future to use structural methods to characterize at least parts of thesesystems. computer modeling of such supramolecular structures will benecessary if we are to gain a deeper understanding of how biological materialsare organized to carry out complex functional tasks.role of computerscomputers clearly play an essential role at virtually every stage and invirtually every process, theoretical and experimental, in determining the threedimensional structures and biological activity of macromolecules. bothpersonal and laboratory computers and large, mainframe computers are used.computerassisted mathematical (theoretical) modeling is augmented bycomputergenerated threedimensional graphic representations of molecules.modeling from theory is generally tightly coupled to experimental approachessuch as xray crystallography, nmr, and monomer sequencing. the interplayof theory and experiment results in the increasing refinement of the theorybased models, which in turn can be used to predict the behavior and propertiesof the actual molecules.availability of computer software and access to computer time andcomputerbased data banks are often the factors that limit the rate of progress instructural biology. the conclusion is inevitable that progress toward fullerunderstanding of macromolecular structure and function will be accelerated ifcomputerbased activities receive greater support. the computer facilities of thenational laboratories have the attributes required to lead in providing computerbased support for both theoretical and empirical approaches to understandingmacromolecular structure and function.progress in structural biology is likely to produce rapid advances inbiotechnology, drug design, toxicology, and medicine, along with advances inunderstanding of basic biological processes, including heredity and development.our recommendations for dealing with these issues are detailedinchapter 10and summarized in the following section.executive summary15computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.conclusionsthe conclusions we draw from our examination of the facts related to thequestions contained in our charge may be summarized as follows:important advances in the understanding of macromolecular structure andfunction have been and will continue to be gained from the application oftechniques using computers. to maximize the speed of progress toward a betterunderstanding of protein foldings, macromolecular interactions and functions,impediments and limitations to the effective study of these matters must beidentified and dealt with. the areas requiring attention include the need forreadily available data banks of protein and nucleic acid sequences as well asmodelderived structures; improved capability of and access to supercomputers;provisions of educational opportunities in the area; and use of the mostappropriate physical and intellectual resources for the performance of research.our recommendations for dealing with these issues are detailedinchapter 10and summarized in the following section.recommendations a radical new policy on data banking of protein and nucleic acidsequences is required. a permanent national sequence data bankshould be put in place as soon as possible. a standing advisorycommittee of users should be appointed by a consortium drawn fromthe national institutes of health (nih), national science foundation(nsf), and department of energy (doe). whether the new facilityshould be allied with a national laboratory, or with the nationallibrary of medicine, or should be a completely new academic orcommercial enterprise remains to be determined. support for the archiving of coordinate and modelderived structuresshould continue. inclusion of data from new methods of structuralanalysis should be encouraged. we recommend in the strongest terms expanding the supercomputerinitiative, funding of computer networks, improving access by thescientific community to the existing supercomputer centers at thenational laboratories, upgrading those centers, and providing individualresearch grants for purchasing new computers. doe should workclosely with the nsf and nih to provideexecutive summary16computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the broadest and most versatile computer network system on a nationallevel. educational opportunities in structural biology and molecular modelingshould be improved. several mechanisms are available, such asexpanding graduate programs through new training grants; increasedgraduate fellowship and postdoctoral fellow programs; workshops,including formal handson training programs in molecular dynamicsand molecular graphics; and working meetings of independentinvestigators to address critical limiting aspects of a particular problem. innovative and interdisciplinary research proposals in both theoreticaland experimental aspects of structural biology should be directlyencouraged through the use of existing funding mechanisms. we see a special role for the national laboratories. the nationallaboratories should compete for the national sequence data bank. thenational laboratories and doe have leadership status in the nationalcomputer network. they should increase efforts to makesupercomputers available to the scientific community. research effortsare going forward in molecular calculations and structural biology,with major programs at a few locations. strengthening these effortswill assist the department's office of health and environmentalresearch to assess the potential health and environmental effects ofchemicals involved in energy processes.executive summary17computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.2.introductionlife depends on the orderly flow of information among biologicalmacromolecules. information is primarily stored as a linear code in nucleicacids. in general, there is a onetoone correspondence between the amino acidsequence specified by the dna code and that actually found in the protein.processing, however, of the dna itself, the transcribed rna, or the translatedprotein frequently obscures this correspondence and makes it mandatory toverify the amino acid sequence directly. the amino acid sequence establisheswhat is called the ﬁprimary structureﬂ of a protein. to be biologically active, theamino acids must be folded into a convoluted threedimensional structure.there is some debate over the extent to which the final tertiary structure of aprotein is governed solely by its primary sequence. the most widespread viewfollows from experiments by anfinsen et al. (1961) who showed that bovinepancreatic ribonuclease regained activity from a denatured state without theinvolvement of any other macromolecule.today, it is generally accepted that all proteins of low molecular weightcan refold spontaneously. the question remains, then, of whether large proteinsuse ribosomes or other cellular materials to fold by a kinetically drivenmechanism. thus, two important questions must be considered. first, how is theprotein tertiary structure encoded in the linear sequence of amino acids? second,introduction18computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.is there a set of signals that controls the kinetic process of protein folding? also,it is becoming increasingly obvious that the cell employs additional codes tosignal for protein transport, protein destruction, carbohydrate structure, cellcellrecognition, hormone function, and the like. one place to begin deciphering allthese messages that are so directly tied to the function of living cells is to gatherinformation about the molecular structures of the proteins and nucleic acids.pauling's elegant insights into the importance of hydrogen bonding werethe earliest quantitative ideas about the structure of proteins (pauling et al.,1951). the models that emerged of helices, sheets, and the structure of collagenstill form the basis of our understanding of fibrous proteins. fibrous proteins arecrucial elements in cellular architecture, but the chemistry of cellsšthemolecular synthesis and metabolism that are hallmarks of lifešis controlled byelaborate enzyme systems whose detailed structural principles remain poorlyunderstood. these proteins are often grouped together under the name ofﬁglobular proteinsﬂ because of their roughly spherical shape. in spite of thehundreds of xray studies of crystals of globular proteins (perutz, 1965; perutzet al., 1965) and important efforts at classification (levitt and chothia, 1976;rossmann and argos, 1977; richardson, 1981), the most useful model ofglobular proteins remains the fundamental analysis put forward by kauzmannin 1959.as kauzmann (1959) noted on thermodynamic grounds, the watersolubleglobular proteins are formed from a hydrophobic core and a hydrophilicexterior. in the ensuing years, this idea has been generalized in two ways. first,it is now apparent that globular proteins of more than 100 to 300 residues areconstructed from independent domains, each of which is built according to thekauzmann hypothesis (wetlaufer, 1973). second, membrane spanning proteinsappear to reflect similar thermodynamic principles. the hydrophobicenvironment of the core of the membrane causes the protein architecture toinvert, producing a hydrophobic surface anda charged or polar interior, oftenin the form of a membranespanning channel (henderson, 1979; stroud andfinermoore, 1985).despite the success of the hydrophobic core model, it has not led to atheory detailed enough to offer an atomic description of protein structure. thebasic difficulty is the amazing complexityintroduction19computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.of the atomic arrangements in these macromolecules. the threedimensionalstructure of globular proteins is governed by a balance of the oftencontradictory requirements of optimum hydrogen bonding, burial ofhydrophobic sidechains, and overall close packing. thus, their geometry isgoverned to a significant degree by tertiary interactions, rather than by thesimple hydrogen bonding that dominates the fibrous proteins and nucleic acidhelices.this complexity leaves us with what has frequently been called theﬁprotein folding problemﬂ: how to calculate the tertiary structure of a protein toa useful degree of accuracy from the amino acid sequence. this report willaddress protein structure calculations at some length. but we recognize thatthere are much broader concerns dealing with the structures of nucleic acids andcarbohydrate species. for example, for some years after the modeling efforts ofwatson and crick (1953), investigators took for granted the structure of nucleicacids. recently, there has been renewed interest in the range of structurespresented by double helical dna (e.g. a,b,z)(drew and dickerson, 1981); byrna secondary structures; by higherorder packing of these molecules intonucleosomes, chromosomes, and ribosomes; and by the specific interactions ofnucleic acids and proteins. as another example, the importance ofpostbiosynthetic modifications of all biological macromolecules is gainingincreasing attention. although the exact roles of phosphorylation, acetylation,methylation, and glycosylation are still being worked out, there is no doubt thatthese modifications frequently constitute the biologically active form ofproteins and nucleic acids in living cells. further, one must recognize thecritical influence of environment on threedimensional structure. the proteinsurroundings may be as simple as an aqueous electrolyte solution or as complexas macromolecular assemblies.another matter of concern is the actual pathway by which the proteinfolding takes place. in the cell, this pathway may be influenced or regulated bythe proximity of the ribosome itself, by chain cleavage, or by the timing of theaddition of carbohydrates or other chemical species. even in the test tube,refolding appears to be a complicated process.beyond these questions, the interplay of structure and function suggeststhat we should try to understand the properties of proteins and how tomanipulate them through the amino acid sequence. we should discourage fromthe start the view that a single structure exists for each protein. theconformational choices areintroduction20computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.numerous, even in the crystal state (smith et al., 1986a). further, most globularproteins are designed to provide organized internal motions (allosteric effects)as part of their functioning. thus, one expects major conformational flexibilityin many of these molecules. some of this flexibility can be seen as thermallyinduced fluctuations that can be easily accounted for with normal modeanalysis. other aspects of the conformational freedom are much more complexand can be examined with the tools of molecular dynamics and statisticalmechanics. in this report we will try to assess our understanding of all theseissues.it is almost impossible to overstate the importance of the protein foldingproblem to the elucidation of structurefunction relations. as a purelyintellectual exercise, it clearly displays the fascinating complexity of a firstclass scientific puzzle. but the spotlight of attention is directed at proteinstructural predictions for other reasons. the most impelling is the incrediblegrowth of knowledge in molecular genetics and protein engineering. newsequences are being reported worldwide at a rate of 1 every 10 minutes, whileprotein crystal structures are determined at a rate of 1 per month. thus,sequences are being generated between two and three orders of magnitudefaster than structures can be determined. even with dramatic improvements inthe technology of crystallography and magnetic resonance, the backlog ofsequence data will grow rapidly. further, the need to make rational plans formodification of protein properties is a major issue for all aspects of thebiotechnology industry. a thorough understanding of the growth anddevelopment of living organisms depends crucially on a molecular structuraland functional description. this understanding would certainly lead to arevolution in health care and a much firmer grip on the problems of chemicaltoxicity.how valuable is it to know the structure of a protein? clearly, models ofstructures have led to the design of pharmaceutical agents (goodford, 1984 andhol, 1986) and the engineering of specific properties such as improved stability(ultsch et al., 1985). we are at the very beginning of such activities. they willsurely become very important with time. a more difficult question is, what canbe done with incomplete or lower resolution structures? their present value isin organizing experimental data and planning new experiments (cohen et al.,1986b). they can also be refined against new xray or nuclear magneticresonance (nmr) data (e.g. fitzwater and scheraga, 1982; brunger et al.,1986a).introduction21computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.it is not yet clear if these approximate structures, by themselves, can be refinedsufficiently to compete with either crystallographic or nmr experiments for alluses. however, for the design of new pharmaceutical agents they are invaluableaids if an experimental structure is not available (e.g. plattner et al., 1986).figure 2 hierarchy of structural descriptions of biological macromolecules.in the broadest terms, the convergence of results from experiment andtheory yields useful models of protein and nucleic acid structure and function.given the very large number of sequences expected in the next two decades, weestimate that thousands of these will yield useful structural calculations.the body of this report is a review of computerassisted modeling ofmacromolecular structure and function. we have interpreted modeling in broadterms as the use of computers in molecular calculations of all kinds. theorganization of the report is illustrated infigure 21, which shows howinformation flows from primary sequence to secondary and tertiary structuremodels. the role of computers in experimental methods is summarized in thesection on tertiary structure. issues of modifying function and designing newmaterials are considered next, followed by a discussion of trends in computerhardware.introduction22computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.3.primary structure of proteins and nucleicacidsprotein sequences and data basesas of mid1987, more than 5,000 protein amino acid sequences had beenreported, most of which were inferred from the dna sequences that encodethem. although the collection is redundant (same protein from differentspecies) and definitely biased (many human and few plant sequences, forexample), several patterns nevertheless stand out. foremost among these is thatthe number of different types of protein is finite. it is becoming increasinglyclear that most of the proteins determined thus far belong to identifiablefamilies that are easily recognized by amino acid sequences alone. indeed, thechances are now better than even that a newly determined amino acid sequencefrom a eukaryotic organism will be found to resemble a previously enteredsequence.some of these families were anticipated (table 31) on the basis ofsimilarities in function and size. thus, globins were all known to bind heme andto have very similar properties. we knew about large numbers of kinases, serineproteases, and thiol proteases, for example, and scores of protease inhibitors. itis not surprising, either, that many dehydrogenases and reductases have relatedsequences or that all the atpases belong to a homologous set.primary structure of proteins and nucleic acids23computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.table 31. some wellestablished protein familiesaenzymes:serine proteasesdehydrogenasescarboxypeptidasesthiol proteasesreductasestranscarbamoylasesacid proteaseskinases atpasesphosphorylasesnonenzymes:globinscollagensimmunoglobulinscytochromeskeratinspolypeptide hormoneshistonescrystallinsglycopeptide hormonesproteaseinhibitorslipidbindingproteinsinterferonstoxinstransferrinst cell receptorsmhc antigensa in each group some members are known to have similar amino acid sequences.what is surprising is that the same kinds of protein structures are appearingin proteins in quite different settings. polypeptide hormone precursors havebeen found that are related to protease inhibitors, for example, and structuralproteins of the lens of the eye have been found to be related to regulatory agentscalled ﬁheat shockﬂ proteins (ignolia and craig, 1982). sometimes theconnections seem astonishing at first, but, upon reflection, they are veryreasonable. thus, the recently determined sequences of the betaadrenergicreceptor, which binds adrenaline and its derivatives, were found to be similar tothat of rhodopsin, the eye pigment protein that responds to stimulation by light.this was extraordinary (dixon et al., 1986), but not inexplicable, since theactivating signalsšadrenaline in the one case and light in the otheršboth canprovoke excitatory actions. subsequently, kubo et al. (1986) found that a thirdprotein, the muscarinic acetylcholine receptor, also belongs to this family.many proteins, then, came into being through a process of ﬁduplicate andmodify.ﬂ gene duplications (partial or complete,primary structure of proteins and nucleic acids24computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.as will be discussed further) lead to extra gene copies that suffer basesubstitutions in the usual way; the substitutions, in turn, lead to modifiedproteins. for most proteins, these replacements are established sufficientlyslowly that, even after a billion years or more of evolution along diverging linesof descent, it is possible to recognize common origins.more to the point for this report, an abundance of data show that threedimensional structures of proteins are better conserved during the course ofevolution than are their amino acid sequences. in this regard, a detailedcrystallographic study of a series of serine proteases led to the conclusion thatrecognizably similar threedimensional structures may endure as much as 10times longer than do distinguishably similar amino acid sequences, a naturalconsequence of the diverse ways in which amino acids may be arranged to yieldequivalent structures (james et al., 1978). as a result, it is reasonable to assumethat similar amino acid sequences give rise to similar threedimensionalstructures. this is obviously an important point because it is considerably easierto determine amino acid sequences (albeit using dna sequencing) than todetermine crystal structures.the current crystal structure censusin the next decade, the sequences of 50,000 proteins are likely to bedetermined. in the majority of cases, it should be possible to assign them toexisting families. the question then arises: for what fraction of those knownfamilies do we have crystal structures?the brookhaven protein data bank, which keeps data for all knownprotein structures, lists about 300 entries. like the sequence data banks,however, the brookhaven collection is heavily redundant and biased. theentries include many variations of the same proteins crystallized in differentsettings (14 entries for eggwhite lysozyme alone) and from different species.actually, only about 100 different protein structures have been determined, andof these, many belong to the same families, as do the dehydrogenases or theserine proteases. equally important, many known protein familiesštheinterferons, for examplešhave not yet had a single crystal structure determined.the situation is changing rapidly, however, and the prospects appear verygood for determining a truly representative set ofprimary structure of proteins and nucleic acids25computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.crystal structures. innovations in recombinant dna technology now allow theproduction of proteins in quantities sufficient for crystallization; previously,many of these proteins were available only in trace amounts. beyond that, newtechniques for crystallizing membrane proteins have opened an entirely newdimension (michel, 1982). in addition, modern techniques for rapid datacollection have revolutionized the entire field and hastened the processimmensely (xuong et al., 1978). finally, improved techniques for structuresolution and refinement have also accelerated this process.modeling on the basis of sequence aloneat present, it is not possible to generate, with any hope of accuracy, a threedimensional structure of a protein using only the amino acid sequence. opinionsdiffer widely as to whether a general solution to the ﬁfolding problemﬂ is nearand recent developments in the field are discussed elsewhere in this report.certainly cohen et al. (1986b) have shown that in special situations, much canbe predicted about a protein on the basis of its sequence, but the routineapplication of an allinclusive procedure is not yet in sight.it is possible, of course, to make computerassisted predictions aboutsecondary structure (chou and fasman, 1974), and although these methodshave a limited accuracy (kabsch and sander, 1983; nishikawa, 1983), they cannevertheless provide useful information when applied judiciously. predictionsabout protein structure can also be made with computer programs that assesshydropathy (kyte and doolittle, 1982). these have been especially successfulin predicting the membranespanning segments of membraneassociated proteins.existing data basesthe major data bases for sequences are the protein identification resource(pir) at the national biomedical research foundation, washington, d.c.;genbank, operated by bolt, beranek, and newman in cambridge,massachusetts; and embldata bank in heidelberg, germany (table 32).genbank and embl store only dna sequences, although recently, they havebegun to make available derived amino acid sequences. genbankprimary structure of proteins and nucleic acids26computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.and embl exchange data frequently as a way to enhance the data sets.currently, these two data bases together contain more than 15 million bases ofnucleic acid sequences.table 32. some sequence data banks and searching facilitiesprotein identification resourcegeorgetown university medical centernational biomedical research foundation3900 reservoir road, n.w.washington, d.c. 20007 u.s.a.genbank: genetic sequence databasecomputer & information science div.bbn laboratoreis, inc.10 moulton streetcambridge, ma 02238 u.s.a.embl data librarygraham cameron, data library managerpostfach 10 2209 meyerhofstrasse 16900 heidelberg, germanyuniversity of wisconsin genetics computer group (uwgcp)john devereuxuniversity of wisconsin biotechnology center1710 university avenuemadison, wi 53705 u.s.a.unite d'informatique scientifiquejeanmichel claverieinstitute pasteurparis, francebionet: national computer resource for molecular biologyintelligenetics, inc.124 university avenuepalo alto, ca 94301 u.s.a.prf amino acid sequence collectionyasuniko setopeptide institute, protein res. found.476 inaminon, osaka 562 japana although genbank and the embl data library primarily store dna sequences,translated versions of the data are available.all of the three major banks currently have backlogs of data awaitingentry. in the case of the pir, for example, most of the protein sequence data arestill typed in from the published literature. genbank and embl are trying tomake arrangementsprimary structure of proteins and nucleic acids27computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.with some key journals (nucleic acid researchis one) that will allow data to besubmitted to the data bases in various computer modes: diskettes, tapes, anddirect transmission.the logistic and policy problems associated with such data bases areenormous and many committees and societies are trying to establish anacceptable policy that will speed things up. at the same time, all indications arethat the generation of sequence data will increase exponentially in the next fewyears. clearly, we need a new, permanent, centralized data repository. ideally,this should be international; practically, it may be more readily attained at thenational level. this should be an institution at least as large as the nationallibrary of medicine. it could be located anywhere, although certainlyconsideration should be given to los alamos, which has already been heavilyinvolved in sequence banking with genbank. models for this center, whichmust be a constantly updated base and not merely a repository, include thenational bureau of standards or the coast and geodetic survey.in addition to these major sequence collections, some smaller enterprisesare operating, both in the united states and elsewhere (table 32). however, allof these appear to rely heavily on the pirgenbankembl collections as theirdata cores. finally, some beginning efforts are underway to create acarbohydrate structure bank.pattern based comparisonsmethods for determining sequence alignments and homologies represent apowerful set of tools for relating the structures and, potentially, the functions oftwo or more biopolymers. however, these homologies alone do not take fulladvantage of the information content of primary structures of biopolymers. forexample, different nucleotide patterns may code for the same protein sequence;different protein sequences may share a very similar function. often thedifferences at the level of primary sequence are substantial, and similarity offunction among sequences is lost when the sequences are compared byhomology. yet, if we can somehow relate the sequence of a new protein to thatof another protein whose structure and function are known, we can begin todetermine the structure of the new protein. how might we take advantage of amore general view of homology, and view sequencesprimary structure of proteins and nucleic acids28computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.as patterns in order to extract more structural information from them?figure 31 hierarchical relationship among patterns in biological sequences.if we consider the concept of a sequence as a string of characters, we canview the concept of a pattern as a string (or collection) of partial sequences.this view of primary amino acid sequences derives from our belief in ahierarchy of structural descriptions of proteins (see figure 21).if the only structural information we have about a protein is its sequence orprimary structure, we seek patterns in its sequence that will guide us to a betterunderstanding of the protein. patterns can be derived by examining thesecondary and tertiary structures of known proteins, and relating spatialinformation back to patterns in the primary structure. in essence, we attempt tomap what is known about spatial configurations into the onedimensional worldof sequences. this mapping itself can be done hierarchically, closely related tothe hierarchy shown above, as shown from the bottom up infigure 31.the scheme symbolized infigure 31represents the fact that a sequence canbe analyzed to determine patterns of partial sequences, illustrated by the boxedelements. the individual patternsp1 p4, for example, secondary structuralelements, may themselves be part of a larger patterns, such asp5, p6, whichprimary structure of proteins and nucleic acids29computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.may only be recognized after the abstraction top1 p4 is accomplished.p5andp6, for example, structural domains, may then be recognized as part of aneven larger pattern,p7, for example, the tertiary structure of a protein.the hierarchy offigure 31also represents a computational model forderiving secondary and tertiary structural information from the patternsthemselves. this computational model is described below.methodologythe concept of patterns is useful for expanding our view of the primarystructure of proteins only if we find some method for labeling the individualamino acids or partial sequences with properties other than identity. forexample, we can choose labelings related to physical, chemical, or functionalproperties of the amino acid. if we choose properties related to secondary orhigher order structure, we can encode higher order properties in the sequenceitself. labelings can be assigned to individual amino acid residues or to groupsof residues based on calculations over a partial sequence. typical propertiesincluded are: charges: plus, minus or neutral pk: acidic, basic, neutral; or specific value hydropathicity: a hydrophobicity or hydrophilicity value for oneresidue or calculated over a set of residues chemical similarity: several possible definitions tendency for replacement over evolutionary time secondary structure calculated over a group of residues (see below)some labelings are valuable for examining sequence homologies. forexample, one can examine similarities in the chemical properties of a sequenceby performing the homology search among sequences labeled with characters orflags that represent assignment to various chemical classes. if the evaluationfunction for rating the degree of homology is adjusted appropriately based onthe variety of the labels, or thealphabet, it is possible to find meaningfulhomologies among sequences with substantially different amino acidsequences. one example of the success of this approach is a method for findingprotein sequence homologies based on the tendency for replacement overevolutionary time ofprimary structure of proteins and nucleic acids30computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.one amino acid by another (dayhoff, 1978; lipman and pearson, 1985).software and hardware considerationsthe computer software and hardware needed to carry out the patternmatching operations on sequences contrast in interesting ways with thoserequired for the intense numerical calculations described in other sections ofthis report. first, the analyses of patterns in sequences is a problem in symbolic,not numeric, computation. for efficient program development and application,languages that support symbol manipulation and patternmatching primitivesare desirable; c and lisp are often the languages of choice. second, thealgorithms used are the result of years of development of dynamicprogramming techniques, recursion, and other methods that allow flexiblepattern detection and matching. mismatches, density matches, gaps, and otherirregularities are all characteristics of ﬁfuzzyﬂ patterns that must beaccommodated. third, many of the techniques used to infer higher orderstructural information in patterns, such as secondary structural analysis and theheuristic techniques described below, are highly empirical. these methods oftenhave a theoretical foundation or justification, but the actual inferences may bebased on statistics over data bases of known structures or on judgmental rulesbased on experience and analysis of patterns in known systems.the computer power needed for these symbolic computations is widelyavailable on several general purpose machines. however, as is true fornumerical computations, progress in symbol manipulation and pattern matchingcould be hampered by insufficient hardware. it is becoming more and moredifficult to explore complex patterns in large data bases because of thecomputer time required. thus, just as array processors and high performancegraphic devices are available to support numerical calculations and present theirresults, special purpose patternmatching hardware has been developed toemulate the necessary symbolic computations. this hardware contains thealgorithms required for symbol processing. it is often several orders ofmagnitude faster than the corresponding software.primary structure of proteins and nucleic acids31computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.4.secondary structure of proteins andnucleic acidsproteinsthe secondary structural features of proteins can be grouped into threebroad classes: helical features, extended strands, and turns or loops. the mostcommonly seen helices are the socalled alpha helices, which were firstdescribed by pauling and corey (pauling et al., 1951). minor forms include the310 and pi helices. beta structures are formed from hydrogen bonding betweenthe backbone amides of extended polypeptide strands. although such featuresare properly considered tertiary structure, they are often discussed as secondarystructure. they are named according to whether the strand pairs run parallel orantiparallel to each other (based on a vector drawn from the n to c termini ofthe feature) and whether the sheets are folded or rolled into a barrel(richardson, 1981). turns are much less regular (rose et al., 1985). they arecharacterized according to local geometric features.prediction of secondary structure has been of interest since the first proteinstructures were determined. accurate secondary structure prediction is onedirect approach to the development of a tertiary prediction algorithm.the methods used to predict secondary structure from amino acid sequencehave been (1) calculation of the energies of thesecondary structure of proteins and nucleic acids32computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.major conformers for a given sequence; (2) statistical analysis of knownstructures; and (3) modeling. it is now computationally feasible to calculateenergies for conformations of short peptides with or without solvent. however,this is not yet a definite method of predicting secondary structure in proteinsbecause the energy differences among conformers are relatively smallcompared to the interactions between the peptide and the rest of the protein andbecause of neglect of the solvent entropy terms.statistical methods began with the efforts of chou and fasman (1974),who characterized the preference of each amino acid found in each type ofsecondary structure. other early efforts focused on turns in proteins (kuntz,1972; lewis et al., 1971). robson (robson and osguthorpe, 1979; robson,1986) followed with more sophisticated approaches. these approaches give thegeneral impression that the statistical methods are easy to use but havesignificant random and systematic noise that limits their accuracy. for example,they ignore longrange effects (kabsch and sander, 1983) and prosthetic groups.modeling efforts have grown from the early observations of schiffer andedmundson (1967) that alpha helices in globular proteins often containhydrophobic and hydrophilic faces in agreement with the ideas of kauzmann(1959). many investigators followed this line of thought. thus, helicalpropensity has been identified with helical nets, from a fourier analysis of thehydrophobicity (eisenberg et al., 1984; finermoore and stroud, 1984), or frompatternmatching (cohen et al., 1986b). beta structures have been treated insimilar ways, although less successfully. turns are often associated with regionsof hydrophilicity.some labelings are valuable for detecting higher order structuralinformation. one of the most common methods used to explore this informationis secondary structure analysis. this analysis provides information on possiblepatterns of coils, sheets, and helices in a protein. other information can beextracted from the sequence by recognizing that certain combinations of aminoacids indicate turns or other structural features. alternative representations canbe used to determine patterns comprising amphiphilic betasheets or alpha orpihelices (kaiser and kézdy, 1984). often this information can be gathered byempirical, rulebased systems, described below. however it is determined, thisinformation can be used to build up a hierarchy of patterns. this hierarchy issecondary structure of proteins and nucleic acids33computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.indicated symbolically infigure 41, which is based on the general schemeshown infigure 31.figure 41 hierarchical relationship of a protein sequence to higher orderpatterns of organization, culminating in the tertiary structure of the proteinitself.according to this scheme, patterns of partial sequences can be recognizedas representing secondary structural elements. combinations of these elementsare recognized as higher order patterns that correspond to supersecondarystructures. these, in turn, may be recognized as patterns that make up a domain.if any portion of such a hierarchy is determined using only a sequence, thisrepresents a major step toward constructing an actual threedimensionalstructure for a protein. more frequently, this procedure is used with othercomputational techniques for examining combinations of patterns that may leadto recognizable structural motifs in three dimensions.the general method used to study these problems involves only a fewbasic steps. first, one or more techniques are used to make the first assignmentof structural features to patterns in a sequencešfor example, hypothesizedsecondary structural elements associated with specific partial sequences.second, the pattern or patterns obtained are compared to those derived fromknown structures or hypothesized by the investigator. third, if a match is found,the investigator proceeds to the next step of searching for patterns of the nexthighest order, which may be composedsecondary structure of proteins and nucleic acids34computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.of several different combinations of smaller patterns identified in the previousstep. if one can derive sufficient structural information, hypothetical threedimensional structures can be proposed. several examples have appearedrecently where this approach has been successfully applied to patternbasedelucidation of structural features of proteins of known and unknown structure(abarbanel, 1984, 1986; cohen et al., 1986; taylor and thornton, 1983).current status and future prospectsthe assignment of each amino acid in a protein sequence to a particularsecondary structure class has rarely been more than 70 percent accurate and isoften worse. some of the newer approaches increase accuracy by reducing thescope of the problem. for example, cohen et al. (1986a) describe proceduresfor the prediction of turns in subgroups of proteins. by tailoring algorithms totake advantage of the characteristics of, for example, allalpha domains, theaccuracy is improved to about 90 percent.in the near term, developments in this area are most likely to beincremental improvements. computer speed will surely continue to increasesubstantially. data bases will continue to grow at least linearly. experiments onthe structural consequences of modifying amino acids are beginning to bereported in significant numbers (ultsch et al., 1985; alber et al., 1987). morepowerful statistical and modeling efforts are under development. what is moreimportant, these approaches can be combined in useful ways. within five years,several laboratories should have set up unified programs that allow comp]exinquiries of structural data bases. automatic learning programs that extractsecondary structure features will also have been intensively studied.within 10 years, we may well see major improvements in our ability tocorrelate sequences and secondary structure. the current goal of correctlypredicting every major feature in a new sequence is a plausible target. accuratespecification of the secondary structural environment of each amino acid in aprotein is probably not attainable without a major conceptual or computationalbreakthrough.secondary structure of proteins and nucleic acids35computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.nucleic acidspredicting rna structurerna molecules are crucial to all stages of protein synthesis. messengerrna carries the code that specifies the amino acid sequence of the protein; thetransfer rna molecules translate the code word by word into protein; and theribosomal rnas in the ribosome provide part of the machinery to do thesynthesis. many animal and plant viruses that cause tremendous damage tohuman health and economic wellbeing are rna viruses. human disease rnaviruses include those for colds and influenza, aids, some cancers, andhepatitis. it would be very useful to be able to use only the sequence to predictthe folded threedimensional structure of any rna in any environment. thisstructure determines how stable an rna molecule will be in a biological cell,because the ability of the enzymes that hydrolyze rna (exo and endonucleases) to degrade a particular rna is very sensitive to rna conformation.also, each rna molecule requires the correct conformation in order to functionbiologically. the conformation, in turn, will depend on the environment ascharacterized by the type and concentration of ions, the presence of specificinteracting molecules and other variables.the computer programs now used to predict rna conformation fromsequence have limited goals and limited success (see, for example, zuker andsteigler, 1981). they were designed to calculate secondary structure onlyštospecify which bases are paired. the computerized procedure uses experimentalthermodynamic data on doublestrand formation in synthetic rnaoligonucleotides (freier et al., 1986). a dynamic programming algorithmconsiders all possible base pairs in the rnaša sequence of n nucleotides has n(n1)/2 possible base pairsšand calculates the free energies of thecorresponding structures. the free energy of a structure is assumed to be thesum of the free energies of its constituent substructures (tinoco et al., 1971),including singlestranded regions, doublestranded regions, bulges, hairpinloops, and interior loops. the lowest free energy structure is the predictedsecondary structure. the computer programs allow one to specify that any twobases are paired to each other or that anysecondary structure of proteins and nucleic acids36computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.base is unpaired. thus, other experimental data based on enzymatic digestionexperiments, chemical reactivity, or phylogenetic comparisons can beintroduced.clearly, the predicted results are only as good as the experimentalthermodynamic and other data used. for example, although all transfer rnasare thought to fold as clover leaves, present computer programs only calculateabout 90 percent clover leaves. also, the thermodynamic experiments have allbeen done in one standard solvent, so knowledge about other solvents is needed.finally, a limited number of oligonucleotides have been studied; they provideonly a very small sample of the structural elements present in natural rnamolecules. a much better understanding of the thermodynamics of possiblesubstructures in an rna is needed before an accurate and complete predictionof secondary structure is possible.the existing computer methods for calculating secondary structure in rnaare useful as aids in designing experiments to determine the actual secondarystructure. for example, a program can provide the calculated lowest free energystructure, as well as other significantly different low free energy structures(williams and tinoco, 1986). experiments are done to test some of thepredicted substructures, and their results are incorporated into the calculation ofthe next prediction. successive approximations thus lead to more correctlydetermined secondary structures (cech et al., 1983).computer methods of the future must be based on much more detailedknowledge of the thermodynamics of local regions of an rna molecule. theextensive thermodynamic data needed for correct prediction of secondarystructure will most likely come from computer interpolation and extrapolationof limited data measured on synthetic oligonucleotides in a few solvents. oncewe understand better the forces and energies involved in the interactions ofnucleotides with solvent, ions, and each other, it will become easier to calculatesecondary structures for large rna molecules. algorithms exist for calculatinglow free energy structures as a sum of substructure energies, so their use withrna of up to about 600 nucleotides requires only the appropriate data.however, for a rigorous search for structures, central processor (cpu) time andmemory requirements increase as the cube or fourth power of the number ofnucleotides. we estimate that a molecule of 3,000 nucleotides (typicalribosomal rnas or smallsecondary structure of proteins and nucleic acids37computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.viruses) would require about 40 hours of cpu time on a cray xmp and 2gigabytes of memory. parallel processing or equivalent improvements inhardware then become necessary.prediction of tertiary structure in rnašthe threedimension al structureof the rnašis much more difficult. levitt (1969) made an early attempt atpredicting the structure of transfer rna, but an algorithm to find the lowest freeenergy tertiary structure still does not exist. proposals of methods to foldpossible secondary structures into threedimensional structures and calculatetheir energies are in very early stages of development. prediction of secondarystructure in rna is about at the same stage as it is in proteins, but prediction oftertiary structure is far behind. novel methods are needed for rna that takeinto account either implicitly or explicitly: the long range electrostatic repulsion of phosphates shielded by counterions; the detailed conformation of hairpin, bulge, and interior loops; the hydrogen bonding between loops and singlestranded regions(pseudoknots); nonwatsoncrick base pairs and triple base interactions; and all the usual london vanderwaals interactions, including solvent.kollman and his associates at the university of california, san franciscohave made a beginning in this direction with the program amber (bash et al.,1987a). this program performs the molecular mechanics calculations ofenergies with parameters optimized for nucleic acids. other programs calculatedifferences in free energies caused by changes in conformations.the most useful computer modeling process would provide realtimecalculation of free energies as the folding of a macromolecule in a solvent wasshown on a computer graphics screen. achieving this will require greatimprovement in hardware and software. close collaboration withexperimentalists will be needed to ensure meaningful calculated results.rapid and efficient progress in this field will require: effective methods for crystallizing rna oligonucleotides and naturallyoccurring rna molecules. to date, transfer rna is the only rnamolecule whose xray structure has been determined.secondary structure of proteins and nucleic acids38computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved. nuclear magnetic resonance methods that can provide conformationsfor rna molecules that contain from 10 to 100 nucleotides. computer programs that can reproduce experimental results. the highcharge densities in nucleic acids (one per nucleotide) require specialcare in the correct treatment of solvent and ionic effects. oncecalculations can be done that provide known structures, we can placesome confidence on extrapolation to new structures.we have been stressing free energies (thermodynamics), but kinetics maybe just as important; equilibrium is never attained in a living system. rna isfolded as it is synthesized, so kinetic barriers may prevent it from reaching aglobal minimum. for some rna molecules, such as ribosomal rna, thedynamic movement from one conformation to another may be an important partof their function.we would like to be able to calculate and verify structures of rnamolecules and their interactions with a wide variety of molecules. in aribosome, for example, the ribosomal rna interacts with messenger rna andtransfer rnas, as well as all the proteins involved in protein synthesis. it wouldbe very useful to know how a change in any variable would affect the efficiencyand fidelity of protein synthesis. we want to be able to design efficientmessenger rnas to produce any protein desired. we need to develop models ofthe process of protein manufacture so that we can then improve theproductivity, cut the cost, and ensure high quality output of proteins. computermodeling and calculations should provide the sequences of the ribosomalrnas, the transfer rnas, and the messenger rnas that would be optimal forthe production of a particular protein. we are very far from this ideal.we need mathematical and dynamic structural models of how an rnavirus replicates, how reverse transcriptase copies the rna into dna, and howthe rna is packaged into its protein coat. with this knowledge, we will bemuch closer to finding ways to prevent or cure diseases caused by rna viruses,which include colds, influenza, aids, and hepatitis.rna is now known to have catalytic activity (zaug and cech, 1986). todate, it has been demonstrated that rna catalysis is involved in rnaprocessing and in glycogen synthesis. this catalytic activity of rna is neededfor the replication cycle ofsecondary structure of proteins and nucleic acids39computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.some viroids and virusoids (small infective rna particles) and the processingof some ribosomal rnas. fundamental advances in understanding this catalyticactivity require knowledge of the location and structure of the active site ofrna enzymes. computer calculations in conjunction with mutationexperiments may allow us to progress most rapidly.predicting dna structurealthough dna and rna are very similar, in practice, the importantproblems relating to their sequences and structures are usually different. dnastores all the genetic information that determines the organism and itscharacteristics. its sequence, conformation, and interactions with proteins, smallmolecules, and other dna molecules determine how and when the geneticinformation is expressed. the ability to understand and ultimately to control thegenetic expression will make it possible to control genetic diseases, bacterialdiseases, and dna viral diseases. thus,the important questions for dna are: what is the detailed conformation of any sequence of doublestrandeddna and how does it depend on the environment? how does the conformation interact with other molecules?to answer these questions, we will need to understand nucleic acidstructure, protein structure, and their interactions in complex environments. itwill take a great deal of effort to achieve this understanding, but the rewards forsociety will be very high.xray diffraction experiments have determined structures for doublestranded dna, proteindna complexes, and dnasmall molecule compoundsin crystals. computer modeling is needed to extrapolate these results to predictwhat would occur in different biological environments and to other complexes.one obvious application is in the design of more specific and more effectiveantibiotics. in general, we would like to be able to design molecules that canstart or stop the expression of any gene in any dna.secondary structure of proteins and nucleic acids40computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.5.tertiary structure of proteins and nucleicacids: experimentalxray diffraction of biologicalmacromoleculesin 1934 bernal and crowfoot demonstrated that a crystalline protein couldgive rise to a wellordered xray diffraction pattern, thus setting the stage formodern analysis of the structure of proteins. progress was gradual at first,interrupted by world war ii, but in 1953 green, ingram, and perutz tookanother essential step when they accomplished the first heavy atom analysis of ahemoglobin crystal (green et al., 1954). the culmination of these years of workcame in 1959 when kendrew and his colleagues (1960) reported the analysis ofmyoglobin at 2 å resolution, revealing for the first time the underlying structureof a globular protein. they noted the complexity and lack of regularity of themoleculešmajor features that continue to impress us today as general featuresof protein structure. the alphahelices and beta sheets of pauling and corey(pauling et al., 1951) form striking regions of regularity, but are joined togetherin very complex ways.another major event of protein structure analysis occurred the same yearwhen cullis et al. (1959) described the structure of hemoglobin at 6 å anddemonstrated that the folding of the globin chain is similar to that in myoglobin,despite relatively lowtertiary structure of proteins and nucleic acids: experimental41computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.sequence homology between the two. this observation of a family pattern to thethreedimensional structure of globins has been followed by the identification ofmany other families.today, several hundred proteins have been analyzed by xray diffractionand their threedimensional structures catalogued. this number continues togrow at an everincreasing rate and, together with the amino acid and genesequence data, forms the principal basis for understanding the mechanisms ofaction of these proteins at the molecular level.the development of twodimensional nuclear magnetic resonance (nmr)techniques already is a valuable complement to xray diffraction for relativelysmall molecules (less than 10,000 molecular weight) but for the foreseeablefuture, crystal structure analysis will be the principal experimental source ofstructural data for enzymes, nucleic acid binding proteins, antibodies, and otherproteins of the immune system, receptors, and indeed, for all proteins that canbe effectively crystallized.determining the threedimensional structure of a biologicalmacromolecule by crystallography involves a number of clearly defined steps.first, crystals of suitable size and diffraction properties must be prepared. next,xray diffraction data must be collected for these crystals and also, typically, fora number of heavy atom derivatives of the crystals. these data can then beassembled to obtain an electron density map using a computational process thatresembles the action of the lens in a microscope. this map must then be fittedwith a polypeptide chain of the appropriate amino acid sequence. because themap is of lessthanatomic resolution and also contains errors in the phasedetermination, the investigator must have considerable skill to obtain the bestfit. the resulting protein model must then be refined to remove the errorspresent in the map as much as possible as well as those errors introduced by thefitting process.computers play an essential role in most of these steps. even the analysesof the first protein crystal structure, myoglobin, could not have beenaccomplished without the use of the edsacii in cambridge (kendrew, 1960).at present, modern crystallography depends completely on heavy computer use,and this dependence will certainly increase steadily in the future. in the fourmathematical procedures required to solve a structure using proteintertiary structure of proteins and nucleic acids: experimental42computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.crystallographyšdata processing, phase determination, map fitting, andrefinementšnew methods are continually appearing that depend on readyaccess to considerable computer power.first, we will consider the first step, data collection. this is now changingsignificantly, as most laboratories in the united states convert from the use offilm or diffractometer to the use of area detectors. these machines can increasethe speed of data collection within the laboratory by as much as two orders ofmagnitude. the output from the area detectors is generally processed directly,resulting in the speedy production of finished intensity data. the ability toproduce directly, in a few days, data that previously were collected in weeks ormonths of laborintensive work is revolutionizing the field at an opportune time,when developments in genetic engineering have made it possible to use sitedirected mutagenesis to answer many structural questions. these questions,however, require separate data sets for each mutant.when measuring xray intensities, whether using photography or areadetectors, the presentation of the data on a computer graphics screen can makeit much easier to analyze the diffraction pattern. area detectors coupled withgraphics facilities can now be used to align a crystal almost in real time. it is notclear how much the use of computer graphics in data collection will continue toincrease in the future, since its impact will probably be reduced by theincreasing power of the data processing software.a major discovery of protein crystallography is that most proteins belongto families with closely related threedimensional structures. examples includethe hemoglobins, serine proteases, aspartic proteinases, and theimmunoglobulin domain structure. consequently, we can now use the knownstructure to obtain phase information about an unknown structure, a methodknown as molecular replacement (rossmann, 1972). there have been numerousexamples of the successful application of molecular replacement to determinecrystal structures. the structure of a bacterial serine protease inhibitor was usedto analyze the structure of the protease bound with an inhibitor (james et al.,1978). another example is the use of the known structures of lysozyme and thetwodomain modules of an immunoglobulin fab to analyze the structure of amonoclonal antibody bound to lysozyme (sheriff et al., in press). the use ofthis molecular replacement method will become even more widespread as moremembers of a protein family are investigated.tertiary structure of proteins and nucleic acids: experimental43computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.molecular replacement techniques have also been applied in the use ofredundancy to obtain phase information (rossmann, 1972; harrison et al.,1978). a spectacular illustration of this occurred in the recent analyses of thepicornaviruses for polio and the common cold (rossmann et al., 1985; hogle etal., 1985).these methods require heavy computational analysis for their success. forexample, rossmann and argos (1977) concluded that they could determine therhinovirus structure only with extensive use of the supercomputer at purdueuniversity and could not have carried out the analysis and phase extensionwithout such a facility.computerassisted modeling in dna structureanalysisin the current method of fitting the electron density map, computergraphics are essential. although several programs can fit an approximate modelof a protein to the map without human intervention, most crystallographers donot use them, preferring to use instead computer graphics to fit. here, thedevelopment of color and stereo graphics systems has been an importantadvance. computer graphics constitutes such a colorful and seductive tool thatit virtually compels the nonscientific observer to believe in whateverphenomenon is being displayed. this inherent fascination with graphics displayextends to some working scientists as well. one always must ask whether [toparaphrase an old joke about statistics] a scientist is using computer graphicslike a drunk uses a lamp post: more for support than for illumination. but in thearea of macromolecular structural analysis, particularly with dna and itscomplexes with antitumor drugs and control proteins such as repressors,computer graphics will illuminate by enabling the investigator to carry out thestructure analysis efficiently and to see aspects of the structure of the moleculethat he could perceive only with difficulty or would overlook entirely usingmore traditional methods.in the early 1950s, before any protein structure had been determined by xray methods, the british crystallographer j. d. bernal once remarked that, evenif we were to obtain an electron density map of a protein, we would never beable to understand it until we could build a map big enough to walk through andpoint out features around and above us as we walked (personaltertiary structure of proteins and nucleic acids: experimental44computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.communication, around 1955). kendrew had this dictum in mind when heconstructed the first electron density map of any protein, myoglobin, byattaching colorcoded spring clips up the lengths of steel rods mounted in aregular grid on heavy plywood baseboard. (a portion of this first map stillexists on display in the kensington science museum in london.) richards(1968) provided the next step in the display of large and complex electrondensity maps of macromolecules, with a halfsilvered mirror arrangement thatcame to be known as a richards box. the device superimposed a direct imageof mylar sheets of electron density on a reflected image of the wire model beingconstructed (figure 51). in the 1960s and 1970s, virtually all macromolecularstructure groups had at least one richards box to use in interpreting electrondensity maps and building macromolecular models into them.this entire halfsilvered mirror box technology has been replaced by newmethods of computer graphics. detailed chain fitting is carried out on thegraphics screen, fitting stick bond skeletons into ﬁchickenwireﬂ threedimensional contoured volumes. diamond (1966) wrote the first such displayprogram, bilder. this routine has largely been superseded by the easiertouse frodo routines of jones (1985). more recently many even more flexiblepackages have been offered, both for large mainframe computers andminicomputers.the software most widely used is the program frodo developed byalwyn jones, who is at the university of uppsala, sweden. the use of frodoon a computer graphics system has now almost entirely replaced theconstruction of mechanical models, and greatly improved the accuracy in themodeling and, in particular, the speed and precision of the more predictivekinds of modeling, such as fitting substrates to the surfaces of enzyme molecules.in these programs, atoms can be placed within the observed density withgreat accuracy. because the coordinates are in the computer as soon as theatoms are located, acceptable bond lengths and angles can be built into the trialmodel from the outset. once a trial model has been built into the displayedelectron density, least squares refinement against the xray can be carried outusing one of several available programs that compensate for a toosmall ratio ofdata points to refined parameters at lessthanatomic resolution. the programsimpose constraints ontertiary structure of proteins and nucleic acids: experimental45computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.figure 51 illustrations of the method used before the advent of computergraphics to interpret an electron density map of a macromolecule in a richardsbox. section through the map of the protein cytochromec are mounted onplexiglass sheets that can be slid over the face of a light box at the upper rear.the lower left front shows a wire model of the cytochromec molecule,constructed in a framework with transparent top. the halfsilvered mirror inthe frame at 45 degrees to the main frame supporting the box superimposes adirect view of the contoured map and a reflected view of the wire modelbelow. this approach was ﬁhigh techﬂ around 1968.tertiary structure of proteins and nucleic acids: experimental46computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.bond lengths, bond angles, and (if desired) bond torsion angles to keepthem within known acceptable limits.in refining protein and nucleic acid structures, the use of new methods isincreasing investigators' dependence on heavy computing. current methods ofrefinement include the use of restrained least squares programs originallydeveloped by hendrickson and konnert (1980), sussman (1985), and by jackand levitt (1978) among others. these programs can be used successfully onrelatively slow computers, particularly when the fast fourier transformalgorithm is used to accelerate them. at present, the restrained least squaresrefinement procedure must be interrupted frequently to compare the fit of themodel to the electron density map, remodel to remove stereochemicallyunacceptable local minima, insert solvent molecules, and for other procedures.this process of model building is the step that is limiting the rate of therefinement procedure.it takes many days, even weeks, for a comprehensive, residuebyresidueexamination of an averagesized protein molecule of, for example, 40,000molecular weight. the procedure for identifying solvent molecules on theprotein surface is also tedious and timeconsuming. any method that wouldreduce the number of interventions during a refinement or would require lesshuman intervention during the modeling would speed up the refinementprocess. in this respect, brunger et al. (1987) have recently shown that bycombining protein dynamics simulation with the refinement process, one canavoid many of the minor minima that sometimes occur in the usual refinementprocedures. however, the successful application of the dynamics calculationswould require considerably more computer power than is currently available tomost crystallographic laboratories.at any point during refinement, computer graphics enable one to examinethe trial structure alone or superimposed on the electron density in one ofseveral options: a simple fo electron density map, a (fo fc) difference map, orthe (2fo fc) map that is in fact the superimposition of the two previousfunctions. when refinement is complete, the resulting coordinates areimmediately available within the computer for use in drawing figures thatillustrate the final structure. this ability to work within the computer duringmodel fitting, refinement, and display of results saves an enormous amount oftime over the older technique of constructing physical models.tertiary structure of proteins and nucleic acids: experimental47computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.difference patterson vector maps to locate heavy atomsthe standard way of determining the phases of the xray diffraction patternof a macromolecular structure is to prepare one or more heavy atom derivativesof the macromolecule that differ from the parent compound only by the additionof a heavy atomšmetal or halogenšat defined locations in the molecule. fordna, this can be done either by synthesizing the dna oligomer using 5bromocytosine instead of cytosine at one point in the sequence or by diffusingheavy atom complexes into the dna after crystallization. data are thencollected on the parent dna crystals and on each of the available heavy atomderivatives. heavy atom positions are found by interpreting a differencepatterson vector map, which in principle has features that locate all of thevectors between heavy atoms in the crystal unit cell.difference patterson vector maps traditionally are examined by usingminimaps stacked on plexiglass sheets that are placed on a light box. computergraphics display discussed above, however, offers several advantages over thisold technique. once a trial position of a heavy atom is established, one mustcalculate all of the heavy atomheavy atom vectors possible and see how manyof them correspond to features in the patterson map. if the crystal hasappreciable space group symmetry, this is a tedious and painstaking job. but itis a trivial task for a computer. the operator need only type in or locate a trialheavy atom position, andall the resulting interatomic vectors can be displayedinstantly on the graphic image of the patterson map. this allows rapidinterpretation of the vector map and is especially important if the space grouphas high symmetry or there are multiple heavy atom sites.computer graphicsper se is of relatively little assistance in the subsequentprocess of refinement of heavy atoms and single or multiple isomorphousreplacement phase analysis. but once a rough electron density map of the dnahelix is calculated, graphics again proves extremely useful.construction of a trial structure into an electron densitymapthe advantages of computer graphics in fitting a structure into a displayedelectron density map have already been mentioned: greater accuracy in fittingthe map, the ability to build intertiary structure of proteins and nucleic acids: experimental48computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.realistic bond lengths and angles from the outset, and the immediate availabilityof the coordinates in the computer.display of intermediate maps for checking errors in thestructureno restrained least squares refinement process is automatic, and peoplewho have assumed too much in this regard have made serious errors. theinvestigator must monitor the progress frequently during least squaresrefinement by examining difference maps (2fo fc) to look for wronglypositioned groups or missing features. this is tedious when one uses contouredminimaps, but can be much less so on a computer graphics display.the value of computer display of difference maps is well illustrated whenone is examining the structure of a dnadrug complex. in solving the structureof a bdna dodecamer of sequence cgcgaattcgcg with theantitumor antibiotic netropsin, kopka first positioned the dna in the crystalunit cell, using the results from the dna alone, and refined the dna until nofurther improvement was possible (kopka et al., 1985a, 1985b, 1985c). shethen calculated a difference map of coefficients (fo fc), where fo representedthe observed intensity data from crystals of the dnadrug complex, and fcrepresented the trial structure calculated from the dna alone. the result is aﬁchicken wireﬂ contoured image of the drug molecule (figure 52). the knownchemical structure of netropsin could be fitted easily and accurately into thegraphics display, and refinement then continued to completion of the dna anddrug together. as a control, kopka also drew a conventional minimap at thesame point in refinement, but this was nearly uninterpretable because of theawkward orientation of the sectioning of the map and the difficulty of buildingan idealized drug molecule into a map of stacked plexiglass sheets. in thisparticular application, the conventional minimap was tedious, but the graphicsdisplay was very simple to interpret.location of solvent molecules and ions around amacromoleculethe images of solvent molecules around a macromolecule cannot all befound from unrefined electron density maps. the quality of detail of the entiremap improves as the fitting of the dna is sharpened. locating solventmolecules is a repetitive process thattertiary structure of proteins and nucleic acids: experimental49computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.involves adding a restricted number of solvent peaks in the immediateneighborhood of the dna, refinement, and examination of the improved mapfor new images of solvent. this process is shown infigure 53 for the bdnadodecamer cgcgaattcgcg. this particular analysis was carriedout with minimaps because the computer graphics capability did not exist at thetime, but recent dna structure analyses use the more efficient graphics display.figure 52 stereo pair drawing, photographed off the face of an evans andsutherland multipicture system graphics station, of the difference electrondensity of the antitumor drug netropsin in its complex with bdna. thescreen image was photographed onto ektachrome slide film, and this film thenwas used as a negative in making a positive print. the framework is arepresentation in three dimensions of one contour level in the electron densityof the drug, and the graphics operator has built a skeleton of the netropsinmolecule within this contour cage. this is the first point at which informationabout the drug was built into the analysis and was the point of departure forfurther leastsquares refinement of the dnadrug complex. source: kopka etal., 1985c.tertiary structure of proteins and nucleic acids: experimental50computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.figure 53 illustration of the iterative process of locating solvent moleculesaround a dna double helix. the quality of the solvent images improves withrefinement and improvement of the phases used in the electron density mapcalculation. one must avoid adding ﬁsolventﬂ molecules too hastily, for fear ofintroducing erroneous peaks that then will persist and confuse during laterrefinement. such a search for solvent requires the inspection of manysuccessive electron density maps as refinement proceeds, and computergraphics are of enormous help in speeding up this process. (a) vicinity ofthymines no. 7 and 19 of the bdna dodecamer cgcgaattcgcg, prior to the addition of any solvent molecules to the phasing. residual error,r = 27 percent. (b) later stage of refinement, r = 21 percent, three solventpeaks visible in these sections. (c) still later stage, r = 20 percent, five solventpeaks visible. (d) final map, r = 18 percent, ten solvent peaks indicated.source: drew and dickerson, 1981.display of completed macromolecular structurethe most familiar application of computer graphics to macromolecularstructure is the display of the final results. but eventertiary structure of proteins and nucleic acids: experimental51computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.here, the flexibility of computer graphics enables one to go beyond simpledrawing of views of the molecule and see features that ordinarily would beoverlooked. a case in point is provided by the stereo pair infigure 54, whichshows the drug molecule netropsin complexed with a 12 base pair bdnadouble helix. the image was oriented to sight directly down the minor groove,with the object of demonstrating that netropsin sits in the middle of the grooverather than to one side. but an unintended secondary dividend emerged. in thisview, the bases of each individual strand of the double helix are seen to bestacked atop one another, almost as though the other strand of the helix did notexist. this efficiency of intrachain base stacking means that when the twostrands are wound around one another to build a double helix, the bases of eachbase pair are not coplanar; they are given what is defined as a positive propellertwist about the long axis connecting them.figure 5.3b continuedtertiary structure of proteins and nucleic acids: experimental52computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the lessened resistance to propeller twisting in at base pairs, which resultsbecause at base pairs have two connecting hydrogen bonds, as compared tothree for gc pairs, means that the minor groove of bdna is closed downmore in at regions than in gc. this makes a flat multiring drug molecule suchas netropsin fit more snugly into the narrow at region and is part of theexplanation for the previously established binding of netropsin only to at basepairs. hence, in this example, an unusual view of the dna that was intended toillustrate one point revealed an unexpected new association. examples of thisserendipity with computer graphics are found over and over again inmacromolecular structure analysis.figure 5.3c continuedstudies of docking and macromolecular interactionsonce the structure of a macromolecule is known, it can be compared withthose of related macromolecules or with other molecules with which it formscomplexes. computer graphicstertiary structure of proteins and nucleic acids: experimental53computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.permits one to move molecules relative to one another and to introduce minorchanges in a manner that would be tedious or impossible with physical models.for example,figure 55shows the fitting of a netropsin molecule against thefloor of the minor groove seen in profile. without computer graphics, it wouldbe virtually impossible even to represent the contour of the floor of the minorgroove, yet the drug binds to this surface. the figure illustrates the structurallysignificant finding that the ends of the molecule are more closely associatedwith the dna than is the central amide. one can change base pairs in the dnafrom at to 2aminoadeninethymine and show the steric clash that then ensueswith the drug. one also can modify the drug itself and see what effects this islikely to have on its binding to dna.figure 5.3d continuedthis ability to examine intermolecular ﬁdockingﬂ is equally importantwhen the two molecules are known, but their complex is not. trials of variousdocking geometries, with calculations oftertiary structure of proteins and nucleic acids: experimental54computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.relevant energies, can suggest new modes of interaction, as well as theexperiments needed to test them.figure 54 oblique computer graphics stereo diagram of the complex ofnetropsin with cgcgaattcgcg, in a view sighting directly downthe minor groove with the drug molecule slotted into it in a crescent curvingaway from the viewer. this view also illustrates the strong stacking of basesdown each strand of a betadna double helix, in a more strikingrepresentation than is obtained from a more conventional view of the betahelix. positive print from ektachrome photo taken directly from graphicsterminal. source: kopka et al., 1985a.in summary, computer graphics is far more than an attractive way ofdrawing pictures of macromolecules. it is a very powerful tool that greatly aidsin understanding the interactions between dna and other macromolecules andso leads to insights that otherwise would be overlooked. even without computergraphics, considerations of only energy minimization have led to a predictedstructure of an enzymesubstrate complex (pincus and scheraga, 1979) that wassubsequently verified by experiment (smithgill et al., 1984).tertiary structure of proteins and nucleic acids: experimental55computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.figure 55 van der waals surface representations of the netrospin molecule(top) fitted along the floor of the minor groove of betadna. this highlyunconventional view is possible only with computer graphics. it follows theplane of the drug molecule, and hence cuts the dna base pairs only in obliquesections. the dna major groove is seen at bottom nearly in profile, flankedleft and right by phosphates. this view illustrates the less intimate contact withthe floor of the minor groove at the center of the drug molecule than at the twoends. source: kopka et al., 1985c.tertiary structure of proteins and nucleic acids: experimental56computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.using nuclear magnetic resonance todetermine tertiary structuresnuclear magnetic resonance (nmr) is an important source for structuraldata, particularly when one considers its potential for meshing with theoreticalmodeling and other sources of structural data, such as xray crystallography. itsuse has been growing explosively. nmr has been applied in aqueous mediaand, to a limited extent, in environments that approximate those of biologicalmembranes (braun et al., 1981). it is most useful when it is necessary to explorechanges in preferred structure in response to environmental or structuralperturbations. in this sense, nmr can play an important role in extrapolatingstructural data obtained by other techniques to alternate environments. it is alsowell suited to the exploration of changes in structure when comparinghomologous series of macromolecules, such as a series produced by sitespecific mutagenesis (markley, 1987).more recently, technological advances have extended the range ofapplicability to solids, oriented phases, and even total structure determination ofmolecules in solution. the latter extension has attracted the most attention andhas the greatest potential impact on computerassisted modeling efforts.examples of total structure determination by nmr are most numerous amongrelatively small molecules: peptides, oligosaccharides, and nucleotideoligomers. however, several groups have determined peptide or proteinstructure for molecules in the 5 to 10 kda molecular weight range (arseniev etal., 1984; braun et al., 1986; havel and wüthrich, 1985; kaptein et al., 1985;kline et al., 1986; williamson et al., 1985). a brief discussion of the proteinexamples provides insight into the potential contribution nmr may make to theprediction of macromolecular structure and function in years to come.methodologyin most cases, the basis of structure determination by nmr methods is theinteratomic distance dependence of the nuclear overhauser effect (noe). thisis a nuclear spin relaxation phenomenon that depends on through space dipolarinteraction between magnetic moments centered on different nuclei (usuallyprotons). the noe shows an inverse sixth power dependence on distance. inprinciple, havel et al. (1979) found that the conversiontertiary structure of proteins and nucleic acids: experimental57computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.of enough noe measurements to distance constraints between pairs of protonsin macromolecules would be completely equivalent to the specification ofstructure through a set of cartesian coordinates. the ubiquitous occurrence ofprotons as the hydrogen nucleus in chemical structures insures an abundance ofnoe data. these data have been gathered and used for a long time in studies ofsmall molecules, but until recently, the sheer abundance of data formacromolecular systems has prevented unequivocal interpretation in terms ofmacromolecule structure.a protein of 10 kda will have approximately 1,000 protons, each givingrise to one or more resonances in a proton nmr spectrum. resolution inconventional spectral acquisitions is in adequate to identify each resonance, letalone assign it to a primary structure site or acquire noe data on a significantfraction of the possible 5 × 105 proton pairs. the situation with other types ofmacromolecules, nucleic acids or oligosaccharides, is less formidable in termsof numbers of protons. however, it is complicated because residues in thesestructures are less chemically diverse and the resulting resonances are lessdispersed in nmr spectra and so it is difficult to assign a particular peak to aparticular proton.the resolution and assignment problem has been solved with the advent ofhigher field magnets (currently 14 tesla) that provide increased chemical shiftresolution, as well as by the devel opment of twodimensional acquisitiontechniques that provide multidimensional resolution and greatly improveefficiency of data acquisition (ernst et al., 1987). wüthrich (1986) summarizesthe methods for proteins and nucleic acids in his work.assignment of a resonance to a proton at a particular point in the primarystructure site relies on a combination of experiments that display through bondscalar connectivities of resonances (cosy, or coupling correlated spectroscopy,for example) and through space dipolar connectivities of resonances (noesy,or nuclear overhauser effect spectroscopy). cosy is important in findingscalar coupling patterns that correspond to sets of spins that are characteristic ofa particular type amino acid. for example, only alanine has three equivalentmethyl protons coupled to an alphaproton. the noesy experiment isimportant in linking resonances assigned to a given amino acid to resonances ofa neighboring amino acid. in cases where the amino acid sequence is known,the linkage of two to three amino acids is often enoughtertiary structure of proteins and nucleic acids: experimental58computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.to create a segment that occurs only once in the sequence. in principle, thisprocedure provides a complete sequence specific assignment of nmrresonances.after the assignment of resonances, the determination of secondary andtertiary structures of proteins proceeds largely on the basis of noe information.qualitative analysis of the intensity of the crosspeaks that connect protonresonances involved in an noe is often enough to characterize secondarystructure. for example, in an alphahelix, the amide protons of adjacent residuesare 2.8 å apart as compared to 4.6 å in a betasheet (wüthrich, 1986). becausenoe has a steep inverse distance dependence, this leads to strong amideamidecrosspeaks in an alphahelix but crosspeaks that are a factor of 20 less intense ina betasheet (usually unobservable). it is possible to assign residueconformations to known types of turns as well as to more extended secondarystructural elements. since this assignment is sequence specific, it gives valuableinformation for verifying structure predictions and possibly assessing foldingpreferences even without a tertiary structure determination.determining tertiary structure is more difficult. to determine a structure, alimited amount of longer range distance constraint information must besystematically integrated with other constraints. the most direct approachprobably employs a distance geometry search for structures that haveinterproton distances between the experimentally determined upper and lowerbounds (braun and g, 1985; havel et al., 1979). altman and jardetzky (1986)recently developed an expert system that has also succeeded in producing aspacefilling representation of protein structure.it is, however, proving desirable to increase the degree to which theoreticalconstraints play a role in determining structures. this increase has beenachieved using both molecular dynamics and molecular mechanicsbasedprograms (brunger et al., 1986b; kaptein et al., 1985). it is desirable tointegrate nmr data with theoretical predictions for two reasons. first, nmrdata often leave certain regions of the macromolecule poorly defined; forexample, there may be little noe data on certain sidechain conformations inproteins. theoretical predictions can help specify the conformation of theseregions. second, use of some experimental data seems a viable approach toselecting among multiple minima in the complex energy surfaces that must besearched by theoretical modeling programs.tertiary structure of proteins and nucleic acids: experimental59computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.viability of approachas with any new approach to structure determination, nmrbasedmethods are being tested for viability. the most direct method of evaluation isto compare structures determined independently by the new methodology withan established technique such as xray crystallography. unfortunately, whenbraun and coworkers (1986) first determined a structure without the aid of anexisting crystal structure (metallothionein, a 7,000 da protein) the structurevaried dramatically from the xray structure when it did appear. the reasons forthe differences, although still unresolved, are more likely the result of actualstructural differences in the samples examined than of a flaw in themethodology. more recent comparisons show excellent agreement of structuresdetermined from real or simulated nmr data with structures determined by xray crystallography; examples include an alphaamylase inhibitor, a 8,000 daprotein (kline et al., 1986) and crambin, a 5,000 da protein (laue et al., 1985).resolution is difficult to define in nmr structures because some aspects,such as the conformation of the backbone, are determined very precisely, whileothers involving sidechain conformations are poorly defined. it is even possiblethat the lack of adequate numbers of distance constraints will leave someregions completely undetermined. in principle, distances can be determinedprecisely, within 0.01 å, but this is only accomplished when relaxationprocesses are very well defined and interproton distances are short. recentestimates for general resolution based on rootmeansquare (rms) deviations ofheavy atoms in multiple structure solutions of proteins obtained from nmr datasuggest resolution to be approximately 3 å (williamson et al., 1985). althoughthese average deviations are larger than those usually seen in xray data, nmrmethods can be used in a variety of media and yield very precise distanceinformation on selected distances. both of these advantages compensate for thelower precision.the effort required to produce a structure is difficult to assess in this earlystage of development. the first few tertiary structures probably required severalpersonyears of effort. however, this is dropping rapidly. secondary structureshave always been produced with far less effort. to produce a tertiary structureof a protein in the 10 kda range, one month of spectrometer timetertiary structure of proteins and nucleic acids: experimental60computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.and six months of analysis is a reasonable estimate. sample requirements aremodest; 50 mg of a soluble 10 kda protein. smaller molecules require aproportionately smaller sample or a quadratically smaller investment in time. itis important to realize that this is an emerging technology, compared to betterestablished structural methods. large opportunities are available to improveefficiency and viability.limitations and prospects for the futurethe major limitation to the above methods appears to be one of accessiblemacromolecule size. current applications in which nearcomplete assignmentsare made and structures are determined appear to be restricted to proteins of 10kda and less. this is due in part to inadequate resolution when thousands ofconnecting peaks are involved. it is also due to loss of sensitivity in one of thekey spectral assignment data sets (cosy sets). cosy crosspeak intensity isextremely dependent on the ratio of scalar coupling constants to linewidth. thelinewidths increase rapidly with molecular weight, leading to loss of signal. it issignificant that the principal source of distance information, the noesyexperiment, does not have the same degree of sensitivity loss as one increasesmacromolecule size. if other assignment strategies emerge and resolution ofchemical shift can be improved, it will be possible to use nmr methods onlarger macromolecules.we believe that improved assignment strategies will emerge. alreadysignificant work has been done replacing normal amino acids with isotopicallysubstituted amino acids in order to assign peaks arising from particular aminoacid types (kainosho and tsuji, 1982; lemaster and richards, 1985). thisstrategy bypasses some of the dependence of assignment on noesy spectraand can be applied to proteins of more than 12 kda (kainosho and tsuji, 1982;lemaster and richards, 1985). replacement of normal amino acids with aminoacids that contain 15n and 13c and the use of indirect detection methods toimprove sensitivity also allow use of the increased chemical shift dispersiondisplayed in spectra of other nuclei. proteins of 19 kda (mcintosh et al., 1987)and 23 kda (kainosho et al., 1987) are under study. in these cases, the isotopiclabelings were easily performed because the proteins were obtained frommicroorganisms. these developments, along with the probable advance inresolution from higher field magnets,tertiary structure of proteins and nucleic acids: experimental61computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.make it likely that general structure determination methods may be applied toproteins in the 20 kda class within the next five years. application to proteinsas large as 60 kda, where questions are focused on specific sites, already arepossible. a rather limited quantity of residuespecific information may berequired to improve dramatically the quality of theoretical predictions.a second limitation, to current methodology beyond accessiblemacromolecule size, stems from the restricted range of measurable interprotondistances, <4 å. although this range is adequate to determine structures of shortsegments, tertiary structures of larger systems are frequently the result ofsuccessive application of many short range constraints. this introduces thepossibility that significant errors will be propagated. here again, optimism isjustified. the use of paramagnetic labels leads to perturbations of spectrainterpretable in terms of distances over separations of more than 10 å (kosen etal., 1986).a third limitation occurs because the conversion of noe measurements todistances requires assumptions about macromolecule rigidity. since someportions of macromolecules are not rigid, the distances extracted for thoseportions are imprecise. to some extent, the imprecision is reduced by the 1/r6dependence of the noe. an error of ± 50 percent in an noe ratio for a 3 åcontact converts to error limits of 0.21 and +.33 å. it is nevertheless animportant limitation. at present, these potential errors are handled by assigninggenerous distance constraint limits, rather than by trying to specify distancesprecisely. in the future, it may be possible specifically to include dynamicinformation eliminating this necessity.areas of potential impact of nmrproteins and peptidesit is clear from the above discussion that much of the research into thestructure and dynamics of macromolecules, particularly proteins, may berestricted to relatively small members of the class. this limitation is imposedboth by the magnitude of the task and the loss of sensitivity as macromoleculesize increases. we should consider how these restrictions may affect biologicalscience and what special problems or opportunities may arise in consideringsmaller members of macromolecule families.tertiary structure of proteins and nucleic acids: experimental62computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.limiting research over the next five years to proteins of molecular weight10 kda or less may seem highly restrictive. however, a survey of the currentprotein sequence data base maintained by the protein identification resourceshows a surprisingly large fraction (20 percent) to be under this size (barker etal., 1986). this fraction may be inflated by the ease of handling shortersequences, but even 10 percent of the current 4,000 sequenced proteins is a verylarge number to be studied by nmr spectroscopy. the current rate of physicalcharacterization stands at 20 proteins per year by xray crystallography and 10or more by nmr. given that rate and the likelihood of producing sufficientquantities of many of the sequenced proteins by cloning techniques, humanresources and characterization facilities are more likely to be limiting factorsthan is the number of proteins on which we want information.beyond the issue of numbers, small proteins and even smaller peptidesconstitute a physiologically important class. polypeptide hormones such asatrial naturietic factor, oxytocin, vasopressin, and insulin (subunit) fall in theseclasses (wallis et al., 1985). various neurotoxins are small polypeptides, and anumber of endogenous opioid peptides exist, such as the enkephalins andendorphins.one may also ask whether studies of small protein or peptide structuremight be relevant for the understanding of larger structures. although somebehavior, such as allosteric interaction, is certain to be poorly represented insmall molecules, the basic structural considerations are reasonably likely tocarry over, and it is likely that fundamental processes such as protein foldingcan be studied. a large number of proteins are composed of smaller subunitsthat largely maintain their structure when isolated. in some single chainproteins, structural domains that can be cleaved and functionally reconstitutedwithout reforming a covalent linkage can be identified (rose, 1985).small peptides present some potentially unique problems forconformational studies. it is not clear that the dominant conformations observedin solution, crystals, or simulations are those that are important for biologicalfunction. these molecules do interact with receptors, which may select a minorconformer or dictate a unique conformation that is a function of the propertiesof both molecules. because most receptors exist in very small numbers, it hasonly recently become possible to produce enough for physical study. for thecoming years, a major challenge istertiary structure of proteins and nucleic acids: experimental63computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the modeling of systems in which both activator and receptor can changeconformation. this challenge relates not only to the understanding ofphysiologically important molecules, but also to the design ofpharmacologically important molecules. it is possible that a study of relativelyflexible polypeptides will contribute to the development of the methods neededto meet this challenge.experimental measurements designed to explore minor conformers shouldcontribute in important ways to the understanding and development of modelingmethods. an experiment using nmr where this type of study appears possibleoffers one example. small molecules (12 kda) have relatively inefficientpathways leading to nuclear overhauser enhancements. when these smallmolecules bind to macromolecular receptors, more efficient path ways arepresent. distance constraints derived from the measured noes on moleculesthat exchange rapidly between bound and free states therefore pertain to theconformation of the bound molecule more than the free molecule (clore andgronenborn, 1983). such experiments have many limitations of size, bindingconstants, and rates of exchange, but they still promise to make some inroadsinto a very difficult set of problems in molecular biology.nucleic acidsas a class, intact nucleic acids exist as molecular entities in sizes far largerthan the proteins with which we typically work in nmr. however, smallersegments appear to display structural characteristics important in biologicalfunction. for example, double helix structures formed from oligomers of 8 to 12bases in length exhibit variations in backbone torsion angles, base twist, andbase tilt angles that characterize helix forms suspected to modulate transcriptionactivity.a dodecamer helix has an effective molecular weight equivalent to smallproteins. the same twodimensional nmr methods applied to proteins allowsus to characterize nucleic acid structures and explore in detail the factors thatlead to interconversion of structural forms. the imino protons involved in thehydrogen bond connecting base pairs exchange slowly with protons in thesolvent and are easily resolved in the low field region of a proton nmrspectrum. sequential assignments are made possible by the proximity of iminoprotons on adjacent base pairs and the strong cross relaxation peaks that connectthese resonances in noesytertiary structure of proteins and nucleic acids: experimental64computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.spectra. variation in distances between imino protons and sugar backboneprotonsšfor example, h6 protons on pyrimidine bases and h2' protons on theattached deoxyribose ringšmakes it possible to distinguish the type of helix onthe basis of the presence or absence of cross relaxation peaks. more quantitativetreatments of structure employ the same molecular mechanics, moleculardynamics, and distance geometry methods used with proteins (hare and reid,1986; nilsson et al., 1986; suzuki et al., 1986).beyond simple helical structures lies a vast region of structural biology ofnucleic acids that has been much less explored. nucleic acids are importantelements of ribosome structure and function. some ribonucleic acids have evenbeen shown to exhibit enzymelike activity. hybrid systems involving proteinsand nucleic acids are important in synthesis, repair, and regulation of proteinstructure and function. in the near future, we should have the potential forstructural characterization by nmr of at least parts of these systems. inbuilding a more theoretical basis for the extrapolation of primary structure tothreedimensional structure and function, one key step is the experimentalverification of the existence of fundamental structural elements andunderstanding of the factors that dictate their occurrence.carbohydratesthe carbohydrate moieties of glycolipids and glycoproteins are a thirdclass of biologically important molecules. they are important modulators ofcommunication between and across cell membranes. a knowledge of threedimensional structure and flexibility is essential to understand this modulatingfunction. because the function of these molecules has been less widelyappreciated, they are discussed in more detail later in this report.most oligosaccharides, if examined in isolation, are smaller than theprotein and nucleic acid systems we have been discussing. structuredetermination is, however, no less challenging because of the structuraldiversity of this class of molecules. the number of monosaccharide buildingblocks is intermediate in number between that of proteins and nucleic acids, buteach monosaccharide can be linked through any one of several sites, with eitherof two anomeric configurations. that there are multiple linkage sites also opensthe possibility of branching. it is difficult to predict the number of structurallydistinct oligosaccharides in an organism,tertiary structure of proteins and nucleic acids: experimental65computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.but it is certainly large. even if we attend only to a single class ofoligosaccharide containingmolecules, such as glycosphingolipids, a significantnumber (more than 150) of primary structures have been determined(hakomori, 1986). few of these structures have experimentally determinedtertiary structures, and all evidence indicates that 150 represents a small fractionof the total number that exist. also, unlike the protein and nucleic acidproblems, carbohydrates present a primary as well as a tertiary structureproblem. nmr methodology has contributed to the solution of both and, withsome advances, should contribute further (yu et al., 1986).analogies with protein structure determination exist. cosy spectra areimportant in assigning resonances to particular residue types. noesy spectraare important in identifying linkage sites, linkage configuration, and sequence.bottlenecks in terms of manual assignment and conversion of cross relaxationdata to structures are very similar to those encountered in protein studies (bushet al., 1986; yu et al., 1986; homans et al., 1987; dabrowski et al., 1986).progress has been impeded slightly more because computer modeling programsfor oligosaccharides are somewhat less refined than are those for proteins.oligosaccharides are also likely to be less rigidly structured and so require moreattention to proper treatment of motional averaging. nevertheless, significantadvances are possible, at least in smaller molecules and more stericallyconstrained molecules of this class. with the establishment of a largerexperimental data base using methods such as twodimensional nmr,theoretical predictions of structure from sequence should become possible.demand on computational facilitiesimproved computational and molecular modeling facilities could advancestructure determination using nmr methods in several ways. processing andanalysis of nmr data for a 10 kda macromolecule is far more timeconsumingthan is data acquisition. each phase of this operation could be improved. dataare normally collected as a twodimensional time domain set and processinginvolves fourier transformation to a frequency domain set. these processes arenow handled by array processors associated with instrument computers with amoderate investment in time (tens of minutes). however, alternative methods ofprocessing,tertiary structure of proteins and nucleic acids: experimental66computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.including linear decomposition and maximum entropy methods, may be moreadvantageous in terms of signal to noise and may be more compatible withautomating analysis (laue et al., 1985; schussheim and cowburn, 1987). theserequire far more computer time and may become practical only onsupercomputers.automating analysis can be difficult when working directly with afrequency domain data set. the sets are 4 to 16 megawords in size, and theconnectivity peaks used in assignment are complex shapes that have bothfrequency and phase information. several approaches are being explored toreduce these complex peaks to a few pieces of connectivity information, but it ispossible that methods such as linear decomposition, which reduce frequencydomain sets to lists of peak frequency and intensity at an early stage, willprovide the breakthrough needed in this area.once resonances have been cataloged, the next step is the assignment andextraction of spectral characteristics important for the determination ofsecondary and tertiary structures. this process is now mostly done by hand.some efforts are underway to use semiautomated pattern recognition and expertsystem strategies, but these will require substantial investments in programmingand computer hardware (pfandler and bodenhausen, 1986).at present, conversion of the data to a threedimensional structure ishandled by distance geometry or one of the pseudo energy approaches. mostsuch programs that currently run on supercomputers require one to severalhours of computer time per trial structure.at least 5 trial structures should be generated for each data set to explorethe constraint boundary conditions. as interest and capabilities for theproduction of data sets increase, the demand for computer time will becomestaggering. it is difficult to project if and how much these demands will beoffset by improved algorithms. an investment in programming is obviouslywarranted. this investment could be put to best use by acknowledging that, inthe future, it may be desirable to accommodate types of data not used today.some data may come from other nmr methods that are applicable to solids andoriented specimens. other data may come from entirely differentmethodologies, such as fluorescence spectroscopy or tunneling microscopy.although modeling and energy refinement programs have existed for years, it isclear that attempts to accommodate nmr data have met with some obstacles.most modeling programs presume the existence of atertiary structure of proteins and nucleic acids: experimental67computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.cartesian coordinate set similar to that obtained from an xray structure. nmrdata are most compatible with interatomic distances or interactive manipulationof segments of known secondary structure.present methods, except in a few preliminary calculations, also assume thatstructure of biomolecules can be described in terms of a single rigid conformer.this is certainly not true. relaxation of these assumptions will lead todrastically increased computational demands. some of the problems andopportunities related to this are discussed more fully under the section onmolecular dynamics.in summary, current nmr methods to determine structure seem applicableto a variety of biologically important molecules of less than 10 kda. dataproduction in this class will be made much easier by improved computationalfacilities, available high field spectrometers, and attention to the compatibilityof modeling programs with experimental constraints provided by nmr. it isimportant that those working in nmr collaborate with investigators attemptingto determine structure with other methods, because such links will increase thestructural data base and also enhance testing and theoretical modeling. it islikely that the range of molecules accessible by nmr methods will increase bya factor of two over the next five years. the rate of data production is likely toincrease even more as structure determination protocols are improved and highfield spectrometers become more generally available. advances in hightemperature superconductors may accelerate this process.tertiary structure of proteins and nucleic acids: experimental68computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.6.tertiary structure of proteins and nucleicacids: theoryenergy optimizationaccording to the thermodynamic hypothesis, based on anfin sen's(anfinsen et al., 1961) experiments on the oxidative refolding of bovinepancreatic ribonuclease a from the reduced form, the amino acid sequencedetermines the threedimensional structure of a protein in a given medium asthe thermodynamically most stable one. it must be emphasized that thishypothesis applies to the length of the polypeptide chain at the stage whenfolding takes place, and not at some subsequent processing stage. for example,this hypothesis would be applicable to the singlechain proinsulin and(possibly) not to the processed product, the twochain disulfidelinked insulin.thus, it is a challenge to chemists to understand how the interatomicinteractions within the polypeptide chain and the interactions between the atomsof the chain and those of the surrounding solvent lead to the thermodynamicallystable structure, that is, the one for which the statistical weight of the system isa maximum.the hypothesis that the statistical weight is a maximum immediatelyimplies that some kind of optimization strategy is neces sary to find the moststable structure. this requires procedures to generate arbitrary conformations ofa polypeptide chain, computetertiary structure of proteins and nucleic acids: theory69computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the statistical weight for each conformation, and then alter the conformation sothat it ultimately corresponds to the global maxi mum of the statistical weight.although the problem is formidable, current indications are that it can be solvedusing a sound scien tific approach without resorting to ad hoc procedures todeduce ﬁfolding rulesﬂ that do not explain the molecular basis of such ﬁrules.ﬂto compute the global statistical weight, one optimizes the conformationalenergy of the polypeptide, incorporates the effect of the solvent, and takesaccount of the entropy of the system. procedures are available for carrying outsuch computations, and currently available supercomputers permit thecomputations to be applied to very large systems. although these procedureswill undoubtedly improve, they are now adequate for computating andobtaining results that can be checked experimentally. the major difficulty stillto be overcome, although partial success has been achieved (see review bygibson and scheraga, 1988; also, robson, 1986; crippen, 1984), arises fromthe presence of many local min ima in the multidimensional energy surface.although algorithms are available for minimizing an energy function of manyvariables, there are no efficient ones for passing from one local minimum, overa potential barrier, to the next local minimumšand ulti mately to the globalminimum of the potential energy in a very high dimensional space. thus,minimization leads to the nearest local minimum, where the procedure istrapped. this trapping in a local, rather than the global, minimum is referred toas the ﬁmultipleminima problem.ﬂ efforts are being made to overcome thisproblem using a variety of procedures, including approximations that place thesystem in the potential well in which the global minimum lies (gibson andscheraga, 1988). then, any approxi mations (introduced in the initial stages) areabandoned, and the full energy function is minimized. the use of moleculardynamics for minimization is an alternative strategy; it is considered in the nextsection.the energy minimization approach and its associated compu tationalprogram, described here for polypeptides and proteins, is equally applicable toany other type of macromolecules, such as polynucleotides andpolysaccharides, as well as to interactions between the various types ofmacromolecule. general references to this methodology include the works ofanfinsen and scheragatertiary structure of proteins and nucleic acids: theory70computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.(1975), némethy and scheraga (1977), levitt (1982), karplus and mccammon(1983 ), scheraga (1984), and richards (1986).generation of an arbitrary conformationanalytical geometry and associated matrix algebra provide the tools togenerate a polypeptide chain. to do so, internal co ordinates (dihedral anglesfor rotating about bonds) or cartesian coordinates may be used as independentvariables. when inter nal coordinates are used, the bond lengths and bondangles are held fixed, but chosen very carefully from xray structures of modelsystems so as to properly reflect the geometric results of side chainbackboneinteractions within each amino acid residue. the validity of this approach hasbeen demonstrated for both polypeptides and polysaccharidesšsystems inwhich strained conformations rarely arise (scheraga, 1984). when cartesiancoordinates are used, and hence bond lengths and bond angles are allowed tovary, one faces the problem that force constants for these motions are not aswell known as the geometric features of the molecule. further, bondanglebending modes are anharmonic, and no currently available forcefield takesanharmonicity into account. thus, we will have to overcome inadequacies inthe force constants and problems of anharmonicity before we can rely oncomputed bond angles. impo sition of fixed bond lengths and bond angles is atleast reconciled with observed crystal structures of small molecules. the subjectof fixed versus flexible geometries has been discussed by swenson et al. (1978).potential functionsmany research groups have developed potential energy functions withwhich to carry out such computations on polypep tides, polysaccharides,polynucleotides, and synthetic polymers. the various potential functions havemany similarities, but differ enough in detail to make them difficult to compare.this difficulty is compounded by the small number of cases for whichparameters that characterize the strengths of the various interactions have beenestablished in a selfconsistent way on experimental data such as crystalstructures, lattice energies, and barriers to inter nal rotation. at present, thepotential functions for polypeptides,tertiary structure of proteins and nucleic acids: theory71computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.polysaccharides and synthetic polymers have been better parameterized thanhave those for polynucleotides, primarily because there are fewer reliable datafor model nucleotide compounds. similarly, more experimental data will berequired for proper parameterization of the potential functions for the prostheticgroups attached to biological macromolecules. until recently, the poten tialfunctions involving water molecules still would not account adequately for theobserved radial distribution function of water, but this situation is improving(see, e.g., the work of jorgensen et al., 1983).it must be emphasized that the molecule responds to the total (in principle,quantum mechanical) potential function, and its partition into various empiricalcomponents (such as nonbonded, electrostatic, hydrogenbonding, and otherinteractions) is at best arbitrary, although there is some physical basis for assigning such names to the various components. consequently, one must avoidcombining components from forcefields from different research groups. eachforcefield must be parameterized by itself in a selfconsistent way. the totalenergy of a given conformation is expressed as a sum of the energies of allnonbonded pairs of atoms.when considering biological function, such as the formation of an enzymesubstrate complex, then the pair interactions both within and between the twopartners of the complex must be included in the total energy. thus, theinfluence of each member of the complex on the other (the socalled induced fitphenomenon) is taken into account. consequently, the conformations of thepartners in the complex can differ from their conformations as individualspecies. this means that the computed conformation of an isolated hormonemay not resemble the biologically active one when it is bound to a receptor(scheraga, 1984).although potential functions could still be improved, those for whichparameters have been determined in a selfconsistent way have led to manycomputed structures that have subsequently been checked by experiment. forexample, the computed structure of the collagenlike poly(glypropro) (millerand scheraga, 1976) agrees with the subsequently determined crystal structure(okuyama et al, 1976) within a rootmean square (rms) deviation of o.3 å.scheraga (1984) has cited many similar examples of experimental verificationof computed structures. therefore, we can be confident that the problem ofadequate potential functionstertiary structure of proteins and nucleic acids: theory72computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.is not serious, and more effort should be devoted to the most difficult problemof allšthe multipleminima problem. after the multipleminima problem issolved, it will then be worthwhile to reexamine the possibility or necessity ofimproving the potential functions further.solvationthere are several methods to include the effect of hydration in thecomputations. hydration tends to force the polar groups to the surface of themolecule, putting them in contact with water, and forces the nonpolar groups tothe interior, removing them from contact with water.one method includes the water molecules explicitly, and calculates theinteraction energy between the molecule and the water. the success of thisapproach depends on the adequacy of the po tential function describing thewaterwater interaction. another approach ignores the structural features of thewater molecule, and assigns a hydration shell (and an accompanying freeenergy of hydration) to each atom or group of atoms. as the conformationchanges and hydration shells overlap, a freeenergy penalty is assessed. thehydrationshell model is parameterized on experimental data on free energies ofhydration (kang et al., 1987), but current efforts are being made to obtain suchfree energies from monte carlo and molecular dynamic studies of aqueoussolutions of small molecules (see, e.g., jorgensen et al., 1983). the computation of free energies by these simulation techniques faces many theoreticalobstacles, although this very active field of research is progressing quickly.entropya variety of methods exist to incorporate entropic effects. one entropiceffect arises from the hydration; this effect is treated as described earlier. theother entropic effect arises from the conformational fluctuations of themolecule. several procedures may be used to compute this contribution, themost direct being the evaluation of the second derivative of the potentialfunction. this describes the curvature at the bottom of the potential energy welland hence the fluctuation in conformation about each local minimum in thepotential energy surface. local minima that aretertiary structure of proteins and nucleic acids: theory73computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.not the global minimum of the potential energy can become the conformationsof higher statistical weight if there is a large enough entropy gain from largeconformational fluctuations. paine and scheraga (1987) have encountered sucheffects.optimization proceduresoptimization procedures are available for searching for the local minima.these include direct energy minimization, monte carlo, and moleculardynamics procedures. in energy minimization, the variables describing theconformation are altered system atically so as to lower the energy continuously.the monte carlo method makes random changes in the conformationalvariables and accepts the new conformation according to various protocols thatcompute the energies before and after the random changes in the conformation.in molecular dynamics calculations, newton's equations of motion for theatoms of the macromolecule (subject to interatomic forces determined by thepotential functions) are solved to obtain a trajectory in conformational space.very ef ficient energy minimization algorithms exist, even for functions ofmany variables, but lead only to local minima (however, see the followingsection). conventional monte carlo procedures can overcome local minima buttend not to cover conformational space efficiently enough. however, thisdifficulty is being overcome using modifications that include adaptiveimportance sampling and other efficiencyseeking procedures (gibson andscheraga, 1988). molecular dynamics can also surmount local barriers, but thepi cosecond time scale of practical computations does not approach themillisecond time scale of actual protein folding.because most published papers do not provide the relevant data, it isdifficult to compare the computer time needed for various optimizationprocedures. the required computation time will be very sensitive to how wellthe code is optimized, whether parallel processing is carried out, and otherfactors. to obtain such benchmarks, it would be necessary to run eachprocedure on several different computer systemsša task not yet undertaken.solutions to the multipleminima problem formacromoleculessince no mathematical procedures are available to locate the globalminimum for any macromolecule (except in energy surfacestertiary structure of proteins and nucleic acids: theory74computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.of very low dimensionality), as mentioned above we must first resort toapproximate procedures to obtain structures that might lie close to that of thenative macromolecule. then, the approximations are abandoned, and fullscaleenergy minimization, monte carlo, or molecular dynamics procedure is carriedout. a variety of such procedures have been developed (gibson and scheraga,1988). these include: a ﬁbuildupﬂ method, in which large structures are built up fromensembles of lowenergy conformations of smaller ones (with energyminimization being carried out at each stage); optimization of electrostatic interactions; optimization in a space of high dimensionality where fewer interveningbarriers exist (with subsequent relax ation back to three dimensions); monte carlo sampling among local minima (accompa nied by energyminimization); adaptive importance monte carlo sampling (to drive the system moreefficiently to the global minimum); pattern recognition methods to assemble organized back bonestructures as alphahelices and betasheets; use of distance constraints either from experiment (nu clearoverhauser effects (noes), nonradiative energy transfer, or nmr onspinlabeled molecules) or from statistical analysis of xray structuresof proteins; and empirical methods to predict the locations of alpha helices, betasheets,and betaturns.numerous valid predictions of global minimum structures of peptides havebeen made using these methods (gibson and scher aga, 1988). however, theyhave thus far been successful only for structures that contain at most 20residues, and current efforts (most of which require access to supercomputers)are being made to extend these methods to larger moleculesšto proteinscontaining on the order of 100 amino acid residues.successes and failuresnumerous structures have been predicted and subsequently confirmedexperimentally (scheraga, 1984). the right or lefthanded twists of thefundamental structures (alphahelices andtertiary structure of proteins and nucleic acids: theory75computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.betasheets) from which proteins are built have been accounted for by energyminimization. the observed packing features of alphahelices and betasheetshave likewise been accounted for in energetic terms. parameters calculated forconformational tran sitions (e.g., the helixcoil transition in water) have beenverified by experiment. the computed structures of openchain and cyclicmolecules (e.g., the 20residue membranebound portion of melit tin and the 10residue gramicidin s, respectively), and those of collagenlike polytripeptideshave also been verified by experi ment (scheraga, 1984). finally, the computedstructure of an enzymesubstrate complex (hen egg white lysozyme and a hexasaccharide substrate) (pincus and scheraga, 1979) has been verified byexperiment (smithgill et al., 1984). these and other examples should give usconfidence in the validity of the potential functions and computationalmethodology (gibson and scheraga, 1988).the failures, in the sense of not yet having solved the proteinfoldingproblem, exist because no one has yet used optimization techniques to deducethe threedimensional structure of even a small protein, such as the 58residuebovine pancreatic trypsin inhibitor (bpti). current procedures applied to bptihave not yet yielded a computed structure that comes closer to the xraystructure than 23 å. several procedures that work to overcome the multipleminima problem on small molecules become compu tationally intensive as theyare used on larger molecules. however, the increasing use of supercomputerswill help overcome this prob lem.impediments to progressalthough supercomputers will allow larger calculations and thus coverconformational space better, workers in this field will need additional time to beallotted on these machines to do the research necessary to achieve greaterefficiency. parallel processing offers a breakthrough, and this will require newsoftware to take advantage of the hardware enhancements. with new hardwareand software, it should be possible to surmount the major hurdle created by themultipleminima problem. however, it is conceivable that bottlenecks maydevelop as we attempt to scale up procedures that work on 20residue segmentsto proteins containing 100 to 200 residues. we will also need imaginative newapproaches to overcome this problem.tertiary structure of proteins and nucleic acids: theory76computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.potential functions should be improved, especially those forpolynucleotides and prosthetic groups, and for waterwater inter actions, butthis is not now the most serious problem. certainly, this problem should beaddressed again when the multipleminima problem is solved for bovinepancreatic trypsin inhibitor.finally, new developments will be needed to bring molecular dynamicsfrom the picosecond to the millisecond time scale.future prospectsat every stage in the development of conformational energy calculationsover the past 25 years, we always seemed to face in surmountable obstacles.however, the steady progress during this period indicates that many of theseobstacles have been overcome. the remaining major hurdle is the multipleminima problem (gib son and scheraga, 1988), but we have an array ofpossible solutions to it. the solutions have worked for small molecules, andcurrent and impending developments in computer hardware and softwareshould justify our confidence that, within 5 to 10 years, we may ex pect tounderstand how interatomic interactions dictate not only the final foldedstructure but the pathways taken by the newly formed polypeptide chain toreach the native structure.molecular dynamicsthe principle behind a molecular dynamics simulation is sim ply theapplication of newton's equations of motion to the atoms of one or moremolecules. newton's equations relate three in dependent quantities: time,conformation (atomic coordinates), and potential energy. as the calculationprogresses and the positions and velocities of the atoms change, the system willtraverse many different states; as the simulation is prolonged, the observedstates together approach a perfect sample of the thermal equilib rium ensembleof all states the system will occupy. the thermal equilibrium distribution mayalso be sampled without considering motion, using appropriate purely statisticalmethods (monte carlo techniques). in principle, a monte carlo calculationmight produce a representative sample using less computer time. noguti and g(1985) indicate how, with knowledge of the secondderivative matrix of thepotential energy, the atomic coordinates can be ef fectively used to speed up themonte carlo process. however, it istertiary structure of proteins and nucleic acids: theory77computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.as yet uncertain whether this accelerated monte carlo procedure produces amore rapid exploration of conformation space of a protein than a moleculardynamics simulation. thus, the molecular dynamics simulation gives us a wayto make theoretical estimates of mean atomic positions and deviations from themean; of rates of motion and conformation change; and of ensemble averages,including thermodynamic functions such as energy, enthalpy, spe cific heat, andfree energy. since free energies can be expressed as equilibrium constants andvice versa, simulations are being used to obtain theoretical estimates ofdifferences of affinity of proteins for small molecules. recent results showremarkably good agree ment with experimental values. major pharmaceuticalcompanies have already noted the usefulness of accurately predicting thesedifferences.molecular dynamics simulations, although simple in concept, were notpractical before the advent of high speed computers. this method of theoreticalchemistry is particularly useful for the study of condensed phases and was firstused to study the structure and dynamics of liquids. later, several investigatorsapplied existing techniques to protein molecules (karplus and mccammon,1983; berendsen [cf. hermans, 1985, beveridge and jorgenson, 1987]). atpresent, several laboratories are active in the field. more are be cominginvolved as the methods are applied to increasingly quan titative studies thataim to reproduce experimental observations as closely as possible in thecomputer model. many investiga tors express the belief that moleculardynamics calculations will soon produce useful predictions of structure,dynamics and ther modynamics of proteins, nucleic acids, and complexes ofthese macromolecules with one another and with other molecules.the simulation requires two pieces of information at the out set: a startingconformation and potential energy function or forcefield. for a protein, currenttechnology requires that the starting conformation be firmly based onexperimental observation: because many conformations exist at local minimumenergy, a conformation that is very different from the correct most stableconformation evolves too slowly to reach the correct conformation in the lengthof a typical calculation.the forcefield is a very simple empirical approximation to the underlyingphysics, which properly should be expressed in terms of quantum mechanicsbut is totally unmanageable in that form. parameters of the forcefields now inuse have been proposed ontertiary structure of proteins and nucleic acids: theory78computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the basis of a variety of experimental data and to some extent on theoreticalconsiderations. overall, the several forcefields proposed by different groups forcomputation of the internal energy of proteins tended to have very similar setsof parameters. recently developed forcefields for waterwater and waterprotein interactions permit the simulation of dynamics of proteins in solution,which is a prerequisite for modeling events at the protein surface, includingmost interactions of proteins with other molecules. (the problems ofdeveloping adequate forcefields are discussed in the following section onﬁsolvation.ﬂ)carrying out molecular dynamics simulations of proteins is very much anart of the feasible, the limiting factor always being the available computingpower. one is always facing the conse quence of an inescapable physical fact:that the most rapidly fluc tuating atomic motions, bond stretching, and bondangle bending vibrations have periodicities of the order of once in every fewfem toseconds (1015 sec). current simulation methodology requires thatperiodic motions be sampled several times per period, and each samplingrequires an evaluation of the system's potential energy, requiring computer timein milliseconds on the fastest machines, cray and cyber 205. clearly,simulations cannot now span a time that is on the biological time scale ofmicroseconds to seconds. unavoidably, molecular dynamics simulations usesim ple forcefields to span a longer time. given more computer time, thoseworking in the field will improve simulations in various ways: use of moredetailed forcefields; longer simulations; simulation of larger systems posingnew physical and biological questions; and application of new, more timeconsuming, dynamics methods to ask different questions about the system. tothose working in the field, the future is bright; ideas and interesting problemsabound, and new computer technology continues to widen the limits offeasibility.resultscollected papers for symposia held in 1984 and 1985 give an overview ofmethods and results of applications of molecular dynamics toproteins.1subsequent work achieved many of thetertiary structure of proteins and nucleic acids: theory79computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.possibilities proposed in these papers, but did not deviate radically from thedirections anticipated at the symposia. the following section summarizesachievements and describes possible future applications and advances. thissection is divided into three parts that cover structure, dynamics and kinetics,and thermodynamics of macromolecules. the section concludes with aprognosis of developments to come.the determination of macromolecular structurethe first molecular dynamics calculations of protein molecules producedtrajectories whose mean atomic positions deviated very significantly from thestarting positions (by rootmeansquare (rms) displacements of severalangstroms), which were known within a much smaller error from xraycrystallography. with the development of better forcefields and the inclusion ofa solvent en vironment or even a complete crystalline matrix that consisted ofsolvent and other protein molecules, the rootmeansquare differ ence of theatomic positions decreased significantly. nevertheless, xray crystallographicstructures, especially after crystallographic refinement, have a precision wellinside this difference. the sit uation appears to be reversed with regard to thethermal distri bution of the atomic positions about their means. except in rareinstances, xray crystallography produces a single parameter for each atom thatrepresents the width of an isotropic gaussian distribution of the atomic center.in contrast, the results of molecular dynamics simulation can be used todescribe in detail anisotropic distributions of any shape, even distributions withseveral max ima. in the one case where results of molecular dynamicssimulation have been compared with anisotropic thermal parameters from xraycrystallography, the agreement was very good. meth ods for introducingtheoretical estimates of thermal restraints into crystallographic structurerefinement are being developed.molecular dynamics simulations show considerable promise of being ableto increase our knowledge of structures proposed on the basis of incompleteinformation, particularly information derived hermans, 985; beveridge and jorgensen, 986; results described in thesesymposium papers are not explicitly referenced in this section. some interestingwork has been reported on nucleic acids. however, the technical difficulties ofworking with tese highly charged molecules much exceed the difficultiesencountered in simulations of proteins; given a limited amount of resources, itis understandable that technically less formidable problems have receivedpriority.tertiary structure of proteins and nucleic acids: theory80computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.from twodimensional nmr. twodimensional nmr produces a set ofdistances between hydrogen atoms, the nuclear overhauser effect (noe)distances; for any given (small) protein, many but not all of these distances canbe assigned to individual atom pairs. regular structures such as helices and betasheets are easily identi fied and assigned to particular segments of the molecule.however, it is seldom possible to obtain a sufficiently large number of thelonger distances that define the relative packing of the regular parts and thestructure of irregular chain segments. in this situation, additional informationmust be brought to bear, an obvious choice for this information being theconstraints imposed on the structure by its chemistry and by the requirement ofadequate interchain ﬁpacking.ﬂ as these requirements are those observed in atypical molecular dynamics simulation, this has led to the development of amethod of molecular dynamics with added constraints, i.e., the noe distances.by varying the importance of the constraints that determine the conformationand varying the tem perature (the total kinetic energy), the structure can bemade to evolve to one with a lower conformational energy. this structure alsomeets the requirements imposed by the noe measurements as well as or betterthan the starting model and may show new distances between hydrogens thatare sufficiently short to be detected in the noe measurement, but whoseassignment had been ambiguous (see also the section on ﬁtertiary structures ofmacro molecules using nmrﬂ in this report).spectroscopy/kinetics and molecular dynamicsmolecular dynamics is a unique tool for simulating time dependentprocesses in condensed systems. the problem of eval uating the timedependence of motion of a protein is formidable. because of a lack ofsymmetry, each atom introduces molecular motion at three new frequencies(normal modes), each of which may be distributed over all atoms. this bothoverstates and un derstates the situation: it is an overstatement because the frequencies of many normal modes (e.g. bondstretching modes) are predictableand correspond to localized vibrations; it is an un derstatement both becauseeach conformation of minimum energy (that contributes to the thermalensemble) contributes its own set of normal modes, and because transitionsbetween conformations, across energy barriers, produce additional motion. thisadditionaltertiary structure of proteins and nucleic acids: theory81computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.motion is usually not a periodic oscillatory motion, but one gov erned by thestatistics of barrier crossing.the highfrequency oscillations of a molecular dynamics tra jectory areeasily determined, but are also the least interesting type of motion. slowermotions are far more likely to be relevant to biological function. these typicallyinvolve many atoms and have large amplitudes, which are also expected ofmolecular motions required for the macromolecule's biological function,although not every lowfrequency mode will be significant in this respect.important motions that have been studied by simulation in clude the hingebending of lysozyme and the internal breathing motions necessary to transportoxygen to reach the active site (heme group) of myoglobin and hemoglobin.the hingebending motion is typical of that presumably required for manyenzymes to accept a substrate in the active site and release the products ofcatalysis. because of the low frequency of these motions, the hinge bending wasnot simulated by a direct molecular dynamics calculation. instead, its frequencywas estimated by combining an analysis of the potential energy required to bendthe hinge region with hydrodynamic considerations. in contrast, the breathingmotion of myoglobin was observed in a molecular dynamics sim ulation of 100picoseconds (1010sec) to have a period of roughly 30 picoseconds. it wouldhave been missed had its frequency been only twice as large.the motion of carbon monoxide in hemoglobin following thephotodissociation of carbon monoxide hemoglobin has been sim ulated withmolecular dynamics (henry et al., 1985) to compare the results with extensivespectroscopic experimental studies of the events that follow this reaction. theagreement is very good; a striking result of the simulation was the considerablelocal in crease of atomic thermal motion that follows the absorption of thephoton and breakage of the hemeco bond. this increase in ther mal motionhas a very significant effect on the early kinetics, i.e. during the time requiredfor the excess kinetic energy to dissipate into the protein and then into thesolvent.case and mccammon (1986) have analyzed the dynamics of ligands in theinterior of the myoglobin molecule, with emphasis on the details of the passageof the ligand molecule into and out of the heme pocket. this movement ofoxygen is an example of a process requiring passage of the system over a (free)energy barrier. the breathing motions of myoglobin appear to open passages orgatestertiary structure of proteins and nucleic acids: theory82computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.that, when open, allow probes (and by implication, oxygen) to move back andforth between cavities inside the protein (tilton et al., in press).very few thorough investigations have been conducted of such gatedevents. the best is a study of the manner in which tyrosine rings inside proteinsrotate by 180°, a process for which exper imental information is available fromnmr spectroscopy. this rotation is an essentially stochastic process, asopposed to the regularly occurring oscillatory motions, and can occur onlywhen the protein assumes particular favorable local conformations, incidentally, in the course of its internal vibrations. this is often described as aﬁgatedﬂ event. the kinetic process is best studied by placing the protein in agateopen conformation and determining the relaxation, during which theotherwise rare event (i.e. ring flip) may take place with a good probability(gosh and mccam mon, 1987). because the trajectories are reversible, therequired kinetic information can be extracted. a difficulty of these studies isthat the scientist chooses what parts form the gate and how it opens. as thiswork has been refined with careful attention to detail and use of improvedpotential functions, the model's kinetic parameters have tended to approach theexperimentally observed values. however, because the motion is so localized,this study of tyrosine ring flips may be the only welldeveloped example of itskind. we seem far from being able to analyze the kinetic path ways withmolecular dynamics, let alone predict rate constants, for the biologicallyimportant conformation changes of allosteric proteins, in which many residuesreadjust their conformation and parts of the protein may undergo relative shiftsin position of many angstroms.many interesting conformational relaxation processes of proteins are tooslow to be directly accessible using current techniques of molecular dynamicssimulation. however, there is a range of fundamental interest (1012 to 109 sec)that can be studied by both molecular dynamics and nmr spin relaxationspectroscopy. we believe there is substantial opportunity for productivecomparison of nmr and the results of molecular dynamics simulation.perturbed nmr resonances for spin onehalf nuclei relax primar ily because ofmodulation of dipolar interactions by global and internal molecular motion.resonances in nmr spectra can also be assigned to discrete sites and, in caseswhere the geometry of the dipolar interaction is well defined, time scales formotion at atertiary structure of proteins and nucleic acids: theory83computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.particular site can be extracted. although relaxation mechanisms can be verycomplex, especially for protons, useful analysis should be possible in somecases. use of13c nmr can, for example, simplify relaxation time analysis,because most relaxation interactions occur with directly bonded protons(wagner and bruhwiller, 1986). it is also becoming increasingly possible tointroduce amino acids enriched in13c at specific sites. nmr of13cenrichedproteins and peptides offers substantial possibilities for extraction ofexperimental time scales of motion in the 1012  109 range for verification oftheoretical predictions.when motion of groups or relaxation interactions are complex, moleculardynamics simulations may also improve the interpretation of nmr data. here,levy et al. (1981) have shown that it is possible to construct appropriate dipolarcorrelation functions from states sampled in a molecular dynamics simulation.in prin ciple, this allows calculation of nmr relaxation parameters that can beused to validate models used for interpreting nmr data. thus, the improvementof molecular dynamics simulations and the development of experimentalmethods for determining structure may prove symbiotic. carrying out this dualstrategy will require substantial investment in producing an accurate descriptionof spin relaxation, as well as coordination among those developing simulationprograms.thermodynamics of macromoleculesphysicists have known for a considerable time about techniques tocalculate equilibrium thermodynamic properties from molecular dynamicscalculations. the techniques have been ap plied to proteins very recently, butalready their use has shifted the emphasis of the simulation field to calculationsof free energy dif ferences. several factors explain the great current interest inthis application, the most important being the availability of many preciseexperimental data for a variety of equilibria that involve biologicalmacromolecules and the unexpectedly excellent theoretical estimates that thesimulations produce. the first successes were obtained in studies of thehydration of small molecules and ions, in which the free energy of transfer of asmall molecule to bulk water could be compared with accurate experimentaldata (see following section on ﬁsolvationﬂ).an important feature of the ongoing research program ontertiary structure of proteins and nucleic acids: theory84computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.macromolecular equilibria is that investigators are carefully iso lating a smallsubset of the global problem to avoid overwhelming available computers. forexample, in studying enzyme inhibition equilibria, mccammon's group is usingmolecular dynamics simu lations to estimate the differences in binding freeenergy of a series of small inhibitors to the enzyme trypsin. a completecalculation consists of two parts, one in which one substrate bound to theprotein is replaced with another, and one in which the first substrate solvated inwater is replaced by the other. as can be seen from the followingthermodynamic cycle (e is enzyme, s1 and s2 are two different substrates),the difference of the two free energy changes obtained from thesimulations (indicated by vertical arrows) is equal to the difference of freeenergy of binding the two substrates to the enzyme (indi cated by horizontalarrows). the agreement between theory and experiment is of the order of a fewkj/mole, which amounts to a factor of two to three in the equilibrium constant.these methods are easily adapted to the estimation of differences in affinity ofsubstrates and inhibitors caused by alteration of the enzyme by sitedirectedmutagenesis (e.g., bash et al., 1987b). in one study of the interaction of aprotein and a small molecule, the binding of xenon gas to myoglobin, hermansand shankar (1987) found that the molecular dynamics simulation was able togive a direct estimate of the binding equilibrium constant, which was within afactor of two of that observed experimentally.similar methods are being used to study conformational equi libria ofmacromolecules. most thoroughly studied are conformational equilibria of thealanine dipeptide, a wellknown low molecular weight model of a polypeptide.the most important result concerns the equilibrium between two conformations,al pha and beta, which correspond to different helical structures of polypeptides.in an environment of water molecules, simulations performed by two groupswith different methods gave similar results: a preference by a factor of two tofive for the (extended)tertiary structure of proteins and nucleic acids: theory85computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.beta conformation. experiment indicates, imprecisely, a value of around 10.prognosis of developmentsthe success of the free energy simulations has suddenly changed the scopeand emphasis of molecular dynamics simulations. the early simulations eitherclarified properties of proteins that were difficult to study experimentally(kinetics and dynamics on the picosecond time scale) or else gaveunsatisfactory agreement with experiment (mean atomic positions). however,free energy calculations suffer from neither of these problems. in addition, theresults are in a field that is traditionally of great interest to biochemists.biochemists routinely and accurately achieve exper imental determination offree energies of binding (from binding equilibrium constants) of inhibitors andsubstrates to enzymes. furthermore, the agreement between theory andexperiment is so good that molecular dynamics simulations are widely believedto be a useful tool to predict the inhibitory power of new compounds. this toolwill at least screen out a large fraction of possible in hibitors, and therebygreatly reduce the synthetic work required in the search for the perfect inhibitor.replace ﬁinhibitorﬂ with ﬁdrug,ﬂ and one realizes the potential of these tools.add to this the possibility of predicting the properties of genetically alteredproteins produced by the biotechnology industry and the demand for such toolssoars.this new application has created sudden and perhaps unex pected demandsfor computer time for two reasons. first, investi gators suddenly have aseemingly limitless number of technologically and biochemically interestingquestions to answer; one may envision the possibility of rationalizing theinhibition constants of all studied inhibitors of any one enzyme and its mutants(the latter designed and manufactured in the laboratory on order). second, as theemphasis has shifted from problems of structure and dynamics to problems ofequilibrium thermodynamics, there is less reason to analyze the details of mosttrajectories and conformations. this is because free energy simulations typicallypass through a series of artificially constructed intermediates that are physicallyun realizable. thus, each researcher will be able to perform more simulationswithout being overwhelmed by the time requirementstertiary structure of proteins and nucleic acids: theory86computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.of analyzing the results. consequently, one researcher can more effectively usemore computer time.accordingly, progress in free energy simulations, although po tentiallyvery rapid, is heavily limited by available computer time. as recently as 5 yearsago the demands of these calculations ex ceeded the available computer power.at present, each of several research groups is using hundreds of machine hoursof cray time. in addition, a number of groups have been able to acquire stararray processors, which may have the power of a cray but a much lower price.dedicating one or more array processors full time to the single task ofmolecular dynamics is extremely efficient in terms of total cost of hardware andprogramming. similarly, the economics of building a hardwired specialpurpose machine for molecular dynamics may be justified in terms of theeconomics of building and operating several copies of the final product, andsuch a machine is almost complete. in spite of these rapid developments, thescope of freeenergy simulations is still severely limited.within a short time, we will need a radical increase in computer time torealize possibilities that are now clearly defined. an immediate 10fold increaseappears needed, and does not seem an extravagant objective with properplanning (i.e., duplicate existing hardware that is already programmed andotherwise inexpensive). the pharmaceutical and biotechnology industries willmake some investment since companies' efforts at rational drug design requiresimulation capability that works in parallel with nmr and xray determinationof physiologically crucial enzymes.apart from drug and protein design, others within and out side of industrywill apply these techniques to the broad problems of proteinprotein and proteinnucleic acid recognition, by using a combination of molecular dynamicssimulations and the results of sitedirected mutagenesis. once we have dealtwith the problem of rationalizing these equilibria in terms of molecularinteractions in atomic detail, our attention will shift to the application of thenewly acquired skills to problems of the dynamics of interaction of proteinswith other molecules, which will presumably require just as much computertime. in contrast to the protein folding prob lem described in the previoussection of this report, the problem of computer modeling of the dynamics ofprotein interactions can be tackled in a series of small, increasingly complexsteps, each oftertiary structure of proteins and nucleic acids: theory87computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.which solves a discrete problem of immediate biochemical inter est, yet alsoprovides additional insight and experience needed to advance the technicalexpertise.beyond the need for sufficient computer time, we must improveforcefields for proteins, carbohydrates, and nucleic acids by determining bettervalues for the parameters and extending these to include drugtype molecules;attempts should also be made to adapt molecular dynamic techniques in waysdesigned to over come some of the intrinsic imperfections of existingforcefields. at present, there is a disturbing trend towards the development andcommercialization of proprietary software instead of free exchange of programsand subroutines, and there appears to be a parallel development of a proprietaryforcefield. the members of this committee hope that these trends are temporary;the emphasis on commercialization is appearing too early in the scientificprocess. if the trend persists, a national agency should commission thedevelopment of stateoftheart programs and forcefields that would beavailable to all workers.solvation and electrostatics in computersimulation of biopolymersbiomolecular systems function in vivo in an aqueous solutionenvironment. that environment includes solvent as well as a substantialcomponent that consists of a variety of salt ions. because these componentsinteract significantly with each other and typically also with themacromolecular species, this environment can contribute substantially to theobserved state of macromolecules in solution. manifestations of its influenceinclude the relative stability of various macromolecular conformations and thebinding constants that characterize the association of macromolecules with eachother or with other biochemically significant molecules.the simplest effect of water can be thought of as that of a high dielectricmedium that screens the interaction of charged and polar groups. hence, theinteraction is in effect much smaller than the corresponding interaction in theabsence of solvent. however, solvent influence cannot be described solely insuch terms. for example, it has long been appreciated that nonpolar moieties arepreferentially excluded from water, and such ﬁhydrophobicﬂtertiary structure of proteins and nucleic acids: theory88computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.effects have long been believed to be a major component in proteinconformational free energies (kauzmann, 1959). for all po lar interactions,hydrogen bonding in particular, thenet energy is determined primarily by themismatch between shortranged solventsolute and solutesolute interactions. inthe case of the highly charged nucleic acid polymers, the identity anddistribution of solution counterions also seems to be particularly significant.as this brief discussion makes clear, we cannot expect to succeed in thequantitative treatment of biopolymer structure and function without paying dueattention to the molecular role of the solution environment. in particular, wemust take into account the significant role played by the environment indetermining the strength of ligand binding, as well as the relative stability (freeenergy) of thevaried structures that must be encountered during protein foldingand that may accompany function.in the following section, we describe briefly alternative frame works forconsidering environmental effects and discuss the current state of theory in thisarea. we focus our attention on the limi tations of currently available results andmethods, as well as on the potential for significant progress in the near future.finally, we point out important areas for attention in the short term, andcomment on the prospects for successful quantitative treatments in the longerterm.allatom modelingdetailed molecular models for the solution environment take the sameform as those used for the biopolymer as such. that is, the solution componentsare represented as a collection of sites, typically atomic sites, that carry partialelectrostatic charges and are each associated with a spherical shortrangedpotential that accounts for short distance interatomic repulsion and for londonattractive forces. molecular entities are usually specified through sets of bondlength and angle constraints. for water, those models that most successfullyreproduce experimental liquid data (jor gensen et al., 1983) include anadditional charged site that is not aligned with any of the three nuclei of eachmolecule. the sol vent molecules (and ions) then interact with each other andwith macromolecular components by a superposition of electrostatic and shortranged terms.this format for the potential is itself an approximation, andtertiary structure of proteins and nucleic acids: theory89computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the quantitative limitations of this form are not yet completely determined. themost significant limitation is that, in reality, the polarity of a molecule insolution is substantially influenced by its surroundings due to electronicpolarization. for hydrogenbonded liquids such as water, it is known that asuccessful nonpolarizable model must include electrostatic site charges for eachmolecule that correspond to an increased dipole moment with respect to the gasphase; the increase represents the average additional polarization induced byneighboring molecules (stillinger, 1975). such effects appear, in principle, forall components of the solution, including macromolecular species. although wehave no evidence that the neglect of explicit polarizability is now limiting thepredictive power of such models, it should be kept in mind as a potentiallimitation to quantitative prediction. whether such effects are included inmodeling efforts is limited primarily by computational rather than theoreticalcapabilities, so even in the worst case, such effects can eventually be added later.carrying out any computational study of macromolecular be havior takingfull atomic account of the solvent is an extraordi narily demanding task, sincethe surrounding solvent constitutes most of the whole system. in the presence offinite concentrations of ions, the problem is substantially more difficult, since inthat case, the solvent associated with ionic dilution must be included as well (25ion pairs require 15,000 water molecules to dilute to 0.1m). such a computersimulation study remains at least an order of magnitude beyond what is nowfeasible. nevertheless, consider able progress is being made in simulatingmacromolecular systems and related model compounds, taking full account ofthe solvent environment. this progress is due in large part to the vast increasein available computational power.in particular, in the area of model systems, this power has per mitted a fewstudies of small molecule conformational equilibrium (jorgensen, 1982;rosenberg et al., 1982; zichi and rossky, 1986) and one direct investigation ofthe conformational free energy of a dipeptide (mezei et al., 1985). carrying outsuch studies requires specialized sampling techniques, termed umbrellasampling, that allow the accurate determination of relative populations ofconformers that are separated from one another by significant free energybarriers. such techniques and their efficient use are the products of recentresearch on simulations of molecular model systems.tertiary structure of proteins and nucleic acids: theory90computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the results of these studies are consistent with the limited experimentaldata available, as documented in the cited reports. a few other studies havebeen carried out on peptides in water without any attempt to fully exploreconformational space (brady and karplus, 1985; hagler et al., 1980a).recently, a number of studies have been carried out that aimed to evaluatedirectly the relative hydration free energies of small molecules, amino acids,and nucleotide bases (bash et al., 1987a; jorgensen and ravimohan, 1985;lybrand et al., 1986; singh et al., 1987). such studies are essential forcalibrating the potentials in use. these relative free energy quantities areamenable to calculation using a thermodynamic perturbation approach, anothertool added recently to simulators' methods (postma et al., 1982).the results of the studies are encouraging in that the investi gatorsobtained relative free energies within about 1 kcal of exper imentaldeterminations. although this level of accuracy may not be sufficient todetermine quantitatively the stability of systems involving many such groups, itstrongly suggests that the potential functions are sufficiently close to being rightthat relatively small adjustments may adequately finish the job.similarly encouraging results have been obtained in small model systembinding equilibria. studies of relative affinities of ions for a cyclic ionophore(lybrand et al., 1986) and of base pair stacking and hydrogen bonding (bash etal., 1987) have been carried out. in the latter case, the results do not agreequantita tively with experimental estimates but are, again, close enough towarrant optimism.in parallel, several groups have carried out true macromolec ular bindingstudies. these will be discussed in detail in the following section on moleculardynamics of biopolymers.in the area of globular protein structureper se, several at tempts have nowbeen made to compare the structural and dynamic behavior of the hydratedmodel to experimental hydrated crystal structures and to the results obtained inthe absence of solvent (krüger et al., 1985; teleman, 1986; van gunsteren andberendsen, 1984; van gunsteren and karplus, 1982; van gun steren et al.,1983; wong and mccammon, in press). the results of these studies areencouraging in that they show that the ad dition of solvent makes simulatedstructures agree better with experimental crystallographic atomic positions.significant quan titative differences remain, however. further, for hydrated singletertiary structure of proteins and nucleic acids: theory91computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.proteins, a simulation initiated in the crystallographic protein structure wasfound to produce an increasingly deviant structure (as measured by the r factor)from the crystallographic structure as the simulation proceeds (krüger et al.,1985; teleman, 1986). in a recent hydrated crystal study, similar behaviorappeared to be present (berendsen et al., 1986). one possible interpretation isthat these studies simply sample fluctuations that are not fully av eraged, andthe deviation is only an apparent onešthe simulations are relatively short, lessthan 100 picoseconds. alternatively, for the noncrystalline simulations, thisresult may reflect real differ ences between crystal and solution structures.however, one also should suspect the underlying theoretical interactionpotentials as the source of the deviation, and much more testing is required tonarrow the alternatives.in this context, it is important to emphasize that the state of the art has notyet reached a level where computational complex ity is the only limiting issue,as a simple example can illustrate. although shortrange solutesolvent forcesplay a very important role, we have already noted that the dielectric screeningof solute charges is of substantial importance. in light of this, it is no table thatfor those popular water models for which the dielectric constant has beendetermined, the agreement with experiment is not very good; at roomtemperature the socalled mcy model yields a value near 35 (neumann, 1985),while for the structurally and thermodynamically excellent tip4p model ofjorgensen (jor gensen et al., 1983) one finds about 50 (neumann, 1986), andthe st2 model yields about 120 (steinhanser, 1983), all compared to theexperimental result of about 80. clearly, for the interaction of charges at longrange, such discrepancies would be quantitatively disastrous. this does notimply that results obtained, for example, for polypeptide conformationalequilibria would have comparable relative errors, but it does indicate thatcaution is warranted, and that further model development is necessary.implicit environmental modelingsince the solvent and small ions as such are often not of primary interest, itis in principle simplest to avoid giving an explicit account of the surroundingsolution and treat its influence only implicitly. formally, this can be done byintroducing effective, or socalled solventaveraged, potentials among the soluteatomstertiary structure of proteins and nucleic acids: theory92computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.of explicit interest. the rigorous existence and formulation for such a reductionis well known. however, such effective potentials are not generally representedby only pairwise interactions, but can be resolved into pair, threebody, andother terms. the pair term, for example, is the potential of mean force betweenan isolated solute pair in an infinite amount of solvent. the lack of pairwiseadditivity is present even if the full unreduced system is described by pairwiseadditive potentials. the use of a continuum dielectric model of an ionic solutionrepresents the simplest form of a pairwise additive effective potential, where, inaddition, the pair potential is only roughly modeled.the question is whether pairwise additivity of the effective potentials is agood approximation. the validity of this approx imation remains largelyuntested, although for ionic solutions pairwise additive semiempirical potentialsadequately reproduce experimental solution thermodynamics up to about 1mconcen tration (see friedman et al., 1973 and references therein).current macromolecular modeling of the effects of solution environmentstypically invokes such effective potentials in a relatively crude form. mostoften, an effective dielectric constant typical of a nonpolar, polarizable materialis used to account for polarization screening of electrostatic charges (weiner etal., 1984). in some treatments, a modification to the potential to account forshortrange, molecular, solvent effects is then added in some treat ments(gibson and scheraga, 1967; némethy et al., 1978; hodes et al., 1979a, 1979b;kang et al., 1987). this added ﬁhydration shellﬂ term introduces a free energybonus or penalty associated with the close approach of solute atoms, typicallyproportional to the overlap volume of the first solvation shells of theapproaching polypeptide atoms. this approach is closely analogous to themethod widely used in models of ionic solutions pioneered by friedman et al.(1973).a significant problem of the implicit approaches to solvents now in use isthat they use an ad hoc form for effective potentials, the reliability of which isnot well established. the ability of such potential functions to produce correctquantitative results for protein/nucleic acid systems is obviously difficult toassess since the system is complex, with many theoretical parameters andrelatively little experimental data for comparison. however, g and scheraga(1984) have demonstrated that such approaches are useful in analyzingdifferential hydration effects in specifictertiary structure of proteins and nucleic acids: theory93computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.cases. the current procedure is to establish the parameters for the potentialsfrom the thermodynamics of hydration (némethy et al., 1978; hodes et al.,1979a, 1979b; kang et al., 1987); this procedure is valid at the present stage.however, in the near future, we should emphasize more direct comparison tospectroscopic and nmr results for small molecules such as oligopeptides.in fact, some skepticism of the current forms of the potentials is warranted,given the results obtained for the most simple so lute systems. it is known, forexample, that for ionic solutions, a detailed molecular solvent treatment of theinterionic potential of mean force does not closely resemble the hydration shellmodel, although both are consistent with observed thermodynamics (pet titt androssky, 1986). the true effective potential exhibits large oscillations as afunction of distance. the minima are shifted in spatial position compared to thesimpler model, but the depth of the alternative potentials appears to comparefavorably. hence, the hydration shell model may be a viable way to estimatesolvent effects associated with native versus completely unfolded states, but notfor intermediate structures. this last hypothesis is consis tent with the use ofaqueous thermodynamic data to parameterize the potential. it is clear that thefolded state prediction per se is of great import in the a priori prediction ofprotein structure and function.recent efforts to generalize the molecular solvent theory avail able forionic solutions to the atoms that make up peptides appear promising (pettitt andkarplus, 1985; pettitt et al., 1986), but no quantitative comparison toexperimental data has yet been made.even if we accept a purely continuum fluid description of the solventenvironment, the issue of dielectric screening itself is a major one. if one isstudying a protein crystal, a small dielectric constant may well be appropriate.however, the use of such a value to determine structures does not seemwarranted. particularly for atomic charges near the solvent interface in a foldedprotein, one expects that the pure solvent value is more relevant. recent work isaimed directly at rigorously examining the usefulness of different distancedependent dielectric functions for such interactions within a dielectriccontinuum picture, but for dielectrically inhomogeneous systems (gilson et al.,1985; klapper et al., 1986). this work may well produce an optimal and wellfounded treatment within the scope of this simplified model.the approach for nucleic acid modeling is less refined thantertiary structure of proteins and nucleic acids: theory94computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.for proteins because of the ubiquitous charges and requisite coun terions presentin solutions of nucleic acids. for these macromolecules, it is insufficient to dealwith solvent alone. current ap proaches have considered various polyioniccharges, solvent, and, in some cases, counterions. in many studies, the polyionicphos phate charges have been artificially reduced to about 25 percent of thephysical value to account crudely for counterion association (hingerty andbroyde, 1982; tidor et al., 1983). this value arises from the counterioncondensation formalism, which describes a required fractional counterionscreening for counterions that are far from the polyelectrolye (manning, 1978).this approach is a valuable qualitative tool, but we do not expect quantitativeresults from such a strong approximation.only recently have initial allatom studies of polynucleotide ionsolventsystems been carried out (corongiu and clementi, 1981; seibel et al., 1985; vangunsteren et al., 1986), but it is clear that the exceptionally timeconsumingnature of these simulations with ions present does not yet permit suchcalculations to be very informative in practical ways. to simulate a duplexoligonucleotide without added salt for 2 nanoseconds (a relevant motional timescale for the polymer) would require roughly 1,000 hours of supercomputer time.in the case of nucleic acids, an intermediate ground state exists that is notrelevant for many proteins. that is, the set of explicitly simulated atoms can beextended to include the macromolecule and ambient ions, while retaining theimplicit treatment of only the solvent. in terms of the number of atoms to befollowed, the simplification is substantial.in any of the cases discussed above in which the solvent is treatedimplicitly, one still must implement realistic potentials of mean force, or, atleast, invoke a firmly based dielectric continuum treatment. since the potentialpayoff of knowing viable implicit solvation routes is very large, it is importantto encourage research into implicit modeling in biopolymer related systems.a potentially useful approach to the ionic atmosphere that avoids even theintermediatelevel treatment of ions is the implementation of solvent and ionaveraged potentials within the biopolymer. the use of reduced phosphatecharges is an ad hoc form of such a potential function. an oversimplified butwellfounded alternative is the use of a debyehückellike screening betweenpolymer sites (hesselink et al., 1973; manning, 1978;tertiary structure of proteins and nucleic acids: theory95computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.soumpasis, 1984), employing the bulk solvent dielectric constant. the latterapproach cannot, however, account for the unusually high degree of ionicassociation that is present in the immediate vicinity of a polyion.another unusually promising approach involves applying more analyticaltheories for the influence of the solution environment, while retaining a detaileddescription of the biopolymer. in essence, one evaluates the effective potentialsthat govern the intrapolymer interactions for fixed polymer configuration by(numerically) solving the relevant equations of an essentially analytical theory.an example of significant recent progress along these lines is the work of packand coworkers (klein and pack, 1983). they have used an algorithm forsolution of the poissonboltzmann equation for the ionic distributions around adetailed dna model, and from such distributions the relevant free energies ofdifferent conformations are, in principle, obtainable. at least for simplifiedmodels of dna, the poissonboltzmann mean field theory has proved accuratecompared to computer simulation for the same mod els (murthy et al., 1985).closely related approaches have been considered for enzymesubstrate bindinginvolving charged species (klapper et al., 1986). however, a poissonboltzmann treatment is tied to a dielectric continuum view of the solvent,although dielectric heterogeneity can be readily accounted for within thiscontext.a brief comment on biopolymer dynamics is appropriate here. dynamicsare clearly connected to the general question of protein folding, and are likely tobe significant for function in many cases. although molecular dynamics maynot be directly related to the issue of predicting function, it is clearly connectedto the more general question of protein folding. as for the equilibrium timeindependent problem, one can, in principle, consider the full atomic description.however, one can also focus only on an explicit subset of solute atoms, such asbiopolymer or biopolymer plus ions. the formal theory to be applied when onlysome of the atoms are considered explicitly is well established (for recentdiscussions in a variety of contexts see: adelman, 1982; ermak andmccammon, 1978; tully, 1981). the motion proceeds according to the forcesprescribed by the effective potential, but with additional random forces andfriction due to the implicit solvent collisions. in general, these solvent forces arenot simple, but depend on the history oftertiary structure of proteins and nucleic acids: theory96computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the solute dynamics (memory) and the current solute conformation(hydrodynamic interaction). in the general case, the relevant equation is the socalled generalized langevin equation with the friction described by a memoryfunction that embodies the sta tistical properties of the solvent collisionalcorrelations in space and time. the approximation that neglects any frictionalcorrelation involves only constant drag coefficients, the socalled ordinarylangevin equation. further approximation leads to equations of a diffusion type.as with most areas of theory in physical science, the timedependenttheory lags behind the equilibrium theory in terms of development andapplication. a few examples of attempts to ap ply these methods to realistic andsimplified models exist (levy et al., 1979; mccammon et al., 1980) but onlyonce does it ap pear that a polypeptide has been examined (brooks and karplus,1986). the problems encountered in any application involve, first,computational limitations, since the dynamics that are of biochemical interestare relatively slow. perhaps more significant is our extremely limitedknowledge of the memory function and hy drodynamic interactions for acomplex solute. in principle, we can test our assumptions against allatomsimulations or the relevant functions extracted from these simulations, but thisroute is itself limited by the current sparsity of the requisite simulations. nevertheless, future developments in this area seem very likely, although they arefurther away than are those in equilibrium theory.conclusionsthe ability to adequately test predictions of theoretical calcu lations is anelement of overriding importance in the future of the modeling of solvation andelectrostatics. this testing can occur at two levels: first and foremost bycomparing theory and experiment and second, by comparing results obtainedthrough convenient but approximate theory with those derived from accuratetheoretical treatment. the first is essential for accuracy and the second for thefuture development of viable theoretical methods for studying increasinglycomplex systems. therefore, we should continue to encourage both experimentand theory for both macromolecular and smaller model compounds.we cannot expect an immediate and completely satisfactory way toaccount for the influence of the solution environment ontertiary structure of proteins and nucleic acids: theory97computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the behavior of macromolecules. the above discussion indicates that someunsolved and many partially solved problems remain. nevertheless, reasonableapproaches already exist that provide adequate grounds for qualitative study.the degree of quantitative accuracy is not yet well established and awaits bothfurther model calculations and further thermodynamic and spectroscopicexperimental data, so that we may make unequivocal comparisons betweentheory and experiment. based on the steady progress described above over onlythe past few years, we have every reason to expect rapid incremental progress tocontinue. a clear view of the capabilities of current models and methods fordescribing flexible small molecules should be available within only a few years.at the same time, the large amount of theoretical activity both in thedevelopment of wellfounded approximate approaches and in the simulation ofatomiclevel solvated molecules virtually assures our ability to make theappropriate comparisons between the two in the near future. a very significantelement in recent developments has come from algorithmic breakthroughs.biased sampling techniques and thermodynamic perturbation/integrationmethods are two new methods that contribute essential capabilities to thetheoretical effort. hence, we should encourage theoretical developments asmuch as computational applications.the rapidly increasing access to the necessary computer facilities hascontributed significantly to progress, and it is essential that this access continueto grow. for allatom models of the environment, the current limitations onmacromolecular simulation are primarily computational. although limitationsof the model theory are also likely, we now have insufficient data to make thatjudgement. an orderofmagnitude increase in available computing powerwould be enough to make a dramatic difference in this area; two orders ofmagnitude would permit simulations into the interesting manynanosecondregime. such changes are likely within the next five years through thecombined effects of new hardware, improved performance, and lower cost.to explore adequately events such as protein folding that occur on muchlonger time scales (or involve vast conformational exploration), thesecomputational improvements would still be inadequate by many orders ofmagnitude. thus, a theoretical breakthrough appears necessary if we are tomake real progress within the next several years. such a breakthrough wouldbe, for example, the demonstration of an implicit treatment for thetertiary structure of proteins and nucleic acids: theory98computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.solution environment that yielded accurate biopolymer dynamics on ananosecond time scale when compared to a full atomiclevel simulation. such atreatment could then be applied for longer times.considering the very limited knowledge available about the performanceof alternative implicit modeling techniques, we can not now say whether suchan approach is workable, even in prin ciple. however, the process ofdetermining the usefulness of these techniques requires a one to two orderofmagnitude gain in computer power.in summary, the rapid progress in our ability to describe the environmentalaspects of bipolymer systems gives solid ground for optimism that this elementof biomolecular modeling will not impede development of useful predictivemethods. however, for the most challenging aspects, we are at least severalyears away from demonstrating the ability to mimic accurately solutionenvironmental effects.heuristic methodsthere are two major approaches to the prediction of threedimensionalstructures of proteins: modeling by extension and hierarchical searching. bothmethods can combine heuristic ideas and energy calculations. they differ fromthe energy calculations described earlier and from each other in the way theyarrive at starting structure. modeling by extension uses the known structure of aprotein or proteins with strong sequence homology to the unknown. thehierarchical methods use packing considerations derived from thecrystallography of many proteins. the following section describes theseapproaches in more detail.homologyprotein homologyproteins occur in families. evidence for this comes first from proteinsequence homology and then from the architectural simi larity of homologousproteins determined by xray crystallography and nmr spectroscopy. a familyof proteins can be modeled by homology if several conditions are fulfilled. firstand most important, the structure of at least one member of the family musttertiary structure of proteins and nucleic acids: theory99computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.be known. second, the threedimensional protein to be modeled must besufficiently homologous to that of the known protein. many proteins have beenmodeled over the past five years, and the general consensus is that if twoproteins share at least 30 per cent similarity, then computer graphics and energymodeling will be useful. if the global homology is less than 30 percent, then itis difficult but not impossible to say whether the two proteins are in the samefamily. if there are important conserved residues such as disulfide bridges theneven 30 percent homology might be sufficient.the difficulty of modeling a given protein depends on the range ofhomology with the known structure. when the homology is between 80 and 100percent, normally only the surface amino acids are changing. in these cases,there is usually no change in peptide length. with homology of between 50 and80 percent, again, mainly the surface amino acids are changing, but there maybe additions and deletions in the peptide length. the amino acids on the surfaceof the protein can be easily substituted. energy minimization and/or moleculardynamics are sufficient to reduce the errors caused by any changes in surfacesidechain conformation. surfacecharged amino acids under moleculardynamics ei ther must be neutralized by artificially altering the parameters or byadding a solvent box about the protein.when interior amino acids are changed from one protein to another, thechanges are either to make a long amino acid shorter, thus creating a hole in theinterior of the protein, or a longshort pair of amino acids are changed to a shortlong pair of amino acids.when amino acids are added or deleted in a helix, they are generally inmultiples of three amino acids. this preserves the hydrophobicity/hydrophilicity relations in the helix. in contrast, beta strands tend to haveinsertions or deletions of two amino acids, thus preserving the inside/outsiderelations (feldmann et al., 1985). the inside amino acids of a protein normallyare hy drophobic, while the outside amino acids are normally hydrophilic.graphic modeling of such changes is accomplished by moving the additionsand deletions in helices and beta strands toward the ends of the secondarystructure feature. graphic modeling of loops is easy to do but fraught with largeinaccuracies. insertion or deletion of amino acids on a loop can beaccomplished by breaking the peptide chain, making the appropriate change andthen bendingtertiary structure of proteins and nucleic acids: theory100computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the loop ends to accommodate the change. energy modeling un der localconditions of relatively high simulated temperature can be used to explore thelocal conformational space.there are two ways to align sequences, automatically and manually. theautomatic alignment methods such as wilbur and lipman tend to align thesequence for highest local match. man ual methods (see feldmann et al., 1985)permit the alignment of secondary structure features which minimize thenumber of disturbances which must be made to the protein and convert from thecrystallographic structure to the model structure.one of the ways to overcome the uncertainties of the structure of aparticular loop is to build a library of representative loops. alwyn jones atuppsala has done this and recently integrated it into frodo, his modelingprogram.after all the changes have been made either by graphic methods or byusing a loop library, extensive molecular dynamics sim ulation is generally usedto improve the quality of the model. whether a broad range of scientists can usemolecular dynamics calculations depends on the availability of appropriatemodeling software and on a variety of displays and workstations. to completethe modeling by molecular dynamics calculations, sufficient computer powermust be available either on a personal supercomputer (psc) or by networkaccess to a national supercomputer.modeling by extensiontwenty years ago, phillips (1967) made a model of the protein lactalbuminwithout obtaining a single crystal. this was possible because the amino acidsequence of lactalbumin had been found to be 35 percent identical with that ofthe enzyme lysozyme, a protein whose crystal structure had recently beendetermined. the residues for lactalbumin were simply placed in the equivalentpo sitions known to be occupied by the residues of lysozyme (browne et al.,1969).subsequently, warme et al. (1974) underscored the validity of theapproach by computational approaches to the structures of the two proteins. thestructure of alphalactalbumin computed by energy minimization by warme etal. (1974) has recently been verified by xray crystallography (d.c. phillips,personal commu nication, 1987). since then, ﬁmodeling by homologousextensionﬂtertiary structure of proteins and nucleic acids: theory101computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.has become a common if sometimes casually applied approach, that hasbenefited from modern computer graphics (greer, 1985).a recent example of the utility of modeling by extension is that animportant but elusive factor, angiogenin, involved in the biogenesis of bloodvessels was isolated after a search of more than 15 years. the sequence of thisfactor was determined and found to be 45 percent identical to pancreaticribonuclease. as a result, palmer et al. (1986) promptly generated a threedimensional structure.naturally, the closer the resemblance of the unknown protein to the onewhose structure has been determined, the more accu rate the modeled structure.recently, however, moult and james (1986) have shown that it is possible toconstruct good models even when the sequence resemblance is barelyrecognizable. in many instances, then, all that is needed is the familyrelationship of the new protein.exon shufflingmany recently evolved proteins exhibit evidence of ﬁexon shuf fling.ﬂ inthis phenomenon, mosaic proteins result from the ge nomic rearrangement ofsegments that encode small portions of different proteins. for such proteins, it isthought that the peptide segments, which often range from 30 to 90 amino acidsin length, all fold independently (doolittle, 1985); as such, they constitutedomains in the truest sense. as of mid1987, about six such domains had beenfound in a variety of proteins in different threedimensional settings. most ofthem are tightly folded and contain disulfide bonds that hold the structure inplace. they include such wellknown motifs as: the ﬁegf domain,ﬂ theﬁkringle,ﬂ and the ﬁfibronectin fingers.ﬂ they are readily identified by rou tinecomputer searches of sequence, and, when such a structure has been identified,can be immediately modeled in place. exon shuffling, which is due at least inpart to the additional recombination that ensues from the presence of intronsbetween exons, is not restricted to the small set of stable structures listed above,and it is anticipated that hybrid and mosaic proteins of many sorts will beidentified. in all these situations, prior knowledge of any structural motif willaid in interpreting the overall structure. doubtless, other motifs will emerge asmore sequences are determined, compared and analyzed.tertiary structure of proteins and nucleic acids: theory102computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.hierarchical models of protein foldingthe major goal of hierarchical modeling is to build threedimensionalstructures that incorporate directly or indirectly the architectural principles bywhich nature constructs globular proteins. the direct approach uses empiricalrules or models that capture recognized aspects of protein folding. the indirectap proach uses homology to provide the basic structure and explores the localenvironment with energy calculations or other modeling efforts. this latterwork was described in the previous section. here, we assess the success of rulebased procedures.investigators have used these procedures at various levels of formality.these efforts generally follow the same plan: predicting secondary structurefollowed by packing secondary features. they also use the kauzmannhydrophobic model as the basic packing principle. classifying protein domainsby structure has been particularly important because it provides major rules (fora discussion and extensive references see richardson, 1981; cohen et al.,1983). such rules include statements about the geometry of helices packingagainst helices and beta sheets and beta sheetbeta sheet packing. the effortshave also led to the development of a list of rules concerning the ordering ofstrands within a beta sheet. we should note clearly that rules such as these onlysum marize what is observed in known structures; they are not derived fromfirst principles of physics or chemistry. nevertheless, many of the idealizedstructures built to be consistent with such rules do look recognizably likeprotein domains and some are rather close (average error 4 å) to thecrystallographic result.pattern recognition and artificial intelligencewe differentiate the techniques of pattern recognition from those ofartificial intelligence, especially its subdiscipline of ex pert systems. patternrecognition is usually defined as including numerical techniques for clusteringobserved data into binary or higher order categories (but see below). artificialintelligence is usually defined to include use of rulebased systems to expressand use empirical knowledge of a subject.the usual techniques of pattern recognition, such as linear discriminateanalysis, cluster analysis, and other parametric andtertiary structure of proteins and nucleic acids: theory103computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.nonparametric methods, have not proved useful in the analysis of proteinstructures and functions. these methods pose difficulties in determining thestatistical significance of a derived classification. given the relative lack ofknowledge about structurefunction relationships in complex molecules such asproteins, it is very dif ficult even to pick a reasonable set of structuraldescriptors upon which to build a clustering scheme.other definitions of pattern recognition, however, are less controversial intechnique, if not in interpretation of results. these techniques involve, forexample, the presentation of threedimensional protein structures in the form ofcalpha distance maps (kuntz, 1975; rao and rossmann, 1973) to infer thepres ence of secondary and super secondary structures and location of intron/exon boundaries (g, 1981).the technology of expert systems may be applied when em piricalknowledge, which can be expressed in rulebased systems, can be used to solveproblems. for example, production rules of the form if (x) then (y) may bean integral part of a hierar chical pattern comparison described previously(figure 41). to achieve high performance, such rulebased approaches areoften supplemented with methods and data from other sources. two systemsunder development, karma (klein et al., 1986) and protean (hayesrothet al., 1986) illustrate this point. the karma system employs rulebasedproposal and evaluation of small molecules and their predicted bindingactivities in receptor sites of known proteins. a variety of mathematical andgraphic procedures are used to evaluate candidate structures and their affinitiesfor binding. protean uses artificial intelligence techniques with interatomic(nonbonded) distance information from nmr and a variety of mathematical andgraphic techniques to ex plore structural possibilities for proteins of knownprimary structure.cohen et al. (1983, 1986b) have carried out one of the most ex tensiveprojects in their studies of alpha/beta domains and four he lix bundles. in theformer case, they identified secondary features by using pattern matching andthen built tertiary structures from exhaustive combinatorial packing of thesecondary elements. in the most favorable case, flavodoxin, they could generatea unique prediction for the alpha carbons involved in helix or sheet of theprotein. similar predictions for molecules such as interleukin2tertiary structure of proteins and nucleic acids: theory104computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.have been made based on a core structure of four helices (cohen, et al., 1986b).the important strengths of such projects are (1) they achieve lowresolution structures of the central residues of proteins that contain manyprotein features, including a prediction of the ﬁac tiveﬂ portion of the molecules;(2) the computational labor is modest; and (3) the rule system can be testeddirectly against known structures and their homologs. in some sense, they arethe best solution currently available to the folding problem. on the negativeside, the low resolution is an obvious limitation. details of loops are oftenneglected. only certain classes of proteins can be dealt with successfully.the next several years should bring improvements in all as pects. morerealistic models will reduce errors. loops and side chains can be treated eitherfrom rulebased or energybased ap proaches. expansion to more proteinstructural classes is proceeding rapidly. it is difficult to see the ultimatelimitations of these heuristic methods. we are hopeful that they yield good firstorder approximations that can be refined by the energy minimization andmolecular dynamics calculations.tertiary structure of proteins and nucleic acids: theory105computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.7.functional aspects of proteins and nucleicacidswe turn our attention from structural considerations to the more complexquestions surrounding biological function. this section contains discussions ofenzyme catalysis, protein design, and ligand/substrate design.catalysisthe theory of enzyme catalysisenzyme catalysis is one of the most crucial and certainly the mostintriguing aspects of the kinetic behaviors of proteins. the central questionabout catalysis is, which aspects of protein structure and dynamics cause theoften enormous enhancements of rates of reaction over the rates in water? thisquestion is, at best, incompletely answered and at worst very much open. onecan not expect that molecular dynamics, with its use of a classical mechanicalforcefield, will, by itself, provide definitive answers. empirical potentials inmolecular dynamics or molecular mechanics calcu lations are approximationschosen to model thermodynamically stable minima in energy surfaces. catalyticreactions are by their very nature dependent on barriers or maxima in thesesurfaces. not even the form of the potential used in most classical calculationswould be correct. however, it is reasonable to think that thisfunctional aspects of proteins and nucleic acids106computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.problem will eventually be solved by an approach that combines moleculardynamics and quantum mechanical methods. molecular dynamics techniquescan handle the motion of many atoms, and quantum mechanics can be used torepresent events along the reaction pathway at the catalytic site and in thereactants (substrates), that is, wherever chemical bonds are broken and/orformed. recent studies of simple organic reactions in solution by jorgensen (inpress) and studies of enzyme mechanisms by warshel (1986) exemplify thiscombined approach.in work on simple organic reactions in solution, the reaction path has beeninvestigated by a series of ab initio quantum me chanical calculations of thereactants in vacuo in different states of reaction, and molecular mechanical(monte carlo) simulation of the solvation of each state. when combined, theresults of these two calculations yielded estimates of the free energy profilealong the reaction coordinate, from which reaction kinetics can be estimated.although the quantum mechanical calculations did not take into account theresponse of the reactants to the solvent environment, jorgensen (in press)nevertheless obtained very promising results for three different reaction types:sn1, sn2, and addition reactions.parallel studies of enzyme mechanisms pose additional prob lems, simplybecause the systems, including the reacting species, contain many more atoms.except in a few simple reactions such as catalysis by carbonic anhydrase, thesubstrates are much larger than the reactants in the models chosen by jorgensen.also, in many enzymecatalyzed reactions, a chemical bond forms betweenenzyme and substrate in an intermediate product of the reaction. in these casesthe ab initio quantum mechanics calculation, which by its nature is currentlyrestricted to systems of a few atoms, will have to be performed on a fragment orfragments of the chemically reacting species. it is not yet clear how this can bedone without introducing large errors. warshel has introduced the use of a moreapproximate quantum mechanics method, the ab initio empirical valence bond(evb) method, into this problem to replace the quantum mechanicalcomponent. although it can handle more atoms, the evb method initially hadthe drawback of having to be calibrated by simulations designed to predictknown molecular properties. in this instance, acidities of ionizing groups wereused. however, this was done successfully, and warshel and sussman (1986)and hwang and warshel (1987) found that the methodfunctional aspects of proteins and nucleic acids107computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.now can rationalize observations of changes in catalytic efficiency of mutantenzymes. these results emphasize the critical role of stabilization of thereaction's transition state by electrostatic interactions. because of the empiricalcharacter of the evb method and a lack of general experience with it, theseconclusions await confirmation through further study with the evb method andab initio methods.given the great interest in the theory of enzyme catalysis, investigatorshave already begun to apply a combination of ab initio quantum mechanics andmolecular dynamics (rao et al., 1987). this will generate new problems to besolved. as noted, a major problem will be encountered for those enzymereactions in which a chemical bond is formed between enzyme and substrate inan intermediate step. it will also be necessary to establish the magnitude of thesystematic error caused by transfer of a quantum mechanical result obtainedwithout solvation, not only to a solvated situation, but also to a protein activesite environment, where the rates are much enhanced. some very careful workwill be required before this approach can be applied reliably to enzymemechanisms. however, caveats notwithstanding, these studies are worth doing.designing new protein structuresthe following section discusses the future of protein design, which is oneof the key areas of growth in macromolecular modeling.in the same way as levinthal's (1966) pioneering studies initiatedcomputerassisted modeling, richardson's (1981) work on the anatomy andtaxonomy of proteins signaled the transition from molecular archeology tomolecular design, for protein chemists. we call our drug design projectcomputerassisted molecular designšthere are more types of molecules thanproteins. richardson presented a framework for understanding the organizationof protein architecture. this framework condenses the observations of proteinstructure and architecture from individual structure solutions into a form thatallows us to think of protein architecture as manipulable. sitedirectedmutagenesis of protein structure is a simple way of altering proteins withoutreally altering protein architecture. the technique of producing chimericproteins by gross manipulation of gene structure is another early approach to thefunctional aspects of proteins and nucleic acids108computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.manipulation of protein architecture. at this point, the problems involved indesigning new proteins are formidable. consider the process of designing anordinary protease. proteases typically have 250 amino acids. since there are 20amino acids, there are 20250 possible proteins of length 250. the only sensibleway to reduce the number of possible proteins to one design is to use severallevels of decomposition that specify how portions of the protein are to beorganized architecturally, spatially, and functionally. our understanding of therules of thumb triggered by the richardson paper is now evolving rapidly.figure 7 the cycle of protein design and expression.protein design cannot be divorced from the issues of protein expressionand folding. the complete cycle for the design, expression, and folding ofproteins can be represented as infigure 71.to be able to design a protein effectively, one must be able to traverse thisdesign cycle rapidly and often. at present, several important conceptualproblems prevent us from completing this cycle at all. suppose that we coulddesign a hypothetical protein using the architectural concepts. the output wouldbe a threedimensional model of the protein embodying a particular amino acidsequence. given this hypothetical design, the next task would be to construct agene. the problem here is that the amino acid sequence of the hypotheticalprotein, in general, specifies only two of the three bases in each codon of thegene. one way to resolve this issue is to choose a random third base (seefigure 72).functional aspects of proteins and nucleic acids109computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.figure 72 the current pattern of the flow of information in the cycle of protein design and expression.functional aspects of proteins and nucleic acids110computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.once the dna of the constructed gene has been transcribed to messengerrna and edited, there is a linear sequence of threebase codes that, asnirenberg (1965) has described, exist in 64 combinations of the bases.however, the 64 codons code for only 20 amino acids, so there is, at this pointin the cycle, a surplus of information. the ribosome translates the messengerrna codons into nascent polypeptide.the anfinsen (1975) experiment involving the denaturation andrenaturation of ribonuclease has been used to convince us that proteins fold intotheir active threedimensional structure solely on the basis of the informationcontained in their sequence. many scientists have been trying for the last twodecades to predict the secondary and tertiary structures of proteins from theamino acid sequences alone. their efforts have met with partial success at best.we lack information about the protein folding portion of the design cycle. thesurpluses of information (denoted by pluses in the upper portion offigure 72)and the deficiencies of information (denoted by the minuses) can be abstractedto form the cycle pattern in the lower portion of the same figure. clearly, ourcurrent perception of the design cycle is flawed. recent experiments show, forexample, that a gene that is moved from its native host to another expressionvector does not necessarily produce wellfolded proteins. even when the codonutilization statistics of the new expression vector are mimicked, completeprotein folding does not necessarily occur. this suggests that third baseredundancy may be partially used to control protein folding, especially forcomplex proteins.experiments should be designed to explore how third base redundancyinfluences protein folding. with such data, the information from a hypotheticalprotein design could be used to properly construct the dna of a gene. a propergene would then transcribe and translate properly to yield a polypeptide thatfolds properly. if these conditions were met, the design cycle abstraction wouldbe as shown infigure 73.if the information flow around the protein design and implementationcycle is preserved, then it should be possible for protein engineers to rapidlytraverse this cycle in the design and perfection of novel proteins.functional aspects of proteins and nucleic acids111computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.figure 73 the ideal pattern of flow of information in the cycle of proteindesign and expression.computer representationcomputerassisted modeling of molecules has been evolving since theoriginal work of levinthal (1966). his work was the first time that a computer,a pdp1 from the theninfant digital equipment corporation (dec), was usedto draw the threedimensional structure of a small organic molecule. it used oneline segment to represent each chemical bond. with simple software controls,the molecule could be rotated in space and redisplayed. similarly, theconformation of the molecule could be changed by rotating one portion of themolecule around a bond that formed an isthmus between it and the remainder ofthe molecule. the display of the molecule was done in pairs of images wherethe image of one molecule was rotated 5 degrees around the vertical axis. thisproduced a stereoscopic effect that permitted the threedimensional structure ofthe molecule to be perceived without having to rotate it continually. all ofmolecular graphics has simply been an extension and refinement of thesepowerful ideas. the number of line segments drawn per second has risendramatically. color has been added. hardware stereo devices have beendeveloped, and very recently powerful array processors have been added topermit the rapid calculation of molecular energetics during modeling.these techniques for display and modeling were developed and refined ina few academic research laboratories. they began to diffuse to biochemical andgenetics laboratories in academic and industrial institutions worldwide. overthe past 20 years, the manufacturers of computer and graphics hardware havebegun to recognize that molecular graphics and modeling is a substantialmarket. we are now at the critical point in this respect. hardware manufacturersare now willing to design workstations (i.e. integrated computational andgraphics machines for individualfunctional aspects of proteins and nucleic acids112computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.use) for the molecular modeling and design market. a new class ofworkstations is expected in the next year. two members of the class of personalsupercomputers (pscs) have been identified, and collaborations are in place toinsure that these machines, when they enter the commercial market, will befully conditioned ﬁchemistry enginesﬂ. the four functions, molecular energycomputation, molecular configuration control, molecular graphics, andreasoning about molecular structure, will be integrated in one computer system.the pscs will provide a nearly ideal package for mass distribution ofcamd capabilities. market forces can be expected to expand the number ofdifferent machines and the features that each machine offers. standards atvarious levels, as defined by the international standards organization (iso),will permit existing and new program systems to be transported rapidly onto thepsc class members. the standardization efforts will permit a decoupling of thecomputational support systems (i.e. hardware, graphics, operating systems, andthe molecular modeling and design programs) from the intellectual uses of suchsystems.the existence of standards, however, does not guarantee portable programcode. scientists who write new programs must know about these standards andwrite programs that conform to them. commercial organizations that takeexisting scientific programs should shape them towards the standard stylebecause, in the end, the size of the commercial market will depend on the abilityof end users to piece together working systems from components made out ofvarious standard programs. if these standardization efforts succeed, then in thefuture, the molecular modeling community will be able to routinely makesmooth transitions to more powerful computer support systems.computer graphics representations offer alternative ways of understandingmolecular structure and function. they started as the simplest white linedrawings on black screens, then progressed to color images, to solid surfaces, todot surfaces, and to electrostatic surfaces. intergraph threedimensionalrepresentations and white light hologram representations have been developedand used for molecular structure problems. intergraph is composed ofapproximately 20 individual photographs where vertical strips are selected fromeach photograph and composed into one image. the composite image is viewedthrough a linear fresnel lens. thefunctional aspects of proteins and nucleic acids113computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.next generation of workstation, the psc, will offer raytraced images as part ofthe operating system. in a ray traced image the reflections on a surface arecompared by calculating the trajectory of light beams from all possible lightsources. this produces in the extreme the reflections of one object on another.a truly threedimensional representation where the molecule would actuallyoccupy threedimensional space is needed. a breakthrough in a field such asplasma physics is necessary to make this a reality.impediments to progressthe central bottleneck to progress in protein design is our inability topredict protein tertiary structure from amino acid sequence. the notion put forthby anfinsen 25 years ago was that the amino acid sequence alone determinestertiary structure. this notion may be too simplistic, and there may indeed be ahigher level code than the nirenberg nucleic acid to amino acid conversion bythe ribosome. since the anfinsen conjecture and the experimental detailsurrounding it are largely prohibitory in nature, they had the effect ofdiscouraging experimentation in expression and folding of proteins. scientistswho are concerned with protein expression are content with the nirenberg codeand explain away anomolous results because they see no need for any othereffect. scientists concerned with protein folding cannot explain how proteinsfold, but then are discouraged by the anfinsen conjecture from asking for moreinformation from the geneticists. a theory and experiment linking codonutilization in gene structure with the folding of protein structure would be amajor step toward reconciling these views.predicting function from a predicted threedimensional structurein principle, the information needed to predict the function of a biologicalmacromolecule is encoded in its threedimensional structure. we assume thatwe must know the threedimensional structure of a macromolecule before wecan fully understand its function. the problem is, how do we decode the rulesthat govern the relationship between structure and function? a subset of thisproblem will be discussed below: the prediction of the change infunctional aspects of proteins and nucleic acids114computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the functioning of a protein that results from the binding of a ligand.recently, the possibility of computerassisted drug design based on thethreedimensional structure of target biomolecules has received much attentionin the scientific literature (beddell, 1984; goodford, 1984; hol, 1986). those inthe field believe that medicinal chemistry is poised to undergo a revolution asdramatic as the events in the 1950s and 1960s that transformed organicchemistry from a descriptive to a predictive science. since we are at thebeginning of a new age, the many challenges ahead do not diminish theexcitement of knowing that the solutions are also on the horizon. we have asense that, at last, we know what it is that we have to learn and have at least therudiments of the necessary tools at hand.in anticipating this revolution, we are presupposing that we can or soonwill be able to predict the functions of proteins from their structures. inparticular, we would need to be able to predict the ability of a protein torecognize and bind a ligand and to predict the structure of the ﬁoptimumﬂligand. beyond that, however, we would need to be able to predict how theprotein carries out its function and how it recognizes and interacts with othermacromolecules to alter its own functions and theirs. although we have learnedmuch about these topics, there are unanswered questions that we must be able toanswer before we will be able to make accurate predictions.experience in ligand design from experimental proteinstructuresone illustration of our current state of achievement is given by work onhemoglobin. ligands affect the function and properties of hemoglobin incomplex ways. investigators began to attempt to design ligands based on thethreedimensional structure of a protein as soon as such structures wereavailable. in the early 1970s, the group headed by goodford at wellcomelaboratories in england began to explore the possibilities of ligand design byreceptor fit (beddell, 1984; goodford, 1984). they used the structure ofhemoglobin as determined by protein crystallography and constructed a wiremodel that was hinged so that they could examine both the oxy and deoxystates.functional aspects of proteins and nucleic acids115computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the first studies involved the design of ligands (using mechanical models)to fit the diphosphoglycerate (figure 74, compound 1) binding site and then tomimic its function. the investigators used simple concepts of complementaryshapes, electrostatic interactions, and possible covalent bonds. the designedcompounds (figure 74, designated compounds 24) do indeed mimic the effectof diphosphoglycerate on the dissociation of oxygen from hemoglobin.subsequent crystallographic work supported the proposed binding mode. inaddition, the relative binding energy of various analogues to a number ofdifferent hemoglobins was measured for 29 proteininhibitor combinations.statistical analysis revealed a highly significant correlation between the strengthof binding and the number of covalent and ionic interactions. the use ofcomputer graphics for the design would have accelerated this process since ittook three months to construct the physical wire model of the protein.this work was then expanded in an attempt to design a compound for thetreatment of sickle cell anemia. the goal was to develop a compound thatwould affect the oxygendissociation curve in a way opposite to that ofdiphosphoglycerate. an intensive biochemical, physiological, and structuralexamination of the problem suggested that a ligand that binds between the alphasubunits of oxyhemoglobin might have the desired effect. since no naturalligand for this site was known, the ligands were designed from the proteinstructure alone and designated compounds 5 and 6 (see figure 74). althoughthe proposed binding mode has not been experimentally verified, the designedcompounds did produce the expected change in function of hemoglobin. one ofthe compounds is now in clinical trials for the treatment of sickle cell disease.thus, using rather primitive tools, the wellcome group was able to predict theeffect of a small molecule on the function of a protein.the recent experience of perutz et al. (1986) emphasizes both theimportant accomplishment made by these workers and the limits of ourmolecular understanding. perutz and coworkers experimentally demonstratedseveral of the potential binding sites that a molecule might recognize inhemoglobin. specifically, they solved the crystal structure of eight ligandhemoglobin complexes and showed that there are at least six different positionson the protein at which a ligand might form a tight complex. since the ligandswere selected on the basis of their perceived structuralfunctional aspects of proteins and nucleic acids116computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.figure 74 some molecules synthesized to aid in elucidating the relation ofstructure to biological activity of some macromolecules. see text for details.functional aspects of proteins and nucleic acids117computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.similarity, this result must be carefully considered by those who attempt todesign ligands to fit a particular site on a protein. three of the molecules bind insites that overlap; two of these raise the minimum gelling concentration ofhemoglobin s, whereas the third lowers it. each of the bound ligands changesthe structure of the proteins so little that the change is barely detectable, yetsome of the ligands increase the gelling concentration, some decrease it, andothers do not change it at all. this work makes it clear that even after studyingstructure and function of hemoglobin for 25 years, an investigator may still bepuzzled by the functional consequences of the minute structural changes thataccompany ligand binding.the work of perutz et al. (1986) also illustrates that the design of a drug ismore complicated than the mere design of a tightly bound ligand. clofibrateraises the gelling concentration of hemoglobin s. also, it has been usedclinically for other disorders and so is known to be absorbed, metabolized, andnontoxic. yet it cannot be used to treat sickle cell disease because it is so tightlybound to serum albumin that it is not available to bind to the hemoglobin. thelesson to be drawn from this is that when we design a new drug from theoreticalprinciples, we must somehow incorporate the possible interaction of theproposed ligand with all other macromolecules of the body.the work cited and other studies on hemoglobin underscore both thepromise and the challenges in predicting the changes in the function of a proteinthat are brought about by formation of a proteinligand complex. this work alsohighliglits the further challenges of predicting all of the interactions of theligand with the organism.the design of inhibitors of dihydrofolate reductase was aided by the threedimensional structures of the proteins. research efforts of two pharmaceuticalcompanies and their collaborators culminated in the crystallographicdetermination of the structure of the dihydrofolate reductase from severalspecies, some with bound ligands (beddell, 1984; blaney et al., 1984;goodford, 1984). each group designed a trimethoprim (figure 74, compound7) analogue (figure 74, compounds 8 and 9), that was proposed to form a newinteraction with a nearby arginine. goodford (1985) was able to verify thisinteraction (figure 74, compound 8) by crystallography. both new analoguesshow greatly enhanced binding affinity. however, neither shows enhancedantibacterial activity,functional aspects of proteins and nucleic acids118computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.presumably because they do not easily penetrate into the bacterial cell.additionally, neither has any antibacterial activity in whole animals, so they arenot candidates for development as new therapeutic agents. thus, although thiswork did successfully predict the local functional consequences of structuralmodification of a previously marketed drug, it did not predict all of thoseproperties needed to convert a biologically interesting compound into atherapeutically useful one.in summary, efforts to design inhibitors of dihydrofolate reductase haveshown that, although knowing the structure of the target biomolecule is veryuseful when designing a ligand, this alone is not enough information to design adrug. furthermore, these protein structures have been available forapproximately five years, yet neither company has capitalized on them, norhave other research groups used the published enzyme structures to design newcompounds.many other groups have used crystal structures of proteins to designanalogues of known ligands. in an early example, a physical model of lysozymeand a proposed mechanism of its hydrolytic action were used to design atransitionstate inhibitor (goodford, 1984). the compound inhibits the enzyme;it binds 32 times more strongly than the corresponding substrate. the proposedbinding mode has also been confirmed by xray diffraction studies.in the first use of color computer graphics in the design of ligands to bindto a protein, workers at the university of california at san francisco usedinteractive potential energy calculations and molecular graphics to dockthyroxine analogues into the binding site in the crystallographic structure of prealbumin (blaney et al., 1982). they designed and synthesized several morestrongly bound ligands. the predictions were confirmed experimentally. sincethe function of prealbumin appears to be transport of thyroxine, no furtherpredictions of the consequence of ligandprotein interaction were made.experience in ligand design from predicted proteinstructuresprotein structures modeled by homology to proteins whose threedimensional structure is known have also proved useful in the design of novelligands. for example, workers at two different pharmaceutical companies haveused a structure of the enzyme renin that was modeled from other members ofthe asparticfunctional aspects of proteins and nucleic acids119computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.proteinase class (anonymous, 1986; boger, 1986). such models suggested thestructures of new inhibitors. the compounds were shown to be potent inhibitorsin vivo as well as in vitro.approximate target macromolecule structures have also been used todesign new agents. the classic example is the design of captopril (figure 74,compound 9), an inhibitor of angiotensinconverting enzyme and a clinicallysuccessful antihypertensive agent (petrillo, 1982). captopril was designed froma proposed structure of the substrate when bound to the enzyme. the structureof the enzyme was assumed to be similar to that of carboxypeptidase a becauseof mechanistic similarities between the two enzymes.inferring binding sitesmuch of this section has addressed issues related to determining andanalyzing the structures of proteins of known sequence but unknown threedimensional structure. once these structures are known, detailed studies can becarried out of the relationships between those structures and the correspondingfunctions of a protein. proteins express their functions through binding of othermolecules, often termed effectors, with or without concomitant transformationof the effector, e.g., degradation or chemical reactions at functional groups. wehave discussed structure/activity studies of the binding of effector molecules toputative sites in a protein of known structure. a separate body of research hasfocused on a complementary problem: relating the structures of several effectormolecules to one another in order to determine information about binding sites,often termed active sites, in proteins of unknown structure. when such studiesare successful, they can obviously provide structural information about aprotein that can be used in conjunction with some of the techniques for structuredetermination discussed earlier in this report.the general problem of inferring binding sites can be stated simply. givena set of molecules that are presumed to bind to the same site in a given proteinof unknown structure, we must infer the size, shape, and binding characteristicsof the active site. several problems are subsidiary to this general problem. wemention them here, but a detailed analysis is beyond the scope of this report.for example, one must consider the process ofrecognition of the effectormolecules prior to the actual binding infunctional aspects of proteins and nucleic acids120computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the active site. one must consider the possibility of conformational changes ofboth an effector and an active site during recognition and binding. one mustperform very careful studies to ensure that the measured biological or chemicalresponses for several effectors are in fact due to binding in the same active site.a useful introduction to this research area, with leading references, has beenpresented (olson and kristoffersen, 1979).at least three approaches have been used to infer the structure of receptorsites: thereceptor mapping aproach of humber et al. (1979); theactive analog approach of marshall et al. (1979); the dylomms program of wise et al. (1983).these approaches are closely related. all follow the same basic principles,but in different ways. all begin with the assumption that similar effectorspossess relatedpharmacophoric patterns, i.e., similar dispositions in threedimensional space of similar structural features important for binding.independent studies are used to postulate pharmacophoric patterns of activemolecules, generally using the most conformationally rigid molecules to formhypotheses. once such a pattern is assigned, all possible conformations of eacheffector are examined to determine if there are low energy conformations thatpresent the pattern. this both tests the hypothetical pattern and begins buildinga set of molecules that can be superimposed based on the pattern. oncesuperpositions are established, the volume occupied by the molecules can beused to define the cavity of the active site. molecules of related structure thatcan yield the pharmacophoric pattern, but that display no activity, can be usedto define the walls of the cavity, further elaborating its shape.recently, practicing medicinal chemists have become enthusiastic aboutthese uses of computational and computer graphics techniques to compare thethreedimensional structures of ligands that bind to a receptor. they use thecommon features of the aligned structures to propose tentative maps of thereceptor topography. these maps are then used to design new compounds(ghose and crippen 1985; hopfinger, 1985; humblet and marshall, 1981).these techniques have benefited from the knowledge gained through proteincrystallography. in particular, current applications of receptormapping methodsusually compare the location of the projection of ligand atoms to possiblebinding sites,functional aspects of proteins and nucleic acids121computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.rather than identifying the location of the ligand atoms themselves as had beendone previously.the final category of computerassisted prediction of the biologicalproperties of a small molecule is also the oldest. this type of methodology,quantitative structure/activity relation ships (qsar) uses statistical or patternrecognition methods to explore the possible relationship between the biologicaland physical or substructural (presence or absence of certain functional groups)properties of molecules. given the known utility of qsar methodology topredict the potency of untested analogues (hopfinger, 1985; martin, 1981), it isimportant that the developers of this methodology are actively pursuing thechallenge of evaluating the reliability of linear freeenergy equations for casesin which the protein structure is known. in the case of dihydrofolate reductase,several investigators have compared the conclusions from qsar and moleculargraphics modeling of the inhibitors (blaney et al., 1984). the conclusionsderived from the two methods agree closely, confirming the proposal that theqsar equations contain information about the types of noncovalentinteractions between the inhibitors and the enzyme. however, a majoradvantage of qsar over other computerbased methodologies is that one canattempt to develop equations for any biological response. for example,equations have been developed for the enzyme inhibition, antibacterial, andwholeanimal antitumor activity of dihydrofolate reductase inhibitors (blaney etal., 1984). thus, qsar is a logical complement to the more structurebasedcomputer methodologies. it could be used to model the potential wholeanimalactivity of new ligands and perhaps to search for unanticipated interactions withother macromolecules.computer tools for ligand design from threedimensionalprotein structurethe recent excitement in computerassisted drug design has arisen becausescientists now have available the elements of each of the important tools forsuch an activity. two types of computer hardware are necessary: highspeedcolor graphics and affordable but powerful computers dedicated to modeling. inaddition, a growing body of data on the threedimensional structure of proteinsis becoming available, as our understanding increases of some of therelationships between structure and function of proteins.functional aspects of proteins and nucleic acids122computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.finally, software is also available for the graphics display of the molecules andfor modeling the energetics and thermodynamics of the binding.specialized graphics tools for molecular design have also been developed.some of these arose from the related activity of docking a known ligand into aprotein. the display of the surface of the binding site is more useful for liganddesign if it is colorcoded to suggest the preferred type of noncovalentinteraction at that point in space. for example, through such displays we candistinguish between surfaces near positively charged, negatively charged,hydrogenbond accepting, hydrogenbond donating, and hydrophobic regions ofthe protein.another helpful tool used with the graphics display is the immediate readout of energy values as the ligand is docked into a putative binding site and asbonds in the ligand and/or the protein are rotated to facilitate the docking.design of ligands at the computer screen is aided by stereoscopic viewingdevices and implements that allow one to move an object being displayed (suchas a ligand) in three dimensions while keeping the rest of the display as it was.experience has shown that molecular mechanics energy minimizations arenecessary to evaluate the geometry and energy of the proposed complexes(pincus and scheraga, 1979).it was noted previously that one persistent but often hidden problem inligand design is that a ligand may bind to a protein in a different orientation orat a totally different site than the investigator anticipated. kuntz et al. (1982)have devised a computerized means of evaluating such possibilities based onshape alone.the design of a new ligand molecule is aided by the graphics display of theenergetically preferred sites on the protein for interaction with various types ofpossible ligand atoms (goodford, 1985). such sites are identified as the energyof interaction of the probe atom at each point on a threedimensional gridsurrounding a protein. the ligand would be designed to interact at as many ofthese sites as feasible.once a proposed ligand is designed, its thermodynamics of binding can bepredicted with the freeenergy perturbation method if it is a reasonably closeanalogue of a known compound.if there are data on the relative energy of binding of other ligands to theprotein, a qsar or receptor mapping analysisfunctional aspects of proteins and nucleic acids123computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.discussed above may suggest regions on the target that are conformationallymore flexible than the experimental structure may suggest. qsar (or at leastconsideration of physical properties) is expected to also be useful in the designof ligands that will have the appropriate wholeanimal properties.impediments to ligand design from protein structuresproteins are conformationally mobile. they are not the static structuresthat the graphics display of the crystal structure suggests. for example,molecular dynamics calculations on myoglobin have shown that within 300picoseconds, 2,000 different conformational minima are sampled (elber andkarplus, 1987). the rootmeansquare difference in the location of the atoms inthe most different structures is 2 å; this means that many atoms movesubstantially more than that.proteins also change conformation when ligands are bound to them; hence,ligand design methodologies must be able accurately to predict suchmovements. for example, when the antiviral compound vin 52084 is bound tothe human rhinovirus, 13 residues of the protein undergo measurableconformational change (smith et al., 1986b). the main chain moves as much as3 å, the channel to the binding pocket opens to the solution, the isoelectricpoint of the system changes from 6.9 to 7.1, and the occupancy of ca++ at adistant point on the virus increases.conformational responses to ligand binding may be part of the function ofthe protein. for example, in response to ca++, the channelforming proteins ofthe gap junction between cells show small cooperative rearrangements of therelative orientation of the subunits. this rearrangement results in the narrowingof the diameter of the ca++ channel within the cell by 18å and thus closes thechannel to ca++ passage (unwin and ennis, 1984). during this rearrangement,the conformation of each subunit does not change appreciably, only theorientation of each subunit changes with respect to the others.conformational responses to ligand binding may form the basis of theselectivity of ligands for very similar proteins. evidence from crystallography,qsar, and molecular graphics suggests that conformational changes in theenzyme in response to the binding of ligands is responsible for the selectivity oftrimethoprim for bacterial dihydrofolate reductases in contrast to vertebrateenzymesfunctional aspects of proteins and nucleic acids124computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.(blaney et al., 1984). in the chicken liver enzyme, a tyrosine residue moves 5.4å in response to the binding of trimethoprim.since there is no experimentally established threedimensional structure ofa membranebound receptor, for this type of protein we depend on indirectobservation and inference for our notions about conformation andconformational changes in response to ligand binding. current concepts ofreceptor function usually invoke a conformational change as part of thetransduction of the signal of a binding event into the ultimate biochemical andphysiological response. thus, it is possible that the regulatory and secondmessenger binding sites on receptor proteins might become available only in thepresence of the ligand. furthermore, that certain compounds only partiallyactivate a receptor suggests the possibility that a whole family of receptorconformations is available.thus, to use protein structure design a ligand that influences the action of aprotein whose function requires more than one conformation or in which theputative binding site is very flexible, we would like to know the relevant threedimensional structures of that protein and be able to predict the conditionsunder which each is stable. in other words, we would find it difficult to predictthe function of a new ligand unless we had available structures of these proteinconformations. we see this as a problem that will require at least as much studyas the problem of finding the global minimum energy structure.the ligand binds to a protein that is part of a system. in solution, a proteinis part of a complex with water, ions, and cofactors. alternatively, it mayfunction while interacting with a membrane. these other species affect thestrength of binding of the ligands of interest. for example, trimethoprim bindsto dihydrofolate reductase with a 10,000fold increase of affinity in the presenceof its cofactor compared to its absence.the covalent structures of some proteins are modified during the course oftheir function. the large family of receptor kinases are responsible forphosphorylatation of receptors as a means of regulating that receptor function.thus, the addition of a single phosphate group to a protein can dramaticallyalter its function.other proteins are not functional until they are structurally modified aftertheir synthesis. for example, sperm binds to its receptors on the egg only ifthese receptors are glycosylated. additionally, posttranslational processing canimpart subtle variationsfunctional aspects of proteins and nucleic acids125computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.in properties to a protein. for example, it is thought that the benzodiazepinereceptor is the same protein throughout the brain, but that it is glycosylated to adifferent extent in different regions of the brain. these differences inglycosylation are reflected in different relative affinities of the receptor forvarious ligands.thus, for accurate and realistic models on which to base theoretical liganddesign, we need to be able to include such other species in the calculation.unfortunately, there are often not molecular mechanics parameters for suchcofactors and transition metals. including these additional ions and moleculesincreases the complexity and time of the calculation enormously, partly becausethe number of atoms is increased but more dramatically because the search forthe stable arrangement of atoms is much more complicated. this is the multipleminimum problem, but with even fewer experimental constraints on thesolution of the problem. furthermore, we cannot use traditional molecularmechanics concepts for transition metals because they undergo changes inoxidation and spin states that dramatically affect the optimum geometricarrangement of ligands. to include such ions, we need a combination quantumand molecular mechanics calculation. although progress has been made in suchcalculations (warshel, 1981; singh and kollman, 1986), they still needrefinement and testing and tend to be calculations that strain availablecomputers. thus, we see promise that the tools required will be available, butthey are not yet in routine use.there may be more than one binding made for the ligand. the experiencewith the binding of ligands to hemoglobin and the different binding orientationsof methotrexate (figure 74, structure 10) and dihydrofolate (figure 74,structure 11) to dihydrofolate reductase highlight this problem (blaney et al.,1984). the method of matching ligand shapes to protein cavities is helpful inpredicting such alternate binding modes. however, it is currently limitedbecause it considers only the correspondence of the shape of the ligand and thebinding site and not their possible flexibility or electrostatic and hydrophobiccontributions to binding energy. in principle, this problem could be solved byexamining the relative energy of all potential conformations of the protein andthe ligand and all potential relative orientations of the two. as noted above, forsuch calculations water and cofactor molecules and associated ions should alsobe included. even if there are only two conformations of the protein each withtwo binding sites and twofunctional aspects of proteins and nucleic acids126computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.conformations or enantiomers of the ligand, the problem increases eightfold!the challenge escalates when we consider that, in drug design, we would like toconsider many possible analogues for synthesis. thus, much more sophisticatedtechniques for pruning conformational and orientation hyperspace need to bedeveloped before detailed calculations of this magnitude will be possible.even if we could predict the mode and strength of binding of a ligand to aprotein, the effect of such binding on the function of the protein in the cellmight not be obvious. the simplest case would seem to be the design of anenzyme inhibitor. if an enzyme is inhibited, we would expect that fewersubstrate molecules would be transformed in a given unit of time. however, thisis not necessarily true. for example, current evidence is that receptor kinasesare present in the cell in high concentrations: the rate of phosphorylation of thereceptor is apparently governed by the concentration of the cyclic nucleotideand the conformational state of the receptor and not the level of the enzyme.inhibition of such an enzyme by even 90 percent might have no observablephysiological effect. in other cases, the level of a particular enzymatic activityis regulated by feedback control. inhibition of such an enzyme would beovercome by production of more enzyme. alternatively, inhibition of anenzyme might simply lead to the presence of higher levels of substrate but thesame rate of turnover of substrate through the biochemical system. thephysiological effects of such agents may be impossible to predict.the situation is even more complex in proteins that have multiple domainsthat control multiple functions. a compound that prevented sickling ofhemoglobin s would be useless as a drug if it also prevented oxygen binding orrelease or if, when bound, it promoted the crystallization of hemoglobin in adifferent crystal form.a further complication in trying to understand function from structure isthat a single protein may interact with several small molecules and otherproteins in a complex regulatory scheme. different subunits of domains of aprotein may have different but interrelated functions. for example, all foursubunits oftorpedocalifornica acetylcholine receptor are necessary to elicit anicotinic response to acetylcholine, whereas only the alpha subunit is refquiredfor binding the antagonist alphabungarotoxin (mishina et al., 1984). thus, thestructure of the alpha subunit might help in the design of a ligand, but thestructure and function of all fourfunctional aspects of proteins and nucleic acids127computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.subunits might be needed to predict whether the compound would be an agonistor antagonist.other factors might make a ligand useless as a therapeutic agent. when aligand is administered to an animal, it must survive the metabolic and structuraldefenses of the animal in order to reach its proposed site of action at therequired concentration. the ligand may be a substrate for any one of manyenzymes, some of which appear to have evolved broad specificity in order tometabolize foreign substances and thereby protect the organism from itsunpredictable environment. ultimately, we expect to be able to predict thebiotransformations of small molecules from the structures of the enzymesinvolved, but we cannot do so today.the ligand may also fortuitously bind to other macromolecules in the bodyand, as a result, may not be available to the target protein. the ligand may havethe correct physical and chemical properties to be rapidly excreted into the urineor bile before it has a chance to move to its target. finally, the ligand may be soslightly soluble that it cannot achieve high enough concentrations in the bloodor gastrointestinal tract for it to be distributed to its site of action. again, wehave some informal rules that allow us to attack these problems, but lack thebasic knowledge we need to make true predictions. a ligand might also beuseless in curing disease because it or one of its metabolites produces toxicity inthe animal.to use a ligand as a drug, it must be technically feasible to do so. thismeans that it must be possible to produce the compound in the requiredquantities and purity; it must be stable enough to ship to the patient; and anacceptable pharmaceutical form of the compound must be devised. a majoradvance has been made in the computerassisted design of pathways for thesynthesis of compounds. however, further enhancements would make this tooleven more useful.economic factors also figure into feasibility; if the compound is to be sold,the patentability of the compound, the cost of its manufacture, the cost andeffectiveness of competing therapy, and the expected incidence of the diseasefor which it is effective will also be issues in the decision to market thecompound.other complications may also emerge when one is predicting function ordesigning ligands from predicted threedimensional protein structures. first, theconfidence in the exact coordinates of the protein structures will be lower. thisgreater uncertaintyfunctional aspects of proteins and nucleic acids128computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.will complicate the investigation of proposed function or the design of ligandsbecause the exact dimensions of the possible binding sites will be uncertain, aswill the conformation of residues on the surface of the protein. in principle,these questions can be answered using extensive molecular dynamics andminimization calculations. the prediction of function might be straightforwardif the unknown protein shows a strong sequence homology with a protein ofknown structure and function.another complication with the use of predicted structures is that we maybe unaware of posttranslational modifications of the structure. ultimately, weexpect to be able to predict such modifications from the substrate specificitiesof the enzymes that perform them. however, we cannot do so today.consideration of protein structures based on dna sequence may obscurethe fact that the protein may function as part of a multisubunit assembly.multiple subunit proteins are common. to predict the function of such aprotein, we must realize that it binds to the other subunits. it is not enough toconsider other proteins coded on the same chromosome; the genes that code forthe two different protein chains that form the subunits of hemoglobin arelocated on different chromosomes. hemoglobin illustrates a furthercomplication in using dna sequences: there are at least four different variantsof the beta subunit. only one of these is produced in quantity by the organism.thus, to predict the function of the alpha chain of hemoglobin, we would needto recognize that it functions in a tetrameric structure with two subunits of adifferent type, and that, of those with which the alpha subunits could bind, onlythe beta subunit is produced in appreciable quantity.the transcribed protein may have one activity and be transformed into aproduct that has a different activity. peptide hormones usually arise by thelimited hydrolysis of a larger protein that circulates in serum. sometimes thesame carrier protein can be cleaved at different sites to produce differentpeptide hormones. at present, we cannot predict such events. only when weknow the sequence of every peptide hormone would we be able to recognize thepotential for a particular protein to be a carrier of a hormone.in summary we do not adequately understand the relationship between thedetails of the threedimensional structure of a protein and its function. withoutsuch an understanding, we cannot predict the effect that a bound ligand willhave on the functionfunctional aspects of proteins and nucleic acids129computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.of the protein. we lack this understanding partly because threedimensionalstructures of proteins have been determined only recently, and moleculargraphics hardware and software are also newly available to experimentalscientists. but in many cases, we do not know the threedimensional structure ofthe protein of interest, nor do we have a good idea of all of its functions. weknow even less about the relationship between structure and function ofcarbohydrates, because we have so little structural information on them. this isa problem that will not be solved in the shortterm.while there are methods to predict the potency of molecules once astructure is suggested, we need better tools for molecular design to help thechemist suggest molecules to examine experimentally or theoretically. the toolsdescribed above are primitive. although some methods are available to matchcandidate molecules against proposed shape requirements for binding, it is notpossible to also specify the chemical properties of the designed compound withexisting software. the current methods process a file of threedimensionalcoordinates of candidate molecules; this file is generated from experimental ortheoretical studies and so is incomplete. additionally, we cannot automaticallycompare a compound proposed by a computer program with those already inthe world literature as tested for that activity, nor can we automatically detect ifthe proposed compound is identical or similar to compounds known to havesome biological activity deleterious to that desired. it is expected that many ofthese tools will be developed rather soon.functional aspects of proteins and nucleic acids130computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.8.structure and function of complexcarbohydratescomplex carbohydrates are very common in animals, plants, and bacteria.they are constituents of cell membranes, as well as subcellular materials ofcells. they are also found in physiological fluids such as blood, tears, milk, andurine. it was estimated recently that the covalent structures of between 4,000and 6,000 natural carbohydrates have been determined (doe, 1987). manycomplex carbohydrates are unsubstituted at their reducing ends and are referredto as polysaccharides; examples include the oligosaccharides of milk, thecellulose of plant cell walls, and storage forms such as starch and glycogen.many other naturally occurring complex carbohydrates are covalentlyconnected to other molecules, such as proteins or lipids, by glycosidic linkagesof the sugar residues at their reducing ends to form glycoconjugates.biological functionglycoproteins have many functions in higher organisms. collagen is animportant structural element in the extracellular space and in cartilage, bone andbasement membranes. mucins are significant as lubricants and protective agentsin mucous secretions. important immunological molecules of the glycoproteinclass include the immunoglobulins, histocompatibility antigens,structure and function of complex carbohydrates131computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.blood group antigens of the abo and lewis types, complement in the bloodclotting mechanism, and interferon. many human plasma proteins such asfetuin, transferrin, and ceruloplasmin are glycoproteins, as are several of thehormones such as chorionic gonadotropin and thyrotropin. most of the animaland plant lectins are glycoproteins, as are the lysosomal enzymes. therecognition and binding of lysosomal enzymes to specific receptors in the golgiapparatus and on the cell surface involves one or more phosphorylated mannoseresidues on nlinked oligosaccharide chains. recognition sites on cell surfacesfor binding and uptake of hormones and for interactions with other cells, virusesand bacteria are also glycoproteins.many of the cell surface functions of glycoproteins have also beenproposed for the neutral and acidic glycosphingolipids. in addition, certainglycosphingolipids of the ganglioside class have been found recently to inhibitthe mitogenic response of cell growth factors by allosteric modulation of theircell surface receptors (bremer et al., 1986). oncogenic transformation by viralinfection or chemical mutagens usually leads to alterations in the cell surfacepattern of glycosphingolipids such that certain types increase greatly inquantity. in some cases, there are also qualitative differences due to theexpression of genes that are silent in the differentiated normal cells. this isparticularly important in tumor cells, where tumorassociated antigens mayprovide a basis for specific monoclonal antibodybased diagnostic assays andeventually, perhaps, treatment.the binding between glycosaminoglycans and other extracellularmacromolecules contributes significantly to the structural organization ofconnective tissue matrix. all of the glycosaminoglycans, except those that lacksulfate groups or carboxyl groups, bind electrostatically to collagen at neutralph because of their remarkable anionic character. dermatan sulfate, whichappears to be the major glycosaminoglycan synthesized by arterial smoothmuscle cells, binds strongly to plasma lipoproteins, and heparin also interactswith several plasma proteins, including clotting fac tors ix and xi andantithrombin iii. interestingly, the 1:1 stoichiometric binding of heparin to lysresidues of antithrombin iii is believed to induce a conformational change inantithrombin iii that increases the binding of antithrombin iii to thrombin. thisbinding inactivates the thrombin. hyaluronic acid is deposited on the surface ofpetri dishes by cells growing in tissue culture,structure and function of complex carbohydrates132computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.giving them a substratum for attachment during growth. the proteoglycanshave also been implicated in the regulation of cell growth, possibly throughnuclear effects on chromatin structure and activation of dna polymerase, andmay mediate cellcell communication and the shedding of cell surface receptors.biosynthesis of nlinked glycoproteins andglycosphingolipidsthe role of carbohydrates in biological function poses a particularlychallenging problem for the future. the synthesis of these glycoconjugatesoccurs during their intracellular transport from the site of initial assembly of alipidlinked intermediate (glycoproteins) or ceramide (glycosphingolipids) inthe endoplasmic reticulum, through the golgi apparatus, to the cell surface,intracellular organelles, or extracellular space. their synthesis requires a familyof activated sugar donors called sugar nucleotides that are synthesized in thecytosolic fraction of cells from sugar phosphates and nucleoside triphosphates.an interesting exception is the sugar nucleotide of sialic acid, called cytidinemonophosphate sialic acid (cmpneuac), which is synthesized in the nucleusfrom free sialic acid and ctp. the enzymes involved in glycoconjugatebiosynthesis are glycosyltransferases that catalyze the transfer of sugar residuesfrom the sugar nucleotides to the nonreducing end of a growing carbohydratechain.the distinction between glycoconjugate biosynthesis and protein synthesisis key; the latter occurs on a template of messenger rna and is thereforedetermined by the genetic code for a single structural gene.1 in sharp contrast,glycoconjugate synthesis is accomplished by the stepwise addition of sugarunits using a different enzyme for each step. therefore, no single dnasequence is involved in determining the primary structure of the complexcarbohydrate, since the order in which sugars are added depends on thesubstrate specificities and kinetic characteristics of the different glycosyltransferases, each of which is coded by a different structural gene. it is clearlyimpossible to predict the primarystructure and function of complex carbohydrates133computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.structures of complex carbohydrates from dna sequences. therefore, the threedimensional structures of glycoproteins, glycosphingolipids and other complexcarbohydratecontaining molecules can never be completely predicted withoutexperimental structural analysis of the carbohydrates.snider (1984) reported that glycoproteins of the nlinked type aresynthesized as a cotranslational event in the rough endoplasmic reticulum.while the polypeptide chain is being translated on a messenger rna andconcurrently passed through the endoplasmic reticulum membrane into thecisternal space (lumen), a single oligosaccharide is coordinately synthesized ona phosphorylated polyisoprenoid alcohol (dolichol in higher animals andsmaller, similar substances in insects, yeast, and plants). the entire precursoroligosaccharide is then transferred to appropriate asparagine residues on thenascent polypeptide chain (probably before folding into a tertiary structure)according to rules of specificity that are not completely understood. transferrequires an asnxser or asnxthr sequence but additional factors areinvolved as well. accessibility of the asn residue may be one such factor andassessment of this possibility could be made by the predictive methodsdescribed in this report.the second stage of nlinked glycoprotein synthesis involves extensiveposttranslational modification of the proteinlinked precursor oligosaccharideby the removal and addition of sugars. in many cases the protein moiety is alsomodified by partial proteolytic cleavages and/or the addition of functionmodifying groups on specific amino acid residues. posttranslationalmodification is initiated in the rough endoplasmic reticulum by the removal ofthe three glucose residues by two specific membranebound glucosidases. theseglucose residues appear to have the sole function of enabling transfer of theoligosaccharide chain from dolichol pyrophosphate to nascent polypeptidechains. it will be interesting to determine from threedimensional structures andpredicted conformations how these groups interact with the transferase enzymeinvolved at this step. mature high mannose oligosaccharide chains aresynthesized by the subsequent removal of up to four mannosyl residues fromthe three branches of the precursor structure. at least three different alphamannosidases in the golgi apparatus are involved in this process. theseenzymes and the two glucosidases are hydrolases like lysosomal glycosidasesbut their activities areactually, it is more appropriate to refer to ﬁone cistronone polypep tideﬂ. thisis no longer strictly accurate either, as more than one gene may contribute to theprimary structure of a protein, i.e., immunoglobulins.structure and function of complex carbohydrates134computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.greatest at neutral ph, in contrast with lysosomal enzymes that have theirgreatest catalytic activity at an acid ph.figure 8intermediate partially processed asparaginešlinked carbohy drate chain of aglycoprotein.in eukaryotic cells, the high mannose oligosaccharide with five mannoseunits (see figure 81) is the direct precursor of complex and hybrid structures.the initial step in the golgi apparatus is the addition of an nacetylglucosamineresidue to the last remaining man on branch i (*), after which the remainingtwo man residues on branches ii and iii can be removed by alphamannosidasesthat are almost certainly different from those involved in earlier steps.additional branches may be made at this point to produce tri and tetraantennary structures, and the final stages of processing are carried out by theaddition of galactose, nacetylglucosamine, sialic and fucose residues to givemature, complex, nlinked chains. an interesting nacetylglucosaminyltransferase may add a beta1,4linked glcnac residue to thebranched betalinked mannose residue of the inner core region (0) to give aﬁbisected structure.ﬂ this step has been the subject of intensive study by carverand coworkers, who have been interested in the structural specificity of theenzyme with different conformations of the precursor oligosaccharides (carverand brisson, 1984).it is likely that predictive methods will be employed in studiesstructure and function of complex carbohydrates135computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.of processing pathways and the extent of processing of oligosaccharide chains.if control arises from an enzyme specificity for a particular threedimensionalstructure of the substrate, it may be possible to determine these preferences and,from predictions of the distributions of threedimensional structures of theoligosaccharide attached to the glycoprotein substrate, predict how far thecarbohydrate chain will be processed.lysosomal enzymes contain one or more phosphate groups on mannoseresidues of the high mannose type oligosaccharide chains. the mannose6phosphate groups are specific recognition markers that are involved in thetransport of lysosomal enzymes from the golgi apparatus or outside the cellsinto lysosomes. two membranebound mannose6phosphate receptors havebeen discovered in the plasma membrane; at least one of them also resides inthe golgi membranes. although their binding specificities have been probed insome detail, other aspects have not been determined: the nature of theinteraction of the phosphorylated mannose residues with the receptors and thethreedimensional structures of the lysosomal enzymereceptor complexes.another interesting aspect of lyosomal enzyme synthesis involves thedetermination of structural domains on the folded proteins recognized by theenzyme that initiates phosphorylation of mannose residues, which is an nacetylglucosaminephosphotransferase (glcnacp transferase) in the golgiapparatus. this is the mechanism by which only lysosomal enzyme proteins areselected for phosphorylation. it is especially important because one form of agenetic lysosomal storage disorder, called mucolipidosis ii, results from adefect in the binding domain of the glcnacp transferase for lysosomalenzyme proteins. perhaps this problem can be solved only by computermodeling to predict the threedimensional structures of both proteins.glycosphingolipids are synthesized in an analogous manner, except thatceramide serves the function served by dolichol for glycoproteins and transferoccurs directly from a sugar nucleotide to the acceptor glycolipid. ceramide isan acceptor for either glucose (from udpglc) or galactose (from udpgal),giving glucosylceramide or galactosylceramide. these simpleglycosphingolipids predominate in human plasma and the brain, respectively,and also serve as precursors for more complex glycosphingolipids. instructure and function of complex carbohydrates136computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.most organs, including the brain, the major pathways involve conversion ofglucosylceramide to lactosylceramide, galbeta1,4glccer. lactosylceramideis the substrate for several glycosyltrans ferases, the products of which are thefirst intermediates in the synthesis of related glycosphingolipids that may beclassified according to their general structural characteristics. more than 100different glycosphingolipids have already been characterized, and newcompounds are still being discovered. although some of the glycosphingolipidsmay contain between 15 and 35 or more sugar residues, most of the commonlyoccurring types have between 4 and 10 residues in the oligosaccharide chain.analysis of primary and tertiary structurea complete understanding of the interactions between carbohydrates andproteins (enzymes, lectins, antibodies, and cell surface receptors) will dependon the determination of accurate threedimensional structures of both kinds ofmolecules. as was noted, the primary structures of the oligosaccharide chainsof complex carbohydrates cannot be deduced from dna sequences and so mustbe determined by chemical and spectroscopic analysis. modernchromatographic methods of separation, along with mass spectrometry andnuclear magnetic resonance (nmr), allow us to carry out complete analysis ofa primary structure on a one micromole sample. still to be determined arecomposition; arrangement of sugar residues; ring size; positions of glycosidiclinkages and their anomerity; and the location and the chemical nature of noncarbohydrate substituents such as lipids, sulfate, and phosphate groups.threedimensional structures of carbohydrates represent the spatialarrangements of the individual sugar residues. most commonly occurringmammalian complex carbohydrates consist of sugar residues that exist in thepyranose ring form, the most stable and rigid conformation of which are thechair forms. when two sugar residues are joined together covalently in aglycosidic linkage, they are free to rotate about the glycosidic oxygen atombetween the two rings, and the resulting disaccharide can therefore assume anumber of different conformations corresponding to the rotations about thesetwo bonds. it is customary to designate the dihedral angles at the glycosidiclinkage (see figure 82) by thestructure and function of complex carbohydrates137computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.greek symbols phi () and psi (), where the initial conformation () = 0°, =0°) is that conformer where the clšh1 bond eclipses ošc`x` and c1šoeclipses c`x`šhx`.figure 82 dihedral angles determining the spatial relationship of two sugarresidues in a disaccharide.the relative orientations of adjacent sugar residues in an oligosaccharidechain are described by specifying the rotational angles (), ) at eachglycosidic oxygen atom. when these angles are the same at each linkage, thechain has a helical conformation with n residues per turn and h unit translationalong the helical axis. if n and h are available from xray data, then () and can be computed and vice versa. if () and  are different among glycosidiclinkages in an oligosaccharide chain, the threedimensional structure becomesnonperiodic and, for extreme variations, assumes a random coil conformation.information about perturbations can be obtained by lightscattering, viscosity,sedimentation, and diffusion measurements.xray analysis of crystal structures ofcarbohydratesof the three major classes of complex biological molecules, we have theleast structural information at atomic resolution about carbohydrates. this isbecause they have not been crystallized, and consequently there is no relevantcrystal structure data base other than that of the simple monomers to trimersupon which to model classical or semiempirical quantum mechanicalcalculations. the blood groupspecific oligosaccharides, cord factors, and lipidsa and x are typical examples. exceptions are the cyclodextrins, whichcrystallize well, but are conformationally a separate class. structures derivedfrom the fiberpatterns of polysaccharides arestructure and function of complex carbohydrates138computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.modeldependent and do not constitute a source of definitive structural data.stachyose, an oligosaccharide consisting of four sugar residues, is the largestnoncyclic oligosaccharide for which there is a crystal structure analysis, buteven in this case, the associated water structure has not been determined.the crystallinity problem is only partially intrinsic. carbohydrates do notsolvate the same way as proteins, oligonucleotides, or nucleic acids. however,fewer efforts have been made to obtain the significant amountsofconfigurationally homogeneous material needed to conduct crystallizationexperiments than were made for proteins and nucleic acids. another aspect ofthe crystallography of glycoconjugates is that the electron density for theoligosaccharide portion of glycoproteins has rarely been interpreted, eventhough several crystalline glycoproteins have been studied. this is because thestandard refinement programs cannot handle the oligosaccharides, or there ismicroheterogeneity at the site of glycosylation, and so it is left out of the model.thus, a potentially valuable source of information is not being exploited forlack of appropriate program development or strategic approaches to deal withmicroheterogeneity.steric considerations about the minimum approach distances betweenatoms, derived from observed nonbonded distances in various crystal structures,can be used to predict allowed conformations. this ﬁhard sphereﬂ approach,which was originally developed by v.s.r. rao in the mid1970s, is arudimentary method of theoretical calculation that ignores electrostatic effects(hydrogen bonding), but does give a qualitative prediction of structure. thisapproach was subsequently extended by adapting energy calculations originallyused for peptides, where the potential energy is divided into functions thatdescribe discrete contributions such as van der waals energies, electrostaticinteractions, torsional energy, hydrogen bond energy, and bond and angledeformations (bock, 1983). the data are presented in the form of computergenerated energy contour maps.in much of the recent literature, conformational energy calculations havebeen made using a form of rao's parameters with an added torsional potentialabout one of the glycosidic bonds (exoanomeric effect). this approach, whichgoes by the name hsea (hardsphere exoanomeric) method (bock, 1983), hasbeen used with success by lemieux and bock (1983), carver and brisson(1984), and others, although it contains a number of untestedstructure and function of complex carbohydrates139computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.assumptions. the addition of a hydrogen bond potential (heah method) yieldsenergy minimization results that differ from those calculated by the hseamethod, from which geometries can be derived that differ from those obtainedby the hsea method.nmr solution structures of carbohydratesproton nmr methods provide detailed experimental data from which threedimensional structures can be determined and compared with conformationsarrived at by potential energy calculations. carver and cumming (1987) havegenerated contour maps of computed noes of various high mannoseoligosaccharides as a function of the torsional angles  and . they then relatedthem to experimental results as well as to minimum energy conformationsestimated by various potential energy calculations (carver and cumming, inpress). brisson and carver (1983) evaluated the utility of this approach usingtwo biantennary complex type glycopeptides (see figure 83). since the noederived conformations were within a range centered on the minimum energyconformations derived from potential energy calculations, it was concludedﬁthat motional averaging is confined to a narrow range about one stableconformationﬂ (brisson and carver, 1983). it now appears, however, that it ismeaningless to seek a single noederived conformation that satisfies a singlepotential energy minimum, because the molecules in fact may occupy suchminima for a very small proportion of the time in solution. ﬁconformationalflexibility must be incorporated into the theoretical treatmentﬂ (carver andcumming, 1987), and the calculation of energy surfaces becomes extremelyimportant. the latest studies by cumming and carver indicate that noedetermined threedimensional structures may differ significantly from anyminimum energy conformation. they have concluded from this that the noederived conformations in such cases might correspond to ﬁvirtualﬂconformations as defined by jardetzky (1980) to be computed structures thatfew if any molecules in solution actually adopt.scarsdale et al. (in press) have employed a molecular mechanicsbasedprogram in an effort to model conformational averaging of nmr data.conformations were calculated using a combination of molecular potentials andnmr data for the oligosaccharide moiety of an erythrocyte glycolipidcomposed of three neutral sugars and an amino sugar. the lowest energyconformer closelystructure and function of complex carbohydrates140computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.resembled a structure proposed earlier. however, fits to data could be improvedwhen two equilibrating conformers were considered. thus, it may be possible todetermine solution conformations of the complex carbohydrates, even innonrigid cases, using a combination of calculations and constraints imposedfrom experimental nmr data.figure 83 structures of two partially processed asparaginešlinkedcarbohydrate chains. the bisecting 1,4glcnac of b causes a conformationaldifference from that of a.despite the questions raised about the interpretation of nmr results andthe value of potential energy minimizations, some important information hasbeen collected about interactions of carbohydrate antigens with antibodies(lemieux et al., 1985), oligosaccharides with lectins such as concanavalin a(sekharudu et al., 1986), and oligosaccharides with glycosyltransferaseenzymes (carver and cumming, 1987). further refinements will depend uponthe development of an agreedon set of potential en ergy functions, which canbe used with experimentally determined noederived threedimensionalstructures to evaluate whether a given molecule is distributed among severallow energy conformations or occupies a particular subset of them. tvaroska andperez (1986) have recently compared several conformational energycalculations and proposed a general strategy for oligosaccharides.computer time and access to appropriate parallel processing arrayprocessors are important considerations in determining the level of support ofresearch in this area at the present time. the availability of machines tocalculate interatomic distances and vanstructure and function of complex carbohydrates141computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.der waals contributions extremely fast is a question that should be addressed byfunding agencies. interestingly, the several supercomputers currently operatingon campuses have not been used to their capacity; perhaps efforts should bedirected by appropriate advisory groups at these centers toward developingnecessary software in these computers and establishing a policy that woulddirect a portion of their time for computer modeling of threedimensionalstructures.supramolecular structurestructures that consist of more than one macromolecule interact as a unit inbiological phenomena such as catalysis by many enzymes, binding at a cellsurface, signal transduction across cell membranes, and other biologicalphenomena. any enzyme that consists of more than one subunit should bethought of as a supramolecular structure. when large numbers of subunits areinvolved, and perhaps carry out more than one function, special considerationmay have to be given to their relative spatial orientations. examples are thereplication of dna by dna polymerases, where complexes containing 10 or12 proteins (called primosomes) are required to initiate replication. ribosomesare even more complex, requiring at least 75 proteins to translate messengerrna. surfaces that consist of more than one macromolecule often behave as afunctional unit. for example, the uptake of cholesterol by many cells requiresthe interaction of a specific cell surface receptor with a polypeptide surface of acomplex supramolecular structure called low density lipoprotein (ldl), whichconsists of protein, cholesterol, phospholipids, and triacylglycerols. alterationof the ldl protein by acetylation of a lys residue blocks the binding of ldl toits receptor and uptake of cholesterol by the cell. several hormones, includingnorepinephrine and epidermal growth factor (egf), and other signals such aslight (with rhodopsin) induce protein phosphorylation. egf stimulates thegrowth of normal fibroblasts by binding to a specific transmembrane proteinreceptor on the cell surface. the hormone signal in this case is transduced byselfphosphorylation of the receptor on the intracellular side after the hormonebinds, followed by other kinasecatalyzed phos phorylations of proteins,internalization of the egfegf receptor complex, and a complex set ofconsequences in the nucleus and elsewhere in preparation for cell division.bremer et al. (1986)structure and function of complex carbohydrates142computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.recently found that gm3 ganglioside inhibits this process in an allostericfashion by preventing the selfphosphorylation of egf receptor after egfbinding. to accomplish this, gm3 in the outer half of the cell membrane mustinteract with a domain of the polypeptide chain of egf receptor, probablycausing a conformational change that prevents phosphorylation. a similarsituation involving a lipid membrane is found with a mitochondrial enzyme,betahydroxybutyric dehydrogenase, which is catalytically active only whenincorporated into a lipid bilayer composed of certain phospholipids. computerassisted mathematical modeling of such supramolecular structures will benecessary to gain a deeper understanding of the organization of biologicalmaterials for complex functions.structure and function of complex carbohydrates143computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.9.hardwarefour functions are essential to computer modeling of molecules: molecular energy computation configurational control graphics reasoninguntil recently, the standard hardware configuration of a vax and anevans and sutherland display terminal could only achieve the second and thirditems. molecular energy calculation on a vax is very slow, although thesecomputers were used to develop the programs. the advent of craytypesupercomputers connected by national communications networks has givenscientists access to more computer power for molecular energy calculations.more recently, the development of special purpose array processors made itpossible to have in the laboratory computational power roughly comparable tothe supercomputers. reasoning about molecular structure until recently couldbe done only with special purpose machines which run the programminglanguage lisp.as the power of computers available to individual scientists increases weexpect that these four functions will be brought together. the early vaxcomputers (for example the 11/780) typically provide 0.5 megaflop (millionfloating point instructions perhardware144computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.second) and 1.0 mips (million instructions per second). typical arrayprocessors provide 100 megaflop while typical lisp machines provide 2.0mips. in the last years it was necessary to have one each of these types ofmachines in order to have reasonable amounts of computational power for thefour molecular modeling functions. the next generation of computer describedas a personal supercomputer (psc) will have between 40 and 60 megaflops ofnumber crunching power and between 15 to 20 mips of general (i.e. logical)computational power. with this level of numeric and logical computationalpower available in the next year at a scientific workstation there will be littleneed for separate machines to perform special functions.the national supercomputers, however, already in place and operational,constitutes a very real scientific resource. as scientists learn that thesupercomputers can effectively carry out molecular energy calculations, thesemachines will be used to their fullest capacity. however, the technology of thesupercomputers is advancing rapidly, and the manufacturers promise thatsystems with three orders of magnitude more computational power will beavailable in the next few years.while the supercomputers grow more powerful, the power of workstationsand the pscs is also increasing. current workstations have the power of vaxs,but lack the capacity to run all four functions simultaneously. as the pscsemerge, they will offer a combination of capabilities that will make it possibleto run all four functions at once. the pscs should create the possibility of anew computational and graphic plateau:1988  1995: personal supercomputer1977  1987: e & s display coupled to a microvax ii1970  1976: tektronix display coupled to a dec system10.the tektronix display and a scientific mainframe gave us the first plateauseventeen years ago. on this plateau it was possible for many scientists to viewand manipulate molecules. the vax computers, and more recently the evenless expensive microvax ii computers coupled to an evans and sutherlanddisplay, have established over the last ten years a plateau of graphic capabilitywhich has enabled scientists to go over from the physical modeling ofmacromolecules to completely electronic modeling. the pscs expected toemerge in the next years will permit scientists to compute and to visualizemolecules in much more powerful ways.hardware145computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.using the pscs, it should be possible to shape molecular models easilyusing joystick controls, creating stereo color graphics in multiple modes ofrepresentation, while doing energy calculations and molecular reasoning. theonly foreseeable problem with the supercomputers is that scientists' appetitesfor energy calculations may exceed the computational capacities of the pscs.configurational control should make it possible to sketch protein models. usingcollections of rules, we should be able to use molecular reasoning to generateand evaluate large numbers of possible model states.because of the rapidly changing technology of computers, displays,workstations, and pscs, national effort should be directed to guaranteeing thatthese devices conform to the various levels of standards of the internationalstandards organization (iso).standardization in the united states is achieved by interested partiesworking together in committees under the auspices of agencies andorganizations such as the national bureau of standards, american society fortesting and materials (astm), institute of electrical and electronics engineers(ieee) or iso. considerable standardization at the level of the computeroperating system must be done to make the iso model work. hardware vendorsmust choose between product uniqueness for sales and market development,and intervendor product compatibility. compatibility has many benefits.adherence to the standards will make it possible to move programs quickly andeasily from one device to another, as well as making it possible to construct acomplete system from components supplied by many vendors. the iso modelhas several levels, represented below:1. ethernet2. tcp/ip communications protocol3. nfs  network file system4. unix operating system5. vax/vms and cray fortran compatibility6. xwindows7. dialoglike application program window and functionalityspecificationthe ethernet originated at the xerox palo alto research center. thetcp/ip protocol was developed for the darpanet, operated for thedepartment of defense, and so is in the public domain. the nfs was developedby sun microsystems andhardware146computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.placed in the public domain. bell laboratories developed unix. vax/vmsfortran was originated by digital equipment corporation (dec). xwindows originated at the massachusetts institute of technology where theywere developed to specify a machineindependent windowing system. dialogis an apollo product that is a first attempt to answer the question of how towrite high level mousedriven applications programs in a high levelspecification language.standards are really the key to future progress in molecular modeling. if allinvestigators adhere to the iso standards, then it will be possible to mix variousworkstations and special purpose computers on a laboratory network.adherence to standards should lower the price of equipment to end users byenlarging the market. similarly, with adherence to the standards, it will bepossible to send and receive molecular structure data sets all over the worldusing global communications networks such as bitnet, csnet, darpanet,japan universities net (junet), and commonwealth scientific and industrialresearch organization net in australia (csironet).special purpose computers offer many possibilities for molecularmodeling. over the years, the national institutes of health (nih) has fundedfacilities that developed molecular graphics, computation, and control devices.the control systems laboratory at washington university medical schooldeveloped the mmsx molecular display. the molecular graphics laboratory atthe university of north carolina at chapel hill has been instrumental inexploring the development of a variety of stereo, configurational control, anddisplay devices. the molecular graphics laboratory at columbia university is inthe process of developing fastrun, a special purpose computer attached to ast100 array processor that boosts its molecular dynamics power by a factor of10. the molecular graphics laboratory at the university of california at sanfrancisco medical school has developed stereo and color representationtechniques.special and general purpose graphics devices are increasingly easy toproduce. general electric in research triangle, north carolina has produced avery fast surface graphics processor that can be used to display different typesof objects, including molecules. at least one of the pscs will have a spheregraphics primitive embedded in a silicon chip. every effort should be made toencourage the development of special purpose processors. however,hardware147computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.these processors should be required to adhere to the emerging computerstandards, so that they can be easily integrated into existing laboratory networks.the last few years have seen the emergence of array processors forlaboratory use. the st100 array processor from star technologies, inc. hasbeen programmed by microcoding to produce molecular dynamics calculationsat a rate comparable to a cray xmp. the st100 is rated at peak 100megaflops, while the sustained calculation rate is about 30 megaflops. thest100 costs about onethirtieth of the cray xmp48. the fastrun devicecurrently under development in the laboratory of cyrus levinthal at columbiauniversity will increase the power of the st100 by a factor of 10 from 30average megaflops to 300 average megaflops. floating point systems inc. isdiscussing the delivery of a 10 processor fps264 system with a peak of 1gigaflops. multiple process machines could be added to this list, including thehypercube machines from intel and ncube. all are laboratory machines. thepower of supercomputers will obviously be increasing at the same approximaterates.a very strong relationship exists between the architecture of a specialpurpose computer and the structure of the scientific problem to be solved. thequestion is, how much computational power does molecular modeling reallyneed? the protein folding problem seems to be the gauge of this question, sincemolecular dynamics programs calculate atom position charge in 1015 secondtime steps. if proteins really take minutes to fold, then computation will have togo from 1015 to 102 seconds. the most powerful array processors availabletoday make it possible to calculate and examine molecular trajectories threeorders of magnitude longer than hitherto possible. extending these trajectoriesan additional three orders of magnitude might bring us to the range whereappropriate proteinfolding actions can take place. there is some indication thatif amino acids were synthesized at the rate of one per microsecond, then foldingwould be possible. then, computing would only have to range from 1015 to 105 seconds. this would be seven orders of magnitude less computing. if thisestimate is close to correct and computing power increases at a rate of 50percent per year, then current computer processor development will give us thenecessary amount of power in 5 to 10 years.hardware148computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.central versus distributed computingthe national science foundation (nsf) supercomputer initiative againbrings to the forefront the relationship between central computational servicesand distributed or personal services. proponents of centralization argue thatcertain types of very large calculations are available only on centralizedmachines. the personal computer revolution showed how profoundly scientistsrespond to decentralized computation. the capabilities of personal machinesincrease at the same pace as the supercomputers, but the baseline machines area market of 105 to 106 machines, whereas the supercomputers are a market of102 to 103. special purpose boards added to the baseline machine can raise itscapabilities for specific functions (i.e., energy calculation, sequencecomparison, or graphics) to levels approaching those of supercomputers.the distribution of personal computation is driven totally by market forcesand is not subject to centralized planning. scientists buy laboratory computerswith funds previously allocated for glassware. postdoctoral students returning totheir country of origin bring their personal computers. floppy disks containingdata files and even whole books form a new type of currency in countriesoperating centrally planned economies.these modes of behavior form a valuable dichotomy. we need a balancebetween centralizing and decentralizing efforts. individual scientists canparticipate in the planning and use of national supercomputers, whilesimultaneously helping to specify and buy smaller machines for their personaland laboratory use.computer utilization in the next 5 to 10 yearsin the next 10 years, workstations will become ordinary scientific tools,like pocket calculators and balances. the workstations will become morepopular with scientists as they acquire larger, faster, and more complex workingprograms; better graphics; more storage and access to other computers; and newdata sources. a few years ago, only specialists searched dna sequence databases; now, because many workers have pcs in their laboratories, almost allmolecular biologists search these data bases.workstation use is likely to follow the same pattern. now, moleculargraphics techniques are used only by departmental or laboratory specialists. inyears to come, as all workstations beginhardware149computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.to acquire adequate graphics capabilities, all scientists will routinely domolecular graphics, modeling, and energy calculations.one of the strongest effects in the computer marketplace is the tradeoffbetween constant dollar and constant performance. because computer power isdoubling every two to three years, the manufacturers tend to supply theircustomers with new models that cost the same but have increasingcomputational power. a customer, then, can expect to purchase a given level ofcomputational power for a decreasing amount of money.twenty years ago, one needed a dec pdp10 to search protein or dnadata bases, while 10 years ago one used dec pdp11s or dec vaxs. now,one can use an ibm pc or one of its many clones to do the same job. in severalyears, one should be able to do dna sequence searches on a pocket machine.the brevity of the computer design and manufacture cycles has begun toovertake our ability to use these machines adequately. twenty years ago, bothmanufacturers and consumers could reasonably expect a computer to sell and beworth buying for about 10 years; today, a given level of computational powerhas a life cycle of 3 years. the cycle length appears to be shortening evenfurther in the sense that special purpose boards can be added to a small generalpurpose machine to make it functionally equivalent to a machine that costs upto 100 times as much. why buy a cray when a pc with a special purpose boardwill do the same thing? the cure for this problem will probably be a balance ofmarket forces favoring the small mass distribution computers. pcs will rise inpower to be general purpose workstations.the national supercomputer networkthe national supercomputer initiative sponsored by nsf allocatesavailable computer time by a peerreview process. individual scientist's requestsfor time must meet granting requirements of quality of the proposed work andsize of allocation. from the scientist's viewpoint, the supercomputer networkmust perform tasks that cannot be done either in the laboratory or at localinstitutions. since the network communication rates are 9,600 baud, only alimited amount of data can be passed between the scientist and thesupercomputer. essentially, this means that only batch computing can be run onthe supercomputers. large jobs run in the batch mode of computing are onlyone form of computing.hardware150computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.the highly interactive forms of computing and graphics available onworkstations will be even more competitive with the supercomputer networkwhen the next generation of high performance workstation, the psc, becomesavailable.the use of national supercomputers can be left to the discretion ofindividual scientists as it is in this country or the use of these resources canbemandated. the ability to mandate use depends on the type of the economy orpattern of interaction between scientists and the government. the australianscientists are also in the midst of this type of central planning (personalcommunication, 1987, trip to australia). the government wants scientiststhroughout australia to use the centralized supercomputer by paying for the usewith funds from the scientists' grants; the scientists see this as a form oftaxation. the market forces in australia will probably dominate when thescientists realize that superior computing and graphics performance can beobtained by purchasing a machine. once a machine is in a department orlaboratory, the problem of centralized national supercomputer access andallocation is essentially ended.local area networksmolecular modeling in the future will probably be done on local networksof computers and displays. for the past 5 to 10 years, advanced scientificlaboratories have had one or more minicomputers. five years ago, laboratoryofficials, for the most part, took the first hesitant steps to link these computersin a network. in the last two or three years, networking of laboratory computershas become much more common. laboratory networks contain computersacting as hosts for terminal and computational servers for other workstations.the workstations range in power from the smallest pc to powerful pscs. ascomputers age and are replaced because they no longer work or are tooexpensive to maintain, they will be replaced by networks of a variety ofcomputers and displays.data base useaccess to molecular structure and sequence data bases through globalcommunications networks is an opportunity that will be available in the nearfuture. currently, most data bases are updated by magnetic tape every three tosix months, including thehardware151computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.dna sequence data bases at the los alamos national laboratory and ateuropean molecular biology laboratory (embl) in heidelberg, the proteinsequence data base at the national biomedical research foundation (nbrf) inwashington, d.c., the protein structure data base at the brookhaven nationallaboratory, and the small organic molecule crystal structure data base atcambridge university. generating tapes for institutional and random scientificusers is becoming an increasing burden for the data base operators. the globalscientific networks are organized in such a way that it is possible for the database operators to send out one copy of the update and have that copy spreadthroughout the entire scientific community.for those scientific users who need a particular molecular structure data setfor display or further modeling, the global scientific networks are ideal sourcesof information. only recently, the brookhaven protein structure file was testedat the national research council in ottawa. a simple mail request to abitnet server at the national research council produced one or more of theprotein structure data sets in a few minutes.the small molecule organic crystal structure file from cambridgeuniversity in england is being used by scientists for molecular modeling andcalculation. the cambridge crystal file provides an ideal data source for ligandconformations. the data file and a search program have been available on theinternational commercial computer network for the past 15 years. technologymoves so fast that even while this report is being prepared the panorama withrespect to data bases distribution has changed. for several years 5¼ inch laserdisks have been on the market for audio. now this highly developed consumertechnology has been applied to the storage and retrieval of molecular structuredata. each laser disk, which costs about $2,000 to master and $10 to reproduce,can hold a complete update for the dna sequence, protein sequence, proteinstructure and small molecule data files. the laser disk and associated softwarewill be produced by a small starting company associated with the university ofwisconsin (fred blattner, dnastar, inc. at the university of wisconsin, 1987,personal communication).competitivenessamerica has a world recognized ability to transfer ideas fromhardware152computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.their development in an academic setting to practice by the formation of a smallcommercial enterprise. then by the infusion of capital in several stages thesesmall companies can be transformed into stable industrial corporations. thesecorporations are then able to consume the supply of trained scientific personnelproduced by the universities. the position of the united states in the worldeconomy is changing very dramatically at present, and certainly will continue tochange in the next 5 to 10 years. our overall competitiveness will bedetermined by our ability to form links between previously separate activities. itis already clear that biotechnology as an offshoot of our national expertise inmolecular biology will be increasingly determined by the way we usecomputers in computational chemistry, macromolecular modeling, and thedesign of proteins. we are in the midst of two revolutionary tendencies:genetics and silicon. computational chemistry is the glue that will bring thesetendencies together in a stable form.hardware153computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.10.conclusions and recommendationsconclusionspredicting macromolecular structure from fundamental chemical principlesand information on primary structure is a challenging task. understandingmacromolecular function is even more demanding. identifying important stepstoward these goals is possible, however, and we have made considerableprogress in various subtasks and specialized areas. there is every reason tobelieve that major breakthroughs can be expected over the next 10 years.1. the tools of molecular mechanics and molecular dynamics haveproved useful for exploring the conformational space ofpolypeptides, oligonucleotides, and oligosaccharides. in favorablecases, they identify the most stable conformers and quantitativelyprobe intermolecular interactions. although these methods have notyet successfully predicted, a priori, the structures of molecules thesize of small proteins, they play a major role in the refinement ofexperimentallyderived tertiary structures of macromolecules.some promising results have been obtained in predicting thestructural and thermodynamic consequences of local changes inamino acid sequences. exciting new techniques make it possible tocalculate free energies directly by perturbation methods. thetechniques can be applied to intermolecular interactions or thechangesconclusions and recommendations154computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.in free energy that accompany substitution of one amino acid foranother and are readily applied to nucleic acid and polysaccharideproblems as well.2. the major limitations of current methods include: the quality of the potential functions and of their parameters,especially the electrostatic terms; methods for incorporating the solvent; global search algorithms for solving the multipleminimaproblem.each of these areas has seen notable developments. whilerecently introduced procedures may produce solutions, we expecteffective solutions to the multipleminima problem to await newconceptual breakthroughs.3. heuristic modeling has been successful in the past, particularly inpredicting the double helical structure of dna, the alpha helix, andthe betapleated sheet. when applied to globular proteins, thisapproach has yielded results which, although of relatively lowresolution, have proved useful in guiding experiments in pursuit ofmore definitive data from crystallographic or nuclear magneticresonance (nmr) techniques.4. experimental and theoretical methods can be usefully combinedwhen the goal is to elucidate a new molecular structure based on aknown one. when they are appropriate, modeling efforts based onthe structural homology of one protein to another are currently thestrongest line of attack.5. direct experimental approaches to macromolecular structure havebeen very successful; they cannot always be applied. they arelimited by the need for significant quantities of highly purifiedmaterial. acquiring sufficient amounts of many interestingproteins, glycosylated proteins, and most nucleic acids is achallenging task. the powerful diffraction techniques all have anabsolute requirement for crystals. nmr has molecular weightrestrictions and some constraints on ultimate resolution. it takes atbest months, and frequently a year or more to deduce a structurethrough crystallography or nmr.6. recent progress in instrumentation for crystallography has includedthe development of area detectors, which are only nowconclusions and recommendations155computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.being fully utilized. synchrotron sources and new neutron sourcesoffer improved data. isotopic labeling techniques and improvedmagnet technology signal new directions for nmr. we expectequally important breakthroughs in crystallization techniques.7. even with these advances, the most likely situation in the nextdecade is a substantial but essentially linear growth in the numberof threedimensional molecular structures elucidated by empiricalmethods. we estimate from current rates that several thousandprotein and nucleic acid structures will be known in 10 years.8. the explosive growth in the number of known nucleic acidsequences and hence protein primary sequences will continue toaccelerate with or without implementation of the human genomeproject in the united states. even at current rates, it is reasonable toexpect 100,000 protein sequences to be described in the nextdecade. the overwhelming majority of new protein sequences arelikely to be identifiable as members of known families of proteins.9. currently, the inventory of threedimensional protein structuraldescriptions underrepresents the general distribution of proteinfamilies. the opportunities for computerassisted modeling areenormous and will grow proportionately as more new structuresand sequences are determined. estimates of the number ofsequences to be reported in the next decade suggest that existingfacilities and resources for structural analysis will be overwhelmedby the avalanche of new sequence data.10. effects of covalent modification on structure and function ofproteins, nucleic acids, and carbohydrates are diverse and poorlyunderstood. no theoretical basis for predicting these effects existsin many cases. describing structural relationships and cooperativefunctional roles in supramolecular systems are embryonic researchareas to which modeling methods will contribute. substantialattention will be directed toward these areas in the coming decade.11. computer speed, availability, and storage capacity are importantlimitations on the types of modeling calculations that can beattempted. existing equipment is frequently incapable ofperforming all the necessary control experiments and refiningmajor approximations. a 10fold increase in computer performanceconclusions and recommendations156computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.capability is required for conducting many current projects ofbiological importance systematically and rigorously. a minimumof a 100fold improvement is needed for exploring new time scalesor studying molecules of greater structural complexity than smallproteins. we expect supercomputers, specialized hardware, andpersonal supercomputers (pscs) to be significantly more availablein the next few years. most promising is the development duringthe next decade of highcapacity parallel processors.12. a national computer network, operating at high speed and linkingmajor government, academic, and industrial research facilities, willbe crucial to molecular computation in the coming years. the usesof the network include transmission of sequence and structural dataas well as access to computational facilities.13. of immense applied potential is the design of ligands to interactpreferentially with macromolecular receptors, and the design ofreceptors to cause alterations of structure and/or function. theseprograms are in the earliest stages of development, and manyhurdles must be overcome on the way from the laboratory to fullclinical or commercial utility.14. the intellectual, practical, and economic benefits of improvedunderstanding of protein folding, macromolecular interactions, andmacromolecular function are substantial.recommendations1. the burgeoning volume of new sequence data requires a radicalnew policy on data banking of protein and nucleic acid sequences.a permanent national facility should be put in place as soon aspossible, and considerable attention should be given to developinga data storage format that facilitates data retrieval. there should beno direct charges to the user. the initiation of this new nationalresource should be undertaken only after a round of detailedproposals has been sought and reviewed. a standing advisorycommittee of users should be appointed by a consortium drawnfrom the national institutes of health (nih), national sciencefoundation (nsf), and department of energy (doe).2. whether the new facility should be allied with a nationallaboratory, such as los alamos, or with the national library ofconclusions and recommendations157computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.medicine, or should be a completely new academic or commercialenterprise remains to be determined. until the new unit isfunctioning, current facilities should be maintained to ensure anorderly transition.3. support for the archiving of coordinate and modelderivedstructures should continue. the protein data bank at brookhavenand the cambridge crystallographic file in england currently servethis need for the national and international community. inclusion ofdata from new methods of structural analysis should be encouraged.4. we recommend in the strongest terms expanding thesupercomputer initiative, funding of computer networks, improvingaccess by the scientific community to the existing supercomputercenters at the national laboratories, upgrading those centers, andproviding individual research grants for purchasing pscs. doeshould work closely with the supercomputer project managers atnsf to provide the broadest and most versatile computer networksystem on a national level. nih should become more involved indirect support of scientific supercomputer centers.5. although the report does not specifically address this issue, thecommittee felt strongly that educational opportunities in structuralbiology and molecular modeling should be improved. severalmechanisms are available, such as expanding graduate programsthrough new training grants. we recommend that nsf and doeincrease graduate fellowship and postdoctoral fellow programs inthis area. workshops have been particularly effective fortransferring information and skills. these include formal handsontraining programs in molecular dynamics and molecular graphics,and working meetings of independent investigators to addresscritical limiting aspects of a particular problem. such workshops,which also promote crucial interdisciplinary approaches, could befunded by nih, nsf, or doe, acting together or independently.6. innovative and interdisciplinary research proposals in boththeoretical and experimental aspects of structural biology should bedirectly encouraged through the use of existing funding mechanisms.7. we see a special role for the national laboratories, which shouldinteract at every level of these recommendations. theconclusions and recommendations158computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.national laboratories should compete for the national sequencedata bank. the national laboratories and doe have leadershipstatus in the national computer network. they should increaseefforts to make supercomputers available to the scientificcommunity. research efforts are going forward in molecularcalculations and structural biology, with major programs at a fewlocations. strengthening these efforts will assist the department'soffice of health and environmental research to assess thepotential health and environmental effects of chemicals involved inenergy processes.each of our recommendations involves developing some centralizedactivity. the issues in each area are quite different, however, and should not betaken as a general call for more biotechnology centers.conclusions and recommendations159computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.referencesabarbanel, r. 1984 . protein structural knowledge engineering . ph.d. thesis , university ofcalifornia , san francisco . 422 pp.abarbanel, r. 1986 . pattern matching applications in protein secondary structure . pp. 1827 inartificial intelligence and its impacts in biology and medicine . proceedings of the i. a.biomed. september 1986 .adelman, s. a. 1982 . generalized langevin models and condensedphase chemical reactiondynamics . j. phys. chem. 86 : 15111524 .alber, t. , s. daopin , j. a. nye , d. c. muchmore , and b. w. matthews . 1987 . temperaturesensitive mutations of bacteriophage t4 lysozyme occur at sites with low mobility andlow solvent accessibility in the folded protein . biochemistry 26:37543758 .altman, r. b. , and o. jardetzky . 1986 . new strategies for the determination of macromolecularstructure in solution . j. biochem. 100:14031423 .anfinsen, c. b. , and h. a. scheraga . 1975 . experimental and theoretical aspects of proteinfolding . adv. protein chem. 29:205300 .anfinsen, c. b. , e. haber , m. sela , and f. h. white, jr. 1961 . the kinetics of formation of nativeribonuclease during oxidation of the reduced polypeptide chain . proc. natl. acad. sci.usa 47:13091314 .anonymous . 1986 . renin inhibitors show early promise as antihypertensive agents . chem. eng.news . 64:2324 .arseniev, a. s. , v. i. kondakov , v. n. maiorov , and v. f. bystrov . 1984 . nmr solution spatialstructure of 'short' scorpion insectoxin i5a . febs lett. 165:5762 .references160computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.barker, w. c. , l. t. hunt , d. g. george , l. s. yeh , h. r. chen , m. c.blomquist , i. seibelross , a. elzanowski , m. k. hong , d. a. ferrick , j. k. bair , s. l. chen , and r. s.ledley . 1986 . protein sequence database, protein identification resource . natl. biom.res. found . release 11.0 , washington, d.c.bash, p. , u. c. singh , r. langridge , and p. a. kollman . 1987 . free energy calculations bycomputer simulation . science 236:564568 .bash, p. a . , u. c. singh , s. k. brown , r. langridge , and p. a. kollman . 1987 . calculation ofthe relative change in binding freeenergy of a proteininhibitor complex . science235:574576 .beddell, c. r. 1984 . designing drugs to fit a macromolecular receptor . chem. soc. rev.13:279319 .bennett, w. s. , and r. huber . 1984 . structural and functional aspects of domain motions inproteins . crc crit. rev. biochem. 15:291386 .berendsen, h. j. c. , w. f. van gunsteren , h. r. j. zwinderman , and r. g. geurtsen . 1986 .simulations of proteins in water . ann. n.y. acad. sci. 482:269286 .bernal, j. d. , and d. c. crowfoot . 1934 . xray photographs of crystalline pepsin . nature(london) 133:794 .beveridge, d. l. , and w. l. jorgensen , eds. 1986 . computer simulation of chemical andbiological systems . ann. n.y. acad. sci. , vol. 482 .blaney, j. m. , c. hansch , c. silipo , a. vittoria . 1984 . structureactivity relationships ofdihydrofolate reductase inhibitors . chem. rev. 84:333407 .blaney, j. m. , p. k. weiner , a. dearing , p. a. kollman , e. c. jorgensen , s. j. oatley , j. m.burridge , c. c. f. blake . 1982 . molecular mechanics simulation of proteinligandinteractions: binding of thyroid hormone analogues to prealbumin . j. am. chem. soc.104:64246434 .bock, k. 1983 . the preferred conformation of oligosaccharides in solution inferred from highresolution nmr data and hard sphere exoanomeric calculations . pure appl. chem.55:605622 .boger, j. 1986 . renin inhibitors: drug design and molecular modelling . third scrrscmedicinal chemistry symposium . 271292 .brady, j. , and m. karplus . 1985 . configuration entropy of the alanine dipeptide in vacuum andsolution: a molecular dynamics study . j. am. chem. soc. 107:61036105 .braun, w. , c. bosch , l. r. brown , n. g and k. wüthrich . 1981 . combined use of protonproton overhauser enhancements and a distance geometry algorithm for determination ofpolypeptide conformations: application to micellebound glycagon . biochim. biophys.acta 667(2):377396 .braun, w. , g. wagner , e. worgotter , m. vasak , j. h. r. kagi , and k. wüthrich . 1986 .polypeptide fold in the two metal clusters of metallothionein2 by nuclear magneticresonance in solution . j. mol. biol. 187:125129 .bremer, e. g. , j. schlessinger , and s. hakomori . 1986 . gangliosidemediated modulation of cellgrowth . j. biol. chem. 261:24342440 .brisson, j. r. , and j. p. carver . 1983 . solution conformation of d(13)linked and d(16)linked oligomannosides using proton nuclear magneticresonance . biochemistry22:13621368 .references161computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.brooks, c. l. iii , and m. karplus . 1986 . theoretical approaches to solvation of biopolymers .methods enzymol . 127:369400 .browne, w. j. , a. c. t. north , d. c. phillips , k. brew , t. c. vanaman , and r. l. hill . 1969 . apossible threedimensional structure of bovine lactalbumin based on that of hen's eggwhite lysosyme . j. mol. biol. 42:6586 .brunger, a. , r. l. campbell , g. m. clore , a. m. gronenborn , m. karplus , g. a. petsko , and m.m. teeter . 1986a . solution of a protein crystal structure with a model obtained fromnmr interproton distance restraints . science 235:10491053 .brunger, a. t. , g. m. clore , a. m. gronenborn , and m. karplus . 1986b . threedimensionalstructure of proteins determined by molecular dynamics with interproton distance restraint:application to crambin . proc. natl. acad. sci. usa 83:38013805 .brunger, a. t. , j. kuriyan , and m. karplus . 1987 . crystallographic r factor refinement bymolecular dynamics . science 235:458460 .bush, c. a. , z.y. yan , and b. n. n. rao . 1986 . conformational energy calculations and protonnuclear overhauser enhancements reveal a unique conformation for blood group aoligosaccharides . j. am. chem. soc. 108:61686173 .carver, j. p. , and j. r. brisson . 1984 . the threedimensional structure of nlinkedoligosaccharides . pp.209331 in v. ginsburg and p. w. robbins , eds. biology ofcarbohydrates . vol. 2 . john wiley & sons , new york.carver, j. p. , and d. a. cumming . 1987 . sitedirected processing of nlinked oligosaccharides.the role of threedimensional structure. proc. intl. symp. carbohydr. chem. , ithaca , newyork .case, d. a. , and a. j. mccammon . 1986 . pp. 222233 in d. l. beveridge and w. l. jorgensen ,eds. computer simulation of chemical and biological systems . ann. n.y. acad. sci. ,vol. 482 .cech, t. r. 1987 . the chemistry of selfsplicing rna and rna enzymes . science 236:15321537 .cech, t. r. , n. k. tanner , i. tinoco , jr. , b. r. weir , m. zuker , and p. s. perlman . 1983 .secondary structure of thetetrahymena ribosomal rna intervening sequence: structuralhomology with fungal mitochondrial intervening sequences . proc. natl. acad. sci. usa80:39033907 .chou, p. y. , and g. d. fasman . 1974 . prediction of protein conformation . biochemistry13:222245 .clore, g. m. , and a. m. gronenborn . 1983 . theory of the time dependent transferred nuclearoverhauser effect: applications to structural analysis of ligandprotein complexes insolution . j. magn. reson . 53:423442 .cohen, f. e. , r. m. abarbanel , i. d. kuntz , and r. j. fletterick . 1983 . secondary structureassignment for/ proteins by a combinatorial approach . biochemistry 22:48944904 .cohen, f. e. , r. m. abarbanel , i. d. kuntz , and r. j. fletterick . 1986a . turn prediction inproteins using a patternmatching approach . biochemistry 25: 266275 .cohen, f. e. , p. a. kosen , i. d. kuntz , l. b. epstein , t. l. ciardelli , and k. a. smith . 1986b .structureactivity studies of interleukin2 . science 234:349352 .references162computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.corongiu, g. , and e. clementi . 1981 . simulations of the solvent structure for macromolecules ii.structure of water solvating na+bdna at 300k and a model for conformationaltransitions induced by solvent variations . biopolymers 20:24272483 .crippen, g. m. 1984 . conformational analysis by scaled energy embedding . j. comput. chem.5:548554 .dabrowski, j. , u. dabrowski , p. hanfland , m. kordowicz and w. e. hull . 1986 . structuredetermination of peracetylated glycosphingolipids by oneand twodimensional1h nmr at360 and 500 mhz . magn. reson. chem. 23:5969 .dayhoff, m. o. 1978 . atlas of protein sequence and structure . vol. 5,suppl.3 . nationalbiomedical research foundation , washington, d.c.diamond, r. 1966 . a mathematical modelbuilding procedure for proteins . acta crystallograph .a21:253266 .dixon, r. a. f. , b. k. kobilka , d. j. strader , j. l. benovic , h. g. dohlman , t. frielle , m. a.bolanowski , c. d. bennett , e. rands , r.e. diehl , r. a. mumford , e. e. slater , i. s.sigal , m. g. caron , r. j. lefkowitz , and c. d. strader . 1986 . cloning of the gene andcdna for mammalian badrenergic receptor and homology with rhodopsin . nature(london) 321:7579 .doe (u.s. department of energy) . 1987 . summary report of a workshop on a carbohydratestructure data base . doe/er0310 . washington, d.c.doolittle, r. f. 1985 . the genealogy of some recently evolved vertebrate proteins . trends inbiochemical sciences 10:233237 .drew, h. r. , and r. e. dickerson . 1981 . structure of a bdna dodecamer iii. geometry ofhydration . j. mol. biol. 151:535556 .eisenberg, d. , r. m. weiss , and t. c. terwilliger . 1984 . the hydrophobic moment detectsperiodic periodicity in protein hydrophobicity . proc. natl. acad. sci. usa 81:140144 .elber, r. , and m. karplus . 1987 . multiple conformational states of proteins: a moleculardynamics analysis of myoglobin . science 235:318321 .ermak, d. l. , and j. a. mccammon . 1978 . brownian dynamics with hydrodynamic interactions .j. chem. phys. 69:13521360 .ernst, r. , g. bodenhausen , and a. wokaun . 1987 . principles of nuclear magnetic resonance inone and two dimensions . clarendon press , oxford . 610 pp .feldmann, r. j. , d. h. bing , m. potter , c. mainhart , b. furie , b. c. furie , l. h. caporale .1985 . on the construction of computer models of proteins by the extension ofcrystallographic structures . ann. n.y. acad. sci. 439:1243 .finermoore, j. , and r. m. stroud . 1984 . amphipathic analysis and possible formation of the ionchannel in an acetylcholine receptor . proc. natl. acad. sci. usa 81:155159 .fitzwater, s. , and h. a. scheraga . 1982 . combinedinformation protein structure refinement:potential energyconstrained realspace method for refinement with limited diffractiondata . proc. natl. acad. sci. usa 79:21332137 .references163computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.freier, s. m. , r. kiersek , j. a. jaeger , n. sugimoto , m. h caruthers , t. neilson , and d. h.turner . 1986 . improved free energy parameters for prediction of rna duplex stability .proc. natl. acad. sci. usa 83:93739377 .friedman, h. l. , c. v. krishnan , and c. jolicoeur . 1973 . ionic interactions in water . ann. n.y.acad. sci. 204:7999 .fujinaga, m. , a. r. sielecki , r. j. read , w. ardelt , m. laskowski, jr. , and m. n. g. james .1987 . crystal and molecular structures of the complex of  chymotrypsin with itsinhibitor turkey ovomucoid third domain at 1.8 å resolution . j. mol. biol. 195:397418ghose, a. k. , and g. m. crippen . 1985 . geometrically feasible binding modes of a flexible ligandmolecule at the receptor site . j. comput. chem. 6:350359 .ghosh, i. , and j. a. mccammon . 1987 . sidechain rotational isomerization of proteins. dynamicssimulation with solvent surroundings . biophys. j. 51:637641 .gibson, k. d. , and h. a. scheraga . 1967 . minimization of polypeptide energy. i. preliminarystructures of bovine pancreatic ribonuclease speptide . proc. natl. acad. sci. usa .58:420427 .gibson, k. d. , and h. a. scheraga . 1988 . the multipleminima problem in protein folding . in m.h. sarma and r. h. sarma , eds. structure and expression: vol. 1. from proteins toribosomes . adenine press , guilderland, n.y.gilson, m. , a. rashin , r. fine , and b. honig . 1985 . on the calculation of electrostaticinteractions in proteins . j. mol. biol. 184:503516 .g, m. 1981 . correlation of dna exonic regions with protein structural units in haemoglobin .nature (london) 291:9092 .g, m. , and h. a. scheraga . 1984 . molecular theory of the helixcoil transition in polyaminoacids. v. explanation of the different conformational behavior of valine, isoleucine, andleucine in aqueous solution . biopolymers 23:19611977 .goodford, p. j. 1984 . drug design by the method of receptor fit . j. med. chem. 27:557564 .goodford, p. j. 1985 . a computational procedure for determining energetically favored bindingsites on biologically important macromolecules . j. med. chem. 28:849857 .green, d. w. , v. m. ingram , and m. f. perutz . 1954 . the structure of haemoglobin. iv. signdetermination by the isomorphous replacement method . proc. roy. soc. a 225:287 .greer, j. 1985 . protein structure and function by comparative model building . ann. n.y. acad.sci. 439:4463 .hagler, a. t. , j. moult , and d. j. osguthorpe . 1980a . monte carlo simulation of the solventstructure in crystals of a hydrated cyclic peptide . biopolymers 19:395418 .hagler, a. t. , d. j. osguthorpe , and b. robson . 1980b . monte carlo simulation of waterbehavior around the dipeptide nacetylalanylmethylamide . science 208:599601 .hakomori, s. 1986 . glycosphingolipids . sci. amer. 254(5):4453 .hare, d. r. , and b. r. reid . 1986 . three dimensional structure of a dna hairpin in solution: twodimensional nmr studies and distance geometry calculations on d(cgcgttttcgcg) .biochemistry 25:53415350 .references164computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.harrison, s. c. , a. j. olson , c. e. schutt , f. k. winkler , and g. brigogne . 1978 . tomato bushystunt virus at 2.9 å resolution . nature (london) 276:368373 .havel, t. f. , g. m. crippen , and i. d. kuntz . 1979 . effects of distance constraints onmacromolecular conformation. ii. simulation of experimental results and theoreticalpredictions . biopolymers 18:7381 .havel, t. f. , and k. wüthrich . 1985 . an evaluation of the combined use of nuclear magneticresonance and distance geometry for the determination of protein conformation insolution . j. mol. biol. 182:281294 .hayesroth, b. , b. buchanan , o. lichtarge , m. hewett , r. altman , j. brinkley , c. cornelius ,b. duncan , o. jardetzky . 1986 . protein: deriving protein structure from constraints . pp.904909 in proceedings of aaai86, fifth national congress on artificial intelligencevol. 2 . morgan kaufman , los altos, ca.henderson, r. 1979 . the structure of bacterorhodopsin and its relevance to other membraneproteins . soc. gen. physiol. ser. 33:315 .hendrickson, w. a. , and j. h. konnert . incorporation of stereochemical information intocrystallographic refinement . 1980 . pp. 13.0113.26 in diamond, r. , s. rameseshan , andk. venkatesan , eds. computing in crystallography . indian academy of sciences ,bangalore, india .hendrickson, w. a. 1985 . stereochemically restrained refinement of macromolecular structures .pp. 252270 in h. w. wyckoff , c. w. hirs , and s. n. timasheff , eds. methods inenzymology 115 . academic press , new york .henry, e. r. , m. levitt , and w. a. eaton . 1985 . molecular dynamics simulation ofphotodissociation of carbon monoxide from hemoglobin . proc. natl. acad. sci. usa82:20342038 .hermans, j. , ed. 1985 . molecular dynamics and protein structure . proceedings of a workshopheld 1318 may 1984 at the university of north carolina . polycrystal book service ,western springs, ill. 194 pp.hermans, j. and s. shankar . 1987 . the free energy of xenon binding to myoglobin from moleculardynamics simulation . isr. j. chem 27:225227 .hesselink, f. t. , t. ooi , and h. a. scheraga . 1973 . conformation energy calculations.thermodynamic parameters of the helixcoil transition for poly(llysine) in aqueous saltsolution . macromolecules 6:541552 .hingerty, b. , and s. broyde . 1982 . conformation of the deosydinucleoside monophosphatedcpdg modified at carbon 8 of guanine with 2(acetylamino)fluorene . biochemistry21:32433252 .hodes, z. i. , g. némethy , and h. a. scheraga . 1979a . model for the conformational analysis ofhydrated peptides. effect of hydration on the conformational stability of the terminallyblocked residues of the 20 naturally occurring amino acids . biopolymers 18:15651610 .hodes, z. i. , g. némethy , and h. a. scheraga . 1979b . influence of hydration on theconformational stability and formation of bends in terminally blocked dipeptides .biopolymers 18:16111634 .hogle, j. , m. chow , and d. filman . 1985 . threedimensional structure of poliovirus at 2.0 åresolution . science 229:1359 .hol, w. g. 1986 . protein crystallography and computer graphics š toward rational drug design .angew. chem., int. ed. engl. 25:767778 .references165computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.homans, s. w. , r. a. dwek , and t. w. rademacher . 1987 . solution conformations of nlinkedoligosaccharides . biochemistry 26:65716578 .hopfinger, a. j. 1985 . computerassisted drug design . j. med. chem. 28:11331139 .humber, l. g. , a. h. philips , f. t. bruderlein , m. gotz , k. voith . 1979. mapping the dopaminereceptor: some primary and accessory binding sites . pp. 227242 in e. c. olson and r. e.christofferson , eds. 1979 . computerassisted drug design . acs symposium series112 , american chemical society , washington, d.c.humblet, c. , and g. r. marshall . 1981 . threedimensional computer modeling as an aid to drugdesign . drug dev. res. 1:409434 .hwang, j. k. , and a. warshel . 1987 . semiquantitative calculations of catalytic free energies ingenetically modified enzymes . biochemistry 26:26692670 .ingolia, t. d. , and e. a. craig . 1982 . four small drosophila heat shock proteins are related to eachother and to mammalian alpha crystallin . proc. natl. acad. sci. usa 79:23602364 .jack, a. , and m. levitt . 1978 . refinement of large structures by simultaneous minimization ofenergy and r factor . acta crystallogr . a34:931 .james, m. n. g. , l. t. j. delbaere , and g. d. brayer . 1978 . amino acid sequence alignment ofbacterial and mammalian pancreatic serine proteases based on topological equivalences .can. j. biochem. 56:396402 .jardetzky, o. 1980 . nature of molecularconformations inferred from highresolution nmr ,biochim. biophys. acta 621:227232 .jones, t. a. 1985 . interactive computer graphics: frodo . pp. 157170 in wyckoff, h. w. , c. w.hirs , and s. n. timashoff , eds. methods in enzymology 115 . academic press , newyork .jorgensen, w. l. 1982 . monte carlo simulation of nbutane in water. conformational evidence forthe hydrophobic effect . j. chem. phys. 77:57575765 .jorgensen, w. l. in press . energy profiles for organic reactions in solution . r. d. levine , j.jortner , and s. a. rice , eds. adv. chem. phys. , special volume. evolution of sizeeffects in chemical dynamics . john wiley & sons , new york .jorgensen, w. l. , j. chandrasekhar , j. d. madura , r. w. impey , and m. l. klein . 1983 .comparison of simple potential functions for simulating liquid water . j. chem. phys.79:926935 .jorgensen, w. l. , and c. ravimohan . 1985 . monte carlo simulation of differences in free energiesof hydration . j. chem. phys. 83:30503054 .kabsch, w. , and c. sander . 1983 . how good are predictions of protein secondary structure? febslett. 155:179182 .kainosho, m. , and t. tsuji . 1982 . assignment of the three methionyl carbonyl carbon resonancesinstreptomyces subtillsin inhibitor by a carbon13 and nitrogen15 doublelabelingtechnique. a new strategy for structural studies of proteins in solution . biochemistry21:62736279 .kainosho, m. , h. nagao , and t. tsuji . 1987 . local structural features around the cterminalsegment ofstreptomyces subtilisin inhibitor studied by carbonyl carbon nuclear magneticresonances of three phenylalanyl residues . biochemistry 26:10681075 .references166computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.kaiser, e. t. , and f. j. kézdy . 1984 . amphiphilic secondary structure: design of peptidehormones . science 223:249255 .kang, y. k. , g. némethy , and h. a. scheraga . 1987 . free energies of hydration of solutemolecules . j. phys. chem. 91:41054120 .kaptein, r. , e. r. p. zuiderweg , r. m. scheek , r. boelens , and w. f. van gunsteren . 1985 . aprotein structure from nuclear magnetic resonance data . lac repressor headpiece . j. mol.biol. 182:179182 .karplus, m. , and j. a. mccammon . 1983 . dynamics of proteins: elements and function . ann.rev. biochem. 52:263300 .kauzmann, w. 1959 . some factors in the interpretation of protein denaturation . advan. prot.chem . 14:164 .kendrew, j. c. , r. e. dickerson , b. e. strandberg , r. g. hart , d. r. davies , d. c. phillips , andv. c. shore . 1960 . structure of myoglobin . nature (london) 185:422427 .klapper, i. , r. hagstrom , r. fine , k. sharp , and b. honig . 1986 . focussing of electric fields inthe active site of cuzn superoxide dismutose: effects of ionic strength and aminoacidmodification . proteins 1:4759 .klein, b. j. , and g. r. pack . 1983 . calculations of the spatial distribution of charge density in theenvironment of dna . biopolymers 22:23312352 .klein, t. e. , c. huang , t. e. ferrin , r. langridge , c. hansch . 1986 . computerassisted drugreceptor mapping analysis . pp. 147158 in t. h. pierce , and b. a. mohne , eds. artificialintelligence applications in chemistry . acs symposium series 306 . american chemicalsociety , washington, d.c.kopka, m. l. , p. pjura , c. yoon , d. goodsell , r. e. dickerson . 1985a . the bigning of netropsinto doublehelical bdna of sequence cgcgaattbrcgcg: single crystal xraystructure analysis . pp. 461483 in e. clementi , g. corongiu , m. h. sarma , and r.sarma , eds. structure and motion: membranes, nucleic acids and proteins . adeninepress , new york .kopka, m. l. , c. yoon , d. goodsell , p. pjura , r. e. dickerson . 1985b . the molecular origin ofdnadrug specificity in netropsin and distamycin . proc. nat. acad. sci. usa82:13761380 .kopka, m. l. , c. yoon , d. goodsell , p. pjura , r. e. dickerson . 1985c . the binding of anantitumor drug to dna; netropsin and cgcgaattbrcgcg . j. mol. biol.183:553563 .kosen, p. a. , r. m. scheek , h. naderi , v. j. basus , s. manogaran , p. g. schmidt , n. j.oppenheimer , and i. d. kuntz . 1986 . twodimensional1h nmr of three spinlabeledderivatives of bpti . biochemistry 25:23562364 .krüger, p. , w. strassburger , a. wollmer , and w. f. van gunsteren . 1985 . a comparison of thestructure and dynamics of avian pancreatic polypeptide hormone in solution and in thecrystal . eur. biophys. j. 13:7388 .references167computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.kubo, t. , k. fukuda , a. mikami , a. maeda , h. takahashi , m. mishina , t. haga , k. haga , a.ichiyama , k. kangawa , m. kojima , h. matsuo , t. hirose , and s. numa . 1986 .cloning, sequencing and expression of complementary dna encoding the muscarinicacetylcholine receptor . nature (london) 323:411416 .kuntz, i. d. 1972 . protein folding . j. am. chem. soc. 94:40094012 .kuntz, i. d. 1975 . approach to the tertiary structure of globular proteins . j. am. chem. soc.97:43624366 .kuntz, i. d. , j. m. blaney , s. j. oatley , r. langridge , and t. ferrin . 1982 . a geometricapproach to macromoleculeligand interactions . j. mol. biol. 161:269288kyte, j. , and r. f. doolittle . 1982 . a simple method for displaying the hydropathic character of aprotein . j. mol. biol. 157:105132 .laue, e. d. , j. skilling , j. staunton . 1985 . maximum entropy reconstruction of spectra containingantiphase peaks . j. magn. reson. 63:418424 .lemaster, d. m. , and f. m. richards . 1985 . 1h15n heteronuclear nmr studies of e. colithioredoxin in samples isotopically labeled by residue type . biochemistry 24:72637268 .lemieux, r. u. , and k. bock . 1983 . the conformational analysis of oligosaccharides by hnmrand hsea calculation . arch. biochem. biophys. 221:125134 .lemieux, r. u. , a. p. venot , u. spohr , p. bird , g. mandal , n. morishima , o. hindsgaul , andd. r. bundle . 1985 . molecular recognition. v. the binding of the human b blood groupdeterminant by hybridoma monoclonal antibodies . can. j. chem. 63:26642668 .levinthal, c. 1966 . molecular modelbuilding by computer . sci. am. 214(6):4252levitt, m. 1969 . detailed molecular model for transfer ribonucleic acid . nature (london)224:759763 .levitt, m. 1982 . protein conformation, dynamics and folding by computer simulation . annu. rev.biophys. bioeng . 11:251271 .levitt, m. , and c. chothia . 1976 . structural patterns in globular proteins . nature (london)261:552558 .levy, r. m. , m. karplus , and j. a. mccammon . 1979 . diffusive langevin dynamics of modelalkanes . chem. phys. lett. 65:411 .levy, r. m. , m. karplus , and p. g. wolynes . 1981 . nmr relaxation parameters in moleculeswith internal motion: exact langevin trajectory results compared with simplifiedrelaxation models . j. am. chem. soc. 103:59986011 .lewis, p. n. , f. a. momany , and h. a. scheraga . 1971 . folding of polypeptide chains inproteins: a proposed mechanism for folding . proc. natl. acad. sci. usa 68:22932297 .lipman, d. , and w. pearson . 1985 . rapid and sensitive protein similarity searches . science227:14351441 .lybrand, t. , j. a. mccammon , and g. wipff . 1986 . theoretical calculation of relative bindingaffinity in hostguest systems . proc. natl. acad. sci. usa 83:833835 .manning, g. s. 1978 . the molecular theory of polyelectrolyte solutions with applications to theelectrostatic properties of polynucleotides . q. rev. biophys. 11:179246 .references168computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.markley, j. l. 1987 . oneand twodimensional nmr investigations of the consequences of aminoacid replacements in proteins . pp. 1533 in d. l. oxender , and c. f. fox , eds. proteinengineering . a. r. liss , inc. , new york .marshall, g. r. , c. d. barry , h. e. bosshard , r. a. dammkoehler , d. a. dunn . 1979 . theconformational parameter in drug design: the active analog approach . pp. 205226 in e.c. olson , and r. e. christofferson , eds. computerassisted drug design . acssymposium series 112 , american chemical society , washington, d.c.martin, y. c. 1981 . a practitioner's perspective of the role of quantitative structure activity analysisin medicinal chemistry . j. med. chem. 24:229237 .mccammon, j. a. , s. h. northrup , m. karplus , and r. m. levy . 1980 . helixcoil transitions in asample polypeptide model . biopolymers 19:20332045 .mcintosh, l. p. , r. h. griffey , d. g. muchmore , c. p. nielson , a. g. redfield , and f. w.dahlquist . 1987 . protein nmr measurements of bacteriophage t4 lysozyme aided by15nisotopic labeling: structural and dynamic studies of large proteins . proc. natl. acad. sci.usa 84:12441248 .mezei, m. , p. k. mehrotra , and d. l. beveridge . 1985 . monte carlo determiniation of the freeenergy and internal energy of hydration for the ala dipeptide at 25°c . j. am. chem. soc.107:22392245 .michel, h. 1982 . threedimensional crystals of a membrane protein complex. the photosyntheticreaction centre fromrhodopseudomonas viridis . j. mol. biol. 158:567572 .miller, m. h. , and h. a. scheraga . 1976 . calculation of the structure of collagen models. role ofinterchain interactions in determining the triplehelical coiledcoil conformation. i. poly(glycylprolylprolyl) . j. polym. sci. polym. syrup . 54:171200 .mishina, m. , t. kurosaki , t. tobimatsu , y. morimoro , m. noda , t. yamamoio , m. terao , j.lindstrom , t. takahashi , m. kuno , and s. numa . 1984 . expression of functionalacetylcholine receptor from cloned cdnas . nature (london) 307:604613 .moult, j. , and m. n. g. james . 1986 . an algorithm for determining the conformation ofpolypeptide segments in proteins by systematic search . proteins 1:146163 .murthy, c. s. , r. bacquet , and p. j. rossky . 1985 . ionic distribution near polyelectrolytes. acomparison of theoretical approaches . j. phys. chem. 89:701710 .némethy, g. , and h. a. scheraga . 1977 . protein folding . q. rev. biophys. 10:239352 .némethy, g. z. i. hodes , and h. a. scheraga . 1978 . a model for hydration of peptides and itsapplication to the conformational analysis of terminally blocked amino acids anddipeptides . proc. natl. acad. sci. usa 75:57605764 .neumann, m. 1985 . the dielectric constant of water. computer simulation with mcy potential .82:56635672 .neumann, m. 1986 . dielectric relaxation in water. computer simulations with the tip4p potential .j. chem. phys. 85:15671580 .references169computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.nilsson, l. , g. m. clore , a. m. gronenborn , a. t. brunger , and m. karplus . 1986 . structurerefinement of oligonucleotides by molecular dynamics with noe interproton distancerestraints: application to 5' d(cgtacg)2ﬁ . j. mol. biol. 188:455475 .nirenberg, m. , p. leder , m. bernfield , r. brimacombe , j. trupin , f. rottman , c. o'neal .1965 . rna codewords and protein synthesis, vii. on the general nature of the rnacode . proc. natl. acad. sci. usa 53:11611168 .nishikawa, k. 1983 . assessment of secondarystructure prediction of proteins. comparison ofcomputerized choufasman method with others . biochim. biophys. acta 748:285299 .noguti, t. , and n. g . 1985 . efficient monte carlo method for simulation of fluctuatingconformations of native proteins . biopolymers 24:527546 .okuyama, k. , n. tanaka , t. ashida , and m. kakudo . 1976 . structure analysis of a collagenmodel polypeptide, (proprogly),10 . bull . chem. soc. jpn. 49:18051810 .olson, e. c. , and r. e. christoffersen , eds. 1979 . computerassisted drug design . acssymposium series 112 , american chemical society , washington, d.c. 619 pp.paine, g. h. , and h. a. scheraga . 1987 . prediction of the native conformation of a polypeptide bya statisticalmechanical procedure. iii. probable and average conformations of enkephalin .biopolymers 26:11251162 .palmer, k. a. , h. a. scheraga , j. f. riordan , and b. l. vallee . 1986 . a preliminary threedimensional structure of angiogenin . proc. natl. acad. sci. usa 83:19651969 .pauling, l. , r. b. corey , and h. r. branson . 1951 . the structure of proteins: two hydrogenbonded helical configurations of the polypeptide chain . proc. natl. acad. sci. usa37:205211 .perutz, m. f. 1965 structure and function of hemoglobin. i. a tentative atomic model of horseoxyhemoglobin . j. mol. biol. 13:646668 .perutz, m. f. , g. fermi , d. j. abraham , c. poyart , and e. bursaux . 1986 . hemoglobin as areceptor of drugs and peptides: xray studies of the tereochemistry of binding . j. am.chem. soc. 108:10641078 .perutz, m. f. , j. c. kendrew , and h. c. watson . 1965 . structure and function of hemoglobin. ii.some relations between polypeptide chain configuration and amino acid sequence . j. mol.biol. 13 : 669678 .perutz, m. f. , m. g. rossman , a. f. cullis , h. muirhead , g. will , and a. c. t. north . 1960 .structure of hemoglobin . nature (london) 185 : 416421 .petrillo, e. w. , and m. a. ondetti . 1982 . angiotensinconverting enzyme inhibitors: medicinalchemistry and biological activity . med. res. revs. 2: 141 .petsko, g. a. , and d. ringe . 1984 . fluctuations in protein structure from xray diffraction . annu.rev. biophys. bioeng. 13: 331371 .pettitt, b. m. , and m. karplus . 1985 . the potential of mean force surface for the alanine dipeptidein aqueous solution: a theoretical approach . chem. phys. lett. 121: 194201 .pettitt, b. m. , and p. j. rossky . 1986 . alkali halides in water: ionsolvent correlations and ionionpotentials of mean force at infinite dilution . j. chem. phys. 84:58365844 .references170computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.pettitt, b. m. , m. karplus , and p. j. rossky . 1986 . integral equation model for aqueous solvationof polyatomic solutes: application to the determination of the free energy surface for theinternal motion of biomolecules . j. phys. chem. 90:63356345 .pfandler, p. , and g. bodenhausen . 1986 . automated analysis of twodimensional nmr spectra ofmixtures by pattern recognition . j. magn. reson . 70:7178 .phillips, d. c. 1967 . lysozyme and the development of protein crystal chemistry . proc. int. cong.biochem. ( tokyo) 7:6382 .pincus, m. r. , and h. a. scheraga . 1979 . conformational energy calculations of enzymesubstrateand enzymeinhibitor complexes of lysozyme. 2. calculation of the structures ofcomplexes with a flexible enzyme . macromolecules 12:633644 .plattner, j. j. , j. greer , a. k. l. fung , h. stein , h. d. kleinert , h. l. sham , j. r. smital , and t.j. perun . 1986 . peptide analogs of angeniotensinogen. effect of peptide chain length onrenin inhibition . biochem. biophys. res. commun. 139: 982990 .postma , j. p. m. , h. j. c. berendsen , and j. r. haak . 1982 . thermodynamics of cavity formationin water: a molecular dynamics study . faraday symp. chem. soc. 17:5567 .rao, n. r. , u. c. singh , p. a. bash , and p. a. kollman . 1987 . free energy perturbationcalculations on binding and catalysis after mutating asn 155 in subtilisin . nature(london) 328:551553 .rao, s. t. , and m. g. rossmann . 1973 . comparison of supersecondary structures in proteins . j.mol. biol. 76:241256 .richards, f. m. , 1968 . the matching of physical models to three dimensional electron densitymaps: a simple optical device . j. mol. biol. 37:225230 .richards, f. m. 1986 . protein design: are we ready? pp. 171196 in d. l. oxender , ed. proteinstructure, folding and design . alan r. liss , new york .richardson, j. s. 1981 . the anatomy and taxonomy of protein structure . pp. 168340 in c. b.anfinsen , j. t. edsall , and f. m. richards , eds. advances in protein chemistry . vol. 34.academic press , new york .robson, b. and d. j. osguthorpe . 1979 . refined models for computer simulation of proteinfolding . j. mol. biol. 132:1951 .robson, b. 1986 . the prediction of peptide and protein structure . pp. 567607 in a. darbre , ed.practical protein chemistry  a handbook . john wiley & sons , new york .rose, g. d. 1985 . automated recognition of domains in globular proteins . methods enzymol .115:430440 .rose, g. d. , l. m. gierasch , and j. a. smith . 1985 . turns in peptides and proteins . pp. 1109 inadvances in protein chemistry . vol. 37 . academic press , new york .rosenberg, r. o. , m. rao , and b. j. berne . 1982 . hydrophobic effect on chain folding. the transto gauche isomerization of nbutane in water . j. am. chem. soc. 104:76477649 .rossmann, m. g. , ed. 1972 . the molecular replacement method . gordon & breach publishers ,new york .rossmann, m. g. , and p. argos . 1977 . the taxonomy of protein structure . j. mol. biol.109:99129 .references171computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.rossmann, m. g. , e. arnold , j. w. erickson , j. e. johnson , g. kamers , m. luo , a. g. mosser ,r. r. rueckert , b. sherry , and g. friend . 1985 . structure of a human common coldvirus and functional relationship to other picornaviruses . nature (london) 317:145153 .scarsdale, j. n. , p. ram , and j. h. prestegard . in press . a molecular mechanics nmrpseudoenergy approach to the solution conformation of glycolipids . j. comp. chem.scheraga, h. a. 1984 . protein structure and function from a collodial to a molecular view .carlsberg rev. commun . 49:155 .schiffer, j. , and a. b. edmundson . 1967 . use of helical wheels to represent the structures ofproteins and to identify segments with helical potential . biophys. j. 7:121135 .schussheim, a. e. , and d. cowburn . 1987 . deconvolution of high resolution 2dnmr signals bydigital signal processing with linear predictive singular value decomposition . j. magn.reson . 71:371378 .seibel, g. l. , u. c. singh , and p. a. kollman . 1985 . a molecular dynamics simulation of doublehelical bdna including counterions and water . proc. natl. acad. sci. usa .sekharudu, y. c. , m. biswas , and v. s. r. rao . 1986 . complex carbohydrates. 2 . the modes ofbinding of complex carbohydrates to concanavalin a  a computer modeling approach .int. j. biol. macromol . 8:919 .sela, m. , f. h. white , jr. , and c. b. anfinsen . 1957 . reductive cleavage of disulfide bridges inribonuclease . science 125:691 .sheriff, s. , e. w. silverton , e. a. padlan , g. h. cohen , s. j. smithgill , b. c. finzel , and d. r.davies . in press . threedimensional structure of an antibody antigen complex . proc.natl. acad. sci. usa .singh, u. c. , f. brown , p. a. bush , and p. a. kollman . 1987 . an approach to the application offree energy perturbation methods using molecular dynamics: applications to thetransformation of ch3ohch3ch3, h3o+nh4+, glyala, alaphe in aqueoussolution and to h3o+ (h2o)3nh4+(h2o)3 in the gas phase . j. am. chem. soc.109:16071614 .smith, j. l. , w. a. hendrickson , r. b. honzatko , and s. sheriff . 1986a . structural heterogeneityin protein crystals . biochemistry 25:50185027 .smith, t. j. , m. j. kremer , m. luo , g. vriend , e. arnold , g. damer , m. g. rossmann , m. a.mckinlay , g. d. diana , and m. j. otto . 1986b . the site of attachment in humanrhinovirus 14 for antiviral agents that inhibit uncoating . science 233:12861293 .smithgill , s. j. , j. a. rupley , j. r. princes , r. p. ceerty , and h. a. scheraga . 1984 .experimental identification of a theoreticallypredicted ﬁleftsidedﬂ binding mode for(glcnac)6 in the active site of liponyml . biochemistry 23:993997 .snider , m. d. 1984 . biosynthesis of glycoproteins . formation of nlinkedoligosaccharides . pp.163198 in v. ginsburg and p. w. robbins , eds. biology of carbohydrates . vol. 2 . johnwiley & sons , new york .soumpasis, d. 1984 . statistical mechanics of the bz transition of dna: contribution of diffuseionic interactions . proc. natl. acad. sci. usa 81:51165120 .steinhauser, o. 1983 . on the dielectric theory and computer simulation of water . chem. phys.79:465482 .references172computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.stillinger, f. h. 1975 . theory and molecular models for water . adv. chem. phys. 31:1101 .stroud, r. m. , and j. finermoore . 1985 . acetylcholine receptor structure, function, andevolution . annu. rev. cell. biol. 1:317351 .sussman, j. l. 1985 . constrainedrestrained least squares refinement of proteins and nucleic acids .pp. 271302 in wyckoff, h. w. , c. w. hirs ,and s. n. timasheff , eds. methods inenzymology , 115 . academic press , new york .suzuki, e. , n. pattabiraman , g. zon , and t. l. james . 1986 . solution structure of [d(at)5]2 viacomplete relaxation matrix analysis of two dimensional noe spectra and molecularmechanics calculations: evidence for a hydration tunnel . biochemistry 25:68546865 .swenson, m. k. , a. w. burgess and h. a. scheraga . 1978 . conformational analysis ofpolypeptides: applications to homologous proteins . pp. 115142 in b. paullaman , ed.frontiers in physical chemical biology . academic press , new york .taylor, w. r. , and j. m. thornton . 1983 . prediction of supersecondary structure in proteins .nature (london) 301:540542 .teleman, o. 1986 . molecular dynamics simulation of polyatomic molecules in aqueoussolution . thesis . university of lund , sweden . 180 pp .tembe, b. l. , and a. mccammon . 1984 . ligandreceptor interactions . comp. chem. 8:281283 .tidor, b. , k. k. irikura , b. r. brooks , and m. karplus . 1983 . dynamics of dna oligomers . j.biomol. struc. dyn. 1:231252 .tilton, r. f. , u. c. singh , i. d. kuntz , and p. a. kollman . in press . protein ligand dynamics: a96 picosecond simulation of a myoglobinxenon complex . j. mol. biol.tinoco, i., jr. , o. c. uhlenbeck , and m. d. levine . 1971 . estimation of secondary structure inribonucleic acids . nature (london) 230:362367 .tully, j. c. 1981 . computer simulation of the dynamics of chemical processes . comp. chem.5:159165 .tvaroska, i. , and s. perez . 1986 . conformation energy calculations for oligosaccharides: acomparison of methods and a strategy of calculation . carbohydr. res. 149:389410 .ultsch, m. h. , a. a. kossiakoff , j. burnier , j. a. wells , d. p. powers , b. a. katz , r. r. bolt ,b. c. cunningham , and s. s. power . 1985 . industrial applications of enzymeengineering . world biotech . rep. 1:611616 .unwin, p. , and p. d. ennis . 1984 . two configurations of a channelforming membrane protein .nature (london) 307:609612 .van gunsteren , w. f. , and h. j. c. berendsen . 1984 . computer simulations as a tool for tracingthe conformational differences between proteins in solution and in the crystalline state . j.mol. biol. 176:559564 .van gunsteren , w. f. , and m. karplus . 1982 . protein dynamics in solution and in a crystallineenvironment: a molecular dynamics study . biochemistry 21:22592274 .van gunsteren , w. f. , h. j. c. berendensen , j. hermans , w. g. j. hol , and j. p. m. postma .1983 . computer simulation of the dynamics of hydrated protein crystals and itscomparison with xray data . proc. natl. acad. sci. usa 80:43154319 .references173computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.van gunsteren , w. f. , h. j. c. berendsen , r. g. geurtsen , and h. r. j. zwinderman . 1986 . amolecular dynamics computer simulation of an eight base pair dna fragment in aqueoussolution: comparison with experimental twodimensional nmr data . ann. n.y. acad.sci. 482:287303 .wagner, g. , and d. bruhwiler . 1986 . toward the complete assignment of the carbon nmrspectrum of the bovine pancreatic trypsin inhibitor . biochemistry 25:58395843 .wallis, m. , s. l. howell , and k. w. taylor . 1985 . the biochemisty of the polypeptidehormones . j. wiley & sons , new york .wand, a. j. , h. roder , and s. w. englander . 1986 . twodimensional1h nmr studies ofcytochrome c: hydrogen exchange in the nterminal helix . biochemistry 25:11071114 .warme, p. k. , f. a. momany , s. v. rumball , r. w. tuttle , and h. a. scheraga . 1974 .computation of structures of homologous proteins. lactalbumin from lysozyme .biochemistry 13:768782 .warshel, a. 1981 . electrostatic basis of structurefunction correlation in proteins . acc. chem. res.9:284290 .warshel, a. , and f. sussman . 1986 . toward computeraided sitedirected mutagenesis ofenzymes . proc. natl. acad. sci. usa 83:38063810 .watson, j. d. , and f. h. c. crick . 1953 . molecular structure of nucleic acids . a structure fordeosyribosenucleic acid . nature (london) 171:737738 .weiner, s. j. , p. a. kollman , d. a. case , u. c. singh , c. ghio , g. alagona , s. profeta, jr. , andp. weiner . 1984 . a new force field for molecular mechanical simulation of nucleic acidsand proteins . j. am. chem. soc. 106:765784 .wetlaufer, d. b. 1973 . nucleation , rapid folding , and globular intrachainregions in proteins . proc.natl. acad. sci. usa 70:697701 .wilbur, w. j. , and d. j. lipman . 1984 . the context of dependent compari son of biologicalsequences . siam j. appl. math. 44:557567 .williams, a. l., jr. , and i. tinoco, jr. 1986 . a dynamic programming algorithm for findingalternative rna secondary structures . nucleic acids res. 14:299315 .williamson, m. p. , t. f. havels and k. wüthrich . 1985 . solution conformation of proteinaseinhibitor iia from bull seminal plasma by1h nuclear magnetic resonance and distancegeomety . j. mol. biol. 182:295315 .wise, m. , r. d. cramer , d. smiths and i. exman. 1983 . progress in threedimensional drugdesign: the use of realtime colour graphics and computer postulation of bioactivemolecules in dylomms . pp. 145146 in j. c. deardon , ed. quantitative approaches todrug design . elsevier , amsterdam .wong, c. f. , and j. a. mccammon . in press . computer simulation and the design of newbiological molecules . isr. j. chem.wüthrich, k. 1986 . nmr of proteins and nucleic acids . john wiley & sons , new york . 292 pp .xuong, n. g. , s. t. freer , r. hamlin , c. nielsen , and w. vernon . 1978 . the electronicstationary picture method for high speed measurement of reflection intensities fromcrystals with large unit cell dimensions . acta crystallogr . a34:289296 .references174computer assisted modeling: contributions of computational approaches to elucidating macromolecular...copyright national academy of sciences. all rights reserved.yu, r. k. , t. a. w. koerner , j. n. scarsdale , and j. h. prestegard . 1986 . elucidation ofglycolipid structure by proton nuclear magnetic resonance spectroscopy . chem. phys.lipids 42:2748 .zaug, a. j. , and t. r. cech . 1986 . the intervening sequence oftetrahymena is an enzyme .science 231:470475 .zichi, d. a. , and p. j. rossky . 1986 . molecular conformational equilibria in liquids . j. chem.phys. 84:17121723 .zuker, m. , and p. steigler . 1981 . optimal computer folding of large rna sequences usingthermodynamics and auxiliary information . nucleic acids res. 9:133148 .references175